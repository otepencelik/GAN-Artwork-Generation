{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "#parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "#parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "#parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "#parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "#parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "#parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "#parser.add_argument(\"--n_classes\", type=int, default=10, help=\"number of classes for dataset\")\n",
    "#parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
    "#parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "#parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
    "#opt = parser.parse_args()\n",
    "#print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameter_opt():\n",
    "    None\n",
    "opt = parameter_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.n_epochs=200\n",
    "opt.batch_size = 64\n",
    "opt.lr = 0.0002\n",
    "opt.b1 = 0.5\n",
    "opt.b2 = 0.999\n",
    "opt.n_cpu = 8\n",
    "opt.latent_dim = 100\n",
    "opt.n_classes = 27\n",
    "opt.img_size = 64\n",
    "opt.channels = 3\n",
    "opt.sample_interval = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim + opt.n_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure data loader\n",
    "#os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
    "#dataloader = torch.utils.data.DataLoader(\n",
    "#    datasets.MNIST(\n",
    "#        \"../../data/mnist\",\n",
    "#        train=True,\n",
    "#        download=True,\n",
    "#        transform=transforms.Compose(\n",
    "#            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "#        ),\n",
    "#    ),\n",
    "#    batch_size=opt.batch_size,\n",
    "#    shuffle=True,\n",
    "#)\n",
    "\n",
    "from dataloader_wikiart import *\n",
    "\n",
    "dataloader = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/637] [D loss: 0.501207] [G loss: 1.025522]\n",
      "[Epoch 0/200] [Batch 1/637] [D loss: 0.237407] [G loss: 0.984633]\n",
      "[Epoch 0/200] [Batch 2/637] [D loss: 0.155929] [G loss: 0.934533]\n",
      "[Epoch 0/200] [Batch 3/637] [D loss: 0.156103] [G loss: 0.901976]\n",
      "[Epoch 0/200] [Batch 4/637] [D loss: 0.105348] [G loss: 0.872902]\n",
      "[Epoch 0/200] [Batch 5/637] [D loss: 0.128893] [G loss: 0.843888]\n",
      "[Epoch 0/200] [Batch 6/637] [D loss: 0.076811] [G loss: 0.814623]\n",
      "[Epoch 0/200] [Batch 7/637] [D loss: 0.091339] [G loss: 0.771831]\n",
      "[Epoch 0/200] [Batch 8/637] [D loss: 0.068928] [G loss: 0.736516]\n",
      "[Epoch 0/200] [Batch 9/637] [D loss: 0.081164] [G loss: 0.703316]\n",
      "[Epoch 0/200] [Batch 10/637] [D loss: 0.101053] [G loss: 0.696367]\n",
      "[Epoch 0/200] [Batch 11/637] [D loss: 0.080394] [G loss: 0.673285]\n",
      "[Epoch 0/200] [Batch 12/637] [D loss: 0.096459] [G loss: 0.650023]\n",
      "[Epoch 0/200] [Batch 13/637] [D loss: 0.073343] [G loss: 0.650755]\n",
      "[Epoch 0/200] [Batch 14/637] [D loss: 0.085626] [G loss: 0.645087]\n",
      "[Epoch 0/200] [Batch 15/637] [D loss: 0.085673] [G loss: 0.662544]\n",
      "[Epoch 0/200] [Batch 16/637] [D loss: 0.077939] [G loss: 0.685698]\n",
      "[Epoch 0/200] [Batch 17/637] [D loss: 0.082015] [G loss: 0.703570]\n",
      "[Epoch 0/200] [Batch 18/637] [D loss: 0.071860] [G loss: 0.728526]\n",
      "[Epoch 0/200] [Batch 19/637] [D loss: 0.073149] [G loss: 0.718013]\n",
      "[Epoch 0/200] [Batch 20/637] [D loss: 0.067551] [G loss: 0.785202]\n",
      "[Epoch 0/200] [Batch 21/637] [D loss: 0.064490] [G loss: 0.800223]\n",
      "[Epoch 0/200] [Batch 22/637] [D loss: 0.085862] [G loss: 0.812508]\n",
      "[Epoch 0/200] [Batch 23/637] [D loss: 0.059823] [G loss: 0.832950]\n",
      "[Epoch 0/200] [Batch 24/637] [D loss: 0.061213] [G loss: 0.811038]\n",
      "[Epoch 0/200] [Batch 25/637] [D loss: 0.078509] [G loss: 0.821099]\n",
      "[Epoch 0/200] [Batch 26/637] [D loss: 0.078720] [G loss: 0.806102]\n",
      "[Epoch 0/200] [Batch 27/637] [D loss: 0.070877] [G loss: 0.828163]\n",
      "[Epoch 0/200] [Batch 28/637] [D loss: 0.063568] [G loss: 0.851014]\n",
      "[Epoch 0/200] [Batch 29/637] [D loss: 0.064810] [G loss: 0.813824]\n",
      "[Epoch 0/200] [Batch 30/637] [D loss: 0.076629] [G loss: 0.894859]\n",
      "[Epoch 0/200] [Batch 31/637] [D loss: 0.069525] [G loss: 0.818987]\n",
      "[Epoch 0/200] [Batch 32/637] [D loss: 0.065850] [G loss: 0.779103]\n",
      "[Epoch 0/200] [Batch 33/637] [D loss: 0.078898] [G loss: 0.937392]\n",
      "[Epoch 0/200] [Batch 34/637] [D loss: 0.080366] [G loss: 0.845592]\n",
      "[Epoch 0/200] [Batch 35/637] [D loss: 0.073754] [G loss: 0.773736]\n",
      "[Epoch 0/200] [Batch 36/637] [D loss: 0.058211] [G loss: 1.013382]\n",
      "[Epoch 0/200] [Batch 37/637] [D loss: 0.093435] [G loss: 0.657323]\n",
      "[Epoch 0/200] [Batch 38/637] [D loss: 0.134854] [G loss: 1.472161]\n",
      "[Epoch 0/200] [Batch 39/637] [D loss: 0.103134] [G loss: 0.524628]\n",
      "[Epoch 0/200] [Batch 40/637] [D loss: 0.060803] [G loss: 0.827579]\n",
      "[Epoch 0/200] [Batch 41/637] [D loss: 0.054817] [G loss: 0.989109]\n",
      "[Epoch 0/200] [Batch 42/637] [D loss: 0.052133] [G loss: 0.915219]\n",
      "[Epoch 0/200] [Batch 43/637] [D loss: 0.077267] [G loss: 0.730263]\n",
      "[Epoch 0/200] [Batch 44/637] [D loss: 0.060619] [G loss: 0.981547]\n",
      "[Epoch 0/200] [Batch 45/637] [D loss: 0.067965] [G loss: 0.824719]\n",
      "[Epoch 0/200] [Batch 46/637] [D loss: 0.069882] [G loss: 0.895204]\n",
      "[Epoch 0/200] [Batch 47/637] [D loss: 0.080735] [G loss: 0.825715]\n",
      "[Epoch 0/200] [Batch 48/637] [D loss: 0.094463] [G loss: 1.016794]\n",
      "[Epoch 0/200] [Batch 49/637] [D loss: 0.117264] [G loss: 0.447333]\n",
      "[Epoch 0/200] [Batch 50/637] [D loss: 0.143965] [G loss: 1.577239]\n",
      "[Epoch 0/200] [Batch 51/637] [D loss: 0.102538] [G loss: 0.727995]\n",
      "[Epoch 0/200] [Batch 52/637] [D loss: 0.065737] [G loss: 0.787979]\n",
      "[Epoch 0/200] [Batch 53/637] [D loss: 0.061626] [G loss: 0.880296]\n",
      "[Epoch 0/200] [Batch 54/637] [D loss: 0.068126] [G loss: 0.942312]\n",
      "[Epoch 0/200] [Batch 55/637] [D loss: 0.062323] [G loss: 0.827281]\n",
      "[Epoch 0/200] [Batch 56/637] [D loss: 0.046514] [G loss: 0.875849]\n",
      "[Epoch 0/200] [Batch 57/637] [D loss: 0.058019] [G loss: 0.863381]\n",
      "[Epoch 0/200] [Batch 58/637] [D loss: 0.053563] [G loss: 0.941873]\n",
      "[Epoch 0/200] [Batch 59/637] [D loss: 0.068516] [G loss: 0.707337]\n",
      "[Epoch 0/200] [Batch 60/637] [D loss: 0.088808] [G loss: 1.307429]\n",
      "[Epoch 0/200] [Batch 61/637] [D loss: 0.188508] [G loss: 0.320175]\n",
      "[Epoch 0/200] [Batch 62/637] [D loss: 0.142723] [G loss: 1.419481]\n",
      "[Epoch 0/200] [Batch 63/637] [D loss: 0.100946] [G loss: 0.771386]\n",
      "[Epoch 0/200] [Batch 64/637] [D loss: 0.071127] [G loss: 0.785135]\n",
      "[Epoch 0/200] [Batch 65/637] [D loss: 0.067485] [G loss: 1.077215]\n",
      "[Epoch 0/200] [Batch 66/637] [D loss: 0.085985] [G loss: 0.942437]\n",
      "[Epoch 0/200] [Batch 67/637] [D loss: 0.066415] [G loss: 0.963042]\n",
      "[Epoch 0/200] [Batch 68/637] [D loss: 0.066200] [G loss: 0.765567]\n",
      "[Epoch 0/200] [Batch 69/637] [D loss: 0.060110] [G loss: 0.903709]\n",
      "[Epoch 0/200] [Batch 70/637] [D loss: 0.057304] [G loss: 0.892752]\n",
      "[Epoch 0/200] [Batch 71/637] [D loss: 0.063410] [G loss: 0.916847]\n",
      "[Epoch 0/200] [Batch 72/637] [D loss: 0.057951] [G loss: 0.799987]\n",
      "[Epoch 0/200] [Batch 73/637] [D loss: 0.063601] [G loss: 0.946633]\n",
      "[Epoch 0/200] [Batch 74/637] [D loss: 0.093405] [G loss: 0.637887]\n",
      "[Epoch 0/200] [Batch 75/637] [D loss: 0.196781] [G loss: 1.736585]\n",
      "[Epoch 0/200] [Batch 76/637] [D loss: 0.255771] [G loss: 0.321717]\n",
      "[Epoch 0/200] [Batch 77/637] [D loss: 0.121024] [G loss: 0.921039]\n",
      "[Epoch 0/200] [Batch 78/637] [D loss: 0.115412] [G loss: 0.884961]\n",
      "[Epoch 0/200] [Batch 79/637] [D loss: 0.105882] [G loss: 0.781647]\n",
      "[Epoch 0/200] [Batch 80/637] [D loss: 0.089245] [G loss: 0.880323]\n",
      "[Epoch 0/200] [Batch 81/637] [D loss: 0.076522] [G loss: 0.911540]\n",
      "[Epoch 0/200] [Batch 82/637] [D loss: 0.079638] [G loss: 0.915840]\n",
      "[Epoch 0/200] [Batch 83/637] [D loss: 0.076166] [G loss: 0.932254]\n",
      "[Epoch 0/200] [Batch 84/637] [D loss: 0.057367] [G loss: 0.878970]\n",
      "[Epoch 0/200] [Batch 85/637] [D loss: 0.065171] [G loss: 0.859320]\n",
      "[Epoch 0/200] [Batch 86/637] [D loss: 0.078168] [G loss: 0.897173]\n",
      "[Epoch 0/200] [Batch 87/637] [D loss: 0.060313] [G loss: 0.921124]\n",
      "[Epoch 0/200] [Batch 88/637] [D loss: 0.082526] [G loss: 0.701023]\n",
      "[Epoch 0/200] [Batch 89/637] [D loss: 0.162516] [G loss: 1.392466]\n",
      "[Epoch 0/200] [Batch 90/637] [D loss: 0.156908] [G loss: 0.504050]\n",
      "[Epoch 0/200] [Batch 91/637] [D loss: 0.167738] [G loss: 1.115555]\n",
      "[Epoch 0/200] [Batch 92/637] [D loss: 0.097050] [G loss: 0.856564]\n",
      "[Epoch 0/200] [Batch 93/637] [D loss: 0.117693] [G loss: 0.725872]\n",
      "[Epoch 0/200] [Batch 94/637] [D loss: 0.097711] [G loss: 1.016912]\n",
      "[Epoch 0/200] [Batch 95/637] [D loss: 0.070632] [G loss: 0.965157]\n",
      "[Epoch 0/200] [Batch 96/637] [D loss: 0.087590] [G loss: 0.709074]\n",
      "[Epoch 0/200] [Batch 97/637] [D loss: 0.065315] [G loss: 1.090565]\n",
      "[Epoch 0/200] [Batch 98/637] [D loss: 0.084454] [G loss: 0.888568]\n",
      "[Epoch 0/200] [Batch 99/637] [D loss: 0.065276] [G loss: 0.858686]\n",
      "[Epoch 0/200] [Batch 100/637] [D loss: 0.075093] [G loss: 0.818656]\n",
      "[Epoch 0/200] [Batch 101/637] [D loss: 0.075420] [G loss: 0.940184]\n",
      "[Epoch 0/200] [Batch 102/637] [D loss: 0.081153] [G loss: 0.885573]\n",
      "[Epoch 0/200] [Batch 103/637] [D loss: 0.131451] [G loss: 0.954781]\n",
      "[Epoch 0/200] [Batch 104/637] [D loss: 0.090283] [G loss: 0.949788]\n",
      "[Epoch 0/200] [Batch 105/637] [D loss: 0.072372] [G loss: 0.882870]\n",
      "[Epoch 0/200] [Batch 106/637] [D loss: 0.089327] [G loss: 0.895001]\n",
      "[Epoch 0/200] [Batch 107/637] [D loss: 0.073013] [G loss: 0.944726]\n",
      "[Epoch 0/200] [Batch 108/637] [D loss: 0.090594] [G loss: 0.944191]\n",
      "[Epoch 0/200] [Batch 109/637] [D loss: 0.072061] [G loss: 0.800865]\n",
      "[Epoch 0/200] [Batch 110/637] [D loss: 0.075353] [G loss: 0.785369]\n",
      "[Epoch 0/200] [Batch 111/637] [D loss: 0.051444] [G loss: 1.016630]\n",
      "[Epoch 0/200] [Batch 112/637] [D loss: 0.057447] [G loss: 0.953885]\n",
      "[Epoch 0/200] [Batch 113/637] [D loss: 0.058454] [G loss: 0.908373]\n",
      "[Epoch 0/200] [Batch 114/637] [D loss: 0.059902] [G loss: 0.822570]\n",
      "[Epoch 0/200] [Batch 115/637] [D loss: 0.072492] [G loss: 0.850128]\n",
      "[Epoch 0/200] [Batch 116/637] [D loss: 0.062283] [G loss: 1.028322]\n",
      "[Epoch 0/200] [Batch 117/637] [D loss: 0.062005] [G loss: 0.746654]\n",
      "[Epoch 0/200] [Batch 118/637] [D loss: 0.055446] [G loss: 0.918582]\n",
      "[Epoch 0/200] [Batch 119/637] [D loss: 0.077794] [G loss: 0.911379]\n",
      "[Epoch 0/200] [Batch 120/637] [D loss: 0.064651] [G loss: 0.835613]\n",
      "[Epoch 0/200] [Batch 121/637] [D loss: 0.058967] [G loss: 0.904393]\n",
      "[Epoch 0/200] [Batch 122/637] [D loss: 0.067483] [G loss: 0.972996]\n",
      "[Epoch 0/200] [Batch 123/637] [D loss: 0.069489] [G loss: 0.806878]\n",
      "[Epoch 0/200] [Batch 124/637] [D loss: 0.063709] [G loss: 0.910151]\n",
      "[Epoch 0/200] [Batch 125/637] [D loss: 0.068829] [G loss: 0.791805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 126/637] [D loss: 0.088509] [G loss: 0.937730]\n",
      "[Epoch 0/200] [Batch 127/637] [D loss: 0.089228] [G loss: 0.641958]\n",
      "[Epoch 0/200] [Batch 128/637] [D loss: 0.110962] [G loss: 1.126111]\n",
      "[Epoch 0/200] [Batch 129/637] [D loss: 0.083882] [G loss: 0.807143]\n",
      "[Epoch 0/200] [Batch 130/637] [D loss: 0.088453] [G loss: 0.780978]\n",
      "[Epoch 0/200] [Batch 131/637] [D loss: 0.066855] [G loss: 0.910092]\n",
      "[Epoch 0/200] [Batch 132/637] [D loss: 0.078661] [G loss: 0.782249]\n",
      "[Epoch 0/200] [Batch 133/637] [D loss: 0.064286] [G loss: 0.892181]\n",
      "[Epoch 0/200] [Batch 134/637] [D loss: 0.064654] [G loss: 0.894287]\n",
      "[Epoch 0/200] [Batch 135/637] [D loss: 0.073887] [G loss: 0.967721]\n",
      "[Epoch 0/200] [Batch 136/637] [D loss: 0.082690] [G loss: 0.634182]\n",
      "[Epoch 0/200] [Batch 137/637] [D loss: 0.084126] [G loss: 1.170176]\n",
      "[Epoch 0/200] [Batch 138/637] [D loss: 0.072053] [G loss: 0.805461]\n",
      "[Epoch 0/200] [Batch 139/637] [D loss: 0.075512] [G loss: 0.738780]\n",
      "[Epoch 0/200] [Batch 140/637] [D loss: 0.075322] [G loss: 0.989055]\n",
      "[Epoch 0/200] [Batch 141/637] [D loss: 0.082691] [G loss: 0.855991]\n",
      "[Epoch 0/200] [Batch 142/637] [D loss: 0.091325] [G loss: 0.712313]\n",
      "[Epoch 0/200] [Batch 143/637] [D loss: 0.074794] [G loss: 1.066952]\n",
      "[Epoch 0/200] [Batch 144/637] [D loss: 0.074333] [G loss: 0.689945]\n",
      "[Epoch 0/200] [Batch 145/637] [D loss: 0.080029] [G loss: 1.060448]\n",
      "[Epoch 0/200] [Batch 146/637] [D loss: 0.087515] [G loss: 0.763598]\n",
      "[Epoch 0/200] [Batch 147/637] [D loss: 0.094874] [G loss: 0.986031]\n",
      "[Epoch 0/200] [Batch 148/637] [D loss: 0.089356] [G loss: 0.612697]\n",
      "[Epoch 0/200] [Batch 149/637] [D loss: 0.074991] [G loss: 0.996312]\n",
      "[Epoch 0/200] [Batch 150/637] [D loss: 0.074709] [G loss: 0.890324]\n",
      "[Epoch 0/200] [Batch 151/637] [D loss: 0.074599] [G loss: 0.839536]\n",
      "[Epoch 0/200] [Batch 152/637] [D loss: 0.063490] [G loss: 0.847630]\n",
      "[Epoch 0/200] [Batch 153/637] [D loss: 0.064876] [G loss: 0.894753]\n",
      "[Epoch 0/200] [Batch 154/637] [D loss: 0.075948] [G loss: 0.784160]\n",
      "[Epoch 0/200] [Batch 155/637] [D loss: 0.074515] [G loss: 0.967232]\n",
      "[Epoch 0/200] [Batch 156/637] [D loss: 0.114347] [G loss: 0.750355]\n",
      "[Epoch 0/200] [Batch 157/637] [D loss: 0.165375] [G loss: 1.412792]\n",
      "[Epoch 0/200] [Batch 158/637] [D loss: 0.115670] [G loss: 0.536765]\n",
      "[Epoch 0/200] [Batch 159/637] [D loss: 0.075217] [G loss: 0.851212]\n",
      "[Epoch 0/200] [Batch 160/637] [D loss: 0.070509] [G loss: 0.847743]\n",
      "[Epoch 0/200] [Batch 161/637] [D loss: 0.074876] [G loss: 0.820171]\n",
      "[Epoch 0/200] [Batch 162/637] [D loss: 0.058835] [G loss: 0.872774]\n",
      "[Epoch 0/200] [Batch 163/637] [D loss: 0.060510] [G loss: 0.794637]\n",
      "[Epoch 0/200] [Batch 164/637] [D loss: 0.078955] [G loss: 0.828079]\n",
      "[Epoch 0/200] [Batch 165/637] [D loss: 0.081740] [G loss: 1.044996]\n",
      "[Epoch 0/200] [Batch 166/637] [D loss: 0.070952] [G loss: 0.609737]\n",
      "[Epoch 0/200] [Batch 167/637] [D loss: 0.071216] [G loss: 0.876176]\n",
      "[Epoch 0/200] [Batch 168/637] [D loss: 0.070897] [G loss: 0.837892]\n",
      "[Epoch 0/200] [Batch 169/637] [D loss: 0.069547] [G loss: 0.870084]\n",
      "[Epoch 0/200] [Batch 170/637] [D loss: 0.105954] [G loss: 0.510878]\n",
      "[Epoch 0/200] [Batch 171/637] [D loss: 0.140612] [G loss: 1.228323]\n",
      "[Epoch 0/200] [Batch 172/637] [D loss: 0.107545] [G loss: 0.578972]\n",
      "[Epoch 0/200] [Batch 173/637] [D loss: 0.091898] [G loss: 0.808287]\n",
      "[Epoch 0/200] [Batch 174/637] [D loss: 0.069284] [G loss: 0.731445]\n",
      "[Epoch 0/200] [Batch 175/637] [D loss: 0.059662] [G loss: 0.834015]\n",
      "[Epoch 0/200] [Batch 176/637] [D loss: 0.070351] [G loss: 0.892826]\n",
      "[Epoch 0/200] [Batch 177/637] [D loss: 0.073670] [G loss: 0.740753]\n",
      "[Epoch 0/200] [Batch 178/637] [D loss: 0.070848] [G loss: 0.873928]\n",
      "[Epoch 0/200] [Batch 179/637] [D loss: 0.065331] [G loss: 0.920920]\n",
      "[Epoch 0/200] [Batch 180/637] [D loss: 0.126227] [G loss: 0.504671]\n",
      "[Epoch 0/200] [Batch 181/637] [D loss: 0.422832] [G loss: 1.568285]\n",
      "[Epoch 0/200] [Batch 182/637] [D loss: 0.337896] [G loss: 0.518212]\n",
      "[Epoch 0/200] [Batch 183/637] [D loss: 0.117831] [G loss: 0.909258]\n",
      "[Epoch 0/200] [Batch 184/637] [D loss: 0.096787] [G loss: 0.649080]\n",
      "[Epoch 0/200] [Batch 185/637] [D loss: 0.088309] [G loss: 0.851712]\n",
      "[Epoch 0/200] [Batch 186/637] [D loss: 0.090694] [G loss: 0.910700]\n",
      "[Epoch 0/200] [Batch 187/637] [D loss: 0.074612] [G loss: 0.783951]\n",
      "[Epoch 0/200] [Batch 188/637] [D loss: 0.081625] [G loss: 0.865490]\n",
      "[Epoch 0/200] [Batch 189/637] [D loss: 0.068873] [G loss: 0.870455]\n",
      "[Epoch 0/200] [Batch 190/637] [D loss: 0.095182] [G loss: 0.577044]\n",
      "[Epoch 0/200] [Batch 191/637] [D loss: 0.194647] [G loss: 1.432871]\n",
      "[Epoch 0/200] [Batch 192/637] [D loss: 0.314753] [G loss: 0.463597]\n",
      "[Epoch 0/200] [Batch 193/637] [D loss: 0.204915] [G loss: 0.752144]\n",
      "[Epoch 0/200] [Batch 194/637] [D loss: 0.165839] [G loss: 0.817143]\n",
      "[Epoch 0/200] [Batch 195/637] [D loss: 0.154428] [G loss: 0.562228]\n",
      "[Epoch 0/200] [Batch 196/637] [D loss: 0.115798] [G loss: 0.683332]\n",
      "[Epoch 0/200] [Batch 197/637] [D loss: 0.106287] [G loss: 0.756630]\n",
      "[Epoch 0/200] [Batch 198/637] [D loss: 0.090567] [G loss: 0.650092]\n",
      "[Epoch 0/200] [Batch 199/637] [D loss: 0.089229] [G loss: 0.938059]\n",
      "[Epoch 0/200] [Batch 200/637] [D loss: 0.110850] [G loss: 0.616075]\n",
      "[Epoch 0/200] [Batch 201/637] [D loss: 0.158134] [G loss: 1.021768]\n",
      "[Epoch 0/200] [Batch 202/637] [D loss: 0.099698] [G loss: 0.679529]\n",
      "[Epoch 0/200] [Batch 203/637] [D loss: 0.111186] [G loss: 0.564594]\n",
      "[Epoch 0/200] [Batch 204/637] [D loss: 0.097895] [G loss: 0.803760]\n",
      "[Epoch 0/200] [Batch 205/637] [D loss: 0.091005] [G loss: 0.675408]\n",
      "[Epoch 0/200] [Batch 206/637] [D loss: 0.087148] [G loss: 0.682261]\n",
      "[Epoch 0/200] [Batch 207/637] [D loss: 0.084195] [G loss: 0.884122]\n",
      "[Epoch 0/200] [Batch 208/637] [D loss: 0.089857] [G loss: 0.661463]\n",
      "[Epoch 0/200] [Batch 209/637] [D loss: 0.117477] [G loss: 0.990741]\n",
      "[Epoch 0/200] [Batch 210/637] [D loss: 0.137914] [G loss: 0.553377]\n",
      "[Epoch 0/200] [Batch 211/637] [D loss: 0.150652] [G loss: 0.992403]\n",
      "[Epoch 0/200] [Batch 212/637] [D loss: 0.122832] [G loss: 0.623530]\n",
      "[Epoch 0/200] [Batch 213/637] [D loss: 0.127857] [G loss: 0.636163]\n",
      "[Epoch 0/200] [Batch 214/637] [D loss: 0.114690] [G loss: 0.846034]\n",
      "[Epoch 0/200] [Batch 215/637] [D loss: 0.096371] [G loss: 0.666736]\n",
      "[Epoch 0/200] [Batch 216/637] [D loss: 0.107468] [G loss: 0.865080]\n",
      "[Epoch 0/200] [Batch 217/637] [D loss: 0.123318] [G loss: 0.557585]\n",
      "[Epoch 0/200] [Batch 218/637] [D loss: 0.135744] [G loss: 0.907977]\n",
      "[Epoch 0/200] [Batch 219/637] [D loss: 0.125026] [G loss: 0.604980]\n",
      "[Epoch 0/200] [Batch 220/637] [D loss: 0.104241] [G loss: 0.803003]\n",
      "[Epoch 0/200] [Batch 221/637] [D loss: 0.107247] [G loss: 0.685017]\n",
      "[Epoch 0/200] [Batch 222/637] [D loss: 0.091136] [G loss: 0.727265]\n",
      "[Epoch 0/200] [Batch 223/637] [D loss: 0.109329] [G loss: 0.989211]\n",
      "[Epoch 0/200] [Batch 224/637] [D loss: 0.179510] [G loss: 0.429675]\n",
      "[Epoch 0/200] [Batch 225/637] [D loss: 0.337866] [G loss: 1.090652]\n",
      "[Epoch 0/200] [Batch 226/637] [D loss: 0.269573] [G loss: 0.616537]\n",
      "[Epoch 0/200] [Batch 227/637] [D loss: 0.152444] [G loss: 0.594110]\n",
      "[Epoch 0/200] [Batch 228/637] [D loss: 0.125466] [G loss: 0.603889]\n",
      "[Epoch 0/200] [Batch 229/637] [D loss: 0.134609] [G loss: 0.552803]\n",
      "[Epoch 0/200] [Batch 230/637] [D loss: 0.123987] [G loss: 0.688314]\n",
      "[Epoch 0/200] [Batch 231/637] [D loss: 0.096967] [G loss: 0.797045]\n",
      "[Epoch 0/200] [Batch 232/637] [D loss: 0.097751] [G loss: 0.614896]\n",
      "[Epoch 0/200] [Batch 233/637] [D loss: 0.131803] [G loss: 0.861852]\n",
      "[Epoch 0/200] [Batch 234/637] [D loss: 0.103620] [G loss: 0.651857]\n",
      "[Epoch 0/200] [Batch 235/637] [D loss: 0.108382] [G loss: 0.740389]\n",
      "[Epoch 0/200] [Batch 236/637] [D loss: 0.124106] [G loss: 0.564653]\n",
      "[Epoch 0/200] [Batch 237/637] [D loss: 0.109913] [G loss: 0.787512]\n",
      "[Epoch 0/200] [Batch 238/637] [D loss: 0.126777] [G loss: 0.562417]\n",
      "[Epoch 0/200] [Batch 239/637] [D loss: 0.145888] [G loss: 0.894532]\n",
      "[Epoch 0/200] [Batch 240/637] [D loss: 0.147550] [G loss: 0.489907]\n",
      "[Epoch 0/200] [Batch 241/637] [D loss: 0.125830] [G loss: 0.817649]\n",
      "[Epoch 0/200] [Batch 242/637] [D loss: 0.114456] [G loss: 0.633781]\n",
      "[Epoch 0/200] [Batch 243/637] [D loss: 0.122829] [G loss: 0.625727]\n",
      "[Epoch 0/200] [Batch 244/637] [D loss: 0.115726] [G loss: 0.773759]\n",
      "[Epoch 0/200] [Batch 245/637] [D loss: 0.128404] [G loss: 0.581977]\n",
      "[Epoch 0/200] [Batch 246/637] [D loss: 0.200664] [G loss: 1.036015]\n",
      "[Epoch 0/200] [Batch 247/637] [D loss: 0.180318] [G loss: 0.423218]\n",
      "[Epoch 0/200] [Batch 248/637] [D loss: 0.142790] [G loss: 0.706126]\n",
      "[Epoch 0/200] [Batch 249/637] [D loss: 0.129215] [G loss: 0.672950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 250/637] [D loss: 0.125007] [G loss: 0.669338]\n",
      "[Epoch 0/200] [Batch 251/637] [D loss: 0.133701] [G loss: 0.542513]\n",
      "[Epoch 0/200] [Batch 252/637] [D loss: 0.138317] [G loss: 0.885819]\n",
      "[Epoch 0/200] [Batch 253/637] [D loss: 0.178930] [G loss: 0.596846]\n",
      "[Epoch 0/200] [Batch 254/637] [D loss: 0.233834] [G loss: 0.785572]\n",
      "[Epoch 0/200] [Batch 255/637] [D loss: 0.163957] [G loss: 0.552765]\n",
      "[Epoch 0/200] [Batch 256/637] [D loss: 0.160765] [G loss: 0.705834]\n",
      "[Epoch 0/200] [Batch 257/637] [D loss: 0.131709] [G loss: 0.582026]\n",
      "[Epoch 0/200] [Batch 258/637] [D loss: 0.128528] [G loss: 0.567117]\n",
      "[Epoch 0/200] [Batch 259/637] [D loss: 0.122660] [G loss: 0.667782]\n",
      "[Epoch 0/200] [Batch 260/637] [D loss: 0.106882] [G loss: 0.606192]\n",
      "[Epoch 0/200] [Batch 261/637] [D loss: 0.118104] [G loss: 0.647424]\n",
      "[Epoch 0/200] [Batch 262/637] [D loss: 0.096786] [G loss: 0.640684]\n",
      "[Epoch 0/200] [Batch 263/637] [D loss: 0.114506] [G loss: 0.857710]\n",
      "[Epoch 0/200] [Batch 264/637] [D loss: 0.125544] [G loss: 0.675102]\n",
      "[Epoch 0/200] [Batch 265/637] [D loss: 0.139791] [G loss: 0.775256]\n",
      "[Epoch 0/200] [Batch 266/637] [D loss: 0.137954] [G loss: 0.500351]\n",
      "[Epoch 0/200] [Batch 267/637] [D loss: 0.103538] [G loss: 0.778760]\n",
      "[Epoch 0/200] [Batch 268/637] [D loss: 0.124572] [G loss: 0.599196]\n",
      "[Epoch 0/200] [Batch 269/637] [D loss: 0.129575] [G loss: 0.922225]\n",
      "[Epoch 0/200] [Batch 270/637] [D loss: 0.146561] [G loss: 0.649932]\n",
      "[Epoch 0/200] [Batch 271/637] [D loss: 0.103707] [G loss: 0.726375]\n",
      "[Epoch 0/200] [Batch 272/637] [D loss: 0.117266] [G loss: 0.717884]\n",
      "[Epoch 0/200] [Batch 273/637] [D loss: 0.094092] [G loss: 0.855760]\n",
      "[Epoch 0/200] [Batch 274/637] [D loss: 0.118566] [G loss: 0.669425]\n",
      "[Epoch 0/200] [Batch 275/637] [D loss: 0.116335] [G loss: 0.579153]\n",
      "[Epoch 0/200] [Batch 276/637] [D loss: 0.131359] [G loss: 0.999008]\n",
      "[Epoch 0/200] [Batch 277/637] [D loss: 0.158108] [G loss: 0.520241]\n",
      "[Epoch 0/200] [Batch 278/637] [D loss: 0.135271] [G loss: 0.806991]\n",
      "[Epoch 0/200] [Batch 279/637] [D loss: 0.167788] [G loss: 0.691323]\n",
      "[Epoch 0/200] [Batch 280/637] [D loss: 0.175693] [G loss: 0.884067]\n",
      "[Epoch 0/200] [Batch 281/637] [D loss: 0.146719] [G loss: 0.587384]\n",
      "[Epoch 0/200] [Batch 282/637] [D loss: 0.107436] [G loss: 0.699116]\n",
      "[Epoch 0/200] [Batch 283/637] [D loss: 0.129724] [G loss: 0.767322]\n",
      "[Epoch 0/200] [Batch 284/637] [D loss: 0.111002] [G loss: 0.690523]\n",
      "[Epoch 0/200] [Batch 285/637] [D loss: 0.103159] [G loss: 0.696650]\n",
      "[Epoch 0/200] [Batch 286/637] [D loss: 0.127530] [G loss: 0.635326]\n",
      "[Epoch 0/200] [Batch 287/637] [D loss: 0.131397] [G loss: 0.948466]\n",
      "[Epoch 0/200] [Batch 288/637] [D loss: 0.155067] [G loss: 0.539337]\n",
      "[Epoch 0/200] [Batch 289/637] [D loss: 0.140909] [G loss: 0.864287]\n",
      "[Epoch 0/200] [Batch 290/637] [D loss: 0.142004] [G loss: 0.668565]\n",
      "[Epoch 0/200] [Batch 291/637] [D loss: 0.120812] [G loss: 0.580134]\n",
      "[Epoch 0/200] [Batch 292/637] [D loss: 0.133827] [G loss: 0.655746]\n",
      "[Epoch 0/200] [Batch 293/637] [D loss: 0.115719] [G loss: 0.558407]\n",
      "[Epoch 0/200] [Batch 294/637] [D loss: 0.134577] [G loss: 0.909043]\n",
      "[Epoch 0/200] [Batch 295/637] [D loss: 0.118725] [G loss: 0.703689]\n",
      "[Epoch 0/200] [Batch 296/637] [D loss: 0.119750] [G loss: 0.668188]\n",
      "[Epoch 0/200] [Batch 297/637] [D loss: 0.102286] [G loss: 0.693442]\n",
      "[Epoch 0/200] [Batch 298/637] [D loss: 0.094049] [G loss: 0.760652]\n",
      "[Epoch 0/200] [Batch 299/637] [D loss: 0.113357] [G loss: 0.753128]\n",
      "[Epoch 0/200] [Batch 300/637] [D loss: 0.136142] [G loss: 0.599388]\n",
      "[Epoch 0/200] [Batch 301/637] [D loss: 0.199004] [G loss: 0.888768]\n",
      "[Epoch 0/200] [Batch 302/637] [D loss: 0.275941] [G loss: 0.531601]\n",
      "[Epoch 0/200] [Batch 303/637] [D loss: 0.197655] [G loss: 0.690566]\n",
      "[Epoch 0/200] [Batch 304/637] [D loss: 0.176555] [G loss: 0.512472]\n",
      "[Epoch 0/200] [Batch 305/637] [D loss: 0.147125] [G loss: 0.860371]\n",
      "[Epoch 0/200] [Batch 306/637] [D loss: 0.140384] [G loss: 0.455707]\n",
      "[Epoch 0/200] [Batch 307/637] [D loss: 0.158359] [G loss: 0.958069]\n",
      "[Epoch 0/200] [Batch 308/637] [D loss: 0.127545] [G loss: 0.681637]\n",
      "[Epoch 0/200] [Batch 309/637] [D loss: 0.139920] [G loss: 0.552340]\n",
      "[Epoch 0/200] [Batch 310/637] [D loss: 0.153820] [G loss: 0.905128]\n",
      "[Epoch 0/200] [Batch 311/637] [D loss: 0.129794] [G loss: 0.730168]\n",
      "[Epoch 0/200] [Batch 312/637] [D loss: 0.130926] [G loss: 0.639003]\n",
      "[Epoch 0/200] [Batch 313/637] [D loss: 0.125606] [G loss: 0.703631]\n",
      "[Epoch 0/200] [Batch 314/637] [D loss: 0.118520] [G loss: 0.577436]\n",
      "[Epoch 0/200] [Batch 315/637] [D loss: 0.131548] [G loss: 0.750565]\n",
      "[Epoch 0/200] [Batch 316/637] [D loss: 0.121503] [G loss: 0.725622]\n",
      "[Epoch 0/200] [Batch 317/637] [D loss: 0.121654] [G loss: 0.497436]\n",
      "[Epoch 0/200] [Batch 318/637] [D loss: 0.150663] [G loss: 0.998009]\n",
      "[Epoch 0/200] [Batch 319/637] [D loss: 0.229201] [G loss: 0.556872]\n",
      "[Epoch 0/200] [Batch 320/637] [D loss: 0.208854] [G loss: 0.764064]\n",
      "[Epoch 0/200] [Batch 321/637] [D loss: 0.140527] [G loss: 0.685642]\n",
      "[Epoch 0/200] [Batch 322/637] [D loss: 0.136140] [G loss: 0.682879]\n",
      "[Epoch 0/200] [Batch 323/637] [D loss: 0.143322] [G loss: 0.630496]\n",
      "[Epoch 0/200] [Batch 324/637] [D loss: 0.132230] [G loss: 0.589716]\n",
      "[Epoch 0/200] [Batch 325/637] [D loss: 0.119328] [G loss: 0.718668]\n",
      "[Epoch 0/200] [Batch 326/637] [D loss: 0.117598] [G loss: 0.706618]\n",
      "[Epoch 0/200] [Batch 327/637] [D loss: 0.105209] [G loss: 0.684190]\n",
      "[Epoch 0/200] [Batch 328/637] [D loss: 0.119513] [G loss: 0.663248]\n",
      "[Epoch 0/200] [Batch 329/637] [D loss: 0.111361] [G loss: 0.661543]\n",
      "[Epoch 0/200] [Batch 330/637] [D loss: 0.144766] [G loss: 1.085336]\n",
      "[Epoch 0/200] [Batch 331/637] [D loss: 0.136647] [G loss: 0.526716]\n",
      "[Epoch 0/200] [Batch 332/637] [D loss: 0.164839] [G loss: 0.694039]\n",
      "[Epoch 0/200] [Batch 333/637] [D loss: 0.142260] [G loss: 0.692241]\n",
      "[Epoch 0/200] [Batch 334/637] [D loss: 0.107694] [G loss: 0.669300]\n",
      "[Epoch 0/200] [Batch 335/637] [D loss: 0.128341] [G loss: 0.696723]\n",
      "[Epoch 0/200] [Batch 336/637] [D loss: 0.119939] [G loss: 0.659765]\n",
      "[Epoch 0/200] [Batch 337/637] [D loss: 0.128134] [G loss: 0.724939]\n",
      "[Epoch 0/200] [Batch 338/637] [D loss: 0.125732] [G loss: 0.773185]\n",
      "[Epoch 0/200] [Batch 339/637] [D loss: 0.143312] [G loss: 0.549547]\n",
      "[Epoch 0/200] [Batch 340/637] [D loss: 0.163194] [G loss: 0.770735]\n",
      "[Epoch 0/200] [Batch 341/637] [D loss: 0.142680] [G loss: 0.696435]\n",
      "[Epoch 0/200] [Batch 342/637] [D loss: 0.139131] [G loss: 0.683868]\n",
      "[Epoch 0/200] [Batch 343/637] [D loss: 0.104758] [G loss: 0.636936]\n",
      "[Epoch 0/200] [Batch 344/637] [D loss: 0.113273] [G loss: 0.670398]\n",
      "[Epoch 0/200] [Batch 345/637] [D loss: 0.124722] [G loss: 0.638838]\n",
      "[Epoch 0/200] [Batch 346/637] [D loss: 0.140720] [G loss: 1.015218]\n",
      "[Epoch 0/200] [Batch 347/637] [D loss: 0.106739] [G loss: 0.728274]\n",
      "[Epoch 0/200] [Batch 348/637] [D loss: 0.126261] [G loss: 0.651434]\n",
      "[Epoch 0/200] [Batch 349/637] [D loss: 0.117312] [G loss: 0.559885]\n",
      "[Epoch 0/200] [Batch 350/637] [D loss: 0.118323] [G loss: 0.785561]\n",
      "[Epoch 0/200] [Batch 351/637] [D loss: 0.164055] [G loss: 0.525816]\n",
      "[Epoch 0/200] [Batch 352/637] [D loss: 0.183307] [G loss: 0.760529]\n",
      "[Epoch 0/200] [Batch 353/637] [D loss: 0.248377] [G loss: 0.430162]\n",
      "[Epoch 0/200] [Batch 354/637] [D loss: 0.255504] [G loss: 1.167327]\n",
      "[Epoch 0/200] [Batch 355/637] [D loss: 0.149191] [G loss: 0.462685]\n",
      "[Epoch 0/200] [Batch 356/637] [D loss: 0.160901] [G loss: 0.515843]\n",
      "[Epoch 0/200] [Batch 357/637] [D loss: 0.140921] [G loss: 0.698280]\n",
      "[Epoch 0/200] [Batch 358/637] [D loss: 0.130429] [G loss: 0.664460]\n",
      "[Epoch 0/200] [Batch 359/637] [D loss: 0.148133] [G loss: 0.516967]\n",
      "[Epoch 0/200] [Batch 360/637] [D loss: 0.170186] [G loss: 0.908021]\n",
      "[Epoch 0/200] [Batch 361/637] [D loss: 0.142190] [G loss: 0.538534]\n",
      "[Epoch 0/200] [Batch 362/637] [D loss: 0.127798] [G loss: 0.647466]\n",
      "[Epoch 0/200] [Batch 363/637] [D loss: 0.119804] [G loss: 0.741412]\n",
      "[Epoch 0/200] [Batch 364/637] [D loss: 0.126588] [G loss: 0.627604]\n",
      "[Epoch 0/200] [Batch 365/637] [D loss: 0.127785] [G loss: 0.777849]\n",
      "[Epoch 0/200] [Batch 366/637] [D loss: 0.143157] [G loss: 0.557513]\n",
      "[Epoch 0/200] [Batch 367/637] [D loss: 0.189862] [G loss: 0.865691]\n",
      "[Epoch 0/200] [Batch 368/637] [D loss: 0.208423] [G loss: 0.563160]\n",
      "[Epoch 0/200] [Batch 369/637] [D loss: 0.143730] [G loss: 0.922546]\n",
      "[Epoch 0/200] [Batch 370/637] [D loss: 0.151706] [G loss: 0.658748]\n",
      "[Epoch 0/200] [Batch 371/637] [D loss: 0.145727] [G loss: 0.485408]\n",
      "[Epoch 0/200] [Batch 372/637] [D loss: 0.140234] [G loss: 0.797239]\n",
      "[Epoch 0/200] [Batch 373/637] [D loss: 0.149010] [G loss: 0.734446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 374/637] [D loss: 0.127267] [G loss: 0.544775]\n",
      "[Epoch 0/200] [Batch 375/637] [D loss: 0.113423] [G loss: 0.727485]\n",
      "[Epoch 0/200] [Batch 376/637] [D loss: 0.115284] [G loss: 0.763331]\n",
      "[Epoch 0/200] [Batch 377/637] [D loss: 0.101809] [G loss: 0.739656]\n",
      "[Epoch 0/200] [Batch 378/637] [D loss: 0.104529] [G loss: 0.793503]\n",
      "[Epoch 0/200] [Batch 379/637] [D loss: 0.126517] [G loss: 0.639211]\n",
      "[Epoch 0/200] [Batch 380/637] [D loss: 0.116666] [G loss: 0.747875]\n",
      "[Epoch 0/200] [Batch 381/637] [D loss: 0.108371] [G loss: 0.656006]\n",
      "[Epoch 0/200] [Batch 382/637] [D loss: 0.115366] [G loss: 0.801808]\n",
      "[Epoch 0/200] [Batch 383/637] [D loss: 0.125746] [G loss: 0.651897]\n",
      "[Epoch 0/200] [Batch 384/637] [D loss: 0.124973] [G loss: 0.793035]\n",
      "[Epoch 0/200] [Batch 385/637] [D loss: 0.114702] [G loss: 0.677938]\n",
      "[Epoch 0/200] [Batch 386/637] [D loss: 0.124675] [G loss: 0.652258]\n",
      "[Epoch 0/200] [Batch 387/637] [D loss: 0.094451] [G loss: 0.759600]\n",
      "[Epoch 0/200] [Batch 388/637] [D loss: 0.162530] [G loss: 0.701385]\n",
      "[Epoch 0/200] [Batch 389/637] [D loss: 0.132547] [G loss: 0.747387]\n",
      "[Epoch 0/200] [Batch 390/637] [D loss: 0.183191] [G loss: 0.442626]\n",
      "[Epoch 0/200] [Batch 391/637] [D loss: 0.275128] [G loss: 1.097105]\n",
      "[Epoch 0/200] [Batch 392/637] [D loss: 0.395212] [G loss: 0.544216]\n",
      "[Epoch 0/200] [Batch 393/637] [D loss: 0.216869] [G loss: 0.895997]\n",
      "[Epoch 0/200] [Batch 394/637] [D loss: 0.263386] [G loss: 0.360451]\n",
      "[Epoch 0/200] [Batch 395/637] [D loss: 0.241197] [G loss: 1.100605]\n",
      "[Epoch 0/200] [Batch 396/637] [D loss: 0.171785] [G loss: 0.617131]\n",
      "[Epoch 0/200] [Batch 397/637] [D loss: 0.200682] [G loss: 0.437272]\n",
      "[Epoch 0/200] [Batch 398/637] [D loss: 0.177663] [G loss: 0.752359]\n",
      "[Epoch 0/200] [Batch 399/637] [D loss: 0.158374] [G loss: 0.695335]\n",
      "[Epoch 0/200] [Batch 400/637] [D loss: 0.131255] [G loss: 0.487312]\n",
      "[Epoch 0/200] [Batch 401/637] [D loss: 0.141628] [G loss: 0.713382]\n",
      "[Epoch 0/200] [Batch 402/637] [D loss: 0.120114] [G loss: 0.711013]\n",
      "[Epoch 0/200] [Batch 403/637] [D loss: 0.133186] [G loss: 0.563372]\n",
      "[Epoch 0/200] [Batch 404/637] [D loss: 0.140816] [G loss: 0.845897]\n",
      "[Epoch 0/200] [Batch 405/637] [D loss: 0.122755] [G loss: 0.676933]\n",
      "[Epoch 0/200] [Batch 406/637] [D loss: 0.128066] [G loss: 0.625940]\n",
      "[Epoch 0/200] [Batch 407/637] [D loss: 0.123949] [G loss: 0.766967]\n",
      "[Epoch 0/200] [Batch 408/637] [D loss: 0.110837] [G loss: 0.681238]\n",
      "[Epoch 0/200] [Batch 409/637] [D loss: 0.132765] [G loss: 0.519101]\n",
      "[Epoch 0/200] [Batch 410/637] [D loss: 0.106597] [G loss: 0.827328]\n",
      "[Epoch 0/200] [Batch 411/637] [D loss: 0.116288] [G loss: 0.680011]\n",
      "[Epoch 0/200] [Batch 412/637] [D loss: 0.111448] [G loss: 0.740327]\n",
      "[Epoch 0/200] [Batch 413/637] [D loss: 0.120873] [G loss: 0.549029]\n",
      "[Epoch 0/200] [Batch 414/637] [D loss: 0.108388] [G loss: 0.766344]\n",
      "[Epoch 0/200] [Batch 415/637] [D loss: 0.135850] [G loss: 0.590793]\n",
      "[Epoch 0/200] [Batch 416/637] [D loss: 0.150718] [G loss: 0.915390]\n",
      "[Epoch 0/200] [Batch 417/637] [D loss: 0.139251] [G loss: 0.595977]\n",
      "[Epoch 0/200] [Batch 418/637] [D loss: 0.137840] [G loss: 0.696826]\n",
      "[Epoch 0/200] [Batch 419/637] [D loss: 0.111169] [G loss: 0.689983]\n",
      "[Epoch 0/200] [Batch 420/637] [D loss: 0.125987] [G loss: 0.575957]\n",
      "[Epoch 0/200] [Batch 421/637] [D loss: 0.105400] [G loss: 0.700578]\n",
      "[Epoch 0/200] [Batch 422/637] [D loss: 0.115271] [G loss: 0.660806]\n",
      "[Epoch 0/200] [Batch 423/637] [D loss: 0.124243] [G loss: 0.803519]\n",
      "[Epoch 0/200] [Batch 424/637] [D loss: 0.168513] [G loss: 0.536484]\n",
      "[Epoch 0/200] [Batch 425/637] [D loss: 0.188221] [G loss: 1.047698]\n",
      "[Epoch 0/200] [Batch 426/637] [D loss: 0.187169] [G loss: 0.507703]\n",
      "[Epoch 0/200] [Batch 427/637] [D loss: 0.150430] [G loss: 0.631446]\n",
      "[Epoch 0/200] [Batch 428/637] [D loss: 0.136321] [G loss: 0.677455]\n",
      "[Epoch 0/200] [Batch 429/637] [D loss: 0.151863] [G loss: 0.641783]\n",
      "[Epoch 0/200] [Batch 430/637] [D loss: 0.158499] [G loss: 0.567810]\n",
      "[Epoch 0/200] [Batch 431/637] [D loss: 0.134488] [G loss: 0.631990]\n",
      "[Epoch 0/200] [Batch 432/637] [D loss: 0.144932] [G loss: 0.725236]\n",
      "[Epoch 0/200] [Batch 433/637] [D loss: 0.139116] [G loss: 0.545003]\n",
      "[Epoch 0/200] [Batch 434/637] [D loss: 0.107690] [G loss: 0.699282]\n",
      "[Epoch 0/200] [Batch 435/637] [D loss: 0.115483] [G loss: 0.762218]\n",
      "[Epoch 0/200] [Batch 436/637] [D loss: 0.133042] [G loss: 0.784663]\n",
      "[Epoch 0/200] [Batch 437/637] [D loss: 0.153099] [G loss: 0.502151]\n",
      "[Epoch 0/200] [Batch 438/637] [D loss: 0.216971] [G loss: 0.948717]\n",
      "[Epoch 0/200] [Batch 439/637] [D loss: 0.145813] [G loss: 0.510589]\n",
      "[Epoch 0/200] [Batch 440/637] [D loss: 0.127172] [G loss: 0.615466]\n",
      "[Epoch 0/200] [Batch 441/637] [D loss: 0.124501] [G loss: 0.663885]\n",
      "[Epoch 0/200] [Batch 442/637] [D loss: 0.136085] [G loss: 0.589999]\n",
      "[Epoch 0/200] [Batch 443/637] [D loss: 0.128021] [G loss: 0.630201]\n",
      "[Epoch 0/200] [Batch 444/637] [D loss: 0.179516] [G loss: 0.846043]\n",
      "[Epoch 0/200] [Batch 445/637] [D loss: 0.177682] [G loss: 0.504839]\n",
      "[Epoch 0/200] [Batch 446/637] [D loss: 0.130975] [G loss: 0.679522]\n",
      "[Epoch 0/200] [Batch 447/637] [D loss: 0.123997] [G loss: 0.653503]\n",
      "[Epoch 0/200] [Batch 448/637] [D loss: 0.132131] [G loss: 0.710861]\n",
      "[Epoch 0/200] [Batch 449/637] [D loss: 0.145592] [G loss: 0.512207]\n",
      "[Epoch 0/200] [Batch 450/637] [D loss: 0.199014] [G loss: 0.915561]\n",
      "[Epoch 0/200] [Batch 451/637] [D loss: 0.156791] [G loss: 0.565972]\n",
      "[Epoch 0/200] [Batch 452/637] [D loss: 0.148490] [G loss: 0.546622]\n",
      "[Epoch 0/200] [Batch 453/637] [D loss: 0.176089] [G loss: 0.767852]\n",
      "[Epoch 0/200] [Batch 454/637] [D loss: 0.130135] [G loss: 0.653793]\n",
      "[Epoch 0/200] [Batch 455/637] [D loss: 0.130292] [G loss: 0.519535]\n",
      "[Epoch 0/200] [Batch 456/637] [D loss: 0.115691] [G loss: 0.610511]\n",
      "[Epoch 0/200] [Batch 457/637] [D loss: 0.111693] [G loss: 0.672652]\n",
      "[Epoch 0/200] [Batch 458/637] [D loss: 0.146501] [G loss: 0.588973]\n",
      "[Epoch 0/200] [Batch 459/637] [D loss: 0.109274] [G loss: 0.676888]\n",
      "[Epoch 0/200] [Batch 460/637] [D loss: 0.111033] [G loss: 0.697308]\n",
      "[Epoch 0/200] [Batch 461/637] [D loss: 0.119217] [G loss: 0.620658]\n",
      "[Epoch 0/200] [Batch 462/637] [D loss: 0.124406] [G loss: 0.657829]\n",
      "[Epoch 0/200] [Batch 463/637] [D loss: 0.136101] [G loss: 0.631955]\n",
      "[Epoch 0/200] [Batch 464/637] [D loss: 0.135660] [G loss: 0.887667]\n",
      "[Epoch 0/200] [Batch 465/637] [D loss: 0.177845] [G loss: 0.390915]\n",
      "[Epoch 0/200] [Batch 466/637] [D loss: 0.272506] [G loss: 1.139318]\n",
      "[Epoch 0/200] [Batch 467/637] [D loss: 0.383128] [G loss: 0.494920]\n",
      "[Epoch 0/200] [Batch 468/637] [D loss: 0.179286] [G loss: 0.755415]\n",
      "[Epoch 0/200] [Batch 469/637] [D loss: 0.185983] [G loss: 0.490665]\n",
      "[Epoch 0/200] [Batch 470/637] [D loss: 0.166781] [G loss: 0.532855]\n",
      "[Epoch 0/200] [Batch 471/637] [D loss: 0.171540] [G loss: 0.758214]\n",
      "[Epoch 0/200] [Batch 472/637] [D loss: 0.147395] [G loss: 0.628402]\n",
      "[Epoch 0/200] [Batch 473/637] [D loss: 0.150666] [G loss: 0.457499]\n",
      "[Epoch 0/200] [Batch 474/637] [D loss: 0.134283] [G loss: 0.722872]\n",
      "[Epoch 0/200] [Batch 475/637] [D loss: 0.143293] [G loss: 0.604339]\n",
      "[Epoch 0/200] [Batch 476/637] [D loss: 0.152433] [G loss: 0.642291]\n",
      "[Epoch 0/200] [Batch 477/637] [D loss: 0.121853] [G loss: 0.621839]\n",
      "[Epoch 0/200] [Batch 478/637] [D loss: 0.120193] [G loss: 0.768837]\n",
      "[Epoch 0/200] [Batch 479/637] [D loss: 0.130791] [G loss: 0.659141]\n",
      "[Epoch 0/200] [Batch 480/637] [D loss: 0.127875] [G loss: 0.639870]\n",
      "[Epoch 0/200] [Batch 481/637] [D loss: 0.144908] [G loss: 0.793237]\n",
      "[Epoch 0/200] [Batch 482/637] [D loss: 0.180782] [G loss: 0.436317]\n",
      "[Epoch 0/200] [Batch 483/637] [D loss: 0.350625] [G loss: 1.338280]\n",
      "[Epoch 0/200] [Batch 484/637] [D loss: 0.176489] [G loss: 0.534671]\n",
      "[Epoch 0/200] [Batch 485/637] [D loss: 0.174731] [G loss: 0.522925]\n",
      "[Epoch 0/200] [Batch 486/637] [D loss: 0.151437] [G loss: 0.594719]\n",
      "[Epoch 0/200] [Batch 487/637] [D loss: 0.158154] [G loss: 0.589492]\n",
      "[Epoch 0/200] [Batch 488/637] [D loss: 0.149018] [G loss: 0.554741]\n",
      "[Epoch 0/200] [Batch 489/637] [D loss: 0.122134] [G loss: 0.596875]\n",
      "[Epoch 0/200] [Batch 490/637] [D loss: 0.121319] [G loss: 0.632137]\n",
      "[Epoch 0/200] [Batch 491/637] [D loss: 0.110688] [G loss: 0.634229]\n",
      "[Epoch 0/200] [Batch 492/637] [D loss: 0.115784] [G loss: 0.763768]\n",
      "[Epoch 0/200] [Batch 493/637] [D loss: 0.121382] [G loss: 0.640459]\n",
      "[Epoch 0/200] [Batch 494/637] [D loss: 0.119270] [G loss: 0.626955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 495/637] [D loss: 0.150446] [G loss: 0.654681]\n",
      "[Epoch 0/200] [Batch 496/637] [D loss: 0.123491] [G loss: 0.680376]\n",
      "[Epoch 0/200] [Batch 497/637] [D loss: 0.106150] [G loss: 0.754012]\n",
      "[Epoch 0/200] [Batch 498/637] [D loss: 0.139943] [G loss: 0.655163]\n",
      "[Epoch 0/200] [Batch 499/637] [D loss: 0.154724] [G loss: 0.520580]\n",
      "[Epoch 0/200] [Batch 500/637] [D loss: 0.231054] [G loss: 1.286825]\n",
      "[Epoch 0/200] [Batch 501/637] [D loss: 0.181112] [G loss: 0.540668]\n",
      "[Epoch 0/200] [Batch 502/637] [D loss: 0.159193] [G loss: 0.546316]\n",
      "[Epoch 0/200] [Batch 503/637] [D loss: 0.151456] [G loss: 0.596590]\n",
      "[Epoch 0/200] [Batch 504/637] [D loss: 0.142940] [G loss: 0.567706]\n",
      "[Epoch 0/200] [Batch 505/637] [D loss: 0.116235] [G loss: 0.578875]\n",
      "[Epoch 0/200] [Batch 506/637] [D loss: 0.137303] [G loss: 0.725224]\n",
      "[Epoch 0/200] [Batch 507/637] [D loss: 0.124281] [G loss: 0.722520]\n",
      "[Epoch 0/200] [Batch 508/637] [D loss: 0.120925] [G loss: 0.654730]\n",
      "[Epoch 0/200] [Batch 509/637] [D loss: 0.125192] [G loss: 0.703497]\n",
      "[Epoch 0/200] [Batch 510/637] [D loss: 0.128871] [G loss: 0.516356]\n",
      "[Epoch 0/200] [Batch 511/637] [D loss: 0.128993] [G loss: 0.783017]\n",
      "[Epoch 0/200] [Batch 512/637] [D loss: 0.135542] [G loss: 0.495384]\n",
      "[Epoch 0/200] [Batch 513/637] [D loss: 0.161959] [G loss: 0.809559]\n",
      "[Epoch 0/200] [Batch 514/637] [D loss: 0.157805] [G loss: 0.555816]\n",
      "[Epoch 0/200] [Batch 515/637] [D loss: 0.111726] [G loss: 0.634072]\n",
      "[Epoch 0/200] [Batch 516/637] [D loss: 0.143350] [G loss: 0.634006]\n",
      "[Epoch 0/200] [Batch 517/637] [D loss: 0.123860] [G loss: 0.570826]\n",
      "[Epoch 0/200] [Batch 518/637] [D loss: 0.158866] [G loss: 0.939440]\n",
      "[Epoch 0/200] [Batch 519/637] [D loss: 0.189820] [G loss: 0.422883]\n",
      "[Epoch 0/200] [Batch 520/637] [D loss: 0.292549] [G loss: 1.098532]\n",
      "[Epoch 0/200] [Batch 521/637] [D loss: 0.176416] [G loss: 0.538187]\n",
      "[Epoch 0/200] [Batch 522/637] [D loss: 0.160079] [G loss: 0.647871]\n",
      "[Epoch 0/200] [Batch 523/637] [D loss: 0.150206] [G loss: 0.673193]\n",
      "[Epoch 0/200] [Batch 524/637] [D loss: 0.167203] [G loss: 0.552787]\n",
      "[Epoch 0/200] [Batch 525/637] [D loss: 0.138519] [G loss: 0.556930]\n",
      "[Epoch 0/200] [Batch 526/637] [D loss: 0.132438] [G loss: 0.627337]\n",
      "[Epoch 0/200] [Batch 527/637] [D loss: 0.115542] [G loss: 0.699225]\n",
      "[Epoch 0/200] [Batch 528/637] [D loss: 0.126207] [G loss: 0.593474]\n",
      "[Epoch 0/200] [Batch 529/637] [D loss: 0.135253] [G loss: 0.652812]\n",
      "[Epoch 0/200] [Batch 530/637] [D loss: 0.128725] [G loss: 0.635630]\n",
      "[Epoch 0/200] [Batch 531/637] [D loss: 0.121915] [G loss: 0.622586]\n",
      "[Epoch 0/200] [Batch 532/637] [D loss: 0.132669] [G loss: 0.763369]\n",
      "[Epoch 0/200] [Batch 533/637] [D loss: 0.157043] [G loss: 0.461701]\n",
      "[Epoch 0/200] [Batch 534/637] [D loss: 0.235071] [G loss: 1.054014]\n",
      "[Epoch 0/200] [Batch 535/637] [D loss: 0.188958] [G loss: 0.435174]\n",
      "[Epoch 0/200] [Batch 536/637] [D loss: 0.149868] [G loss: 0.535120]\n",
      "[Epoch 0/200] [Batch 537/637] [D loss: 0.155718] [G loss: 0.613213]\n",
      "[Epoch 0/200] [Batch 538/637] [D loss: 0.139517] [G loss: 0.571774]\n",
      "[Epoch 0/200] [Batch 539/637] [D loss: 0.127565] [G loss: 0.710209]\n",
      "[Epoch 0/200] [Batch 540/637] [D loss: 0.135262] [G loss: 0.531917]\n",
      "[Epoch 0/200] [Batch 541/637] [D loss: 0.125505] [G loss: 0.629951]\n",
      "[Epoch 0/200] [Batch 542/637] [D loss: 0.119423] [G loss: 0.639713]\n",
      "[Epoch 0/200] [Batch 543/637] [D loss: 0.124823] [G loss: 0.654875]\n",
      "[Epoch 0/200] [Batch 544/637] [D loss: 0.107245] [G loss: 0.726018]\n",
      "[Epoch 0/200] [Batch 545/637] [D loss: 0.119769] [G loss: 0.622517]\n",
      "[Epoch 0/200] [Batch 546/637] [D loss: 0.155881] [G loss: 0.816286]\n",
      "[Epoch 0/200] [Batch 547/637] [D loss: 0.202693] [G loss: 0.454599]\n",
      "[Epoch 0/200] [Batch 548/637] [D loss: 0.328710] [G loss: 1.197816]\n",
      "[Epoch 0/200] [Batch 549/637] [D loss: 0.180686] [G loss: 0.396540]\n",
      "[Epoch 0/200] [Batch 550/637] [D loss: 0.149319] [G loss: 0.637366]\n",
      "[Epoch 0/200] [Batch 551/637] [D loss: 0.163397] [G loss: 0.625325]\n",
      "[Epoch 0/200] [Batch 552/637] [D loss: 0.133873] [G loss: 0.570821]\n",
      "[Epoch 0/200] [Batch 553/637] [D loss: 0.140618] [G loss: 0.551795]\n",
      "[Epoch 0/200] [Batch 554/637] [D loss: 0.153899] [G loss: 0.725066]\n",
      "[Epoch 0/200] [Batch 555/637] [D loss: 0.124569] [G loss: 0.607123]\n",
      "[Epoch 0/200] [Batch 556/637] [D loss: 0.129666] [G loss: 0.562661]\n",
      "[Epoch 0/200] [Batch 557/637] [D loss: 0.143191] [G loss: 0.812701]\n",
      "[Epoch 0/200] [Batch 558/637] [D loss: 0.140459] [G loss: 0.624410]\n",
      "[Epoch 0/200] [Batch 559/637] [D loss: 0.130554] [G loss: 0.622316]\n",
      "[Epoch 0/200] [Batch 560/637] [D loss: 0.149492] [G loss: 0.562428]\n",
      "[Epoch 0/200] [Batch 561/637] [D loss: 0.130534] [G loss: 0.648566]\n",
      "[Epoch 0/200] [Batch 562/637] [D loss: 0.129329] [G loss: 0.704170]\n",
      "[Epoch 0/200] [Batch 563/637] [D loss: 0.152774] [G loss: 0.433050]\n",
      "[Epoch 0/200] [Batch 564/637] [D loss: 0.160980] [G loss: 0.709780]\n",
      "[Epoch 0/200] [Batch 565/637] [D loss: 0.145614] [G loss: 0.582433]\n",
      "[Epoch 0/200] [Batch 566/637] [D loss: 0.142040] [G loss: 0.725760]\n",
      "[Epoch 0/200] [Batch 567/637] [D loss: 0.189929] [G loss: 0.433818]\n",
      "[Epoch 0/200] [Batch 568/637] [D loss: 0.264907] [G loss: 1.070081]\n",
      "[Epoch 0/200] [Batch 569/637] [D loss: 0.158241] [G loss: 0.453520]\n",
      "[Epoch 0/200] [Batch 570/637] [D loss: 0.142555] [G loss: 0.598542]\n",
      "[Epoch 0/200] [Batch 571/637] [D loss: 0.153451] [G loss: 0.677484]\n",
      "[Epoch 0/200] [Batch 572/637] [D loss: 0.130601] [G loss: 0.569422]\n",
      "[Epoch 0/200] [Batch 573/637] [D loss: 0.135838] [G loss: 0.619120]\n",
      "[Epoch 0/200] [Batch 574/637] [D loss: 0.121773] [G loss: 0.751926]\n",
      "[Epoch 0/200] [Batch 575/637] [D loss: 0.137188] [G loss: 0.558086]\n",
      "[Epoch 0/200] [Batch 576/637] [D loss: 0.136091] [G loss: 0.860838]\n",
      "[Epoch 0/200] [Batch 577/637] [D loss: 0.122458] [G loss: 0.568945]\n",
      "[Epoch 0/200] [Batch 578/637] [D loss: 0.115060] [G loss: 0.710840]\n",
      "[Epoch 0/200] [Batch 579/637] [D loss: 0.117148] [G loss: 0.732688]\n",
      "[Epoch 0/200] [Batch 580/637] [D loss: 0.133701] [G loss: 0.539179]\n",
      "[Epoch 0/200] [Batch 581/637] [D loss: 0.145745] [G loss: 0.872715]\n",
      "[Epoch 0/200] [Batch 582/637] [D loss: 0.157486] [G loss: 0.485327]\n",
      "[Epoch 0/200] [Batch 583/637] [D loss: 0.160502] [G loss: 0.733605]\n",
      "[Epoch 0/200] [Batch 584/637] [D loss: 0.132056] [G loss: 0.713430]\n",
      "[Epoch 0/200] [Batch 585/637] [D loss: 0.152647] [G loss: 0.562361]\n",
      "[Epoch 0/200] [Batch 586/637] [D loss: 0.132042] [G loss: 0.683871]\n",
      "[Epoch 0/200] [Batch 587/637] [D loss: 0.113047] [G loss: 0.565522]\n",
      "[Epoch 0/200] [Batch 588/637] [D loss: 0.119955] [G loss: 0.596482]\n",
      "[Epoch 0/200] [Batch 589/637] [D loss: 0.138518] [G loss: 0.802967]\n",
      "[Epoch 0/200] [Batch 590/637] [D loss: 0.146789] [G loss: 0.623746]\n",
      "[Epoch 0/200] [Batch 591/637] [D loss: 0.114888] [G loss: 0.647275]\n",
      "[Epoch 0/200] [Batch 592/637] [D loss: 0.134113] [G loss: 0.556338]\n",
      "[Epoch 0/200] [Batch 593/637] [D loss: 0.124526] [G loss: 0.781422]\n",
      "[Epoch 0/200] [Batch 594/637] [D loss: 0.133969] [G loss: 0.495241]\n",
      "[Epoch 0/200] [Batch 595/637] [D loss: 0.139168] [G loss: 0.788582]\n",
      "[Epoch 0/200] [Batch 596/637] [D loss: 0.135791] [G loss: 0.586294]\n",
      "[Epoch 0/200] [Batch 597/637] [D loss: 0.120842] [G loss: 0.699582]\n",
      "[Epoch 0/200] [Batch 598/637] [D loss: 0.111836] [G loss: 0.660496]\n",
      "[Epoch 0/200] [Batch 599/637] [D loss: 0.110045] [G loss: 0.652672]\n",
      "[Epoch 0/200] [Batch 600/637] [D loss: 0.126352] [G loss: 0.667094]\n",
      "[Epoch 0/200] [Batch 601/637] [D loss: 0.137888] [G loss: 0.608741]\n",
      "[Epoch 0/200] [Batch 602/637] [D loss: 0.146588] [G loss: 0.776866]\n",
      "[Epoch 0/200] [Batch 603/637] [D loss: 0.181356] [G loss: 0.491746]\n",
      "[Epoch 0/200] [Batch 604/637] [D loss: 0.196298] [G loss: 0.889880]\n",
      "[Epoch 0/200] [Batch 605/637] [D loss: 0.153300] [G loss: 0.643914]\n",
      "[Epoch 0/200] [Batch 606/637] [D loss: 0.207263] [G loss: 0.403799]\n",
      "[Epoch 0/200] [Batch 607/637] [D loss: 0.167786] [G loss: 0.757402]\n",
      "[Epoch 0/200] [Batch 608/637] [D loss: 0.148397] [G loss: 0.578811]\n",
      "[Epoch 0/200] [Batch 609/637] [D loss: 0.136921] [G loss: 0.452798]\n",
      "[Epoch 0/200] [Batch 610/637] [D loss: 0.128379] [G loss: 0.792488]\n",
      "[Epoch 0/200] [Batch 611/637] [D loss: 0.115780] [G loss: 0.651161]\n",
      "[Epoch 0/200] [Batch 612/637] [D loss: 0.110367] [G loss: 0.576232]\n",
      "[Epoch 0/200] [Batch 613/637] [D loss: 0.112177] [G loss: 0.654643]\n",
      "[Epoch 0/200] [Batch 614/637] [D loss: 0.122831] [G loss: 0.726694]\n",
      "[Epoch 0/200] [Batch 615/637] [D loss: 0.137420] [G loss: 0.627404]\n",
      "[Epoch 0/200] [Batch 616/637] [D loss: 0.132935] [G loss: 0.552540]\n",
      "[Epoch 0/200] [Batch 617/637] [D loss: 0.110620] [G loss: 0.609784]\n",
      "[Epoch 0/200] [Batch 618/637] [D loss: 0.153783] [G loss: 0.902472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 619/637] [D loss: 0.188164] [G loss: 0.437620]\n",
      "[Epoch 0/200] [Batch 620/637] [D loss: 0.227491] [G loss: 1.002913]\n",
      "[Epoch 0/200] [Batch 621/637] [D loss: 0.158195] [G loss: 0.691032]\n",
      "[Epoch 0/200] [Batch 622/637] [D loss: 0.163510] [G loss: 0.568173]\n",
      "[Epoch 0/200] [Batch 623/637] [D loss: 0.143887] [G loss: 0.609049]\n",
      "[Epoch 0/200] [Batch 624/637] [D loss: 0.153343] [G loss: 0.504223]\n",
      "[Epoch 0/200] [Batch 625/637] [D loss: 0.123578] [G loss: 0.668708]\n",
      "[Epoch 0/200] [Batch 626/637] [D loss: 0.135204] [G loss: 0.572658]\n",
      "[Epoch 0/200] [Batch 627/637] [D loss: 0.132099] [G loss: 0.622979]\n",
      "[Epoch 0/200] [Batch 628/637] [D loss: 0.140136] [G loss: 0.539634]\n",
      "[Epoch 0/200] [Batch 629/637] [D loss: 0.130867] [G loss: 0.823849]\n",
      "[Epoch 0/200] [Batch 630/637] [D loss: 0.119526] [G loss: 0.601132]\n",
      "[Epoch 0/200] [Batch 631/637] [D loss: 0.127204] [G loss: 0.722456]\n",
      "[Epoch 0/200] [Batch 632/637] [D loss: 0.156968] [G loss: 0.522394]\n",
      "[Epoch 0/200] [Batch 633/637] [D loss: 0.199605] [G loss: 0.933299]\n",
      "[Epoch 0/200] [Batch 634/637] [D loss: 0.133377] [G loss: 0.564950]\n",
      "[Epoch 0/200] [Batch 635/637] [D loss: 0.138314] [G loss: 0.589143]\n",
      "[Epoch 0/200] [Batch 636/637] [D loss: 0.121078] [G loss: 0.580483]\n",
      "[Epoch 1/200] [Batch 0/637] [D loss: 0.127116] [G loss: 0.578611]\n",
      "[Epoch 1/200] [Batch 1/637] [D loss: 0.152502] [G loss: 0.600162]\n",
      "[Epoch 1/200] [Batch 2/637] [D loss: 0.122971] [G loss: 0.708711]\n",
      "[Epoch 1/200] [Batch 3/637] [D loss: 0.184220] [G loss: 0.495127]\n",
      "[Epoch 1/200] [Batch 4/637] [D loss: 0.226819] [G loss: 0.862222]\n",
      "[Epoch 1/200] [Batch 5/637] [D loss: 0.269948] [G loss: 0.326723]\n",
      "[Epoch 1/200] [Batch 6/637] [D loss: 0.178829] [G loss: 0.856133]\n",
      "[Epoch 1/200] [Batch 7/637] [D loss: 0.153463] [G loss: 0.546825]\n",
      "[Epoch 1/200] [Batch 8/637] [D loss: 0.148338] [G loss: 0.532989]\n",
      "[Epoch 1/200] [Batch 9/637] [D loss: 0.151265] [G loss: 0.772580]\n",
      "[Epoch 1/200] [Batch 10/637] [D loss: 0.130558] [G loss: 0.685394]\n",
      "[Epoch 1/200] [Batch 11/637] [D loss: 0.161427] [G loss: 0.550666]\n",
      "[Epoch 1/200] [Batch 12/637] [D loss: 0.149185] [G loss: 0.688978]\n",
      "[Epoch 1/200] [Batch 13/637] [D loss: 0.125617] [G loss: 0.669061]\n",
      "[Epoch 1/200] [Batch 14/637] [D loss: 0.142548] [G loss: 0.566636]\n",
      "[Epoch 1/200] [Batch 15/637] [D loss: 0.159901] [G loss: 0.715810]\n",
      "[Epoch 1/200] [Batch 16/637] [D loss: 0.142992] [G loss: 0.699742]\n",
      "[Epoch 1/200] [Batch 17/637] [D loss: 0.130322] [G loss: 0.536471]\n",
      "[Epoch 1/200] [Batch 18/637] [D loss: 0.127100] [G loss: 0.657137]\n",
      "[Epoch 1/200] [Batch 19/637] [D loss: 0.118164] [G loss: 0.687079]\n",
      "[Epoch 1/200] [Batch 20/637] [D loss: 0.143006] [G loss: 0.481595]\n",
      "[Epoch 1/200] [Batch 21/637] [D loss: 0.154623] [G loss: 0.832887]\n",
      "[Epoch 1/200] [Batch 22/637] [D loss: 0.146277] [G loss: 0.661157]\n",
      "[Epoch 1/200] [Batch 23/637] [D loss: 0.121806] [G loss: 0.661763]\n",
      "[Epoch 1/200] [Batch 24/637] [D loss: 0.147916] [G loss: 0.588921]\n",
      "[Epoch 1/200] [Batch 25/637] [D loss: 0.153148] [G loss: 0.580142]\n",
      "[Epoch 1/200] [Batch 26/637] [D loss: 0.153624] [G loss: 0.562658]\n",
      "[Epoch 1/200] [Batch 27/637] [D loss: 0.133594] [G loss: 0.668574]\n",
      "[Epoch 1/200] [Batch 28/637] [D loss: 0.136953] [G loss: 0.608211]\n",
      "[Epoch 1/200] [Batch 29/637] [D loss: 0.155281] [G loss: 0.596506]\n",
      "[Epoch 1/200] [Batch 30/637] [D loss: 0.171991] [G loss: 0.790198]\n",
      "[Epoch 1/200] [Batch 31/637] [D loss: 0.178429] [G loss: 0.425235]\n",
      "[Epoch 1/200] [Batch 32/637] [D loss: 0.205976] [G loss: 0.791813]\n",
      "[Epoch 1/200] [Batch 33/637] [D loss: 0.145749] [G loss: 0.606159]\n",
      "[Epoch 1/200] [Batch 34/637] [D loss: 0.123283] [G loss: 0.633922]\n",
      "[Epoch 1/200] [Batch 35/637] [D loss: 0.145325] [G loss: 0.658673]\n",
      "[Epoch 1/200] [Batch 36/637] [D loss: 0.150994] [G loss: 0.446031]\n",
      "[Epoch 1/200] [Batch 37/637] [D loss: 0.129954] [G loss: 0.843466]\n",
      "[Epoch 1/200] [Batch 38/637] [D loss: 0.134055] [G loss: 0.711778]\n",
      "[Epoch 1/200] [Batch 39/637] [D loss: 0.161133] [G loss: 0.460621]\n",
      "[Epoch 1/200] [Batch 40/637] [D loss: 0.189896] [G loss: 0.934825]\n",
      "[Epoch 1/200] [Batch 41/637] [D loss: 0.142217] [G loss: 0.558669]\n",
      "[Epoch 1/200] [Batch 42/637] [D loss: 0.133723] [G loss: 0.562415]\n",
      "[Epoch 1/200] [Batch 43/637] [D loss: 0.144624] [G loss: 0.710442]\n",
      "[Epoch 1/200] [Batch 44/637] [D loss: 0.146744] [G loss: 0.605308]\n",
      "[Epoch 1/200] [Batch 45/637] [D loss: 0.127174] [G loss: 0.552599]\n",
      "[Epoch 1/200] [Batch 46/637] [D loss: 0.150326] [G loss: 0.707459]\n",
      "[Epoch 1/200] [Batch 47/637] [D loss: 0.150782] [G loss: 0.527574]\n",
      "[Epoch 1/200] [Batch 48/637] [D loss: 0.149953] [G loss: 0.759544]\n",
      "[Epoch 1/200] [Batch 49/637] [D loss: 0.160741] [G loss: 0.629074]\n",
      "[Epoch 1/200] [Batch 50/637] [D loss: 0.154459] [G loss: 0.472303]\n",
      "[Epoch 1/200] [Batch 51/637] [D loss: 0.169870] [G loss: 0.771816]\n",
      "[Epoch 1/200] [Batch 52/637] [D loss: 0.157113] [G loss: 0.548843]\n",
      "[Epoch 1/200] [Batch 53/637] [D loss: 0.148946] [G loss: 0.478358]\n",
      "[Epoch 1/200] [Batch 54/637] [D loss: 0.150251] [G loss: 0.753768]\n",
      "[Epoch 1/200] [Batch 55/637] [D loss: 0.170734] [G loss: 0.532286]\n",
      "[Epoch 1/200] [Batch 56/637] [D loss: 0.160874] [G loss: 0.846030]\n",
      "[Epoch 1/200] [Batch 57/637] [D loss: 0.136808] [G loss: 0.622696]\n",
      "[Epoch 1/200] [Batch 58/637] [D loss: 0.142161] [G loss: 0.479548]\n",
      "[Epoch 1/200] [Batch 59/637] [D loss: 0.138004] [G loss: 0.688420]\n",
      "[Epoch 1/200] [Batch 60/637] [D loss: 0.153992] [G loss: 0.558732]\n",
      "[Epoch 1/200] [Batch 61/637] [D loss: 0.130898] [G loss: 0.852307]\n",
      "[Epoch 1/200] [Batch 62/637] [D loss: 0.147910] [G loss: 0.590765]\n",
      "[Epoch 1/200] [Batch 63/637] [D loss: 0.134890] [G loss: 0.717865]\n",
      "[Epoch 1/200] [Batch 64/637] [D loss: 0.161327] [G loss: 0.610451]\n",
      "[Epoch 1/200] [Batch 65/637] [D loss: 0.123250] [G loss: 0.553460]\n",
      "[Epoch 1/200] [Batch 66/637] [D loss: 0.126162] [G loss: 0.616145]\n",
      "[Epoch 1/200] [Batch 67/637] [D loss: 0.173594] [G loss: 0.458241]\n",
      "[Epoch 1/200] [Batch 68/637] [D loss: 0.447961] [G loss: 1.380702]\n",
      "[Epoch 1/200] [Batch 69/637] [D loss: 0.358959] [G loss: 0.574065]\n",
      "[Epoch 1/200] [Batch 70/637] [D loss: 0.187585] [G loss: 0.550122]\n",
      "[Epoch 1/200] [Batch 71/637] [D loss: 0.164183] [G loss: 0.561991]\n",
      "[Epoch 1/200] [Batch 72/637] [D loss: 0.163687] [G loss: 0.556068]\n",
      "[Epoch 1/200] [Batch 73/637] [D loss: 0.153987] [G loss: 0.507841]\n",
      "[Epoch 1/200] [Batch 74/637] [D loss: 0.147898] [G loss: 0.538594]\n",
      "[Epoch 1/200] [Batch 75/637] [D loss: 0.129238] [G loss: 0.612090]\n",
      "[Epoch 1/200] [Batch 76/637] [D loss: 0.130621] [G loss: 0.629537]\n",
      "[Epoch 1/200] [Batch 77/637] [D loss: 0.123933] [G loss: 0.579795]\n",
      "[Epoch 1/200] [Batch 78/637] [D loss: 0.125726] [G loss: 0.571628]\n",
      "[Epoch 1/200] [Batch 79/637] [D loss: 0.110596] [G loss: 0.584653]\n",
      "[Epoch 1/200] [Batch 80/637] [D loss: 0.114995] [G loss: 0.604511]\n",
      "[Epoch 1/200] [Batch 81/637] [D loss: 0.130447] [G loss: 0.602795]\n",
      "[Epoch 1/200] [Batch 82/637] [D loss: 0.148529] [G loss: 0.820900]\n",
      "[Epoch 1/200] [Batch 83/637] [D loss: 0.217525] [G loss: 0.377736]\n",
      "[Epoch 1/200] [Batch 84/637] [D loss: 0.225854] [G loss: 0.841389]\n",
      "[Epoch 1/200] [Batch 85/637] [D loss: 0.166439] [G loss: 0.627225]\n",
      "[Epoch 1/200] [Batch 86/637] [D loss: 0.172164] [G loss: 0.424451]\n",
      "[Epoch 1/200] [Batch 87/637] [D loss: 0.144535] [G loss: 0.541110]\n",
      "[Epoch 1/200] [Batch 88/637] [D loss: 0.132630] [G loss: 0.580266]\n",
      "[Epoch 1/200] [Batch 89/637] [D loss: 0.129808] [G loss: 0.581696]\n",
      "[Epoch 1/200] [Batch 90/637] [D loss: 0.149164] [G loss: 0.552106]\n",
      "[Epoch 1/200] [Batch 91/637] [D loss: 0.128105] [G loss: 0.532645]\n",
      "[Epoch 1/200] [Batch 92/637] [D loss: 0.118440] [G loss: 0.609277]\n",
      "[Epoch 1/200] [Batch 93/637] [D loss: 0.119923] [G loss: 0.652738]\n",
      "[Epoch 1/200] [Batch 94/637] [D loss: 0.130644] [G loss: 0.538932]\n",
      "[Epoch 1/200] [Batch 95/637] [D loss: 0.106322] [G loss: 0.759727]\n",
      "[Epoch 1/200] [Batch 96/637] [D loss: 0.155434] [G loss: 0.594227]\n",
      "[Epoch 1/200] [Batch 97/637] [D loss: 0.169196] [G loss: 0.424994]\n",
      "[Epoch 1/200] [Batch 98/637] [D loss: 0.235237] [G loss: 1.001119]\n",
      "[Epoch 1/200] [Batch 99/637] [D loss: 0.190428] [G loss: 0.657528]\n",
      "[Epoch 1/200] [Batch 100/637] [D loss: 0.131558] [G loss: 0.510514]\n",
      "[Epoch 1/200] [Batch 101/637] [D loss: 0.152324] [G loss: 0.663181]\n",
      "[Epoch 1/200] [Batch 102/637] [D loss: 0.154793] [G loss: 0.602318]\n",
      "[Epoch 1/200] [Batch 103/637] [D loss: 0.128516] [G loss: 0.517123]\n",
      "[Epoch 1/200] [Batch 104/637] [D loss: 0.116418] [G loss: 0.610732]\n",
      "[Epoch 1/200] [Batch 105/637] [D loss: 0.124635] [G loss: 0.585242]\n",
      "[Epoch 1/200] [Batch 106/637] [D loss: 0.096390] [G loss: 0.572540]\n",
      "[Epoch 1/200] [Batch 107/637] [D loss: 0.117426] [G loss: 0.673203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 108/637] [D loss: 0.104694] [G loss: 0.646177]\n",
      "[Epoch 1/200] [Batch 109/637] [D loss: 0.113045] [G loss: 0.559046]\n",
      "[Epoch 1/200] [Batch 110/637] [D loss: 0.101834] [G loss: 0.627729]\n",
      "[Epoch 1/200] [Batch 111/637] [D loss: 0.127366] [G loss: 0.626019]\n",
      "[Epoch 1/200] [Batch 112/637] [D loss: 0.187446] [G loss: 0.512016]\n",
      "[Epoch 1/200] [Batch 113/637] [D loss: 0.365091] [G loss: 1.112430]\n",
      "[Epoch 1/200] [Batch 114/637] [D loss: 0.294196] [G loss: 0.578260]\n",
      "[Epoch 1/200] [Batch 115/637] [D loss: 0.187148] [G loss: 0.751302]\n",
      "[Epoch 1/200] [Batch 116/637] [D loss: 0.168610] [G loss: 0.571416]\n",
      "[Epoch 1/200] [Batch 117/637] [D loss: 0.166613] [G loss: 0.442416]\n",
      "[Epoch 1/200] [Batch 118/637] [D loss: 0.155745] [G loss: 0.419276]\n",
      "[Epoch 1/200] [Batch 119/637] [D loss: 0.128527] [G loss: 0.543318]\n",
      "[Epoch 1/200] [Batch 120/637] [D loss: 0.127470] [G loss: 0.658385]\n",
      "[Epoch 1/200] [Batch 121/637] [D loss: 0.136148] [G loss: 0.618658]\n",
      "[Epoch 1/200] [Batch 122/637] [D loss: 0.130126] [G loss: 0.604265]\n",
      "[Epoch 1/200] [Batch 123/637] [D loss: 0.126300] [G loss: 0.645781]\n",
      "[Epoch 1/200] [Batch 124/637] [D loss: 0.135574] [G loss: 0.478568]\n",
      "[Epoch 1/200] [Batch 125/637] [D loss: 0.145871] [G loss: 0.807413]\n",
      "[Epoch 1/200] [Batch 126/637] [D loss: 0.143075] [G loss: 0.518198]\n",
      "[Epoch 1/200] [Batch 127/637] [D loss: 0.143994] [G loss: 0.614113]\n",
      "[Epoch 1/200] [Batch 128/637] [D loss: 0.135600] [G loss: 0.495580]\n",
      "[Epoch 1/200] [Batch 129/637] [D loss: 0.174880] [G loss: 0.572676]\n",
      "[Epoch 1/200] [Batch 130/637] [D loss: 0.165848] [G loss: 0.465060]\n",
      "[Epoch 1/200] [Batch 131/637] [D loss: 0.153947] [G loss: 0.741902]\n",
      "[Epoch 1/200] [Batch 132/637] [D loss: 0.137678] [G loss: 0.575271]\n",
      "[Epoch 1/200] [Batch 133/637] [D loss: 0.141051] [G loss: 0.507572]\n",
      "[Epoch 1/200] [Batch 134/637] [D loss: 0.158086] [G loss: 0.537568]\n",
      "[Epoch 1/200] [Batch 135/637] [D loss: 0.130546] [G loss: 0.540171]\n",
      "[Epoch 1/200] [Batch 136/637] [D loss: 0.120930] [G loss: 0.678337]\n",
      "[Epoch 1/200] [Batch 137/637] [D loss: 0.136100] [G loss: 0.664199]\n",
      "[Epoch 1/200] [Batch 138/637] [D loss: 0.149963] [G loss: 0.483886]\n",
      "[Epoch 1/200] [Batch 139/637] [D loss: 0.160143] [G loss: 0.764070]\n",
      "[Epoch 1/200] [Batch 140/637] [D loss: 0.160094] [G loss: 0.560703]\n",
      "[Epoch 1/200] [Batch 141/637] [D loss: 0.192938] [G loss: 0.828898]\n",
      "[Epoch 1/200] [Batch 142/637] [D loss: 0.160182] [G loss: 0.561937]\n",
      "[Epoch 1/200] [Batch 143/637] [D loss: 0.137550] [G loss: 0.664120]\n",
      "[Epoch 1/200] [Batch 144/637] [D loss: 0.137701] [G loss: 0.550970]\n",
      "[Epoch 1/200] [Batch 145/637] [D loss: 0.142388] [G loss: 0.462727]\n",
      "[Epoch 1/200] [Batch 146/637] [D loss: 0.128597] [G loss: 0.795439]\n",
      "[Epoch 1/200] [Batch 147/637] [D loss: 0.145098] [G loss: 0.501793]\n",
      "[Epoch 1/200] [Batch 148/637] [D loss: 0.132396] [G loss: 0.703423]\n",
      "[Epoch 1/200] [Batch 149/637] [D loss: 0.154388] [G loss: 0.492081]\n",
      "[Epoch 1/200] [Batch 150/637] [D loss: 0.147638] [G loss: 0.839726]\n",
      "[Epoch 1/200] [Batch 151/637] [D loss: 0.208764] [G loss: 0.476230]\n",
      "[Epoch 1/200] [Batch 152/637] [D loss: 0.249691] [G loss: 0.899358]\n",
      "[Epoch 1/200] [Batch 153/637] [D loss: 0.181357] [G loss: 0.551893]\n",
      "[Epoch 1/200] [Batch 154/637] [D loss: 0.179855] [G loss: 0.448205]\n",
      "[Epoch 1/200] [Batch 155/637] [D loss: 0.149943] [G loss: 0.544314]\n",
      "[Epoch 1/200] [Batch 156/637] [D loss: 0.151749] [G loss: 0.621518]\n",
      "[Epoch 1/200] [Batch 157/637] [D loss: 0.154089] [G loss: 0.522645]\n",
      "[Epoch 1/200] [Batch 158/637] [D loss: 0.143516] [G loss: 0.582397]\n",
      "[Epoch 1/200] [Batch 159/637] [D loss: 0.136763] [G loss: 0.591815]\n",
      "[Epoch 1/200] [Batch 160/637] [D loss: 0.124763] [G loss: 0.533848]\n",
      "[Epoch 1/200] [Batch 161/637] [D loss: 0.135887] [G loss: 0.573397]\n",
      "[Epoch 1/200] [Batch 162/637] [D loss: 0.114642] [G loss: 0.743186]\n",
      "[Epoch 1/200] [Batch 163/637] [D loss: 0.128069] [G loss: 0.537562]\n",
      "[Epoch 1/200] [Batch 164/637] [D loss: 0.117223] [G loss: 0.719150]\n",
      "[Epoch 1/200] [Batch 165/637] [D loss: 0.122704] [G loss: 0.565391]\n",
      "[Epoch 1/200] [Batch 166/637] [D loss: 0.145920] [G loss: 0.824088]\n",
      "[Epoch 1/200] [Batch 167/637] [D loss: 0.182747] [G loss: 0.441457]\n",
      "[Epoch 1/200] [Batch 168/637] [D loss: 0.352223] [G loss: 1.072004]\n",
      "[Epoch 1/200] [Batch 169/637] [D loss: 0.173995] [G loss: 0.691128]\n",
      "[Epoch 1/200] [Batch 170/637] [D loss: 0.218441] [G loss: 0.459844]\n",
      "[Epoch 1/200] [Batch 171/637] [D loss: 0.156123] [G loss: 0.624101]\n",
      "[Epoch 1/200] [Batch 172/637] [D loss: 0.142344] [G loss: 0.602660]\n",
      "[Epoch 1/200] [Batch 173/637] [D loss: 0.129861] [G loss: 0.526859]\n",
      "[Epoch 1/200] [Batch 174/637] [D loss: 0.132386] [G loss: 0.470265]\n",
      "[Epoch 1/200] [Batch 175/637] [D loss: 0.129444] [G loss: 0.702081]\n",
      "[Epoch 1/200] [Batch 176/637] [D loss: 0.095703] [G loss: 0.673631]\n",
      "[Epoch 1/200] [Batch 177/637] [D loss: 0.101566] [G loss: 0.563441]\n",
      "[Epoch 1/200] [Batch 178/637] [D loss: 0.106650] [G loss: 0.644614]\n",
      "[Epoch 1/200] [Batch 179/637] [D loss: 0.111097] [G loss: 0.599339]\n",
      "[Epoch 1/200] [Batch 180/637] [D loss: 0.120105] [G loss: 0.728521]\n",
      "[Epoch 1/200] [Batch 181/637] [D loss: 0.153278] [G loss: 0.463254]\n",
      "[Epoch 1/200] [Batch 182/637] [D loss: 0.191691] [G loss: 0.862393]\n",
      "[Epoch 1/200] [Batch 183/637] [D loss: 0.167289] [G loss: 0.463337]\n",
      "[Epoch 1/200] [Batch 184/637] [D loss: 0.150118] [G loss: 0.587168]\n",
      "[Epoch 1/200] [Batch 185/637] [D loss: 0.158228] [G loss: 0.555144]\n",
      "[Epoch 1/200] [Batch 186/637] [D loss: 0.151619] [G loss: 0.445977]\n",
      "[Epoch 1/200] [Batch 187/637] [D loss: 0.131101] [G loss: 0.540006]\n",
      "[Epoch 1/200] [Batch 188/637] [D loss: 0.121810] [G loss: 0.564046]\n",
      "[Epoch 1/200] [Batch 189/637] [D loss: 0.132057] [G loss: 0.594342]\n",
      "[Epoch 1/200] [Batch 190/637] [D loss: 0.126560] [G loss: 0.667415]\n",
      "[Epoch 1/200] [Batch 191/637] [D loss: 0.125098] [G loss: 0.607396]\n",
      "[Epoch 1/200] [Batch 192/637] [D loss: 0.126467] [G loss: 0.722714]\n",
      "[Epoch 1/200] [Batch 193/637] [D loss: 0.125246] [G loss: 0.542032]\n",
      "[Epoch 1/200] [Batch 194/637] [D loss: 0.129987] [G loss: 0.596511]\n",
      "[Epoch 1/200] [Batch 195/637] [D loss: 0.137266] [G loss: 0.696098]\n",
      "[Epoch 1/200] [Batch 196/637] [D loss: 0.161970] [G loss: 0.501898]\n",
      "[Epoch 1/200] [Batch 197/637] [D loss: 0.273955] [G loss: 1.043092]\n",
      "[Epoch 1/200] [Batch 198/637] [D loss: 0.146755] [G loss: 0.613865]\n",
      "[Epoch 1/200] [Batch 199/637] [D loss: 0.157583] [G loss: 0.528339]\n",
      "[Epoch 1/200] [Batch 200/637] [D loss: 0.124088] [G loss: 0.584189]\n",
      "[Epoch 1/200] [Batch 201/637] [D loss: 0.120169] [G loss: 0.607038]\n",
      "[Epoch 1/200] [Batch 202/637] [D loss: 0.113166] [G loss: 0.596058]\n",
      "[Epoch 1/200] [Batch 203/637] [D loss: 0.105961] [G loss: 0.579778]\n",
      "[Epoch 1/200] [Batch 204/637] [D loss: 0.105803] [G loss: 0.675820]\n",
      "[Epoch 1/200] [Batch 205/637] [D loss: 0.108635] [G loss: 0.670519]\n",
      "[Epoch 1/200] [Batch 206/637] [D loss: 0.114439] [G loss: 0.577460]\n",
      "[Epoch 1/200] [Batch 207/637] [D loss: 0.119337] [G loss: 0.699895]\n",
      "[Epoch 1/200] [Batch 208/637] [D loss: 0.111289] [G loss: 0.528011]\n",
      "[Epoch 1/200] [Batch 209/637] [D loss: 0.109657] [G loss: 0.675827]\n",
      "[Epoch 1/200] [Batch 210/637] [D loss: 0.107842] [G loss: 0.639544]\n",
      "[Epoch 1/200] [Batch 211/637] [D loss: 0.147200] [G loss: 0.559031]\n",
      "[Epoch 1/200] [Batch 212/637] [D loss: 0.163954] [G loss: 0.788178]\n",
      "[Epoch 1/200] [Batch 213/637] [D loss: 0.225743] [G loss: 0.542577]\n",
      "[Epoch 1/200] [Batch 214/637] [D loss: 0.430125] [G loss: 1.215208]\n",
      "[Epoch 1/200] [Batch 215/637] [D loss: 0.262672] [G loss: 0.552716]\n",
      "[Epoch 1/200] [Batch 216/637] [D loss: 0.189897] [G loss: 0.569750]\n",
      "[Epoch 1/200] [Batch 217/637] [D loss: 0.150876] [G loss: 0.458611]\n",
      "[Epoch 1/200] [Batch 218/637] [D loss: 0.136711] [G loss: 0.474470]\n",
      "[Epoch 1/200] [Batch 219/637] [D loss: 0.133518] [G loss: 0.515141]\n",
      "[Epoch 1/200] [Batch 220/637] [D loss: 0.128070] [G loss: 0.599252]\n",
      "[Epoch 1/200] [Batch 221/637] [D loss: 0.114226] [G loss: 0.559321]\n",
      "[Epoch 1/200] [Batch 222/637] [D loss: 0.128712] [G loss: 0.666237]\n",
      "[Epoch 1/200] [Batch 223/637] [D loss: 0.121439] [G loss: 0.520590]\n",
      "[Epoch 1/200] [Batch 224/637] [D loss: 0.143662] [G loss: 0.869508]\n",
      "[Epoch 1/200] [Batch 225/637] [D loss: 0.115338] [G loss: 0.551316]\n",
      "[Epoch 1/200] [Batch 226/637] [D loss: 0.131925] [G loss: 0.708522]\n",
      "[Epoch 1/200] [Batch 227/637] [D loss: 0.140239] [G loss: 0.498645]\n",
      "[Epoch 1/200] [Batch 228/637] [D loss: 0.149762] [G loss: 0.697016]\n",
      "[Epoch 1/200] [Batch 229/637] [D loss: 0.124446] [G loss: 0.574269]\n",
      "[Epoch 1/200] [Batch 230/637] [D loss: 0.120516] [G loss: 0.507534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 231/637] [D loss: 0.131116] [G loss: 0.612815]\n",
      "[Epoch 1/200] [Batch 232/637] [D loss: 0.151224] [G loss: 0.557954]\n",
      "[Epoch 1/200] [Batch 233/637] [D loss: 0.134463] [G loss: 0.640008]\n",
      "[Epoch 1/200] [Batch 234/637] [D loss: 0.141121] [G loss: 0.478193]\n",
      "[Epoch 1/200] [Batch 235/637] [D loss: 0.151119] [G loss: 0.549905]\n",
      "[Epoch 1/200] [Batch 236/637] [D loss: 0.141746] [G loss: 0.590074]\n",
      "[Epoch 1/200] [Batch 237/637] [D loss: 0.161585] [G loss: 0.436449]\n",
      "[Epoch 1/200] [Batch 238/637] [D loss: 0.173127] [G loss: 0.694310]\n",
      "[Epoch 1/200] [Batch 239/637] [D loss: 0.145502] [G loss: 0.607277]\n",
      "[Epoch 1/200] [Batch 240/637] [D loss: 0.133929] [G loss: 0.677046]\n",
      "[Epoch 1/200] [Batch 241/637] [D loss: 0.123685] [G loss: 0.533180]\n",
      "[Epoch 1/200] [Batch 242/637] [D loss: 0.110002] [G loss: 0.611654]\n",
      "[Epoch 1/200] [Batch 243/637] [D loss: 0.123173] [G loss: 0.758034]\n",
      "[Epoch 1/200] [Batch 244/637] [D loss: 0.122472] [G loss: 0.645919]\n",
      "[Epoch 1/200] [Batch 245/637] [D loss: 0.127583] [G loss: 0.473840]\n",
      "[Epoch 1/200] [Batch 246/637] [D loss: 0.145580] [G loss: 0.933977]\n",
      "[Epoch 1/200] [Batch 247/637] [D loss: 0.213433] [G loss: 0.625112]\n",
      "[Epoch 1/200] [Batch 248/637] [D loss: 0.243725] [G loss: 0.901410]\n",
      "[Epoch 1/200] [Batch 249/637] [D loss: 0.149859] [G loss: 0.572659]\n",
      "[Epoch 1/200] [Batch 250/637] [D loss: 0.153752] [G loss: 0.463849]\n",
      "[Epoch 1/200] [Batch 251/637] [D loss: 0.136869] [G loss: 0.635013]\n",
      "[Epoch 1/200] [Batch 252/637] [D loss: 0.134519] [G loss: 0.617464]\n",
      "[Epoch 1/200] [Batch 253/637] [D loss: 0.118547] [G loss: 0.507452]\n",
      "[Epoch 1/200] [Batch 254/637] [D loss: 0.124379] [G loss: 0.602293]\n",
      "[Epoch 1/200] [Batch 255/637] [D loss: 0.109058] [G loss: 0.690274]\n",
      "[Epoch 1/200] [Batch 256/637] [D loss: 0.140541] [G loss: 0.528021]\n",
      "[Epoch 1/200] [Batch 257/637] [D loss: 0.122068] [G loss: 0.770685]\n",
      "[Epoch 1/200] [Batch 258/637] [D loss: 0.136739] [G loss: 0.621343]\n",
      "[Epoch 1/200] [Batch 259/637] [D loss: 0.186538] [G loss: 0.488338]\n",
      "[Epoch 1/200] [Batch 260/637] [D loss: 0.144043] [G loss: 0.727923]\n",
      "[Epoch 1/200] [Batch 261/637] [D loss: 0.136766] [G loss: 0.631671]\n",
      "[Epoch 1/200] [Batch 262/637] [D loss: 0.150225] [G loss: 0.481525]\n",
      "[Epoch 1/200] [Batch 263/637] [D loss: 0.145783] [G loss: 0.609640]\n",
      "[Epoch 1/200] [Batch 264/637] [D loss: 0.142086] [G loss: 0.627102]\n",
      "[Epoch 1/200] [Batch 265/637] [D loss: 0.113169] [G loss: 0.587259]\n",
      "[Epoch 1/200] [Batch 266/637] [D loss: 0.117569] [G loss: 0.565313]\n",
      "[Epoch 1/200] [Batch 267/637] [D loss: 0.132664] [G loss: 0.691920]\n",
      "[Epoch 1/200] [Batch 268/637] [D loss: 0.124427] [G loss: 0.571749]\n",
      "[Epoch 1/200] [Batch 269/637] [D loss: 0.142033] [G loss: 0.648844]\n",
      "[Epoch 1/200] [Batch 270/637] [D loss: 0.146351] [G loss: 0.704418]\n",
      "[Epoch 1/200] [Batch 271/637] [D loss: 0.161683] [G loss: 0.551319]\n",
      "[Epoch 1/200] [Batch 272/637] [D loss: 0.135704] [G loss: 0.756736]\n",
      "[Epoch 1/200] [Batch 273/637] [D loss: 0.115289] [G loss: 0.592708]\n",
      "[Epoch 1/200] [Batch 274/637] [D loss: 0.128546] [G loss: 0.495457]\n",
      "[Epoch 1/200] [Batch 275/637] [D loss: 0.155037] [G loss: 0.710951]\n",
      "[Epoch 1/200] [Batch 276/637] [D loss: 0.128596] [G loss: 0.633181]\n",
      "[Epoch 1/200] [Batch 277/637] [D loss: 0.128866] [G loss: 0.586338]\n",
      "[Epoch 1/200] [Batch 278/637] [D loss: 0.139492] [G loss: 0.772276]\n",
      "[Epoch 1/200] [Batch 279/637] [D loss: 0.115195] [G loss: 0.646631]\n",
      "[Epoch 1/200] [Batch 280/637] [D loss: 0.158112] [G loss: 0.449963]\n",
      "[Epoch 1/200] [Batch 281/637] [D loss: 0.162769] [G loss: 0.671398]\n",
      "[Epoch 1/200] [Batch 282/637] [D loss: 0.127108] [G loss: 0.612466]\n",
      "[Epoch 1/200] [Batch 283/637] [D loss: 0.135655] [G loss: 0.535637]\n",
      "[Epoch 1/200] [Batch 284/637] [D loss: 0.116047] [G loss: 0.581975]\n",
      "[Epoch 1/200] [Batch 285/637] [D loss: 0.115275] [G loss: 0.550542]\n",
      "[Epoch 1/200] [Batch 286/637] [D loss: 0.134182] [G loss: 0.570352]\n",
      "[Epoch 1/200] [Batch 287/637] [D loss: 0.171811] [G loss: 0.732112]\n",
      "[Epoch 1/200] [Batch 288/637] [D loss: 0.153809] [G loss: 0.526480]\n",
      "[Epoch 1/200] [Batch 289/637] [D loss: 0.124741] [G loss: 0.684909]\n",
      "[Epoch 1/200] [Batch 290/637] [D loss: 0.110930] [G loss: 0.646310]\n",
      "[Epoch 1/200] [Batch 291/637] [D loss: 0.132500] [G loss: 0.515720]\n",
      "[Epoch 1/200] [Batch 292/637] [D loss: 0.118682] [G loss: 0.598552]\n",
      "[Epoch 1/200] [Batch 293/637] [D loss: 0.132856] [G loss: 0.623464]\n",
      "[Epoch 1/200] [Batch 294/637] [D loss: 0.129621] [G loss: 0.551989]\n",
      "[Epoch 1/200] [Batch 295/637] [D loss: 0.125441] [G loss: 0.604975]\n",
      "[Epoch 1/200] [Batch 296/637] [D loss: 0.135532] [G loss: 0.625261]\n",
      "[Epoch 1/200] [Batch 297/637] [D loss: 0.121975] [G loss: 0.627096]\n",
      "[Epoch 1/200] [Batch 298/637] [D loss: 0.142861] [G loss: 0.523541]\n",
      "[Epoch 1/200] [Batch 299/637] [D loss: 0.127859] [G loss: 0.728417]\n",
      "[Epoch 1/200] [Batch 300/637] [D loss: 0.122874] [G loss: 0.587876]\n",
      "[Epoch 1/200] [Batch 301/637] [D loss: 0.116224] [G loss: 0.612399]\n",
      "[Epoch 1/200] [Batch 302/637] [D loss: 0.108143] [G loss: 0.718789]\n",
      "[Epoch 1/200] [Batch 303/637] [D loss: 0.107125] [G loss: 0.699952]\n",
      "[Epoch 1/200] [Batch 304/637] [D loss: 0.130378] [G loss: 0.556908]\n",
      "[Epoch 1/200] [Batch 305/637] [D loss: 0.275973] [G loss: 1.096864]\n",
      "[Epoch 1/200] [Batch 306/637] [D loss: 0.147188] [G loss: 0.544769]\n",
      "[Epoch 1/200] [Batch 307/637] [D loss: 0.147822] [G loss: 0.585568]\n",
      "[Epoch 1/200] [Batch 308/637] [D loss: 0.147885] [G loss: 0.635246]\n",
      "[Epoch 1/200] [Batch 309/637] [D loss: 0.122388] [G loss: 0.560517]\n",
      "[Epoch 1/200] [Batch 310/637] [D loss: 0.103666] [G loss: 0.561624]\n",
      "[Epoch 1/200] [Batch 311/637] [D loss: 0.118740] [G loss: 0.633325]\n",
      "[Epoch 1/200] [Batch 312/637] [D loss: 0.108560] [G loss: 0.679134]\n",
      "[Epoch 1/200] [Batch 313/637] [D loss: 0.122224] [G loss: 0.580015]\n",
      "[Epoch 1/200] [Batch 314/637] [D loss: 0.111558] [G loss: 0.678267]\n",
      "[Epoch 1/200] [Batch 315/637] [D loss: 0.102423] [G loss: 0.670452]\n",
      "[Epoch 1/200] [Batch 316/637] [D loss: 0.116052] [G loss: 0.609031]\n",
      "[Epoch 1/200] [Batch 317/637] [D loss: 0.129101] [G loss: 0.558652]\n",
      "[Epoch 1/200] [Batch 318/637] [D loss: 0.108507] [G loss: 0.544358]\n",
      "[Epoch 1/200] [Batch 319/637] [D loss: 0.118496] [G loss: 0.696200]\n",
      "[Epoch 1/200] [Batch 320/637] [D loss: 0.155395] [G loss: 0.606129]\n",
      "[Epoch 1/200] [Batch 321/637] [D loss: 0.137389] [G loss: 0.574953]\n",
      "[Epoch 1/200] [Batch 322/637] [D loss: 0.141307] [G loss: 0.520108]\n",
      "[Epoch 1/200] [Batch 323/637] [D loss: 0.176591] [G loss: 0.840129]\n",
      "[Epoch 1/200] [Batch 324/637] [D loss: 0.121505] [G loss: 0.605092]\n",
      "[Epoch 1/200] [Batch 325/637] [D loss: 0.143723] [G loss: 0.569474]\n",
      "[Epoch 1/200] [Batch 326/637] [D loss: 0.138909] [G loss: 0.756348]\n",
      "[Epoch 1/200] [Batch 327/637] [D loss: 0.115300] [G loss: 0.591615]\n",
      "[Epoch 1/200] [Batch 328/637] [D loss: 0.109200] [G loss: 0.552265]\n",
      "[Epoch 1/200] [Batch 329/637] [D loss: 0.111896] [G loss: 0.659715]\n",
      "[Epoch 1/200] [Batch 330/637] [D loss: 0.118115] [G loss: 0.622504]\n",
      "[Epoch 1/200] [Batch 331/637] [D loss: 0.135139] [G loss: 0.455011]\n",
      "[Epoch 1/200] [Batch 332/637] [D loss: 0.158840] [G loss: 0.735111]\n",
      "[Epoch 1/200] [Batch 333/637] [D loss: 0.128860] [G loss: 0.557995]\n",
      "[Epoch 1/200] [Batch 334/637] [D loss: 0.156491] [G loss: 0.495975]\n",
      "[Epoch 1/200] [Batch 335/637] [D loss: 0.137670] [G loss: 0.713193]\n",
      "[Epoch 1/200] [Batch 336/637] [D loss: 0.138057] [G loss: 0.606864]\n",
      "[Epoch 1/200] [Batch 337/637] [D loss: 0.134889] [G loss: 0.475837]\n",
      "[Epoch 1/200] [Batch 338/637] [D loss: 0.159252] [G loss: 0.647747]\n",
      "[Epoch 1/200] [Batch 339/637] [D loss: 0.122500] [G loss: 0.571585]\n",
      "[Epoch 1/200] [Batch 340/637] [D loss: 0.158348] [G loss: 0.483902]\n",
      "[Epoch 1/200] [Batch 341/637] [D loss: 0.177605] [G loss: 0.691989]\n",
      "[Epoch 1/200] [Batch 342/637] [D loss: 0.171845] [G loss: 0.460639]\n",
      "[Epoch 1/200] [Batch 343/637] [D loss: 0.153729] [G loss: 0.523016]\n",
      "[Epoch 1/200] [Batch 344/637] [D loss: 0.128751] [G loss: 0.560483]\n",
      "[Epoch 1/200] [Batch 345/637] [D loss: 0.148836] [G loss: 0.564605]\n",
      "[Epoch 1/200] [Batch 346/637] [D loss: 0.149329] [G loss: 0.550199]\n",
      "[Epoch 1/200] [Batch 347/637] [D loss: 0.148210] [G loss: 0.561688]\n",
      "[Epoch 1/200] [Batch 348/637] [D loss: 0.144608] [G loss: 0.476293]\n",
      "[Epoch 1/200] [Batch 349/637] [D loss: 0.162743] [G loss: 0.726847]\n",
      "[Epoch 1/200] [Batch 350/637] [D loss: 0.178830] [G loss: 0.484949]\n",
      "[Epoch 1/200] [Batch 351/637] [D loss: 0.173003] [G loss: 0.692007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 352/637] [D loss: 0.116667] [G loss: 0.563777]\n",
      "[Epoch 1/200] [Batch 353/637] [D loss: 0.131246] [G loss: 0.589229]\n",
      "[Epoch 1/200] [Batch 354/637] [D loss: 0.140096] [G loss: 0.539744]\n",
      "[Epoch 1/200] [Batch 355/637] [D loss: 0.142414] [G loss: 0.563460]\n",
      "[Epoch 1/200] [Batch 356/637] [D loss: 0.165745] [G loss: 0.763844]\n",
      "[Epoch 1/200] [Batch 357/637] [D loss: 0.116700] [G loss: 0.541083]\n",
      "[Epoch 1/200] [Batch 358/637] [D loss: 0.148902] [G loss: 0.531639]\n",
      "[Epoch 1/200] [Batch 359/637] [D loss: 0.133065] [G loss: 0.686564]\n",
      "[Epoch 1/200] [Batch 360/637] [D loss: 0.113305] [G loss: 0.606630]\n",
      "[Epoch 1/200] [Batch 361/637] [D loss: 0.133474] [G loss: 0.538487]\n",
      "[Epoch 1/200] [Batch 362/637] [D loss: 0.119337] [G loss: 0.544213]\n",
      "[Epoch 1/200] [Batch 363/637] [D loss: 0.134164] [G loss: 0.525017]\n",
      "[Epoch 1/200] [Batch 364/637] [D loss: 0.175469] [G loss: 0.788693]\n",
      "[Epoch 1/200] [Batch 365/637] [D loss: 0.135015] [G loss: 0.534509]\n",
      "[Epoch 1/200] [Batch 366/637] [D loss: 0.117134] [G loss: 0.532855]\n",
      "[Epoch 1/200] [Batch 367/637] [D loss: 0.120452] [G loss: 0.601566]\n",
      "[Epoch 1/200] [Batch 368/637] [D loss: 0.126625] [G loss: 0.569645]\n",
      "[Epoch 1/200] [Batch 369/637] [D loss: 0.129026] [G loss: 0.613483]\n",
      "[Epoch 1/200] [Batch 370/637] [D loss: 0.134260] [G loss: 0.528879]\n",
      "[Epoch 1/200] [Batch 371/637] [D loss: 0.130303] [G loss: 0.560892]\n",
      "[Epoch 1/200] [Batch 372/637] [D loss: 0.119430] [G loss: 0.583831]\n",
      "[Epoch 1/200] [Batch 373/637] [D loss: 0.151413] [G loss: 0.502186]\n",
      "[Epoch 1/200] [Batch 374/637] [D loss: 0.239508] [G loss: 0.756848]\n",
      "[Epoch 1/200] [Batch 375/637] [D loss: 0.168511] [G loss: 0.545489]\n",
      "[Epoch 1/200] [Batch 376/637] [D loss: 0.148926] [G loss: 0.593179]\n",
      "[Epoch 1/200] [Batch 377/637] [D loss: 0.152482] [G loss: 0.591657]\n",
      "[Epoch 1/200] [Batch 378/637] [D loss: 0.128756] [G loss: 0.528797]\n",
      "[Epoch 1/200] [Batch 379/637] [D loss: 0.144237] [G loss: 0.478605]\n",
      "[Epoch 1/200] [Batch 380/637] [D loss: 0.147061] [G loss: 0.701939]\n",
      "[Epoch 1/200] [Batch 381/637] [D loss: 0.108346] [G loss: 0.633001]\n",
      "[Epoch 1/200] [Batch 382/637] [D loss: 0.130954] [G loss: 0.499064]\n",
      "[Epoch 1/200] [Batch 383/637] [D loss: 0.143727] [G loss: 0.675705]\n",
      "[Epoch 1/200] [Batch 384/637] [D loss: 0.112910] [G loss: 0.622245]\n",
      "[Epoch 1/200] [Batch 385/637] [D loss: 0.116180] [G loss: 0.560246]\n",
      "[Epoch 1/200] [Batch 386/637] [D loss: 0.132604] [G loss: 0.779527]\n",
      "[Epoch 1/200] [Batch 387/637] [D loss: 0.137584] [G loss: 0.512830]\n",
      "[Epoch 1/200] [Batch 388/637] [D loss: 0.154117] [G loss: 0.624589]\n",
      "[Epoch 1/200] [Batch 389/637] [D loss: 0.140156] [G loss: 0.528875]\n",
      "[Epoch 1/200] [Batch 390/637] [D loss: 0.124505] [G loss: 0.797804]\n",
      "[Epoch 1/200] [Batch 391/637] [D loss: 0.115476] [G loss: 0.659326]\n",
      "[Epoch 1/200] [Batch 392/637] [D loss: 0.142973] [G loss: 0.495802]\n",
      "[Epoch 1/200] [Batch 393/637] [D loss: 0.152410] [G loss: 0.750388]\n",
      "[Epoch 1/200] [Batch 394/637] [D loss: 0.122204] [G loss: 0.658032]\n",
      "[Epoch 1/200] [Batch 395/637] [D loss: 0.184367] [G loss: 0.488785]\n",
      "[Epoch 1/200] [Batch 396/637] [D loss: 0.218309] [G loss: 0.845169]\n",
      "[Epoch 1/200] [Batch 397/637] [D loss: 0.149973] [G loss: 0.725191]\n",
      "[Epoch 1/200] [Batch 398/637] [D loss: 0.161670] [G loss: 0.528316]\n",
      "[Epoch 1/200] [Batch 399/637] [D loss: 0.135350] [G loss: 0.431185]\n",
      "[Epoch 1/200] [Batch 400/637] [D loss: 0.110926] [G loss: 0.525024]\n",
      "[Epoch 1/200] [Batch 401/637] [D loss: 0.112653] [G loss: 0.576543]\n",
      "[Epoch 1/200] [Batch 402/637] [D loss: 0.114898] [G loss: 0.604692]\n",
      "[Epoch 1/200] [Batch 403/637] [D loss: 0.105987] [G loss: 0.693983]\n",
      "[Epoch 1/200] [Batch 404/637] [D loss: 0.120633] [G loss: 0.586796]\n",
      "[Epoch 1/200] [Batch 405/637] [D loss: 0.145693] [G loss: 0.528035]\n",
      "[Epoch 1/200] [Batch 406/637] [D loss: 0.161801] [G loss: 0.777315]\n",
      "[Epoch 1/200] [Batch 407/637] [D loss: 0.142565] [G loss: 0.617002]\n",
      "[Epoch 1/200] [Batch 408/637] [D loss: 0.169582] [G loss: 0.460121]\n",
      "[Epoch 1/200] [Batch 409/637] [D loss: 0.155935] [G loss: 0.696417]\n",
      "[Epoch 1/200] [Batch 410/637] [D loss: 0.129291] [G loss: 0.488874]\n",
      "[Epoch 1/200] [Batch 411/637] [D loss: 0.136411] [G loss: 0.516664]\n",
      "[Epoch 1/200] [Batch 412/637] [D loss: 0.112579] [G loss: 0.665916]\n",
      "[Epoch 1/200] [Batch 413/637] [D loss: 0.150033] [G loss: 0.549845]\n",
      "[Epoch 1/200] [Batch 414/637] [D loss: 0.128621] [G loss: 0.537040]\n",
      "[Epoch 1/200] [Batch 415/637] [D loss: 0.144145] [G loss: 0.535583]\n",
      "[Epoch 1/200] [Batch 416/637] [D loss: 0.121680] [G loss: 0.500677]\n",
      "[Epoch 1/200] [Batch 417/637] [D loss: 0.131287] [G loss: 0.678988]\n",
      "[Epoch 1/200] [Batch 418/637] [D loss: 0.142229] [G loss: 0.547501]\n",
      "[Epoch 1/200] [Batch 419/637] [D loss: 0.136014] [G loss: 0.641430]\n",
      "[Epoch 1/200] [Batch 420/637] [D loss: 0.155855] [G loss: 0.483033]\n",
      "[Epoch 1/200] [Batch 421/637] [D loss: 0.143136] [G loss: 0.620826]\n",
      "[Epoch 1/200] [Batch 422/637] [D loss: 0.119532] [G loss: 0.509842]\n",
      "[Epoch 1/200] [Batch 423/637] [D loss: 0.146466] [G loss: 0.806265]\n",
      "[Epoch 1/200] [Batch 424/637] [D loss: 0.167988] [G loss: 0.453543]\n",
      "[Epoch 1/200] [Batch 425/637] [D loss: 0.196724] [G loss: 0.881511]\n",
      "[Epoch 1/200] [Batch 426/637] [D loss: 0.131419] [G loss: 0.599378]\n",
      "[Epoch 1/200] [Batch 427/637] [D loss: 0.140796] [G loss: 0.478060]\n",
      "[Epoch 1/200] [Batch 428/637] [D loss: 0.121386] [G loss: 0.544602]\n",
      "[Epoch 1/200] [Batch 429/637] [D loss: 0.099736] [G loss: 0.564056]\n",
      "[Epoch 1/200] [Batch 430/637] [D loss: 0.117551] [G loss: 0.570081]\n",
      "[Epoch 1/200] [Batch 431/637] [D loss: 0.108636] [G loss: 0.621247]\n",
      "[Epoch 1/200] [Batch 432/637] [D loss: 0.112778] [G loss: 0.576468]\n",
      "[Epoch 1/200] [Batch 433/637] [D loss: 0.110915] [G loss: 0.646413]\n",
      "[Epoch 1/200] [Batch 434/637] [D loss: 0.135109] [G loss: 0.566090]\n",
      "[Epoch 1/200] [Batch 435/637] [D loss: 0.133028] [G loss: 0.694182]\n",
      "[Epoch 1/200] [Batch 436/637] [D loss: 0.149022] [G loss: 0.503861]\n",
      "[Epoch 1/200] [Batch 437/637] [D loss: 0.266997] [G loss: 0.866246]\n",
      "[Epoch 1/200] [Batch 438/637] [D loss: 0.212306] [G loss: 0.398883]\n",
      "[Epoch 1/200] [Batch 439/637] [D loss: 0.134770] [G loss: 0.638732]\n",
      "[Epoch 1/200] [Batch 440/637] [D loss: 0.148577] [G loss: 0.648220]\n",
      "[Epoch 1/200] [Batch 441/637] [D loss: 0.119832] [G loss: 0.546510]\n",
      "[Epoch 1/200] [Batch 442/637] [D loss: 0.123221] [G loss: 0.475882]\n",
      "[Epoch 1/200] [Batch 443/637] [D loss: 0.116692] [G loss: 0.542697]\n",
      "[Epoch 1/200] [Batch 444/637] [D loss: 0.122904] [G loss: 0.590980]\n",
      "[Epoch 1/200] [Batch 445/637] [D loss: 0.118937] [G loss: 0.594229]\n",
      "[Epoch 1/200] [Batch 446/637] [D loss: 0.134998] [G loss: 0.494070]\n",
      "[Epoch 1/200] [Batch 447/637] [D loss: 0.124844] [G loss: 0.707565]\n",
      "[Epoch 1/200] [Batch 448/637] [D loss: 0.116709] [G loss: 0.564845]\n",
      "[Epoch 1/200] [Batch 449/637] [D loss: 0.115243] [G loss: 0.535651]\n",
      "[Epoch 1/200] [Batch 450/637] [D loss: 0.134372] [G loss: 0.579614]\n",
      "[Epoch 1/200] [Batch 451/637] [D loss: 0.117050] [G loss: 0.596640]\n",
      "[Epoch 1/200] [Batch 452/637] [D loss: 0.123713] [G loss: 0.716102]\n",
      "[Epoch 1/200] [Batch 453/637] [D loss: 0.118233] [G loss: 0.534316]\n",
      "[Epoch 1/200] [Batch 454/637] [D loss: 0.146054] [G loss: 0.610558]\n",
      "[Epoch 1/200] [Batch 455/637] [D loss: 0.122201] [G loss: 0.471740]\n",
      "[Epoch 1/200] [Batch 456/637] [D loss: 0.137740] [G loss: 0.764308]\n",
      "[Epoch 1/200] [Batch 457/637] [D loss: 0.152306] [G loss: 0.510493]\n",
      "[Epoch 1/200] [Batch 458/637] [D loss: 0.173174] [G loss: 0.748071]\n",
      "[Epoch 1/200] [Batch 459/637] [D loss: 0.136469] [G loss: 0.518663]\n",
      "[Epoch 1/200] [Batch 460/637] [D loss: 0.114186] [G loss: 0.666004]\n",
      "[Epoch 1/200] [Batch 461/637] [D loss: 0.132161] [G loss: 0.617913]\n",
      "[Epoch 1/200] [Batch 462/637] [D loss: 0.130195] [G loss: 0.499097]\n",
      "[Epoch 1/200] [Batch 463/637] [D loss: 0.125805] [G loss: 0.735962]\n",
      "[Epoch 1/200] [Batch 464/637] [D loss: 0.116766] [G loss: 0.586277]\n",
      "[Epoch 1/200] [Batch 465/637] [D loss: 0.118596] [G loss: 0.549586]\n",
      "[Epoch 1/200] [Batch 466/637] [D loss: 0.117063] [G loss: 0.833391]\n",
      "[Epoch 1/200] [Batch 467/637] [D loss: 0.098601] [G loss: 0.596095]\n",
      "[Epoch 1/200] [Batch 468/637] [D loss: 0.111809] [G loss: 0.593390]\n",
      "[Epoch 1/200] [Batch 469/637] [D loss: 0.141989] [G loss: 0.736108]\n",
      "[Epoch 1/200] [Batch 470/637] [D loss: 0.193784] [G loss: 0.459486]\n",
      "[Epoch 1/200] [Batch 471/637] [D loss: 0.313559] [G loss: 1.068627]\n",
      "[Epoch 1/200] [Batch 472/637] [D loss: 0.141048] [G loss: 0.621992]\n",
      "[Epoch 1/200] [Batch 473/637] [D loss: 0.166131] [G loss: 0.503542]\n",
      "[Epoch 1/200] [Batch 474/637] [D loss: 0.137745] [G loss: 0.513162]\n",
      "[Epoch 1/200] [Batch 475/637] [D loss: 0.140358] [G loss: 0.571723]\n",
      "[Epoch 1/200] [Batch 476/637] [D loss: 0.116242] [G loss: 0.540838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 477/637] [D loss: 0.119875] [G loss: 0.545857]\n",
      "[Epoch 1/200] [Batch 478/637] [D loss: 0.124321] [G loss: 0.563046]\n",
      "[Epoch 1/200] [Batch 479/637] [D loss: 0.096112] [G loss: 0.638907]\n",
      "[Epoch 1/200] [Batch 480/637] [D loss: 0.102695] [G loss: 0.592822]\n",
      "[Epoch 1/200] [Batch 481/637] [D loss: 0.121423] [G loss: 0.577643]\n",
      "[Epoch 1/200] [Batch 482/637] [D loss: 0.122621] [G loss: 0.635925]\n",
      "[Epoch 1/200] [Batch 483/637] [D loss: 0.140074] [G loss: 0.452293]\n",
      "[Epoch 1/200] [Batch 484/637] [D loss: 0.149659] [G loss: 0.716910]\n",
      "[Epoch 1/200] [Batch 485/637] [D loss: 0.144292] [G loss: 0.520743]\n",
      "[Epoch 1/200] [Batch 486/637] [D loss: 0.131895] [G loss: 0.636531]\n",
      "[Epoch 1/200] [Batch 487/637] [D loss: 0.125170] [G loss: 0.545325]\n",
      "[Epoch 1/200] [Batch 488/637] [D loss: 0.117805] [G loss: 0.517186]\n",
      "[Epoch 1/200] [Batch 489/637] [D loss: 0.136380] [G loss: 0.655954]\n",
      "[Epoch 1/200] [Batch 490/637] [D loss: 0.161725] [G loss: 0.465712]\n",
      "[Epoch 1/200] [Batch 491/637] [D loss: 0.171586] [G loss: 0.782251]\n",
      "[Epoch 1/200] [Batch 492/637] [D loss: 0.128547] [G loss: 0.559151]\n",
      "[Epoch 1/200] [Batch 493/637] [D loss: 0.144990] [G loss: 0.475877]\n",
      "[Epoch 1/200] [Batch 494/637] [D loss: 0.132628] [G loss: 0.568822]\n",
      "[Epoch 1/200] [Batch 495/637] [D loss: 0.121420] [G loss: 0.533986]\n",
      "[Epoch 1/200] [Batch 496/637] [D loss: 0.127602] [G loss: 0.505950]\n",
      "[Epoch 1/200] [Batch 497/637] [D loss: 0.122434] [G loss: 0.586837]\n",
      "[Epoch 1/200] [Batch 498/637] [D loss: 0.146927] [G loss: 0.555313]\n",
      "[Epoch 1/200] [Batch 499/637] [D loss: 0.143305] [G loss: 0.517452]\n",
      "[Epoch 1/200] [Batch 500/637] [D loss: 0.139050] [G loss: 0.578986]\n",
      "[Epoch 1/200] [Batch 501/637] [D loss: 0.144210] [G loss: 0.498614]\n",
      "[Epoch 1/200] [Batch 502/637] [D loss: 0.143979] [G loss: 0.706056]\n",
      "[Epoch 1/200] [Batch 503/637] [D loss: 0.148819] [G loss: 0.474961]\n",
      "[Epoch 1/200] [Batch 504/637] [D loss: 0.144905] [G loss: 0.659882]\n",
      "[Epoch 1/200] [Batch 505/637] [D loss: 0.134626] [G loss: 0.542802]\n",
      "[Epoch 1/200] [Batch 506/637] [D loss: 0.145923] [G loss: 0.469481]\n",
      "[Epoch 1/200] [Batch 507/637] [D loss: 0.146340] [G loss: 0.662358]\n",
      "[Epoch 1/200] [Batch 508/637] [D loss: 0.154044] [G loss: 0.492191]\n",
      "[Epoch 1/200] [Batch 509/637] [D loss: 0.192065] [G loss: 0.887304]\n",
      "[Epoch 1/200] [Batch 510/637] [D loss: 0.179090] [G loss: 0.428062]\n",
      "[Epoch 1/200] [Batch 511/637] [D loss: 0.186135] [G loss: 0.672644]\n",
      "[Epoch 1/200] [Batch 512/637] [D loss: 0.146214] [G loss: 0.616151]\n",
      "[Epoch 1/200] [Batch 513/637] [D loss: 0.153454] [G loss: 0.474648]\n",
      "[Epoch 1/200] [Batch 514/637] [D loss: 0.132417] [G loss: 0.524438]\n",
      "[Epoch 1/200] [Batch 515/637] [D loss: 0.145326] [G loss: 0.560945]\n",
      "[Epoch 1/200] [Batch 516/637] [D loss: 0.128982] [G loss: 0.584717]\n",
      "[Epoch 1/200] [Batch 517/637] [D loss: 0.151303] [G loss: 0.699898]\n",
      "[Epoch 1/200] [Batch 518/637] [D loss: 0.154532] [G loss: 0.458492]\n",
      "[Epoch 1/200] [Batch 519/637] [D loss: 0.178920] [G loss: 0.712459]\n",
      "[Epoch 1/200] [Batch 520/637] [D loss: 0.135331] [G loss: 0.565062]\n",
      "[Epoch 1/200] [Batch 521/637] [D loss: 0.158148] [G loss: 0.473207]\n",
      "[Epoch 1/200] [Batch 522/637] [D loss: 0.126561] [G loss: 0.544780]\n",
      "[Epoch 1/200] [Batch 523/637] [D loss: 0.124646] [G loss: 0.597516]\n",
      "[Epoch 1/200] [Batch 524/637] [D loss: 0.136649] [G loss: 0.641740]\n",
      "[Epoch 1/200] [Batch 525/637] [D loss: 0.131820] [G loss: 0.540013]\n",
      "[Epoch 1/200] [Batch 526/637] [D loss: 0.144440] [G loss: 0.448310]\n",
      "[Epoch 1/200] [Batch 527/637] [D loss: 0.140224] [G loss: 0.662792]\n",
      "[Epoch 1/200] [Batch 528/637] [D loss: 0.134629] [G loss: 0.571764]\n",
      "[Epoch 1/200] [Batch 529/637] [D loss: 0.142372] [G loss: 0.462528]\n",
      "[Epoch 1/200] [Batch 530/637] [D loss: 0.126813] [G loss: 0.572986]\n",
      "[Epoch 1/200] [Batch 531/637] [D loss: 0.127724] [G loss: 0.576370]\n",
      "[Epoch 1/200] [Batch 532/637] [D loss: 0.167003] [G loss: 0.823031]\n",
      "[Epoch 1/200] [Batch 533/637] [D loss: 0.129649] [G loss: 0.488189]\n",
      "[Epoch 1/200] [Batch 534/637] [D loss: 0.127959] [G loss: 0.512166]\n",
      "[Epoch 1/200] [Batch 535/637] [D loss: 0.134324] [G loss: 0.570131]\n",
      "[Epoch 1/200] [Batch 536/637] [D loss: 0.127154] [G loss: 0.638150]\n",
      "[Epoch 1/200] [Batch 537/637] [D loss: 0.125341] [G loss: 0.551732]\n",
      "[Epoch 1/200] [Batch 538/637] [D loss: 0.143620] [G loss: 0.579121]\n",
      "[Epoch 1/200] [Batch 539/637] [D loss: 0.185430] [G loss: 0.467981]\n",
      "[Epoch 1/200] [Batch 540/637] [D loss: 0.350831] [G loss: 1.032233]\n",
      "[Epoch 1/200] [Batch 541/637] [D loss: 0.163391] [G loss: 0.591477]\n",
      "[Epoch 1/200] [Batch 542/637] [D loss: 0.156859] [G loss: 0.474692]\n",
      "[Epoch 1/200] [Batch 543/637] [D loss: 0.156801] [G loss: 0.465504]\n",
      "[Epoch 1/200] [Batch 544/637] [D loss: 0.140890] [G loss: 0.485609]\n",
      "[Epoch 1/200] [Batch 545/637] [D loss: 0.139511] [G loss: 0.503344]\n",
      "[Epoch 1/200] [Batch 546/637] [D loss: 0.127049] [G loss: 0.566742]\n",
      "[Epoch 1/200] [Batch 547/637] [D loss: 0.112228] [G loss: 0.518040]\n",
      "[Epoch 1/200] [Batch 548/637] [D loss: 0.117551] [G loss: 0.519214]\n",
      "[Epoch 1/200] [Batch 549/637] [D loss: 0.107591] [G loss: 0.620581]\n",
      "[Epoch 1/200] [Batch 550/637] [D loss: 0.108892] [G loss: 0.551990]\n",
      "[Epoch 1/200] [Batch 551/637] [D loss: 0.120474] [G loss: 0.500741]\n",
      "[Epoch 1/200] [Batch 552/637] [D loss: 0.117205] [G loss: 0.650570]\n",
      "[Epoch 1/200] [Batch 553/637] [D loss: 0.095152] [G loss: 0.620534]\n",
      "[Epoch 1/200] [Batch 554/637] [D loss: 0.119936] [G loss: 0.529827]\n",
      "[Epoch 1/200] [Batch 555/637] [D loss: 0.139772] [G loss: 0.655398]\n",
      "[Epoch 1/200] [Batch 556/637] [D loss: 0.126392] [G loss: 0.522955]\n",
      "[Epoch 1/200] [Batch 557/637] [D loss: 0.110195] [G loss: 0.582588]\n",
      "[Epoch 1/200] [Batch 558/637] [D loss: 0.118397] [G loss: 0.507006]\n",
      "[Epoch 1/200] [Batch 559/637] [D loss: 0.125535] [G loss: 0.620767]\n",
      "[Epoch 1/200] [Batch 560/637] [D loss: 0.140441] [G loss: 0.518718]\n",
      "[Epoch 1/200] [Batch 561/637] [D loss: 0.125543] [G loss: 0.542968]\n",
      "[Epoch 1/200] [Batch 562/637] [D loss: 0.153073] [G loss: 0.588774]\n",
      "[Epoch 1/200] [Batch 563/637] [D loss: 0.123277] [G loss: 0.590172]\n",
      "[Epoch 1/200] [Batch 564/637] [D loss: 0.121110] [G loss: 0.549441]\n",
      "[Epoch 1/200] [Batch 565/637] [D loss: 0.131238] [G loss: 0.617119]\n",
      "[Epoch 1/200] [Batch 566/637] [D loss: 0.123903] [G loss: 0.526847]\n",
      "[Epoch 1/200] [Batch 567/637] [D loss: 0.127269] [G loss: 0.604291]\n",
      "[Epoch 1/200] [Batch 568/637] [D loss: 0.162237] [G loss: 0.502137]\n",
      "[Epoch 1/200] [Batch 569/637] [D loss: 0.276480] [G loss: 0.805195]\n",
      "[Epoch 1/200] [Batch 570/637] [D loss: 0.151388] [G loss: 0.678715]\n",
      "[Epoch 1/200] [Batch 571/637] [D loss: 0.179758] [G loss: 0.550608]\n",
      "[Epoch 1/200] [Batch 572/637] [D loss: 0.144892] [G loss: 0.490241]\n",
      "[Epoch 1/200] [Batch 573/637] [D loss: 0.133833] [G loss: 0.498858]\n",
      "[Epoch 1/200] [Batch 574/637] [D loss: 0.127044] [G loss: 0.488558]\n",
      "[Epoch 1/200] [Batch 575/637] [D loss: 0.121495] [G loss: 0.481487]\n",
      "[Epoch 1/200] [Batch 576/637] [D loss: 0.122289] [G loss: 0.521297]\n",
      "[Epoch 1/200] [Batch 577/637] [D loss: 0.110648] [G loss: 0.608578]\n",
      "[Epoch 1/200] [Batch 578/637] [D loss: 0.108241] [G loss: 0.525759]\n",
      "[Epoch 1/200] [Batch 579/637] [D loss: 0.107874] [G loss: 0.644193]\n",
      "[Epoch 1/200] [Batch 580/637] [D loss: 0.114957] [G loss: 0.580473]\n",
      "[Epoch 1/200] [Batch 581/637] [D loss: 0.120527] [G loss: 0.538591]\n",
      "[Epoch 1/200] [Batch 582/637] [D loss: 0.130104] [G loss: 0.600992]\n",
      "[Epoch 1/200] [Batch 583/637] [D loss: 0.114279] [G loss: 0.592222]\n",
      "[Epoch 1/200] [Batch 584/637] [D loss: 0.167116] [G loss: 0.463936]\n",
      "[Epoch 1/200] [Batch 585/637] [D loss: 0.244175] [G loss: 0.798242]\n",
      "[Epoch 1/200] [Batch 586/637] [D loss: 0.151916] [G loss: 0.584665]\n",
      "[Epoch 1/200] [Batch 587/637] [D loss: 0.159837] [G loss: 0.483104]\n",
      "[Epoch 1/200] [Batch 588/637] [D loss: 0.137459] [G loss: 0.527418]\n",
      "[Epoch 1/200] [Batch 589/637] [D loss: 0.131212] [G loss: 0.525873]\n",
      "[Epoch 1/200] [Batch 590/637] [D loss: 0.131304] [G loss: 0.488299]\n",
      "[Epoch 1/200] [Batch 591/637] [D loss: 0.142865] [G loss: 0.626537]\n",
      "[Epoch 1/200] [Batch 592/637] [D loss: 0.128703] [G loss: 0.579939]\n",
      "[Epoch 1/200] [Batch 593/637] [D loss: 0.120753] [G loss: 0.542157]\n",
      "[Epoch 1/200] [Batch 594/637] [D loss: 0.104626] [G loss: 0.524470]\n",
      "[Epoch 1/200] [Batch 595/637] [D loss: 0.122088] [G loss: 0.590608]\n",
      "[Epoch 1/200] [Batch 596/637] [D loss: 0.130115] [G loss: 0.570423]\n",
      "[Epoch 1/200] [Batch 597/637] [D loss: 0.152958] [G loss: 0.579965]\n",
      "[Epoch 1/200] [Batch 598/637] [D loss: 0.174931] [G loss: 0.723146]\n",
      "[Epoch 1/200] [Batch 599/637] [D loss: 0.174200] [G loss: 0.418855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 600/637] [D loss: 0.175245] [G loss: 0.691577]\n",
      "[Epoch 1/200] [Batch 601/637] [D loss: 0.143655] [G loss: 0.555548]\n",
      "[Epoch 1/200] [Batch 602/637] [D loss: 0.163632] [G loss: 0.454246]\n",
      "[Epoch 1/200] [Batch 603/637] [D loss: 0.135628] [G loss: 0.492883]\n",
      "[Epoch 1/200] [Batch 604/637] [D loss: 0.137994] [G loss: 0.573392]\n",
      "[Epoch 1/200] [Batch 605/637] [D loss: 0.121723] [G loss: 0.502692]\n",
      "[Epoch 1/200] [Batch 606/637] [D loss: 0.126666] [G loss: 0.533533]\n",
      "[Epoch 1/200] [Batch 607/637] [D loss: 0.138019] [G loss: 0.601090]\n",
      "[Epoch 1/200] [Batch 608/637] [D loss: 0.144751] [G loss: 0.575490]\n",
      "[Epoch 1/200] [Batch 609/637] [D loss: 0.143294] [G loss: 0.482743]\n",
      "[Epoch 1/200] [Batch 610/637] [D loss: 0.133400] [G loss: 0.585706]\n",
      "[Epoch 1/200] [Batch 611/637] [D loss: 0.152522] [G loss: 0.442769]\n",
      "[Epoch 1/200] [Batch 612/637] [D loss: 0.127864] [G loss: 0.586411]\n",
      "[Epoch 1/200] [Batch 613/637] [D loss: 0.159756] [G loss: 0.568510]\n",
      "[Epoch 1/200] [Batch 614/637] [D loss: 0.184061] [G loss: 0.379355]\n",
      "[Epoch 1/200] [Batch 615/637] [D loss: 0.174400] [G loss: 0.677090]\n",
      "[Epoch 1/200] [Batch 616/637] [D loss: 0.159357] [G loss: 0.569873]\n",
      "[Epoch 1/200] [Batch 617/637] [D loss: 0.174889] [G loss: 0.425437]\n",
      "[Epoch 1/200] [Batch 618/637] [D loss: 0.192375] [G loss: 0.629468]\n",
      "[Epoch 1/200] [Batch 619/637] [D loss: 0.150883] [G loss: 0.501336]\n",
      "[Epoch 1/200] [Batch 620/637] [D loss: 0.165140] [G loss: 0.410025]\n",
      "[Epoch 1/200] [Batch 621/637] [D loss: 0.144943] [G loss: 0.604936]\n",
      "[Epoch 1/200] [Batch 622/637] [D loss: 0.129969] [G loss: 0.591969]\n",
      "[Epoch 1/200] [Batch 623/637] [D loss: 0.127112] [G loss: 0.488455]\n",
      "[Epoch 1/200] [Batch 624/637] [D loss: 0.137176] [G loss: 0.586185]\n",
      "[Epoch 1/200] [Batch 625/637] [D loss: 0.119955] [G loss: 0.520666]\n",
      "[Epoch 1/200] [Batch 626/637] [D loss: 0.115442] [G loss: 0.551938]\n",
      "[Epoch 1/200] [Batch 627/637] [D loss: 0.118537] [G loss: 0.625395]\n",
      "[Epoch 1/200] [Batch 628/637] [D loss: 0.122629] [G loss: 0.528632]\n",
      "[Epoch 1/200] [Batch 629/637] [D loss: 0.185859] [G loss: 0.692942]\n",
      "[Epoch 1/200] [Batch 630/637] [D loss: 0.143113] [G loss: 0.444353]\n",
      "[Epoch 1/200] [Batch 631/637] [D loss: 0.132534] [G loss: 0.586271]\n",
      "[Epoch 1/200] [Batch 632/637] [D loss: 0.127366] [G loss: 0.495495]\n",
      "[Epoch 1/200] [Batch 633/637] [D loss: 0.122115] [G loss: 0.566275]\n",
      "[Epoch 1/200] [Batch 634/637] [D loss: 0.136569] [G loss: 0.466247]\n",
      "[Epoch 1/200] [Batch 635/637] [D loss: 0.154934] [G loss: 0.595319]\n",
      "[Epoch 1/200] [Batch 636/637] [D loss: 0.226508] [G loss: 0.502343]\n",
      "[Epoch 2/200] [Batch 0/637] [D loss: 0.328891] [G loss: 0.801763]\n",
      "[Epoch 2/200] [Batch 1/637] [D loss: 0.175090] [G loss: 0.516469]\n",
      "[Epoch 2/200] [Batch 2/637] [D loss: 0.207519] [G loss: 0.441378]\n",
      "[Epoch 2/200] [Batch 3/637] [D loss: 0.168635] [G loss: 0.455702]\n",
      "[Epoch 2/200] [Batch 4/637] [D loss: 0.176836] [G loss: 0.432788]\n",
      "[Epoch 2/200] [Batch 5/637] [D loss: 0.155523] [G loss: 0.471433]\n",
      "[Epoch 2/200] [Batch 6/637] [D loss: 0.137517] [G loss: 0.483871]\n",
      "[Epoch 2/200] [Batch 7/637] [D loss: 0.142890] [G loss: 0.457453]\n",
      "[Epoch 2/200] [Batch 8/637] [D loss: 0.144914] [G loss: 0.451004]\n",
      "[Epoch 2/200] [Batch 9/637] [D loss: 0.147898] [G loss: 0.494504]\n",
      "[Epoch 2/200] [Batch 10/637] [D loss: 0.137760] [G loss: 0.542750]\n",
      "[Epoch 2/200] [Batch 11/637] [D loss: 0.126276] [G loss: 0.581511]\n",
      "[Epoch 2/200] [Batch 12/637] [D loss: 0.143244] [G loss: 0.454350]\n",
      "[Epoch 2/200] [Batch 13/637] [D loss: 0.143138] [G loss: 0.467396]\n",
      "[Epoch 2/200] [Batch 14/637] [D loss: 0.151201] [G loss: 0.637061]\n",
      "[Epoch 2/200] [Batch 15/637] [D loss: 0.125805] [G loss: 0.560923]\n",
      "[Epoch 2/200] [Batch 16/637] [D loss: 0.126467] [G loss: 0.558693]\n",
      "[Epoch 2/200] [Batch 17/637] [D loss: 0.145464] [G loss: 0.532846]\n",
      "[Epoch 2/200] [Batch 18/637] [D loss: 0.139974] [G loss: 0.607877]\n",
      "[Epoch 2/200] [Batch 19/637] [D loss: 0.140843] [G loss: 0.534956]\n",
      "[Epoch 2/200] [Batch 20/637] [D loss: 0.225988] [G loss: 0.398402]\n",
      "[Epoch 2/200] [Batch 21/637] [D loss: 0.331082] [G loss: 0.841875]\n",
      "[Epoch 2/200] [Batch 22/637] [D loss: 0.177707] [G loss: 0.665508]\n",
      "[Epoch 2/200] [Batch 23/637] [D loss: 0.196804] [G loss: 0.475042]\n",
      "[Epoch 2/200] [Batch 24/637] [D loss: 0.153918] [G loss: 0.491121]\n",
      "[Epoch 2/200] [Batch 25/637] [D loss: 0.173587] [G loss: 0.465784]\n",
      "[Epoch 2/200] [Batch 26/637] [D loss: 0.175862] [G loss: 0.471645]\n",
      "[Epoch 2/200] [Batch 27/637] [D loss: 0.153528] [G loss: 0.492399]\n",
      "[Epoch 2/200] [Batch 28/637] [D loss: 0.134476] [G loss: 0.486967]\n",
      "[Epoch 2/200] [Batch 29/637] [D loss: 0.124177] [G loss: 0.496163]\n",
      "[Epoch 2/200] [Batch 30/637] [D loss: 0.129348] [G loss: 0.522219]\n",
      "[Epoch 2/200] [Batch 31/637] [D loss: 0.129652] [G loss: 0.551544]\n",
      "[Epoch 2/200] [Batch 32/637] [D loss: 0.138007] [G loss: 0.467514]\n",
      "[Epoch 2/200] [Batch 33/637] [D loss: 0.131383] [G loss: 0.596204]\n",
      "[Epoch 2/200] [Batch 34/637] [D loss: 0.123965] [G loss: 0.512891]\n",
      "[Epoch 2/200] [Batch 35/637] [D loss: 0.138077] [G loss: 0.539899]\n",
      "[Epoch 2/200] [Batch 36/637] [D loss: 0.132345] [G loss: 0.534939]\n",
      "[Epoch 2/200] [Batch 37/637] [D loss: 0.128665] [G loss: 0.547082]\n",
      "[Epoch 2/200] [Batch 38/637] [D loss: 0.147218] [G loss: 0.457693]\n",
      "[Epoch 2/200] [Batch 39/637] [D loss: 0.183768] [G loss: 0.843618]\n",
      "[Epoch 2/200] [Batch 40/637] [D loss: 0.124887] [G loss: 0.589404]\n",
      "[Epoch 2/200] [Batch 41/637] [D loss: 0.151274] [G loss: 0.489004]\n",
      "[Epoch 2/200] [Batch 42/637] [D loss: 0.130957] [G loss: 0.545586]\n",
      "[Epoch 2/200] [Batch 43/637] [D loss: 0.140607] [G loss: 0.550188]\n",
      "[Epoch 2/200] [Batch 44/637] [D loss: 0.120749] [G loss: 0.488243]\n",
      "[Epoch 2/200] [Batch 45/637] [D loss: 0.110164] [G loss: 0.604004]\n",
      "[Epoch 2/200] [Batch 46/637] [D loss: 0.118391] [G loss: 0.539664]\n",
      "[Epoch 2/200] [Batch 47/637] [D loss: 0.136182] [G loss: 0.615335]\n",
      "[Epoch 2/200] [Batch 48/637] [D loss: 0.123032] [G loss: 0.546471]\n",
      "[Epoch 2/200] [Batch 49/637] [D loss: 0.133046] [G loss: 0.527291]\n",
      "[Epoch 2/200] [Batch 50/637] [D loss: 0.136987] [G loss: 0.633995]\n",
      "[Epoch 2/200] [Batch 51/637] [D loss: 0.131532] [G loss: 0.490879]\n",
      "[Epoch 2/200] [Batch 52/637] [D loss: 0.155900] [G loss: 0.681907]\n",
      "[Epoch 2/200] [Batch 53/637] [D loss: 0.157346] [G loss: 0.550578]\n",
      "[Epoch 2/200] [Batch 54/637] [D loss: 0.142684] [G loss: 0.680006]\n",
      "[Epoch 2/200] [Batch 55/637] [D loss: 0.132370] [G loss: 0.534663]\n",
      "[Epoch 2/200] [Batch 56/637] [D loss: 0.161416] [G loss: 0.448883]\n",
      "[Epoch 2/200] [Batch 57/637] [D loss: 0.191958] [G loss: 0.741105]\n",
      "[Epoch 2/200] [Batch 58/637] [D loss: 0.129066] [G loss: 0.557914]\n",
      "[Epoch 2/200] [Batch 59/637] [D loss: 0.132072] [G loss: 0.502686]\n",
      "[Epoch 2/200] [Batch 60/637] [D loss: 0.124087] [G loss: 0.589017]\n",
      "[Epoch 2/200] [Batch 61/637] [D loss: 0.139913] [G loss: 0.517521]\n",
      "[Epoch 2/200] [Batch 62/637] [D loss: 0.120559] [G loss: 0.566600]\n",
      "[Epoch 2/200] [Batch 63/637] [D loss: 0.126984] [G loss: 0.592367]\n",
      "[Epoch 2/200] [Batch 64/637] [D loss: 0.119249] [G loss: 0.580772]\n",
      "[Epoch 2/200] [Batch 65/637] [D loss: 0.153468] [G loss: 0.471194]\n",
      "[Epoch 2/200] [Batch 66/637] [D loss: 0.173588] [G loss: 0.771054]\n",
      "[Epoch 2/200] [Batch 67/637] [D loss: 0.146637] [G loss: 0.575870]\n",
      "[Epoch 2/200] [Batch 68/637] [D loss: 0.155571] [G loss: 0.481973]\n",
      "[Epoch 2/200] [Batch 69/637] [D loss: 0.153782] [G loss: 0.611821]\n",
      "[Epoch 2/200] [Batch 70/637] [D loss: 0.154715] [G loss: 0.525195]\n",
      "[Epoch 2/200] [Batch 71/637] [D loss: 0.152749] [G loss: 0.512619]\n",
      "[Epoch 2/200] [Batch 72/637] [D loss: 0.146760] [G loss: 0.575514]\n",
      "[Epoch 2/200] [Batch 73/637] [D loss: 0.151056] [G loss: 0.494244]\n",
      "[Epoch 2/200] [Batch 74/637] [D loss: 0.141932] [G loss: 0.639825]\n",
      "[Epoch 2/200] [Batch 75/637] [D loss: 0.130039] [G loss: 0.578796]\n",
      "[Epoch 2/200] [Batch 76/637] [D loss: 0.124631] [G loss: 0.484877]\n",
      "[Epoch 2/200] [Batch 77/637] [D loss: 0.134822] [G loss: 0.583953]\n",
      "[Epoch 2/200] [Batch 78/637] [D loss: 0.151351] [G loss: 0.635938]\n",
      "[Epoch 2/200] [Batch 79/637] [D loss: 0.142560] [G loss: 0.523801]\n",
      "[Epoch 2/200] [Batch 80/637] [D loss: 0.168964] [G loss: 0.646113]\n",
      "[Epoch 2/200] [Batch 81/637] [D loss: 0.226211] [G loss: 0.409803]\n",
      "[Epoch 2/200] [Batch 82/637] [D loss: 0.261806] [G loss: 0.870995]\n",
      "[Epoch 2/200] [Batch 83/637] [D loss: 0.175281] [G loss: 0.632047]\n",
      "[Epoch 2/200] [Batch 84/637] [D loss: 0.184475] [G loss: 0.474697]\n",
      "[Epoch 2/200] [Batch 85/637] [D loss: 0.165094] [G loss: 0.381445]\n",
      "[Epoch 2/200] [Batch 86/637] [D loss: 0.133455] [G loss: 0.465459]\n",
      "[Epoch 2/200] [Batch 87/637] [D loss: 0.152108] [G loss: 0.536745]\n",
      "[Epoch 2/200] [Batch 88/637] [D loss: 0.123800] [G loss: 0.507873]\n",
      "[Epoch 2/200] [Batch 89/637] [D loss: 0.125706] [G loss: 0.570557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 90/637] [D loss: 0.113320] [G loss: 0.575600]\n",
      "[Epoch 2/200] [Batch 91/637] [D loss: 0.128217] [G loss: 0.588773]\n",
      "[Epoch 2/200] [Batch 92/637] [D loss: 0.134553] [G loss: 0.533338]\n",
      "[Epoch 2/200] [Batch 93/637] [D loss: 0.119329] [G loss: 0.550325]\n",
      "[Epoch 2/200] [Batch 94/637] [D loss: 0.116300] [G loss: 0.627326]\n",
      "[Epoch 2/200] [Batch 95/637] [D loss: 0.128382] [G loss: 0.621957]\n",
      "[Epoch 2/200] [Batch 96/637] [D loss: 0.135957] [G loss: 0.575203]\n",
      "[Epoch 2/200] [Batch 97/637] [D loss: 0.154492] [G loss: 0.463720]\n",
      "[Epoch 2/200] [Batch 98/637] [D loss: 0.207926] [G loss: 0.821354]\n",
      "[Epoch 2/200] [Batch 99/637] [D loss: 0.152004] [G loss: 0.564405]\n",
      "[Epoch 2/200] [Batch 100/637] [D loss: 0.146023] [G loss: 0.468792]\n",
      "[Epoch 2/200] [Batch 101/637] [D loss: 0.147805] [G loss: 0.630541]\n",
      "[Epoch 2/200] [Batch 102/637] [D loss: 0.115274] [G loss: 0.562748]\n",
      "[Epoch 2/200] [Batch 103/637] [D loss: 0.134283] [G loss: 0.529520]\n",
      "[Epoch 2/200] [Batch 104/637] [D loss: 0.123237] [G loss: 0.570647]\n",
      "[Epoch 2/200] [Batch 105/637] [D loss: 0.119830] [G loss: 0.579961]\n",
      "[Epoch 2/200] [Batch 106/637] [D loss: 0.112923] [G loss: 0.568211]\n",
      "[Epoch 2/200] [Batch 107/637] [D loss: 0.137053] [G loss: 0.523666]\n",
      "[Epoch 2/200] [Batch 108/637] [D loss: 0.140820] [G loss: 0.492753]\n",
      "[Epoch 2/200] [Batch 109/637] [D loss: 0.109913] [G loss: 0.628379]\n",
      "[Epoch 2/200] [Batch 110/637] [D loss: 0.134852] [G loss: 0.610892]\n",
      "[Epoch 2/200] [Batch 111/637] [D loss: 0.135980] [G loss: 0.590479]\n",
      "[Epoch 2/200] [Batch 112/637] [D loss: 0.128093] [G loss: 0.573461]\n",
      "[Epoch 2/200] [Batch 113/637] [D loss: 0.123372] [G loss: 0.569637]\n",
      "[Epoch 2/200] [Batch 114/637] [D loss: 0.134616] [G loss: 0.700011]\n",
      "[Epoch 2/200] [Batch 115/637] [D loss: 0.164281] [G loss: 0.512669]\n",
      "[Epoch 2/200] [Batch 116/637] [D loss: 0.143873] [G loss: 0.686876]\n",
      "[Epoch 2/200] [Batch 117/637] [D loss: 0.128816] [G loss: 0.574324]\n",
      "[Epoch 2/200] [Batch 118/637] [D loss: 0.172274] [G loss: 0.500196]\n",
      "[Epoch 2/200] [Batch 119/637] [D loss: 0.136235] [G loss: 0.658057]\n",
      "[Epoch 2/200] [Batch 120/637] [D loss: 0.129144] [G loss: 0.630138]\n",
      "[Epoch 2/200] [Batch 121/637] [D loss: 0.120393] [G loss: 0.560707]\n",
      "[Epoch 2/200] [Batch 122/637] [D loss: 0.108280] [G loss: 0.638412]\n",
      "[Epoch 2/200] [Batch 123/637] [D loss: 0.130336] [G loss: 0.567536]\n",
      "[Epoch 2/200] [Batch 124/637] [D loss: 0.116358] [G loss: 0.585161]\n",
      "[Epoch 2/200] [Batch 125/637] [D loss: 0.129398] [G loss: 0.529568]\n",
      "[Epoch 2/200] [Batch 126/637] [D loss: 0.141776] [G loss: 0.639631]\n",
      "[Epoch 2/200] [Batch 127/637] [D loss: 0.115079] [G loss: 0.642649]\n",
      "[Epoch 2/200] [Batch 128/637] [D loss: 0.121175] [G loss: 0.535645]\n",
      "[Epoch 2/200] [Batch 129/637] [D loss: 0.119932] [G loss: 0.526180]\n",
      "[Epoch 2/200] [Batch 130/637] [D loss: 0.128626] [G loss: 0.589621]\n",
      "[Epoch 2/200] [Batch 131/637] [D loss: 0.134989] [G loss: 0.584192]\n",
      "[Epoch 2/200] [Batch 132/637] [D loss: 0.135253] [G loss: 0.524814]\n",
      "[Epoch 2/200] [Batch 133/637] [D loss: 0.140497] [G loss: 0.519858]\n",
      "[Epoch 2/200] [Batch 134/637] [D loss: 0.151690] [G loss: 0.510108]\n",
      "[Epoch 2/200] [Batch 135/637] [D loss: 0.189518] [G loss: 0.731266]\n",
      "[Epoch 2/200] [Batch 136/637] [D loss: 0.224819] [G loss: 0.459257]\n",
      "[Epoch 2/200] [Batch 137/637] [D loss: 0.249237] [G loss: 0.714796]\n",
      "[Epoch 2/200] [Batch 138/637] [D loss: 0.177017] [G loss: 0.650636]\n",
      "[Epoch 2/200] [Batch 139/637] [D loss: 0.154159] [G loss: 0.486970]\n",
      "[Epoch 2/200] [Batch 140/637] [D loss: 0.174448] [G loss: 0.368243]\n",
      "[Epoch 2/200] [Batch 141/637] [D loss: 0.148234] [G loss: 0.443764]\n",
      "[Epoch 2/200] [Batch 142/637] [D loss: 0.145610] [G loss: 0.511743]\n",
      "[Epoch 2/200] [Batch 143/637] [D loss: 0.137191] [G loss: 0.505346]\n",
      "[Epoch 2/200] [Batch 144/637] [D loss: 0.134572] [G loss: 0.457640]\n",
      "[Epoch 2/200] [Batch 145/637] [D loss: 0.132792] [G loss: 0.542586]\n",
      "[Epoch 2/200] [Batch 146/637] [D loss: 0.130416] [G loss: 0.544767]\n",
      "[Epoch 2/200] [Batch 147/637] [D loss: 0.130052] [G loss: 0.501231]\n",
      "[Epoch 2/200] [Batch 148/637] [D loss: 0.135862] [G loss: 0.514855]\n",
      "[Epoch 2/200] [Batch 149/637] [D loss: 0.125853] [G loss: 0.503196]\n",
      "[Epoch 2/200] [Batch 150/637] [D loss: 0.124728] [G loss: 0.609262]\n",
      "[Epoch 2/200] [Batch 151/637] [D loss: 0.164258] [G loss: 0.477321]\n",
      "[Epoch 2/200] [Batch 152/637] [D loss: 0.177401] [G loss: 0.650609]\n",
      "[Epoch 2/200] [Batch 153/637] [D loss: 0.179820] [G loss: 0.466141]\n",
      "[Epoch 2/200] [Batch 154/637] [D loss: 0.145954] [G loss: 0.612173]\n",
      "[Epoch 2/200] [Batch 155/637] [D loss: 0.130914] [G loss: 0.547738]\n",
      "[Epoch 2/200] [Batch 156/637] [D loss: 0.144008] [G loss: 0.490609]\n",
      "[Epoch 2/200] [Batch 157/637] [D loss: 0.151398] [G loss: 0.579668]\n",
      "[Epoch 2/200] [Batch 158/637] [D loss: 0.116318] [G loss: 0.568822]\n",
      "[Epoch 2/200] [Batch 159/637] [D loss: 0.167546] [G loss: 0.489622]\n",
      "[Epoch 2/200] [Batch 160/637] [D loss: 0.165092] [G loss: 0.592282]\n",
      "[Epoch 2/200] [Batch 161/637] [D loss: 0.128688] [G loss: 0.541530]\n",
      "[Epoch 2/200] [Batch 162/637] [D loss: 0.146329] [G loss: 0.484728]\n",
      "[Epoch 2/200] [Batch 163/637] [D loss: 0.144327] [G loss: 0.487001]\n",
      "[Epoch 2/200] [Batch 164/637] [D loss: 0.140534] [G loss: 0.503434]\n",
      "[Epoch 2/200] [Batch 165/637] [D loss: 0.127463] [G loss: 0.552560]\n",
      "[Epoch 2/200] [Batch 166/637] [D loss: 0.136673] [G loss: 0.562273]\n",
      "[Epoch 2/200] [Batch 167/637] [D loss: 0.129924] [G loss: 0.576948]\n",
      "[Epoch 2/200] [Batch 168/637] [D loss: 0.132394] [G loss: 0.572882]\n",
      "[Epoch 2/200] [Batch 169/637] [D loss: 0.148251] [G loss: 0.554513]\n",
      "[Epoch 2/200] [Batch 170/637] [D loss: 0.131298] [G loss: 0.503517]\n",
      "[Epoch 2/200] [Batch 171/637] [D loss: 0.144511] [G loss: 0.543160]\n",
      "[Epoch 2/200] [Batch 172/637] [D loss: 0.145280] [G loss: 0.510916]\n",
      "[Epoch 2/200] [Batch 173/637] [D loss: 0.144321] [G loss: 0.520111]\n",
      "[Epoch 2/200] [Batch 174/637] [D loss: 0.131685] [G loss: 0.634950]\n",
      "[Epoch 2/200] [Batch 175/637] [D loss: 0.132367] [G loss: 0.531686]\n",
      "[Epoch 2/200] [Batch 176/637] [D loss: 0.138575] [G loss: 0.633527]\n",
      "[Epoch 2/200] [Batch 177/637] [D loss: 0.151321] [G loss: 0.516288]\n",
      "[Epoch 2/200] [Batch 178/637] [D loss: 0.163275] [G loss: 0.619295]\n",
      "[Epoch 2/200] [Batch 179/637] [D loss: 0.129935] [G loss: 0.596652]\n",
      "[Epoch 2/200] [Batch 180/637] [D loss: 0.122353] [G loss: 0.578264]\n",
      "[Epoch 2/200] [Batch 181/637] [D loss: 0.120033] [G loss: 0.612882]\n",
      "[Epoch 2/200] [Batch 182/637] [D loss: 0.113622] [G loss: 0.577016]\n",
      "[Epoch 2/200] [Batch 183/637] [D loss: 0.124774] [G loss: 0.541747]\n",
      "[Epoch 2/200] [Batch 184/637] [D loss: 0.163847] [G loss: 0.672410]\n",
      "[Epoch 2/200] [Batch 185/637] [D loss: 0.239827] [G loss: 0.589401]\n",
      "[Epoch 2/200] [Batch 186/637] [D loss: 0.322288] [G loss: 0.751376]\n",
      "[Epoch 2/200] [Batch 187/637] [D loss: 0.170105] [G loss: 0.700494]\n",
      "[Epoch 2/200] [Batch 188/637] [D loss: 0.152547] [G loss: 0.564031]\n",
      "[Epoch 2/200] [Batch 189/637] [D loss: 0.178696] [G loss: 0.433657]\n",
      "[Epoch 2/200] [Batch 190/637] [D loss: 0.147561] [G loss: 0.491333]\n",
      "[Epoch 2/200] [Batch 191/637] [D loss: 0.144943] [G loss: 0.486299]\n",
      "[Epoch 2/200] [Batch 192/637] [D loss: 0.132945] [G loss: 0.479932]\n",
      "[Epoch 2/200] [Batch 193/637] [D loss: 0.131845] [G loss: 0.469698]\n",
      "[Epoch 2/200] [Batch 194/637] [D loss: 0.144107] [G loss: 0.529814]\n",
      "[Epoch 2/200] [Batch 195/637] [D loss: 0.113050] [G loss: 0.572506]\n",
      "[Epoch 2/200] [Batch 196/637] [D loss: 0.131303] [G loss: 0.515677]\n",
      "[Epoch 2/200] [Batch 197/637] [D loss: 0.142548] [G loss: 0.466190]\n",
      "[Epoch 2/200] [Batch 198/637] [D loss: 0.121749] [G loss: 0.509634]\n",
      "[Epoch 2/200] [Batch 199/637] [D loss: 0.145418] [G loss: 0.546865]\n",
      "[Epoch 2/200] [Batch 200/637] [D loss: 0.134941] [G loss: 0.580563]\n",
      "[Epoch 2/200] [Batch 201/637] [D loss: 0.152361] [G loss: 0.580371]\n",
      "[Epoch 2/200] [Batch 202/637] [D loss: 0.122497] [G loss: 0.533183]\n",
      "[Epoch 2/200] [Batch 203/637] [D loss: 0.145400] [G loss: 0.524349]\n",
      "[Epoch 2/200] [Batch 204/637] [D loss: 0.114938] [G loss: 0.545978]\n",
      "[Epoch 2/200] [Batch 205/637] [D loss: 0.147943] [G loss: 0.557664]\n",
      "[Epoch 2/200] [Batch 206/637] [D loss: 0.122956] [G loss: 0.559225]\n",
      "[Epoch 2/200] [Batch 207/637] [D loss: 0.124265] [G loss: 0.569015]\n",
      "[Epoch 2/200] [Batch 208/637] [D loss: 0.141885] [G loss: 0.607713]\n",
      "[Epoch 2/200] [Batch 209/637] [D loss: 0.213358] [G loss: 0.432560]\n",
      "[Epoch 2/200] [Batch 210/637] [D loss: 0.420364] [G loss: 0.870857]\n",
      "[Epoch 2/200] [Batch 211/637] [D loss: 0.202277] [G loss: 0.674384]\n",
      "[Epoch 2/200] [Batch 212/637] [D loss: 0.168836] [G loss: 0.487043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 213/637] [D loss: 0.147099] [G loss: 0.461862]\n",
      "[Epoch 2/200] [Batch 214/637] [D loss: 0.138095] [G loss: 0.454413]\n",
      "[Epoch 2/200] [Batch 215/637] [D loss: 0.149167] [G loss: 0.447226]\n",
      "[Epoch 2/200] [Batch 216/637] [D loss: 0.134386] [G loss: 0.456265]\n",
      "[Epoch 2/200] [Batch 217/637] [D loss: 0.127729] [G loss: 0.461176]\n",
      "[Epoch 2/200] [Batch 218/637] [D loss: 0.117817] [G loss: 0.545728]\n",
      "[Epoch 2/200] [Batch 219/637] [D loss: 0.114761] [G loss: 0.544467]\n",
      "[Epoch 2/200] [Batch 220/637] [D loss: 0.125378] [G loss: 0.513091]\n",
      "[Epoch 2/200] [Batch 221/637] [D loss: 0.110890] [G loss: 0.497193]\n",
      "[Epoch 2/200] [Batch 222/637] [D loss: 0.148053] [G loss: 0.507343]\n",
      "[Epoch 2/200] [Batch 223/637] [D loss: 0.139803] [G loss: 0.625396]\n",
      "[Epoch 2/200] [Batch 224/637] [D loss: 0.151234] [G loss: 0.455172]\n",
      "[Epoch 2/200] [Batch 225/637] [D loss: 0.137873] [G loss: 0.554970]\n",
      "[Epoch 2/200] [Batch 226/637] [D loss: 0.177507] [G loss: 0.435983]\n",
      "[Epoch 2/200] [Batch 227/637] [D loss: 0.188816] [G loss: 0.645539]\n",
      "[Epoch 2/200] [Batch 228/637] [D loss: 0.149918] [G loss: 0.512225]\n",
      "[Epoch 2/200] [Batch 229/637] [D loss: 0.162579] [G loss: 0.488502]\n",
      "[Epoch 2/200] [Batch 230/637] [D loss: 0.126072] [G loss: 0.618856]\n",
      "[Epoch 2/200] [Batch 231/637] [D loss: 0.152084] [G loss: 0.513863]\n",
      "[Epoch 2/200] [Batch 232/637] [D loss: 0.178955] [G loss: 0.439445]\n",
      "[Epoch 2/200] [Batch 233/637] [D loss: 0.177508] [G loss: 0.619238]\n",
      "[Epoch 2/200] [Batch 234/637] [D loss: 0.152373] [G loss: 0.639227]\n",
      "[Epoch 2/200] [Batch 235/637] [D loss: 0.161114] [G loss: 0.517464]\n",
      "[Epoch 2/200] [Batch 236/637] [D loss: 0.158001] [G loss: 0.457806]\n",
      "[Epoch 2/200] [Batch 237/637] [D loss: 0.161415] [G loss: 0.524110]\n",
      "[Epoch 2/200] [Batch 238/637] [D loss: 0.130988] [G loss: 0.521444]\n",
      "[Epoch 2/200] [Batch 239/637] [D loss: 0.131705] [G loss: 0.598590]\n",
      "[Epoch 2/200] [Batch 240/637] [D loss: 0.144675] [G loss: 0.626732]\n",
      "[Epoch 2/200] [Batch 241/637] [D loss: 0.145343] [G loss: 0.554934]\n",
      "[Epoch 2/200] [Batch 242/637] [D loss: 0.128067] [G loss: 0.523159]\n",
      "[Epoch 2/200] [Batch 243/637] [D loss: 0.139680] [G loss: 0.612709]\n",
      "[Epoch 2/200] [Batch 244/637] [D loss: 0.172400] [G loss: 0.488999]\n",
      "[Epoch 2/200] [Batch 245/637] [D loss: 0.247974] [G loss: 0.800582]\n",
      "[Epoch 2/200] [Batch 246/637] [D loss: 0.143001] [G loss: 0.536173]\n",
      "[Epoch 2/200] [Batch 247/637] [D loss: 0.196231] [G loss: 0.434627]\n",
      "[Epoch 2/200] [Batch 248/637] [D loss: 0.168662] [G loss: 0.569766]\n",
      "[Epoch 2/200] [Batch 249/637] [D loss: 0.140207] [G loss: 0.573549]\n",
      "[Epoch 2/200] [Batch 250/637] [D loss: 0.129919] [G loss: 0.565646]\n",
      "[Epoch 2/200] [Batch 251/637] [D loss: 0.131322] [G loss: 0.540288]\n",
      "[Epoch 2/200] [Batch 252/637] [D loss: 0.132125] [G loss: 0.490242]\n",
      "[Epoch 2/200] [Batch 253/637] [D loss: 0.137606] [G loss: 0.544076]\n",
      "[Epoch 2/200] [Batch 254/637] [D loss: 0.126751] [G loss: 0.593979]\n",
      "[Epoch 2/200] [Batch 255/637] [D loss: 0.131663] [G loss: 0.520300]\n",
      "[Epoch 2/200] [Batch 256/637] [D loss: 0.135522] [G loss: 0.524197]\n",
      "[Epoch 2/200] [Batch 257/637] [D loss: 0.123649] [G loss: 0.516492]\n",
      "[Epoch 2/200] [Batch 258/637] [D loss: 0.126106] [G loss: 0.548080]\n",
      "[Epoch 2/200] [Batch 259/637] [D loss: 0.160848] [G loss: 0.542928]\n",
      "[Epoch 2/200] [Batch 260/637] [D loss: 0.201421] [G loss: 0.632686]\n",
      "[Epoch 2/200] [Batch 261/637] [D loss: 0.174046] [G loss: 0.502448]\n",
      "[Epoch 2/200] [Batch 262/637] [D loss: 0.159228] [G loss: 0.489394]\n",
      "[Epoch 2/200] [Batch 263/637] [D loss: 0.156653] [G loss: 0.463307]\n",
      "[Epoch 2/200] [Batch 264/637] [D loss: 0.167687] [G loss: 0.536058]\n",
      "[Epoch 2/200] [Batch 265/637] [D loss: 0.156417] [G loss: 0.488882]\n",
      "[Epoch 2/200] [Batch 266/637] [D loss: 0.155010] [G loss: 0.479194]\n",
      "[Epoch 2/200] [Batch 267/637] [D loss: 0.151401] [G loss: 0.499061]\n",
      "[Epoch 2/200] [Batch 268/637] [D loss: 0.161481] [G loss: 0.581692]\n",
      "[Epoch 2/200] [Batch 269/637] [D loss: 0.140304] [G loss: 0.544591]\n",
      "[Epoch 2/200] [Batch 270/637] [D loss: 0.151584] [G loss: 0.502354]\n",
      "[Epoch 2/200] [Batch 271/637] [D loss: 0.119891] [G loss: 0.462422]\n",
      "[Epoch 2/200] [Batch 272/637] [D loss: 0.124372] [G loss: 0.488682]\n",
      "[Epoch 2/200] [Batch 273/637] [D loss: 0.131211] [G loss: 0.613875]\n",
      "[Epoch 2/200] [Batch 274/637] [D loss: 0.114516] [G loss: 0.582680]\n",
      "[Epoch 2/200] [Batch 275/637] [D loss: 0.126867] [G loss: 0.538078]\n",
      "[Epoch 2/200] [Batch 276/637] [D loss: 0.147283] [G loss: 0.468107]\n",
      "[Epoch 2/200] [Batch 277/637] [D loss: 0.144673] [G loss: 0.722524]\n",
      "[Epoch 2/200] [Batch 278/637] [D loss: 0.125340] [G loss: 0.592929]\n",
      "[Epoch 2/200] [Batch 279/637] [D loss: 0.143506] [G loss: 0.519927]\n",
      "[Epoch 2/200] [Batch 280/637] [D loss: 0.129153] [G loss: 0.541724]\n",
      "[Epoch 2/200] [Batch 281/637] [D loss: 0.121080] [G loss: 0.528074]\n",
      "[Epoch 2/200] [Batch 282/637] [D loss: 0.135912] [G loss: 0.667724]\n",
      "[Epoch 2/200] [Batch 283/637] [D loss: 0.128857] [G loss: 0.595058]\n",
      "[Epoch 2/200] [Batch 284/637] [D loss: 0.137762] [G loss: 0.489046]\n",
      "[Epoch 2/200] [Batch 285/637] [D loss: 0.131548] [G loss: 0.572003]\n",
      "[Epoch 2/200] [Batch 286/637] [D loss: 0.149867] [G loss: 0.610954]\n",
      "[Epoch 2/200] [Batch 287/637] [D loss: 0.168350] [G loss: 0.467162]\n",
      "[Epoch 2/200] [Batch 288/637] [D loss: 0.212379] [G loss: 0.688483]\n",
      "[Epoch 2/200] [Batch 289/637] [D loss: 0.194875] [G loss: 0.636277]\n",
      "[Epoch 2/200] [Batch 290/637] [D loss: 0.143215] [G loss: 0.497948]\n",
      "[Epoch 2/200] [Batch 291/637] [D loss: 0.147239] [G loss: 0.428995]\n",
      "[Epoch 2/200] [Batch 292/637] [D loss: 0.150802] [G loss: 0.454872]\n",
      "[Epoch 2/200] [Batch 293/637] [D loss: 0.154231] [G loss: 0.495371]\n",
      "[Epoch 2/200] [Batch 294/637] [D loss: 0.144079] [G loss: 0.527921]\n",
      "[Epoch 2/200] [Batch 295/637] [D loss: 0.141104] [G loss: 0.479035]\n",
      "[Epoch 2/200] [Batch 296/637] [D loss: 0.153894] [G loss: 0.571832]\n",
      "[Epoch 2/200] [Batch 297/637] [D loss: 0.128969] [G loss: 0.514184]\n",
      "[Epoch 2/200] [Batch 298/637] [D loss: 0.144138] [G loss: 0.428291]\n",
      "[Epoch 2/200] [Batch 299/637] [D loss: 0.123123] [G loss: 0.575873]\n",
      "[Epoch 2/200] [Batch 300/637] [D loss: 0.125169] [G loss: 0.563587]\n",
      "[Epoch 2/200] [Batch 301/637] [D loss: 0.167834] [G loss: 0.502307]\n",
      "[Epoch 2/200] [Batch 302/637] [D loss: 0.187098] [G loss: 0.654342]\n",
      "[Epoch 2/200] [Batch 303/637] [D loss: 0.133639] [G loss: 0.600449]\n",
      "[Epoch 2/200] [Batch 304/637] [D loss: 0.199145] [G loss: 0.457049]\n",
      "[Epoch 2/200] [Batch 305/637] [D loss: 0.190293] [G loss: 0.476336]\n",
      "[Epoch 2/200] [Batch 306/637] [D loss: 0.137349] [G loss: 0.511405]\n",
      "[Epoch 2/200] [Batch 307/637] [D loss: 0.140265] [G loss: 0.484561]\n",
      "[Epoch 2/200] [Batch 308/637] [D loss: 0.139645] [G loss: 0.526259]\n",
      "[Epoch 2/200] [Batch 309/637] [D loss: 0.142358] [G loss: 0.449876]\n",
      "[Epoch 2/200] [Batch 310/637] [D loss: 0.149799] [G loss: 0.451915]\n",
      "[Epoch 2/200] [Batch 311/637] [D loss: 0.128595] [G loss: 0.470451]\n",
      "[Epoch 2/200] [Batch 312/637] [D loss: 0.134932] [G loss: 0.499632]\n",
      "[Epoch 2/200] [Batch 313/637] [D loss: 0.137845] [G loss: 0.578959]\n",
      "[Epoch 2/200] [Batch 314/637] [D loss: 0.142151] [G loss: 0.474270]\n",
      "[Epoch 2/200] [Batch 315/637] [D loss: 0.161638] [G loss: 0.531371]\n",
      "[Epoch 2/200] [Batch 316/637] [D loss: 0.152589] [G loss: 0.614124]\n",
      "[Epoch 2/200] [Batch 317/637] [D loss: 0.160354] [G loss: 0.509871]\n",
      "[Epoch 2/200] [Batch 318/637] [D loss: 0.142408] [G loss: 0.550305]\n",
      "[Epoch 2/200] [Batch 319/637] [D loss: 0.156414] [G loss: 0.538450]\n",
      "[Epoch 2/200] [Batch 320/637] [D loss: 0.148321] [G loss: 0.546747]\n",
      "[Epoch 2/200] [Batch 321/637] [D loss: 0.146557] [G loss: 0.533891]\n",
      "[Epoch 2/200] [Batch 322/637] [D loss: 0.138050] [G loss: 0.540805]\n",
      "[Epoch 2/200] [Batch 323/637] [D loss: 0.138474] [G loss: 0.501348]\n",
      "[Epoch 2/200] [Batch 324/637] [D loss: 0.134074] [G loss: 0.542703]\n",
      "[Epoch 2/200] [Batch 325/637] [D loss: 0.135958] [G loss: 0.531303]\n",
      "[Epoch 2/200] [Batch 326/637] [D loss: 0.141324] [G loss: 0.536708]\n",
      "[Epoch 2/200] [Batch 327/637] [D loss: 0.150703] [G loss: 0.499422]\n",
      "[Epoch 2/200] [Batch 328/637] [D loss: 0.165502] [G loss: 0.618287]\n",
      "[Epoch 2/200] [Batch 329/637] [D loss: 0.141342] [G loss: 0.593814]\n",
      "[Epoch 2/200] [Batch 330/637] [D loss: 0.127629] [G loss: 0.597665]\n",
      "[Epoch 2/200] [Batch 331/637] [D loss: 0.120474] [G loss: 0.511812]\n",
      "[Epoch 2/200] [Batch 332/637] [D loss: 0.133264] [G loss: 0.568119]\n",
      "[Epoch 2/200] [Batch 333/637] [D loss: 0.140661] [G loss: 0.539866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 334/637] [D loss: 0.127932] [G loss: 0.502192]\n",
      "[Epoch 2/200] [Batch 335/637] [D loss: 0.137002] [G loss: 0.659204]\n",
      "[Epoch 2/200] [Batch 336/637] [D loss: 0.178430] [G loss: 0.549163]\n",
      "[Epoch 2/200] [Batch 337/637] [D loss: 0.159524] [G loss: 0.645766]\n",
      "[Epoch 2/200] [Batch 338/637] [D loss: 0.158156] [G loss: 0.574628]\n",
      "[Epoch 2/200] [Batch 339/637] [D loss: 0.183110] [G loss: 0.500014]\n",
      "[Epoch 2/200] [Batch 340/637] [D loss: 0.207794] [G loss: 0.573925]\n",
      "[Epoch 2/200] [Batch 341/637] [D loss: 0.170236] [G loss: 0.595075]\n",
      "[Epoch 2/200] [Batch 342/637] [D loss: 0.165339] [G loss: 0.529883]\n",
      "[Epoch 2/200] [Batch 343/637] [D loss: 0.155050] [G loss: 0.472328]\n",
      "[Epoch 2/200] [Batch 344/637] [D loss: 0.152814] [G loss: 0.459983]\n",
      "[Epoch 2/200] [Batch 345/637] [D loss: 0.148750] [G loss: 0.421384]\n",
      "[Epoch 2/200] [Batch 346/637] [D loss: 0.135928] [G loss: 0.536484]\n",
      "[Epoch 2/200] [Batch 347/637] [D loss: 0.125129] [G loss: 0.555998]\n",
      "[Epoch 2/200] [Batch 348/637] [D loss: 0.121577] [G loss: 0.524125]\n",
      "[Epoch 2/200] [Batch 349/637] [D loss: 0.140477] [G loss: 0.503148]\n",
      "[Epoch 2/200] [Batch 350/637] [D loss: 0.137751] [G loss: 0.519105]\n",
      "[Epoch 2/200] [Batch 351/637] [D loss: 0.146355] [G loss: 0.587471]\n",
      "[Epoch 2/200] [Batch 352/637] [D loss: 0.151251] [G loss: 0.556113]\n",
      "[Epoch 2/200] [Batch 353/637] [D loss: 0.124245] [G loss: 0.609942]\n",
      "[Epoch 2/200] [Batch 354/637] [D loss: 0.132897] [G loss: 0.511376]\n",
      "[Epoch 2/200] [Batch 355/637] [D loss: 0.148560] [G loss: 0.523060]\n",
      "[Epoch 2/200] [Batch 356/637] [D loss: 0.173874] [G loss: 0.548630]\n",
      "[Epoch 2/200] [Batch 357/637] [D loss: 0.143294] [G loss: 0.679372]\n",
      "[Epoch 2/200] [Batch 358/637] [D loss: 0.149594] [G loss: 0.531854]\n",
      "[Epoch 2/200] [Batch 359/637] [D loss: 0.210832] [G loss: 0.444503]\n",
      "[Epoch 2/200] [Batch 360/637] [D loss: 0.247726] [G loss: 0.636400]\n",
      "[Epoch 2/200] [Batch 361/637] [D loss: 0.149436] [G loss: 0.748935]\n",
      "[Epoch 2/200] [Batch 362/637] [D loss: 0.170712] [G loss: 0.622988]\n",
      "[Epoch 2/200] [Batch 363/637] [D loss: 0.146781] [G loss: 0.446158]\n",
      "[Epoch 2/200] [Batch 364/637] [D loss: 0.156181] [G loss: 0.452849]\n",
      "[Epoch 2/200] [Batch 365/637] [D loss: 0.127727] [G loss: 0.535589]\n",
      "[Epoch 2/200] [Batch 366/637] [D loss: 0.131593] [G loss: 0.562695]\n",
      "[Epoch 2/200] [Batch 367/637] [D loss: 0.120840] [G loss: 0.528997]\n",
      "[Epoch 2/200] [Batch 368/637] [D loss: 0.129690] [G loss: 0.545099]\n",
      "[Epoch 2/200] [Batch 369/637] [D loss: 0.132898] [G loss: 0.568050]\n",
      "[Epoch 2/200] [Batch 370/637] [D loss: 0.136303] [G loss: 0.447758]\n",
      "[Epoch 2/200] [Batch 371/637] [D loss: 0.140132] [G loss: 0.556527]\n",
      "[Epoch 2/200] [Batch 372/637] [D loss: 0.150620] [G loss: 0.468820]\n",
      "[Epoch 2/200] [Batch 373/637] [D loss: 0.176981] [G loss: 0.618206]\n",
      "[Epoch 2/200] [Batch 374/637] [D loss: 0.148005] [G loss: 0.522092]\n",
      "[Epoch 2/200] [Batch 375/637] [D loss: 0.154312] [G loss: 0.431566]\n",
      "[Epoch 2/200] [Batch 376/637] [D loss: 0.172640] [G loss: 0.461891]\n",
      "[Epoch 2/200] [Batch 377/637] [D loss: 0.136918] [G loss: 0.492258]\n",
      "[Epoch 2/200] [Batch 378/637] [D loss: 0.122506] [G loss: 0.536311]\n",
      "[Epoch 2/200] [Batch 379/637] [D loss: 0.140529] [G loss: 0.535714]\n",
      "[Epoch 2/200] [Batch 380/637] [D loss: 0.136164] [G loss: 0.503313]\n",
      "[Epoch 2/200] [Batch 381/637] [D loss: 0.132611] [G loss: 0.530287]\n",
      "[Epoch 2/200] [Batch 382/637] [D loss: 0.144940] [G loss: 0.490096]\n",
      "[Epoch 2/200] [Batch 383/637] [D loss: 0.132948] [G loss: 0.602419]\n",
      "[Epoch 2/200] [Batch 384/637] [D loss: 0.139651] [G loss: 0.595845]\n",
      "[Epoch 2/200] [Batch 385/637] [D loss: 0.122844] [G loss: 0.562728]\n",
      "[Epoch 2/200] [Batch 386/637] [D loss: 0.126954] [G loss: 0.482437]\n",
      "[Epoch 2/200] [Batch 387/637] [D loss: 0.127273] [G loss: 0.653414]\n",
      "[Epoch 2/200] [Batch 388/637] [D loss: 0.129540] [G loss: 0.600505]\n",
      "[Epoch 2/200] [Batch 389/637] [D loss: 0.115057] [G loss: 0.539334]\n",
      "[Epoch 2/200] [Batch 390/637] [D loss: 0.123889] [G loss: 0.533699]\n",
      "[Epoch 2/200] [Batch 391/637] [D loss: 0.143190] [G loss: 0.555023]\n",
      "[Epoch 2/200] [Batch 392/637] [D loss: 0.134023] [G loss: 0.535453]\n",
      "[Epoch 2/200] [Batch 393/637] [D loss: 0.129619] [G loss: 0.545120]\n",
      "[Epoch 2/200] [Batch 394/637] [D loss: 0.135711] [G loss: 0.561085]\n",
      "[Epoch 2/200] [Batch 395/637] [D loss: 0.138218] [G loss: 0.585624]\n",
      "[Epoch 2/200] [Batch 396/637] [D loss: 0.173363] [G loss: 0.466462]\n",
      "[Epoch 2/200] [Batch 397/637] [D loss: 0.174858] [G loss: 0.722098]\n",
      "[Epoch 2/200] [Batch 398/637] [D loss: 0.127275] [G loss: 0.546105]\n",
      "[Epoch 2/200] [Batch 399/637] [D loss: 0.172937] [G loss: 0.502919]\n",
      "[Epoch 2/200] [Batch 400/637] [D loss: 0.156272] [G loss: 0.571024]\n",
      "[Epoch 2/200] [Batch 401/637] [D loss: 0.142096] [G loss: 0.515765]\n",
      "[Epoch 2/200] [Batch 402/637] [D loss: 0.169394] [G loss: 0.460652]\n",
      "[Epoch 2/200] [Batch 403/637] [D loss: 0.137080] [G loss: 0.575788]\n",
      "[Epoch 2/200] [Batch 404/637] [D loss: 0.155640] [G loss: 0.522948]\n",
      "[Epoch 2/200] [Batch 405/637] [D loss: 0.159913] [G loss: 0.421934]\n",
      "[Epoch 2/200] [Batch 406/637] [D loss: 0.136961] [G loss: 0.591195]\n",
      "[Epoch 2/200] [Batch 407/637] [D loss: 0.145380] [G loss: 0.637730]\n",
      "[Epoch 2/200] [Batch 408/637] [D loss: 0.130668] [G loss: 0.516468]\n",
      "[Epoch 2/200] [Batch 409/637] [D loss: 0.128010] [G loss: 0.578886]\n",
      "[Epoch 2/200] [Batch 410/637] [D loss: 0.118494] [G loss: 0.563738]\n",
      "[Epoch 2/200] [Batch 411/637] [D loss: 0.137637] [G loss: 0.534415]\n",
      "[Epoch 2/200] [Batch 412/637] [D loss: 0.153053] [G loss: 0.558028]\n",
      "[Epoch 2/200] [Batch 413/637] [D loss: 0.156113] [G loss: 0.629684]\n",
      "[Epoch 2/200] [Batch 414/637] [D loss: 0.142464] [G loss: 0.622766]\n",
      "[Epoch 2/200] [Batch 415/637] [D loss: 0.120992] [G loss: 0.523856]\n",
      "[Epoch 2/200] [Batch 416/637] [D loss: 0.129032] [G loss: 0.584684]\n",
      "[Epoch 2/200] [Batch 417/637] [D loss: 0.141510] [G loss: 0.546045]\n",
      "[Epoch 2/200] [Batch 418/637] [D loss: 0.129101] [G loss: 0.547165]\n",
      "[Epoch 2/200] [Batch 419/637] [D loss: 0.151617] [G loss: 0.518077]\n",
      "[Epoch 2/200] [Batch 420/637] [D loss: 0.152431] [G loss: 0.582644]\n",
      "[Epoch 2/200] [Batch 421/637] [D loss: 0.152995] [G loss: 0.534097]\n",
      "[Epoch 2/200] [Batch 422/637] [D loss: 0.160102] [G loss: 0.485296]\n",
      "[Epoch 2/200] [Batch 423/637] [D loss: 0.142716] [G loss: 0.532544]\n",
      "[Epoch 2/200] [Batch 424/637] [D loss: 0.168410] [G loss: 0.466760]\n",
      "[Epoch 2/200] [Batch 425/637] [D loss: 0.164070] [G loss: 0.518445]\n",
      "[Epoch 2/200] [Batch 426/637] [D loss: 0.139767] [G loss: 0.552771]\n",
      "[Epoch 2/200] [Batch 427/637] [D loss: 0.139611] [G loss: 0.628582]\n",
      "[Epoch 2/200] [Batch 428/637] [D loss: 0.133994] [G loss: 0.552577]\n",
      "[Epoch 2/200] [Batch 429/637] [D loss: 0.130099] [G loss: 0.488162]\n",
      "[Epoch 2/200] [Batch 430/637] [D loss: 0.120635] [G loss: 0.543454]\n",
      "[Epoch 2/200] [Batch 431/637] [D loss: 0.149304] [G loss: 0.584470]\n",
      "[Epoch 2/200] [Batch 432/637] [D loss: 0.116548] [G loss: 0.597957]\n",
      "[Epoch 2/200] [Batch 433/637] [D loss: 0.118922] [G loss: 0.531871]\n",
      "[Epoch 2/200] [Batch 434/637] [D loss: 0.160177] [G loss: 0.610994]\n",
      "[Epoch 2/200] [Batch 435/637] [D loss: 0.141244] [G loss: 0.539826]\n",
      "[Epoch 2/200] [Batch 436/637] [D loss: 0.133338] [G loss: 0.595250]\n",
      "[Epoch 2/200] [Batch 437/637] [D loss: 0.133019] [G loss: 0.508581]\n",
      "[Epoch 2/200] [Batch 438/637] [D loss: 0.136308] [G loss: 0.560268]\n",
      "[Epoch 2/200] [Batch 439/637] [D loss: 0.135903] [G loss: 0.564378]\n",
      "[Epoch 2/200] [Batch 440/637] [D loss: 0.140821] [G loss: 0.518368]\n",
      "[Epoch 2/200] [Batch 441/637] [D loss: 0.130979] [G loss: 0.535049]\n",
      "[Epoch 2/200] [Batch 442/637] [D loss: 0.148344] [G loss: 0.523247]\n",
      "[Epoch 2/200] [Batch 443/637] [D loss: 0.139885] [G loss: 0.568275]\n",
      "[Epoch 2/200] [Batch 444/637] [D loss: 0.169013] [G loss: 0.456047]\n",
      "[Epoch 2/200] [Batch 445/637] [D loss: 0.196130] [G loss: 0.583487]\n",
      "[Epoch 2/200] [Batch 446/637] [D loss: 0.179062] [G loss: 0.618846]\n",
      "[Epoch 2/200] [Batch 447/637] [D loss: 0.144753] [G loss: 0.592410]\n",
      "[Epoch 2/200] [Batch 448/637] [D loss: 0.144107] [G loss: 0.478998]\n",
      "[Epoch 2/200] [Batch 449/637] [D loss: 0.141152] [G loss: 0.426671]\n",
      "[Epoch 2/200] [Batch 450/637] [D loss: 0.156446] [G loss: 0.461798]\n",
      "[Epoch 2/200] [Batch 451/637] [D loss: 0.146350] [G loss: 0.564797]\n",
      "[Epoch 2/200] [Batch 452/637] [D loss: 0.129836] [G loss: 0.590339]\n",
      "[Epoch 2/200] [Batch 453/637] [D loss: 0.145708] [G loss: 0.467390]\n",
      "[Epoch 2/200] [Batch 454/637] [D loss: 0.159597] [G loss: 0.576131]\n",
      "[Epoch 2/200] [Batch 455/637] [D loss: 0.121230] [G loss: 0.560268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 456/637] [D loss: 0.143341] [G loss: 0.455886]\n",
      "[Epoch 2/200] [Batch 457/637] [D loss: 0.145133] [G loss: 0.546238]\n",
      "[Epoch 2/200] [Batch 458/637] [D loss: 0.138708] [G loss: 0.541336]\n",
      "[Epoch 2/200] [Batch 459/637] [D loss: 0.155282] [G loss: 0.447101]\n",
      "[Epoch 2/200] [Batch 460/637] [D loss: 0.171959] [G loss: 0.587551]\n",
      "[Epoch 2/200] [Batch 461/637] [D loss: 0.165144] [G loss: 0.552295]\n",
      "[Epoch 2/200] [Batch 462/637] [D loss: 0.199210] [G loss: 0.535063]\n",
      "[Epoch 2/200] [Batch 463/637] [D loss: 0.171531] [G loss: 0.499548]\n",
      "[Epoch 2/200] [Batch 464/637] [D loss: 0.181245] [G loss: 0.452099]\n",
      "[Epoch 2/200] [Batch 465/637] [D loss: 0.171738] [G loss: 0.553240]\n",
      "[Epoch 2/200] [Batch 466/637] [D loss: 0.145730] [G loss: 0.621145]\n",
      "[Epoch 2/200] [Batch 467/637] [D loss: 0.153053] [G loss: 0.513187]\n",
      "[Epoch 2/200] [Batch 468/637] [D loss: 0.152628] [G loss: 0.406298]\n",
      "[Epoch 2/200] [Batch 469/637] [D loss: 0.154570] [G loss: 0.479765]\n",
      "[Epoch 2/200] [Batch 470/637] [D loss: 0.132264] [G loss: 0.579596]\n",
      "[Epoch 2/200] [Batch 471/637] [D loss: 0.136502] [G loss: 0.589823]\n",
      "[Epoch 2/200] [Batch 472/637] [D loss: 0.159823] [G loss: 0.502550]\n",
      "[Epoch 2/200] [Batch 473/637] [D loss: 0.134222] [G loss: 0.474879]\n",
      "[Epoch 2/200] [Batch 474/637] [D loss: 0.136670] [G loss: 0.534158]\n",
      "[Epoch 2/200] [Batch 475/637] [D loss: 0.125534] [G loss: 0.577708]\n",
      "[Epoch 2/200] [Batch 476/637] [D loss: 0.126950] [G loss: 0.516351]\n",
      "[Epoch 2/200] [Batch 477/637] [D loss: 0.148520] [G loss: 0.547600]\n",
      "[Epoch 2/200] [Batch 478/637] [D loss: 0.128732] [G loss: 0.558078]\n",
      "[Epoch 2/200] [Batch 479/637] [D loss: 0.125632] [G loss: 0.539526]\n",
      "[Epoch 2/200] [Batch 480/637] [D loss: 0.123795] [G loss: 0.607701]\n",
      "[Epoch 2/200] [Batch 481/637] [D loss: 0.124996] [G loss: 0.598512]\n",
      "[Epoch 2/200] [Batch 482/637] [D loss: 0.141261] [G loss: 0.484885]\n",
      "[Epoch 2/200] [Batch 483/637] [D loss: 0.140577] [G loss: 0.542253]\n",
      "[Epoch 2/200] [Batch 484/637] [D loss: 0.157036] [G loss: 0.635256]\n",
      "[Epoch 2/200] [Batch 485/637] [D loss: 0.129086] [G loss: 0.555731]\n",
      "[Epoch 2/200] [Batch 486/637] [D loss: 0.126875] [G loss: 0.576181]\n",
      "[Epoch 2/200] [Batch 487/637] [D loss: 0.132852] [G loss: 0.483230]\n",
      "[Epoch 2/200] [Batch 488/637] [D loss: 0.135741] [G loss: 0.538165]\n",
      "[Epoch 2/200] [Batch 489/637] [D loss: 0.166403] [G loss: 0.539604]\n",
      "[Epoch 2/200] [Batch 490/637] [D loss: 0.161973] [G loss: 0.637522]\n",
      "[Epoch 2/200] [Batch 491/637] [D loss: 0.179714] [G loss: 0.514536]\n",
      "[Epoch 2/200] [Batch 492/637] [D loss: 0.174920] [G loss: 0.568205]\n",
      "[Epoch 2/200] [Batch 493/637] [D loss: 0.175876] [G loss: 0.541488]\n",
      "[Epoch 2/200] [Batch 494/637] [D loss: 0.133396] [G loss: 0.566004]\n",
      "[Epoch 2/200] [Batch 495/637] [D loss: 0.133568] [G loss: 0.565858]\n",
      "[Epoch 2/200] [Batch 496/637] [D loss: 0.136122] [G loss: 0.509467]\n",
      "[Epoch 2/200] [Batch 497/637] [D loss: 0.133360] [G loss: 0.595459]\n",
      "[Epoch 2/200] [Batch 498/637] [D loss: 0.126148] [G loss: 0.597371]\n",
      "[Epoch 2/200] [Batch 499/637] [D loss: 0.130453] [G loss: 0.556966]\n",
      "[Epoch 2/200] [Batch 500/637] [D loss: 0.131933] [G loss: 0.623851]\n",
      "[Epoch 2/200] [Batch 501/637] [D loss: 0.173430] [G loss: 0.528080]\n",
      "[Epoch 2/200] [Batch 502/637] [D loss: 0.165076] [G loss: 0.762919]\n",
      "[Epoch 2/200] [Batch 503/637] [D loss: 0.120928] [G loss: 0.673821]\n",
      "[Epoch 2/200] [Batch 504/637] [D loss: 0.147330] [G loss: 0.519927]\n",
      "[Epoch 2/200] [Batch 505/637] [D loss: 0.136810] [G loss: 0.514085]\n",
      "[Epoch 2/200] [Batch 506/637] [D loss: 0.132765] [G loss: 0.532490]\n",
      "[Epoch 2/200] [Batch 507/637] [D loss: 0.134099] [G loss: 0.553942]\n",
      "[Epoch 2/200] [Batch 508/637] [D loss: 0.141270] [G loss: 0.623531]\n",
      "[Epoch 2/200] [Batch 509/637] [D loss: 0.130535] [G loss: 0.533717]\n",
      "[Epoch 2/200] [Batch 510/637] [D loss: 0.154616] [G loss: 0.528877]\n",
      "[Epoch 2/200] [Batch 511/637] [D loss: 0.136951] [G loss: 0.522331]\n",
      "[Epoch 2/200] [Batch 512/637] [D loss: 0.138342] [G loss: 0.583737]\n",
      "[Epoch 2/200] [Batch 513/637] [D loss: 0.136854] [G loss: 0.631008]\n",
      "[Epoch 2/200] [Batch 514/637] [D loss: 0.145182] [G loss: 0.638759]\n",
      "[Epoch 2/200] [Batch 515/637] [D loss: 0.132160] [G loss: 0.458657]\n",
      "[Epoch 2/200] [Batch 516/637] [D loss: 0.130653] [G loss: 0.580010]\n",
      "[Epoch 2/200] [Batch 517/637] [D loss: 0.161904] [G loss: 0.614476]\n",
      "[Epoch 2/200] [Batch 518/637] [D loss: 0.154699] [G loss: 0.573643]\n",
      "[Epoch 2/200] [Batch 519/637] [D loss: 0.132433] [G loss: 0.599485]\n",
      "[Epoch 2/200] [Batch 520/637] [D loss: 0.146423] [G loss: 0.620536]\n",
      "[Epoch 2/200] [Batch 521/637] [D loss: 0.132533] [G loss: 0.570490]\n",
      "[Epoch 2/200] [Batch 522/637] [D loss: 0.129694] [G loss: 0.565038]\n",
      "[Epoch 2/200] [Batch 523/637] [D loss: 0.128092] [G loss: 0.615292]\n",
      "[Epoch 2/200] [Batch 524/637] [D loss: 0.098993] [G loss: 0.595584]\n",
      "[Epoch 2/200] [Batch 525/637] [D loss: 0.111446] [G loss: 0.618614]\n",
      "[Epoch 2/200] [Batch 526/637] [D loss: 0.122758] [G loss: 0.659896]\n",
      "[Epoch 2/200] [Batch 527/637] [D loss: 0.120303] [G loss: 0.585006]\n",
      "[Epoch 2/200] [Batch 528/637] [D loss: 0.121817] [G loss: 0.532246]\n",
      "[Epoch 2/200] [Batch 529/637] [D loss: 0.122738] [G loss: 0.622548]\n",
      "[Epoch 2/200] [Batch 530/637] [D loss: 0.119822] [G loss: 0.533768]\n",
      "[Epoch 2/200] [Batch 531/637] [D loss: 0.113132] [G loss: 0.565594]\n",
      "[Epoch 2/200] [Batch 532/637] [D loss: 0.132546] [G loss: 0.596473]\n",
      "[Epoch 2/200] [Batch 533/637] [D loss: 0.163429] [G loss: 0.485167]\n",
      "[Epoch 2/200] [Batch 534/637] [D loss: 0.210274] [G loss: 0.718714]\n",
      "[Epoch 2/200] [Batch 535/637] [D loss: 0.194908] [G loss: 0.543163]\n",
      "[Epoch 2/200] [Batch 536/637] [D loss: 0.142994] [G loss: 0.575260]\n",
      "[Epoch 2/200] [Batch 537/637] [D loss: 0.139784] [G loss: 0.482082]\n",
      "[Epoch 2/200] [Batch 538/637] [D loss: 0.142829] [G loss: 0.469752]\n",
      "[Epoch 2/200] [Batch 539/637] [D loss: 0.146895] [G loss: 0.527899]\n",
      "[Epoch 2/200] [Batch 540/637] [D loss: 0.140294] [G loss: 0.579155]\n",
      "[Epoch 2/200] [Batch 541/637] [D loss: 0.146994] [G loss: 0.580679]\n",
      "[Epoch 2/200] [Batch 542/637] [D loss: 0.167070] [G loss: 0.553509]\n",
      "[Epoch 2/200] [Batch 543/637] [D loss: 0.152583] [G loss: 0.467384]\n",
      "[Epoch 2/200] [Batch 544/637] [D loss: 0.139672] [G loss: 0.536774]\n",
      "[Epoch 2/200] [Batch 545/637] [D loss: 0.169859] [G loss: 0.501825]\n",
      "[Epoch 2/200] [Batch 546/637] [D loss: 0.137815] [G loss: 0.549924]\n",
      "[Epoch 2/200] [Batch 547/637] [D loss: 0.157340] [G loss: 0.488273]\n",
      "[Epoch 2/200] [Batch 548/637] [D loss: 0.162408] [G loss: 0.542843]\n",
      "[Epoch 2/200] [Batch 549/637] [D loss: 0.152420] [G loss: 0.535236]\n",
      "[Epoch 2/200] [Batch 550/637] [D loss: 0.161572] [G loss: 0.526886]\n",
      "[Epoch 2/200] [Batch 551/637] [D loss: 0.150230] [G loss: 0.570786]\n",
      "[Epoch 2/200] [Batch 552/637] [D loss: 0.160218] [G loss: 0.500320]\n",
      "[Epoch 2/200] [Batch 553/637] [D loss: 0.157007] [G loss: 0.586615]\n",
      "[Epoch 2/200] [Batch 554/637] [D loss: 0.156742] [G loss: 0.549448]\n",
      "[Epoch 2/200] [Batch 555/637] [D loss: 0.178540] [G loss: 0.410444]\n",
      "[Epoch 2/200] [Batch 556/637] [D loss: 0.160952] [G loss: 0.584717]\n",
      "[Epoch 2/200] [Batch 557/637] [D loss: 0.177218] [G loss: 0.495808]\n",
      "[Epoch 2/200] [Batch 558/637] [D loss: 0.166731] [G loss: 0.703072]\n",
      "[Epoch 2/200] [Batch 559/637] [D loss: 0.132832] [G loss: 0.592729]\n",
      "[Epoch 2/200] [Batch 560/637] [D loss: 0.128984] [G loss: 0.508363]\n",
      "[Epoch 2/200] [Batch 561/637] [D loss: 0.127650] [G loss: 0.475749]\n",
      "[Epoch 2/200] [Batch 562/637] [D loss: 0.122221] [G loss: 0.663102]\n",
      "[Epoch 2/200] [Batch 563/637] [D loss: 0.139895] [G loss: 0.561606]\n",
      "[Epoch 2/200] [Batch 564/637] [D loss: 0.136147] [G loss: 0.598835]\n",
      "[Epoch 2/200] [Batch 565/637] [D loss: 0.124263] [G loss: 0.563475]\n",
      "[Epoch 2/200] [Batch 566/637] [D loss: 0.145444] [G loss: 0.607715]\n",
      "[Epoch 2/200] [Batch 567/637] [D loss: 0.152660] [G loss: 0.527542]\n",
      "[Epoch 2/200] [Batch 568/637] [D loss: 0.175558] [G loss: 0.693567]\n",
      "[Epoch 2/200] [Batch 569/637] [D loss: 0.151940] [G loss: 0.500111]\n",
      "[Epoch 2/200] [Batch 570/637] [D loss: 0.126051] [G loss: 0.558799]\n",
      "[Epoch 2/200] [Batch 571/637] [D loss: 0.142196] [G loss: 0.550073]\n",
      "[Epoch 2/200] [Batch 572/637] [D loss: 0.149932] [G loss: 0.523482]\n",
      "[Epoch 2/200] [Batch 573/637] [D loss: 0.141638] [G loss: 0.561212]\n",
      "[Epoch 2/200] [Batch 574/637] [D loss: 0.186365] [G loss: 0.517098]\n",
      "[Epoch 2/200] [Batch 575/637] [D loss: 0.181438] [G loss: 0.706712]\n",
      "[Epoch 2/200] [Batch 576/637] [D loss: 0.212156] [G loss: 0.429418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 577/637] [D loss: 0.195822] [G loss: 0.654891]\n",
      "[Epoch 2/200] [Batch 578/637] [D loss: 0.166882] [G loss: 0.566635]\n",
      "[Epoch 2/200] [Batch 579/637] [D loss: 0.186257] [G loss: 0.451021]\n",
      "[Epoch 2/200] [Batch 580/637] [D loss: 0.138093] [G loss: 0.519802]\n",
      "[Epoch 2/200] [Batch 581/637] [D loss: 0.147055] [G loss: 0.568305]\n",
      "[Epoch 2/200] [Batch 582/637] [D loss: 0.126634] [G loss: 0.617112]\n",
      "[Epoch 2/200] [Batch 583/637] [D loss: 0.140932] [G loss: 0.529265]\n",
      "[Epoch 2/200] [Batch 584/637] [D loss: 0.146901] [G loss: 0.568538]\n",
      "[Epoch 2/200] [Batch 585/637] [D loss: 0.130513] [G loss: 0.605361]\n",
      "[Epoch 2/200] [Batch 586/637] [D loss: 0.135760] [G loss: 0.593176]\n",
      "[Epoch 2/200] [Batch 587/637] [D loss: 0.126201] [G loss: 0.543716]\n",
      "[Epoch 2/200] [Batch 588/637] [D loss: 0.126507] [G loss: 0.566941]\n",
      "[Epoch 2/200] [Batch 589/637] [D loss: 0.135408] [G loss: 0.682436]\n",
      "[Epoch 2/200] [Batch 590/637] [D loss: 0.117631] [G loss: 0.603310]\n",
      "[Epoch 2/200] [Batch 591/637] [D loss: 0.133968] [G loss: 0.527111]\n",
      "[Epoch 2/200] [Batch 592/637] [D loss: 0.130417] [G loss: 0.535929]\n",
      "[Epoch 2/200] [Batch 593/637] [D loss: 0.140839] [G loss: 0.537151]\n",
      "[Epoch 2/200] [Batch 594/637] [D loss: 0.127699] [G loss: 0.532885]\n",
      "[Epoch 2/200] [Batch 595/637] [D loss: 0.133590] [G loss: 0.568165]\n",
      "[Epoch 2/200] [Batch 596/637] [D loss: 0.155489] [G loss: 0.486039]\n",
      "[Epoch 2/200] [Batch 597/637] [D loss: 0.206966] [G loss: 0.661697]\n",
      "[Epoch 2/200] [Batch 598/637] [D loss: 0.207547] [G loss: 0.594271]\n",
      "[Epoch 2/200] [Batch 599/637] [D loss: 0.159204] [G loss: 0.557694]\n",
      "[Epoch 2/200] [Batch 600/637] [D loss: 0.172409] [G loss: 0.507984]\n",
      "[Epoch 2/200] [Batch 601/637] [D loss: 0.144961] [G loss: 0.503448]\n",
      "[Epoch 2/200] [Batch 602/637] [D loss: 0.203312] [G loss: 0.428154]\n",
      "[Epoch 2/200] [Batch 603/637] [D loss: 0.202357] [G loss: 0.629410]\n",
      "[Epoch 2/200] [Batch 604/637] [D loss: 0.161447] [G loss: 0.551745]\n",
      "[Epoch 2/200] [Batch 605/637] [D loss: 0.181622] [G loss: 0.432561]\n",
      "[Epoch 2/200] [Batch 606/637] [D loss: 0.135717] [G loss: 0.488082]\n",
      "[Epoch 2/200] [Batch 607/637] [D loss: 0.151509] [G loss: 0.507900]\n",
      "[Epoch 2/200] [Batch 608/637] [D loss: 0.145485] [G loss: 0.485658]\n",
      "[Epoch 2/200] [Batch 609/637] [D loss: 0.143623] [G loss: 0.481080]\n",
      "[Epoch 2/200] [Batch 610/637] [D loss: 0.125685] [G loss: 0.517385]\n",
      "[Epoch 2/200] [Batch 611/637] [D loss: 0.146042] [G loss: 0.539485]\n",
      "[Epoch 2/200] [Batch 612/637] [D loss: 0.143044] [G loss: 0.531903]\n",
      "[Epoch 2/200] [Batch 613/637] [D loss: 0.142961] [G loss: 0.518295]\n",
      "[Epoch 2/200] [Batch 614/637] [D loss: 0.124479] [G loss: 0.490968]\n",
      "[Epoch 2/200] [Batch 615/637] [D loss: 0.141873] [G loss: 0.595063]\n",
      "[Epoch 2/200] [Batch 616/637] [D loss: 0.130847] [G loss: 0.646458]\n",
      "[Epoch 2/200] [Batch 617/637] [D loss: 0.118296] [G loss: 0.580077]\n",
      "[Epoch 2/200] [Batch 618/637] [D loss: 0.128532] [G loss: 0.576416]\n",
      "[Epoch 2/200] [Batch 619/637] [D loss: 0.130495] [G loss: 0.626543]\n",
      "[Epoch 2/200] [Batch 620/637] [D loss: 0.134032] [G loss: 0.653771]\n",
      "[Epoch 2/200] [Batch 621/637] [D loss: 0.134600] [G loss: 0.621067]\n",
      "[Epoch 2/200] [Batch 622/637] [D loss: 0.136508] [G loss: 0.568378]\n",
      "[Epoch 2/200] [Batch 623/637] [D loss: 0.135999] [G loss: 0.598815]\n",
      "[Epoch 2/200] [Batch 624/637] [D loss: 0.156164] [G loss: 0.535516]\n",
      "[Epoch 2/200] [Batch 625/637] [D loss: 0.152956] [G loss: 0.544962]\n",
      "[Epoch 2/200] [Batch 626/637] [D loss: 0.163668] [G loss: 0.561990]\n",
      "[Epoch 2/200] [Batch 627/637] [D loss: 0.142445] [G loss: 0.469086]\n",
      "[Epoch 2/200] [Batch 628/637] [D loss: 0.166705] [G loss: 0.455112]\n",
      "[Epoch 2/200] [Batch 629/637] [D loss: 0.193667] [G loss: 0.510512]\n",
      "[Epoch 2/200] [Batch 630/637] [D loss: 0.187697] [G loss: 0.596724]\n",
      "[Epoch 2/200] [Batch 631/637] [D loss: 0.165341] [G loss: 0.591736]\n",
      "[Epoch 2/200] [Batch 632/637] [D loss: 0.190414] [G loss: 0.527282]\n",
      "[Epoch 2/200] [Batch 633/637] [D loss: 0.162975] [G loss: 0.519080]\n",
      "[Epoch 2/200] [Batch 634/637] [D loss: 0.158671] [G loss: 0.455952]\n",
      "[Epoch 2/200] [Batch 635/637] [D loss: 0.142862] [G loss: 0.462847]\n",
      "[Epoch 2/200] [Batch 636/637] [D loss: 0.157119] [G loss: 0.561184]\n",
      "[Epoch 3/200] [Batch 0/637] [D loss: 0.221076] [G loss: 0.549983]\n",
      "[Epoch 3/200] [Batch 1/637] [D loss: 0.170593] [G loss: 0.649475]\n",
      "[Epoch 3/200] [Batch 2/637] [D loss: 0.174192] [G loss: 0.614388]\n",
      "[Epoch 3/200] [Batch 3/637] [D loss: 0.146407] [G loss: 0.526527]\n",
      "[Epoch 3/200] [Batch 4/637] [D loss: 0.158369] [G loss: 0.496411]\n",
      "[Epoch 3/200] [Batch 5/637] [D loss: 0.151570] [G loss: 0.458989]\n",
      "[Epoch 3/200] [Batch 6/637] [D loss: 0.145960] [G loss: 0.547120]\n",
      "[Epoch 3/200] [Batch 7/637] [D loss: 0.139000] [G loss: 0.507408]\n",
      "[Epoch 3/200] [Batch 8/637] [D loss: 0.097145] [G loss: 0.560226]\n",
      "[Epoch 3/200] [Batch 9/637] [D loss: 0.130797] [G loss: 0.561408]\n",
      "[Epoch 3/200] [Batch 10/637] [D loss: 0.145759] [G loss: 0.535217]\n",
      "[Epoch 3/200] [Batch 11/637] [D loss: 0.123608] [G loss: 0.558416]\n",
      "[Epoch 3/200] [Batch 12/637] [D loss: 0.131744] [G loss: 0.584626]\n",
      "[Epoch 3/200] [Batch 13/637] [D loss: 0.131264] [G loss: 0.578533]\n",
      "[Epoch 3/200] [Batch 14/637] [D loss: 0.131652] [G loss: 0.482551]\n",
      "[Epoch 3/200] [Batch 15/637] [D loss: 0.137009] [G loss: 0.686367]\n",
      "[Epoch 3/200] [Batch 16/637] [D loss: 0.141117] [G loss: 0.599661]\n",
      "[Epoch 3/200] [Batch 17/637] [D loss: 0.145758] [G loss: 0.462238]\n",
      "[Epoch 3/200] [Batch 18/637] [D loss: 0.145872] [G loss: 0.559160]\n",
      "[Epoch 3/200] [Batch 19/637] [D loss: 0.145174] [G loss: 0.497085]\n",
      "[Epoch 3/200] [Batch 20/637] [D loss: 0.157463] [G loss: 0.608864]\n",
      "[Epoch 3/200] [Batch 21/637] [D loss: 0.144398] [G loss: 0.502282]\n",
      "[Epoch 3/200] [Batch 22/637] [D loss: 0.147872] [G loss: 0.511157]\n",
      "[Epoch 3/200] [Batch 23/637] [D loss: 0.147122] [G loss: 0.461923]\n",
      "[Epoch 3/200] [Batch 24/637] [D loss: 0.127040] [G loss: 0.532815]\n",
      "[Epoch 3/200] [Batch 25/637] [D loss: 0.122492] [G loss: 0.607943]\n",
      "[Epoch 3/200] [Batch 26/637] [D loss: 0.143303] [G loss: 0.643501]\n",
      "[Epoch 3/200] [Batch 27/637] [D loss: 0.155322] [G loss: 0.537345]\n",
      "[Epoch 3/200] [Batch 28/637] [D loss: 0.123692] [G loss: 0.644877]\n",
      "[Epoch 3/200] [Batch 29/637] [D loss: 0.143382] [G loss: 0.610926]\n",
      "[Epoch 3/200] [Batch 30/637] [D loss: 0.138644] [G loss: 0.554230]\n",
      "[Epoch 3/200] [Batch 31/637] [D loss: 0.150285] [G loss: 0.519893]\n",
      "[Epoch 3/200] [Batch 32/637] [D loss: 0.178643] [G loss: 0.631620]\n",
      "[Epoch 3/200] [Batch 33/637] [D loss: 0.175069] [G loss: 0.545475]\n",
      "[Epoch 3/200] [Batch 34/637] [D loss: 0.143344] [G loss: 0.724716]\n",
      "[Epoch 3/200] [Batch 35/637] [D loss: 0.128228] [G loss: 0.584255]\n",
      "[Epoch 3/200] [Batch 36/637] [D loss: 0.141642] [G loss: 0.484319]\n",
      "[Epoch 3/200] [Batch 37/637] [D loss: 0.151245] [G loss: 0.586610]\n",
      "[Epoch 3/200] [Batch 38/637] [D loss: 0.138810] [G loss: 0.586845]\n",
      "[Epoch 3/200] [Batch 39/637] [D loss: 0.185814] [G loss: 0.652196]\n",
      "[Epoch 3/200] [Batch 40/637] [D loss: 0.196027] [G loss: 0.567028]\n",
      "[Epoch 3/200] [Batch 41/637] [D loss: 0.161407] [G loss: 0.567858]\n",
      "[Epoch 3/200] [Batch 42/637] [D loss: 0.144550] [G loss: 0.570803]\n",
      "[Epoch 3/200] [Batch 43/637] [D loss: 0.144594] [G loss: 0.562083]\n",
      "[Epoch 3/200] [Batch 44/637] [D loss: 0.133980] [G loss: 0.546287]\n",
      "[Epoch 3/200] [Batch 45/637] [D loss: 0.127485] [G loss: 0.536336]\n",
      "[Epoch 3/200] [Batch 46/637] [D loss: 0.159071] [G loss: 0.499454]\n",
      "[Epoch 3/200] [Batch 47/637] [D loss: 0.259094] [G loss: 0.836131]\n",
      "[Epoch 3/200] [Batch 48/637] [D loss: 0.171307] [G loss: 0.651338]\n",
      "[Epoch 3/200] [Batch 49/637] [D loss: 0.175088] [G loss: 0.498272]\n",
      "[Epoch 3/200] [Batch 50/637] [D loss: 0.156466] [G loss: 0.491319]\n",
      "[Epoch 3/200] [Batch 51/637] [D loss: 0.140483] [G loss: 0.493871]\n",
      "[Epoch 3/200] [Batch 52/637] [D loss: 0.143957] [G loss: 0.525415]\n",
      "[Epoch 3/200] [Batch 53/637] [D loss: 0.128483] [G loss: 0.615062]\n",
      "[Epoch 3/200] [Batch 54/637] [D loss: 0.122662] [G loss: 0.573807]\n",
      "[Epoch 3/200] [Batch 55/637] [D loss: 0.139799] [G loss: 0.546965]\n",
      "[Epoch 3/200] [Batch 56/637] [D loss: 0.186912] [G loss: 0.635834]\n",
      "[Epoch 3/200] [Batch 57/637] [D loss: 0.139471] [G loss: 0.668749]\n",
      "[Epoch 3/200] [Batch 58/637] [D loss: 0.152484] [G loss: 0.598670]\n",
      "[Epoch 3/200] [Batch 59/637] [D loss: 0.161921] [G loss: 0.594369]\n",
      "[Epoch 3/200] [Batch 60/637] [D loss: 0.156430] [G loss: 0.560849]\n",
      "[Epoch 3/200] [Batch 61/637] [D loss: 0.142922] [G loss: 0.525013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 62/637] [D loss: 0.159916] [G loss: 0.472336]\n",
      "[Epoch 3/200] [Batch 63/637] [D loss: 0.156058] [G loss: 0.594304]\n",
      "[Epoch 3/200] [Batch 64/637] [D loss: 0.140183] [G loss: 0.478262]\n",
      "[Epoch 3/200] [Batch 65/637] [D loss: 0.125724] [G loss: 0.548332]\n",
      "[Epoch 3/200] [Batch 66/637] [D loss: 0.145571] [G loss: 0.536625]\n",
      "[Epoch 3/200] [Batch 67/637] [D loss: 0.144375] [G loss: 0.523127]\n",
      "[Epoch 3/200] [Batch 68/637] [D loss: 0.137872] [G loss: 0.581117]\n",
      "[Epoch 3/200] [Batch 69/637] [D loss: 0.129054] [G loss: 0.498525]\n",
      "[Epoch 3/200] [Batch 70/637] [D loss: 0.167137] [G loss: 0.473944]\n",
      "[Epoch 3/200] [Batch 71/637] [D loss: 0.212668] [G loss: 0.600965]\n",
      "[Epoch 3/200] [Batch 72/637] [D loss: 0.149594] [G loss: 0.585494]\n",
      "[Epoch 3/200] [Batch 73/637] [D loss: 0.178631] [G loss: 0.559313]\n",
      "[Epoch 3/200] [Batch 74/637] [D loss: 0.134904] [G loss: 0.525993]\n",
      "[Epoch 3/200] [Batch 75/637] [D loss: 0.152386] [G loss: 0.553364]\n",
      "[Epoch 3/200] [Batch 76/637] [D loss: 0.175812] [G loss: 0.519573]\n",
      "[Epoch 3/200] [Batch 77/637] [D loss: 0.134410] [G loss: 0.514078]\n",
      "[Epoch 3/200] [Batch 78/637] [D loss: 0.148172] [G loss: 0.582606]\n",
      "[Epoch 3/200] [Batch 79/637] [D loss: 0.140571] [G loss: 0.575327]\n",
      "[Epoch 3/200] [Batch 80/637] [D loss: 0.134693] [G loss: 0.621782]\n",
      "[Epoch 3/200] [Batch 81/637] [D loss: 0.148822] [G loss: 0.496924]\n",
      "[Epoch 3/200] [Batch 82/637] [D loss: 0.157147] [G loss: 0.656244]\n",
      "[Epoch 3/200] [Batch 83/637] [D loss: 0.161247] [G loss: 0.568336]\n",
      "[Epoch 3/200] [Batch 84/637] [D loss: 0.141367] [G loss: 0.610733]\n",
      "[Epoch 3/200] [Batch 85/637] [D loss: 0.157431] [G loss: 0.561500]\n",
      "[Epoch 3/200] [Batch 86/637] [D loss: 0.134979] [G loss: 0.547284]\n",
      "[Epoch 3/200] [Batch 87/637] [D loss: 0.135688] [G loss: 0.622251]\n",
      "[Epoch 3/200] [Batch 88/637] [D loss: 0.141859] [G loss: 0.553155]\n",
      "[Epoch 3/200] [Batch 89/637] [D loss: 0.148909] [G loss: 0.632316]\n",
      "[Epoch 3/200] [Batch 90/637] [D loss: 0.162540] [G loss: 0.543694]\n",
      "[Epoch 3/200] [Batch 91/637] [D loss: 0.165443] [G loss: 0.689082]\n",
      "[Epoch 3/200] [Batch 92/637] [D loss: 0.171689] [G loss: 0.558623]\n",
      "[Epoch 3/200] [Batch 93/637] [D loss: 0.161684] [G loss: 0.551249]\n",
      "[Epoch 3/200] [Batch 94/637] [D loss: 0.168732] [G loss: 0.479092]\n",
      "[Epoch 3/200] [Batch 95/637] [D loss: 0.141646] [G loss: 0.576121]\n",
      "[Epoch 3/200] [Batch 96/637] [D loss: 0.158927] [G loss: 0.575006]\n",
      "[Epoch 3/200] [Batch 97/637] [D loss: 0.143432] [G loss: 0.511628]\n",
      "[Epoch 3/200] [Batch 98/637] [D loss: 0.146329] [G loss: 0.465090]\n",
      "[Epoch 3/200] [Batch 99/637] [D loss: 0.128172] [G loss: 0.570046]\n",
      "[Epoch 3/200] [Batch 100/637] [D loss: 0.158788] [G loss: 0.540802]\n",
      "[Epoch 3/200] [Batch 101/637] [D loss: 0.134184] [G loss: 0.630706]\n",
      "[Epoch 3/200] [Batch 102/637] [D loss: 0.126539] [G loss: 0.519805]\n",
      "[Epoch 3/200] [Batch 103/637] [D loss: 0.162671] [G loss: 0.500411]\n",
      "[Epoch 3/200] [Batch 104/637] [D loss: 0.208679] [G loss: 0.773310]\n",
      "[Epoch 3/200] [Batch 105/637] [D loss: 0.181290] [G loss: 0.516747]\n",
      "[Epoch 3/200] [Batch 106/637] [D loss: 0.142599] [G loss: 0.566755]\n",
      "[Epoch 3/200] [Batch 107/637] [D loss: 0.149824] [G loss: 0.620856]\n",
      "[Epoch 3/200] [Batch 108/637] [D loss: 0.128935] [G loss: 0.539114]\n",
      "[Epoch 3/200] [Batch 109/637] [D loss: 0.126202] [G loss: 0.526476]\n",
      "[Epoch 3/200] [Batch 110/637] [D loss: 0.102082] [G loss: 0.581986]\n",
      "[Epoch 3/200] [Batch 111/637] [D loss: 0.109885] [G loss: 0.653798]\n",
      "[Epoch 3/200] [Batch 112/637] [D loss: 0.123366] [G loss: 0.582614]\n",
      "[Epoch 3/200] [Batch 113/637] [D loss: 0.115825] [G loss: 0.542145]\n",
      "[Epoch 3/200] [Batch 114/637] [D loss: 0.099791] [G loss: 0.615742]\n",
      "[Epoch 3/200] [Batch 115/637] [D loss: 0.103782] [G loss: 0.650532]\n",
      "[Epoch 3/200] [Batch 116/637] [D loss: 0.133893] [G loss: 0.651450]\n",
      "[Epoch 3/200] [Batch 117/637] [D loss: 0.130198] [G loss: 0.586536]\n",
      "[Epoch 3/200] [Batch 118/637] [D loss: 0.126057] [G loss: 0.548869]\n",
      "[Epoch 3/200] [Batch 119/637] [D loss: 0.134738] [G loss: 0.540226]\n",
      "[Epoch 3/200] [Batch 120/637] [D loss: 0.137304] [G loss: 0.708135]\n",
      "[Epoch 3/200] [Batch 121/637] [D loss: 0.198463] [G loss: 0.496621]\n",
      "[Epoch 3/200] [Batch 122/637] [D loss: 0.259122] [G loss: 0.840221]\n",
      "[Epoch 3/200] [Batch 123/637] [D loss: 0.152887] [G loss: 0.552432]\n",
      "[Epoch 3/200] [Batch 124/637] [D loss: 0.163497] [G loss: 0.453030]\n",
      "[Epoch 3/200] [Batch 125/637] [D loss: 0.137816] [G loss: 0.500850]\n",
      "[Epoch 3/200] [Batch 126/637] [D loss: 0.135816] [G loss: 0.574966]\n",
      "[Epoch 3/200] [Batch 127/637] [D loss: 0.149080] [G loss: 0.555950]\n",
      "[Epoch 3/200] [Batch 128/637] [D loss: 0.133034] [G loss: 0.521191]\n",
      "[Epoch 3/200] [Batch 129/637] [D loss: 0.149629] [G loss: 0.509854]\n",
      "[Epoch 3/200] [Batch 130/637] [D loss: 0.136276] [G loss: 0.546157]\n",
      "[Epoch 3/200] [Batch 131/637] [D loss: 0.135217] [G loss: 0.546302]\n",
      "[Epoch 3/200] [Batch 132/637] [D loss: 0.123037] [G loss: 0.575252]\n",
      "[Epoch 3/200] [Batch 133/637] [D loss: 0.123077] [G loss: 0.585436]\n",
      "[Epoch 3/200] [Batch 134/637] [D loss: 0.130493] [G loss: 0.547213]\n",
      "[Epoch 3/200] [Batch 135/637] [D loss: 0.134437] [G loss: 0.538767]\n",
      "[Epoch 3/200] [Batch 136/637] [D loss: 0.157336] [G loss: 0.643696]\n",
      "[Epoch 3/200] [Batch 137/637] [D loss: 0.154802] [G loss: 0.559902]\n",
      "[Epoch 3/200] [Batch 138/637] [D loss: 0.145641] [G loss: 0.633962]\n",
      "[Epoch 3/200] [Batch 139/637] [D loss: 0.125230] [G loss: 0.578408]\n",
      "[Epoch 3/200] [Batch 140/637] [D loss: 0.167680] [G loss: 0.503128]\n",
      "[Epoch 3/200] [Batch 141/637] [D loss: 0.185305] [G loss: 0.588554]\n",
      "[Epoch 3/200] [Batch 142/637] [D loss: 0.147081] [G loss: 0.657782]\n",
      "[Epoch 3/200] [Batch 143/637] [D loss: 0.152667] [G loss: 0.581543]\n",
      "[Epoch 3/200] [Batch 144/637] [D loss: 0.143781] [G loss: 0.534259]\n",
      "[Epoch 3/200] [Batch 145/637] [D loss: 0.157985] [G loss: 0.514832]\n",
      "[Epoch 3/200] [Batch 146/637] [D loss: 0.152436] [G loss: 0.549462]\n",
      "[Epoch 3/200] [Batch 147/637] [D loss: 0.142282] [G loss: 0.521248]\n",
      "[Epoch 3/200] [Batch 148/637] [D loss: 0.146086] [G loss: 0.533887]\n",
      "[Epoch 3/200] [Batch 149/637] [D loss: 0.180237] [G loss: 0.471756]\n",
      "[Epoch 3/200] [Batch 150/637] [D loss: 0.178970] [G loss: 0.510824]\n",
      "[Epoch 3/200] [Batch 151/637] [D loss: 0.144532] [G loss: 0.596640]\n",
      "[Epoch 3/200] [Batch 152/637] [D loss: 0.153099] [G loss: 0.565558]\n",
      "[Epoch 3/200] [Batch 153/637] [D loss: 0.151195] [G loss: 0.533346]\n",
      "[Epoch 3/200] [Batch 154/637] [D loss: 0.146478] [G loss: 0.513802]\n",
      "[Epoch 3/200] [Batch 155/637] [D loss: 0.143234] [G loss: 0.573524]\n",
      "[Epoch 3/200] [Batch 156/637] [D loss: 0.162859] [G loss: 0.569037]\n",
      "[Epoch 3/200] [Batch 157/637] [D loss: 0.186927] [G loss: 0.841205]\n",
      "[Epoch 3/200] [Batch 158/637] [D loss: 0.158256] [G loss: 0.620986]\n",
      "[Epoch 3/200] [Batch 159/637] [D loss: 0.178970] [G loss: 0.491040]\n",
      "[Epoch 3/200] [Batch 160/637] [D loss: 0.150823] [G loss: 0.479771]\n",
      "[Epoch 3/200] [Batch 161/637] [D loss: 0.124175] [G loss: 0.548884]\n",
      "[Epoch 3/200] [Batch 162/637] [D loss: 0.124361] [G loss: 0.551699]\n",
      "[Epoch 3/200] [Batch 163/637] [D loss: 0.155720] [G loss: 0.596574]\n",
      "[Epoch 3/200] [Batch 164/637] [D loss: 0.137952] [G loss: 0.607778]\n",
      "[Epoch 3/200] [Batch 165/637] [D loss: 0.204588] [G loss: 0.491692]\n",
      "[Epoch 3/200] [Batch 166/637] [D loss: 0.276414] [G loss: 0.739625]\n",
      "[Epoch 3/200] [Batch 167/637] [D loss: 0.158736] [G loss: 0.667162]\n",
      "[Epoch 3/200] [Batch 168/637] [D loss: 0.145009] [G loss: 0.592929]\n",
      "[Epoch 3/200] [Batch 169/637] [D loss: 0.164753] [G loss: 0.466252]\n",
      "[Epoch 3/200] [Batch 170/637] [D loss: 0.147824] [G loss: 0.509178]\n",
      "[Epoch 3/200] [Batch 171/637] [D loss: 0.161555] [G loss: 0.494609]\n",
      "[Epoch 3/200] [Batch 172/637] [D loss: 0.150786] [G loss: 0.465355]\n",
      "[Epoch 3/200] [Batch 173/637] [D loss: 0.144106] [G loss: 0.507984]\n",
      "[Epoch 3/200] [Batch 174/637] [D loss: 0.135894] [G loss: 0.545010]\n",
      "[Epoch 3/200] [Batch 175/637] [D loss: 0.146839] [G loss: 0.540409]\n",
      "[Epoch 3/200] [Batch 176/637] [D loss: 0.148692] [G loss: 0.510948]\n",
      "[Epoch 3/200] [Batch 177/637] [D loss: 0.117348] [G loss: 0.514596]\n",
      "[Epoch 3/200] [Batch 178/637] [D loss: 0.144808] [G loss: 0.474429]\n",
      "[Epoch 3/200] [Batch 179/637] [D loss: 0.139687] [G loss: 0.598728]\n",
      "[Epoch 3/200] [Batch 180/637] [D loss: 0.146270] [G loss: 0.555903]\n",
      "[Epoch 3/200] [Batch 181/637] [D loss: 0.141896] [G loss: 0.539508]\n",
      "[Epoch 3/200] [Batch 182/637] [D loss: 0.156507] [G loss: 0.551133]\n",
      "[Epoch 3/200] [Batch 183/637] [D loss: 0.145072] [G loss: 0.539832]\n",
      "[Epoch 3/200] [Batch 184/637] [D loss: 0.172786] [G loss: 0.600115]\n",
      "[Epoch 3/200] [Batch 185/637] [D loss: 0.174054] [G loss: 0.451333]\n",
      "[Epoch 3/200] [Batch 186/637] [D loss: 0.152666] [G loss: 0.551426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 187/637] [D loss: 0.153125] [G loss: 0.576521]\n",
      "[Epoch 3/200] [Batch 188/637] [D loss: 0.145193] [G loss: 0.583818]\n",
      "[Epoch 3/200] [Batch 189/637] [D loss: 0.127704] [G loss: 0.555296]\n",
      "[Epoch 3/200] [Batch 190/637] [D loss: 0.140998] [G loss: 0.538390]\n",
      "[Epoch 3/200] [Batch 191/637] [D loss: 0.174485] [G loss: 0.571177]\n",
      "[Epoch 3/200] [Batch 192/637] [D loss: 0.142627] [G loss: 0.584049]\n",
      "[Epoch 3/200] [Batch 193/637] [D loss: 0.141373] [G loss: 0.637896]\n",
      "[Epoch 3/200] [Batch 194/637] [D loss: 0.145784] [G loss: 0.556782]\n",
      "[Epoch 3/200] [Batch 195/637] [D loss: 0.186025] [G loss: 0.485281]\n",
      "[Epoch 3/200] [Batch 196/637] [D loss: 0.263329] [G loss: 0.675555]\n",
      "[Epoch 3/200] [Batch 197/637] [D loss: 0.180571] [G loss: 0.616352]\n",
      "[Epoch 3/200] [Batch 198/637] [D loss: 0.183171] [G loss: 0.558339]\n",
      "[Epoch 3/200] [Batch 199/637] [D loss: 0.126550] [G loss: 0.487978]\n",
      "[Epoch 3/200] [Batch 200/637] [D loss: 0.151031] [G loss: 0.411526]\n",
      "[Epoch 3/200] [Batch 201/637] [D loss: 0.143117] [G loss: 0.447120]\n",
      "[Epoch 3/200] [Batch 202/637] [D loss: 0.137470] [G loss: 0.502450]\n",
      "[Epoch 3/200] [Batch 203/637] [D loss: 0.132427] [G loss: 0.579302]\n",
      "[Epoch 3/200] [Batch 204/637] [D loss: 0.140043] [G loss: 0.568402]\n",
      "[Epoch 3/200] [Batch 205/637] [D loss: 0.144194] [G loss: 0.538828]\n",
      "[Epoch 3/200] [Batch 206/637] [D loss: 0.143702] [G loss: 0.494655]\n",
      "[Epoch 3/200] [Batch 207/637] [D loss: 0.142579] [G loss: 0.533189]\n",
      "[Epoch 3/200] [Batch 208/637] [D loss: 0.141108] [G loss: 0.569105]\n",
      "[Epoch 3/200] [Batch 209/637] [D loss: 0.167343] [G loss: 0.543497]\n",
      "[Epoch 3/200] [Batch 210/637] [D loss: 0.157099] [G loss: 0.505499]\n",
      "[Epoch 3/200] [Batch 211/637] [D loss: 0.158671] [G loss: 0.468344]\n",
      "[Epoch 3/200] [Batch 212/637] [D loss: 0.135246] [G loss: 0.555479]\n",
      "[Epoch 3/200] [Batch 213/637] [D loss: 0.164473] [G loss: 0.564325]\n",
      "[Epoch 3/200] [Batch 214/637] [D loss: 0.173356] [G loss: 0.478863]\n",
      "[Epoch 3/200] [Batch 215/637] [D loss: 0.138418] [G loss: 0.522951]\n",
      "[Epoch 3/200] [Batch 216/637] [D loss: 0.138761] [G loss: 0.500420]\n",
      "[Epoch 3/200] [Batch 217/637] [D loss: 0.156722] [G loss: 0.448724]\n",
      "[Epoch 3/200] [Batch 218/637] [D loss: 0.173968] [G loss: 0.510141]\n",
      "[Epoch 3/200] [Batch 219/637] [D loss: 0.147040] [G loss: 0.553671]\n",
      "[Epoch 3/200] [Batch 220/637] [D loss: 0.126356] [G loss: 0.539000]\n",
      "[Epoch 3/200] [Batch 221/637] [D loss: 0.151613] [G loss: 0.485605]\n",
      "[Epoch 3/200] [Batch 222/637] [D loss: 0.126624] [G loss: 0.577623]\n",
      "[Epoch 3/200] [Batch 223/637] [D loss: 0.140964] [G loss: 0.547324]\n",
      "[Epoch 3/200] [Batch 224/637] [D loss: 0.161866] [G loss: 0.492246]\n",
      "[Epoch 3/200] [Batch 225/637] [D loss: 0.165352] [G loss: 0.588764]\n",
      "[Epoch 3/200] [Batch 226/637] [D loss: 0.138888] [G loss: 0.534659]\n",
      "[Epoch 3/200] [Batch 227/637] [D loss: 0.133667] [G loss: 0.582038]\n",
      "[Epoch 3/200] [Batch 228/637] [D loss: 0.126181] [G loss: 0.533810]\n",
      "[Epoch 3/200] [Batch 229/637] [D loss: 0.125240] [G loss: 0.505088]\n",
      "[Epoch 3/200] [Batch 230/637] [D loss: 0.142802] [G loss: 0.508356]\n",
      "[Epoch 3/200] [Batch 231/637] [D loss: 0.166598] [G loss: 0.612033]\n",
      "[Epoch 3/200] [Batch 232/637] [D loss: 0.158327] [G loss: 0.589038]\n",
      "[Epoch 3/200] [Batch 233/637] [D loss: 0.145842] [G loss: 0.428025]\n",
      "[Epoch 3/200] [Batch 234/637] [D loss: 0.153770] [G loss: 0.474063]\n",
      "[Epoch 3/200] [Batch 235/637] [D loss: 0.165124] [G loss: 0.481521]\n",
      "[Epoch 3/200] [Batch 236/637] [D loss: 0.146447] [G loss: 0.533057]\n",
      "[Epoch 3/200] [Batch 237/637] [D loss: 0.171225] [G loss: 0.499236]\n",
      "[Epoch 3/200] [Batch 238/637] [D loss: 0.150989] [G loss: 0.462359]\n",
      "[Epoch 3/200] [Batch 239/637] [D loss: 0.157785] [G loss: 0.466910]\n",
      "[Epoch 3/200] [Batch 240/637] [D loss: 0.178832] [G loss: 0.449098]\n",
      "[Epoch 3/200] [Batch 241/637] [D loss: 0.170353] [G loss: 0.451045]\n",
      "[Epoch 3/200] [Batch 242/637] [D loss: 0.139631] [G loss: 0.498366]\n",
      "[Epoch 3/200] [Batch 243/637] [D loss: 0.140810] [G loss: 0.497889]\n",
      "[Epoch 3/200] [Batch 244/637] [D loss: 0.153572] [G loss: 0.417858]\n",
      "[Epoch 3/200] [Batch 245/637] [D loss: 0.139110] [G loss: 0.552431]\n",
      "[Epoch 3/200] [Batch 246/637] [D loss: 0.151752] [G loss: 0.581320]\n",
      "[Epoch 3/200] [Batch 247/637] [D loss: 0.170430] [G loss: 0.498418]\n",
      "[Epoch 3/200] [Batch 248/637] [D loss: 0.146868] [G loss: 0.512241]\n",
      "[Epoch 3/200] [Batch 249/637] [D loss: 0.162883] [G loss: 0.468449]\n",
      "[Epoch 3/200] [Batch 250/637] [D loss: 0.150459] [G loss: 0.574896]\n",
      "[Epoch 3/200] [Batch 251/637] [D loss: 0.137776] [G loss: 0.530968]\n",
      "[Epoch 3/200] [Batch 252/637] [D loss: 0.160112] [G loss: 0.473588]\n",
      "[Epoch 3/200] [Batch 253/637] [D loss: 0.201875] [G loss: 0.561320]\n",
      "[Epoch 3/200] [Batch 254/637] [D loss: 0.158396] [G loss: 0.424533]\n",
      "[Epoch 3/200] [Batch 255/637] [D loss: 0.153137] [G loss: 0.460809]\n",
      "[Epoch 3/200] [Batch 256/637] [D loss: 0.153424] [G loss: 0.532968]\n",
      "[Epoch 3/200] [Batch 257/637] [D loss: 0.154184] [G loss: 0.507069]\n",
      "[Epoch 3/200] [Batch 258/637] [D loss: 0.146123] [G loss: 0.514669]\n",
      "[Epoch 3/200] [Batch 259/637] [D loss: 0.149375] [G loss: 0.517231]\n",
      "[Epoch 3/200] [Batch 260/637] [D loss: 0.155303] [G loss: 0.459038]\n",
      "[Epoch 3/200] [Batch 261/637] [D loss: 0.149127] [G loss: 0.508753]\n",
      "[Epoch 3/200] [Batch 262/637] [D loss: 0.142061] [G loss: 0.514825]\n",
      "[Epoch 3/200] [Batch 263/637] [D loss: 0.163448] [G loss: 0.445715]\n",
      "[Epoch 3/200] [Batch 264/637] [D loss: 0.186585] [G loss: 0.463773]\n",
      "[Epoch 3/200] [Batch 265/637] [D loss: 0.196737] [G loss: 0.579999]\n",
      "[Epoch 3/200] [Batch 266/637] [D loss: 0.158661] [G loss: 0.644523]\n",
      "[Epoch 3/200] [Batch 267/637] [D loss: 0.162320] [G loss: 0.511273]\n",
      "[Epoch 3/200] [Batch 268/637] [D loss: 0.155151] [G loss: 0.518634]\n",
      "[Epoch 3/200] [Batch 269/637] [D loss: 0.142247] [G loss: 0.467846]\n",
      "[Epoch 3/200] [Batch 270/637] [D loss: 0.136037] [G loss: 0.514025]\n",
      "[Epoch 3/200] [Batch 271/637] [D loss: 0.135797] [G loss: 0.608277]\n",
      "[Epoch 3/200] [Batch 272/637] [D loss: 0.147957] [G loss: 0.488909]\n",
      "[Epoch 3/200] [Batch 273/637] [D loss: 0.150423] [G loss: 0.560001]\n",
      "[Epoch 3/200] [Batch 274/637] [D loss: 0.153586] [G loss: 0.565219]\n",
      "[Epoch 3/200] [Batch 275/637] [D loss: 0.129498] [G loss: 0.608213]\n",
      "[Epoch 3/200] [Batch 276/637] [D loss: 0.142690] [G loss: 0.509659]\n",
      "[Epoch 3/200] [Batch 277/637] [D loss: 0.143169] [G loss: 0.555295]\n",
      "[Epoch 3/200] [Batch 278/637] [D loss: 0.163166] [G loss: 0.514309]\n",
      "[Epoch 3/200] [Batch 279/637] [D loss: 0.168640] [G loss: 0.615092]\n",
      "[Epoch 3/200] [Batch 280/637] [D loss: 0.172695] [G loss: 0.581126]\n",
      "[Epoch 3/200] [Batch 281/637] [D loss: 0.154024] [G loss: 0.488088]\n",
      "[Epoch 3/200] [Batch 282/637] [D loss: 0.157587] [G loss: 0.487164]\n",
      "[Epoch 3/200] [Batch 283/637] [D loss: 0.154421] [G loss: 0.454446]\n",
      "[Epoch 3/200] [Batch 284/637] [D loss: 0.154579] [G loss: 0.511649]\n",
      "[Epoch 3/200] [Batch 285/637] [D loss: 0.156069] [G loss: 0.535836]\n",
      "[Epoch 3/200] [Batch 286/637] [D loss: 0.138217] [G loss: 0.500676]\n",
      "[Epoch 3/200] [Batch 287/637] [D loss: 0.148685] [G loss: 0.470054]\n",
      "[Epoch 3/200] [Batch 288/637] [D loss: 0.143816] [G loss: 0.555643]\n",
      "[Epoch 3/200] [Batch 289/637] [D loss: 0.124356] [G loss: 0.558668]\n",
      "[Epoch 3/200] [Batch 290/637] [D loss: 0.190406] [G loss: 0.473272]\n",
      "[Epoch 3/200] [Batch 291/637] [D loss: 0.354587] [G loss: 0.721027]\n",
      "[Epoch 3/200] [Batch 292/637] [D loss: 0.227490] [G loss: 0.699866]\n",
      "[Epoch 3/200] [Batch 293/637] [D loss: 0.201353] [G loss: 0.531917]\n",
      "[Epoch 3/200] [Batch 294/637] [D loss: 0.154381] [G loss: 0.532204]\n",
      "[Epoch 3/200] [Batch 295/637] [D loss: 0.137753] [G loss: 0.457842]\n",
      "[Epoch 3/200] [Batch 296/637] [D loss: 0.156565] [G loss: 0.443348]\n",
      "[Epoch 3/200] [Batch 297/637] [D loss: 0.136501] [G loss: 0.472805]\n",
      "[Epoch 3/200] [Batch 298/637] [D loss: 0.123917] [G loss: 0.524688]\n",
      "[Epoch 3/200] [Batch 299/637] [D loss: 0.133685] [G loss: 0.486072]\n",
      "[Epoch 3/200] [Batch 300/637] [D loss: 0.140823] [G loss: 0.497915]\n",
      "[Epoch 3/200] [Batch 301/637] [D loss: 0.124187] [G loss: 0.541926]\n",
      "[Epoch 3/200] [Batch 302/637] [D loss: 0.137598] [G loss: 0.597563]\n",
      "[Epoch 3/200] [Batch 303/637] [D loss: 0.128101] [G loss: 0.559499]\n",
      "[Epoch 3/200] [Batch 304/637] [D loss: 0.148672] [G loss: 0.492208]\n",
      "[Epoch 3/200] [Batch 305/637] [D loss: 0.141080] [G loss: 0.519472]\n",
      "[Epoch 3/200] [Batch 306/637] [D loss: 0.133010] [G loss: 0.565895]\n",
      "[Epoch 3/200] [Batch 307/637] [D loss: 0.171959] [G loss: 0.492299]\n",
      "[Epoch 3/200] [Batch 308/637] [D loss: 0.179672] [G loss: 0.638410]\n",
      "[Epoch 3/200] [Batch 309/637] [D loss: 0.135984] [G loss: 0.512791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 310/637] [D loss: 0.146953] [G loss: 0.584983]\n",
      "[Epoch 3/200] [Batch 311/637] [D loss: 0.140612] [G loss: 0.531259]\n",
      "[Epoch 3/200] [Batch 312/637] [D loss: 0.146812] [G loss: 0.503272]\n",
      "[Epoch 3/200] [Batch 313/637] [D loss: 0.216820] [G loss: 0.562128]\n",
      "[Epoch 3/200] [Batch 314/637] [D loss: 0.172056] [G loss: 0.507540]\n",
      "[Epoch 3/200] [Batch 315/637] [D loss: 0.168405] [G loss: 0.521527]\n",
      "[Epoch 3/200] [Batch 316/637] [D loss: 0.164719] [G loss: 0.513277]\n",
      "[Epoch 3/200] [Batch 317/637] [D loss: 0.146582] [G loss: 0.514178]\n",
      "[Epoch 3/200] [Batch 318/637] [D loss: 0.138011] [G loss: 0.544700]\n",
      "[Epoch 3/200] [Batch 319/637] [D loss: 0.149746] [G loss: 0.520007]\n",
      "[Epoch 3/200] [Batch 320/637] [D loss: 0.137187] [G loss: 0.638021]\n",
      "[Epoch 3/200] [Batch 321/637] [D loss: 0.142365] [G loss: 0.572921]\n",
      "[Epoch 3/200] [Batch 322/637] [D loss: 0.150636] [G loss: 0.585797]\n",
      "[Epoch 3/200] [Batch 323/637] [D loss: 0.113440] [G loss: 0.584479]\n",
      "[Epoch 3/200] [Batch 324/637] [D loss: 0.133221] [G loss: 0.559268]\n",
      "[Epoch 3/200] [Batch 325/637] [D loss: 0.123165] [G loss: 0.493742]\n",
      "[Epoch 3/200] [Batch 326/637] [D loss: 0.172977] [G loss: 0.575835]\n",
      "[Epoch 3/200] [Batch 327/637] [D loss: 0.155957] [G loss: 0.638976]\n",
      "[Epoch 3/200] [Batch 328/637] [D loss: 0.119877] [G loss: 0.613940]\n",
      "[Epoch 3/200] [Batch 329/637] [D loss: 0.134076] [G loss: 0.575582]\n",
      "[Epoch 3/200] [Batch 330/637] [D loss: 0.121468] [G loss: 0.554404]\n",
      "[Epoch 3/200] [Batch 331/637] [D loss: 0.129570] [G loss: 0.599364]\n",
      "[Epoch 3/200] [Batch 332/637] [D loss: 0.132933] [G loss: 0.584775]\n",
      "[Epoch 3/200] [Batch 333/637] [D loss: 0.130736] [G loss: 0.551825]\n",
      "[Epoch 3/200] [Batch 334/637] [D loss: 0.140791] [G loss: 0.487616]\n",
      "[Epoch 3/200] [Batch 335/637] [D loss: 0.232989] [G loss: 0.727126]\n",
      "[Epoch 3/200] [Batch 336/637] [D loss: 0.151253] [G loss: 0.566914]\n",
      "[Epoch 3/200] [Batch 337/637] [D loss: 0.156239] [G loss: 0.590208]\n",
      "[Epoch 3/200] [Batch 338/637] [D loss: 0.137044] [G loss: 0.533629]\n",
      "[Epoch 3/200] [Batch 339/637] [D loss: 0.134247] [G loss: 0.497064]\n",
      "[Epoch 3/200] [Batch 340/637] [D loss: 0.139774] [G loss: 0.512002]\n",
      "[Epoch 3/200] [Batch 341/637] [D loss: 0.123492] [G loss: 0.539158]\n",
      "[Epoch 3/200] [Batch 342/637] [D loss: 0.167431] [G loss: 0.548335]\n",
      "[Epoch 3/200] [Batch 343/637] [D loss: 0.144797] [G loss: 0.604012]\n",
      "[Epoch 3/200] [Batch 344/637] [D loss: 0.129119] [G loss: 0.582605]\n",
      "[Epoch 3/200] [Batch 345/637] [D loss: 0.140901] [G loss: 0.524063]\n",
      "[Epoch 3/200] [Batch 346/637] [D loss: 0.138214] [G loss: 0.503960]\n",
      "[Epoch 3/200] [Batch 347/637] [D loss: 0.161714] [G loss: 0.555513]\n",
      "[Epoch 3/200] [Batch 348/637] [D loss: 0.140659] [G loss: 0.613021]\n",
      "[Epoch 3/200] [Batch 349/637] [D loss: 0.135957] [G loss: 0.622341]\n",
      "[Epoch 3/200] [Batch 350/637] [D loss: 0.144260] [G loss: 0.510567]\n",
      "[Epoch 3/200] [Batch 351/637] [D loss: 0.114693] [G loss: 0.519714]\n",
      "[Epoch 3/200] [Batch 352/637] [D loss: 0.146815] [G loss: 0.515515]\n",
      "[Epoch 3/200] [Batch 353/637] [D loss: 0.135545] [G loss: 0.567660]\n",
      "[Epoch 3/200] [Batch 354/637] [D loss: 0.151785] [G loss: 0.565101]\n",
      "[Epoch 3/200] [Batch 355/637] [D loss: 0.137480] [G loss: 0.539731]\n",
      "[Epoch 3/200] [Batch 356/637] [D loss: 0.150526] [G loss: 0.499008]\n",
      "[Epoch 3/200] [Batch 357/637] [D loss: 0.138553] [G loss: 0.571945]\n",
      "[Epoch 3/200] [Batch 358/637] [D loss: 0.164696] [G loss: 0.612927]\n",
      "[Epoch 3/200] [Batch 359/637] [D loss: 0.135584] [G loss: 0.537935]\n",
      "[Epoch 3/200] [Batch 360/637] [D loss: 0.146079] [G loss: 0.499797]\n",
      "[Epoch 3/200] [Batch 361/637] [D loss: 0.148969] [G loss: 0.488249]\n",
      "[Epoch 3/200] [Batch 362/637] [D loss: 0.179149] [G loss: 0.569657]\n",
      "[Epoch 3/200] [Batch 363/637] [D loss: 0.217953] [G loss: 0.487921]\n",
      "[Epoch 3/200] [Batch 364/637] [D loss: 0.384662] [G loss: 0.749032]\n",
      "[Epoch 3/200] [Batch 365/637] [D loss: 0.239820] [G loss: 0.658744]\n",
      "[Epoch 3/200] [Batch 366/637] [D loss: 0.232062] [G loss: 0.467770]\n",
      "[Epoch 3/200] [Batch 367/637] [D loss: 0.183077] [G loss: 0.460269]\n",
      "[Epoch 3/200] [Batch 368/637] [D loss: 0.172158] [G loss: 0.476026]\n",
      "[Epoch 3/200] [Batch 369/637] [D loss: 0.168108] [G loss: 0.389215]\n",
      "[Epoch 3/200] [Batch 370/637] [D loss: 0.164791] [G loss: 0.406806]\n",
      "[Epoch 3/200] [Batch 371/637] [D loss: 0.157047] [G loss: 0.455612]\n",
      "[Epoch 3/200] [Batch 372/637] [D loss: 0.155865] [G loss: 0.446326]\n",
      "[Epoch 3/200] [Batch 373/637] [D loss: 0.151196] [G loss: 0.448685]\n",
      "[Epoch 3/200] [Batch 374/637] [D loss: 0.139693] [G loss: 0.536584]\n",
      "[Epoch 3/200] [Batch 375/637] [D loss: 0.161167] [G loss: 0.527718]\n",
      "[Epoch 3/200] [Batch 376/637] [D loss: 0.177807] [G loss: 0.409653]\n",
      "[Epoch 3/200] [Batch 377/637] [D loss: 0.207349] [G loss: 0.588037]\n",
      "[Epoch 3/200] [Batch 378/637] [D loss: 0.161309] [G loss: 0.604731]\n",
      "[Epoch 3/200] [Batch 379/637] [D loss: 0.176083] [G loss: 0.532557]\n",
      "[Epoch 3/200] [Batch 380/637] [D loss: 0.140082] [G loss: 0.453724]\n",
      "[Epoch 3/200] [Batch 381/637] [D loss: 0.163014] [G loss: 0.409809]\n",
      "[Epoch 3/200] [Batch 382/637] [D loss: 0.157839] [G loss: 0.439714]\n",
      "[Epoch 3/200] [Batch 383/637] [D loss: 0.151091] [G loss: 0.574404]\n",
      "[Epoch 3/200] [Batch 384/637] [D loss: 0.195899] [G loss: 0.519857]\n",
      "[Epoch 3/200] [Batch 385/637] [D loss: 0.199797] [G loss: 0.629429]\n",
      "[Epoch 3/200] [Batch 386/637] [D loss: 0.152008] [G loss: 0.511556]\n",
      "[Epoch 3/200] [Batch 387/637] [D loss: 0.155949] [G loss: 0.464118]\n",
      "[Epoch 3/200] [Batch 388/637] [D loss: 0.147964] [G loss: 0.457226]\n",
      "[Epoch 3/200] [Batch 389/637] [D loss: 0.160541] [G loss: 0.427987]\n",
      "[Epoch 3/200] [Batch 390/637] [D loss: 0.152035] [G loss: 0.475302]\n",
      "[Epoch 3/200] [Batch 391/637] [D loss: 0.170405] [G loss: 0.556223]\n",
      "[Epoch 3/200] [Batch 392/637] [D loss: 0.157253] [G loss: 0.516461]\n",
      "[Epoch 3/200] [Batch 393/637] [D loss: 0.181362] [G loss: 0.458888]\n",
      "[Epoch 3/200] [Batch 394/637] [D loss: 0.182022] [G loss: 0.479813]\n",
      "[Epoch 3/200] [Batch 395/637] [D loss: 0.170810] [G loss: 0.509490]\n",
      "[Epoch 3/200] [Batch 396/637] [D loss: 0.164035] [G loss: 0.493759]\n",
      "[Epoch 3/200] [Batch 397/637] [D loss: 0.180874] [G loss: 0.500235]\n",
      "[Epoch 3/200] [Batch 398/637] [D loss: 0.143764] [G loss: 0.593773]\n",
      "[Epoch 3/200] [Batch 399/637] [D loss: 0.157899] [G loss: 0.477474]\n",
      "[Epoch 3/200] [Batch 400/637] [D loss: 0.170395] [G loss: 0.603964]\n",
      "[Epoch 3/200] [Batch 401/637] [D loss: 0.205108] [G loss: 0.493265]\n",
      "[Epoch 3/200] [Batch 402/637] [D loss: 0.221538] [G loss: 0.655956]\n",
      "[Epoch 3/200] [Batch 403/637] [D loss: 0.151043] [G loss: 0.616769]\n",
      "[Epoch 3/200] [Batch 404/637] [D loss: 0.174482] [G loss: 0.558351]\n",
      "[Epoch 3/200] [Batch 405/637] [D loss: 0.145840] [G loss: 0.519383]\n",
      "[Epoch 3/200] [Batch 406/637] [D loss: 0.149689] [G loss: 0.508247]\n",
      "[Epoch 3/200] [Batch 407/637] [D loss: 0.143399] [G loss: 0.524807]\n",
      "[Epoch 3/200] [Batch 408/637] [D loss: 0.161011] [G loss: 0.445321]\n",
      "[Epoch 3/200] [Batch 409/637] [D loss: 0.159577] [G loss: 0.493373]\n",
      "[Epoch 3/200] [Batch 410/637] [D loss: 0.167508] [G loss: 0.482476]\n",
      "[Epoch 3/200] [Batch 411/637] [D loss: 0.158458] [G loss: 0.638752]\n",
      "[Epoch 3/200] [Batch 412/637] [D loss: 0.143403] [G loss: 0.570959]\n",
      "[Epoch 3/200] [Batch 413/637] [D loss: 0.151200] [G loss: 0.492636]\n",
      "[Epoch 3/200] [Batch 414/637] [D loss: 0.173108] [G loss: 0.465385]\n",
      "[Epoch 3/200] [Batch 415/637] [D loss: 0.185785] [G loss: 0.418162]\n",
      "[Epoch 3/200] [Batch 416/637] [D loss: 0.257305] [G loss: 0.563549]\n",
      "[Epoch 3/200] [Batch 417/637] [D loss: 0.200070] [G loss: 0.634194]\n",
      "[Epoch 3/200] [Batch 418/637] [D loss: 0.176731] [G loss: 0.568777]\n",
      "[Epoch 3/200] [Batch 419/637] [D loss: 0.158378] [G loss: 0.467359]\n",
      "[Epoch 3/200] [Batch 420/637] [D loss: 0.160227] [G loss: 0.478988]\n",
      "[Epoch 3/200] [Batch 421/637] [D loss: 0.139566] [G loss: 0.450455]\n",
      "[Epoch 3/200] [Batch 422/637] [D loss: 0.153045] [G loss: 0.570570]\n",
      "[Epoch 3/200] [Batch 423/637] [D loss: 0.141347] [G loss: 0.513556]\n",
      "[Epoch 3/200] [Batch 424/637] [D loss: 0.154731] [G loss: 0.489729]\n",
      "[Epoch 3/200] [Batch 425/637] [D loss: 0.227416] [G loss: 0.701145]\n",
      "[Epoch 3/200] [Batch 426/637] [D loss: 0.160935] [G loss: 0.647804]\n",
      "[Epoch 3/200] [Batch 427/637] [D loss: 0.210432] [G loss: 0.503274]\n",
      "[Epoch 3/200] [Batch 428/637] [D loss: 0.162949] [G loss: 0.632540]\n",
      "[Epoch 3/200] [Batch 429/637] [D loss: 0.179607] [G loss: 0.513621]\n",
      "[Epoch 3/200] [Batch 430/637] [D loss: 0.152618] [G loss: 0.449311]\n",
      "[Epoch 3/200] [Batch 431/637] [D loss: 0.130061] [G loss: 0.470885]\n",
      "[Epoch 3/200] [Batch 432/637] [D loss: 0.138494] [G loss: 0.469332]\n",
      "[Epoch 3/200] [Batch 433/637] [D loss: 0.133979] [G loss: 0.529220]\n",
      "[Epoch 3/200] [Batch 434/637] [D loss: 0.144618] [G loss: 0.645870]\n",
      "[Epoch 3/200] [Batch 435/637] [D loss: 0.112145] [G loss: 0.622941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 436/637] [D loss: 0.146028] [G loss: 0.497608]\n",
      "[Epoch 3/200] [Batch 437/637] [D loss: 0.151745] [G loss: 0.462116]\n",
      "[Epoch 3/200] [Batch 438/637] [D loss: 0.181487] [G loss: 0.605233]\n",
      "[Epoch 3/200] [Batch 439/637] [D loss: 0.171337] [G loss: 0.562207]\n",
      "[Epoch 3/200] [Batch 440/637] [D loss: 0.150001] [G loss: 0.558394]\n",
      "[Epoch 3/200] [Batch 441/637] [D loss: 0.159591] [G loss: 0.456794]\n",
      "[Epoch 3/200] [Batch 442/637] [D loss: 0.166041] [G loss: 0.445766]\n",
      "[Epoch 3/200] [Batch 443/637] [D loss: 0.144421] [G loss: 0.633122]\n",
      "[Epoch 3/200] [Batch 444/637] [D loss: 0.165330] [G loss: 0.589292]\n",
      "[Epoch 3/200] [Batch 445/637] [D loss: 0.160179] [G loss: 0.503370]\n",
      "[Epoch 3/200] [Batch 446/637] [D loss: 0.138144] [G loss: 0.476969]\n",
      "[Epoch 3/200] [Batch 447/637] [D loss: 0.160167] [G loss: 0.488998]\n",
      "[Epoch 3/200] [Batch 448/637] [D loss: 0.146234] [G loss: 0.494082]\n",
      "[Epoch 3/200] [Batch 449/637] [D loss: 0.183872] [G loss: 0.475603]\n",
      "[Epoch 3/200] [Batch 450/637] [D loss: 0.196222] [G loss: 0.594317]\n",
      "[Epoch 3/200] [Batch 451/637] [D loss: 0.146426] [G loss: 0.563633]\n",
      "[Epoch 3/200] [Batch 452/637] [D loss: 0.149457] [G loss: 0.456141]\n",
      "[Epoch 3/200] [Batch 453/637] [D loss: 0.143398] [G loss: 0.545701]\n",
      "[Epoch 3/200] [Batch 454/637] [D loss: 0.145117] [G loss: 0.516196]\n",
      "[Epoch 3/200] [Batch 455/637] [D loss: 0.139881] [G loss: 0.525857]\n",
      "[Epoch 3/200] [Batch 456/637] [D loss: 0.131016] [G loss: 0.492083]\n",
      "[Epoch 3/200] [Batch 457/637] [D loss: 0.145152] [G loss: 0.491005]\n",
      "[Epoch 3/200] [Batch 458/637] [D loss: 0.155201] [G loss: 0.583753]\n",
      "[Epoch 3/200] [Batch 459/637] [D loss: 0.146351] [G loss: 0.542292]\n",
      "[Epoch 3/200] [Batch 460/637] [D loss: 0.156706] [G loss: 0.467578]\n",
      "[Epoch 3/200] [Batch 461/637] [D loss: 0.188629] [G loss: 0.532110]\n",
      "[Epoch 3/200] [Batch 462/637] [D loss: 0.151513] [G loss: 0.676150]\n",
      "[Epoch 3/200] [Batch 463/637] [D loss: 0.172468] [G loss: 0.520644]\n",
      "[Epoch 3/200] [Batch 464/637] [D loss: 0.147468] [G loss: 0.488828]\n",
      "[Epoch 3/200] [Batch 465/637] [D loss: 0.161586] [G loss: 0.428731]\n",
      "[Epoch 3/200] [Batch 466/637] [D loss: 0.153251] [G loss: 0.509964]\n",
      "[Epoch 3/200] [Batch 467/637] [D loss: 0.141231] [G loss: 0.558437]\n",
      "[Epoch 3/200] [Batch 468/637] [D loss: 0.178664] [G loss: 0.550617]\n",
      "[Epoch 3/200] [Batch 469/637] [D loss: 0.133047] [G loss: 0.482887]\n",
      "[Epoch 3/200] [Batch 470/637] [D loss: 0.200938] [G loss: 0.401449]\n",
      "[Epoch 3/200] [Batch 471/637] [D loss: 0.239519] [G loss: 0.613509]\n",
      "[Epoch 3/200] [Batch 472/637] [D loss: 0.175791] [G loss: 0.618488]\n",
      "[Epoch 3/200] [Batch 473/637] [D loss: 0.162681] [G loss: 0.504400]\n",
      "[Epoch 3/200] [Batch 474/637] [D loss: 0.162031] [G loss: 0.459154]\n",
      "[Epoch 3/200] [Batch 475/637] [D loss: 0.170851] [G loss: 0.440187]\n",
      "[Epoch 3/200] [Batch 476/637] [D loss: 0.145378] [G loss: 0.481563]\n",
      "[Epoch 3/200] [Batch 477/637] [D loss: 0.152034] [G loss: 0.485337]\n",
      "[Epoch 3/200] [Batch 478/637] [D loss: 0.143811] [G loss: 0.462529]\n",
      "[Epoch 3/200] [Batch 479/637] [D loss: 0.146117] [G loss: 0.523110]\n",
      "[Epoch 3/200] [Batch 480/637] [D loss: 0.133667] [G loss: 0.500451]\n",
      "[Epoch 3/200] [Batch 481/637] [D loss: 0.131839] [G loss: 0.542135]\n",
      "[Epoch 3/200] [Batch 482/637] [D loss: 0.124895] [G loss: 0.567292]\n",
      "[Epoch 3/200] [Batch 483/637] [D loss: 0.133838] [G loss: 0.555462]\n",
      "[Epoch 3/200] [Batch 484/637] [D loss: 0.138931] [G loss: 0.517255]\n",
      "[Epoch 3/200] [Batch 485/637] [D loss: 0.149675] [G loss: 0.672171]\n",
      "[Epoch 3/200] [Batch 486/637] [D loss: 0.131880] [G loss: 0.572633]\n",
      "[Epoch 3/200] [Batch 487/637] [D loss: 0.152573] [G loss: 0.482176]\n",
      "[Epoch 3/200] [Batch 488/637] [D loss: 0.159176] [G loss: 0.508061]\n",
      "[Epoch 3/200] [Batch 489/637] [D loss: 0.188744] [G loss: 0.705103]\n",
      "[Epoch 3/200] [Batch 490/637] [D loss: 0.163761] [G loss: 0.610287]\n",
      "[Epoch 3/200] [Batch 491/637] [D loss: 0.157328] [G loss: 0.519126]\n",
      "[Epoch 3/200] [Batch 492/637] [D loss: 0.145687] [G loss: 0.466806]\n",
      "[Epoch 3/200] [Batch 493/637] [D loss: 0.172144] [G loss: 0.477050]\n",
      "[Epoch 3/200] [Batch 494/637] [D loss: 0.159868] [G loss: 0.508190]\n",
      "[Epoch 3/200] [Batch 495/637] [D loss: 0.152122] [G loss: 0.500261]\n",
      "[Epoch 3/200] [Batch 496/637] [D loss: 0.176290] [G loss: 0.532572]\n",
      "[Epoch 3/200] [Batch 497/637] [D loss: 0.161890] [G loss: 0.516962]\n",
      "[Epoch 3/200] [Batch 498/637] [D loss: 0.147089] [G loss: 0.532860]\n",
      "[Epoch 3/200] [Batch 499/637] [D loss: 0.156842] [G loss: 0.524798]\n",
      "[Epoch 3/200] [Batch 500/637] [D loss: 0.158933] [G loss: 0.591760]\n",
      "[Epoch 3/200] [Batch 501/637] [D loss: 0.135127] [G loss: 0.518393]\n",
      "[Epoch 3/200] [Batch 502/637] [D loss: 0.157828] [G loss: 0.488776]\n",
      "[Epoch 3/200] [Batch 503/637] [D loss: 0.122442] [G loss: 0.585175]\n",
      "[Epoch 3/200] [Batch 504/637] [D loss: 0.138223] [G loss: 0.542590]\n",
      "[Epoch 3/200] [Batch 505/637] [D loss: 0.142744] [G loss: 0.523753]\n",
      "[Epoch 3/200] [Batch 506/637] [D loss: 0.160796] [G loss: 0.543464]\n",
      "[Epoch 3/200] [Batch 507/637] [D loss: 0.147118] [G loss: 0.553824]\n",
      "[Epoch 3/200] [Batch 508/637] [D loss: 0.124261] [G loss: 0.577782]\n",
      "[Epoch 3/200] [Batch 509/637] [D loss: 0.128584] [G loss: 0.525430]\n",
      "[Epoch 3/200] [Batch 510/637] [D loss: 0.157139] [G loss: 0.474218]\n",
      "[Epoch 3/200] [Batch 511/637] [D loss: 0.156076] [G loss: 0.575022]\n",
      "[Epoch 3/200] [Batch 512/637] [D loss: 0.132048] [G loss: 0.585534]\n",
      "[Epoch 3/200] [Batch 513/637] [D loss: 0.143484] [G loss: 0.512083]\n",
      "[Epoch 3/200] [Batch 514/637] [D loss: 0.143526] [G loss: 0.519567]\n",
      "[Epoch 3/200] [Batch 515/637] [D loss: 0.132684] [G loss: 0.497527]\n",
      "[Epoch 3/200] [Batch 516/637] [D loss: 0.119840] [G loss: 0.493159]\n",
      "[Epoch 3/200] [Batch 517/637] [D loss: 0.133867] [G loss: 0.508058]\n",
      "[Epoch 3/200] [Batch 518/637] [D loss: 0.126624] [G loss: 0.575926]\n",
      "[Epoch 3/200] [Batch 519/637] [D loss: 0.135842] [G loss: 0.552086]\n",
      "[Epoch 3/200] [Batch 520/637] [D loss: 0.127513] [G loss: 0.519533]\n",
      "[Epoch 3/200] [Batch 521/637] [D loss: 0.154037] [G loss: 0.572970]\n",
      "[Epoch 3/200] [Batch 522/637] [D loss: 0.168320] [G loss: 0.557435]\n",
      "[Epoch 3/200] [Batch 523/637] [D loss: 0.126238] [G loss: 0.614450]\n",
      "[Epoch 3/200] [Batch 524/637] [D loss: 0.153107] [G loss: 0.643666]\n",
      "[Epoch 3/200] [Batch 525/637] [D loss: 0.160851] [G loss: 0.459231]\n",
      "[Epoch 3/200] [Batch 526/637] [D loss: 0.149987] [G loss: 0.492786]\n",
      "[Epoch 3/200] [Batch 527/637] [D loss: 0.149803] [G loss: 0.528987]\n",
      "[Epoch 3/200] [Batch 528/637] [D loss: 0.135729] [G loss: 0.510182]\n",
      "[Epoch 3/200] [Batch 529/637] [D loss: 0.146805] [G loss: 0.506523]\n",
      "[Epoch 3/200] [Batch 530/637] [D loss: 0.133922] [G loss: 0.524834]\n",
      "[Epoch 3/200] [Batch 531/637] [D loss: 0.146883] [G loss: 0.507905]\n",
      "[Epoch 3/200] [Batch 532/637] [D loss: 0.139080] [G loss: 0.575294]\n",
      "[Epoch 3/200] [Batch 533/637] [D loss: 0.127484] [G loss: 0.533125]\n",
      "[Epoch 3/200] [Batch 534/637] [D loss: 0.171896] [G loss: 0.560106]\n",
      "[Epoch 3/200] [Batch 535/637] [D loss: 0.182072] [G loss: 0.552348]\n",
      "[Epoch 3/200] [Batch 536/637] [D loss: 0.147224] [G loss: 0.671765]\n",
      "[Epoch 3/200] [Batch 537/637] [D loss: 0.139350] [G loss: 0.546916]\n",
      "[Epoch 3/200] [Batch 538/637] [D loss: 0.147708] [G loss: 0.535725]\n",
      "[Epoch 3/200] [Batch 539/637] [D loss: 0.135609] [G loss: 0.457223]\n",
      "[Epoch 3/200] [Batch 540/637] [D loss: 0.143885] [G loss: 0.509146]\n",
      "[Epoch 3/200] [Batch 541/637] [D loss: 0.128874] [G loss: 0.567707]\n",
      "[Epoch 3/200] [Batch 542/637] [D loss: 0.140513] [G loss: 0.503235]\n",
      "[Epoch 3/200] [Batch 543/637] [D loss: 0.154543] [G loss: 0.524023]\n",
      "[Epoch 3/200] [Batch 544/637] [D loss: 0.129786] [G loss: 0.569218]\n",
      "[Epoch 3/200] [Batch 545/637] [D loss: 0.141637] [G loss: 0.599897]\n",
      "[Epoch 3/200] [Batch 546/637] [D loss: 0.139568] [G loss: 0.544756]\n",
      "[Epoch 3/200] [Batch 547/637] [D loss: 0.126814] [G loss: 0.568901]\n",
      "[Epoch 3/200] [Batch 548/637] [D loss: 0.122060] [G loss: 0.546449]\n",
      "[Epoch 3/200] [Batch 549/637] [D loss: 0.122406] [G loss: 0.569595]\n",
      "[Epoch 3/200] [Batch 550/637] [D loss: 0.170923] [G loss: 0.493918]\n",
      "[Epoch 3/200] [Batch 551/637] [D loss: 0.206086] [G loss: 0.747708]\n",
      "[Epoch 3/200] [Batch 552/637] [D loss: 0.154300] [G loss: 0.598978]\n",
      "[Epoch 3/200] [Batch 553/637] [D loss: 0.152206] [G loss: 0.533676]\n",
      "[Epoch 3/200] [Batch 554/637] [D loss: 0.139310] [G loss: 0.458685]\n",
      "[Epoch 3/200] [Batch 555/637] [D loss: 0.146306] [G loss: 0.483487]\n",
      "[Epoch 3/200] [Batch 556/637] [D loss: 0.132297] [G loss: 0.541631]\n",
      "[Epoch 3/200] [Batch 557/637] [D loss: 0.128861] [G loss: 0.521921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 558/637] [D loss: 0.134811] [G loss: 0.545921]\n",
      "[Epoch 3/200] [Batch 559/637] [D loss: 0.122004] [G loss: 0.568319]\n",
      "[Epoch 3/200] [Batch 560/637] [D loss: 0.108747] [G loss: 0.571181]\n",
      "[Epoch 3/200] [Batch 561/637] [D loss: 0.128959] [G loss: 0.550019]\n",
      "[Epoch 3/200] [Batch 562/637] [D loss: 0.119618] [G loss: 0.561908]\n",
      "[Epoch 3/200] [Batch 563/637] [D loss: 0.135075] [G loss: 0.553352]\n",
      "[Epoch 3/200] [Batch 564/637] [D loss: 0.158183] [G loss: 0.544313]\n",
      "[Epoch 3/200] [Batch 565/637] [D loss: 0.152349] [G loss: 0.573587]\n",
      "[Epoch 3/200] [Batch 566/637] [D loss: 0.134086] [G loss: 0.585173]\n",
      "[Epoch 3/200] [Batch 567/637] [D loss: 0.137050] [G loss: 0.535205]\n",
      "[Epoch 3/200] [Batch 568/637] [D loss: 0.145848] [G loss: 0.532812]\n",
      "[Epoch 3/200] [Batch 569/637] [D loss: 0.130564] [G loss: 0.538906]\n",
      "[Epoch 3/200] [Batch 570/637] [D loss: 0.144652] [G loss: 0.498016]\n",
      "[Epoch 3/200] [Batch 571/637] [D loss: 0.173072] [G loss: 0.585596]\n",
      "[Epoch 3/200] [Batch 572/637] [D loss: 0.154710] [G loss: 0.596030]\n",
      "[Epoch 3/200] [Batch 573/637] [D loss: 0.183971] [G loss: 0.495910]\n",
      "[Epoch 3/200] [Batch 574/637] [D loss: 0.204438] [G loss: 0.635343]\n",
      "[Epoch 3/200] [Batch 575/637] [D loss: 0.155673] [G loss: 0.590982]\n",
      "[Epoch 3/200] [Batch 576/637] [D loss: 0.165041] [G loss: 0.475289]\n",
      "[Epoch 3/200] [Batch 577/637] [D loss: 0.156569] [G loss: 0.479176]\n",
      "[Epoch 3/200] [Batch 578/637] [D loss: 0.144236] [G loss: 0.512507]\n",
      "[Epoch 3/200] [Batch 579/637] [D loss: 0.130182] [G loss: 0.462859]\n",
      "[Epoch 3/200] [Batch 580/637] [D loss: 0.145523] [G loss: 0.576146]\n",
      "[Epoch 3/200] [Batch 581/637] [D loss: 0.121646] [G loss: 0.572849]\n",
      "[Epoch 3/200] [Batch 582/637] [D loss: 0.141038] [G loss: 0.518509]\n",
      "[Epoch 3/200] [Batch 583/637] [D loss: 0.140516] [G loss: 0.533822]\n",
      "[Epoch 3/200] [Batch 584/637] [D loss: 0.141891] [G loss: 0.565057]\n",
      "[Epoch 3/200] [Batch 585/637] [D loss: 0.153623] [G loss: 0.478760]\n",
      "[Epoch 3/200] [Batch 586/637] [D loss: 0.157556] [G loss: 0.666943]\n",
      "[Epoch 3/200] [Batch 587/637] [D loss: 0.148873] [G loss: 0.509385]\n",
      "[Epoch 3/200] [Batch 588/637] [D loss: 0.156149] [G loss: 0.512712]\n",
      "[Epoch 3/200] [Batch 589/637] [D loss: 0.175153] [G loss: 0.471850]\n",
      "[Epoch 3/200] [Batch 590/637] [D loss: 0.173652] [G loss: 0.607521]\n",
      "[Epoch 3/200] [Batch 591/637] [D loss: 0.154588] [G loss: 0.543777]\n",
      "[Epoch 3/200] [Batch 592/637] [D loss: 0.137092] [G loss: 0.505203]\n",
      "[Epoch 3/200] [Batch 593/637] [D loss: 0.124424] [G loss: 0.524572]\n",
      "[Epoch 3/200] [Batch 594/637] [D loss: 0.136764] [G loss: 0.546728]\n",
      "[Epoch 3/200] [Batch 595/637] [D loss: 0.146645] [G loss: 0.581691]\n",
      "[Epoch 3/200] [Batch 596/637] [D loss: 0.134029] [G loss: 0.599676]\n",
      "[Epoch 3/200] [Batch 597/637] [D loss: 0.150790] [G loss: 0.576101]\n",
      "[Epoch 3/200] [Batch 598/637] [D loss: 0.148935] [G loss: 0.601626]\n",
      "[Epoch 3/200] [Batch 599/637] [D loss: 0.144751] [G loss: 0.613321]\n",
      "[Epoch 3/200] [Batch 600/637] [D loss: 0.164183] [G loss: 0.570439]\n",
      "[Epoch 3/200] [Batch 601/637] [D loss: 0.182137] [G loss: 0.458500]\n",
      "[Epoch 3/200] [Batch 602/637] [D loss: 0.281954] [G loss: 0.655878]\n",
      "[Epoch 3/200] [Batch 603/637] [D loss: 0.170603] [G loss: 0.701424]\n",
      "[Epoch 3/200] [Batch 604/637] [D loss: 0.172507] [G loss: 0.605470]\n",
      "[Epoch 3/200] [Batch 605/637] [D loss: 0.153025] [G loss: 0.482717]\n",
      "[Epoch 3/200] [Batch 606/637] [D loss: 0.157364] [G loss: 0.490808]\n",
      "[Epoch 3/200] [Batch 607/637] [D loss: 0.152711] [G loss: 0.509249]\n",
      "[Epoch 3/200] [Batch 608/637] [D loss: 0.152662] [G loss: 0.582809]\n",
      "[Epoch 3/200] [Batch 609/637] [D loss: 0.135760] [G loss: 0.546762]\n",
      "[Epoch 3/200] [Batch 610/637] [D loss: 0.196663] [G loss: 0.470716]\n",
      "[Epoch 3/200] [Batch 611/637] [D loss: 0.216488] [G loss: 0.661207]\n",
      "[Epoch 3/200] [Batch 612/637] [D loss: 0.156391] [G loss: 0.629733]\n",
      "[Epoch 3/200] [Batch 613/637] [D loss: 0.160245] [G loss: 0.508789]\n",
      "[Epoch 3/200] [Batch 614/637] [D loss: 0.141848] [G loss: 0.552553]\n",
      "[Epoch 3/200] [Batch 615/637] [D loss: 0.182631] [G loss: 0.497698]\n",
      "[Epoch 3/200] [Batch 616/637] [D loss: 0.144554] [G loss: 0.512915]\n",
      "[Epoch 3/200] [Batch 617/637] [D loss: 0.185445] [G loss: 0.460378]\n",
      "[Epoch 3/200] [Batch 618/637] [D loss: 0.148556] [G loss: 0.597185]\n",
      "[Epoch 3/200] [Batch 619/637] [D loss: 0.153123] [G loss: 0.509400]\n",
      "[Epoch 3/200] [Batch 620/637] [D loss: 0.139326] [G loss: 0.553049]\n",
      "[Epoch 3/200] [Batch 621/637] [D loss: 0.141147] [G loss: 0.533201]\n",
      "[Epoch 3/200] [Batch 622/637] [D loss: 0.145124] [G loss: 0.508214]\n",
      "[Epoch 3/200] [Batch 623/637] [D loss: 0.156913] [G loss: 0.572385]\n",
      "[Epoch 3/200] [Batch 624/637] [D loss: 0.161009] [G loss: 0.585232]\n",
      "[Epoch 3/200] [Batch 625/637] [D loss: 0.142314] [G loss: 0.542039]\n",
      "[Epoch 3/200] [Batch 626/637] [D loss: 0.144134] [G loss: 0.518199]\n",
      "[Epoch 3/200] [Batch 627/637] [D loss: 0.154720] [G loss: 0.536581]\n",
      "[Epoch 3/200] [Batch 628/637] [D loss: 0.154862] [G loss: 0.594380]\n",
      "[Epoch 3/200] [Batch 629/637] [D loss: 0.161886] [G loss: 0.590568]\n",
      "[Epoch 3/200] [Batch 630/637] [D loss: 0.131677] [G loss: 0.629659]\n",
      "[Epoch 3/200] [Batch 631/637] [D loss: 0.153691] [G loss: 0.551285]\n",
      "[Epoch 3/200] [Batch 632/637] [D loss: 0.163761] [G loss: 0.547684]\n",
      "[Epoch 3/200] [Batch 633/637] [D loss: 0.152620] [G loss: 0.510766]\n",
      "[Epoch 3/200] [Batch 634/637] [D loss: 0.130632] [G loss: 0.537075]\n",
      "[Epoch 3/200] [Batch 635/637] [D loss: 0.136454] [G loss: 0.578344]\n",
      "[Epoch 3/200] [Batch 636/637] [D loss: 0.129990] [G loss: 0.505503]\n",
      "[Epoch 4/200] [Batch 0/637] [D loss: 0.130160] [G loss: 0.584472]\n",
      "[Epoch 4/200] [Batch 1/637] [D loss: 0.128108] [G loss: 0.609876]\n",
      "[Epoch 4/200] [Batch 2/637] [D loss: 0.124833] [G loss: 0.554680]\n",
      "[Epoch 4/200] [Batch 3/637] [D loss: 0.136162] [G loss: 0.612460]\n",
      "[Epoch 4/200] [Batch 4/637] [D loss: 0.130562] [G loss: 0.587333]\n",
      "[Epoch 4/200] [Batch 5/637] [D loss: 0.158948] [G loss: 0.505312]\n",
      "[Epoch 4/200] [Batch 6/637] [D loss: 0.211239] [G loss: 0.630300]\n",
      "[Epoch 4/200] [Batch 7/637] [D loss: 0.225765] [G loss: 0.516270]\n",
      "[Epoch 4/200] [Batch 8/637] [D loss: 0.181112] [G loss: 0.656716]\n",
      "[Epoch 4/200] [Batch 9/637] [D loss: 0.169086] [G loss: 0.518151]\n",
      "[Epoch 4/200] [Batch 10/637] [D loss: 0.164582] [G loss: 0.455521]\n",
      "[Epoch 4/200] [Batch 11/637] [D loss: 0.156422] [G loss: 0.443420]\n",
      "[Epoch 4/200] [Batch 12/637] [D loss: 0.155951] [G loss: 0.472799]\n",
      "[Epoch 4/200] [Batch 13/637] [D loss: 0.158845] [G loss: 0.487093]\n",
      "[Epoch 4/200] [Batch 14/637] [D loss: 0.129693] [G loss: 0.509650]\n",
      "[Epoch 4/200] [Batch 15/637] [D loss: 0.153159] [G loss: 0.542443]\n",
      "[Epoch 4/200] [Batch 16/637] [D loss: 0.133424] [G loss: 0.496333]\n",
      "[Epoch 4/200] [Batch 17/637] [D loss: 0.153247] [G loss: 0.604060]\n",
      "[Epoch 4/200] [Batch 18/637] [D loss: 0.136061] [G loss: 0.531023]\n",
      "[Epoch 4/200] [Batch 19/637] [D loss: 0.150593] [G loss: 0.490370]\n",
      "[Epoch 4/200] [Batch 20/637] [D loss: 0.142015] [G loss: 0.569921]\n",
      "[Epoch 4/200] [Batch 21/637] [D loss: 0.142670] [G loss: 0.560422]\n",
      "[Epoch 4/200] [Batch 22/637] [D loss: 0.154276] [G loss: 0.515783]\n",
      "[Epoch 4/200] [Batch 23/637] [D loss: 0.179298] [G loss: 0.589642]\n",
      "[Epoch 4/200] [Batch 24/637] [D loss: 0.171093] [G loss: 0.513781]\n",
      "[Epoch 4/200] [Batch 25/637] [D loss: 0.156624] [G loss: 0.564103]\n",
      "[Epoch 4/200] [Batch 26/637] [D loss: 0.158148] [G loss: 0.530265]\n",
      "[Epoch 4/200] [Batch 27/637] [D loss: 0.162742] [G loss: 0.469176]\n",
      "[Epoch 4/200] [Batch 28/637] [D loss: 0.163051] [G loss: 0.596157]\n",
      "[Epoch 4/200] [Batch 29/637] [D loss: 0.158843] [G loss: 0.561197]\n",
      "[Epoch 4/200] [Batch 30/637] [D loss: 0.169390] [G loss: 0.500145]\n",
      "[Epoch 4/200] [Batch 31/637] [D loss: 0.224474] [G loss: 0.684748]\n",
      "[Epoch 4/200] [Batch 32/637] [D loss: 0.173536] [G loss: 0.541372]\n",
      "[Epoch 4/200] [Batch 33/637] [D loss: 0.170756] [G loss: 0.530738]\n",
      "[Epoch 4/200] [Batch 34/637] [D loss: 0.151090] [G loss: 0.479195]\n",
      "[Epoch 4/200] [Batch 35/637] [D loss: 0.153008] [G loss: 0.497986]\n",
      "[Epoch 4/200] [Batch 36/637] [D loss: 0.135634] [G loss: 0.492434]\n",
      "[Epoch 4/200] [Batch 37/637] [D loss: 0.129460] [G loss: 0.491880]\n",
      "[Epoch 4/200] [Batch 38/637] [D loss: 0.124423] [G loss: 0.525527]\n",
      "[Epoch 4/200] [Batch 39/637] [D loss: 0.131948] [G loss: 0.512915]\n",
      "[Epoch 4/200] [Batch 40/637] [D loss: 0.130104] [G loss: 0.515423]\n",
      "[Epoch 4/200] [Batch 41/637] [D loss: 0.150003] [G loss: 0.553168]\n",
      "[Epoch 4/200] [Batch 42/637] [D loss: 0.130242] [G loss: 0.553958]\n",
      "[Epoch 4/200] [Batch 43/637] [D loss: 0.146429] [G loss: 0.531433]\n",
      "[Epoch 4/200] [Batch 44/637] [D loss: 0.157194] [G loss: 0.479540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 45/637] [D loss: 0.160351] [G loss: 0.659375]\n",
      "[Epoch 4/200] [Batch 46/637] [D loss: 0.139091] [G loss: 0.552507]\n",
      "[Epoch 4/200] [Batch 47/637] [D loss: 0.147221] [G loss: 0.506168]\n",
      "[Epoch 4/200] [Batch 48/637] [D loss: 0.154795] [G loss: 0.480193]\n",
      "[Epoch 4/200] [Batch 49/637] [D loss: 0.143437] [G loss: 0.524036]\n",
      "[Epoch 4/200] [Batch 50/637] [D loss: 0.147562] [G loss: 0.554080]\n",
      "[Epoch 4/200] [Batch 51/637] [D loss: 0.121868] [G loss: 0.604352]\n",
      "[Epoch 4/200] [Batch 52/637] [D loss: 0.126353] [G loss: 0.611046]\n",
      "[Epoch 4/200] [Batch 53/637] [D loss: 0.153519] [G loss: 0.630879]\n",
      "[Epoch 4/200] [Batch 54/637] [D loss: 0.200106] [G loss: 0.573136]\n",
      "[Epoch 4/200] [Batch 55/637] [D loss: 0.206737] [G loss: 0.659537]\n",
      "[Epoch 4/200] [Batch 56/637] [D loss: 0.149323] [G loss: 0.644746]\n",
      "[Epoch 4/200] [Batch 57/637] [D loss: 0.156869] [G loss: 0.533068]\n",
      "[Epoch 4/200] [Batch 58/637] [D loss: 0.147612] [G loss: 0.519644]\n",
      "[Epoch 4/200] [Batch 59/637] [D loss: 0.148931] [G loss: 0.465029]\n",
      "[Epoch 4/200] [Batch 60/637] [D loss: 0.164677] [G loss: 0.467829]\n",
      "[Epoch 4/200] [Batch 61/637] [D loss: 0.143643] [G loss: 0.548671]\n",
      "[Epoch 4/200] [Batch 62/637] [D loss: 0.145364] [G loss: 0.502717]\n",
      "[Epoch 4/200] [Batch 63/637] [D loss: 0.146512] [G loss: 0.493703]\n",
      "[Epoch 4/200] [Batch 64/637] [D loss: 0.130635] [G loss: 0.536602]\n",
      "[Epoch 4/200] [Batch 65/637] [D loss: 0.133888] [G loss: 0.573183]\n",
      "[Epoch 4/200] [Batch 66/637] [D loss: 0.155526] [G loss: 0.549989]\n",
      "[Epoch 4/200] [Batch 67/637] [D loss: 0.165189] [G loss: 0.572397]\n",
      "[Epoch 4/200] [Batch 68/637] [D loss: 0.145051] [G loss: 0.558530]\n",
      "[Epoch 4/200] [Batch 69/637] [D loss: 0.147674] [G loss: 0.560374]\n",
      "[Epoch 4/200] [Batch 70/637] [D loss: 0.160898] [G loss: 0.505868]\n",
      "[Epoch 4/200] [Batch 71/637] [D loss: 0.169506] [G loss: 0.569258]\n",
      "[Epoch 4/200] [Batch 72/637] [D loss: 0.157706] [G loss: 0.611073]\n",
      "[Epoch 4/200] [Batch 73/637] [D loss: 0.164548] [G loss: 0.619919]\n",
      "[Epoch 4/200] [Batch 74/637] [D loss: 0.136586] [G loss: 0.549119]\n",
      "[Epoch 4/200] [Batch 75/637] [D loss: 0.154180] [G loss: 0.493087]\n",
      "[Epoch 4/200] [Batch 76/637] [D loss: 0.164462] [G loss: 0.513050]\n",
      "[Epoch 4/200] [Batch 77/637] [D loss: 0.158385] [G loss: 0.565090]\n",
      "[Epoch 4/200] [Batch 78/637] [D loss: 0.159415] [G loss: 0.526171]\n",
      "[Epoch 4/200] [Batch 79/637] [D loss: 0.129095] [G loss: 0.590454]\n",
      "[Epoch 4/200] [Batch 80/637] [D loss: 0.155493] [G loss: 0.583283]\n",
      "[Epoch 4/200] [Batch 81/637] [D loss: 0.151735] [G loss: 0.529448]\n",
      "[Epoch 4/200] [Batch 82/637] [D loss: 0.134024] [G loss: 0.581043]\n",
      "[Epoch 4/200] [Batch 83/637] [D loss: 0.145542] [G loss: 0.541150]\n",
      "[Epoch 4/200] [Batch 84/637] [D loss: 0.170582] [G loss: 0.528061]\n",
      "[Epoch 4/200] [Batch 85/637] [D loss: 0.157594] [G loss: 0.514289]\n",
      "[Epoch 4/200] [Batch 86/637] [D loss: 0.182977] [G loss: 0.460032]\n",
      "[Epoch 4/200] [Batch 87/637] [D loss: 0.204750] [G loss: 0.773898]\n",
      "[Epoch 4/200] [Batch 88/637] [D loss: 0.140540] [G loss: 0.664546]\n",
      "[Epoch 4/200] [Batch 89/637] [D loss: 0.137824] [G loss: 0.567311]\n",
      "[Epoch 4/200] [Batch 90/637] [D loss: 0.159323] [G loss: 0.441477]\n",
      "[Epoch 4/200] [Batch 91/637] [D loss: 0.158745] [G loss: 0.501165]\n",
      "[Epoch 4/200] [Batch 92/637] [D loss: 0.127387] [G loss: 0.568435]\n",
      "[Epoch 4/200] [Batch 93/637] [D loss: 0.141624] [G loss: 0.550124]\n",
      "[Epoch 4/200] [Batch 94/637] [D loss: 0.131643] [G loss: 0.532041]\n",
      "[Epoch 4/200] [Batch 95/637] [D loss: 0.157097] [G loss: 0.480902]\n",
      "[Epoch 4/200] [Batch 96/637] [D loss: 0.123418] [G loss: 0.526746]\n",
      "[Epoch 4/200] [Batch 97/637] [D loss: 0.119554] [G loss: 0.557876]\n",
      "[Epoch 4/200] [Batch 98/637] [D loss: 0.140154] [G loss: 0.515957]\n",
      "[Epoch 4/200] [Batch 99/637] [D loss: 0.156585] [G loss: 0.484872]\n",
      "[Epoch 4/200] [Batch 100/637] [D loss: 0.164793] [G loss: 0.649748]\n",
      "[Epoch 4/200] [Batch 101/637] [D loss: 0.141397] [G loss: 0.597174]\n",
      "[Epoch 4/200] [Batch 102/637] [D loss: 0.153124] [G loss: 0.538028]\n",
      "[Epoch 4/200] [Batch 103/637] [D loss: 0.138981] [G loss: 0.496719]\n",
      "[Epoch 4/200] [Batch 104/637] [D loss: 0.137640] [G loss: 0.535384]\n",
      "[Epoch 4/200] [Batch 105/637] [D loss: 0.154015] [G loss: 0.527805]\n",
      "[Epoch 4/200] [Batch 106/637] [D loss: 0.129971] [G loss: 0.573802]\n",
      "[Epoch 4/200] [Batch 107/637] [D loss: 0.145606] [G loss: 0.627223]\n",
      "[Epoch 4/200] [Batch 108/637] [D loss: 0.134018] [G loss: 0.507278]\n",
      "[Epoch 4/200] [Batch 109/637] [D loss: 0.162696] [G loss: 0.466545]\n",
      "[Epoch 4/200] [Batch 110/637] [D loss: 0.157893] [G loss: 0.555173]\n",
      "[Epoch 4/200] [Batch 111/637] [D loss: 0.141994] [G loss: 0.629367]\n",
      "[Epoch 4/200] [Batch 112/637] [D loss: 0.154256] [G loss: 0.540687]\n",
      "[Epoch 4/200] [Batch 113/637] [D loss: 0.144685] [G loss: 0.507355]\n",
      "[Epoch 4/200] [Batch 114/637] [D loss: 0.146482] [G loss: 0.544766]\n",
      "[Epoch 4/200] [Batch 115/637] [D loss: 0.160375] [G loss: 0.552235]\n",
      "[Epoch 4/200] [Batch 116/637] [D loss: 0.157177] [G loss: 0.544588]\n",
      "[Epoch 4/200] [Batch 117/637] [D loss: 0.119096] [G loss: 0.628547]\n",
      "[Epoch 4/200] [Batch 118/637] [D loss: 0.141986] [G loss: 0.481255]\n",
      "[Epoch 4/200] [Batch 119/637] [D loss: 0.157277] [G loss: 0.511121]\n",
      "[Epoch 4/200] [Batch 120/637] [D loss: 0.186184] [G loss: 0.764224]\n",
      "[Epoch 4/200] [Batch 121/637] [D loss: 0.139168] [G loss: 0.618518]\n",
      "[Epoch 4/200] [Batch 122/637] [D loss: 0.164491] [G loss: 0.582365]\n",
      "[Epoch 4/200] [Batch 123/637] [D loss: 0.161381] [G loss: 0.569392]\n",
      "[Epoch 4/200] [Batch 124/637] [D loss: 0.140775] [G loss: 0.525243]\n",
      "[Epoch 4/200] [Batch 125/637] [D loss: 0.150222] [G loss: 0.532643]\n",
      "[Epoch 4/200] [Batch 126/637] [D loss: 0.131460] [G loss: 0.611362]\n",
      "[Epoch 4/200] [Batch 127/637] [D loss: 0.129993] [G loss: 0.568445]\n",
      "[Epoch 4/200] [Batch 128/637] [D loss: 0.172722] [G loss: 0.470428]\n",
      "[Epoch 4/200] [Batch 129/637] [D loss: 0.162231] [G loss: 0.626632]\n",
      "[Epoch 4/200] [Batch 130/637] [D loss: 0.142820] [G loss: 0.630784]\n",
      "[Epoch 4/200] [Batch 131/637] [D loss: 0.135956] [G loss: 0.597465]\n",
      "[Epoch 4/200] [Batch 132/637] [D loss: 0.150818] [G loss: 0.473174]\n",
      "[Epoch 4/200] [Batch 133/637] [D loss: 0.141157] [G loss: 0.478728]\n",
      "[Epoch 4/200] [Batch 134/637] [D loss: 0.139374] [G loss: 0.451559]\n",
      "[Epoch 4/200] [Batch 135/637] [D loss: 0.154732] [G loss: 0.558599]\n",
      "[Epoch 4/200] [Batch 136/637] [D loss: 0.127737] [G loss: 0.642100]\n",
      "[Epoch 4/200] [Batch 137/637] [D loss: 0.146384] [G loss: 0.571712]\n",
      "[Epoch 4/200] [Batch 138/637] [D loss: 0.149052] [G loss: 0.552706]\n",
      "[Epoch 4/200] [Batch 139/637] [D loss: 0.142617] [G loss: 0.545736]\n",
      "[Epoch 4/200] [Batch 140/637] [D loss: 0.149645] [G loss: 0.536765]\n",
      "[Epoch 4/200] [Batch 141/637] [D loss: 0.151152] [G loss: 0.518038]\n",
      "[Epoch 4/200] [Batch 142/637] [D loss: 0.134170] [G loss: 0.537181]\n",
      "[Epoch 4/200] [Batch 143/637] [D loss: 0.160005] [G loss: 0.552177]\n",
      "[Epoch 4/200] [Batch 144/637] [D loss: 0.205397] [G loss: 0.831999]\n",
      "[Epoch 4/200] [Batch 145/637] [D loss: 0.168121] [G loss: 0.691922]\n",
      "[Epoch 4/200] [Batch 146/637] [D loss: 0.224217] [G loss: 0.547850]\n",
      "[Epoch 4/200] [Batch 147/637] [D loss: 0.248357] [G loss: 0.528302]\n",
      "[Epoch 4/200] [Batch 148/637] [D loss: 0.182927] [G loss: 0.634373]\n",
      "[Epoch 4/200] [Batch 149/637] [D loss: 0.156373] [G loss: 0.499784]\n",
      "[Epoch 4/200] [Batch 150/637] [D loss: 0.157976] [G loss: 0.461337]\n",
      "[Epoch 4/200] [Batch 151/637] [D loss: 0.133950] [G loss: 0.491856]\n",
      "[Epoch 4/200] [Batch 152/637] [D loss: 0.128244] [G loss: 0.532205]\n",
      "[Epoch 4/200] [Batch 153/637] [D loss: 0.156999] [G loss: 0.482178]\n",
      "[Epoch 4/200] [Batch 154/637] [D loss: 0.138775] [G loss: 0.533377]\n",
      "[Epoch 4/200] [Batch 155/637] [D loss: 0.135898] [G loss: 0.545792]\n",
      "[Epoch 4/200] [Batch 156/637] [D loss: 0.121906] [G loss: 0.573019]\n",
      "[Epoch 4/200] [Batch 157/637] [D loss: 0.128706] [G loss: 0.540491]\n",
      "[Epoch 4/200] [Batch 158/637] [D loss: 0.133464] [G loss: 0.588745]\n",
      "[Epoch 4/200] [Batch 159/637] [D loss: 0.135200] [G loss: 0.594777]\n",
      "[Epoch 4/200] [Batch 160/637] [D loss: 0.135124] [G loss: 0.521697]\n",
      "[Epoch 4/200] [Batch 161/637] [D loss: 0.129250] [G loss: 0.568002]\n",
      "[Epoch 4/200] [Batch 162/637] [D loss: 0.146332] [G loss: 0.553110]\n",
      "[Epoch 4/200] [Batch 163/637] [D loss: 0.126580] [G loss: 0.580297]\n",
      "[Epoch 4/200] [Batch 164/637] [D loss: 0.140363] [G loss: 0.580629]\n",
      "[Epoch 4/200] [Batch 165/637] [D loss: 0.152841] [G loss: 0.540535]\n",
      "[Epoch 4/200] [Batch 166/637] [D loss: 0.161361] [G loss: 0.625113]\n",
      "[Epoch 4/200] [Batch 167/637] [D loss: 0.139676] [G loss: 0.637624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 168/637] [D loss: 0.234959] [G loss: 0.481064]\n",
      "[Epoch 4/200] [Batch 169/637] [D loss: 0.257041] [G loss: 0.837877]\n",
      "[Epoch 4/200] [Batch 170/637] [D loss: 0.198146] [G loss: 0.560374]\n",
      "[Epoch 4/200] [Batch 171/637] [D loss: 0.182192] [G loss: 0.554033]\n",
      "[Epoch 4/200] [Batch 172/637] [D loss: 0.151184] [G loss: 0.499394]\n",
      "[Epoch 4/200] [Batch 173/637] [D loss: 0.148664] [G loss: 0.425926]\n",
      "[Epoch 4/200] [Batch 174/637] [D loss: 0.143281] [G loss: 0.544489]\n",
      "[Epoch 4/200] [Batch 175/637] [D loss: 0.129634] [G loss: 0.554619]\n",
      "[Epoch 4/200] [Batch 176/637] [D loss: 0.130861] [G loss: 0.554286]\n",
      "[Epoch 4/200] [Batch 177/637] [D loss: 0.123919] [G loss: 0.582747]\n",
      "[Epoch 4/200] [Batch 178/637] [D loss: 0.131097] [G loss: 0.542099]\n",
      "[Epoch 4/200] [Batch 179/637] [D loss: 0.150864] [G loss: 0.669546]\n",
      "[Epoch 4/200] [Batch 180/637] [D loss: 0.126567] [G loss: 0.584372]\n",
      "[Epoch 4/200] [Batch 181/637] [D loss: 0.224782] [G loss: 0.425763]\n",
      "[Epoch 4/200] [Batch 182/637] [D loss: 0.291157] [G loss: 0.585890]\n",
      "[Epoch 4/200] [Batch 183/637] [D loss: 0.180329] [G loss: 0.655216]\n",
      "[Epoch 4/200] [Batch 184/637] [D loss: 0.212611] [G loss: 0.536345]\n",
      "[Epoch 4/200] [Batch 185/637] [D loss: 0.157410] [G loss: 0.484118]\n",
      "[Epoch 4/200] [Batch 186/637] [D loss: 0.158892] [G loss: 0.440428]\n",
      "[Epoch 4/200] [Batch 187/637] [D loss: 0.158176] [G loss: 0.408842]\n",
      "[Epoch 4/200] [Batch 188/637] [D loss: 0.163794] [G loss: 0.548177]\n",
      "[Epoch 4/200] [Batch 189/637] [D loss: 0.170215] [G loss: 0.568631]\n",
      "[Epoch 4/200] [Batch 190/637] [D loss: 0.157117] [G loss: 0.505307]\n",
      "[Epoch 4/200] [Batch 191/637] [D loss: 0.146242] [G loss: 0.500557]\n",
      "[Epoch 4/200] [Batch 192/637] [D loss: 0.131532] [G loss: 0.544680]\n",
      "[Epoch 4/200] [Batch 193/637] [D loss: 0.121103] [G loss: 0.538992]\n",
      "[Epoch 4/200] [Batch 194/637] [D loss: 0.130130] [G loss: 0.496309]\n",
      "[Epoch 4/200] [Batch 195/637] [D loss: 0.130208] [G loss: 0.536927]\n",
      "[Epoch 4/200] [Batch 196/637] [D loss: 0.144937] [G loss: 0.487476]\n",
      "[Epoch 4/200] [Batch 197/637] [D loss: 0.134506] [G loss: 0.577553]\n",
      "[Epoch 4/200] [Batch 198/637] [D loss: 0.123650] [G loss: 0.527839]\n",
      "[Epoch 4/200] [Batch 199/637] [D loss: 0.133892] [G loss: 0.506299]\n",
      "[Epoch 4/200] [Batch 200/637] [D loss: 0.140989] [G loss: 0.543841]\n",
      "[Epoch 4/200] [Batch 201/637] [D loss: 0.145908] [G loss: 0.541818]\n",
      "[Epoch 4/200] [Batch 202/637] [D loss: 0.146235] [G loss: 0.572405]\n",
      "[Epoch 4/200] [Batch 203/637] [D loss: 0.147683] [G loss: 0.537757]\n",
      "[Epoch 4/200] [Batch 204/637] [D loss: 0.135932] [G loss: 0.490103]\n",
      "[Epoch 4/200] [Batch 205/637] [D loss: 0.126301] [G loss: 0.605610]\n",
      "[Epoch 4/200] [Batch 206/637] [D loss: 0.136629] [G loss: 0.613836]\n",
      "[Epoch 4/200] [Batch 207/637] [D loss: 0.130966] [G loss: 0.555271]\n",
      "[Epoch 4/200] [Batch 208/637] [D loss: 0.140097] [G loss: 0.528844]\n",
      "[Epoch 4/200] [Batch 209/637] [D loss: 0.156850] [G loss: 0.497162]\n",
      "[Epoch 4/200] [Batch 210/637] [D loss: 0.169619] [G loss: 0.708436]\n",
      "[Epoch 4/200] [Batch 211/637] [D loss: 0.132476] [G loss: 0.596620]\n",
      "[Epoch 4/200] [Batch 212/637] [D loss: 0.154921] [G loss: 0.542623]\n",
      "[Epoch 4/200] [Batch 213/637] [D loss: 0.145210] [G loss: 0.536712]\n",
      "[Epoch 4/200] [Batch 214/637] [D loss: 0.142810] [G loss: 0.509540]\n",
      "[Epoch 4/200] [Batch 215/637] [D loss: 0.128924] [G loss: 0.599594]\n",
      "[Epoch 4/200] [Batch 216/637] [D loss: 0.138041] [G loss: 0.549766]\n",
      "[Epoch 4/200] [Batch 217/637] [D loss: 0.162368] [G loss: 0.519286]\n",
      "[Epoch 4/200] [Batch 218/637] [D loss: 0.154111] [G loss: 0.534507]\n",
      "[Epoch 4/200] [Batch 219/637] [D loss: 0.146443] [G loss: 0.611386]\n",
      "[Epoch 4/200] [Batch 220/637] [D loss: 0.139693] [G loss: 0.591716]\n",
      "[Epoch 4/200] [Batch 221/637] [D loss: 0.148403] [G loss: 0.513347]\n",
      "[Epoch 4/200] [Batch 222/637] [D loss: 0.141984] [G loss: 0.501041]\n",
      "[Epoch 4/200] [Batch 223/637] [D loss: 0.154851] [G loss: 0.565361]\n",
      "[Epoch 4/200] [Batch 224/637] [D loss: 0.151285] [G loss: 0.677213]\n",
      "[Epoch 4/200] [Batch 225/637] [D loss: 0.145591] [G loss: 0.508124]\n",
      "[Epoch 4/200] [Batch 226/637] [D loss: 0.173189] [G loss: 0.565194]\n",
      "[Epoch 4/200] [Batch 227/637] [D loss: 0.135194] [G loss: 0.530832]\n",
      "[Epoch 4/200] [Batch 228/637] [D loss: 0.159285] [G loss: 0.544853]\n",
      "[Epoch 4/200] [Batch 229/637] [D loss: 0.129717] [G loss: 0.599803]\n",
      "[Epoch 4/200] [Batch 230/637] [D loss: 0.142783] [G loss: 0.568793]\n",
      "[Epoch 4/200] [Batch 231/637] [D loss: 0.126392] [G loss: 0.547684]\n",
      "[Epoch 4/200] [Batch 232/637] [D loss: 0.139259] [G loss: 0.567508]\n",
      "[Epoch 4/200] [Batch 233/637] [D loss: 0.121426] [G loss: 0.549325]\n",
      "[Epoch 4/200] [Batch 234/637] [D loss: 0.123608] [G loss: 0.585030]\n",
      "[Epoch 4/200] [Batch 235/637] [D loss: 0.131467] [G loss: 0.647818]\n",
      "[Epoch 4/200] [Batch 236/637] [D loss: 0.128912] [G loss: 0.616489]\n",
      "[Epoch 4/200] [Batch 237/637] [D loss: 0.145942] [G loss: 0.494741]\n",
      "[Epoch 4/200] [Batch 238/637] [D loss: 0.210123] [G loss: 0.585223]\n",
      "[Epoch 4/200] [Batch 239/637] [D loss: 0.198070] [G loss: 0.710041]\n",
      "[Epoch 4/200] [Batch 240/637] [D loss: 0.153165] [G loss: 0.631698]\n",
      "[Epoch 4/200] [Batch 241/637] [D loss: 0.144456] [G loss: 0.630171]\n",
      "[Epoch 4/200] [Batch 242/637] [D loss: 0.145777] [G loss: 0.495457]\n",
      "[Epoch 4/200] [Batch 243/637] [D loss: 0.157431] [G loss: 0.432025]\n",
      "[Epoch 4/200] [Batch 244/637] [D loss: 0.138224] [G loss: 0.532962]\n",
      "[Epoch 4/200] [Batch 245/637] [D loss: 0.149766] [G loss: 0.572041]\n",
      "[Epoch 4/200] [Batch 246/637] [D loss: 0.131096] [G loss: 0.510017]\n",
      "[Epoch 4/200] [Batch 247/637] [D loss: 0.158875] [G loss: 0.502795]\n",
      "[Epoch 4/200] [Batch 248/637] [D loss: 0.156547] [G loss: 0.588679]\n",
      "[Epoch 4/200] [Batch 249/637] [D loss: 0.129641] [G loss: 0.628153]\n",
      "[Epoch 4/200] [Batch 250/637] [D loss: 0.146289] [G loss: 0.539882]\n",
      "[Epoch 4/200] [Batch 251/637] [D loss: 0.148488] [G loss: 0.627312]\n",
      "[Epoch 4/200] [Batch 252/637] [D loss: 0.129409] [G loss: 0.551314]\n",
      "[Epoch 4/200] [Batch 253/637] [D loss: 0.139330] [G loss: 0.501516]\n",
      "[Epoch 4/200] [Batch 254/637] [D loss: 0.143019] [G loss: 0.523733]\n",
      "[Epoch 4/200] [Batch 255/637] [D loss: 0.119132] [G loss: 0.502787]\n",
      "[Epoch 4/200] [Batch 256/637] [D loss: 0.148458] [G loss: 0.464721]\n",
      "[Epoch 4/200] [Batch 257/637] [D loss: 0.149214] [G loss: 0.526803]\n",
      "[Epoch 4/200] [Batch 258/637] [D loss: 0.119941] [G loss: 0.610107]\n",
      "[Epoch 4/200] [Batch 259/637] [D loss: 0.124953] [G loss: 0.547120]\n",
      "[Epoch 4/200] [Batch 260/637] [D loss: 0.125776] [G loss: 0.482034]\n",
      "[Epoch 4/200] [Batch 261/637] [D loss: 0.154547] [G loss: 0.508930]\n",
      "[Epoch 4/200] [Batch 262/637] [D loss: 0.138231] [G loss: 0.496802]\n",
      "[Epoch 4/200] [Batch 263/637] [D loss: 0.148159] [G loss: 0.592910]\n",
      "[Epoch 4/200] [Batch 264/637] [D loss: 0.147658] [G loss: 0.523389]\n",
      "[Epoch 4/200] [Batch 265/637] [D loss: 0.144559] [G loss: 0.486386]\n",
      "[Epoch 4/200] [Batch 266/637] [D loss: 0.171341] [G loss: 0.512776]\n",
      "[Epoch 4/200] [Batch 267/637] [D loss: 0.169729] [G loss: 0.517260]\n",
      "[Epoch 4/200] [Batch 268/637] [D loss: 0.141800] [G loss: 0.564770]\n",
      "[Epoch 4/200] [Batch 269/637] [D loss: 0.130428] [G loss: 0.510411]\n",
      "[Epoch 4/200] [Batch 270/637] [D loss: 0.150236] [G loss: 0.547683]\n",
      "[Epoch 4/200] [Batch 271/637] [D loss: 0.138614] [G loss: 0.532120]\n",
      "[Epoch 4/200] [Batch 272/637] [D loss: 0.147082] [G loss: 0.519974]\n",
      "[Epoch 4/200] [Batch 273/637] [D loss: 0.145736] [G loss: 0.552806]\n",
      "[Epoch 4/200] [Batch 274/637] [D loss: 0.133112] [G loss: 0.598768]\n",
      "[Epoch 4/200] [Batch 275/637] [D loss: 0.129029] [G loss: 0.546075]\n",
      "[Epoch 4/200] [Batch 276/637] [D loss: 0.223984] [G loss: 0.513294]\n",
      "[Epoch 4/200] [Batch 277/637] [D loss: 0.324509] [G loss: 0.693082]\n",
      "[Epoch 4/200] [Batch 278/637] [D loss: 0.182243] [G loss: 0.768668]\n",
      "[Epoch 4/200] [Batch 279/637] [D loss: 0.158220] [G loss: 0.671009]\n",
      "[Epoch 4/200] [Batch 280/637] [D loss: 0.167761] [G loss: 0.513250]\n",
      "[Epoch 4/200] [Batch 281/637] [D loss: 0.146217] [G loss: 0.534232]\n",
      "[Epoch 4/200] [Batch 282/637] [D loss: 0.144971] [G loss: 0.535401]\n",
      "[Epoch 4/200] [Batch 283/637] [D loss: 0.128607] [G loss: 0.507880]\n",
      "[Epoch 4/200] [Batch 284/637] [D loss: 0.164463] [G loss: 0.449323]\n",
      "[Epoch 4/200] [Batch 285/637] [D loss: 0.138501] [G loss: 0.611483]\n",
      "[Epoch 4/200] [Batch 286/637] [D loss: 0.131458] [G loss: 0.550123]\n",
      "[Epoch 4/200] [Batch 287/637] [D loss: 0.115392] [G loss: 0.568939]\n",
      "[Epoch 4/200] [Batch 288/637] [D loss: 0.133912] [G loss: 0.506556]\n",
      "[Epoch 4/200] [Batch 289/637] [D loss: 0.135483] [G loss: 0.536785]\n",
      "[Epoch 4/200] [Batch 290/637] [D loss: 0.129831] [G loss: 0.529426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 291/637] [D loss: 0.110536] [G loss: 0.553424]\n",
      "[Epoch 4/200] [Batch 292/637] [D loss: 0.141619] [G loss: 0.483704]\n",
      "[Epoch 4/200] [Batch 293/637] [D loss: 0.128133] [G loss: 0.495674]\n",
      "[Epoch 4/200] [Batch 294/637] [D loss: 0.149351] [G loss: 0.523717]\n",
      "[Epoch 4/200] [Batch 295/637] [D loss: 0.150305] [G loss: 0.580500]\n",
      "[Epoch 4/200] [Batch 296/637] [D loss: 0.135269] [G loss: 0.492805]\n",
      "[Epoch 4/200] [Batch 297/637] [D loss: 0.177722] [G loss: 0.512088]\n",
      "[Epoch 4/200] [Batch 298/637] [D loss: 0.148564] [G loss: 0.473723]\n",
      "[Epoch 4/200] [Batch 299/637] [D loss: 0.183431] [G loss: 0.525480]\n",
      "[Epoch 4/200] [Batch 300/637] [D loss: 0.154909] [G loss: 0.537297]\n",
      "[Epoch 4/200] [Batch 301/637] [D loss: 0.153988] [G loss: 0.545495]\n",
      "[Epoch 4/200] [Batch 302/637] [D loss: 0.169478] [G loss: 0.557780]\n",
      "[Epoch 4/200] [Batch 303/637] [D loss: 0.148187] [G loss: 0.492336]\n",
      "[Epoch 4/200] [Batch 304/637] [D loss: 0.143492] [G loss: 0.457921]\n",
      "[Epoch 4/200] [Batch 305/637] [D loss: 0.167434] [G loss: 0.428368]\n",
      "[Epoch 4/200] [Batch 306/637] [D loss: 0.157111] [G loss: 0.554703]\n",
      "[Epoch 4/200] [Batch 307/637] [D loss: 0.143341] [G loss: 0.631087]\n",
      "[Epoch 4/200] [Batch 308/637] [D loss: 0.163577] [G loss: 0.548051]\n",
      "[Epoch 4/200] [Batch 309/637] [D loss: 0.145933] [G loss: 0.507816]\n",
      "[Epoch 4/200] [Batch 310/637] [D loss: 0.140735] [G loss: 0.554813]\n",
      "[Epoch 4/200] [Batch 311/637] [D loss: 0.168936] [G loss: 0.604357]\n",
      "[Epoch 4/200] [Batch 312/637] [D loss: 0.151953] [G loss: 0.526016]\n",
      "[Epoch 4/200] [Batch 313/637] [D loss: 0.140571] [G loss: 0.577832]\n",
      "[Epoch 4/200] [Batch 314/637] [D loss: 0.136344] [G loss: 0.574059]\n",
      "[Epoch 4/200] [Batch 315/637] [D loss: 0.168608] [G loss: 0.428796]\n",
      "[Epoch 4/200] [Batch 316/637] [D loss: 0.179715] [G loss: 0.594864]\n",
      "[Epoch 4/200] [Batch 317/637] [D loss: 0.141971] [G loss: 0.651291]\n",
      "[Epoch 4/200] [Batch 318/637] [D loss: 0.165741] [G loss: 0.530719]\n",
      "[Epoch 4/200] [Batch 319/637] [D loss: 0.202221] [G loss: 0.497571]\n",
      "[Epoch 4/200] [Batch 320/637] [D loss: 0.142864] [G loss: 0.487857]\n",
      "[Epoch 4/200] [Batch 321/637] [D loss: 0.154692] [G loss: 0.519386]\n",
      "[Epoch 4/200] [Batch 322/637] [D loss: 0.141309] [G loss: 0.540316]\n",
      "[Epoch 4/200] [Batch 323/637] [D loss: 0.159516] [G loss: 0.528941]\n",
      "[Epoch 4/200] [Batch 324/637] [D loss: 0.141627] [G loss: 0.513194]\n",
      "[Epoch 4/200] [Batch 325/637] [D loss: 0.137284] [G loss: 0.506328]\n",
      "[Epoch 4/200] [Batch 326/637] [D loss: 0.147068] [G loss: 0.582709]\n",
      "[Epoch 4/200] [Batch 327/637] [D loss: 0.140042] [G loss: 0.521665]\n",
      "[Epoch 4/200] [Batch 328/637] [D loss: 0.126420] [G loss: 0.494651]\n",
      "[Epoch 4/200] [Batch 329/637] [D loss: 0.167228] [G loss: 0.422295]\n",
      "[Epoch 4/200] [Batch 330/637] [D loss: 0.172620] [G loss: 0.506646]\n",
      "[Epoch 4/200] [Batch 331/637] [D loss: 0.158360] [G loss: 0.614088]\n",
      "[Epoch 4/200] [Batch 332/637] [D loss: 0.155594] [G loss: 0.524296]\n",
      "[Epoch 4/200] [Batch 333/637] [D loss: 0.129024] [G loss: 0.518004]\n",
      "[Epoch 4/200] [Batch 334/637] [D loss: 0.132220] [G loss: 0.467233]\n",
      "[Epoch 4/200] [Batch 335/637] [D loss: 0.127836] [G loss: 0.549944]\n",
      "[Epoch 4/200] [Batch 336/637] [D loss: 0.129798] [G loss: 0.565718]\n",
      "[Epoch 4/200] [Batch 337/637] [D loss: 0.133254] [G loss: 0.516214]\n",
      "[Epoch 4/200] [Batch 338/637] [D loss: 0.122662] [G loss: 0.496510]\n",
      "[Epoch 4/200] [Batch 339/637] [D loss: 0.156792] [G loss: 0.495230]\n",
      "[Epoch 4/200] [Batch 340/637] [D loss: 0.123889] [G loss: 0.518920]\n",
      "[Epoch 4/200] [Batch 341/637] [D loss: 0.147135] [G loss: 0.501527]\n",
      "[Epoch 4/200] [Batch 342/637] [D loss: 0.189874] [G loss: 0.641268]\n",
      "[Epoch 4/200] [Batch 343/637] [D loss: 0.148288] [G loss: 0.585222]\n",
      "[Epoch 4/200] [Batch 344/637] [D loss: 0.145748] [G loss: 0.523723]\n",
      "[Epoch 4/200] [Batch 345/637] [D loss: 0.129439] [G loss: 0.587428]\n",
      "[Epoch 4/200] [Batch 346/637] [D loss: 0.143613] [G loss: 0.508139]\n",
      "[Epoch 4/200] [Batch 347/637] [D loss: 0.170595] [G loss: 0.518839]\n",
      "[Epoch 4/200] [Batch 348/637] [D loss: 0.156449] [G loss: 0.614383]\n",
      "[Epoch 4/200] [Batch 349/637] [D loss: 0.138672] [G loss: 0.640445]\n",
      "[Epoch 4/200] [Batch 350/637] [D loss: 0.140775] [G loss: 0.560809]\n",
      "[Epoch 4/200] [Batch 351/637] [D loss: 0.137534] [G loss: 0.528658]\n",
      "[Epoch 4/200] [Batch 352/637] [D loss: 0.128445] [G loss: 0.541384]\n",
      "[Epoch 4/200] [Batch 353/637] [D loss: 0.138630] [G loss: 0.605819]\n",
      "[Epoch 4/200] [Batch 354/637] [D loss: 0.137654] [G loss: 0.551213]\n",
      "[Epoch 4/200] [Batch 355/637] [D loss: 0.151031] [G loss: 0.555368]\n",
      "[Epoch 4/200] [Batch 356/637] [D loss: 0.126432] [G loss: 0.550621]\n",
      "[Epoch 4/200] [Batch 357/637] [D loss: 0.148244] [G loss: 0.529571]\n",
      "[Epoch 4/200] [Batch 358/637] [D loss: 0.143176] [G loss: 0.502980]\n",
      "[Epoch 4/200] [Batch 359/637] [D loss: 0.166415] [G loss: 0.564007]\n",
      "[Epoch 4/200] [Batch 360/637] [D loss: 0.158634] [G loss: 0.656225]\n",
      "[Epoch 4/200] [Batch 361/637] [D loss: 0.159063] [G loss: 0.515528]\n",
      "[Epoch 4/200] [Batch 362/637] [D loss: 0.242990] [G loss: 0.565471]\n",
      "[Epoch 4/200] [Batch 363/637] [D loss: 0.165449] [G loss: 0.634011]\n",
      "[Epoch 4/200] [Batch 364/637] [D loss: 0.160574] [G loss: 0.563033]\n",
      "[Epoch 4/200] [Batch 365/637] [D loss: 0.135020] [G loss: 0.555144]\n",
      "[Epoch 4/200] [Batch 366/637] [D loss: 0.144727] [G loss: 0.501062]\n",
      "[Epoch 4/200] [Batch 367/637] [D loss: 0.128175] [G loss: 0.536466]\n",
      "[Epoch 4/200] [Batch 368/637] [D loss: 0.124766] [G loss: 0.551301]\n",
      "[Epoch 4/200] [Batch 369/637] [D loss: 0.118730] [G loss: 0.586413]\n",
      "[Epoch 4/200] [Batch 370/637] [D loss: 0.139485] [G loss: 0.556562]\n",
      "[Epoch 4/200] [Batch 371/637] [D loss: 0.134672] [G loss: 0.527897]\n",
      "[Epoch 4/200] [Batch 372/637] [D loss: 0.144585] [G loss: 0.544024]\n",
      "[Epoch 4/200] [Batch 373/637] [D loss: 0.123208] [G loss: 0.599349]\n",
      "[Epoch 4/200] [Batch 374/637] [D loss: 0.144292] [G loss: 0.509172]\n",
      "[Epoch 4/200] [Batch 375/637] [D loss: 0.145772] [G loss: 0.485080]\n",
      "[Epoch 4/200] [Batch 376/637] [D loss: 0.135937] [G loss: 0.543067]\n",
      "[Epoch 4/200] [Batch 377/637] [D loss: 0.124394] [G loss: 0.601229]\n",
      "[Epoch 4/200] [Batch 378/637] [D loss: 0.147947] [G loss: 0.623219]\n",
      "[Epoch 4/200] [Batch 379/637] [D loss: 0.168263] [G loss: 0.508353]\n",
      "[Epoch 4/200] [Batch 380/637] [D loss: 0.204878] [G loss: 0.488494]\n",
      "[Epoch 4/200] [Batch 381/637] [D loss: 0.168616] [G loss: 0.631209]\n",
      "[Epoch 4/200] [Batch 382/637] [D loss: 0.164383] [G loss: 0.616253]\n",
      "[Epoch 4/200] [Batch 383/637] [D loss: 0.161848] [G loss: 0.535179]\n",
      "[Epoch 4/200] [Batch 384/637] [D loss: 0.156799] [G loss: 0.435364]\n",
      "[Epoch 4/200] [Batch 385/637] [D loss: 0.142938] [G loss: 0.502084]\n",
      "[Epoch 4/200] [Batch 386/637] [D loss: 0.143445] [G loss: 0.541088]\n",
      "[Epoch 4/200] [Batch 387/637] [D loss: 0.163649] [G loss: 0.580122]\n",
      "[Epoch 4/200] [Batch 388/637] [D loss: 0.136803] [G loss: 0.580947]\n",
      "[Epoch 4/200] [Batch 389/637] [D loss: 0.226482] [G loss: 0.431244]\n",
      "[Epoch 4/200] [Batch 390/637] [D loss: 0.223999] [G loss: 0.610294]\n",
      "[Epoch 4/200] [Batch 391/637] [D loss: 0.156047] [G loss: 0.665830]\n",
      "[Epoch 4/200] [Batch 392/637] [D loss: 0.169866] [G loss: 0.587474]\n",
      "[Epoch 4/200] [Batch 393/637] [D loss: 0.158046] [G loss: 0.474272]\n",
      "[Epoch 4/200] [Batch 394/637] [D loss: 0.134663] [G loss: 0.486771]\n",
      "[Epoch 4/200] [Batch 395/637] [D loss: 0.138707] [G loss: 0.488188]\n",
      "[Epoch 4/200] [Batch 396/637] [D loss: 0.117111] [G loss: 0.550790]\n",
      "[Epoch 4/200] [Batch 397/637] [D loss: 0.125817] [G loss: 0.534686]\n",
      "[Epoch 4/200] [Batch 398/637] [D loss: 0.140364] [G loss: 0.529133]\n",
      "[Epoch 4/200] [Batch 399/637] [D loss: 0.130489] [G loss: 0.651229]\n",
      "[Epoch 4/200] [Batch 400/637] [D loss: 0.148022] [G loss: 0.616444]\n",
      "[Epoch 4/200] [Batch 401/637] [D loss: 0.180811] [G loss: 0.507565]\n",
      "[Epoch 4/200] [Batch 402/637] [D loss: 0.152963] [G loss: 0.517933]\n",
      "[Epoch 4/200] [Batch 403/637] [D loss: 0.159913] [G loss: 0.520651]\n",
      "[Epoch 4/200] [Batch 404/637] [D loss: 0.145820] [G loss: 0.473456]\n",
      "[Epoch 4/200] [Batch 405/637] [D loss: 0.144516] [G loss: 0.465391]\n",
      "[Epoch 4/200] [Batch 406/637] [D loss: 0.145095] [G loss: 0.512259]\n",
      "[Epoch 4/200] [Batch 407/637] [D loss: 0.142242] [G loss: 0.539457]\n",
      "[Epoch 4/200] [Batch 408/637] [D loss: 0.135989] [G loss: 0.542844]\n",
      "[Epoch 4/200] [Batch 409/637] [D loss: 0.143681] [G loss: 0.547172]\n",
      "[Epoch 4/200] [Batch 410/637] [D loss: 0.135970] [G loss: 0.507627]\n",
      "[Epoch 4/200] [Batch 411/637] [D loss: 0.130701] [G loss: 0.514185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 412/637] [D loss: 0.116742] [G loss: 0.566712]\n",
      "[Epoch 4/200] [Batch 413/637] [D loss: 0.146640] [G loss: 0.630919]\n",
      "[Epoch 4/200] [Batch 414/637] [D loss: 0.137600] [G loss: 0.534524]\n",
      "[Epoch 4/200] [Batch 415/637] [D loss: 0.169377] [G loss: 0.455633]\n",
      "[Epoch 4/200] [Batch 416/637] [D loss: 0.167734] [G loss: 0.701059]\n",
      "[Epoch 4/200] [Batch 417/637] [D loss: 0.137316] [G loss: 0.700520]\n",
      "[Epoch 4/200] [Batch 418/637] [D loss: 0.172882] [G loss: 0.540795]\n",
      "[Epoch 4/200] [Batch 419/637] [D loss: 0.150394] [G loss: 0.600043]\n",
      "[Epoch 4/200] [Batch 420/637] [D loss: 0.183629] [G loss: 0.529534]\n",
      "[Epoch 4/200] [Batch 421/637] [D loss: 0.174882] [G loss: 0.468886]\n",
      "[Epoch 4/200] [Batch 422/637] [D loss: 0.168390] [G loss: 0.539692]\n",
      "[Epoch 4/200] [Batch 423/637] [D loss: 0.140141] [G loss: 0.503406]\n",
      "[Epoch 4/200] [Batch 424/637] [D loss: 0.154552] [G loss: 0.558311]\n",
      "[Epoch 4/200] [Batch 425/637] [D loss: 0.149749] [G loss: 0.598382]\n",
      "[Epoch 4/200] [Batch 426/637] [D loss: 0.117607] [G loss: 0.600959]\n",
      "[Epoch 4/200] [Batch 427/637] [D loss: 0.156213] [G loss: 0.631212]\n",
      "[Epoch 4/200] [Batch 428/637] [D loss: 0.177579] [G loss: 0.582212]\n",
      "[Epoch 4/200] [Batch 429/637] [D loss: 0.142827] [G loss: 0.606968]\n",
      "[Epoch 4/200] [Batch 430/637] [D loss: 0.132072] [G loss: 0.647936]\n",
      "[Epoch 4/200] [Batch 431/637] [D loss: 0.139340] [G loss: 0.514545]\n",
      "[Epoch 4/200] [Batch 432/637] [D loss: 0.151873] [G loss: 0.566115]\n",
      "[Epoch 4/200] [Batch 433/637] [D loss: 0.142916] [G loss: 0.633281]\n",
      "[Epoch 4/200] [Batch 434/637] [D loss: 0.135409] [G loss: 0.578855]\n",
      "[Epoch 4/200] [Batch 435/637] [D loss: 0.150164] [G loss: 0.579343]\n",
      "[Epoch 4/200] [Batch 436/637] [D loss: 0.152446] [G loss: 0.529859]\n",
      "[Epoch 4/200] [Batch 437/637] [D loss: 0.159190] [G loss: 0.560454]\n",
      "[Epoch 4/200] [Batch 438/637] [D loss: 0.130302] [G loss: 0.595738]\n",
      "[Epoch 4/200] [Batch 439/637] [D loss: 0.159880] [G loss: 0.519519]\n",
      "[Epoch 4/200] [Batch 440/637] [D loss: 0.185524] [G loss: 0.635988]\n",
      "[Epoch 4/200] [Batch 441/637] [D loss: 0.138544] [G loss: 0.657322]\n",
      "[Epoch 4/200] [Batch 442/637] [D loss: 0.155348] [G loss: 0.581224]\n",
      "[Epoch 4/200] [Batch 443/637] [D loss: 0.153362] [G loss: 0.458337]\n",
      "[Epoch 4/200] [Batch 444/637] [D loss: 0.150213] [G loss: 0.539146]\n",
      "[Epoch 4/200] [Batch 445/637] [D loss: 0.162396] [G loss: 0.527641]\n",
      "[Epoch 4/200] [Batch 446/637] [D loss: 0.156394] [G loss: 0.532822]\n",
      "[Epoch 4/200] [Batch 447/637] [D loss: 0.152275] [G loss: 0.540050]\n",
      "[Epoch 4/200] [Batch 448/637] [D loss: 0.149460] [G loss: 0.545182]\n",
      "[Epoch 4/200] [Batch 449/637] [D loss: 0.124792] [G loss: 0.569270]\n",
      "[Epoch 4/200] [Batch 450/637] [D loss: 0.127861] [G loss: 0.540869]\n",
      "[Epoch 4/200] [Batch 451/637] [D loss: 0.141148] [G loss: 0.562648]\n",
      "[Epoch 4/200] [Batch 452/637] [D loss: 0.209758] [G loss: 0.611625]\n",
      "[Epoch 4/200] [Batch 453/637] [D loss: 0.165155] [G loss: 0.662001]\n",
      "[Epoch 4/200] [Batch 454/637] [D loss: 0.141672] [G loss: 0.569712]\n",
      "[Epoch 4/200] [Batch 455/637] [D loss: 0.134386] [G loss: 0.451791]\n",
      "[Epoch 4/200] [Batch 456/637] [D loss: 0.142164] [G loss: 0.484119]\n",
      "[Epoch 4/200] [Batch 457/637] [D loss: 0.126135] [G loss: 0.532492]\n",
      "[Epoch 4/200] [Batch 458/637] [D loss: 0.138223] [G loss: 0.530383]\n",
      "[Epoch 4/200] [Batch 459/637] [D loss: 0.146124] [G loss: 0.515337]\n",
      "[Epoch 4/200] [Batch 460/637] [D loss: 0.144353] [G loss: 0.584256]\n",
      "[Epoch 4/200] [Batch 461/637] [D loss: 0.153551] [G loss: 0.637058]\n",
      "[Epoch 4/200] [Batch 462/637] [D loss: 0.131988] [G loss: 0.597569]\n",
      "[Epoch 4/200] [Batch 463/637] [D loss: 0.137729] [G loss: 0.516341]\n",
      "[Epoch 4/200] [Batch 464/637] [D loss: 0.127589] [G loss: 0.493863]\n",
      "[Epoch 4/200] [Batch 465/637] [D loss: 0.127680] [G loss: 0.544635]\n",
      "[Epoch 4/200] [Batch 466/637] [D loss: 0.127303] [G loss: 0.491890]\n",
      "[Epoch 4/200] [Batch 467/637] [D loss: 0.141148] [G loss: 0.579511]\n",
      "[Epoch 4/200] [Batch 468/637] [D loss: 0.167794] [G loss: 0.505138]\n",
      "[Epoch 4/200] [Batch 469/637] [D loss: 0.166391] [G loss: 0.698541]\n",
      "[Epoch 4/200] [Batch 470/637] [D loss: 0.141286] [G loss: 0.588058]\n",
      "[Epoch 4/200] [Batch 471/637] [D loss: 0.191159] [G loss: 0.491338]\n",
      "[Epoch 4/200] [Batch 472/637] [D loss: 0.190470] [G loss: 0.556140]\n",
      "[Epoch 4/200] [Batch 473/637] [D loss: 0.156024] [G loss: 0.626774]\n",
      "[Epoch 4/200] [Batch 474/637] [D loss: 0.168743] [G loss: 0.590891]\n",
      "[Epoch 4/200] [Batch 475/637] [D loss: 0.137138] [G loss: 0.525940]\n",
      "[Epoch 4/200] [Batch 476/637] [D loss: 0.143585] [G loss: 0.549169]\n",
      "[Epoch 4/200] [Batch 477/637] [D loss: 0.123407] [G loss: 0.567547]\n",
      "[Epoch 4/200] [Batch 478/637] [D loss: 0.197940] [G loss: 0.489631]\n",
      "[Epoch 4/200] [Batch 479/637] [D loss: 0.214268] [G loss: 0.631741]\n",
      "[Epoch 4/200] [Batch 480/637] [D loss: 0.144753] [G loss: 0.637416]\n",
      "[Epoch 4/200] [Batch 481/637] [D loss: 0.145742] [G loss: 0.525551]\n",
      "[Epoch 4/200] [Batch 482/637] [D loss: 0.158841] [G loss: 0.460136]\n",
      "[Epoch 4/200] [Batch 483/637] [D loss: 0.158032] [G loss: 0.527240]\n",
      "[Epoch 4/200] [Batch 484/637] [D loss: 0.151099] [G loss: 0.514734]\n",
      "[Epoch 4/200] [Batch 485/637] [D loss: 0.143762] [G loss: 0.520232]\n",
      "[Epoch 4/200] [Batch 486/637] [D loss: 0.148195] [G loss: 0.551704]\n",
      "[Epoch 4/200] [Batch 487/637] [D loss: 0.140982] [G loss: 0.540837]\n",
      "[Epoch 4/200] [Batch 488/637] [D loss: 0.124524] [G loss: 0.500058]\n",
      "[Epoch 4/200] [Batch 489/637] [D loss: 0.146771] [G loss: 0.488469]\n",
      "[Epoch 4/200] [Batch 490/637] [D loss: 0.146291] [G loss: 0.525479]\n",
      "[Epoch 4/200] [Batch 491/637] [D loss: 0.150151] [G loss: 0.510962]\n",
      "[Epoch 4/200] [Batch 492/637] [D loss: 0.125902] [G loss: 0.595210]\n",
      "[Epoch 4/200] [Batch 493/637] [D loss: 0.140602] [G loss: 0.575106]\n",
      "[Epoch 4/200] [Batch 494/637] [D loss: 0.152930] [G loss: 0.528766]\n",
      "[Epoch 4/200] [Batch 495/637] [D loss: 0.146605] [G loss: 0.523864]\n",
      "[Epoch 4/200] [Batch 496/637] [D loss: 0.142522] [G loss: 0.533854]\n",
      "[Epoch 4/200] [Batch 497/637] [D loss: 0.152554] [G loss: 0.551728]\n",
      "[Epoch 4/200] [Batch 498/637] [D loss: 0.136662] [G loss: 0.523567]\n",
      "[Epoch 4/200] [Batch 499/637] [D loss: 0.127178] [G loss: 0.519520]\n",
      "[Epoch 4/200] [Batch 500/637] [D loss: 0.134279] [G loss: 0.586035]\n",
      "[Epoch 4/200] [Batch 501/637] [D loss: 0.146201] [G loss: 0.497494]\n",
      "[Epoch 4/200] [Batch 502/637] [D loss: 0.153873] [G loss: 0.626469]\n",
      "[Epoch 4/200] [Batch 503/637] [D loss: 0.146251] [G loss: 0.600117]\n",
      "[Epoch 4/200] [Batch 504/637] [D loss: 0.152323] [G loss: 0.520542]\n",
      "[Epoch 4/200] [Batch 505/637] [D loss: 0.161051] [G loss: 0.507976]\n",
      "[Epoch 4/200] [Batch 506/637] [D loss: 0.166345] [G loss: 0.541692]\n",
      "[Epoch 4/200] [Batch 507/637] [D loss: 0.146544] [G loss: 0.537465]\n",
      "[Epoch 4/200] [Batch 508/637] [D loss: 0.143989] [G loss: 0.504017]\n",
      "[Epoch 4/200] [Batch 509/637] [D loss: 0.136564] [G loss: 0.553989]\n",
      "[Epoch 4/200] [Batch 510/637] [D loss: 0.151509] [G loss: 0.524047]\n",
      "[Epoch 4/200] [Batch 511/637] [D loss: 0.139828] [G loss: 0.519715]\n",
      "[Epoch 4/200] [Batch 512/637] [D loss: 0.155113] [G loss: 0.495729]\n",
      "[Epoch 4/200] [Batch 513/637] [D loss: 0.138231] [G loss: 0.498267]\n",
      "[Epoch 4/200] [Batch 514/637] [D loss: 0.148438] [G loss: 0.551627]\n",
      "[Epoch 4/200] [Batch 515/637] [D loss: 0.149038] [G loss: 0.563608]\n",
      "[Epoch 4/200] [Batch 516/637] [D loss: 0.161911] [G loss: 0.630011]\n",
      "[Epoch 4/200] [Batch 517/637] [D loss: 0.139833] [G loss: 0.535425]\n",
      "[Epoch 4/200] [Batch 518/637] [D loss: 0.149533] [G loss: 0.561403]\n",
      "[Epoch 4/200] [Batch 519/637] [D loss: 0.154266] [G loss: 0.574459]\n",
      "[Epoch 4/200] [Batch 520/637] [D loss: 0.196527] [G loss: 0.584901]\n",
      "[Epoch 4/200] [Batch 521/637] [D loss: 0.321843] [G loss: 0.861365]\n",
      "[Epoch 4/200] [Batch 522/637] [D loss: 0.210895] [G loss: 0.690428]\n",
      "[Epoch 4/200] [Batch 523/637] [D loss: 0.172337] [G loss: 0.578409]\n",
      "[Epoch 4/200] [Batch 524/637] [D loss: 0.139983] [G loss: 0.552861]\n",
      "[Epoch 4/200] [Batch 525/637] [D loss: 0.154696] [G loss: 0.484239]\n",
      "[Epoch 4/200] [Batch 526/637] [D loss: 0.147885] [G loss: 0.457483]\n",
      "[Epoch 4/200] [Batch 527/637] [D loss: 0.139452] [G loss: 0.434188]\n",
      "[Epoch 4/200] [Batch 528/637] [D loss: 0.143165] [G loss: 0.476584]\n",
      "[Epoch 4/200] [Batch 529/637] [D loss: 0.115364] [G loss: 0.587532]\n",
      "[Epoch 4/200] [Batch 530/637] [D loss: 0.138204] [G loss: 0.582687]\n",
      "[Epoch 4/200] [Batch 531/637] [D loss: 0.118962] [G loss: 0.549035]\n",
      "[Epoch 4/200] [Batch 532/637] [D loss: 0.142739] [G loss: 0.532305]\n",
      "[Epoch 4/200] [Batch 533/637] [D loss: 0.168671] [G loss: 0.448231]\n",
      "[Epoch 4/200] [Batch 534/637] [D loss: 0.181894] [G loss: 0.634474]\n",
      "[Epoch 4/200] [Batch 535/637] [D loss: 0.153515] [G loss: 0.605824]\n",
      "[Epoch 4/200] [Batch 536/637] [D loss: 0.164048] [G loss: 0.507940]\n",
      "[Epoch 4/200] [Batch 537/637] [D loss: 0.148973] [G loss: 0.479623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 538/637] [D loss: 0.144394] [G loss: 0.517726]\n",
      "[Epoch 4/200] [Batch 539/637] [D loss: 0.157376] [G loss: 0.476366]\n",
      "[Epoch 4/200] [Batch 540/637] [D loss: 0.158352] [G loss: 0.520368]\n",
      "[Epoch 4/200] [Batch 541/637] [D loss: 0.141040] [G loss: 0.572521]\n",
      "[Epoch 4/200] [Batch 542/637] [D loss: 0.151186] [G loss: 0.519947]\n",
      "[Epoch 4/200] [Batch 543/637] [D loss: 0.141278] [G loss: 0.542883]\n",
      "[Epoch 4/200] [Batch 544/637] [D loss: 0.142605] [G loss: 0.505390]\n",
      "[Epoch 4/200] [Batch 545/637] [D loss: 0.148645] [G loss: 0.520249]\n",
      "[Epoch 4/200] [Batch 546/637] [D loss: 0.140741] [G loss: 0.474512]\n",
      "[Epoch 4/200] [Batch 547/637] [D loss: 0.127969] [G loss: 0.516255]\n",
      "[Epoch 4/200] [Batch 548/637] [D loss: 0.127680] [G loss: 0.630358]\n",
      "[Epoch 4/200] [Batch 549/637] [D loss: 0.136816] [G loss: 0.659557]\n",
      "[Epoch 4/200] [Batch 550/637] [D loss: 0.129175] [G loss: 0.482818]\n",
      "[Epoch 4/200] [Batch 551/637] [D loss: 0.158396] [G loss: 0.430015]\n",
      "[Epoch 4/200] [Batch 552/637] [D loss: 0.187944] [G loss: 0.549809]\n",
      "[Epoch 4/200] [Batch 553/637] [D loss: 0.169801] [G loss: 0.593420]\n",
      "[Epoch 4/200] [Batch 554/637] [D loss: 0.183828] [G loss: 0.640757]\n",
      "[Epoch 4/200] [Batch 555/637] [D loss: 0.170511] [G loss: 0.498354]\n",
      "[Epoch 4/200] [Batch 556/637] [D loss: 0.200454] [G loss: 0.558774]\n",
      "[Epoch 4/200] [Batch 557/637] [D loss: 0.146885] [G loss: 0.547344]\n",
      "[Epoch 4/200] [Batch 558/637] [D loss: 0.158349] [G loss: 0.499121]\n",
      "[Epoch 4/200] [Batch 559/637] [D loss: 0.161333] [G loss: 0.484217]\n",
      "[Epoch 4/200] [Batch 560/637] [D loss: 0.142292] [G loss: 0.501354]\n",
      "[Epoch 4/200] [Batch 561/637] [D loss: 0.132032] [G loss: 0.608385]\n",
      "[Epoch 4/200] [Batch 562/637] [D loss: 0.140402] [G loss: 0.599729]\n",
      "[Epoch 4/200] [Batch 563/637] [D loss: 0.136109] [G loss: 0.485611]\n",
      "[Epoch 4/200] [Batch 564/637] [D loss: 0.136357] [G loss: 0.594587]\n",
      "[Epoch 4/200] [Batch 565/637] [D loss: 0.169695] [G loss: 0.611085]\n",
      "[Epoch 4/200] [Batch 566/637] [D loss: 0.149545] [G loss: 0.499984]\n",
      "[Epoch 4/200] [Batch 567/637] [D loss: 0.142638] [G loss: 0.568624]\n",
      "[Epoch 4/200] [Batch 568/637] [D loss: 0.156334] [G loss: 0.504166]\n",
      "[Epoch 4/200] [Batch 569/637] [D loss: 0.173443] [G loss: 0.533970]\n",
      "[Epoch 4/200] [Batch 570/637] [D loss: 0.235756] [G loss: 0.778957]\n",
      "[Epoch 4/200] [Batch 571/637] [D loss: 0.180189] [G loss: 0.558791]\n",
      "[Epoch 4/200] [Batch 572/637] [D loss: 0.178339] [G loss: 0.473348]\n",
      "[Epoch 4/200] [Batch 573/637] [D loss: 0.157282] [G loss: 0.489204]\n",
      "[Epoch 4/200] [Batch 574/637] [D loss: 0.147799] [G loss: 0.600717]\n",
      "[Epoch 4/200] [Batch 575/637] [D loss: 0.160937] [G loss: 0.542145]\n",
      "[Epoch 4/200] [Batch 576/637] [D loss: 0.175005] [G loss: 0.495865]\n",
      "[Epoch 4/200] [Batch 577/637] [D loss: 0.171877] [G loss: 0.484868]\n",
      "[Epoch 4/200] [Batch 578/637] [D loss: 0.146505] [G loss: 0.598843]\n",
      "[Epoch 4/200] [Batch 579/637] [D loss: 0.136981] [G loss: 0.634786]\n",
      "[Epoch 4/200] [Batch 580/637] [D loss: 0.243132] [G loss: 0.410638]\n",
      "[Epoch 4/200] [Batch 581/637] [D loss: 0.320613] [G loss: 0.617381]\n",
      "[Epoch 4/200] [Batch 582/637] [D loss: 0.220691] [G loss: 0.740630]\n",
      "[Epoch 4/200] [Batch 583/637] [D loss: 0.211679] [G loss: 0.587858]\n",
      "[Epoch 4/200] [Batch 584/637] [D loss: 0.214120] [G loss: 0.437213]\n",
      "[Epoch 4/200] [Batch 585/637] [D loss: 0.180592] [G loss: 0.497676]\n",
      "[Epoch 4/200] [Batch 586/637] [D loss: 0.180480] [G loss: 0.450947]\n",
      "[Epoch 4/200] [Batch 587/637] [D loss: 0.176247] [G loss: 0.446240]\n",
      "[Epoch 4/200] [Batch 588/637] [D loss: 0.165983] [G loss: 0.440277]\n",
      "[Epoch 4/200] [Batch 589/637] [D loss: 0.156328] [G loss: 0.505744]\n",
      "[Epoch 4/200] [Batch 590/637] [D loss: 0.166087] [G loss: 0.481800]\n",
      "[Epoch 4/200] [Batch 591/637] [D loss: 0.124213] [G loss: 0.577054]\n",
      "[Epoch 4/200] [Batch 592/637] [D loss: 0.158062] [G loss: 0.480291]\n",
      "[Epoch 4/200] [Batch 593/637] [D loss: 0.144047] [G loss: 0.500983]\n",
      "[Epoch 4/200] [Batch 594/637] [D loss: 0.159098] [G loss: 0.552121]\n",
      "[Epoch 4/200] [Batch 595/637] [D loss: 0.146925] [G loss: 0.566853]\n",
      "[Epoch 4/200] [Batch 596/637] [D loss: 0.184071] [G loss: 0.468184]\n",
      "[Epoch 4/200] [Batch 597/637] [D loss: 0.155468] [G loss: 0.581515]\n",
      "[Epoch 4/200] [Batch 598/637] [D loss: 0.166498] [G loss: 0.521774]\n",
      "[Epoch 4/200] [Batch 599/637] [D loss: 0.155863] [G loss: 0.497737]\n",
      "[Epoch 4/200] [Batch 600/637] [D loss: 0.171816] [G loss: 0.490838]\n",
      "[Epoch 4/200] [Batch 601/637] [D loss: 0.144034] [G loss: 0.553718]\n",
      "[Epoch 4/200] [Batch 602/637] [D loss: 0.151066] [G loss: 0.514222]\n",
      "[Epoch 4/200] [Batch 603/637] [D loss: 0.163661] [G loss: 0.554970]\n",
      "[Epoch 4/200] [Batch 604/637] [D loss: 0.122679] [G loss: 0.606039]\n",
      "[Epoch 4/200] [Batch 605/637] [D loss: 0.136071] [G loss: 0.495232]\n",
      "[Epoch 4/200] [Batch 606/637] [D loss: 0.142847] [G loss: 0.559174]\n",
      "[Epoch 4/200] [Batch 607/637] [D loss: 0.132117] [G loss: 0.522274]\n",
      "[Epoch 4/200] [Batch 608/637] [D loss: 0.134563] [G loss: 0.474234]\n",
      "[Epoch 4/200] [Batch 609/637] [D loss: 0.151970] [G loss: 0.700083]\n",
      "[Epoch 4/200] [Batch 610/637] [D loss: 0.137652] [G loss: 0.681862]\n",
      "[Epoch 4/200] [Batch 611/637] [D loss: 0.137620] [G loss: 0.555162]\n",
      "[Epoch 4/200] [Batch 612/637] [D loss: 0.164373] [G loss: 0.516501]\n",
      "[Epoch 4/200] [Batch 613/637] [D loss: 0.134639] [G loss: 0.543914]\n",
      "[Epoch 4/200] [Batch 614/637] [D loss: 0.154721] [G loss: 0.506396]\n",
      "[Epoch 4/200] [Batch 615/637] [D loss: 0.190635] [G loss: 0.613996]\n",
      "[Epoch 4/200] [Batch 616/637] [D loss: 0.166315] [G loss: 0.514913]\n",
      "[Epoch 4/200] [Batch 617/637] [D loss: 0.160803] [G loss: 0.556011]\n",
      "[Epoch 4/200] [Batch 618/637] [D loss: 0.183033] [G loss: 0.398292]\n",
      "[Epoch 4/200] [Batch 619/637] [D loss: 0.186819] [G loss: 0.560252]\n",
      "[Epoch 4/200] [Batch 620/637] [D loss: 0.148668] [G loss: 0.611862]\n",
      "[Epoch 4/200] [Batch 621/637] [D loss: 0.146083] [G loss: 0.569933]\n",
      "[Epoch 4/200] [Batch 622/637] [D loss: 0.140948] [G loss: 0.497905]\n",
      "[Epoch 4/200] [Batch 623/637] [D loss: 0.144540] [G loss: 0.513584]\n",
      "[Epoch 4/200] [Batch 624/637] [D loss: 0.123185] [G loss: 0.569830]\n",
      "[Epoch 4/200] [Batch 625/637] [D loss: 0.132910] [G loss: 0.596923]\n",
      "[Epoch 4/200] [Batch 626/637] [D loss: 0.133861] [G loss: 0.600757]\n",
      "[Epoch 4/200] [Batch 627/637] [D loss: 0.122092] [G loss: 0.584908]\n",
      "[Epoch 4/200] [Batch 628/637] [D loss: 0.128817] [G loss: 0.528268]\n",
      "[Epoch 4/200] [Batch 629/637] [D loss: 0.151510] [G loss: 0.598524]\n",
      "[Epoch 4/200] [Batch 630/637] [D loss: 0.097115] [G loss: 0.591743]\n",
      "[Epoch 4/200] [Batch 631/637] [D loss: 0.144468] [G loss: 0.590561]\n",
      "[Epoch 4/200] [Batch 632/637] [D loss: 0.125566] [G loss: 0.580745]\n",
      "[Epoch 4/200] [Batch 633/637] [D loss: 0.123626] [G loss: 0.658244]\n",
      "[Epoch 4/200] [Batch 634/637] [D loss: 0.147132] [G loss: 0.544028]\n",
      "[Epoch 4/200] [Batch 635/637] [D loss: 0.169920] [G loss: 0.569641]\n",
      "[Epoch 4/200] [Batch 636/637] [D loss: 0.159988] [G loss: 0.644885]\n",
      "[Epoch 5/200] [Batch 0/637] [D loss: 0.128911] [G loss: 0.531678]\n",
      "[Epoch 5/200] [Batch 1/637] [D loss: 0.161355] [G loss: 0.481545]\n",
      "[Epoch 5/200] [Batch 2/637] [D loss: 0.141718] [G loss: 0.547682]\n",
      "[Epoch 5/200] [Batch 3/637] [D loss: 0.142001] [G loss: 0.512117]\n",
      "[Epoch 5/200] [Batch 4/637] [D loss: 0.133512] [G loss: 0.586530]\n",
      "[Epoch 5/200] [Batch 5/637] [D loss: 0.166157] [G loss: 0.514898]\n",
      "[Epoch 5/200] [Batch 6/637] [D loss: 0.164858] [G loss: 0.625082]\n",
      "[Epoch 5/200] [Batch 7/637] [D loss: 0.171913] [G loss: 0.502961]\n",
      "[Epoch 5/200] [Batch 8/637] [D loss: 0.149751] [G loss: 0.493709]\n",
      "[Epoch 5/200] [Batch 9/637] [D loss: 0.140955] [G loss: 0.614686]\n",
      "[Epoch 5/200] [Batch 10/637] [D loss: 0.163660] [G loss: 0.607325]\n",
      "[Epoch 5/200] [Batch 11/637] [D loss: 0.139263] [G loss: 0.571099]\n",
      "[Epoch 5/200] [Batch 12/637] [D loss: 0.153422] [G loss: 0.490106]\n",
      "[Epoch 5/200] [Batch 13/637] [D loss: 0.143892] [G loss: 0.560045]\n",
      "[Epoch 5/200] [Batch 14/637] [D loss: 0.143812] [G loss: 0.604157]\n",
      "[Epoch 5/200] [Batch 15/637] [D loss: 0.137503] [G loss: 0.631186]\n",
      "[Epoch 5/200] [Batch 16/637] [D loss: 0.128601] [G loss: 0.577492]\n",
      "[Epoch 5/200] [Batch 17/637] [D loss: 0.124112] [G loss: 0.589352]\n",
      "[Epoch 5/200] [Batch 18/637] [D loss: 0.151032] [G loss: 0.549160]\n",
      "[Epoch 5/200] [Batch 19/637] [D loss: 0.144400] [G loss: 0.618172]\n",
      "[Epoch 5/200] [Batch 20/637] [D loss: 0.152471] [G loss: 0.521683]\n",
      "[Epoch 5/200] [Batch 21/637] [D loss: 0.134945] [G loss: 0.576909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 22/637] [D loss: 0.135776] [G loss: 0.510956]\n",
      "[Epoch 5/200] [Batch 23/637] [D loss: 0.149962] [G loss: 0.509287]\n",
      "[Epoch 5/200] [Batch 24/637] [D loss: 0.133452] [G loss: 0.555964]\n",
      "[Epoch 5/200] [Batch 25/637] [D loss: 0.142450] [G loss: 0.601958]\n",
      "[Epoch 5/200] [Batch 26/637] [D loss: 0.211294] [G loss: 0.527559]\n",
      "[Epoch 5/200] [Batch 27/637] [D loss: 0.198112] [G loss: 0.571511]\n",
      "[Epoch 5/200] [Batch 28/637] [D loss: 0.144489] [G loss: 0.643166]\n",
      "[Epoch 5/200] [Batch 29/637] [D loss: 0.144880] [G loss: 0.558892]\n",
      "[Epoch 5/200] [Batch 30/637] [D loss: 0.133831] [G loss: 0.514717]\n",
      "[Epoch 5/200] [Batch 31/637] [D loss: 0.135738] [G loss: 0.491815]\n",
      "[Epoch 5/200] [Batch 32/637] [D loss: 0.142902] [G loss: 0.507953]\n",
      "[Epoch 5/200] [Batch 33/637] [D loss: 0.169367] [G loss: 0.518515]\n",
      "[Epoch 5/200] [Batch 34/637] [D loss: 0.185968] [G loss: 0.650748]\n",
      "[Epoch 5/200] [Batch 35/637] [D loss: 0.160229] [G loss: 0.576351]\n",
      "[Epoch 5/200] [Batch 36/637] [D loss: 0.149044] [G loss: 0.520087]\n",
      "[Epoch 5/200] [Batch 37/637] [D loss: 0.146587] [G loss: 0.486793]\n",
      "[Epoch 5/200] [Batch 38/637] [D loss: 0.160135] [G loss: 0.479180]\n",
      "[Epoch 5/200] [Batch 39/637] [D loss: 0.156932] [G loss: 0.534290]\n",
      "[Epoch 5/200] [Batch 40/637] [D loss: 0.129753] [G loss: 0.555939]\n",
      "[Epoch 5/200] [Batch 41/637] [D loss: 0.141531] [G loss: 0.544047]\n",
      "[Epoch 5/200] [Batch 42/637] [D loss: 0.146379] [G loss: 0.554766]\n",
      "[Epoch 5/200] [Batch 43/637] [D loss: 0.154687] [G loss: 0.460459]\n",
      "[Epoch 5/200] [Batch 44/637] [D loss: 0.139646] [G loss: 0.679621]\n",
      "[Epoch 5/200] [Batch 45/637] [D loss: 0.148965] [G loss: 0.612952]\n",
      "[Epoch 5/200] [Batch 46/637] [D loss: 0.130753] [G loss: 0.572045]\n",
      "[Epoch 5/200] [Batch 47/637] [D loss: 0.135084] [G loss: 0.519633]\n",
      "[Epoch 5/200] [Batch 48/637] [D loss: 0.140587] [G loss: 0.524697]\n",
      "[Epoch 5/200] [Batch 49/637] [D loss: 0.165974] [G loss: 0.509713]\n",
      "[Epoch 5/200] [Batch 50/637] [D loss: 0.173127] [G loss: 0.596011]\n",
      "[Epoch 5/200] [Batch 51/637] [D loss: 0.158758] [G loss: 0.652753]\n",
      "[Epoch 5/200] [Batch 52/637] [D loss: 0.134481] [G loss: 0.527452]\n",
      "[Epoch 5/200] [Batch 53/637] [D loss: 0.174107] [G loss: 0.518621]\n",
      "[Epoch 5/200] [Batch 54/637] [D loss: 0.145415] [G loss: 0.483998]\n",
      "[Epoch 5/200] [Batch 55/637] [D loss: 0.151637] [G loss: 0.502196]\n",
      "[Epoch 5/200] [Batch 56/637] [D loss: 0.134355] [G loss: 0.534655]\n",
      "[Epoch 5/200] [Batch 57/637] [D loss: 0.149821] [G loss: 0.528471]\n",
      "[Epoch 5/200] [Batch 58/637] [D loss: 0.146802] [G loss: 0.508674]\n",
      "[Epoch 5/200] [Batch 59/637] [D loss: 0.175510] [G loss: 0.504921]\n",
      "[Epoch 5/200] [Batch 60/637] [D loss: 0.179718] [G loss: 0.711918]\n",
      "[Epoch 5/200] [Batch 61/637] [D loss: 0.137624] [G loss: 0.566309]\n",
      "[Epoch 5/200] [Batch 62/637] [D loss: 0.178062] [G loss: 0.515401]\n",
      "[Epoch 5/200] [Batch 63/637] [D loss: 0.130648] [G loss: 0.515876]\n",
      "[Epoch 5/200] [Batch 64/637] [D loss: 0.151001] [G loss: 0.508210]\n",
      "[Epoch 5/200] [Batch 65/637] [D loss: 0.127318] [G loss: 0.554692]\n",
      "[Epoch 5/200] [Batch 66/637] [D loss: 0.135584] [G loss: 0.595671]\n",
      "[Epoch 5/200] [Batch 67/637] [D loss: 0.120984] [G loss: 0.579213]\n",
      "[Epoch 5/200] [Batch 68/637] [D loss: 0.144824] [G loss: 0.540037]\n",
      "[Epoch 5/200] [Batch 69/637] [D loss: 0.127213] [G loss: 0.555031]\n",
      "[Epoch 5/200] [Batch 70/637] [D loss: 0.150053] [G loss: 0.662887]\n",
      "[Epoch 5/200] [Batch 71/637] [D loss: 0.157411] [G loss: 0.550382]\n",
      "[Epoch 5/200] [Batch 72/637] [D loss: 0.142788] [G loss: 0.514389]\n",
      "[Epoch 5/200] [Batch 73/637] [D loss: 0.123907] [G loss: 0.607742]\n",
      "[Epoch 5/200] [Batch 74/637] [D loss: 0.126297] [G loss: 0.538115]\n",
      "[Epoch 5/200] [Batch 75/637] [D loss: 0.128221] [G loss: 0.515284]\n",
      "[Epoch 5/200] [Batch 76/637] [D loss: 0.119887] [G loss: 0.622676]\n",
      "[Epoch 5/200] [Batch 77/637] [D loss: 0.145790] [G loss: 0.620425]\n",
      "[Epoch 5/200] [Batch 78/637] [D loss: 0.127878] [G loss: 0.653891]\n",
      "[Epoch 5/200] [Batch 79/637] [D loss: 0.150756] [G loss: 0.482594]\n",
      "[Epoch 5/200] [Batch 80/637] [D loss: 0.152498] [G loss: 0.609554]\n",
      "[Epoch 5/200] [Batch 81/637] [D loss: 0.134315] [G loss: 0.565990]\n",
      "[Epoch 5/200] [Batch 82/637] [D loss: 0.142469] [G loss: 0.475024]\n",
      "[Epoch 5/200] [Batch 83/637] [D loss: 0.140264] [G loss: 0.452284]\n",
      "[Epoch 5/200] [Batch 84/637] [D loss: 0.167817] [G loss: 0.537946]\n",
      "[Epoch 5/200] [Batch 85/637] [D loss: 0.134983] [G loss: 0.591919]\n",
      "[Epoch 5/200] [Batch 86/637] [D loss: 0.139078] [G loss: 0.568270]\n",
      "[Epoch 5/200] [Batch 87/637] [D loss: 0.136139] [G loss: 0.511638]\n",
      "[Epoch 5/200] [Batch 88/637] [D loss: 0.171521] [G loss: 0.678192]\n",
      "[Epoch 5/200] [Batch 89/637] [D loss: 0.158696] [G loss: 0.520724]\n",
      "[Epoch 5/200] [Batch 90/637] [D loss: 0.162222] [G loss: 0.495654]\n",
      "[Epoch 5/200] [Batch 91/637] [D loss: 0.146076] [G loss: 0.525267]\n",
      "[Epoch 5/200] [Batch 92/637] [D loss: 0.134415] [G loss: 0.536806]\n",
      "[Epoch 5/200] [Batch 93/637] [D loss: 0.166954] [G loss: 0.487556]\n",
      "[Epoch 5/200] [Batch 94/637] [D loss: 0.141646] [G loss: 0.530530]\n",
      "[Epoch 5/200] [Batch 95/637] [D loss: 0.148606] [G loss: 0.506981]\n",
      "[Epoch 5/200] [Batch 96/637] [D loss: 0.150527] [G loss: 0.464090]\n",
      "[Epoch 5/200] [Batch 97/637] [D loss: 0.137203] [G loss: 0.487084]\n",
      "[Epoch 5/200] [Batch 98/637] [D loss: 0.138019] [G loss: 0.506781]\n",
      "[Epoch 5/200] [Batch 99/637] [D loss: 0.148979] [G loss: 0.507687]\n",
      "[Epoch 5/200] [Batch 100/637] [D loss: 0.136819] [G loss: 0.546813]\n",
      "[Epoch 5/200] [Batch 101/637] [D loss: 0.150495] [G loss: 0.483986]\n",
      "[Epoch 5/200] [Batch 102/637] [D loss: 0.185148] [G loss: 0.506066]\n",
      "[Epoch 5/200] [Batch 103/637] [D loss: 0.128940] [G loss: 0.572924]\n",
      "[Epoch 5/200] [Batch 104/637] [D loss: 0.138259] [G loss: 0.561070]\n",
      "[Epoch 5/200] [Batch 105/637] [D loss: 0.133512] [G loss: 0.603833]\n",
      "[Epoch 5/200] [Batch 106/637] [D loss: 0.129717] [G loss: 0.553641]\n",
      "[Epoch 5/200] [Batch 107/637] [D loss: 0.138037] [G loss: 0.553084]\n",
      "[Epoch 5/200] [Batch 108/637] [D loss: 0.131903] [G loss: 0.533840]\n",
      "[Epoch 5/200] [Batch 109/637] [D loss: 0.132524] [G loss: 0.604829]\n",
      "[Epoch 5/200] [Batch 110/637] [D loss: 0.133830] [G loss: 0.559345]\n",
      "[Epoch 5/200] [Batch 111/637] [D loss: 0.164708] [G loss: 0.596875]\n",
      "[Epoch 5/200] [Batch 112/637] [D loss: 0.145200] [G loss: 0.493275]\n",
      "[Epoch 5/200] [Batch 113/637] [D loss: 0.148899] [G loss: 0.496363]\n",
      "[Epoch 5/200] [Batch 114/637] [D loss: 0.165796] [G loss: 0.522637]\n",
      "[Epoch 5/200] [Batch 115/637] [D loss: 0.188579] [G loss: 0.522765]\n",
      "[Epoch 5/200] [Batch 116/637] [D loss: 0.154305] [G loss: 0.479394]\n",
      "[Epoch 5/200] [Batch 117/637] [D loss: 0.139537] [G loss: 0.553607]\n",
      "[Epoch 5/200] [Batch 118/637] [D loss: 0.179795] [G loss: 0.564548]\n",
      "[Epoch 5/200] [Batch 119/637] [D loss: 0.145791] [G loss: 0.505666]\n",
      "[Epoch 5/200] [Batch 120/637] [D loss: 0.143858] [G loss: 0.559905]\n",
      "[Epoch 5/200] [Batch 121/637] [D loss: 0.155902] [G loss: 0.446557]\n",
      "[Epoch 5/200] [Batch 122/637] [D loss: 0.216504] [G loss: 0.683591]\n",
      "[Epoch 5/200] [Batch 123/637] [D loss: 0.137773] [G loss: 0.639751]\n",
      "[Epoch 5/200] [Batch 124/637] [D loss: 0.175513] [G loss: 0.597753]\n",
      "[Epoch 5/200] [Batch 125/637] [D loss: 0.152916] [G loss: 0.557725]\n",
      "[Epoch 5/200] [Batch 126/637] [D loss: 0.148382] [G loss: 0.506201]\n",
      "[Epoch 5/200] [Batch 127/637] [D loss: 0.143421] [G loss: 0.489802]\n",
      "[Epoch 5/200] [Batch 128/637] [D loss: 0.145387] [G loss: 0.513168]\n",
      "[Epoch 5/200] [Batch 129/637] [D loss: 0.122991] [G loss: 0.626011]\n",
      "[Epoch 5/200] [Batch 130/637] [D loss: 0.142027] [G loss: 0.545093]\n",
      "[Epoch 5/200] [Batch 131/637] [D loss: 0.161178] [G loss: 0.513766]\n",
      "[Epoch 5/200] [Batch 132/637] [D loss: 0.153444] [G loss: 0.504878]\n",
      "[Epoch 5/200] [Batch 133/637] [D loss: 0.149910] [G loss: 0.472970]\n",
      "[Epoch 5/200] [Batch 134/637] [D loss: 0.144101] [G loss: 0.537605]\n",
      "[Epoch 5/200] [Batch 135/637] [D loss: 0.147175] [G loss: 0.501264]\n",
      "[Epoch 5/200] [Batch 136/637] [D loss: 0.167964] [G loss: 0.513111]\n",
      "[Epoch 5/200] [Batch 137/637] [D loss: 0.192397] [G loss: 0.429364]\n",
      "[Epoch 5/200] [Batch 138/637] [D loss: 0.146449] [G loss: 0.509382]\n",
      "[Epoch 5/200] [Batch 139/637] [D loss: 0.143899] [G loss: 0.554508]\n",
      "[Epoch 5/200] [Batch 140/637] [D loss: 0.141253] [G loss: 0.558965]\n",
      "[Epoch 5/200] [Batch 141/637] [D loss: 0.154472] [G loss: 0.569406]\n",
      "[Epoch 5/200] [Batch 142/637] [D loss: 0.155688] [G loss: 0.550193]\n",
      "[Epoch 5/200] [Batch 143/637] [D loss: 0.144981] [G loss: 0.536354]\n",
      "[Epoch 5/200] [Batch 144/637] [D loss: 0.144749] [G loss: 0.521075]\n",
      "[Epoch 5/200] [Batch 145/637] [D loss: 0.138387] [G loss: 0.459558]\n",
      "[Epoch 5/200] [Batch 146/637] [D loss: 0.146434] [G loss: 0.587651]\n",
      "[Epoch 5/200] [Batch 147/637] [D loss: 0.111687] [G loss: 0.611814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 148/637] [D loss: 0.138639] [G loss: 0.597006]\n",
      "[Epoch 5/200] [Batch 149/637] [D loss: 0.139211] [G loss: 0.545212]\n",
      "[Epoch 5/200] [Batch 150/637] [D loss: 0.141191] [G loss: 0.525321]\n",
      "[Epoch 5/200] [Batch 151/637] [D loss: 0.193284] [G loss: 0.460898]\n",
      "[Epoch 5/200] [Batch 152/637] [D loss: 0.256092] [G loss: 0.700047]\n",
      "[Epoch 5/200] [Batch 153/637] [D loss: 0.167503] [G loss: 0.660165]\n",
      "[Epoch 5/200] [Batch 154/637] [D loss: 0.223130] [G loss: 0.492459]\n",
      "[Epoch 5/200] [Batch 155/637] [D loss: 0.167330] [G loss: 0.527807]\n",
      "[Epoch 5/200] [Batch 156/637] [D loss: 0.153360] [G loss: 0.500633]\n",
      "[Epoch 5/200] [Batch 157/637] [D loss: 0.140191] [G loss: 0.458513]\n",
      "[Epoch 5/200] [Batch 158/637] [D loss: 0.142961] [G loss: 0.472615]\n",
      "[Epoch 5/200] [Batch 159/637] [D loss: 0.147457] [G loss: 0.418351]\n",
      "[Epoch 5/200] [Batch 160/637] [D loss: 0.125547] [G loss: 0.538665]\n",
      "[Epoch 5/200] [Batch 161/637] [D loss: 0.128381] [G loss: 0.499745]\n",
      "[Epoch 5/200] [Batch 162/637] [D loss: 0.148905] [G loss: 0.559559]\n",
      "[Epoch 5/200] [Batch 163/637] [D loss: 0.131645] [G loss: 0.611009]\n",
      "[Epoch 5/200] [Batch 164/637] [D loss: 0.127308] [G loss: 0.595040]\n",
      "[Epoch 5/200] [Batch 165/637] [D loss: 0.124306] [G loss: 0.527808]\n",
      "[Epoch 5/200] [Batch 166/637] [D loss: 0.178401] [G loss: 0.580490]\n",
      "[Epoch 5/200] [Batch 167/637] [D loss: 0.160866] [G loss: 0.580930]\n",
      "[Epoch 5/200] [Batch 168/637] [D loss: 0.147636] [G loss: 0.527126]\n",
      "[Epoch 5/200] [Batch 169/637] [D loss: 0.141908] [G loss: 0.525981]\n",
      "[Epoch 5/200] [Batch 170/637] [D loss: 0.145682] [G loss: 0.575207]\n",
      "[Epoch 5/200] [Batch 171/637] [D loss: 0.147766] [G loss: 0.537178]\n",
      "[Epoch 5/200] [Batch 172/637] [D loss: 0.161077] [G loss: 0.475924]\n",
      "[Epoch 5/200] [Batch 173/637] [D loss: 0.139196] [G loss: 0.573833]\n",
      "[Epoch 5/200] [Batch 174/637] [D loss: 0.144837] [G loss: 0.596437]\n",
      "[Epoch 5/200] [Batch 175/637] [D loss: 0.143758] [G loss: 0.448191]\n",
      "[Epoch 5/200] [Batch 176/637] [D loss: 0.146450] [G loss: 0.519323]\n",
      "[Epoch 5/200] [Batch 177/637] [D loss: 0.158281] [G loss: 0.547094]\n",
      "[Epoch 5/200] [Batch 178/637] [D loss: 0.145109] [G loss: 0.613333]\n",
      "[Epoch 5/200] [Batch 179/637] [D loss: 0.132443] [G loss: 0.546347]\n",
      "[Epoch 5/200] [Batch 180/637] [D loss: 0.140144] [G loss: 0.531002]\n",
      "[Epoch 5/200] [Batch 181/637] [D loss: 0.152246] [G loss: 0.629055]\n",
      "[Epoch 5/200] [Batch 182/637] [D loss: 0.163620] [G loss: 0.559748]\n",
      "[Epoch 5/200] [Batch 183/637] [D loss: 0.130251] [G loss: 0.618148]\n",
      "[Epoch 5/200] [Batch 184/637] [D loss: 0.143355] [G loss: 0.536154]\n",
      "[Epoch 5/200] [Batch 185/637] [D loss: 0.137158] [G loss: 0.583485]\n",
      "[Epoch 5/200] [Batch 186/637] [D loss: 0.121025] [G loss: 0.547085]\n",
      "[Epoch 5/200] [Batch 187/637] [D loss: 0.161878] [G loss: 0.483751]\n",
      "[Epoch 5/200] [Batch 188/637] [D loss: 0.202426] [G loss: 0.635136]\n",
      "[Epoch 5/200] [Batch 189/637] [D loss: 0.131467] [G loss: 0.730636]\n",
      "[Epoch 5/200] [Batch 190/637] [D loss: 0.144888] [G loss: 0.657849]\n",
      "[Epoch 5/200] [Batch 191/637] [D loss: 0.162702] [G loss: 0.507374]\n",
      "[Epoch 5/200] [Batch 192/637] [D loss: 0.158626] [G loss: 0.535089]\n",
      "[Epoch 5/200] [Batch 193/637] [D loss: 0.144875] [G loss: 0.510676]\n",
      "[Epoch 5/200] [Batch 194/637] [D loss: 0.166695] [G loss: 0.492038]\n",
      "[Epoch 5/200] [Batch 195/637] [D loss: 0.120392] [G loss: 0.605700]\n",
      "[Epoch 5/200] [Batch 196/637] [D loss: 0.152375] [G loss: 0.541153]\n",
      "[Epoch 5/200] [Batch 197/637] [D loss: 0.149446] [G loss: 0.508246]\n",
      "[Epoch 5/200] [Batch 198/637] [D loss: 0.118267] [G loss: 0.573305]\n",
      "[Epoch 5/200] [Batch 199/637] [D loss: 0.146081] [G loss: 0.526485]\n",
      "[Epoch 5/200] [Batch 200/637] [D loss: 0.135699] [G loss: 0.525136]\n",
      "[Epoch 5/200] [Batch 201/637] [D loss: 0.127702] [G loss: 0.551694]\n",
      "[Epoch 5/200] [Batch 202/637] [D loss: 0.132780] [G loss: 0.523603]\n",
      "[Epoch 5/200] [Batch 203/637] [D loss: 0.135637] [G loss: 0.506971]\n",
      "[Epoch 5/200] [Batch 204/637] [D loss: 0.130123] [G loss: 0.578906]\n",
      "[Epoch 5/200] [Batch 205/637] [D loss: 0.140834] [G loss: 0.601577]\n",
      "[Epoch 5/200] [Batch 206/637] [D loss: 0.146037] [G loss: 0.647768]\n",
      "[Epoch 5/200] [Batch 207/637] [D loss: 0.157778] [G loss: 0.527030]\n",
      "[Epoch 5/200] [Batch 208/637] [D loss: 0.142210] [G loss: 0.621301]\n",
      "[Epoch 5/200] [Batch 209/637] [D loss: 0.142377] [G loss: 0.602837]\n",
      "[Epoch 5/200] [Batch 210/637] [D loss: 0.142963] [G loss: 0.507400]\n",
      "[Epoch 5/200] [Batch 211/637] [D loss: 0.138177] [G loss: 0.537734]\n",
      "[Epoch 5/200] [Batch 212/637] [D loss: 0.166575] [G loss: 0.617825]\n",
      "[Epoch 5/200] [Batch 213/637] [D loss: 0.134261] [G loss: 0.591884]\n",
      "[Epoch 5/200] [Batch 214/637] [D loss: 0.148433] [G loss: 0.542899]\n",
      "[Epoch 5/200] [Batch 215/637] [D loss: 0.193792] [G loss: 0.548406]\n",
      "[Epoch 5/200] [Batch 216/637] [D loss: 0.166569] [G loss: 0.573368]\n",
      "[Epoch 5/200] [Batch 217/637] [D loss: 0.148480] [G loss: 0.612816]\n",
      "[Epoch 5/200] [Batch 218/637] [D loss: 0.137981] [G loss: 0.601468]\n",
      "[Epoch 5/200] [Batch 219/637] [D loss: 0.141802] [G loss: 0.547773]\n",
      "[Epoch 5/200] [Batch 220/637] [D loss: 0.151085] [G loss: 0.515972]\n",
      "[Epoch 5/200] [Batch 221/637] [D loss: 0.136585] [G loss: 0.522063]\n",
      "[Epoch 5/200] [Batch 222/637] [D loss: 0.171695] [G loss: 0.524398]\n",
      "[Epoch 5/200] [Batch 223/637] [D loss: 0.140334] [G loss: 0.548087]\n",
      "[Epoch 5/200] [Batch 224/637] [D loss: 0.153460] [G loss: 0.526925]\n",
      "[Epoch 5/200] [Batch 225/637] [D loss: 0.129294] [G loss: 0.505301]\n",
      "[Epoch 5/200] [Batch 226/637] [D loss: 0.134384] [G loss: 0.482347]\n",
      "[Epoch 5/200] [Batch 227/637] [D loss: 0.153907] [G loss: 0.533641]\n",
      "[Epoch 5/200] [Batch 228/637] [D loss: 0.162216] [G loss: 0.559709]\n",
      "[Epoch 5/200] [Batch 229/637] [D loss: 0.171382] [G loss: 0.528916]\n",
      "[Epoch 5/200] [Batch 230/637] [D loss: 0.157438] [G loss: 0.469106]\n",
      "[Epoch 5/200] [Batch 231/637] [D loss: 0.177513] [G loss: 0.549203]\n",
      "[Epoch 5/200] [Batch 232/637] [D loss: 0.150069] [G loss: 0.538061]\n",
      "[Epoch 5/200] [Batch 233/637] [D loss: 0.170886] [G loss: 0.513474]\n",
      "[Epoch 5/200] [Batch 234/637] [D loss: 0.171743] [G loss: 0.538571]\n",
      "[Epoch 5/200] [Batch 235/637] [D loss: 0.161287] [G loss: 0.528289]\n",
      "[Epoch 5/200] [Batch 236/637] [D loss: 0.165520] [G loss: 0.510604]\n",
      "[Epoch 5/200] [Batch 237/637] [D loss: 0.143840] [G loss: 0.557766]\n",
      "[Epoch 5/200] [Batch 238/637] [D loss: 0.150052] [G loss: 0.601049]\n",
      "[Epoch 5/200] [Batch 239/637] [D loss: 0.178776] [G loss: 0.503593]\n",
      "[Epoch 5/200] [Batch 240/637] [D loss: 0.168266] [G loss: 0.667468]\n",
      "[Epoch 5/200] [Batch 241/637] [D loss: 0.137434] [G loss: 0.556452]\n",
      "[Epoch 5/200] [Batch 242/637] [D loss: 0.151420] [G loss: 0.559220]\n",
      "[Epoch 5/200] [Batch 243/637] [D loss: 0.168049] [G loss: 0.460717]\n",
      "[Epoch 5/200] [Batch 244/637] [D loss: 0.137364] [G loss: 0.512881]\n",
      "[Epoch 5/200] [Batch 245/637] [D loss: 0.149235] [G loss: 0.541025]\n",
      "[Epoch 5/200] [Batch 246/637] [D loss: 0.170914] [G loss: 0.596083]\n",
      "[Epoch 5/200] [Batch 247/637] [D loss: 0.142040] [G loss: 0.573512]\n",
      "[Epoch 5/200] [Batch 248/637] [D loss: 0.166820] [G loss: 0.561878]\n",
      "[Epoch 5/200] [Batch 249/637] [D loss: 0.159807] [G loss: 0.553337]\n",
      "[Epoch 5/200] [Batch 250/637] [D loss: 0.145591] [G loss: 0.552657]\n",
      "[Epoch 5/200] [Batch 251/637] [D loss: 0.129554] [G loss: 0.561055]\n",
      "[Epoch 5/200] [Batch 252/637] [D loss: 0.142841] [G loss: 0.589547]\n",
      "[Epoch 5/200] [Batch 253/637] [D loss: 0.149486] [G loss: 0.585627]\n",
      "[Epoch 5/200] [Batch 254/637] [D loss: 0.136439] [G loss: 0.590370]\n",
      "[Epoch 5/200] [Batch 255/637] [D loss: 0.183815] [G loss: 0.536165]\n",
      "[Epoch 5/200] [Batch 256/637] [D loss: 0.157323] [G loss: 0.490411]\n",
      "[Epoch 5/200] [Batch 257/637] [D loss: 0.164867] [G loss: 0.592141]\n",
      "[Epoch 5/200] [Batch 258/637] [D loss: 0.169772] [G loss: 0.567813]\n",
      "[Epoch 5/200] [Batch 259/637] [D loss: 0.150550] [G loss: 0.517284]\n",
      "[Epoch 5/200] [Batch 260/637] [D loss: 0.136031] [G loss: 0.522465]\n",
      "[Epoch 5/200] [Batch 261/637] [D loss: 0.118170] [G loss: 0.574267]\n",
      "[Epoch 5/200] [Batch 262/637] [D loss: 0.109968] [G loss: 0.568335]\n",
      "[Epoch 5/200] [Batch 263/637] [D loss: 0.134549] [G loss: 0.563255]\n",
      "[Epoch 5/200] [Batch 264/637] [D loss: 0.143369] [G loss: 0.574318]\n",
      "[Epoch 5/200] [Batch 265/637] [D loss: 0.133883] [G loss: 0.561761]\n",
      "[Epoch 5/200] [Batch 266/637] [D loss: 0.138054] [G loss: 0.533420]\n",
      "[Epoch 5/200] [Batch 267/637] [D loss: 0.138309] [G loss: 0.544492]\n",
      "[Epoch 5/200] [Batch 268/637] [D loss: 0.133200] [G loss: 0.558146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 269/637] [D loss: 0.154890] [G loss: 0.577702]\n",
      "[Epoch 5/200] [Batch 270/637] [D loss: 0.167862] [G loss: 0.715831]\n",
      "[Epoch 5/200] [Batch 271/637] [D loss: 0.151028] [G loss: 0.577772]\n",
      "[Epoch 5/200] [Batch 272/637] [D loss: 0.173867] [G loss: 0.503141]\n",
      "[Epoch 5/200] [Batch 273/637] [D loss: 0.141881] [G loss: 0.499079]\n",
      "[Epoch 5/200] [Batch 274/637] [D loss: 0.163780] [G loss: 0.439652]\n",
      "[Epoch 5/200] [Batch 275/637] [D loss: 0.178863] [G loss: 0.575036]\n",
      "[Epoch 5/200] [Batch 276/637] [D loss: 0.135537] [G loss: 0.588898]\n",
      "[Epoch 5/200] [Batch 277/637] [D loss: 0.151167] [G loss: 0.547262]\n",
      "[Epoch 5/200] [Batch 278/637] [D loss: 0.139749] [G loss: 0.559285]\n",
      "[Epoch 5/200] [Batch 279/637] [D loss: 0.139843] [G loss: 0.485073]\n",
      "[Epoch 5/200] [Batch 280/637] [D loss: 0.154588] [G loss: 0.606382]\n",
      "[Epoch 5/200] [Batch 281/637] [D loss: 0.154659] [G loss: 0.549877]\n",
      "[Epoch 5/200] [Batch 282/637] [D loss: 0.139893] [G loss: 0.532635]\n",
      "[Epoch 5/200] [Batch 283/637] [D loss: 0.140183] [G loss: 0.467947]\n",
      "[Epoch 5/200] [Batch 284/637] [D loss: 0.163678] [G loss: 0.548730]\n",
      "[Epoch 5/200] [Batch 285/637] [D loss: 0.141509] [G loss: 0.593938]\n",
      "[Epoch 5/200] [Batch 286/637] [D loss: 0.174993] [G loss: 0.522335]\n",
      "[Epoch 5/200] [Batch 287/637] [D loss: 0.151568] [G loss: 0.550210]\n",
      "[Epoch 5/200] [Batch 288/637] [D loss: 0.143560] [G loss: 0.516218]\n",
      "[Epoch 5/200] [Batch 289/637] [D loss: 0.143958] [G loss: 0.525119]\n",
      "[Epoch 5/200] [Batch 290/637] [D loss: 0.138712] [G loss: 0.511180]\n",
      "[Epoch 5/200] [Batch 291/637] [D loss: 0.141674] [G loss: 0.533529]\n",
      "[Epoch 5/200] [Batch 292/637] [D loss: 0.145136] [G loss: 0.634413]\n",
      "[Epoch 5/200] [Batch 293/637] [D loss: 0.121035] [G loss: 0.589312]\n",
      "[Epoch 5/200] [Batch 294/637] [D loss: 0.199788] [G loss: 0.480101]\n",
      "[Epoch 5/200] [Batch 295/637] [D loss: 0.323614] [G loss: 0.700011]\n",
      "[Epoch 5/200] [Batch 296/637] [D loss: 0.177454] [G loss: 0.793983]\n",
      "[Epoch 5/200] [Batch 297/637] [D loss: 0.244864] [G loss: 0.624156]\n",
      "[Epoch 5/200] [Batch 298/637] [D loss: 0.170663] [G loss: 0.589662]\n",
      "[Epoch 5/200] [Batch 299/637] [D loss: 0.147121] [G loss: 0.533339]\n",
      "[Epoch 5/200] [Batch 300/637] [D loss: 0.152160] [G loss: 0.479746]\n",
      "[Epoch 5/200] [Batch 301/637] [D loss: 0.148477] [G loss: 0.423542]\n",
      "[Epoch 5/200] [Batch 302/637] [D loss: 0.145114] [G loss: 0.479774]\n",
      "[Epoch 5/200] [Batch 303/637] [D loss: 0.139450] [G loss: 0.498366]\n",
      "[Epoch 5/200] [Batch 304/637] [D loss: 0.137278] [G loss: 0.542626]\n",
      "[Epoch 5/200] [Batch 305/637] [D loss: 0.155016] [G loss: 0.678609]\n",
      "[Epoch 5/200] [Batch 306/637] [D loss: 0.113134] [G loss: 0.601500]\n",
      "[Epoch 5/200] [Batch 307/637] [D loss: 0.143320] [G loss: 0.558851]\n",
      "[Epoch 5/200] [Batch 308/637] [D loss: 0.146687] [G loss: 0.648253]\n",
      "[Epoch 5/200] [Batch 309/637] [D loss: 0.131091] [G loss: 0.516401]\n",
      "[Epoch 5/200] [Batch 310/637] [D loss: 0.110059] [G loss: 0.585248]\n",
      "[Epoch 5/200] [Batch 311/637] [D loss: 0.136766] [G loss: 0.544156]\n",
      "[Epoch 5/200] [Batch 312/637] [D loss: 0.198185] [G loss: 0.543936]\n",
      "[Epoch 5/200] [Batch 313/637] [D loss: 0.140325] [G loss: 0.629047]\n",
      "[Epoch 5/200] [Batch 314/637] [D loss: 0.144933] [G loss: 0.583126]\n",
      "[Epoch 5/200] [Batch 315/637] [D loss: 0.150357] [G loss: 0.533716]\n",
      "[Epoch 5/200] [Batch 316/637] [D loss: 0.143537] [G loss: 0.553368]\n",
      "[Epoch 5/200] [Batch 317/637] [D loss: 0.141435] [G loss: 0.538090]\n",
      "[Epoch 5/200] [Batch 318/637] [D loss: 0.162807] [G loss: 0.540633]\n",
      "[Epoch 5/200] [Batch 319/637] [D loss: 0.129604] [G loss: 0.525196]\n",
      "[Epoch 5/200] [Batch 320/637] [D loss: 0.146919] [G loss: 0.532518]\n",
      "[Epoch 5/200] [Batch 321/637] [D loss: 0.121945] [G loss: 0.557536]\n",
      "[Epoch 5/200] [Batch 322/637] [D loss: 0.140309] [G loss: 0.595653]\n",
      "[Epoch 5/200] [Batch 323/637] [D loss: 0.129623] [G loss: 0.616955]\n",
      "[Epoch 5/200] [Batch 324/637] [D loss: 0.130929] [G loss: 0.538239]\n",
      "[Epoch 5/200] [Batch 325/637] [D loss: 0.160932] [G loss: 0.553795]\n",
      "[Epoch 5/200] [Batch 326/637] [D loss: 0.138105] [G loss: 0.540956]\n",
      "[Epoch 5/200] [Batch 327/637] [D loss: 0.156604] [G loss: 0.582701]\n",
      "[Epoch 5/200] [Batch 328/637] [D loss: 0.146759] [G loss: 0.592645]\n",
      "[Epoch 5/200] [Batch 329/637] [D loss: 0.147704] [G loss: 0.576345]\n",
      "[Epoch 5/200] [Batch 330/637] [D loss: 0.136091] [G loss: 0.568313]\n",
      "[Epoch 5/200] [Batch 331/637] [D loss: 0.141547] [G loss: 0.505306]\n",
      "[Epoch 5/200] [Batch 332/637] [D loss: 0.156623] [G loss: 0.614120]\n",
      "[Epoch 5/200] [Batch 333/637] [D loss: 0.124314] [G loss: 0.583935]\n",
      "[Epoch 5/200] [Batch 334/637] [D loss: 0.119620] [G loss: 0.622129]\n",
      "[Epoch 5/200] [Batch 335/637] [D loss: 0.137320] [G loss: 0.544547]\n",
      "[Epoch 5/200] [Batch 336/637] [D loss: 0.110621] [G loss: 0.585081]\n",
      "[Epoch 5/200] [Batch 337/637] [D loss: 0.133151] [G loss: 0.615278]\n",
      "[Epoch 5/200] [Batch 338/637] [D loss: 0.129354] [G loss: 0.591726]\n",
      "[Epoch 5/200] [Batch 339/637] [D loss: 0.157965] [G loss: 0.522296]\n",
      "[Epoch 5/200] [Batch 340/637] [D loss: 0.149475] [G loss: 0.562565]\n",
      "[Epoch 5/200] [Batch 341/637] [D loss: 0.175977] [G loss: 0.760852]\n",
      "[Epoch 5/200] [Batch 342/637] [D loss: 0.151557] [G loss: 0.577137]\n",
      "[Epoch 5/200] [Batch 343/637] [D loss: 0.284359] [G loss: 0.449339]\n",
      "[Epoch 5/200] [Batch 344/637] [D loss: 0.222336] [G loss: 0.597050]\n",
      "[Epoch 5/200] [Batch 345/637] [D loss: 0.169484] [G loss: 0.791302]\n",
      "[Epoch 5/200] [Batch 346/637] [D loss: 0.162481] [G loss: 0.607813]\n",
      "[Epoch 5/200] [Batch 347/637] [D loss: 0.127729] [G loss: 0.529102]\n",
      "[Epoch 5/200] [Batch 348/637] [D loss: 0.162902] [G loss: 0.458432]\n",
      "[Epoch 5/200] [Batch 349/637] [D loss: 0.139735] [G loss: 0.443837]\n",
      "[Epoch 5/200] [Batch 350/637] [D loss: 0.121481] [G loss: 0.520559]\n",
      "[Epoch 5/200] [Batch 351/637] [D loss: 0.126031] [G loss: 0.492431]\n",
      "[Epoch 5/200] [Batch 352/637] [D loss: 0.126490] [G loss: 0.534843]\n",
      "[Epoch 5/200] [Batch 353/637] [D loss: 0.134897] [G loss: 0.552255]\n",
      "[Epoch 5/200] [Batch 354/637] [D loss: 0.144385] [G loss: 0.540257]\n",
      "[Epoch 5/200] [Batch 355/637] [D loss: 0.130180] [G loss: 0.512231]\n",
      "[Epoch 5/200] [Batch 356/637] [D loss: 0.129442] [G loss: 0.564361]\n",
      "[Epoch 5/200] [Batch 357/637] [D loss: 0.121770] [G loss: 0.557046]\n",
      "[Epoch 5/200] [Batch 358/637] [D loss: 0.122794] [G loss: 0.551674]\n",
      "[Epoch 5/200] [Batch 359/637] [D loss: 0.122150] [G loss: 0.557675]\n",
      "[Epoch 5/200] [Batch 360/637] [D loss: 0.149557] [G loss: 0.489429]\n",
      "[Epoch 5/200] [Batch 361/637] [D loss: 0.155033] [G loss: 0.492328]\n",
      "[Epoch 5/200] [Batch 362/637] [D loss: 0.168506] [G loss: 0.533946]\n",
      "[Epoch 5/200] [Batch 363/637] [D loss: 0.155050] [G loss: 0.576193]\n",
      "[Epoch 5/200] [Batch 364/637] [D loss: 0.144955] [G loss: 0.568845]\n",
      "[Epoch 5/200] [Batch 365/637] [D loss: 0.132827] [G loss: 0.517681]\n",
      "[Epoch 5/200] [Batch 366/637] [D loss: 0.139789] [G loss: 0.567231]\n",
      "[Epoch 5/200] [Batch 367/637] [D loss: 0.134425] [G loss: 0.543456]\n",
      "[Epoch 5/200] [Batch 368/637] [D loss: 0.136380] [G loss: 0.566559]\n",
      "[Epoch 5/200] [Batch 369/637] [D loss: 0.158230] [G loss: 0.579567]\n",
      "[Epoch 5/200] [Batch 370/637] [D loss: 0.159415] [G loss: 0.609024]\n",
      "[Epoch 5/200] [Batch 371/637] [D loss: 0.146212] [G loss: 0.588582]\n",
      "[Epoch 5/200] [Batch 372/637] [D loss: 0.142738] [G loss: 0.522381]\n",
      "[Epoch 5/200] [Batch 373/637] [D loss: 0.145718] [G loss: 0.512813]\n",
      "[Epoch 5/200] [Batch 374/637] [D loss: 0.130099] [G loss: 0.563091]\n",
      "[Epoch 5/200] [Batch 375/637] [D loss: 0.169457] [G loss: 0.563943]\n",
      "[Epoch 5/200] [Batch 376/637] [D loss: 0.143800] [G loss: 0.549843]\n",
      "[Epoch 5/200] [Batch 377/637] [D loss: 0.162217] [G loss: 0.473966]\n",
      "[Epoch 5/200] [Batch 378/637] [D loss: 0.154094] [G loss: 0.554127]\n",
      "[Epoch 5/200] [Batch 379/637] [D loss: 0.169708] [G loss: 0.560013]\n",
      "[Epoch 5/200] [Batch 380/637] [D loss: 0.136616] [G loss: 0.493381]\n",
      "[Epoch 5/200] [Batch 381/637] [D loss: 0.158576] [G loss: 0.552600]\n",
      "[Epoch 5/200] [Batch 382/637] [D loss: 0.153984] [G loss: 0.511871]\n",
      "[Epoch 5/200] [Batch 383/637] [D loss: 0.156493] [G loss: 0.502027]\n",
      "[Epoch 5/200] [Batch 384/637] [D loss: 0.182902] [G loss: 0.479359]\n",
      "[Epoch 5/200] [Batch 385/637] [D loss: 0.164950] [G loss: 0.656648]\n",
      "[Epoch 5/200] [Batch 386/637] [D loss: 0.170674] [G loss: 0.561183]\n",
      "[Epoch 5/200] [Batch 387/637] [D loss: 0.143806] [G loss: 0.574514]\n",
      "[Epoch 5/200] [Batch 388/637] [D loss: 0.133118] [G loss: 0.520005]\n",
      "[Epoch 5/200] [Batch 389/637] [D loss: 0.154387] [G loss: 0.542965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 390/637] [D loss: 0.141721] [G loss: 0.571117]\n",
      "[Epoch 5/200] [Batch 391/637] [D loss: 0.172216] [G loss: 0.505336]\n",
      "[Epoch 5/200] [Batch 392/637] [D loss: 0.202511] [G loss: 0.567098]\n",
      "[Epoch 5/200] [Batch 393/637] [D loss: 0.138783] [G loss: 0.596067]\n",
      "[Epoch 5/200] [Batch 394/637] [D loss: 0.187234] [G loss: 0.495891]\n",
      "[Epoch 5/200] [Batch 395/637] [D loss: 0.162287] [G loss: 0.428598]\n",
      "[Epoch 5/200] [Batch 396/637] [D loss: 0.169630] [G loss: 0.516791]\n",
      "[Epoch 5/200] [Batch 397/637] [D loss: 0.165247] [G loss: 0.525570]\n",
      "[Epoch 5/200] [Batch 398/637] [D loss: 0.166327] [G loss: 0.473882]\n",
      "[Epoch 5/200] [Batch 399/637] [D loss: 0.145906] [G loss: 0.532378]\n",
      "[Epoch 5/200] [Batch 400/637] [D loss: 0.146094] [G loss: 0.519378]\n",
      "[Epoch 5/200] [Batch 401/637] [D loss: 0.158774] [G loss: 0.452466]\n",
      "[Epoch 5/200] [Batch 402/637] [D loss: 0.158388] [G loss: 0.461602]\n",
      "[Epoch 5/200] [Batch 403/637] [D loss: 0.156365] [G loss: 0.592246]\n",
      "[Epoch 5/200] [Batch 404/637] [D loss: 0.158706] [G loss: 0.560595]\n",
      "[Epoch 5/200] [Batch 405/637] [D loss: 0.142766] [G loss: 0.584544]\n",
      "[Epoch 5/200] [Batch 406/637] [D loss: 0.161715] [G loss: 0.513942]\n",
      "[Epoch 5/200] [Batch 407/637] [D loss: 0.142932] [G loss: 0.446352]\n",
      "[Epoch 5/200] [Batch 408/637] [D loss: 0.149080] [G loss: 0.519007]\n",
      "[Epoch 5/200] [Batch 409/637] [D loss: 0.148712] [G loss: 0.604184]\n",
      "[Epoch 5/200] [Batch 410/637] [D loss: 0.152431] [G loss: 0.623100]\n",
      "[Epoch 5/200] [Batch 411/637] [D loss: 0.166948] [G loss: 0.563004]\n",
      "[Epoch 5/200] [Batch 412/637] [D loss: 0.153735] [G loss: 0.605949]\n",
      "[Epoch 5/200] [Batch 413/637] [D loss: 0.153115] [G loss: 0.561347]\n",
      "[Epoch 5/200] [Batch 414/637] [D loss: 0.144881] [G loss: 0.609255]\n",
      "[Epoch 5/200] [Batch 415/637] [D loss: 0.170427] [G loss: 0.502927]\n",
      "[Epoch 5/200] [Batch 416/637] [D loss: 0.168256] [G loss: 0.550508]\n",
      "[Epoch 5/200] [Batch 417/637] [D loss: 0.143051] [G loss: 0.513283]\n",
      "[Epoch 5/200] [Batch 418/637] [D loss: 0.162019] [G loss: 0.578534]\n",
      "[Epoch 5/200] [Batch 419/637] [D loss: 0.205093] [G loss: 0.587615]\n",
      "[Epoch 5/200] [Batch 420/637] [D loss: 0.195538] [G loss: 0.639072]\n",
      "[Epoch 5/200] [Batch 421/637] [D loss: 0.164876] [G loss: 0.575969]\n",
      "[Epoch 5/200] [Batch 422/637] [D loss: 0.162636] [G loss: 0.600625]\n",
      "[Epoch 5/200] [Batch 423/637] [D loss: 0.177795] [G loss: 0.501837]\n",
      "[Epoch 5/200] [Batch 424/637] [D loss: 0.144465] [G loss: 0.548347]\n",
      "[Epoch 5/200] [Batch 425/637] [D loss: 0.129365] [G loss: 0.559652]\n",
      "[Epoch 5/200] [Batch 426/637] [D loss: 0.154014] [G loss: 0.566251]\n",
      "[Epoch 5/200] [Batch 427/637] [D loss: 0.158023] [G loss: 0.523571]\n",
      "[Epoch 5/200] [Batch 428/637] [D loss: 0.157748] [G loss: 0.554650]\n",
      "[Epoch 5/200] [Batch 429/637] [D loss: 0.146585] [G loss: 0.572227]\n",
      "[Epoch 5/200] [Batch 430/637] [D loss: 0.138063] [G loss: 0.510003]\n",
      "[Epoch 5/200] [Batch 431/637] [D loss: 0.137682] [G loss: 0.545203]\n",
      "[Epoch 5/200] [Batch 432/637] [D loss: 0.170306] [G loss: 0.578990]\n",
      "[Epoch 5/200] [Batch 433/637] [D loss: 0.160152] [G loss: 0.592669]\n",
      "[Epoch 5/200] [Batch 434/637] [D loss: 0.165816] [G loss: 0.546611]\n",
      "[Epoch 5/200] [Batch 435/637] [D loss: 0.154444] [G loss: 0.523828]\n",
      "[Epoch 5/200] [Batch 436/637] [D loss: 0.137703] [G loss: 0.561354]\n",
      "[Epoch 5/200] [Batch 437/637] [D loss: 0.157139] [G loss: 0.565267]\n",
      "[Epoch 5/200] [Batch 438/637] [D loss: 0.186897] [G loss: 0.611227]\n",
      "[Epoch 5/200] [Batch 439/637] [D loss: 0.163713] [G loss: 0.538564]\n",
      "[Epoch 5/200] [Batch 440/637] [D loss: 0.157579] [G loss: 0.575716]\n",
      "[Epoch 5/200] [Batch 441/637] [D loss: 0.157427] [G loss: 0.523226]\n",
      "[Epoch 5/200] [Batch 442/637] [D loss: 0.165180] [G loss: 0.544939]\n",
      "[Epoch 5/200] [Batch 443/637] [D loss: 0.152650] [G loss: 0.513864]\n",
      "[Epoch 5/200] [Batch 444/637] [D loss: 0.194002] [G loss: 0.550264]\n",
      "[Epoch 5/200] [Batch 445/637] [D loss: 0.152452] [G loss: 0.603616]\n",
      "[Epoch 5/200] [Batch 446/637] [D loss: 0.144025] [G loss: 0.651313]\n",
      "[Epoch 5/200] [Batch 447/637] [D loss: 0.138752] [G loss: 0.573295]\n",
      "[Epoch 5/200] [Batch 448/637] [D loss: 0.172628] [G loss: 0.473530]\n",
      "[Epoch 5/200] [Batch 449/637] [D loss: 0.171302] [G loss: 0.441600]\n",
      "[Epoch 5/200] [Batch 450/637] [D loss: 0.149798] [G loss: 0.641744]\n",
      "[Epoch 5/200] [Batch 451/637] [D loss: 0.151287] [G loss: 0.616387]\n",
      "[Epoch 5/200] [Batch 452/637] [D loss: 0.165371] [G loss: 0.468771]\n",
      "[Epoch 5/200] [Batch 453/637] [D loss: 0.122121] [G loss: 0.564397]\n",
      "[Epoch 5/200] [Batch 454/637] [D loss: 0.130257] [G loss: 0.555059]\n",
      "[Epoch 5/200] [Batch 455/637] [D loss: 0.146221] [G loss: 0.558456]\n",
      "[Epoch 5/200] [Batch 456/637] [D loss: 0.161068] [G loss: 0.597881]\n",
      "[Epoch 5/200] [Batch 457/637] [D loss: 0.142733] [G loss: 0.592117]\n",
      "[Epoch 5/200] [Batch 458/637] [D loss: 0.138193] [G loss: 0.574446]\n",
      "[Epoch 5/200] [Batch 459/637] [D loss: 0.136178] [G loss: 0.566128]\n",
      "[Epoch 5/200] [Batch 460/637] [D loss: 0.197528] [G loss: 0.498340]\n",
      "[Epoch 5/200] [Batch 461/637] [D loss: 0.194811] [G loss: 0.636247]\n",
      "[Epoch 5/200] [Batch 462/637] [D loss: 0.151280] [G loss: 0.652819]\n",
      "[Epoch 5/200] [Batch 463/637] [D loss: 0.135447] [G loss: 0.607700]\n",
      "[Epoch 5/200] [Batch 464/637] [D loss: 0.167793] [G loss: 0.446180]\n",
      "[Epoch 5/200] [Batch 465/637] [D loss: 0.184209] [G loss: 0.533364]\n",
      "[Epoch 5/200] [Batch 466/637] [D loss: 0.148945] [G loss: 0.553118]\n",
      "[Epoch 5/200] [Batch 467/637] [D loss: 0.137726] [G loss: 0.591502]\n",
      "[Epoch 5/200] [Batch 468/637] [D loss: 0.141945] [G loss: 0.597395]\n",
      "[Epoch 5/200] [Batch 469/637] [D loss: 0.133440] [G loss: 0.541781]\n",
      "[Epoch 5/200] [Batch 470/637] [D loss: 0.153059] [G loss: 0.531898]\n",
      "[Epoch 5/200] [Batch 471/637] [D loss: 0.148946] [G loss: 0.545950]\n",
      "[Epoch 5/200] [Batch 472/637] [D loss: 0.162760] [G loss: 0.478174]\n",
      "[Epoch 5/200] [Batch 473/637] [D loss: 0.150461] [G loss: 0.557666]\n",
      "[Epoch 5/200] [Batch 474/637] [D loss: 0.146430] [G loss: 0.548643]\n",
      "[Epoch 5/200] [Batch 475/637] [D loss: 0.145574] [G loss: 0.540468]\n",
      "[Epoch 5/200] [Batch 476/637] [D loss: 0.155378] [G loss: 0.470168]\n",
      "[Epoch 5/200] [Batch 477/637] [D loss: 0.153253] [G loss: 0.520738]\n",
      "[Epoch 5/200] [Batch 478/637] [D loss: 0.199978] [G loss: 0.559109]\n",
      "[Epoch 5/200] [Batch 479/637] [D loss: 0.146082] [G loss: 0.554129]\n",
      "[Epoch 5/200] [Batch 480/637] [D loss: 0.204164] [G loss: 0.519223]\n",
      "[Epoch 5/200] [Batch 481/637] [D loss: 0.146271] [G loss: 0.647675]\n",
      "[Epoch 5/200] [Batch 482/637] [D loss: 0.171652] [G loss: 0.539358]\n",
      "[Epoch 5/200] [Batch 483/637] [D loss: 0.148343] [G loss: 0.562277]\n",
      "[Epoch 5/200] [Batch 484/637] [D loss: 0.144731] [G loss: 0.559107]\n",
      "[Epoch 5/200] [Batch 485/637] [D loss: 0.147945] [G loss: 0.487242]\n",
      "[Epoch 5/200] [Batch 486/637] [D loss: 0.138194] [G loss: 0.541068]\n",
      "[Epoch 5/200] [Batch 487/637] [D loss: 0.135111] [G loss: 0.558383]\n",
      "[Epoch 5/200] [Batch 488/637] [D loss: 0.132497] [G loss: 0.551959]\n",
      "[Epoch 5/200] [Batch 489/637] [D loss: 0.124344] [G loss: 0.561099]\n",
      "[Epoch 5/200] [Batch 490/637] [D loss: 0.115964] [G loss: 0.644818]\n",
      "[Epoch 5/200] [Batch 491/637] [D loss: 0.109883] [G loss: 0.658549]\n",
      "[Epoch 5/200] [Batch 492/637] [D loss: 0.155514] [G loss: 0.490357]\n",
      "[Epoch 5/200] [Batch 493/637] [D loss: 0.192573] [G loss: 0.603419]\n",
      "[Epoch 5/200] [Batch 494/637] [D loss: 0.134518] [G loss: 0.631913]\n",
      "[Epoch 5/200] [Batch 495/637] [D loss: 0.161746] [G loss: 0.597486]\n",
      "[Epoch 5/200] [Batch 496/637] [D loss: 0.139187] [G loss: 0.540482]\n",
      "[Epoch 5/200] [Batch 497/637] [D loss: 0.154654] [G loss: 0.591572]\n",
      "[Epoch 5/200] [Batch 498/637] [D loss: 0.143128] [G loss: 0.552925]\n",
      "[Epoch 5/200] [Batch 499/637] [D loss: 0.196451] [G loss: 0.457220]\n",
      "[Epoch 5/200] [Batch 500/637] [D loss: 0.268299] [G loss: 0.617668]\n",
      "[Epoch 5/200] [Batch 501/637] [D loss: 0.186020] [G loss: 0.625322]\n",
      "[Epoch 5/200] [Batch 502/637] [D loss: 0.168640] [G loss: 0.534884]\n",
      "[Epoch 5/200] [Batch 503/637] [D loss: 0.160896] [G loss: 0.525874]\n",
      "[Epoch 5/200] [Batch 504/637] [D loss: 0.149537] [G loss: 0.529346]\n",
      "[Epoch 5/200] [Batch 505/637] [D loss: 0.150397] [G loss: 0.469248]\n",
      "[Epoch 5/200] [Batch 506/637] [D loss: 0.152663] [G loss: 0.515608]\n",
      "[Epoch 5/200] [Batch 507/637] [D loss: 0.129418] [G loss: 0.554550]\n",
      "[Epoch 5/200] [Batch 508/637] [D loss: 0.151659] [G loss: 0.489599]\n",
      "[Epoch 5/200] [Batch 509/637] [D loss: 0.159062] [G loss: 0.482852]\n",
      "[Epoch 5/200] [Batch 510/637] [D loss: 0.164595] [G loss: 0.449518]\n",
      "[Epoch 5/200] [Batch 511/637] [D loss: 0.163989] [G loss: 0.554571]\n",
      "[Epoch 5/200] [Batch 512/637] [D loss: 0.165106] [G loss: 0.565769]\n",
      "[Epoch 5/200] [Batch 513/637] [D loss: 0.149965] [G loss: 0.555637]\n",
      "[Epoch 5/200] [Batch 514/637] [D loss: 0.155332] [G loss: 0.490859]\n",
      "[Epoch 5/200] [Batch 515/637] [D loss: 0.157455] [G loss: 0.551049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 516/637] [D loss: 0.147671] [G loss: 0.575569]\n",
      "[Epoch 5/200] [Batch 517/637] [D loss: 0.154019] [G loss: 0.566803]\n",
      "[Epoch 5/200] [Batch 518/637] [D loss: 0.165072] [G loss: 0.478508]\n",
      "[Epoch 5/200] [Batch 519/637] [D loss: 0.161847] [G loss: 0.543485]\n",
      "[Epoch 5/200] [Batch 520/637] [D loss: 0.126063] [G loss: 0.601421]\n",
      "[Epoch 5/200] [Batch 521/637] [D loss: 0.128167] [G loss: 0.574508]\n",
      "[Epoch 5/200] [Batch 522/637] [D loss: 0.155274] [G loss: 0.526453]\n",
      "[Epoch 5/200] [Batch 523/637] [D loss: 0.167419] [G loss: 0.574213]\n",
      "[Epoch 5/200] [Batch 524/637] [D loss: 0.152015] [G loss: 0.661342]\n",
      "[Epoch 5/200] [Batch 525/637] [D loss: 0.158590] [G loss: 0.606099]\n",
      "[Epoch 5/200] [Batch 526/637] [D loss: 0.138234] [G loss: 0.568533]\n",
      "[Epoch 5/200] [Batch 527/637] [D loss: 0.131766] [G loss: 0.524650]\n",
      "[Epoch 5/200] [Batch 528/637] [D loss: 0.122338] [G loss: 0.561372]\n",
      "[Epoch 5/200] [Batch 529/637] [D loss: 0.143786] [G loss: 0.628112]\n",
      "[Epoch 5/200] [Batch 530/637] [D loss: 0.156337] [G loss: 0.613376]\n",
      "[Epoch 5/200] [Batch 531/637] [D loss: 0.173990] [G loss: 0.504860]\n",
      "[Epoch 5/200] [Batch 532/637] [D loss: 0.168400] [G loss: 0.541590]\n",
      "[Epoch 5/200] [Batch 533/637] [D loss: 0.190402] [G loss: 0.635565]\n",
      "[Epoch 5/200] [Batch 534/637] [D loss: 0.157095] [G loss: 0.610311]\n",
      "[Epoch 5/200] [Batch 535/637] [D loss: 0.187809] [G loss: 0.446859]\n",
      "[Epoch 5/200] [Batch 536/637] [D loss: 0.177435] [G loss: 0.515628]\n",
      "[Epoch 5/200] [Batch 537/637] [D loss: 0.173655] [G loss: 0.583014]\n",
      "[Epoch 5/200] [Batch 538/637] [D loss: 0.170103] [G loss: 0.554802]\n",
      "[Epoch 5/200] [Batch 539/637] [D loss: 0.162464] [G loss: 0.475042]\n",
      "[Epoch 5/200] [Batch 540/637] [D loss: 0.169056] [G loss: 0.514850]\n",
      "[Epoch 5/200] [Batch 541/637] [D loss: 0.197681] [G loss: 0.482618]\n",
      "[Epoch 5/200] [Batch 542/637] [D loss: 0.193394] [G loss: 0.488288]\n",
      "[Epoch 5/200] [Batch 543/637] [D loss: 0.160948] [G loss: 0.620911]\n",
      "[Epoch 5/200] [Batch 544/637] [D loss: 0.155705] [G loss: 0.546644]\n",
      "[Epoch 5/200] [Batch 545/637] [D loss: 0.149215] [G loss: 0.508055]\n",
      "[Epoch 5/200] [Batch 546/637] [D loss: 0.139157] [G loss: 0.510092]\n",
      "[Epoch 5/200] [Batch 547/637] [D loss: 0.127470] [G loss: 0.543916]\n",
      "[Epoch 5/200] [Batch 548/637] [D loss: 0.160469] [G loss: 0.612223]\n",
      "[Epoch 5/200] [Batch 549/637] [D loss: 0.164736] [G loss: 0.555483]\n",
      "[Epoch 5/200] [Batch 550/637] [D loss: 0.159785] [G loss: 0.563392]\n",
      "[Epoch 5/200] [Batch 551/637] [D loss: 0.152844] [G loss: 0.484177]\n",
      "[Epoch 5/200] [Batch 552/637] [D loss: 0.176698] [G loss: 0.462230]\n",
      "[Epoch 5/200] [Batch 553/637] [D loss: 0.184525] [G loss: 0.625575]\n",
      "[Epoch 5/200] [Batch 554/637] [D loss: 0.135820] [G loss: 0.583717]\n",
      "[Epoch 5/200] [Batch 555/637] [D loss: 0.132995] [G loss: 0.600334]\n",
      "[Epoch 5/200] [Batch 556/637] [D loss: 0.142171] [G loss: 0.505364]\n",
      "[Epoch 5/200] [Batch 557/637] [D loss: 0.131575] [G loss: 0.550163]\n",
      "[Epoch 5/200] [Batch 558/637] [D loss: 0.123004] [G loss: 0.595710]\n",
      "[Epoch 5/200] [Batch 559/637] [D loss: 0.149891] [G loss: 0.534278]\n",
      "[Epoch 5/200] [Batch 560/637] [D loss: 0.116806] [G loss: 0.583598]\n",
      "[Epoch 5/200] [Batch 561/637] [D loss: 0.140589] [G loss: 0.526779]\n",
      "[Epoch 5/200] [Batch 562/637] [D loss: 0.150432] [G loss: 0.537943]\n",
      "[Epoch 5/200] [Batch 563/637] [D loss: 0.188735] [G loss: 0.509918]\n",
      "[Epoch 5/200] [Batch 564/637] [D loss: 0.151016] [G loss: 0.596652]\n",
      "[Epoch 5/200] [Batch 565/637] [D loss: 0.173871] [G loss: 0.522907]\n",
      "[Epoch 5/200] [Batch 566/637] [D loss: 0.153303] [G loss: 0.589780]\n",
      "[Epoch 5/200] [Batch 567/637] [D loss: 0.146928] [G loss: 0.531978]\n",
      "[Epoch 5/200] [Batch 568/637] [D loss: 0.180503] [G loss: 0.473942]\n",
      "[Epoch 5/200] [Batch 569/637] [D loss: 0.266014] [G loss: 0.559001]\n",
      "[Epoch 5/200] [Batch 570/637] [D loss: 0.179237] [G loss: 0.664064]\n",
      "[Epoch 5/200] [Batch 571/637] [D loss: 0.169807] [G loss: 0.614483]\n",
      "[Epoch 5/200] [Batch 572/637] [D loss: 0.130908] [G loss: 0.565973]\n",
      "[Epoch 5/200] [Batch 573/637] [D loss: 0.139951] [G loss: 0.503149]\n",
      "[Epoch 5/200] [Batch 574/637] [D loss: 0.162734] [G loss: 0.446692]\n",
      "[Epoch 5/200] [Batch 575/637] [D loss: 0.143188] [G loss: 0.494222]\n",
      "[Epoch 5/200] [Batch 576/637] [D loss: 0.153539] [G loss: 0.503034]\n",
      "[Epoch 5/200] [Batch 577/637] [D loss: 0.122185] [G loss: 0.582236]\n",
      "[Epoch 5/200] [Batch 578/637] [D loss: 0.142076] [G loss: 0.482117]\n",
      "[Epoch 5/200] [Batch 579/637] [D loss: 0.151379] [G loss: 0.458359]\n",
      "[Epoch 5/200] [Batch 580/637] [D loss: 0.167990] [G loss: 0.520382]\n",
      "[Epoch 5/200] [Batch 581/637] [D loss: 0.155518] [G loss: 0.492264]\n",
      "[Epoch 5/200] [Batch 582/637] [D loss: 0.153442] [G loss: 0.557499]\n",
      "[Epoch 5/200] [Batch 583/637] [D loss: 0.149234] [G loss: 0.598385]\n",
      "[Epoch 5/200] [Batch 584/637] [D loss: 0.147102] [G loss: 0.531723]\n",
      "[Epoch 5/200] [Batch 585/637] [D loss: 0.148482] [G loss: 0.501367]\n",
      "[Epoch 5/200] [Batch 586/637] [D loss: 0.183541] [G loss: 0.470863]\n",
      "[Epoch 5/200] [Batch 587/637] [D loss: 0.154182] [G loss: 0.620737]\n",
      "[Epoch 5/200] [Batch 588/637] [D loss: 0.158847] [G loss: 0.625846]\n",
      "[Epoch 5/200] [Batch 589/637] [D loss: 0.159171] [G loss: 0.526789]\n",
      "[Epoch 5/200] [Batch 590/637] [D loss: 0.145186] [G loss: 0.487224]\n",
      "[Epoch 5/200] [Batch 591/637] [D loss: 0.132406] [G loss: 0.533720]\n",
      "[Epoch 5/200] [Batch 592/637] [D loss: 0.130123] [G loss: 0.573961]\n",
      "[Epoch 5/200] [Batch 593/637] [D loss: 0.145601] [G loss: 0.539349]\n",
      "[Epoch 5/200] [Batch 594/637] [D loss: 0.166362] [G loss: 0.526044]\n",
      "[Epoch 5/200] [Batch 595/637] [D loss: 0.164263] [G loss: 0.542521]\n",
      "[Epoch 5/200] [Batch 596/637] [D loss: 0.159447] [G loss: 0.481095]\n",
      "[Epoch 5/200] [Batch 597/637] [D loss: 0.158892] [G loss: 0.487202]\n",
      "[Epoch 5/200] [Batch 598/637] [D loss: 0.131278] [G loss: 0.524764]\n",
      "[Epoch 5/200] [Batch 599/637] [D loss: 0.173493] [G loss: 0.504505]\n",
      "[Epoch 5/200] [Batch 600/637] [D loss: 0.158861] [G loss: 0.527403]\n",
      "[Epoch 5/200] [Batch 601/637] [D loss: 0.175506] [G loss: 0.424794]\n",
      "[Epoch 5/200] [Batch 602/637] [D loss: 0.178167] [G loss: 0.550364]\n",
      "[Epoch 5/200] [Batch 603/637] [D loss: 0.153799] [G loss: 0.589097]\n",
      "[Epoch 5/200] [Batch 604/637] [D loss: 0.161836] [G loss: 0.512325]\n",
      "[Epoch 5/200] [Batch 605/637] [D loss: 0.169095] [G loss: 0.487053]\n",
      "[Epoch 5/200] [Batch 606/637] [D loss: 0.130007] [G loss: 0.549728]\n",
      "[Epoch 5/200] [Batch 607/637] [D loss: 0.168752] [G loss: 0.488143]\n",
      "[Epoch 5/200] [Batch 608/637] [D loss: 0.160995] [G loss: 0.601940]\n",
      "[Epoch 5/200] [Batch 609/637] [D loss: 0.145934] [G loss: 0.515675]\n",
      "[Epoch 5/200] [Batch 610/637] [D loss: 0.184969] [G loss: 0.552979]\n",
      "[Epoch 5/200] [Batch 611/637] [D loss: 0.162465] [G loss: 0.601984]\n",
      "[Epoch 5/200] [Batch 612/637] [D loss: 0.146158] [G loss: 0.576019]\n",
      "[Epoch 5/200] [Batch 613/637] [D loss: 0.138022] [G loss: 0.635217]\n",
      "[Epoch 5/200] [Batch 614/637] [D loss: 0.156273] [G loss: 0.540444]\n",
      "[Epoch 5/200] [Batch 615/637] [D loss: 0.153583] [G loss: 0.555704]\n",
      "[Epoch 5/200] [Batch 616/637] [D loss: 0.142280] [G loss: 0.584114]\n",
      "[Epoch 5/200] [Batch 617/637] [D loss: 0.144053] [G loss: 0.513558]\n",
      "[Epoch 5/200] [Batch 618/637] [D loss: 0.137807] [G loss: 0.577267]\n",
      "[Epoch 5/200] [Batch 619/637] [D loss: 0.156231] [G loss: 0.585587]\n",
      "[Epoch 5/200] [Batch 620/637] [D loss: 0.129850] [G loss: 0.566481]\n",
      "[Epoch 5/200] [Batch 621/637] [D loss: 0.168537] [G loss: 0.497610]\n",
      "[Epoch 5/200] [Batch 622/637] [D loss: 0.193775] [G loss: 0.695693]\n",
      "[Epoch 5/200] [Batch 623/637] [D loss: 0.162729] [G loss: 0.652999]\n",
      "[Epoch 5/200] [Batch 624/637] [D loss: 0.187943] [G loss: 0.520441]\n",
      "[Epoch 5/200] [Batch 625/637] [D loss: 0.155277] [G loss: 0.529120]\n",
      "[Epoch 5/200] [Batch 626/637] [D loss: 0.136499] [G loss: 0.505575]\n",
      "[Epoch 5/200] [Batch 627/637] [D loss: 0.140577] [G loss: 0.495450]\n",
      "[Epoch 5/200] [Batch 628/637] [D loss: 0.139055] [G loss: 0.526620]\n",
      "[Epoch 5/200] [Batch 629/637] [D loss: 0.155623] [G loss: 0.553878]\n",
      "[Epoch 5/200] [Batch 630/637] [D loss: 0.146352] [G loss: 0.545883]\n",
      "[Epoch 5/200] [Batch 631/637] [D loss: 0.146783] [G loss: 0.533305]\n",
      "[Epoch 5/200] [Batch 632/637] [D loss: 0.168627] [G loss: 0.568287]\n",
      "[Epoch 5/200] [Batch 633/637] [D loss: 0.163975] [G loss: 0.503927]\n",
      "[Epoch 5/200] [Batch 634/637] [D loss: 0.154999] [G loss: 0.535729]\n",
      "[Epoch 5/200] [Batch 635/637] [D loss: 0.160250] [G loss: 0.530261]\n",
      "[Epoch 5/200] [Batch 636/637] [D loss: 0.193964] [G loss: 0.421192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 0/637] [D loss: 0.381878] [G loss: 0.778488]\n",
      "[Epoch 6/200] [Batch 1/637] [D loss: 0.263282] [G loss: 0.747012]\n",
      "[Epoch 6/200] [Batch 2/637] [D loss: 0.248923] [G loss: 0.601055]\n",
      "[Epoch 6/200] [Batch 3/637] [D loss: 0.227323] [G loss: 0.451119]\n",
      "[Epoch 6/200] [Batch 4/637] [D loss: 0.164261] [G loss: 0.489521]\n",
      "[Epoch 6/200] [Batch 5/637] [D loss: 0.156918] [G loss: 0.465098]\n",
      "[Epoch 6/200] [Batch 6/637] [D loss: 0.158027] [G loss: 0.457990]\n",
      "[Epoch 6/200] [Batch 7/637] [D loss: 0.185276] [G loss: 0.403063]\n",
      "[Epoch 6/200] [Batch 8/637] [D loss: 0.176446] [G loss: 0.476724]\n",
      "[Epoch 6/200] [Batch 9/637] [D loss: 0.160109] [G loss: 0.559549]\n",
      "[Epoch 6/200] [Batch 10/637] [D loss: 0.151705] [G loss: 0.492595]\n",
      "[Epoch 6/200] [Batch 11/637] [D loss: 0.139469] [G loss: 0.457253]\n",
      "[Epoch 6/200] [Batch 12/637] [D loss: 0.133073] [G loss: 0.469066]\n",
      "[Epoch 6/200] [Batch 13/637] [D loss: 0.161554] [G loss: 0.513935]\n",
      "[Epoch 6/200] [Batch 14/637] [D loss: 0.156875] [G loss: 0.538668]\n",
      "[Epoch 6/200] [Batch 15/637] [D loss: 0.178218] [G loss: 0.645626]\n",
      "[Epoch 6/200] [Batch 16/637] [D loss: 0.144502] [G loss: 0.495330]\n",
      "[Epoch 6/200] [Batch 17/637] [D loss: 0.222457] [G loss: 0.437815]\n",
      "[Epoch 6/200] [Batch 18/637] [D loss: 0.155709] [G loss: 0.636464]\n",
      "[Epoch 6/200] [Batch 19/637] [D loss: 0.179329] [G loss: 0.541203]\n",
      "[Epoch 6/200] [Batch 20/637] [D loss: 0.157324] [G loss: 0.514717]\n",
      "[Epoch 6/200] [Batch 21/637] [D loss: 0.161723] [G loss: 0.449590]\n",
      "[Epoch 6/200] [Batch 22/637] [D loss: 0.149249] [G loss: 0.410875]\n",
      "[Epoch 6/200] [Batch 23/637] [D loss: 0.158885] [G loss: 0.500735]\n",
      "[Epoch 6/200] [Batch 24/637] [D loss: 0.148596] [G loss: 0.548990]\n",
      "[Epoch 6/200] [Batch 25/637] [D loss: 0.147011] [G loss: 0.529021]\n",
      "[Epoch 6/200] [Batch 26/637] [D loss: 0.163433] [G loss: 0.413171]\n",
      "[Epoch 6/200] [Batch 27/637] [D loss: 0.145358] [G loss: 0.489415]\n",
      "[Epoch 6/200] [Batch 28/637] [D loss: 0.172198] [G loss: 0.524016]\n",
      "[Epoch 6/200] [Batch 29/637] [D loss: 0.153381] [G loss: 0.471854]\n",
      "[Epoch 6/200] [Batch 30/637] [D loss: 0.160406] [G loss: 0.475268]\n",
      "[Epoch 6/200] [Batch 31/637] [D loss: 0.148736] [G loss: 0.503259]\n",
      "[Epoch 6/200] [Batch 32/637] [D loss: 0.163756] [G loss: 0.467858]\n",
      "[Epoch 6/200] [Batch 33/637] [D loss: 0.207733] [G loss: 0.507443]\n",
      "[Epoch 6/200] [Batch 34/637] [D loss: 0.167262] [G loss: 0.592908]\n",
      "[Epoch 6/200] [Batch 35/637] [D loss: 0.165506] [G loss: 0.520078]\n",
      "[Epoch 6/200] [Batch 36/637] [D loss: 0.152942] [G loss: 0.480936]\n",
      "[Epoch 6/200] [Batch 37/637] [D loss: 0.143120] [G loss: 0.512793]\n",
      "[Epoch 6/200] [Batch 38/637] [D loss: 0.170787] [G loss: 0.470850]\n",
      "[Epoch 6/200] [Batch 39/637] [D loss: 0.170674] [G loss: 0.601945]\n",
      "[Epoch 6/200] [Batch 40/637] [D loss: 0.166069] [G loss: 0.548507]\n",
      "[Epoch 6/200] [Batch 41/637] [D loss: 0.184472] [G loss: 0.490137]\n",
      "[Epoch 6/200] [Batch 42/637] [D loss: 0.123527] [G loss: 0.571102]\n",
      "[Epoch 6/200] [Batch 43/637] [D loss: 0.141041] [G loss: 0.583213]\n",
      "[Epoch 6/200] [Batch 44/637] [D loss: 0.150691] [G loss: 0.565520]\n",
      "[Epoch 6/200] [Batch 45/637] [D loss: 0.137446] [G loss: 0.458981]\n",
      "[Epoch 6/200] [Batch 46/637] [D loss: 0.166903] [G loss: 0.447756]\n",
      "[Epoch 6/200] [Batch 47/637] [D loss: 0.154333] [G loss: 0.546931]\n",
      "[Epoch 6/200] [Batch 48/637] [D loss: 0.163635] [G loss: 0.591596]\n",
      "[Epoch 6/200] [Batch 49/637] [D loss: 0.136643] [G loss: 0.559001]\n",
      "[Epoch 6/200] [Batch 50/637] [D loss: 0.129257] [G loss: 0.540159]\n",
      "[Epoch 6/200] [Batch 51/637] [D loss: 0.158905] [G loss: 0.576328]\n",
      "[Epoch 6/200] [Batch 52/637] [D loss: 0.162162] [G loss: 0.527617]\n",
      "[Epoch 6/200] [Batch 53/637] [D loss: 0.186136] [G loss: 0.522099]\n",
      "[Epoch 6/200] [Batch 54/637] [D loss: 0.286652] [G loss: 0.586663]\n",
      "[Epoch 6/200] [Batch 55/637] [D loss: 0.191773] [G loss: 0.627867]\n",
      "[Epoch 6/200] [Batch 56/637] [D loss: 0.202256] [G loss: 0.494514]\n",
      "[Epoch 6/200] [Batch 57/637] [D loss: 0.185171] [G loss: 0.473088]\n",
      "[Epoch 6/200] [Batch 58/637] [D loss: 0.164751] [G loss: 0.430985]\n",
      "[Epoch 6/200] [Batch 59/637] [D loss: 0.158146] [G loss: 0.443123]\n",
      "[Epoch 6/200] [Batch 60/637] [D loss: 0.137576] [G loss: 0.497412]\n",
      "[Epoch 6/200] [Batch 61/637] [D loss: 0.142278] [G loss: 0.485645]\n",
      "[Epoch 6/200] [Batch 62/637] [D loss: 0.141889] [G loss: 0.544880]\n",
      "[Epoch 6/200] [Batch 63/637] [D loss: 0.143338] [G loss: 0.546993]\n",
      "[Epoch 6/200] [Batch 64/637] [D loss: 0.141718] [G loss: 0.571041]\n",
      "[Epoch 6/200] [Batch 65/637] [D loss: 0.147362] [G loss: 0.519228]\n",
      "[Epoch 6/200] [Batch 66/637] [D loss: 0.127337] [G loss: 0.488389]\n",
      "[Epoch 6/200] [Batch 67/637] [D loss: 0.170948] [G loss: 0.514520]\n",
      "[Epoch 6/200] [Batch 68/637] [D loss: 0.123415] [G loss: 0.581065]\n",
      "[Epoch 6/200] [Batch 69/637] [D loss: 0.150621] [G loss: 0.576431]\n",
      "[Epoch 6/200] [Batch 70/637] [D loss: 0.145973] [G loss: 0.545417]\n",
      "[Epoch 6/200] [Batch 71/637] [D loss: 0.150078] [G loss: 0.520238]\n",
      "[Epoch 6/200] [Batch 72/637] [D loss: 0.142394] [G loss: 0.522120]\n",
      "[Epoch 6/200] [Batch 73/637] [D loss: 0.133255] [G loss: 0.565115]\n",
      "[Epoch 6/200] [Batch 74/637] [D loss: 0.183202] [G loss: 0.486181]\n",
      "[Epoch 6/200] [Batch 75/637] [D loss: 0.182681] [G loss: 0.580656]\n",
      "[Epoch 6/200] [Batch 76/637] [D loss: 0.144986] [G loss: 0.590470]\n",
      "[Epoch 6/200] [Batch 77/637] [D loss: 0.151635] [G loss: 0.585702]\n",
      "[Epoch 6/200] [Batch 78/637] [D loss: 0.164486] [G loss: 0.541949]\n",
      "[Epoch 6/200] [Batch 79/637] [D loss: 0.154464] [G loss: 0.514596]\n",
      "[Epoch 6/200] [Batch 80/637] [D loss: 0.152026] [G loss: 0.569968]\n",
      "[Epoch 6/200] [Batch 81/637] [D loss: 0.155886] [G loss: 0.512880]\n",
      "[Epoch 6/200] [Batch 82/637] [D loss: 0.151480] [G loss: 0.543334]\n",
      "[Epoch 6/200] [Batch 83/637] [D loss: 0.145056] [G loss: 0.517350]\n",
      "[Epoch 6/200] [Batch 84/637] [D loss: 0.147846] [G loss: 0.563162]\n",
      "[Epoch 6/200] [Batch 85/637] [D loss: 0.148323] [G loss: 0.564916]\n",
      "[Epoch 6/200] [Batch 86/637] [D loss: 0.160986] [G loss: 0.642333]\n",
      "[Epoch 6/200] [Batch 87/637] [D loss: 0.142671] [G loss: 0.555568]\n",
      "[Epoch 6/200] [Batch 88/637] [D loss: 0.172509] [G loss: 0.540234]\n",
      "[Epoch 6/200] [Batch 89/637] [D loss: 0.168117] [G loss: 0.503646]\n",
      "[Epoch 6/200] [Batch 90/637] [D loss: 0.142563] [G loss: 0.525046]\n",
      "[Epoch 6/200] [Batch 91/637] [D loss: 0.144353] [G loss: 0.508024]\n",
      "[Epoch 6/200] [Batch 92/637] [D loss: 0.145242] [G loss: 0.564959]\n",
      "[Epoch 6/200] [Batch 93/637] [D loss: 0.141945] [G loss: 0.537198]\n",
      "[Epoch 6/200] [Batch 94/637] [D loss: 0.137859] [G loss: 0.523761]\n",
      "[Epoch 6/200] [Batch 95/637] [D loss: 0.116068] [G loss: 0.565228]\n",
      "[Epoch 6/200] [Batch 96/637] [D loss: 0.133612] [G loss: 0.554271]\n",
      "[Epoch 6/200] [Batch 97/637] [D loss: 0.139585] [G loss: 0.572036]\n",
      "[Epoch 6/200] [Batch 98/637] [D loss: 0.139344] [G loss: 0.533102]\n",
      "[Epoch 6/200] [Batch 99/637] [D loss: 0.128783] [G loss: 0.541194]\n",
      "[Epoch 6/200] [Batch 100/637] [D loss: 0.155904] [G loss: 0.483930]\n",
      "[Epoch 6/200] [Batch 101/637] [D loss: 0.161221] [G loss: 0.631974]\n",
      "[Epoch 6/200] [Batch 102/637] [D loss: 0.151352] [G loss: 0.620291]\n",
      "[Epoch 6/200] [Batch 103/637] [D loss: 0.148528] [G loss: 0.517912]\n",
      "[Epoch 6/200] [Batch 104/637] [D loss: 0.165826] [G loss: 0.470705]\n",
      "[Epoch 6/200] [Batch 105/637] [D loss: 0.158251] [G loss: 0.524351]\n",
      "[Epoch 6/200] [Batch 106/637] [D loss: 0.151953] [G loss: 0.505352]\n",
      "[Epoch 6/200] [Batch 107/637] [D loss: 0.168023] [G loss: 0.560909]\n",
      "[Epoch 6/200] [Batch 108/637] [D loss: 0.200622] [G loss: 0.603442]\n",
      "[Epoch 6/200] [Batch 109/637] [D loss: 0.150796] [G loss: 0.605723]\n",
      "[Epoch 6/200] [Batch 110/637] [D loss: 0.263282] [G loss: 0.446840]\n",
      "[Epoch 6/200] [Batch 111/637] [D loss: 0.275824] [G loss: 0.616468]\n",
      "[Epoch 6/200] [Batch 112/637] [D loss: 0.185288] [G loss: 0.649049]\n",
      "[Epoch 6/200] [Batch 113/637] [D loss: 0.183557] [G loss: 0.571469]\n",
      "[Epoch 6/200] [Batch 114/637] [D loss: 0.157763] [G loss: 0.483161]\n",
      "[Epoch 6/200] [Batch 115/637] [D loss: 0.163886] [G loss: 0.430348]\n",
      "[Epoch 6/200] [Batch 116/637] [D loss: 0.153007] [G loss: 0.427392]\n",
      "[Epoch 6/200] [Batch 117/637] [D loss: 0.173948] [G loss: 0.433181]\n",
      "[Epoch 6/200] [Batch 118/637] [D loss: 0.164555] [G loss: 0.579989]\n",
      "[Epoch 6/200] [Batch 119/637] [D loss: 0.150235] [G loss: 0.551234]\n",
      "[Epoch 6/200] [Batch 120/637] [D loss: 0.148260] [G loss: 0.471082]\n",
      "[Epoch 6/200] [Batch 121/637] [D loss: 0.150038] [G loss: 0.459364]\n",
      "[Epoch 6/200] [Batch 122/637] [D loss: 0.160344] [G loss: 0.459937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 123/637] [D loss: 0.153593] [G loss: 0.479821]\n",
      "[Epoch 6/200] [Batch 124/637] [D loss: 0.162285] [G loss: 0.578385]\n",
      "[Epoch 6/200] [Batch 125/637] [D loss: 0.177123] [G loss: 0.524826]\n",
      "[Epoch 6/200] [Batch 126/637] [D loss: 0.189117] [G loss: 0.466591]\n",
      "[Epoch 6/200] [Batch 127/637] [D loss: 0.170107] [G loss: 0.455249]\n",
      "[Epoch 6/200] [Batch 128/637] [D loss: 0.164915] [G loss: 0.499826]\n",
      "[Epoch 6/200] [Batch 129/637] [D loss: 0.162857] [G loss: 0.521178]\n",
      "[Epoch 6/200] [Batch 130/637] [D loss: 0.159935] [G loss: 0.523048]\n",
      "[Epoch 6/200] [Batch 131/637] [D loss: 0.155524] [G loss: 0.489085]\n",
      "[Epoch 6/200] [Batch 132/637] [D loss: 0.153854] [G loss: 0.556914]\n",
      "[Epoch 6/200] [Batch 133/637] [D loss: 0.135153] [G loss: 0.569713]\n",
      "[Epoch 6/200] [Batch 134/637] [D loss: 0.154157] [G loss: 0.549333]\n",
      "[Epoch 6/200] [Batch 135/637] [D loss: 0.139697] [G loss: 0.569996]\n",
      "[Epoch 6/200] [Batch 136/637] [D loss: 0.145927] [G loss: 0.572671]\n",
      "[Epoch 6/200] [Batch 137/637] [D loss: 0.135516] [G loss: 0.580291]\n",
      "[Epoch 6/200] [Batch 138/637] [D loss: 0.167178] [G loss: 0.491418]\n",
      "[Epoch 6/200] [Batch 139/637] [D loss: 0.144749] [G loss: 0.525623]\n",
      "[Epoch 6/200] [Batch 140/637] [D loss: 0.140286] [G loss: 0.529729]\n",
      "[Epoch 6/200] [Batch 141/637] [D loss: 0.179789] [G loss: 0.555107]\n",
      "[Epoch 6/200] [Batch 142/637] [D loss: 0.157307] [G loss: 0.629290]\n",
      "[Epoch 6/200] [Batch 143/637] [D loss: 0.133181] [G loss: 0.607052]\n",
      "[Epoch 6/200] [Batch 144/637] [D loss: 0.143705] [G loss: 0.512335]\n",
      "[Epoch 6/200] [Batch 145/637] [D loss: 0.170713] [G loss: 0.504387]\n",
      "[Epoch 6/200] [Batch 146/637] [D loss: 0.145831] [G loss: 0.555218]\n",
      "[Epoch 6/200] [Batch 147/637] [D loss: 0.159760] [G loss: 0.561956]\n",
      "[Epoch 6/200] [Batch 148/637] [D loss: 0.187523] [G loss: 0.487278]\n",
      "[Epoch 6/200] [Batch 149/637] [D loss: 0.159212] [G loss: 0.503345]\n",
      "[Epoch 6/200] [Batch 150/637] [D loss: 0.183535] [G loss: 0.499188]\n",
      "[Epoch 6/200] [Batch 151/637] [D loss: 0.171398] [G loss: 0.561566]\n",
      "[Epoch 6/200] [Batch 152/637] [D loss: 0.157107] [G loss: 0.522252]\n",
      "[Epoch 6/200] [Batch 153/637] [D loss: 0.157189] [G loss: 0.451467]\n",
      "[Epoch 6/200] [Batch 154/637] [D loss: 0.155217] [G loss: 0.520560]\n",
      "[Epoch 6/200] [Batch 155/637] [D loss: 0.155013] [G loss: 0.557231]\n",
      "[Epoch 6/200] [Batch 156/637] [D loss: 0.176869] [G loss: 0.470254]\n",
      "[Epoch 6/200] [Batch 157/637] [D loss: 0.175804] [G loss: 0.549193]\n",
      "[Epoch 6/200] [Batch 158/637] [D loss: 0.166915] [G loss: 0.571012]\n",
      "[Epoch 6/200] [Batch 159/637] [D loss: 0.196509] [G loss: 0.508782]\n",
      "[Epoch 6/200] [Batch 160/637] [D loss: 0.297664] [G loss: 0.524160]\n",
      "[Epoch 6/200] [Batch 161/637] [D loss: 0.198046] [G loss: 0.691584]\n",
      "[Epoch 6/200] [Batch 162/637] [D loss: 0.137106] [G loss: 0.712018]\n",
      "[Epoch 6/200] [Batch 163/637] [D loss: 0.155076] [G loss: 0.535815]\n",
      "[Epoch 6/200] [Batch 164/637] [D loss: 0.163130] [G loss: 0.455216]\n",
      "[Epoch 6/200] [Batch 165/637] [D loss: 0.159844] [G loss: 0.456055]\n",
      "[Epoch 6/200] [Batch 166/637] [D loss: 0.159639] [G loss: 0.484412]\n",
      "[Epoch 6/200] [Batch 167/637] [D loss: 0.132909] [G loss: 0.515281]\n",
      "[Epoch 6/200] [Batch 168/637] [D loss: 0.144042] [G loss: 0.504086]\n",
      "[Epoch 6/200] [Batch 169/637] [D loss: 0.139091] [G loss: 0.568434]\n",
      "[Epoch 6/200] [Batch 170/637] [D loss: 0.158360] [G loss: 0.519771]\n",
      "[Epoch 6/200] [Batch 171/637] [D loss: 0.157510] [G loss: 0.494498]\n",
      "[Epoch 6/200] [Batch 172/637] [D loss: 0.175642] [G loss: 0.500933]\n",
      "[Epoch 6/200] [Batch 173/637] [D loss: 0.142476] [G loss: 0.573738]\n",
      "[Epoch 6/200] [Batch 174/637] [D loss: 0.141012] [G loss: 0.521847]\n",
      "[Epoch 6/200] [Batch 175/637] [D loss: 0.162426] [G loss: 0.464945]\n",
      "[Epoch 6/200] [Batch 176/637] [D loss: 0.161617] [G loss: 0.552411]\n",
      "[Epoch 6/200] [Batch 177/637] [D loss: 0.168588] [G loss: 0.469693]\n",
      "[Epoch 6/200] [Batch 178/637] [D loss: 0.213983] [G loss: 0.429084]\n",
      "[Epoch 6/200] [Batch 179/637] [D loss: 0.221506] [G loss: 0.580225]\n",
      "[Epoch 6/200] [Batch 180/637] [D loss: 0.185647] [G loss: 0.552458]\n",
      "[Epoch 6/200] [Batch 181/637] [D loss: 0.180336] [G loss: 0.516679]\n",
      "[Epoch 6/200] [Batch 182/637] [D loss: 0.151442] [G loss: 0.463249]\n",
      "[Epoch 6/200] [Batch 183/637] [D loss: 0.144501] [G loss: 0.486741]\n",
      "[Epoch 6/200] [Batch 184/637] [D loss: 0.164979] [G loss: 0.477706]\n",
      "[Epoch 6/200] [Batch 185/637] [D loss: 0.162925] [G loss: 0.569137]\n",
      "[Epoch 6/200] [Batch 186/637] [D loss: 0.171003] [G loss: 0.539898]\n",
      "[Epoch 6/200] [Batch 187/637] [D loss: 0.169661] [G loss: 0.474786]\n",
      "[Epoch 6/200] [Batch 188/637] [D loss: 0.144211] [G loss: 0.490273]\n",
      "[Epoch 6/200] [Batch 189/637] [D loss: 0.199238] [G loss: 0.451678]\n",
      "[Epoch 6/200] [Batch 190/637] [D loss: 0.180132] [G loss: 0.687403]\n",
      "[Epoch 6/200] [Batch 191/637] [D loss: 0.160974] [G loss: 0.588534]\n",
      "[Epoch 6/200] [Batch 192/637] [D loss: 0.168689] [G loss: 0.525372]\n",
      "[Epoch 6/200] [Batch 193/637] [D loss: 0.159475] [G loss: 0.505539]\n",
      "[Epoch 6/200] [Batch 194/637] [D loss: 0.163806] [G loss: 0.463586]\n",
      "[Epoch 6/200] [Batch 195/637] [D loss: 0.163276] [G loss: 0.615107]\n",
      "[Epoch 6/200] [Batch 196/637] [D loss: 0.151973] [G loss: 0.557450]\n",
      "[Epoch 6/200] [Batch 197/637] [D loss: 0.181721] [G loss: 0.571252]\n",
      "[Epoch 6/200] [Batch 198/637] [D loss: 0.137244] [G loss: 0.523170]\n",
      "[Epoch 6/200] [Batch 199/637] [D loss: 0.167265] [G loss: 0.546376]\n",
      "[Epoch 6/200] [Batch 200/637] [D loss: 0.127330] [G loss: 0.547546]\n",
      "[Epoch 6/200] [Batch 201/637] [D loss: 0.141370] [G loss: 0.486830]\n",
      "[Epoch 6/200] [Batch 202/637] [D loss: 0.188233] [G loss: 0.465678]\n",
      "[Epoch 6/200] [Batch 203/637] [D loss: 0.256647] [G loss: 0.680249]\n",
      "[Epoch 6/200] [Batch 204/637] [D loss: 0.179357] [G loss: 0.657977]\n",
      "[Epoch 6/200] [Batch 205/637] [D loss: 0.181078] [G loss: 0.602272]\n",
      "[Epoch 6/200] [Batch 206/637] [D loss: 0.144425] [G loss: 0.540338]\n",
      "[Epoch 6/200] [Batch 207/637] [D loss: 0.134899] [G loss: 0.495750]\n",
      "[Epoch 6/200] [Batch 208/637] [D loss: 0.137141] [G loss: 0.493948]\n",
      "[Epoch 6/200] [Batch 209/637] [D loss: 0.137642] [G loss: 0.521932]\n",
      "[Epoch 6/200] [Batch 210/637] [D loss: 0.143575] [G loss: 0.553586]\n",
      "[Epoch 6/200] [Batch 211/637] [D loss: 0.136626] [G loss: 0.581860]\n",
      "[Epoch 6/200] [Batch 212/637] [D loss: 0.143872] [G loss: 0.536000]\n",
      "[Epoch 6/200] [Batch 213/637] [D loss: 0.143997] [G loss: 0.500969]\n",
      "[Epoch 6/200] [Batch 214/637] [D loss: 0.137175] [G loss: 0.575828]\n",
      "[Epoch 6/200] [Batch 215/637] [D loss: 0.153831] [G loss: 0.507117]\n",
      "[Epoch 6/200] [Batch 216/637] [D loss: 0.138915] [G loss: 0.662332]\n",
      "[Epoch 6/200] [Batch 217/637] [D loss: 0.133086] [G loss: 0.580940]\n",
      "[Epoch 6/200] [Batch 218/637] [D loss: 0.130920] [G loss: 0.558439]\n",
      "[Epoch 6/200] [Batch 219/637] [D loss: 0.175519] [G loss: 0.497290]\n",
      "[Epoch 6/200] [Batch 220/637] [D loss: 0.157157] [G loss: 0.540001]\n",
      "[Epoch 6/200] [Batch 221/637] [D loss: 0.164058] [G loss: 0.626442]\n",
      "[Epoch 6/200] [Batch 222/637] [D loss: 0.162023] [G loss: 0.633088]\n",
      "[Epoch 6/200] [Batch 223/637] [D loss: 0.129215] [G loss: 0.588441]\n",
      "[Epoch 6/200] [Batch 224/637] [D loss: 0.162376] [G loss: 0.510710]\n",
      "[Epoch 6/200] [Batch 225/637] [D loss: 0.211239] [G loss: 0.452888]\n",
      "[Epoch 6/200] [Batch 226/637] [D loss: 0.182235] [G loss: 0.583950]\n",
      "[Epoch 6/200] [Batch 227/637] [D loss: 0.174261] [G loss: 0.688258]\n",
      "[Epoch 6/200] [Batch 228/637] [D loss: 0.148211] [G loss: 0.552407]\n",
      "[Epoch 6/200] [Batch 229/637] [D loss: 0.135782] [G loss: 0.596513]\n",
      "[Epoch 6/200] [Batch 230/637] [D loss: 0.144065] [G loss: 0.429068]\n",
      "[Epoch 6/200] [Batch 231/637] [D loss: 0.140449] [G loss: 0.453037]\n",
      "[Epoch 6/200] [Batch 232/637] [D loss: 0.136888] [G loss: 0.523636]\n",
      "[Epoch 6/200] [Batch 233/637] [D loss: 0.142441] [G loss: 0.592706]\n",
      "[Epoch 6/200] [Batch 234/637] [D loss: 0.133997] [G loss: 0.558599]\n",
      "[Epoch 6/200] [Batch 235/637] [D loss: 0.179347] [G loss: 0.448922]\n",
      "[Epoch 6/200] [Batch 236/637] [D loss: 0.144491] [G loss: 0.543005]\n",
      "[Epoch 6/200] [Batch 237/637] [D loss: 0.128138] [G loss: 0.552740]\n",
      "[Epoch 6/200] [Batch 238/637] [D loss: 0.134446] [G loss: 0.513037]\n",
      "[Epoch 6/200] [Batch 239/637] [D loss: 0.146404] [G loss: 0.458884]\n",
      "[Epoch 6/200] [Batch 240/637] [D loss: 0.155177] [G loss: 0.538309]\n",
      "[Epoch 6/200] [Batch 241/637] [D loss: 0.128706] [G loss: 0.653416]\n",
      "[Epoch 6/200] [Batch 242/637] [D loss: 0.148096] [G loss: 0.545073]\n",
      "[Epoch 6/200] [Batch 243/637] [D loss: 0.175146] [G loss: 0.440880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 244/637] [D loss: 0.149985] [G loss: 0.515148]\n",
      "[Epoch 6/200] [Batch 245/637] [D loss: 0.159687] [G loss: 0.585158]\n",
      "[Epoch 6/200] [Batch 246/637] [D loss: 0.120780] [G loss: 0.564500]\n",
      "[Epoch 6/200] [Batch 247/637] [D loss: 0.188926] [G loss: 0.499385]\n",
      "[Epoch 6/200] [Batch 248/637] [D loss: 0.147901] [G loss: 0.525939]\n",
      "[Epoch 6/200] [Batch 249/637] [D loss: 0.158930] [G loss: 0.593173]\n",
      "[Epoch 6/200] [Batch 250/637] [D loss: 0.143982] [G loss: 0.547334]\n",
      "[Epoch 6/200] [Batch 251/637] [D loss: 0.150233] [G loss: 0.534511]\n",
      "[Epoch 6/200] [Batch 252/637] [D loss: 0.130382] [G loss: 0.610546]\n",
      "[Epoch 6/200] [Batch 253/637] [D loss: 0.153712] [G loss: 0.525470]\n",
      "[Epoch 6/200] [Batch 254/637] [D loss: 0.143882] [G loss: 0.520853]\n",
      "[Epoch 6/200] [Batch 255/637] [D loss: 0.152923] [G loss: 0.480131]\n",
      "[Epoch 6/200] [Batch 256/637] [D loss: 0.149524] [G loss: 0.550849]\n",
      "[Epoch 6/200] [Batch 257/637] [D loss: 0.166784] [G loss: 0.570799]\n",
      "[Epoch 6/200] [Batch 258/637] [D loss: 0.162314] [G loss: 0.533384]\n",
      "[Epoch 6/200] [Batch 259/637] [D loss: 0.186129] [G loss: 0.444761]\n",
      "[Epoch 6/200] [Batch 260/637] [D loss: 0.183911] [G loss: 0.526142]\n",
      "[Epoch 6/200] [Batch 261/637] [D loss: 0.173088] [G loss: 0.567429]\n",
      "[Epoch 6/200] [Batch 262/637] [D loss: 0.150695] [G loss: 0.533757]\n",
      "[Epoch 6/200] [Batch 263/637] [D loss: 0.156551] [G loss: 0.494767]\n",
      "[Epoch 6/200] [Batch 264/637] [D loss: 0.172830] [G loss: 0.476335]\n",
      "[Epoch 6/200] [Batch 265/637] [D loss: 0.183555] [G loss: 0.555696]\n",
      "[Epoch 6/200] [Batch 266/637] [D loss: 0.134788] [G loss: 0.537703]\n",
      "[Epoch 6/200] [Batch 267/637] [D loss: 0.178938] [G loss: 0.529175]\n",
      "[Epoch 6/200] [Batch 268/637] [D loss: 0.164861] [G loss: 0.553001]\n",
      "[Epoch 6/200] [Batch 269/637] [D loss: 0.148350] [G loss: 0.571758]\n",
      "[Epoch 6/200] [Batch 270/637] [D loss: 0.150420] [G loss: 0.610156]\n",
      "[Epoch 6/200] [Batch 271/637] [D loss: 0.135260] [G loss: 0.561385]\n",
      "[Epoch 6/200] [Batch 272/637] [D loss: 0.141409] [G loss: 0.525397]\n",
      "[Epoch 6/200] [Batch 273/637] [D loss: 0.172363] [G loss: 0.516083]\n",
      "[Epoch 6/200] [Batch 274/637] [D loss: 0.145197] [G loss: 0.502039]\n",
      "[Epoch 6/200] [Batch 275/637] [D loss: 0.143129] [G loss: 0.528167]\n",
      "[Epoch 6/200] [Batch 276/637] [D loss: 0.130747] [G loss: 0.530713]\n",
      "[Epoch 6/200] [Batch 277/637] [D loss: 0.145088] [G loss: 0.543306]\n",
      "[Epoch 6/200] [Batch 278/637] [D loss: 0.155538] [G loss: 0.523645]\n",
      "[Epoch 6/200] [Batch 279/637] [D loss: 0.163443] [G loss: 0.533617]\n",
      "[Epoch 6/200] [Batch 280/637] [D loss: 0.134691] [G loss: 0.547369]\n",
      "[Epoch 6/200] [Batch 281/637] [D loss: 0.161366] [G loss: 0.493145]\n",
      "[Epoch 6/200] [Batch 282/637] [D loss: 0.150610] [G loss: 0.565144]\n",
      "[Epoch 6/200] [Batch 283/637] [D loss: 0.167689] [G loss: 0.491742]\n",
      "[Epoch 6/200] [Batch 284/637] [D loss: 0.174315] [G loss: 0.434509]\n",
      "[Epoch 6/200] [Batch 285/637] [D loss: 0.183552] [G loss: 0.606584]\n",
      "[Epoch 6/200] [Batch 286/637] [D loss: 0.165049] [G loss: 0.602303]\n",
      "[Epoch 6/200] [Batch 287/637] [D loss: 0.168346] [G loss: 0.514255]\n",
      "[Epoch 6/200] [Batch 288/637] [D loss: 0.158923] [G loss: 0.443528]\n",
      "[Epoch 6/200] [Batch 289/637] [D loss: 0.179829] [G loss: 0.497782]\n",
      "[Epoch 6/200] [Batch 290/637] [D loss: 0.157559] [G loss: 0.735858]\n",
      "[Epoch 6/200] [Batch 291/637] [D loss: 0.141380] [G loss: 0.592229]\n",
      "[Epoch 6/200] [Batch 292/637] [D loss: 0.150914] [G loss: 0.474478]\n",
      "[Epoch 6/200] [Batch 293/637] [D loss: 0.150169] [G loss: 0.511300]\n",
      "[Epoch 6/200] [Batch 294/637] [D loss: 0.130617] [G loss: 0.594037]\n",
      "[Epoch 6/200] [Batch 295/637] [D loss: 0.114126] [G loss: 0.604954]\n",
      "[Epoch 6/200] [Batch 296/637] [D loss: 0.142249] [G loss: 0.566944]\n",
      "[Epoch 6/200] [Batch 297/637] [D loss: 0.138918] [G loss: 0.490561]\n",
      "[Epoch 6/200] [Batch 298/637] [D loss: 0.141686] [G loss: 0.560898]\n",
      "[Epoch 6/200] [Batch 299/637] [D loss: 0.126485] [G loss: 0.589659]\n",
      "[Epoch 6/200] [Batch 300/637] [D loss: 0.132756] [G loss: 0.547972]\n",
      "[Epoch 6/200] [Batch 301/637] [D loss: 0.141219] [G loss: 0.565585]\n",
      "[Epoch 6/200] [Batch 302/637] [D loss: 0.137501] [G loss: 0.517995]\n",
      "[Epoch 6/200] [Batch 303/637] [D loss: 0.137575] [G loss: 0.485877]\n",
      "[Epoch 6/200] [Batch 304/637] [D loss: 0.144485] [G loss: 0.561343]\n",
      "[Epoch 6/200] [Batch 305/637] [D loss: 0.139327] [G loss: 0.523522]\n",
      "[Epoch 6/200] [Batch 306/637] [D loss: 0.163063] [G loss: 0.538880]\n",
      "[Epoch 6/200] [Batch 307/637] [D loss: 0.149221] [G loss: 0.472494]\n",
      "[Epoch 6/200] [Batch 308/637] [D loss: 0.164324] [G loss: 0.536504]\n",
      "[Epoch 6/200] [Batch 309/637] [D loss: 0.165633] [G loss: 0.539830]\n",
      "[Epoch 6/200] [Batch 310/637] [D loss: 0.175276] [G loss: 0.468875]\n",
      "[Epoch 6/200] [Batch 311/637] [D loss: 0.161759] [G loss: 0.480942]\n",
      "[Epoch 6/200] [Batch 312/637] [D loss: 0.169523] [G loss: 0.487786]\n",
      "[Epoch 6/200] [Batch 313/637] [D loss: 0.174195] [G loss: 0.474297]\n",
      "[Epoch 6/200] [Batch 314/637] [D loss: 0.148183] [G loss: 0.523812]\n",
      "[Epoch 6/200] [Batch 315/637] [D loss: 0.148617] [G loss: 0.556249]\n",
      "[Epoch 6/200] [Batch 316/637] [D loss: 0.145043] [G loss: 0.486143]\n",
      "[Epoch 6/200] [Batch 317/637] [D loss: 0.137263] [G loss: 0.507138]\n",
      "[Epoch 6/200] [Batch 318/637] [D loss: 0.151891] [G loss: 0.551960]\n",
      "[Epoch 6/200] [Batch 319/637] [D loss: 0.161901] [G loss: 0.560153]\n",
      "[Epoch 6/200] [Batch 320/637] [D loss: 0.160218] [G loss: 0.528293]\n",
      "[Epoch 6/200] [Batch 321/637] [D loss: 0.170035] [G loss: 0.456800]\n",
      "[Epoch 6/200] [Batch 322/637] [D loss: 0.141708] [G loss: 0.493099]\n",
      "[Epoch 6/200] [Batch 323/637] [D loss: 0.152018] [G loss: 0.503043]\n",
      "[Epoch 6/200] [Batch 324/637] [D loss: 0.150065] [G loss: 0.566880]\n",
      "[Epoch 6/200] [Batch 325/637] [D loss: 0.129337] [G loss: 0.554071]\n",
      "[Epoch 6/200] [Batch 326/637] [D loss: 0.158275] [G loss: 0.576829]\n",
      "[Epoch 6/200] [Batch 327/637] [D loss: 0.167986] [G loss: 0.524697]\n",
      "[Epoch 6/200] [Batch 328/637] [D loss: 0.173174] [G loss: 0.510647]\n",
      "[Epoch 6/200] [Batch 329/637] [D loss: 0.152005] [G loss: 0.588003]\n",
      "[Epoch 6/200] [Batch 330/637] [D loss: 0.137269] [G loss: 0.601846]\n",
      "[Epoch 6/200] [Batch 331/637] [D loss: 0.109204] [G loss: 0.587245]\n",
      "[Epoch 6/200] [Batch 332/637] [D loss: 0.149347] [G loss: 0.478661]\n",
      "[Epoch 6/200] [Batch 333/637] [D loss: 0.169300] [G loss: 0.467991]\n",
      "[Epoch 6/200] [Batch 334/637] [D loss: 0.163961] [G loss: 0.692366]\n",
      "[Epoch 6/200] [Batch 335/637] [D loss: 0.144483] [G loss: 0.587533]\n",
      "[Epoch 6/200] [Batch 336/637] [D loss: 0.144768] [G loss: 0.536335]\n",
      "[Epoch 6/200] [Batch 337/637] [D loss: 0.135191] [G loss: 0.532298]\n",
      "[Epoch 6/200] [Batch 338/637] [D loss: 0.136303] [G loss: 0.535800]\n",
      "[Epoch 6/200] [Batch 339/637] [D loss: 0.132218] [G loss: 0.564128]\n",
      "[Epoch 6/200] [Batch 340/637] [D loss: 0.124487] [G loss: 0.596754]\n",
      "[Epoch 6/200] [Batch 341/637] [D loss: 0.140314] [G loss: 0.584910]\n",
      "[Epoch 6/200] [Batch 342/637] [D loss: 0.135300] [G loss: 0.562516]\n",
      "[Epoch 6/200] [Batch 343/637] [D loss: 0.151057] [G loss: 0.584891]\n",
      "[Epoch 6/200] [Batch 344/637] [D loss: 0.159313] [G loss: 0.597556]\n",
      "[Epoch 6/200] [Batch 345/637] [D loss: 0.155960] [G loss: 0.508305]\n",
      "[Epoch 6/200] [Batch 346/637] [D loss: 0.160757] [G loss: 0.491257]\n",
      "[Epoch 6/200] [Batch 347/637] [D loss: 0.187493] [G loss: 0.688371]\n",
      "[Epoch 6/200] [Batch 348/637] [D loss: 0.161157] [G loss: 0.642922]\n",
      "[Epoch 6/200] [Batch 349/637] [D loss: 0.144071] [G loss: 0.544311]\n",
      "[Epoch 6/200] [Batch 350/637] [D loss: 0.149944] [G loss: 0.504493]\n",
      "[Epoch 6/200] [Batch 351/637] [D loss: 0.160512] [G loss: 0.442818]\n",
      "[Epoch 6/200] [Batch 352/637] [D loss: 0.148143] [G loss: 0.548510]\n",
      "[Epoch 6/200] [Batch 353/637] [D loss: 0.134609] [G loss: 0.648670]\n",
      "[Epoch 6/200] [Batch 354/637] [D loss: 0.132144] [G loss: 0.557905]\n",
      "[Epoch 6/200] [Batch 355/637] [D loss: 0.152914] [G loss: 0.541767]\n",
      "[Epoch 6/200] [Batch 356/637] [D loss: 0.130406] [G loss: 0.601102]\n",
      "[Epoch 6/200] [Batch 357/637] [D loss: 0.136030] [G loss: 0.559833]\n",
      "[Epoch 6/200] [Batch 358/637] [D loss: 0.147248] [G loss: 0.567024]\n",
      "[Epoch 6/200] [Batch 359/637] [D loss: 0.142376] [G loss: 0.550291]\n",
      "[Epoch 6/200] [Batch 360/637] [D loss: 0.155027] [G loss: 0.558175]\n",
      "[Epoch 6/200] [Batch 361/637] [D loss: 0.148030] [G loss: 0.528590]\n",
      "[Epoch 6/200] [Batch 362/637] [D loss: 0.162765] [G loss: 0.564789]\n",
      "[Epoch 6/200] [Batch 363/637] [D loss: 0.135906] [G loss: 0.509525]\n",
      "[Epoch 6/200] [Batch 364/637] [D loss: 0.142232] [G loss: 0.540182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 365/637] [D loss: 0.128179] [G loss: 0.621409]\n",
      "[Epoch 6/200] [Batch 366/637] [D loss: 0.115652] [G loss: 0.596098]\n",
      "[Epoch 6/200] [Batch 367/637] [D loss: 0.131897] [G loss: 0.536185]\n",
      "[Epoch 6/200] [Batch 368/637] [D loss: 0.193647] [G loss: 0.649028]\n",
      "[Epoch 6/200] [Batch 369/637] [D loss: 0.151194] [G loss: 0.641775]\n",
      "[Epoch 6/200] [Batch 370/637] [D loss: 0.149366] [G loss: 0.704566]\n",
      "[Epoch 6/200] [Batch 371/637] [D loss: 0.162789] [G loss: 0.629167]\n",
      "[Epoch 6/200] [Batch 372/637] [D loss: 0.139773] [G loss: 0.518946]\n",
      "[Epoch 6/200] [Batch 373/637] [D loss: 0.145431] [G loss: 0.488699]\n",
      "[Epoch 6/200] [Batch 374/637] [D loss: 0.149676] [G loss: 0.544411]\n",
      "[Epoch 6/200] [Batch 375/637] [D loss: 0.125390] [G loss: 0.578828]\n",
      "[Epoch 6/200] [Batch 376/637] [D loss: 0.140758] [G loss: 0.542275]\n",
      "[Epoch 6/200] [Batch 377/637] [D loss: 0.147306] [G loss: 0.511486]\n",
      "[Epoch 6/200] [Batch 378/637] [D loss: 0.161526] [G loss: 0.524826]\n",
      "[Epoch 6/200] [Batch 379/637] [D loss: 0.154343] [G loss: 0.578059]\n",
      "[Epoch 6/200] [Batch 380/637] [D loss: 0.177393] [G loss: 0.492749]\n",
      "[Epoch 6/200] [Batch 381/637] [D loss: 0.184711] [G loss: 0.536658]\n",
      "[Epoch 6/200] [Batch 382/637] [D loss: 0.156809] [G loss: 0.470691]\n",
      "[Epoch 6/200] [Batch 383/637] [D loss: 0.170020] [G loss: 0.533219]\n",
      "[Epoch 6/200] [Batch 384/637] [D loss: 0.171194] [G loss: 0.618044]\n",
      "[Epoch 6/200] [Batch 385/637] [D loss: 0.178827] [G loss: 0.548098]\n",
      "[Epoch 6/200] [Batch 386/637] [D loss: 0.183682] [G loss: 0.524640]\n",
      "[Epoch 6/200] [Batch 387/637] [D loss: 0.156282] [G loss: 0.517618]\n",
      "[Epoch 6/200] [Batch 388/637] [D loss: 0.154129] [G loss: 0.491495]\n",
      "[Epoch 6/200] [Batch 389/637] [D loss: 0.150958] [G loss: 0.659629]\n",
      "[Epoch 6/200] [Batch 390/637] [D loss: 0.168311] [G loss: 0.559224]\n",
      "[Epoch 6/200] [Batch 391/637] [D loss: 0.159418] [G loss: 0.496438]\n",
      "[Epoch 6/200] [Batch 392/637] [D loss: 0.166973] [G loss: 0.502613]\n",
      "[Epoch 6/200] [Batch 393/637] [D loss: 0.133401] [G loss: 0.620659]\n",
      "[Epoch 6/200] [Batch 394/637] [D loss: 0.213729] [G loss: 0.463935]\n",
      "[Epoch 6/200] [Batch 395/637] [D loss: 0.243265] [G loss: 0.896232]\n",
      "[Epoch 6/200] [Batch 396/637] [D loss: 0.179228] [G loss: 0.640793]\n",
      "[Epoch 6/200] [Batch 397/637] [D loss: 0.155424] [G loss: 0.549556]\n",
      "[Epoch 6/200] [Batch 398/637] [D loss: 0.192062] [G loss: 0.483223]\n",
      "[Epoch 6/200] [Batch 399/637] [D loss: 0.165633] [G loss: 0.463294]\n",
      "[Epoch 6/200] [Batch 400/637] [D loss: 0.138775] [G loss: 0.538869]\n",
      "[Epoch 6/200] [Batch 401/637] [D loss: 0.128935] [G loss: 0.546012]\n",
      "[Epoch 6/200] [Batch 402/637] [D loss: 0.132340] [G loss: 0.496280]\n",
      "[Epoch 6/200] [Batch 403/637] [D loss: 0.132883] [G loss: 0.598496]\n",
      "[Epoch 6/200] [Batch 404/637] [D loss: 0.122802] [G loss: 0.568459]\n",
      "[Epoch 6/200] [Batch 405/637] [D loss: 0.114537] [G loss: 0.625919]\n",
      "[Epoch 6/200] [Batch 406/637] [D loss: 0.147052] [G loss: 0.605193]\n",
      "[Epoch 6/200] [Batch 407/637] [D loss: 0.151057] [G loss: 0.567731]\n",
      "[Epoch 6/200] [Batch 408/637] [D loss: 0.162583] [G loss: 0.456008]\n",
      "[Epoch 6/200] [Batch 409/637] [D loss: 0.153236] [G loss: 0.547700]\n",
      "[Epoch 6/200] [Batch 410/637] [D loss: 0.157603] [G loss: 0.506928]\n",
      "[Epoch 6/200] [Batch 411/637] [D loss: 0.155547] [G loss: 0.505506]\n",
      "[Epoch 6/200] [Batch 412/637] [D loss: 0.155729] [G loss: 0.497896]\n",
      "[Epoch 6/200] [Batch 413/637] [D loss: 0.214837] [G loss: 0.595048]\n",
      "[Epoch 6/200] [Batch 414/637] [D loss: 0.170841] [G loss: 0.635757]\n",
      "[Epoch 6/200] [Batch 415/637] [D loss: 0.192003] [G loss: 0.550625]\n",
      "[Epoch 6/200] [Batch 416/637] [D loss: 0.171095] [G loss: 0.460844]\n",
      "[Epoch 6/200] [Batch 417/637] [D loss: 0.152197] [G loss: 0.592268]\n",
      "[Epoch 6/200] [Batch 418/637] [D loss: 0.166418] [G loss: 0.464687]\n",
      "[Epoch 6/200] [Batch 419/637] [D loss: 0.147866] [G loss: 0.473589]\n",
      "[Epoch 6/200] [Batch 420/637] [D loss: 0.167998] [G loss: 0.466390]\n",
      "[Epoch 6/200] [Batch 421/637] [D loss: 0.141700] [G loss: 0.516615]\n",
      "[Epoch 6/200] [Batch 422/637] [D loss: 0.154095] [G loss: 0.531865]\n",
      "[Epoch 6/200] [Batch 423/637] [D loss: 0.135231] [G loss: 0.541979]\n",
      "[Epoch 6/200] [Batch 424/637] [D loss: 0.134499] [G loss: 0.514721]\n",
      "[Epoch 6/200] [Batch 425/637] [D loss: 0.143800] [G loss: 0.517861]\n",
      "[Epoch 6/200] [Batch 426/637] [D loss: 0.162913] [G loss: 0.585671]\n",
      "[Epoch 6/200] [Batch 427/637] [D loss: 0.144600] [G loss: 0.588622]\n",
      "[Epoch 6/200] [Batch 428/637] [D loss: 0.128765] [G loss: 0.569602]\n",
      "[Epoch 6/200] [Batch 429/637] [D loss: 0.142249] [G loss: 0.451022]\n",
      "[Epoch 6/200] [Batch 430/637] [D loss: 0.156671] [G loss: 0.548675]\n",
      "[Epoch 6/200] [Batch 431/637] [D loss: 0.163289] [G loss: 0.609774]\n",
      "[Epoch 6/200] [Batch 432/637] [D loss: 0.173483] [G loss: 0.639455]\n",
      "[Epoch 6/200] [Batch 433/637] [D loss: 0.175423] [G loss: 0.564431]\n",
      "[Epoch 6/200] [Batch 434/637] [D loss: 0.149162] [G loss: 0.541019]\n",
      "[Epoch 6/200] [Batch 435/637] [D loss: 0.181402] [G loss: 0.438659]\n",
      "[Epoch 6/200] [Batch 436/637] [D loss: 0.163002] [G loss: 0.481652]\n",
      "[Epoch 6/200] [Batch 437/637] [D loss: 0.145283] [G loss: 0.534758]\n",
      "[Epoch 6/200] [Batch 438/637] [D loss: 0.148847] [G loss: 0.537100]\n",
      "[Epoch 6/200] [Batch 439/637] [D loss: 0.157988] [G loss: 0.534800]\n",
      "[Epoch 6/200] [Batch 440/637] [D loss: 0.159100] [G loss: 0.506501]\n",
      "[Epoch 6/200] [Batch 441/637] [D loss: 0.173496] [G loss: 0.444299]\n",
      "[Epoch 6/200] [Batch 442/637] [D loss: 0.185434] [G loss: 0.494892]\n",
      "[Epoch 6/200] [Batch 443/637] [D loss: 0.182831] [G loss: 0.540051]\n",
      "[Epoch 6/200] [Batch 444/637] [D loss: 0.166648] [G loss: 0.503222]\n",
      "[Epoch 6/200] [Batch 445/637] [D loss: 0.194176] [G loss: 0.444641]\n",
      "[Epoch 6/200] [Batch 446/637] [D loss: 0.217436] [G loss: 0.479971]\n",
      "[Epoch 6/200] [Batch 447/637] [D loss: 0.175481] [G loss: 0.495142]\n",
      "[Epoch 6/200] [Batch 448/637] [D loss: 0.192368] [G loss: 0.468300]\n",
      "[Epoch 6/200] [Batch 449/637] [D loss: 0.166238] [G loss: 0.499363]\n",
      "[Epoch 6/200] [Batch 450/637] [D loss: 0.160219] [G loss: 0.513155]\n",
      "[Epoch 6/200] [Batch 451/637] [D loss: 0.166212] [G loss: 0.503525]\n",
      "[Epoch 6/200] [Batch 452/637] [D loss: 0.171353] [G loss: 0.477381]\n",
      "[Epoch 6/200] [Batch 453/637] [D loss: 0.175622] [G loss: 0.546420]\n",
      "[Epoch 6/200] [Batch 454/637] [D loss: 0.165380] [G loss: 0.566200]\n",
      "[Epoch 6/200] [Batch 455/637] [D loss: 0.143361] [G loss: 0.557693]\n",
      "[Epoch 6/200] [Batch 456/637] [D loss: 0.147014] [G loss: 0.508997]\n",
      "[Epoch 6/200] [Batch 457/637] [D loss: 0.143586] [G loss: 0.507981]\n",
      "[Epoch 6/200] [Batch 458/637] [D loss: 0.124092] [G loss: 0.571543]\n",
      "[Epoch 6/200] [Batch 459/637] [D loss: 0.105833] [G loss: 0.592436]\n",
      "[Epoch 6/200] [Batch 460/637] [D loss: 0.132715] [G loss: 0.555643]\n",
      "[Epoch 6/200] [Batch 461/637] [D loss: 0.142098] [G loss: 0.596611]\n",
      "[Epoch 6/200] [Batch 462/637] [D loss: 0.141508] [G loss: 0.574022]\n",
      "[Epoch 6/200] [Batch 463/637] [D loss: 0.145704] [G loss: 0.513690]\n",
      "[Epoch 6/200] [Batch 464/637] [D loss: 0.136735] [G loss: 0.517307]\n",
      "[Epoch 6/200] [Batch 465/637] [D loss: 0.139639] [G loss: 0.589003]\n",
      "[Epoch 6/200] [Batch 466/637] [D loss: 0.168743] [G loss: 0.579781]\n",
      "[Epoch 6/200] [Batch 467/637] [D loss: 0.158645] [G loss: 0.526375]\n",
      "[Epoch 6/200] [Batch 468/637] [D loss: 0.170700] [G loss: 0.520795]\n",
      "[Epoch 6/200] [Batch 469/637] [D loss: 0.179526] [G loss: 0.512295]\n",
      "[Epoch 6/200] [Batch 470/637] [D loss: 0.166242] [G loss: 0.578213]\n",
      "[Epoch 6/200] [Batch 471/637] [D loss: 0.175977] [G loss: 0.514013]\n",
      "[Epoch 6/200] [Batch 472/637] [D loss: 0.160528] [G loss: 0.515218]\n",
      "[Epoch 6/200] [Batch 473/637] [D loss: 0.164565] [G loss: 0.571831]\n",
      "[Epoch 6/200] [Batch 474/637] [D loss: 0.157083] [G loss: 0.524475]\n",
      "[Epoch 6/200] [Batch 475/637] [D loss: 0.151347] [G loss: 0.522139]\n",
      "[Epoch 6/200] [Batch 476/637] [D loss: 0.146571] [G loss: 0.602569]\n",
      "[Epoch 6/200] [Batch 477/637] [D loss: 0.141903] [G loss: 0.520406]\n",
      "[Epoch 6/200] [Batch 478/637] [D loss: 0.166333] [G loss: 0.496505]\n",
      "[Epoch 6/200] [Batch 479/637] [D loss: 0.128916] [G loss: 0.581803]\n",
      "[Epoch 6/200] [Batch 480/637] [D loss: 0.167953] [G loss: 0.573994]\n",
      "[Epoch 6/200] [Batch 481/637] [D loss: 0.167839] [G loss: 0.532532]\n",
      "[Epoch 6/200] [Batch 482/637] [D loss: 0.148714] [G loss: 0.514817]\n",
      "[Epoch 6/200] [Batch 483/637] [D loss: 0.167166] [G loss: 0.478794]\n",
      "[Epoch 6/200] [Batch 484/637] [D loss: 0.131169] [G loss: 0.581323]\n",
      "[Epoch 6/200] [Batch 485/637] [D loss: 0.145521] [G loss: 0.530521]\n",
      "[Epoch 6/200] [Batch 486/637] [D loss: 0.142024] [G loss: 0.522577]\n",
      "[Epoch 6/200] [Batch 487/637] [D loss: 0.141372] [G loss: 0.582668]\n",
      "[Epoch 6/200] [Batch 488/637] [D loss: 0.160922] [G loss: 0.538841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 489/637] [D loss: 0.164733] [G loss: 0.573869]\n",
      "[Epoch 6/200] [Batch 490/637] [D loss: 0.130131] [G loss: 0.632181]\n",
      "[Epoch 6/200] [Batch 491/637] [D loss: 0.153984] [G loss: 0.521041]\n",
      "[Epoch 6/200] [Batch 492/637] [D loss: 0.137582] [G loss: 0.469713]\n",
      "[Epoch 6/200] [Batch 493/637] [D loss: 0.134969] [G loss: 0.487420]\n",
      "[Epoch 6/200] [Batch 494/637] [D loss: 0.122239] [G loss: 0.629857]\n",
      "[Epoch 6/200] [Batch 495/637] [D loss: 0.162312] [G loss: 0.588633]\n",
      "[Epoch 6/200] [Batch 496/637] [D loss: 0.151895] [G loss: 0.533093]\n",
      "[Epoch 6/200] [Batch 497/637] [D loss: 0.164149] [G loss: 0.595393]\n",
      "[Epoch 6/200] [Batch 498/637] [D loss: 0.160162] [G loss: 0.553205]\n",
      "[Epoch 6/200] [Batch 499/637] [D loss: 0.180924] [G loss: 0.483404]\n",
      "[Epoch 6/200] [Batch 500/637] [D loss: 0.172393] [G loss: 0.552015]\n",
      "[Epoch 6/200] [Batch 501/637] [D loss: 0.128019] [G loss: 0.596262]\n",
      "[Epoch 6/200] [Batch 502/637] [D loss: 0.135188] [G loss: 0.459499]\n",
      "[Epoch 6/200] [Batch 503/637] [D loss: 0.179230] [G loss: 0.525372]\n",
      "[Epoch 6/200] [Batch 504/637] [D loss: 0.146977] [G loss: 0.625600]\n",
      "[Epoch 6/200] [Batch 505/637] [D loss: 0.162005] [G loss: 0.575334]\n",
      "[Epoch 6/200] [Batch 506/637] [D loss: 0.183947] [G loss: 0.503189]\n",
      "[Epoch 6/200] [Batch 507/637] [D loss: 0.175095] [G loss: 0.518143]\n",
      "[Epoch 6/200] [Batch 508/637] [D loss: 0.131498] [G loss: 0.603102]\n",
      "[Epoch 6/200] [Batch 509/637] [D loss: 0.125538] [G loss: 0.528116]\n",
      "[Epoch 6/200] [Batch 510/637] [D loss: 0.113509] [G loss: 0.546731]\n",
      "[Epoch 6/200] [Batch 511/637] [D loss: 0.143259] [G loss: 0.454666]\n",
      "[Epoch 6/200] [Batch 512/637] [D loss: 0.133311] [G loss: 0.530307]\n",
      "[Epoch 6/200] [Batch 513/637] [D loss: 0.117973] [G loss: 0.572756]\n",
      "[Epoch 6/200] [Batch 514/637] [D loss: 0.147869] [G loss: 0.601341]\n",
      "[Epoch 6/200] [Batch 515/637] [D loss: 0.120442] [G loss: 0.623638]\n",
      "[Epoch 6/200] [Batch 516/637] [D loss: 0.131386] [G loss: 0.537032]\n",
      "[Epoch 6/200] [Batch 517/637] [D loss: 0.147440] [G loss: 0.546599]\n",
      "[Epoch 6/200] [Batch 518/637] [D loss: 0.145998] [G loss: 0.566183]\n",
      "[Epoch 6/200] [Batch 519/637] [D loss: 0.130539] [G loss: 0.607706]\n",
      "[Epoch 6/200] [Batch 520/637] [D loss: 0.176589] [G loss: 0.599415]\n",
      "[Epoch 6/200] [Batch 521/637] [D loss: 0.145315] [G loss: 0.595698]\n",
      "[Epoch 6/200] [Batch 522/637] [D loss: 0.158124] [G loss: 0.559945]\n",
      "[Epoch 6/200] [Batch 523/637] [D loss: 0.156325] [G loss: 0.521390]\n",
      "[Epoch 6/200] [Batch 524/637] [D loss: 0.127748] [G loss: 0.598914]\n",
      "[Epoch 6/200] [Batch 525/637] [D loss: 0.112537] [G loss: 0.568483]\n",
      "[Epoch 6/200] [Batch 526/637] [D loss: 0.146411] [G loss: 0.534775]\n",
      "[Epoch 6/200] [Batch 527/637] [D loss: 0.179060] [G loss: 0.611149]\n",
      "[Epoch 6/200] [Batch 528/637] [D loss: 0.124399] [G loss: 0.698219]\n",
      "[Epoch 6/200] [Batch 529/637] [D loss: 0.130929] [G loss: 0.610732]\n",
      "[Epoch 6/200] [Batch 530/637] [D loss: 0.161315] [G loss: 0.490171]\n",
      "[Epoch 6/200] [Batch 531/637] [D loss: 0.226437] [G loss: 0.593240]\n",
      "[Epoch 6/200] [Batch 532/637] [D loss: 0.148228] [G loss: 0.600141]\n",
      "[Epoch 6/200] [Batch 533/637] [D loss: 0.169392] [G loss: 0.472951]\n",
      "[Epoch 6/200] [Batch 534/637] [D loss: 0.139832] [G loss: 0.509640]\n",
      "[Epoch 6/200] [Batch 535/637] [D loss: 0.138498] [G loss: 0.487137]\n",
      "[Epoch 6/200] [Batch 536/637] [D loss: 0.149008] [G loss: 0.537883]\n",
      "[Epoch 6/200] [Batch 537/637] [D loss: 0.140958] [G loss: 0.645499]\n",
      "[Epoch 6/200] [Batch 538/637] [D loss: 0.107830] [G loss: 0.565259]\n",
      "[Epoch 6/200] [Batch 539/637] [D loss: 0.165380] [G loss: 0.499344]\n",
      "[Epoch 6/200] [Batch 540/637] [D loss: 0.142706] [G loss: 0.659546]\n",
      "[Epoch 6/200] [Batch 541/637] [D loss: 0.120697] [G loss: 0.581982]\n",
      "[Epoch 6/200] [Batch 542/637] [D loss: 0.128156] [G loss: 0.600039]\n",
      "[Epoch 6/200] [Batch 543/637] [D loss: 0.146358] [G loss: 0.573598]\n",
      "[Epoch 6/200] [Batch 544/637] [D loss: 0.134806] [G loss: 0.592547]\n",
      "[Epoch 6/200] [Batch 545/637] [D loss: 0.135792] [G loss: 0.590302]\n",
      "[Epoch 6/200] [Batch 546/637] [D loss: 0.139153] [G loss: 0.541250]\n",
      "[Epoch 6/200] [Batch 547/637] [D loss: 0.136698] [G loss: 0.512776]\n",
      "[Epoch 6/200] [Batch 548/637] [D loss: 0.123148] [G loss: 0.655919]\n",
      "[Epoch 6/200] [Batch 549/637] [D loss: 0.141196] [G loss: 0.608160]\n",
      "[Epoch 6/200] [Batch 550/637] [D loss: 0.142205] [G loss: 0.566725]\n",
      "[Epoch 6/200] [Batch 551/637] [D loss: 0.126667] [G loss: 0.633153]\n",
      "[Epoch 6/200] [Batch 552/637] [D loss: 0.138793] [G loss: 0.605757]\n",
      "[Epoch 6/200] [Batch 553/637] [D loss: 0.150796] [G loss: 0.618401]\n",
      "[Epoch 6/200] [Batch 554/637] [D loss: 0.186318] [G loss: 0.554855]\n",
      "[Epoch 6/200] [Batch 555/637] [D loss: 0.241920] [G loss: 0.613360]\n",
      "[Epoch 6/200] [Batch 556/637] [D loss: 0.182089] [G loss: 0.648237]\n",
      "[Epoch 6/200] [Batch 557/637] [D loss: 0.174418] [G loss: 0.535267]\n",
      "[Epoch 6/200] [Batch 558/637] [D loss: 0.145349] [G loss: 0.545862]\n",
      "[Epoch 6/200] [Batch 559/637] [D loss: 0.146635] [G loss: 0.523200]\n",
      "[Epoch 6/200] [Batch 560/637] [D loss: 0.129002] [G loss: 0.491448]\n",
      "[Epoch 6/200] [Batch 561/637] [D loss: 0.123422] [G loss: 0.534098]\n",
      "[Epoch 6/200] [Batch 562/637] [D loss: 0.134331] [G loss: 0.497226]\n",
      "[Epoch 6/200] [Batch 563/637] [D loss: 0.123262] [G loss: 0.557955]\n",
      "[Epoch 6/200] [Batch 564/637] [D loss: 0.136797] [G loss: 0.516873]\n",
      "[Epoch 6/200] [Batch 565/637] [D loss: 0.124006] [G loss: 0.566896]\n",
      "[Epoch 6/200] [Batch 566/637] [D loss: 0.131846] [G loss: 0.521580]\n",
      "[Epoch 6/200] [Batch 567/637] [D loss: 0.135221] [G loss: 0.513665]\n",
      "[Epoch 6/200] [Batch 568/637] [D loss: 0.153772] [G loss: 0.549873]\n",
      "[Epoch 6/200] [Batch 569/637] [D loss: 0.145315] [G loss: 0.515566]\n",
      "[Epoch 6/200] [Batch 570/637] [D loss: 0.138241] [G loss: 0.575480]\n",
      "[Epoch 6/200] [Batch 571/637] [D loss: 0.145303] [G loss: 0.544271]\n",
      "[Epoch 6/200] [Batch 572/637] [D loss: 0.144209] [G loss: 0.530727]\n",
      "[Epoch 6/200] [Batch 573/637] [D loss: 0.133040] [G loss: 0.534925]\n",
      "[Epoch 6/200] [Batch 574/637] [D loss: 0.129597] [G loss: 0.524014]\n",
      "[Epoch 6/200] [Batch 575/637] [D loss: 0.177997] [G loss: 0.475684]\n",
      "[Epoch 6/200] [Batch 576/637] [D loss: 0.170550] [G loss: 0.647043]\n",
      "[Epoch 6/200] [Batch 577/637] [D loss: 0.139681] [G loss: 0.568648]\n",
      "[Epoch 6/200] [Batch 578/637] [D loss: 0.167689] [G loss: 0.518749]\n",
      "[Epoch 6/200] [Batch 579/637] [D loss: 0.169843] [G loss: 0.515073]\n",
      "[Epoch 6/200] [Batch 580/637] [D loss: 0.157597] [G loss: 0.524671]\n",
      "[Epoch 6/200] [Batch 581/637] [D loss: 0.164279] [G loss: 0.496119]\n",
      "[Epoch 6/200] [Batch 582/637] [D loss: 0.158150] [G loss: 0.532637]\n",
      "[Epoch 6/200] [Batch 583/637] [D loss: 0.161084] [G loss: 0.467259]\n",
      "[Epoch 6/200] [Batch 584/637] [D loss: 0.164780] [G loss: 0.465517]\n",
      "[Epoch 6/200] [Batch 585/637] [D loss: 0.139546] [G loss: 0.583311]\n",
      "[Epoch 6/200] [Batch 586/637] [D loss: 0.165446] [G loss: 0.536450]\n",
      "[Epoch 6/200] [Batch 587/637] [D loss: 0.162027] [G loss: 0.500446]\n",
      "[Epoch 6/200] [Batch 588/637] [D loss: 0.242760] [G loss: 0.526851]\n",
      "[Epoch 6/200] [Batch 589/637] [D loss: 0.185958] [G loss: 0.594715]\n",
      "[Epoch 6/200] [Batch 590/637] [D loss: 0.137078] [G loss: 0.570970]\n",
      "[Epoch 6/200] [Batch 591/637] [D loss: 0.189693] [G loss: 0.523564]\n",
      "[Epoch 6/200] [Batch 592/637] [D loss: 0.161702] [G loss: 0.505719]\n",
      "[Epoch 6/200] [Batch 593/637] [D loss: 0.153834] [G loss: 0.592051]\n",
      "[Epoch 6/200] [Batch 594/637] [D loss: 0.169615] [G loss: 0.508609]\n",
      "[Epoch 6/200] [Batch 595/637] [D loss: 0.183781] [G loss: 0.484955]\n",
      "[Epoch 6/200] [Batch 596/637] [D loss: 0.160979] [G loss: 0.494375]\n",
      "[Epoch 6/200] [Batch 597/637] [D loss: 0.168387] [G loss: 0.527647]\n",
      "[Epoch 6/200] [Batch 598/637] [D loss: 0.159608] [G loss: 0.521372]\n",
      "[Epoch 6/200] [Batch 599/637] [D loss: 0.171716] [G loss: 0.546121]\n",
      "[Epoch 6/200] [Batch 600/637] [D loss: 0.159185] [G loss: 0.487387]\n",
      "[Epoch 6/200] [Batch 601/637] [D loss: 0.183286] [G loss: 0.480046]\n",
      "[Epoch 6/200] [Batch 602/637] [D loss: 0.151143] [G loss: 0.493613]\n",
      "[Epoch 6/200] [Batch 603/637] [D loss: 0.137449] [G loss: 0.585516]\n",
      "[Epoch 6/200] [Batch 604/637] [D loss: 0.132561] [G loss: 0.577246]\n",
      "[Epoch 6/200] [Batch 605/637] [D loss: 0.151222] [G loss: 0.479015]\n",
      "[Epoch 6/200] [Batch 606/637] [D loss: 0.158234] [G loss: 0.482118]\n",
      "[Epoch 6/200] [Batch 607/637] [D loss: 0.160773] [G loss: 0.555034]\n",
      "[Epoch 6/200] [Batch 608/637] [D loss: 0.161104] [G loss: 0.572890]\n",
      "[Epoch 6/200] [Batch 609/637] [D loss: 0.160870] [G loss: 0.518112]\n",
      "[Epoch 6/200] [Batch 610/637] [D loss: 0.146884] [G loss: 0.540402]\n",
      "[Epoch 6/200] [Batch 611/637] [D loss: 0.138148] [G loss: 0.591580]\n",
      "[Epoch 6/200] [Batch 612/637] [D loss: 0.142638] [G loss: 0.575579]\n",
      "[Epoch 6/200] [Batch 613/637] [D loss: 0.153752] [G loss: 0.553097]\n",
      "[Epoch 6/200] [Batch 614/637] [D loss: 0.132774] [G loss: 0.554433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 615/637] [D loss: 0.126391] [G loss: 0.539836]\n",
      "[Epoch 6/200] [Batch 616/637] [D loss: 0.148990] [G loss: 0.480342]\n",
      "[Epoch 6/200] [Batch 617/637] [D loss: 0.148681] [G loss: 0.518208]\n",
      "[Epoch 6/200] [Batch 618/637] [D loss: 0.174901] [G loss: 0.529058]\n",
      "[Epoch 6/200] [Batch 619/637] [D loss: 0.144941] [G loss: 0.601583]\n",
      "[Epoch 6/200] [Batch 620/637] [D loss: 0.147150] [G loss: 0.532960]\n",
      "[Epoch 6/200] [Batch 621/637] [D loss: 0.134797] [G loss: 0.584363]\n",
      "[Epoch 6/200] [Batch 622/637] [D loss: 0.165704] [G loss: 0.580369]\n",
      "[Epoch 6/200] [Batch 623/637] [D loss: 0.139017] [G loss: 0.554080]\n",
      "[Epoch 6/200] [Batch 624/637] [D loss: 0.194191] [G loss: 0.527101]\n",
      "[Epoch 6/200] [Batch 625/637] [D loss: 0.174372] [G loss: 0.600655]\n",
      "[Epoch 6/200] [Batch 626/637] [D loss: 0.153503] [G loss: 0.599677]\n",
      "[Epoch 6/200] [Batch 627/637] [D loss: 0.144659] [G loss: 0.496524]\n",
      "[Epoch 6/200] [Batch 628/637] [D loss: 0.150127] [G loss: 0.452535]\n",
      "[Epoch 6/200] [Batch 629/637] [D loss: 0.173255] [G loss: 0.495783]\n",
      "[Epoch 6/200] [Batch 630/637] [D loss: 0.111657] [G loss: 0.579046]\n",
      "[Epoch 6/200] [Batch 631/637] [D loss: 0.125426] [G loss: 0.581672]\n",
      "[Epoch 6/200] [Batch 632/637] [D loss: 0.133958] [G loss: 0.567323]\n",
      "[Epoch 6/200] [Batch 633/637] [D loss: 0.122490] [G loss: 0.565804]\n",
      "[Epoch 6/200] [Batch 634/637] [D loss: 0.136025] [G loss: 0.501164]\n",
      "[Epoch 6/200] [Batch 635/637] [D loss: 0.123471] [G loss: 0.510123]\n",
      "[Epoch 6/200] [Batch 636/637] [D loss: 0.131227] [G loss: 0.553541]\n",
      "[Epoch 7/200] [Batch 0/637] [D loss: 0.151954] [G loss: 0.533650]\n",
      "[Epoch 7/200] [Batch 1/637] [D loss: 0.163133] [G loss: 0.498130]\n",
      "[Epoch 7/200] [Batch 2/637] [D loss: 0.151592] [G loss: 0.602689]\n",
      "[Epoch 7/200] [Batch 3/637] [D loss: 0.164758] [G loss: 0.515900]\n",
      "[Epoch 7/200] [Batch 4/637] [D loss: 0.156437] [G loss: 0.462655]\n",
      "[Epoch 7/200] [Batch 5/637] [D loss: 0.139666] [G loss: 0.521931]\n",
      "[Epoch 7/200] [Batch 6/637] [D loss: 0.146946] [G loss: 0.483495]\n",
      "[Epoch 7/200] [Batch 7/637] [D loss: 0.134691] [G loss: 0.547324]\n",
      "[Epoch 7/200] [Batch 8/637] [D loss: 0.146658] [G loss: 0.497669]\n",
      "[Epoch 7/200] [Batch 9/637] [D loss: 0.162922] [G loss: 0.561883]\n",
      "[Epoch 7/200] [Batch 10/637] [D loss: 0.140876] [G loss: 0.501375]\n",
      "[Epoch 7/200] [Batch 11/637] [D loss: 0.152921] [G loss: 0.494931]\n",
      "[Epoch 7/200] [Batch 12/637] [D loss: 0.185246] [G loss: 0.668150]\n",
      "[Epoch 7/200] [Batch 13/637] [D loss: 0.161275] [G loss: 0.606258]\n",
      "[Epoch 7/200] [Batch 14/637] [D loss: 0.165593] [G loss: 0.581401]\n",
      "[Epoch 7/200] [Batch 15/637] [D loss: 0.170463] [G loss: 0.489539]\n",
      "[Epoch 7/200] [Batch 16/637] [D loss: 0.163150] [G loss: 0.541627]\n",
      "[Epoch 7/200] [Batch 17/637] [D loss: 0.143425] [G loss: 0.508220]\n",
      "[Epoch 7/200] [Batch 18/637] [D loss: 0.184795] [G loss: 0.454948]\n",
      "[Epoch 7/200] [Batch 19/637] [D loss: 0.160657] [G loss: 0.518190]\n",
      "[Epoch 7/200] [Batch 20/637] [D loss: 0.153969] [G loss: 0.620801]\n",
      "[Epoch 7/200] [Batch 21/637] [D loss: 0.149888] [G loss: 0.543658]\n",
      "[Epoch 7/200] [Batch 22/637] [D loss: 0.181514] [G loss: 0.434930]\n",
      "[Epoch 7/200] [Batch 23/637] [D loss: 0.160363] [G loss: 0.545246]\n",
      "[Epoch 7/200] [Batch 24/637] [D loss: 0.152059] [G loss: 0.507714]\n",
      "[Epoch 7/200] [Batch 25/637] [D loss: 0.147397] [G loss: 0.500962]\n",
      "[Epoch 7/200] [Batch 26/637] [D loss: 0.145371] [G loss: 0.501933]\n",
      "[Epoch 7/200] [Batch 27/637] [D loss: 0.143579] [G loss: 0.552746]\n",
      "[Epoch 7/200] [Batch 28/637] [D loss: 0.143305] [G loss: 0.527013]\n",
      "[Epoch 7/200] [Batch 29/637] [D loss: 0.138601] [G loss: 0.510769]\n",
      "[Epoch 7/200] [Batch 30/637] [D loss: 0.128595] [G loss: 0.508260]\n",
      "[Epoch 7/200] [Batch 31/637] [D loss: 0.152216] [G loss: 0.641802]\n",
      "[Epoch 7/200] [Batch 32/637] [D loss: 0.135387] [G loss: 0.593988]\n",
      "[Epoch 7/200] [Batch 33/637] [D loss: 0.133911] [G loss: 0.556676]\n",
      "[Epoch 7/200] [Batch 34/637] [D loss: 0.131301] [G loss: 0.516793]\n",
      "[Epoch 7/200] [Batch 35/637] [D loss: 0.149793] [G loss: 0.522565]\n",
      "[Epoch 7/200] [Batch 36/637] [D loss: 0.149331] [G loss: 0.633865]\n",
      "[Epoch 7/200] [Batch 37/637] [D loss: 0.124940] [G loss: 0.562939]\n",
      "[Epoch 7/200] [Batch 38/637] [D loss: 0.126043] [G loss: 0.544844]\n",
      "[Epoch 7/200] [Batch 39/637] [D loss: 0.129480] [G loss: 0.566669]\n",
      "[Epoch 7/200] [Batch 40/637] [D loss: 0.140748] [G loss: 0.636143]\n",
      "[Epoch 7/200] [Batch 41/637] [D loss: 0.154094] [G loss: 0.558155]\n",
      "[Epoch 7/200] [Batch 42/637] [D loss: 0.155459] [G loss: 0.536303]\n",
      "[Epoch 7/200] [Batch 43/637] [D loss: 0.200999] [G loss: 0.608911]\n",
      "[Epoch 7/200] [Batch 44/637] [D loss: 0.224818] [G loss: 0.586271]\n",
      "[Epoch 7/200] [Batch 45/637] [D loss: 0.158858] [G loss: 0.671925]\n",
      "[Epoch 7/200] [Batch 46/637] [D loss: 0.168752] [G loss: 0.599152]\n",
      "[Epoch 7/200] [Batch 47/637] [D loss: 0.173519] [G loss: 0.425875]\n",
      "[Epoch 7/200] [Batch 48/637] [D loss: 0.242927] [G loss: 0.378663]\n",
      "[Epoch 7/200] [Batch 49/637] [D loss: 0.226692] [G loss: 0.664771]\n",
      "[Epoch 7/200] [Batch 50/637] [D loss: 0.213618] [G loss: 0.675629]\n",
      "[Epoch 7/200] [Batch 51/637] [D loss: 0.181282] [G loss: 0.581302]\n",
      "[Epoch 7/200] [Batch 52/637] [D loss: 0.168951] [G loss: 0.426639]\n",
      "[Epoch 7/200] [Batch 53/637] [D loss: 0.164888] [G loss: 0.450556]\n",
      "[Epoch 7/200] [Batch 54/637] [D loss: 0.145483] [G loss: 0.475067]\n",
      "[Epoch 7/200] [Batch 55/637] [D loss: 0.137654] [G loss: 0.480819]\n",
      "[Epoch 7/200] [Batch 56/637] [D loss: 0.140122] [G loss: 0.482992]\n",
      "[Epoch 7/200] [Batch 57/637] [D loss: 0.154485] [G loss: 0.428984]\n",
      "[Epoch 7/200] [Batch 58/637] [D loss: 0.120440] [G loss: 0.588507]\n",
      "[Epoch 7/200] [Batch 59/637] [D loss: 0.143016] [G loss: 0.611798]\n",
      "[Epoch 7/200] [Batch 60/637] [D loss: 0.155413] [G loss: 0.513069]\n",
      "[Epoch 7/200] [Batch 61/637] [D loss: 0.147036] [G loss: 0.481775]\n",
      "[Epoch 7/200] [Batch 62/637] [D loss: 0.119003] [G loss: 0.529045]\n",
      "[Epoch 7/200] [Batch 63/637] [D loss: 0.140435] [G loss: 0.527902]\n",
      "[Epoch 7/200] [Batch 64/637] [D loss: 0.144927] [G loss: 0.480552]\n",
      "[Epoch 7/200] [Batch 65/637] [D loss: 0.146333] [G loss: 0.572055]\n",
      "[Epoch 7/200] [Batch 66/637] [D loss: 0.135703] [G loss: 0.583576]\n",
      "[Epoch 7/200] [Batch 67/637] [D loss: 0.160717] [G loss: 0.642987]\n",
      "[Epoch 7/200] [Batch 68/637] [D loss: 0.156311] [G loss: 0.465672]\n",
      "[Epoch 7/200] [Batch 69/637] [D loss: 0.142934] [G loss: 0.515234]\n",
      "[Epoch 7/200] [Batch 70/637] [D loss: 0.148803] [G loss: 0.610876]\n",
      "[Epoch 7/200] [Batch 71/637] [D loss: 0.136811] [G loss: 0.557785]\n",
      "[Epoch 7/200] [Batch 72/637] [D loss: 0.140893] [G loss: 0.544963]\n",
      "[Epoch 7/200] [Batch 73/637] [D loss: 0.150256] [G loss: 0.556926]\n",
      "[Epoch 7/200] [Batch 74/637] [D loss: 0.139414] [G loss: 0.597432]\n",
      "[Epoch 7/200] [Batch 75/637] [D loss: 0.149267] [G loss: 0.537392]\n",
      "[Epoch 7/200] [Batch 76/637] [D loss: 0.139558] [G loss: 0.648871]\n",
      "[Epoch 7/200] [Batch 77/637] [D loss: 0.144276] [G loss: 0.586028]\n",
      "[Epoch 7/200] [Batch 78/637] [D loss: 0.158961] [G loss: 0.517452]\n",
      "[Epoch 7/200] [Batch 79/637] [D loss: 0.181496] [G loss: 0.548617]\n",
      "[Epoch 7/200] [Batch 80/637] [D loss: 0.183294] [G loss: 0.630028]\n",
      "[Epoch 7/200] [Batch 81/637] [D loss: 0.154178] [G loss: 0.621197]\n",
      "[Epoch 7/200] [Batch 82/637] [D loss: 0.142991] [G loss: 0.562318]\n",
      "[Epoch 7/200] [Batch 83/637] [D loss: 0.195961] [G loss: 0.463438]\n",
      "[Epoch 7/200] [Batch 84/637] [D loss: 0.167452] [G loss: 0.631810]\n",
      "[Epoch 7/200] [Batch 85/637] [D loss: 0.160651] [G loss: 0.648873]\n",
      "[Epoch 7/200] [Batch 86/637] [D loss: 0.155315] [G loss: 0.583394]\n",
      "[Epoch 7/200] [Batch 87/637] [D loss: 0.160160] [G loss: 0.479991]\n",
      "[Epoch 7/200] [Batch 88/637] [D loss: 0.159542] [G loss: 0.453529]\n",
      "[Epoch 7/200] [Batch 89/637] [D loss: 0.144886] [G loss: 0.514309]\n",
      "[Epoch 7/200] [Batch 90/637] [D loss: 0.186743] [G loss: 0.459427]\n",
      "[Epoch 7/200] [Batch 91/637] [D loss: 0.161986] [G loss: 0.581562]\n",
      "[Epoch 7/200] [Batch 92/637] [D loss: 0.157397] [G loss: 0.570336]\n",
      "[Epoch 7/200] [Batch 93/637] [D loss: 0.170648] [G loss: 0.477188]\n",
      "[Epoch 7/200] [Batch 94/637] [D loss: 0.170108] [G loss: 0.504826]\n",
      "[Epoch 7/200] [Batch 95/637] [D loss: 0.137400] [G loss: 0.562107]\n",
      "[Epoch 7/200] [Batch 96/637] [D loss: 0.162373] [G loss: 0.514104]\n",
      "[Epoch 7/200] [Batch 97/637] [D loss: 0.128108] [G loss: 0.553931]\n",
      "[Epoch 7/200] [Batch 98/637] [D loss: 0.160260] [G loss: 0.535754]\n",
      "[Epoch 7/200] [Batch 99/637] [D loss: 0.153447] [G loss: 0.515874]\n",
      "[Epoch 7/200] [Batch 100/637] [D loss: 0.135047] [G loss: 0.593585]\n",
      "[Epoch 7/200] [Batch 101/637] [D loss: 0.119817] [G loss: 0.563596]\n",
      "[Epoch 7/200] [Batch 102/637] [D loss: 0.128460] [G loss: 0.558098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 103/637] [D loss: 0.128205] [G loss: 0.564355]\n",
      "[Epoch 7/200] [Batch 104/637] [D loss: 0.126200] [G loss: 0.606212]\n",
      "[Epoch 7/200] [Batch 105/637] [D loss: 0.145101] [G loss: 0.628071]\n",
      "[Epoch 7/200] [Batch 106/637] [D loss: 0.168379] [G loss: 0.527150]\n",
      "[Epoch 7/200] [Batch 107/637] [D loss: 0.174520] [G loss: 0.528767]\n",
      "[Epoch 7/200] [Batch 108/637] [D loss: 0.167876] [G loss: 0.543754]\n",
      "[Epoch 7/200] [Batch 109/637] [D loss: 0.144528] [G loss: 0.590628]\n",
      "[Epoch 7/200] [Batch 110/637] [D loss: 0.169616] [G loss: 0.488213]\n",
      "[Epoch 7/200] [Batch 111/637] [D loss: 0.152452] [G loss: 0.487328]\n",
      "[Epoch 7/200] [Batch 112/637] [D loss: 0.165649] [G loss: 0.571762]\n",
      "[Epoch 7/200] [Batch 113/637] [D loss: 0.151683] [G loss: 0.642013]\n",
      "[Epoch 7/200] [Batch 114/637] [D loss: 0.146493] [G loss: 0.492779]\n",
      "[Epoch 7/200] [Batch 115/637] [D loss: 0.178248] [G loss: 0.541592]\n",
      "[Epoch 7/200] [Batch 116/637] [D loss: 0.176499] [G loss: 0.500332]\n",
      "[Epoch 7/200] [Batch 117/637] [D loss: 0.171767] [G loss: 0.540652]\n",
      "[Epoch 7/200] [Batch 118/637] [D loss: 0.200828] [G loss: 0.449316]\n",
      "[Epoch 7/200] [Batch 119/637] [D loss: 0.225912] [G loss: 0.620067]\n",
      "[Epoch 7/200] [Batch 120/637] [D loss: 0.168696] [G loss: 0.577040]\n",
      "[Epoch 7/200] [Batch 121/637] [D loss: 0.154282] [G loss: 0.556232]\n",
      "[Epoch 7/200] [Batch 122/637] [D loss: 0.165897] [G loss: 0.494129]\n",
      "[Epoch 7/200] [Batch 123/637] [D loss: 0.175557] [G loss: 0.596180]\n",
      "[Epoch 7/200] [Batch 124/637] [D loss: 0.155964] [G loss: 0.586268]\n",
      "[Epoch 7/200] [Batch 125/637] [D loss: 0.122292] [G loss: 0.581554]\n",
      "[Epoch 7/200] [Batch 126/637] [D loss: 0.154520] [G loss: 0.553853]\n",
      "[Epoch 7/200] [Batch 127/637] [D loss: 0.116980] [G loss: 0.553919]\n",
      "[Epoch 7/200] [Batch 128/637] [D loss: 0.149585] [G loss: 0.511985]\n",
      "[Epoch 7/200] [Batch 129/637] [D loss: 0.133152] [G loss: 0.574406]\n",
      "[Epoch 7/200] [Batch 130/637] [D loss: 0.159682] [G loss: 0.462531]\n",
      "[Epoch 7/200] [Batch 131/637] [D loss: 0.135144] [G loss: 0.541208]\n",
      "[Epoch 7/200] [Batch 132/637] [D loss: 0.145316] [G loss: 0.560645]\n",
      "[Epoch 7/200] [Batch 133/637] [D loss: 0.140386] [G loss: 0.560616]\n",
      "[Epoch 7/200] [Batch 134/637] [D loss: 0.136377] [G loss: 0.592697]\n",
      "[Epoch 7/200] [Batch 135/637] [D loss: 0.127737] [G loss: 0.533427]\n",
      "[Epoch 7/200] [Batch 136/637] [D loss: 0.139600] [G loss: 0.496301]\n",
      "[Epoch 7/200] [Batch 137/637] [D loss: 0.151831] [G loss: 0.442478]\n",
      "[Epoch 7/200] [Batch 138/637] [D loss: 0.168771] [G loss: 0.495792]\n",
      "[Epoch 7/200] [Batch 139/637] [D loss: 0.140699] [G loss: 0.505977]\n",
      "[Epoch 7/200] [Batch 140/637] [D loss: 0.151825] [G loss: 0.521482]\n",
      "[Epoch 7/200] [Batch 141/637] [D loss: 0.163060] [G loss: 0.456116]\n",
      "[Epoch 7/200] [Batch 142/637] [D loss: 0.152330] [G loss: 0.613253]\n",
      "[Epoch 7/200] [Batch 143/637] [D loss: 0.118926] [G loss: 0.645259]\n",
      "[Epoch 7/200] [Batch 144/637] [D loss: 0.164837] [G loss: 0.441423]\n",
      "[Epoch 7/200] [Batch 145/637] [D loss: 0.162656] [G loss: 0.458311]\n",
      "[Epoch 7/200] [Batch 146/637] [D loss: 0.167166] [G loss: 0.517946]\n",
      "[Epoch 7/200] [Batch 147/637] [D loss: 0.152600] [G loss: 0.490787]\n",
      "[Epoch 7/200] [Batch 148/637] [D loss: 0.157922] [G loss: 0.467622]\n",
      "[Epoch 7/200] [Batch 149/637] [D loss: 0.168271] [G loss: 0.555509]\n",
      "[Epoch 7/200] [Batch 150/637] [D loss: 0.131895] [G loss: 0.573782]\n",
      "[Epoch 7/200] [Batch 151/637] [D loss: 0.183888] [G loss: 0.543588]\n",
      "[Epoch 7/200] [Batch 152/637] [D loss: 0.149525] [G loss: 0.566345]\n",
      "[Epoch 7/200] [Batch 153/637] [D loss: 0.126101] [G loss: 0.582184]\n",
      "[Epoch 7/200] [Batch 154/637] [D loss: 0.135475] [G loss: 0.571011]\n",
      "[Epoch 7/200] [Batch 155/637] [D loss: 0.149888] [G loss: 0.558901]\n",
      "[Epoch 7/200] [Batch 156/637] [D loss: 0.113799] [G loss: 0.567468]\n",
      "[Epoch 7/200] [Batch 157/637] [D loss: 0.123522] [G loss: 0.608718]\n",
      "[Epoch 7/200] [Batch 158/637] [D loss: 0.137735] [G loss: 0.524691]\n",
      "[Epoch 7/200] [Batch 159/637] [D loss: 0.155499] [G loss: 0.481541]\n",
      "[Epoch 7/200] [Batch 160/637] [D loss: 0.155949] [G loss: 0.503647]\n",
      "[Epoch 7/200] [Batch 161/637] [D loss: 0.162241] [G loss: 0.553597]\n",
      "[Epoch 7/200] [Batch 162/637] [D loss: 0.162927] [G loss: 0.504922]\n",
      "[Epoch 7/200] [Batch 163/637] [D loss: 0.149246] [G loss: 0.497295]\n",
      "[Epoch 7/200] [Batch 164/637] [D loss: 0.155421] [G loss: 0.539229]\n",
      "[Epoch 7/200] [Batch 165/637] [D loss: 0.154283] [G loss: 0.547989]\n",
      "[Epoch 7/200] [Batch 166/637] [D loss: 0.158962] [G loss: 0.532297]\n",
      "[Epoch 7/200] [Batch 167/637] [D loss: 0.161482] [G loss: 0.543035]\n",
      "[Epoch 7/200] [Batch 168/637] [D loss: 0.157458] [G loss: 0.572185]\n",
      "[Epoch 7/200] [Batch 169/637] [D loss: 0.168260] [G loss: 0.462492]\n",
      "[Epoch 7/200] [Batch 170/637] [D loss: 0.234286] [G loss: 0.562272]\n",
      "[Epoch 7/200] [Batch 171/637] [D loss: 0.147520] [G loss: 0.692221]\n",
      "[Epoch 7/200] [Batch 172/637] [D loss: 0.150186] [G loss: 0.603049]\n",
      "[Epoch 7/200] [Batch 173/637] [D loss: 0.144094] [G loss: 0.475070]\n",
      "[Epoch 7/200] [Batch 174/637] [D loss: 0.152617] [G loss: 0.468647]\n",
      "[Epoch 7/200] [Batch 175/637] [D loss: 0.164346] [G loss: 0.568046]\n",
      "[Epoch 7/200] [Batch 176/637] [D loss: 0.148088] [G loss: 0.526837]\n",
      "[Epoch 7/200] [Batch 177/637] [D loss: 0.151225] [G loss: 0.548765]\n",
      "[Epoch 7/200] [Batch 178/637] [D loss: 0.178136] [G loss: 0.507835]\n",
      "[Epoch 7/200] [Batch 179/637] [D loss: 0.157694] [G loss: 0.536583]\n",
      "[Epoch 7/200] [Batch 180/637] [D loss: 0.157429] [G loss: 0.520130]\n",
      "[Epoch 7/200] [Batch 181/637] [D loss: 0.168081] [G loss: 0.555857]\n",
      "[Epoch 7/200] [Batch 182/637] [D loss: 0.182118] [G loss: 0.482589]\n",
      "[Epoch 7/200] [Batch 183/637] [D loss: 0.162989] [G loss: 0.521078]\n",
      "[Epoch 7/200] [Batch 184/637] [D loss: 0.178131] [G loss: 0.553252]\n",
      "[Epoch 7/200] [Batch 185/637] [D loss: 0.174581] [G loss: 0.493222]\n",
      "[Epoch 7/200] [Batch 186/637] [D loss: 0.154513] [G loss: 0.497720]\n",
      "[Epoch 7/200] [Batch 187/637] [D loss: 0.159359] [G loss: 0.514463]\n",
      "[Epoch 7/200] [Batch 188/637] [D loss: 0.165792] [G loss: 0.468791]\n",
      "[Epoch 7/200] [Batch 189/637] [D loss: 0.147241] [G loss: 0.582317]\n",
      "[Epoch 7/200] [Batch 190/637] [D loss: 0.150124] [G loss: 0.492844]\n",
      "[Epoch 7/200] [Batch 191/637] [D loss: 0.151904] [G loss: 0.532851]\n",
      "[Epoch 7/200] [Batch 192/637] [D loss: 0.155123] [G loss: 0.578301]\n",
      "[Epoch 7/200] [Batch 193/637] [D loss: 0.141205] [G loss: 0.583278]\n",
      "[Epoch 7/200] [Batch 194/637] [D loss: 0.154672] [G loss: 0.553434]\n",
      "[Epoch 7/200] [Batch 195/637] [D loss: 0.126636] [G loss: 0.571296]\n",
      "[Epoch 7/200] [Batch 196/637] [D loss: 0.152463] [G loss: 0.511018]\n",
      "[Epoch 7/200] [Batch 197/637] [D loss: 0.147008] [G loss: 0.625498]\n",
      "[Epoch 7/200] [Batch 198/637] [D loss: 0.133731] [G loss: 0.698159]\n",
      "[Epoch 7/200] [Batch 199/637] [D loss: 0.144324] [G loss: 0.543955]\n",
      "[Epoch 7/200] [Batch 200/637] [D loss: 0.127662] [G loss: 0.525245]\n",
      "[Epoch 7/200] [Batch 201/637] [D loss: 0.136619] [G loss: 0.553496]\n",
      "[Epoch 7/200] [Batch 202/637] [D loss: 0.140768] [G loss: 0.571145]\n",
      "[Epoch 7/200] [Batch 203/637] [D loss: 0.114268] [G loss: 0.602199]\n",
      "[Epoch 7/200] [Batch 204/637] [D loss: 0.144682] [G loss: 0.672413]\n",
      "[Epoch 7/200] [Batch 205/637] [D loss: 0.166101] [G loss: 0.506269]\n",
      "[Epoch 7/200] [Batch 206/637] [D loss: 0.169930] [G loss: 0.661602]\n",
      "[Epoch 7/200] [Batch 207/637] [D loss: 0.170300] [G loss: 0.570827]\n",
      "[Epoch 7/200] [Batch 208/637] [D loss: 0.246451] [G loss: 0.479598]\n",
      "[Epoch 7/200] [Batch 209/637] [D loss: 0.342097] [G loss: 0.570286]\n",
      "[Epoch 7/200] [Batch 210/637] [D loss: 0.206208] [G loss: 0.750045]\n",
      "[Epoch 7/200] [Batch 211/637] [D loss: 0.186229] [G loss: 0.722218]\n",
      "[Epoch 7/200] [Batch 212/637] [D loss: 0.174861] [G loss: 0.539636]\n",
      "[Epoch 7/200] [Batch 213/637] [D loss: 0.196530] [G loss: 0.346690]\n",
      "[Epoch 7/200] [Batch 214/637] [D loss: 0.170533] [G loss: 0.404199]\n",
      "[Epoch 7/200] [Batch 215/637] [D loss: 0.171610] [G loss: 0.402723]\n",
      "[Epoch 7/200] [Batch 216/637] [D loss: 0.144024] [G loss: 0.472335]\n",
      "[Epoch 7/200] [Batch 217/637] [D loss: 0.145805] [G loss: 0.484716]\n",
      "[Epoch 7/200] [Batch 218/637] [D loss: 0.162035] [G loss: 0.443704]\n",
      "[Epoch 7/200] [Batch 219/637] [D loss: 0.150291] [G loss: 0.499159]\n",
      "[Epoch 7/200] [Batch 220/637] [D loss: 0.140427] [G loss: 0.539465]\n",
      "[Epoch 7/200] [Batch 221/637] [D loss: 0.142136] [G loss: 0.533084]\n",
      "[Epoch 7/200] [Batch 222/637] [D loss: 0.122390] [G loss: 0.514994]\n",
      "[Epoch 7/200] [Batch 223/637] [D loss: 0.160184] [G loss: 0.482169]\n",
      "[Epoch 7/200] [Batch 224/637] [D loss: 0.179927] [G loss: 0.503723]\n",
      "[Epoch 7/200] [Batch 225/637] [D loss: 0.125621] [G loss: 0.541264]\n",
      "[Epoch 7/200] [Batch 226/637] [D loss: 0.132763] [G loss: 0.575435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 227/637] [D loss: 0.117399] [G loss: 0.513172]\n",
      "[Epoch 7/200] [Batch 228/637] [D loss: 0.134531] [G loss: 0.522555]\n",
      "[Epoch 7/200] [Batch 229/637] [D loss: 0.125750] [G loss: 0.563001]\n",
      "[Epoch 7/200] [Batch 230/637] [D loss: 0.139855] [G loss: 0.513833]\n",
      "[Epoch 7/200] [Batch 231/637] [D loss: 0.140959] [G loss: 0.551833]\n",
      "[Epoch 7/200] [Batch 232/637] [D loss: 0.170473] [G loss: 0.578344]\n",
      "[Epoch 7/200] [Batch 233/637] [D loss: 0.163982] [G loss: 0.612830]\n",
      "[Epoch 7/200] [Batch 234/637] [D loss: 0.139476] [G loss: 0.527795]\n",
      "[Epoch 7/200] [Batch 235/637] [D loss: 0.133907] [G loss: 0.523345]\n",
      "[Epoch 7/200] [Batch 236/637] [D loss: 0.136935] [G loss: 0.540036]\n",
      "[Epoch 7/200] [Batch 237/637] [D loss: 0.146390] [G loss: 0.516556]\n",
      "[Epoch 7/200] [Batch 238/637] [D loss: 0.132985] [G loss: 0.544805]\n",
      "[Epoch 7/200] [Batch 239/637] [D loss: 0.133426] [G loss: 0.538080]\n",
      "[Epoch 7/200] [Batch 240/637] [D loss: 0.149841] [G loss: 0.518472]\n",
      "[Epoch 7/200] [Batch 241/637] [D loss: 0.158703] [G loss: 0.550703]\n",
      "[Epoch 7/200] [Batch 242/637] [D loss: 0.153387] [G loss: 0.553791]\n",
      "[Epoch 7/200] [Batch 243/637] [D loss: 0.133101] [G loss: 0.562833]\n",
      "[Epoch 7/200] [Batch 244/637] [D loss: 0.164602] [G loss: 0.563163]\n",
      "[Epoch 7/200] [Batch 245/637] [D loss: 0.166338] [G loss: 0.466022]\n",
      "[Epoch 7/200] [Batch 246/637] [D loss: 0.180519] [G loss: 0.472296]\n",
      "[Epoch 7/200] [Batch 247/637] [D loss: 0.155135] [G loss: 0.525723]\n",
      "[Epoch 7/200] [Batch 248/637] [D loss: 0.147461] [G loss: 0.603621]\n",
      "[Epoch 7/200] [Batch 249/637] [D loss: 0.133690] [G loss: 0.527680]\n",
      "[Epoch 7/200] [Batch 250/637] [D loss: 0.152021] [G loss: 0.474374]\n",
      "[Epoch 7/200] [Batch 251/637] [D loss: 0.165918] [G loss: 0.505895]\n",
      "[Epoch 7/200] [Batch 252/637] [D loss: 0.151430] [G loss: 0.722593]\n",
      "[Epoch 7/200] [Batch 253/637] [D loss: 0.113252] [G loss: 0.652540]\n",
      "[Epoch 7/200] [Batch 254/637] [D loss: 0.148169] [G loss: 0.476863]\n",
      "[Epoch 7/200] [Batch 255/637] [D loss: 0.155112] [G loss: 0.512136]\n",
      "[Epoch 7/200] [Batch 256/637] [D loss: 0.156963] [G loss: 0.576111]\n",
      "[Epoch 7/200] [Batch 257/637] [D loss: 0.147590] [G loss: 0.524199]\n",
      "[Epoch 7/200] [Batch 258/637] [D loss: 0.134247] [G loss: 0.591338]\n",
      "[Epoch 7/200] [Batch 259/637] [D loss: 0.134887] [G loss: 0.481132]\n",
      "[Epoch 7/200] [Batch 260/637] [D loss: 0.135341] [G loss: 0.499940]\n",
      "[Epoch 7/200] [Batch 261/637] [D loss: 0.152036] [G loss: 0.554594]\n",
      "[Epoch 7/200] [Batch 262/637] [D loss: 0.119467] [G loss: 0.574143]\n",
      "[Epoch 7/200] [Batch 263/637] [D loss: 0.138885] [G loss: 0.512115]\n",
      "[Epoch 7/200] [Batch 264/637] [D loss: 0.139958] [G loss: 0.541323]\n",
      "[Epoch 7/200] [Batch 265/637] [D loss: 0.153623] [G loss: 0.509855]\n",
      "[Epoch 7/200] [Batch 266/637] [D loss: 0.141659] [G loss: 0.575549]\n",
      "[Epoch 7/200] [Batch 267/637] [D loss: 0.185116] [G loss: 0.530585]\n",
      "[Epoch 7/200] [Batch 268/637] [D loss: 0.135509] [G loss: 0.598263]\n",
      "[Epoch 7/200] [Batch 269/637] [D loss: 0.181425] [G loss: 0.554116]\n",
      "[Epoch 7/200] [Batch 270/637] [D loss: 0.149604] [G loss: 0.588530]\n",
      "[Epoch 7/200] [Batch 271/637] [D loss: 0.168325] [G loss: 0.505064]\n",
      "[Epoch 7/200] [Batch 272/637] [D loss: 0.177884] [G loss: 0.666944]\n",
      "[Epoch 7/200] [Batch 273/637] [D loss: 0.151790] [G loss: 0.545757]\n",
      "[Epoch 7/200] [Batch 274/637] [D loss: 0.170182] [G loss: 0.507227]\n",
      "[Epoch 7/200] [Batch 275/637] [D loss: 0.153198] [G loss: 0.533463]\n",
      "[Epoch 7/200] [Batch 276/637] [D loss: 0.149609] [G loss: 0.554922]\n",
      "[Epoch 7/200] [Batch 277/637] [D loss: 0.135655] [G loss: 0.503283]\n",
      "[Epoch 7/200] [Batch 278/637] [D loss: 0.133028] [G loss: 0.481308]\n",
      "[Epoch 7/200] [Batch 279/637] [D loss: 0.146467] [G loss: 0.542353]\n",
      "[Epoch 7/200] [Batch 280/637] [D loss: 0.146387] [G loss: 0.602733]\n",
      "[Epoch 7/200] [Batch 281/637] [D loss: 0.139543] [G loss: 0.597374]\n",
      "[Epoch 7/200] [Batch 282/637] [D loss: 0.305234] [G loss: 0.434956]\n",
      "[Epoch 7/200] [Batch 283/637] [D loss: 0.300732] [G loss: 0.580229]\n",
      "[Epoch 7/200] [Batch 284/637] [D loss: 0.214375] [G loss: 0.754016]\n",
      "[Epoch 7/200] [Batch 285/637] [D loss: 0.171134] [G loss: 0.678519]\n",
      "[Epoch 7/200] [Batch 286/637] [D loss: 0.177814] [G loss: 0.490561]\n",
      "[Epoch 7/200] [Batch 287/637] [D loss: 0.183843] [G loss: 0.379666]\n",
      "[Epoch 7/200] [Batch 288/637] [D loss: 0.160135] [G loss: 0.498508]\n",
      "[Epoch 7/200] [Batch 289/637] [D loss: 0.165345] [G loss: 0.471278]\n",
      "[Epoch 7/200] [Batch 290/637] [D loss: 0.140022] [G loss: 0.486987]\n",
      "[Epoch 7/200] [Batch 291/637] [D loss: 0.137166] [G loss: 0.530975]\n",
      "[Epoch 7/200] [Batch 292/637] [D loss: 0.137581] [G loss: 0.565187]\n",
      "[Epoch 7/200] [Batch 293/637] [D loss: 0.137039] [G loss: 0.539293]\n",
      "[Epoch 7/200] [Batch 294/637] [D loss: 0.133828] [G loss: 0.576270]\n",
      "[Epoch 7/200] [Batch 295/637] [D loss: 0.149854] [G loss: 0.572158]\n",
      "[Epoch 7/200] [Batch 296/637] [D loss: 0.155806] [G loss: 0.509619]\n",
      "[Epoch 7/200] [Batch 297/637] [D loss: 0.164352] [G loss: 0.535068]\n",
      "[Epoch 7/200] [Batch 298/637] [D loss: 0.155810] [G loss: 0.632930]\n",
      "[Epoch 7/200] [Batch 299/637] [D loss: 0.137740] [G loss: 0.572565]\n",
      "[Epoch 7/200] [Batch 300/637] [D loss: 0.150278] [G loss: 0.564903]\n",
      "[Epoch 7/200] [Batch 301/637] [D loss: 0.137836] [G loss: 0.465226]\n",
      "[Epoch 7/200] [Batch 302/637] [D loss: 0.143107] [G loss: 0.475698]\n",
      "[Epoch 7/200] [Batch 303/637] [D loss: 0.162547] [G loss: 0.572022]\n",
      "[Epoch 7/200] [Batch 304/637] [D loss: 0.156515] [G loss: 0.558439]\n",
      "[Epoch 7/200] [Batch 305/637] [D loss: 0.135610] [G loss: 0.567649]\n",
      "[Epoch 7/200] [Batch 306/637] [D loss: 0.146288] [G loss: 0.502602]\n",
      "[Epoch 7/200] [Batch 307/637] [D loss: 0.167700] [G loss: 0.434350]\n",
      "[Epoch 7/200] [Batch 308/637] [D loss: 0.174517] [G loss: 0.570133]\n",
      "[Epoch 7/200] [Batch 309/637] [D loss: 0.178001] [G loss: 0.560299]\n",
      "[Epoch 7/200] [Batch 310/637] [D loss: 0.131587] [G loss: 0.587283]\n",
      "[Epoch 7/200] [Batch 311/637] [D loss: 0.140168] [G loss: 0.537156]\n",
      "[Epoch 7/200] [Batch 312/637] [D loss: 0.143135] [G loss: 0.568325]\n",
      "[Epoch 7/200] [Batch 313/637] [D loss: 0.159182] [G loss: 0.496480]\n",
      "[Epoch 7/200] [Batch 314/637] [D loss: 0.129461] [G loss: 0.533004]\n",
      "[Epoch 7/200] [Batch 315/637] [D loss: 0.209196] [G loss: 0.512068]\n",
      "[Epoch 7/200] [Batch 316/637] [D loss: 0.185331] [G loss: 0.667017]\n",
      "[Epoch 7/200] [Batch 317/637] [D loss: 0.183450] [G loss: 0.594604]\n",
      "[Epoch 7/200] [Batch 318/637] [D loss: 0.162265] [G loss: 0.607896]\n",
      "[Epoch 7/200] [Batch 319/637] [D loss: 0.148443] [G loss: 0.477564]\n",
      "[Epoch 7/200] [Batch 320/637] [D loss: 0.196770] [G loss: 0.344121]\n",
      "[Epoch 7/200] [Batch 321/637] [D loss: 0.190348] [G loss: 0.507520]\n",
      "[Epoch 7/200] [Batch 322/637] [D loss: 0.171644] [G loss: 0.607581]\n",
      "[Epoch 7/200] [Batch 323/637] [D loss: 0.136970] [G loss: 0.614373]\n",
      "[Epoch 7/200] [Batch 324/637] [D loss: 0.148921] [G loss: 0.563218]\n",
      "[Epoch 7/200] [Batch 325/637] [D loss: 0.138684] [G loss: 0.454864]\n",
      "[Epoch 7/200] [Batch 326/637] [D loss: 0.154359] [G loss: 0.501163]\n",
      "[Epoch 7/200] [Batch 327/637] [D loss: 0.119048] [G loss: 0.552644]\n",
      "[Epoch 7/200] [Batch 328/637] [D loss: 0.121210] [G loss: 0.595048]\n",
      "[Epoch 7/200] [Batch 329/637] [D loss: 0.117265] [G loss: 0.549243]\n",
      "[Epoch 7/200] [Batch 330/637] [D loss: 0.168056] [G loss: 0.546280]\n",
      "[Epoch 7/200] [Batch 331/637] [D loss: 0.214934] [G loss: 0.549751]\n",
      "[Epoch 7/200] [Batch 332/637] [D loss: 0.144610] [G loss: 0.623429]\n",
      "[Epoch 7/200] [Batch 333/637] [D loss: 0.132345] [G loss: 0.544584]\n",
      "[Epoch 7/200] [Batch 334/637] [D loss: 0.141169] [G loss: 0.521457]\n",
      "[Epoch 7/200] [Batch 335/637] [D loss: 0.154367] [G loss: 0.466372]\n",
      "[Epoch 7/200] [Batch 336/637] [D loss: 0.146996] [G loss: 0.520622]\n",
      "[Epoch 7/200] [Batch 337/637] [D loss: 0.138737] [G loss: 0.541565]\n",
      "[Epoch 7/200] [Batch 338/637] [D loss: 0.139350] [G loss: 0.574295]\n",
      "[Epoch 7/200] [Batch 339/637] [D loss: 0.157473] [G loss: 0.489112]\n",
      "[Epoch 7/200] [Batch 340/637] [D loss: 0.155873] [G loss: 0.504405]\n",
      "[Epoch 7/200] [Batch 341/637] [D loss: 0.144134] [G loss: 0.469243]\n",
      "[Epoch 7/200] [Batch 342/637] [D loss: 0.143781] [G loss: 0.567433]\n",
      "[Epoch 7/200] [Batch 343/637] [D loss: 0.150816] [G loss: 0.559432]\n",
      "[Epoch 7/200] [Batch 344/637] [D loss: 0.157575] [G loss: 0.529649]\n",
      "[Epoch 7/200] [Batch 345/637] [D loss: 0.160780] [G loss: 0.465195]\n",
      "[Epoch 7/200] [Batch 346/637] [D loss: 0.158025] [G loss: 0.564335]\n",
      "[Epoch 7/200] [Batch 347/637] [D loss: 0.165055] [G loss: 0.575029]\n",
      "[Epoch 7/200] [Batch 348/637] [D loss: 0.154886] [G loss: 0.529128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 349/637] [D loss: 0.152531] [G loss: 0.557857]\n",
      "[Epoch 7/200] [Batch 350/637] [D loss: 0.152084] [G loss: 0.562681]\n",
      "[Epoch 7/200] [Batch 351/637] [D loss: 0.122858] [G loss: 0.527832]\n",
      "[Epoch 7/200] [Batch 352/637] [D loss: 0.140252] [G loss: 0.522959]\n",
      "[Epoch 7/200] [Batch 353/637] [D loss: 0.132886] [G loss: 0.505969]\n",
      "[Epoch 7/200] [Batch 354/637] [D loss: 0.152244] [G loss: 0.484817]\n",
      "[Epoch 7/200] [Batch 355/637] [D loss: 0.122370] [G loss: 0.621776]\n",
      "[Epoch 7/200] [Batch 356/637] [D loss: 0.165756] [G loss: 0.538599]\n",
      "[Epoch 7/200] [Batch 357/637] [D loss: 0.133167] [G loss: 0.578450]\n",
      "[Epoch 7/200] [Batch 358/637] [D loss: 0.140947] [G loss: 0.570004]\n",
      "[Epoch 7/200] [Batch 359/637] [D loss: 0.124222] [G loss: 0.523397]\n",
      "[Epoch 7/200] [Batch 360/637] [D loss: 0.145335] [G loss: 0.508504]\n",
      "[Epoch 7/200] [Batch 361/637] [D loss: 0.149339] [G loss: 0.506638]\n",
      "[Epoch 7/200] [Batch 362/637] [D loss: 0.183863] [G loss: 0.447844]\n",
      "[Epoch 7/200] [Batch 363/637] [D loss: 0.166304] [G loss: 0.610587]\n",
      "[Epoch 7/200] [Batch 364/637] [D loss: 0.151308] [G loss: 0.510080]\n",
      "[Epoch 7/200] [Batch 365/637] [D loss: 0.149684] [G loss: 0.518284]\n",
      "[Epoch 7/200] [Batch 366/637] [D loss: 0.140006] [G loss: 0.515737]\n",
      "[Epoch 7/200] [Batch 367/637] [D loss: 0.119813] [G loss: 0.577173]\n",
      "[Epoch 7/200] [Batch 368/637] [D loss: 0.140970] [G loss: 0.605931]\n",
      "[Epoch 7/200] [Batch 369/637] [D loss: 0.170236] [G loss: 0.500195]\n",
      "[Epoch 7/200] [Batch 370/637] [D loss: 0.159665] [G loss: 0.551221]\n",
      "[Epoch 7/200] [Batch 371/637] [D loss: 0.148068] [G loss: 0.672269]\n",
      "[Epoch 7/200] [Batch 372/637] [D loss: 0.144422] [G loss: 0.607995]\n",
      "[Epoch 7/200] [Batch 373/637] [D loss: 0.140133] [G loss: 0.530600]\n",
      "[Epoch 7/200] [Batch 374/637] [D loss: 0.166255] [G loss: 0.519303]\n",
      "[Epoch 7/200] [Batch 375/637] [D loss: 0.143723] [G loss: 0.539945]\n",
      "[Epoch 7/200] [Batch 376/637] [D loss: 0.125356] [G loss: 0.537015]\n",
      "[Epoch 7/200] [Batch 377/637] [D loss: 0.126193] [G loss: 0.612591]\n",
      "[Epoch 7/200] [Batch 378/637] [D loss: 0.127264] [G loss: 0.608149]\n",
      "[Epoch 7/200] [Batch 379/637] [D loss: 0.122978] [G loss: 0.581668]\n",
      "[Epoch 7/200] [Batch 380/637] [D loss: 0.137483] [G loss: 0.522506]\n",
      "[Epoch 7/200] [Batch 381/637] [D loss: 0.133956] [G loss: 0.582447]\n",
      "[Epoch 7/200] [Batch 382/637] [D loss: 0.151567] [G loss: 0.542143]\n",
      "[Epoch 7/200] [Batch 383/637] [D loss: 0.120220] [G loss: 0.670803]\n",
      "[Epoch 7/200] [Batch 384/637] [D loss: 0.156881] [G loss: 0.559576]\n",
      "[Epoch 7/200] [Batch 385/637] [D loss: 0.133728] [G loss: 0.552183]\n",
      "[Epoch 7/200] [Batch 386/637] [D loss: 0.122172] [G loss: 0.535253]\n",
      "[Epoch 7/200] [Batch 387/637] [D loss: 0.120342] [G loss: 0.599116]\n",
      "[Epoch 7/200] [Batch 388/637] [D loss: 0.144920] [G loss: 0.595187]\n",
      "[Epoch 7/200] [Batch 389/637] [D loss: 0.167469] [G loss: 0.567496]\n",
      "[Epoch 7/200] [Batch 390/637] [D loss: 0.156939] [G loss: 0.633849]\n",
      "[Epoch 7/200] [Batch 391/637] [D loss: 0.152846] [G loss: 0.514727]\n",
      "[Epoch 7/200] [Batch 392/637] [D loss: 0.132360] [G loss: 0.643824]\n",
      "[Epoch 7/200] [Batch 393/637] [D loss: 0.125824] [G loss: 0.653567]\n",
      "[Epoch 7/200] [Batch 394/637] [D loss: 0.211779] [G loss: 0.545427]\n",
      "[Epoch 7/200] [Batch 395/637] [D loss: 0.186575] [G loss: 0.554804]\n",
      "[Epoch 7/200] [Batch 396/637] [D loss: 0.169396] [G loss: 0.741411]\n",
      "[Epoch 7/200] [Batch 397/637] [D loss: 0.175028] [G loss: 0.643936]\n",
      "[Epoch 7/200] [Batch 398/637] [D loss: 0.145124] [G loss: 0.470058]\n",
      "[Epoch 7/200] [Batch 399/637] [D loss: 0.178762] [G loss: 0.432097]\n",
      "[Epoch 7/200] [Batch 400/637] [D loss: 0.158565] [G loss: 0.488956]\n",
      "[Epoch 7/200] [Batch 401/637] [D loss: 0.137635] [G loss: 0.656065]\n",
      "[Epoch 7/200] [Batch 402/637] [D loss: 0.149950] [G loss: 0.589276]\n",
      "[Epoch 7/200] [Batch 403/637] [D loss: 0.132612] [G loss: 0.545778]\n",
      "[Epoch 7/200] [Batch 404/637] [D loss: 0.144990] [G loss: 0.542772]\n",
      "[Epoch 7/200] [Batch 405/637] [D loss: 0.162023] [G loss: 0.505698]\n",
      "[Epoch 7/200] [Batch 406/637] [D loss: 0.156036] [G loss: 0.508376]\n",
      "[Epoch 7/200] [Batch 407/637] [D loss: 0.173342] [G loss: 0.547973]\n",
      "[Epoch 7/200] [Batch 408/637] [D loss: 0.162728] [G loss: 0.505693]\n",
      "[Epoch 7/200] [Batch 409/637] [D loss: 0.151739] [G loss: 0.533882]\n",
      "[Epoch 7/200] [Batch 410/637] [D loss: 0.172377] [G loss: 0.481984]\n",
      "[Epoch 7/200] [Batch 411/637] [D loss: 0.183800] [G loss: 0.480366]\n",
      "[Epoch 7/200] [Batch 412/637] [D loss: 0.168072] [G loss: 0.521484]\n",
      "[Epoch 7/200] [Batch 413/637] [D loss: 0.163893] [G loss: 0.546778]\n",
      "[Epoch 7/200] [Batch 414/637] [D loss: 0.165509] [G loss: 0.546002]\n",
      "[Epoch 7/200] [Batch 415/637] [D loss: 0.149360] [G loss: 0.466855]\n",
      "[Epoch 7/200] [Batch 416/637] [D loss: 0.139936] [G loss: 0.526320]\n",
      "[Epoch 7/200] [Batch 417/637] [D loss: 0.121530] [G loss: 0.569569]\n",
      "[Epoch 7/200] [Batch 418/637] [D loss: 0.132320] [G loss: 0.569692]\n",
      "[Epoch 7/200] [Batch 419/637] [D loss: 0.152569] [G loss: 0.538311]\n",
      "[Epoch 7/200] [Batch 420/637] [D loss: 0.150208] [G loss: 0.539195]\n",
      "[Epoch 7/200] [Batch 421/637] [D loss: 0.159385] [G loss: 0.583588]\n",
      "[Epoch 7/200] [Batch 422/637] [D loss: 0.188171] [G loss: 0.454501]\n",
      "[Epoch 7/200] [Batch 423/637] [D loss: 0.217733] [G loss: 0.656212]\n",
      "[Epoch 7/200] [Batch 424/637] [D loss: 0.184205] [G loss: 0.592593]\n",
      "[Epoch 7/200] [Batch 425/637] [D loss: 0.167952] [G loss: 0.592214]\n",
      "[Epoch 7/200] [Batch 426/637] [D loss: 0.152984] [G loss: 0.546562]\n",
      "[Epoch 7/200] [Batch 427/637] [D loss: 0.150557] [G loss: 0.516761]\n",
      "[Epoch 7/200] [Batch 428/637] [D loss: 0.143835] [G loss: 0.482629]\n",
      "[Epoch 7/200] [Batch 429/637] [D loss: 0.150515] [G loss: 0.450956]\n",
      "[Epoch 7/200] [Batch 430/637] [D loss: 0.147145] [G loss: 0.642762]\n",
      "[Epoch 7/200] [Batch 431/637] [D loss: 0.128907] [G loss: 0.576414]\n",
      "[Epoch 7/200] [Batch 432/637] [D loss: 0.164013] [G loss: 0.487484]\n",
      "[Epoch 7/200] [Batch 433/637] [D loss: 0.163079] [G loss: 0.533844]\n",
      "[Epoch 7/200] [Batch 434/637] [D loss: 0.133281] [G loss: 0.655638]\n",
      "[Epoch 7/200] [Batch 435/637] [D loss: 0.145701] [G loss: 0.547894]\n",
      "[Epoch 7/200] [Batch 436/637] [D loss: 0.135780] [G loss: 0.490451]\n",
      "[Epoch 7/200] [Batch 437/637] [D loss: 0.162700] [G loss: 0.499937]\n",
      "[Epoch 7/200] [Batch 438/637] [D loss: 0.209236] [G loss: 0.489174]\n",
      "[Epoch 7/200] [Batch 439/637] [D loss: 0.206762] [G loss: 0.691632]\n",
      "[Epoch 7/200] [Batch 440/637] [D loss: 0.186434] [G loss: 0.600953]\n",
      "[Epoch 7/200] [Batch 441/637] [D loss: 0.160863] [G loss: 0.580103]\n",
      "[Epoch 7/200] [Batch 442/637] [D loss: 0.157848] [G loss: 0.510979]\n",
      "[Epoch 7/200] [Batch 443/637] [D loss: 0.162335] [G loss: 0.450931]\n",
      "[Epoch 7/200] [Batch 444/637] [D loss: 0.179519] [G loss: 0.503399]\n",
      "[Epoch 7/200] [Batch 445/637] [D loss: 0.163655] [G loss: 0.620806]\n",
      "[Epoch 7/200] [Batch 446/637] [D loss: 0.143200] [G loss: 0.576142]\n",
      "[Epoch 7/200] [Batch 447/637] [D loss: 0.142826] [G loss: 0.525072]\n",
      "[Epoch 7/200] [Batch 448/637] [D loss: 0.155179] [G loss: 0.512235]\n",
      "[Epoch 7/200] [Batch 449/637] [D loss: 0.136480] [G loss: 0.469958]\n",
      "[Epoch 7/200] [Batch 450/637] [D loss: 0.125299] [G loss: 0.651991]\n",
      "[Epoch 7/200] [Batch 451/637] [D loss: 0.130771] [G loss: 0.579510]\n",
      "[Epoch 7/200] [Batch 452/637] [D loss: 0.146286] [G loss: 0.521125]\n",
      "[Epoch 7/200] [Batch 453/637] [D loss: 0.144350] [G loss: 0.538912]\n",
      "[Epoch 7/200] [Batch 454/637] [D loss: 0.130498] [G loss: 0.542786]\n",
      "[Epoch 7/200] [Batch 455/637] [D loss: 0.141004] [G loss: 0.577889]\n",
      "[Epoch 7/200] [Batch 456/637] [D loss: 0.158848] [G loss: 0.489206]\n",
      "[Epoch 7/200] [Batch 457/637] [D loss: 0.155271] [G loss: 0.563983]\n",
      "[Epoch 7/200] [Batch 458/637] [D loss: 0.158965] [G loss: 0.485097]\n",
      "[Epoch 7/200] [Batch 459/637] [D loss: 0.124313] [G loss: 0.603177]\n",
      "[Epoch 7/200] [Batch 460/637] [D loss: 0.161771] [G loss: 0.491241]\n",
      "[Epoch 7/200] [Batch 461/637] [D loss: 0.145209] [G loss: 0.501451]\n",
      "[Epoch 7/200] [Batch 462/637] [D loss: 0.150368] [G loss: 0.504009]\n",
      "[Epoch 7/200] [Batch 463/637] [D loss: 0.145764] [G loss: 0.607856]\n",
      "[Epoch 7/200] [Batch 464/637] [D loss: 0.141935] [G loss: 0.587950]\n",
      "[Epoch 7/200] [Batch 465/637] [D loss: 0.135973] [G loss: 0.572135]\n",
      "[Epoch 7/200] [Batch 466/637] [D loss: 0.164625] [G loss: 0.546867]\n",
      "[Epoch 7/200] [Batch 467/637] [D loss: 0.146824] [G loss: 0.508587]\n",
      "[Epoch 7/200] [Batch 468/637] [D loss: 0.115369] [G loss: 0.596159]\n",
      "[Epoch 7/200] [Batch 469/637] [D loss: 0.121192] [G loss: 0.569647]\n",
      "[Epoch 7/200] [Batch 470/637] [D loss: 0.116057] [G loss: 0.532404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 471/637] [D loss: 0.165709] [G loss: 0.541743]\n",
      "[Epoch 7/200] [Batch 472/637] [D loss: 0.136059] [G loss: 0.535819]\n",
      "[Epoch 7/200] [Batch 473/637] [D loss: 0.160375] [G loss: 0.591957]\n",
      "[Epoch 7/200] [Batch 474/637] [D loss: 0.159123] [G loss: 0.609818]\n",
      "[Epoch 7/200] [Batch 475/637] [D loss: 0.133858] [G loss: 0.596245]\n",
      "[Epoch 7/200] [Batch 476/637] [D loss: 0.148310] [G loss: 0.615238]\n",
      "[Epoch 7/200] [Batch 477/637] [D loss: 0.152238] [G loss: 0.472095]\n",
      "[Epoch 7/200] [Batch 478/637] [D loss: 0.152207] [G loss: 0.525076]\n",
      "[Epoch 7/200] [Batch 479/637] [D loss: 0.142098] [G loss: 0.595784]\n",
      "[Epoch 7/200] [Batch 480/637] [D loss: 0.136080] [G loss: 0.584820]\n",
      "[Epoch 7/200] [Batch 481/637] [D loss: 0.139781] [G loss: 0.544257]\n",
      "[Epoch 7/200] [Batch 482/637] [D loss: 0.130610] [G loss: 0.551701]\n",
      "[Epoch 7/200] [Batch 483/637] [D loss: 0.147840] [G loss: 0.591000]\n",
      "[Epoch 7/200] [Batch 484/637] [D loss: 0.178283] [G loss: 0.573536]\n",
      "[Epoch 7/200] [Batch 485/637] [D loss: 0.138170] [G loss: 0.578871]\n",
      "[Epoch 7/200] [Batch 486/637] [D loss: 0.152357] [G loss: 0.517997]\n",
      "[Epoch 7/200] [Batch 487/637] [D loss: 0.132883] [G loss: 0.526328]\n",
      "[Epoch 7/200] [Batch 488/637] [D loss: 0.156217] [G loss: 0.489818]\n",
      "[Epoch 7/200] [Batch 489/637] [D loss: 0.158814] [G loss: 0.527787]\n",
      "[Epoch 7/200] [Batch 490/637] [D loss: 0.151900] [G loss: 0.534441]\n",
      "[Epoch 7/200] [Batch 491/637] [D loss: 0.178593] [G loss: 0.508494]\n",
      "[Epoch 7/200] [Batch 492/637] [D loss: 0.157571] [G loss: 0.611960]\n",
      "[Epoch 7/200] [Batch 493/637] [D loss: 0.156623] [G loss: 0.446980]\n",
      "[Epoch 7/200] [Batch 494/637] [D loss: 0.148421] [G loss: 0.527509]\n",
      "[Epoch 7/200] [Batch 495/637] [D loss: 0.155984] [G loss: 0.502156]\n",
      "[Epoch 7/200] [Batch 496/637] [D loss: 0.128874] [G loss: 0.540970]\n",
      "[Epoch 7/200] [Batch 497/637] [D loss: 0.139755] [G loss: 0.531307]\n",
      "[Epoch 7/200] [Batch 498/637] [D loss: 0.130249] [G loss: 0.517910]\n",
      "[Epoch 7/200] [Batch 499/637] [D loss: 0.122005] [G loss: 0.547057]\n",
      "[Epoch 7/200] [Batch 500/637] [D loss: 0.162126] [G loss: 0.554293]\n",
      "[Epoch 7/200] [Batch 501/637] [D loss: 0.168025] [G loss: 0.683221]\n",
      "[Epoch 7/200] [Batch 502/637] [D loss: 0.169626] [G loss: 0.571778]\n",
      "[Epoch 7/200] [Batch 503/637] [D loss: 0.151114] [G loss: 0.545414]\n",
      "[Epoch 7/200] [Batch 504/637] [D loss: 0.213868] [G loss: 0.414097]\n",
      "[Epoch 7/200] [Batch 505/637] [D loss: 0.337313] [G loss: 0.657039]\n",
      "[Epoch 7/200] [Batch 506/637] [D loss: 0.239583] [G loss: 0.820168]\n",
      "[Epoch 7/200] [Batch 507/637] [D loss: 0.229139] [G loss: 0.684508]\n",
      "[Epoch 7/200] [Batch 508/637] [D loss: 0.213938] [G loss: 0.484642]\n",
      "[Epoch 7/200] [Batch 509/637] [D loss: 0.168066] [G loss: 0.414103]\n",
      "[Epoch 7/200] [Batch 510/637] [D loss: 0.176076] [G loss: 0.379514]\n",
      "[Epoch 7/200] [Batch 511/637] [D loss: 0.164480] [G loss: 0.405657]\n",
      "[Epoch 7/200] [Batch 512/637] [D loss: 0.156981] [G loss: 0.446055]\n",
      "[Epoch 7/200] [Batch 513/637] [D loss: 0.140664] [G loss: 0.468655]\n",
      "[Epoch 7/200] [Batch 514/637] [D loss: 0.169347] [G loss: 0.488147]\n",
      "[Epoch 7/200] [Batch 515/637] [D loss: 0.143697] [G loss: 0.562784]\n",
      "[Epoch 7/200] [Batch 516/637] [D loss: 0.149456] [G loss: 0.522620]\n",
      "[Epoch 7/200] [Batch 517/637] [D loss: 0.152723] [G loss: 0.547816]\n",
      "[Epoch 7/200] [Batch 518/637] [D loss: 0.142583] [G loss: 0.548424]\n",
      "[Epoch 7/200] [Batch 519/637] [D loss: 0.151530] [G loss: 0.478622]\n",
      "[Epoch 7/200] [Batch 520/637] [D loss: 0.178083] [G loss: 0.467768]\n",
      "[Epoch 7/200] [Batch 521/637] [D loss: 0.185266] [G loss: 0.502644]\n",
      "[Epoch 7/200] [Batch 522/637] [D loss: 0.157097] [G loss: 0.507071]\n",
      "[Epoch 7/200] [Batch 523/637] [D loss: 0.168858] [G loss: 0.496899]\n",
      "[Epoch 7/200] [Batch 524/637] [D loss: 0.162066] [G loss: 0.477160]\n",
      "[Epoch 7/200] [Batch 525/637] [D loss: 0.147956] [G loss: 0.508773]\n",
      "[Epoch 7/200] [Batch 526/637] [D loss: 0.144536] [G loss: 0.551301]\n",
      "[Epoch 7/200] [Batch 527/637] [D loss: 0.166720] [G loss: 0.515023]\n",
      "[Epoch 7/200] [Batch 528/637] [D loss: 0.157596] [G loss: 0.568683]\n",
      "[Epoch 7/200] [Batch 529/637] [D loss: 0.161788] [G loss: 0.552892]\n",
      "[Epoch 7/200] [Batch 530/637] [D loss: 0.136826] [G loss: 0.517325]\n",
      "[Epoch 7/200] [Batch 531/637] [D loss: 0.146240] [G loss: 0.491890]\n",
      "[Epoch 7/200] [Batch 532/637] [D loss: 0.152024] [G loss: 0.599620]\n",
      "[Epoch 7/200] [Batch 533/637] [D loss: 0.145918] [G loss: 0.581212]\n",
      "[Epoch 7/200] [Batch 534/637] [D loss: 0.145181] [G loss: 0.559868]\n",
      "[Epoch 7/200] [Batch 535/637] [D loss: 0.156617] [G loss: 0.563240]\n",
      "[Epoch 7/200] [Batch 536/637] [D loss: 0.157543] [G loss: 0.519762]\n",
      "[Epoch 7/200] [Batch 537/637] [D loss: 0.155371] [G loss: 0.564331]\n",
      "[Epoch 7/200] [Batch 538/637] [D loss: 0.147963] [G loss: 0.542862]\n",
      "[Epoch 7/200] [Batch 539/637] [D loss: 0.168716] [G loss: 0.537518]\n",
      "[Epoch 7/200] [Batch 540/637] [D loss: 0.165679] [G loss: 0.509812]\n",
      "[Epoch 7/200] [Batch 541/637] [D loss: 0.151488] [G loss: 0.544046]\n",
      "[Epoch 7/200] [Batch 542/637] [D loss: 0.166398] [G loss: 0.529706]\n",
      "[Epoch 7/200] [Batch 543/637] [D loss: 0.152422] [G loss: 0.516974]\n",
      "[Epoch 7/200] [Batch 544/637] [D loss: 0.174684] [G loss: 0.454113]\n",
      "[Epoch 7/200] [Batch 545/637] [D loss: 0.158967] [G loss: 0.490435]\n",
      "[Epoch 7/200] [Batch 546/637] [D loss: 0.154556] [G loss: 0.478799]\n",
      "[Epoch 7/200] [Batch 547/637] [D loss: 0.170284] [G loss: 0.503630]\n",
      "[Epoch 7/200] [Batch 548/637] [D loss: 0.176612] [G loss: 0.496257]\n",
      "[Epoch 7/200] [Batch 549/637] [D loss: 0.184811] [G loss: 0.492920]\n",
      "[Epoch 7/200] [Batch 550/637] [D loss: 0.154808] [G loss: 0.536278]\n",
      "[Epoch 7/200] [Batch 551/637] [D loss: 0.177706] [G loss: 0.527560]\n",
      "[Epoch 7/200] [Batch 552/637] [D loss: 0.141283] [G loss: 0.613233]\n",
      "[Epoch 7/200] [Batch 553/637] [D loss: 0.185856] [G loss: 0.507335]\n",
      "[Epoch 7/200] [Batch 554/637] [D loss: 0.159539] [G loss: 0.615467]\n",
      "[Epoch 7/200] [Batch 555/637] [D loss: 0.157553] [G loss: 0.603018]\n",
      "[Epoch 7/200] [Batch 556/637] [D loss: 0.162889] [G loss: 0.553586]\n",
      "[Epoch 7/200] [Batch 557/637] [D loss: 0.151459] [G loss: 0.505200]\n",
      "[Epoch 7/200] [Batch 558/637] [D loss: 0.136259] [G loss: 0.534201]\n",
      "[Epoch 7/200] [Batch 559/637] [D loss: 0.139535] [G loss: 0.529231]\n",
      "[Epoch 7/200] [Batch 560/637] [D loss: 0.158231] [G loss: 0.526158]\n",
      "[Epoch 7/200] [Batch 561/637] [D loss: 0.153873] [G loss: 0.635259]\n",
      "[Epoch 7/200] [Batch 562/637] [D loss: 0.132651] [G loss: 0.667014]\n",
      "[Epoch 7/200] [Batch 563/637] [D loss: 0.155092] [G loss: 0.547030]\n",
      "[Epoch 7/200] [Batch 564/637] [D loss: 0.142094] [G loss: 0.596087]\n",
      "[Epoch 7/200] [Batch 565/637] [D loss: 0.153343] [G loss: 0.554796]\n",
      "[Epoch 7/200] [Batch 566/637] [D loss: 0.124822] [G loss: 0.554657]\n",
      "[Epoch 7/200] [Batch 567/637] [D loss: 0.114216] [G loss: 0.586674]\n",
      "[Epoch 7/200] [Batch 568/637] [D loss: 0.188670] [G loss: 0.574833]\n",
      "[Epoch 7/200] [Batch 569/637] [D loss: 0.202609] [G loss: 0.676451]\n",
      "[Epoch 7/200] [Batch 570/637] [D loss: 0.152738] [G loss: 0.662885]\n",
      "[Epoch 7/200] [Batch 571/637] [D loss: 0.177837] [G loss: 0.520644]\n",
      "[Epoch 7/200] [Batch 572/637] [D loss: 0.148104] [G loss: 0.548438]\n",
      "[Epoch 7/200] [Batch 573/637] [D loss: 0.146910] [G loss: 0.624541]\n",
      "[Epoch 7/200] [Batch 574/637] [D loss: 0.161105] [G loss: 0.499951]\n",
      "[Epoch 7/200] [Batch 575/637] [D loss: 0.142242] [G loss: 0.484800]\n",
      "[Epoch 7/200] [Batch 576/637] [D loss: 0.138936] [G loss: 0.618569]\n",
      "[Epoch 7/200] [Batch 577/637] [D loss: 0.147985] [G loss: 0.526629]\n",
      "[Epoch 7/200] [Batch 578/637] [D loss: 0.130411] [G loss: 0.531997]\n",
      "[Epoch 7/200] [Batch 579/637] [D loss: 0.129446] [G loss: 0.598242]\n",
      "[Epoch 7/200] [Batch 580/637] [D loss: 0.139455] [G loss: 0.578306]\n",
      "[Epoch 7/200] [Batch 581/637] [D loss: 0.143448] [G loss: 0.633606]\n",
      "[Epoch 7/200] [Batch 582/637] [D loss: 0.165123] [G loss: 0.499205]\n",
      "[Epoch 7/200] [Batch 583/637] [D loss: 0.165143] [G loss: 0.527066]\n",
      "[Epoch 7/200] [Batch 584/637] [D loss: 0.160038] [G loss: 0.577509]\n",
      "[Epoch 7/200] [Batch 585/637] [D loss: 0.159212] [G loss: 0.547611]\n",
      "[Epoch 7/200] [Batch 586/637] [D loss: 0.170009] [G loss: 0.425033]\n",
      "[Epoch 7/200] [Batch 587/637] [D loss: 0.168097] [G loss: 0.455904]\n",
      "[Epoch 7/200] [Batch 588/637] [D loss: 0.146146] [G loss: 0.573849]\n",
      "[Epoch 7/200] [Batch 589/637] [D loss: 0.151388] [G loss: 0.548261]\n",
      "[Epoch 7/200] [Batch 590/637] [D loss: 0.150426] [G loss: 0.527852]\n",
      "[Epoch 7/200] [Batch 591/637] [D loss: 0.155143] [G loss: 0.471644]\n",
      "[Epoch 7/200] [Batch 592/637] [D loss: 0.139392] [G loss: 0.482258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 593/637] [D loss: 0.139131] [G loss: 0.503172]\n",
      "[Epoch 7/200] [Batch 594/637] [D loss: 0.119545] [G loss: 0.582353]\n",
      "[Epoch 7/200] [Batch 595/637] [D loss: 0.164088] [G loss: 0.443049]\n",
      "[Epoch 7/200] [Batch 596/637] [D loss: 0.156354] [G loss: 0.525467]\n",
      "[Epoch 7/200] [Batch 597/637] [D loss: 0.129467] [G loss: 0.593644]\n",
      "[Epoch 7/200] [Batch 598/637] [D loss: 0.155063] [G loss: 0.600947]\n",
      "[Epoch 7/200] [Batch 599/637] [D loss: 0.122412] [G loss: 0.582525]\n",
      "[Epoch 7/200] [Batch 600/637] [D loss: 0.172713] [G loss: 0.510731]\n",
      "[Epoch 7/200] [Batch 601/637] [D loss: 0.151178] [G loss: 0.530858]\n",
      "[Epoch 7/200] [Batch 602/637] [D loss: 0.126711] [G loss: 0.617390]\n",
      "[Epoch 7/200] [Batch 603/637] [D loss: 0.137485] [G loss: 0.551971]\n",
      "[Epoch 7/200] [Batch 604/637] [D loss: 0.169366] [G loss: 0.480435]\n",
      "[Epoch 7/200] [Batch 605/637] [D loss: 0.161467] [G loss: 0.647453]\n",
      "[Epoch 7/200] [Batch 606/637] [D loss: 0.169737] [G loss: 0.533026]\n",
      "[Epoch 7/200] [Batch 607/637] [D loss: 0.187833] [G loss: 0.532798]\n",
      "[Epoch 7/200] [Batch 608/637] [D loss: 0.158519] [G loss: 0.490639]\n",
      "[Epoch 7/200] [Batch 609/637] [D loss: 0.174892] [G loss: 0.491502]\n",
      "[Epoch 7/200] [Batch 610/637] [D loss: 0.139542] [G loss: 0.460277]\n",
      "[Epoch 7/200] [Batch 611/637] [D loss: 0.139809] [G loss: 0.492669]\n",
      "[Epoch 7/200] [Batch 612/637] [D loss: 0.148846] [G loss: 0.552083]\n",
      "[Epoch 7/200] [Batch 613/637] [D loss: 0.160008] [G loss: 0.520326]\n",
      "[Epoch 7/200] [Batch 614/637] [D loss: 0.160570] [G loss: 0.478457]\n",
      "[Epoch 7/200] [Batch 615/637] [D loss: 0.196515] [G loss: 0.466594]\n",
      "[Epoch 7/200] [Batch 616/637] [D loss: 0.192474] [G loss: 0.493859]\n",
      "[Epoch 7/200] [Batch 617/637] [D loss: 0.154179] [G loss: 0.612611]\n",
      "[Epoch 7/200] [Batch 618/637] [D loss: 0.173049] [G loss: 0.597926]\n",
      "[Epoch 7/200] [Batch 619/637] [D loss: 0.142121] [G loss: 0.506753]\n",
      "[Epoch 7/200] [Batch 620/637] [D loss: 0.152489] [G loss: 0.484837]\n",
      "[Epoch 7/200] [Batch 621/637] [D loss: 0.142391] [G loss: 0.471791]\n",
      "[Epoch 7/200] [Batch 622/637] [D loss: 0.151963] [G loss: 0.459942]\n",
      "[Epoch 7/200] [Batch 623/637] [D loss: 0.156176] [G loss: 0.594988]\n",
      "[Epoch 7/200] [Batch 624/637] [D loss: 0.139781] [G loss: 0.574723]\n",
      "[Epoch 7/200] [Batch 625/637] [D loss: 0.138027] [G loss: 0.484605]\n",
      "[Epoch 7/200] [Batch 626/637] [D loss: 0.146794] [G loss: 0.577188]\n",
      "[Epoch 7/200] [Batch 627/637] [D loss: 0.138172] [G loss: 0.544554]\n",
      "[Epoch 7/200] [Batch 628/637] [D loss: 0.149592] [G loss: 0.482674]\n",
      "[Epoch 7/200] [Batch 629/637] [D loss: 0.165420] [G loss: 0.561118]\n",
      "[Epoch 7/200] [Batch 630/637] [D loss: 0.158024] [G loss: 0.583672]\n",
      "[Epoch 7/200] [Batch 631/637] [D loss: 0.161494] [G loss: 0.535806]\n",
      "[Epoch 7/200] [Batch 632/637] [D loss: 0.154110] [G loss: 0.489257]\n",
      "[Epoch 7/200] [Batch 633/637] [D loss: 0.263003] [G loss: 0.507696]\n",
      "[Epoch 7/200] [Batch 634/637] [D loss: 0.230475] [G loss: 0.813488]\n",
      "[Epoch 7/200] [Batch 635/637] [D loss: 0.198361] [G loss: 0.702211]\n",
      "[Epoch 7/200] [Batch 636/637] [D loss: 0.196751] [G loss: 0.591064]\n",
      "[Epoch 8/200] [Batch 0/637] [D loss: 0.162382] [G loss: 0.490486]\n",
      "[Epoch 8/200] [Batch 1/637] [D loss: 0.164725] [G loss: 0.411132]\n",
      "[Epoch 8/200] [Batch 2/637] [D loss: 0.158672] [G loss: 0.380542]\n",
      "[Epoch 8/200] [Batch 3/637] [D loss: 0.134712] [G loss: 0.479399]\n",
      "[Epoch 8/200] [Batch 4/637] [D loss: 0.133005] [G loss: 0.537858]\n",
      "[Epoch 8/200] [Batch 5/637] [D loss: 0.139541] [G loss: 0.491262]\n",
      "[Epoch 8/200] [Batch 6/637] [D loss: 0.147673] [G loss: 0.497600]\n",
      "[Epoch 8/200] [Batch 7/637] [D loss: 0.158476] [G loss: 0.518387]\n",
      "[Epoch 8/200] [Batch 8/637] [D loss: 0.132705] [G loss: 0.529681]\n",
      "[Epoch 8/200] [Batch 9/637] [D loss: 0.142369] [G loss: 0.576977]\n",
      "[Epoch 8/200] [Batch 10/637] [D loss: 0.162314] [G loss: 0.482318]\n",
      "[Epoch 8/200] [Batch 11/637] [D loss: 0.156847] [G loss: 0.650767]\n",
      "[Epoch 8/200] [Batch 12/637] [D loss: 0.141074] [G loss: 0.572125]\n",
      "[Epoch 8/200] [Batch 13/637] [D loss: 0.176062] [G loss: 0.483879]\n",
      "[Epoch 8/200] [Batch 14/637] [D loss: 0.167780] [G loss: 0.540779]\n",
      "[Epoch 8/200] [Batch 15/637] [D loss: 0.137267] [G loss: 0.574002]\n",
      "[Epoch 8/200] [Batch 16/637] [D loss: 0.138523] [G loss: 0.544183]\n",
      "[Epoch 8/200] [Batch 17/637] [D loss: 0.141398] [G loss: 0.528318]\n",
      "[Epoch 8/200] [Batch 18/637] [D loss: 0.156283] [G loss: 0.504111]\n",
      "[Epoch 8/200] [Batch 19/637] [D loss: 0.167097] [G loss: 0.523609]\n",
      "[Epoch 8/200] [Batch 20/637] [D loss: 0.124647] [G loss: 0.571037]\n",
      "[Epoch 8/200] [Batch 21/637] [D loss: 0.139145] [G loss: 0.518035]\n",
      "[Epoch 8/200] [Batch 22/637] [D loss: 0.163411] [G loss: 0.496976]\n",
      "[Epoch 8/200] [Batch 23/637] [D loss: 0.155100] [G loss: 0.523613]\n",
      "[Epoch 8/200] [Batch 24/637] [D loss: 0.146081] [G loss: 0.542969]\n",
      "[Epoch 8/200] [Batch 25/637] [D loss: 0.148111] [G loss: 0.468792]\n",
      "[Epoch 8/200] [Batch 26/637] [D loss: 0.142045] [G loss: 0.508487]\n",
      "[Epoch 8/200] [Batch 27/637] [D loss: 0.162731] [G loss: 0.538685]\n",
      "[Epoch 8/200] [Batch 28/637] [D loss: 0.179267] [G loss: 0.499043]\n",
      "[Epoch 8/200] [Batch 29/637] [D loss: 0.167715] [G loss: 0.548995]\n",
      "[Epoch 8/200] [Batch 30/637] [D loss: 0.130487] [G loss: 0.610457]\n",
      "[Epoch 8/200] [Batch 31/637] [D loss: 0.163672] [G loss: 0.543644]\n",
      "[Epoch 8/200] [Batch 32/637] [D loss: 0.172253] [G loss: 0.486203]\n",
      "[Epoch 8/200] [Batch 33/637] [D loss: 0.139546] [G loss: 0.476466]\n",
      "[Epoch 8/200] [Batch 34/637] [D loss: 0.159557] [G loss: 0.457122]\n",
      "[Epoch 8/200] [Batch 35/637] [D loss: 0.160661] [G loss: 0.577637]\n",
      "[Epoch 8/200] [Batch 36/637] [D loss: 0.177014] [G loss: 0.484405]\n",
      "[Epoch 8/200] [Batch 37/637] [D loss: 0.195279] [G loss: 0.442656]\n",
      "[Epoch 8/200] [Batch 38/637] [D loss: 0.201056] [G loss: 0.868944]\n",
      "[Epoch 8/200] [Batch 39/637] [D loss: 0.191268] [G loss: 0.581004]\n",
      "[Epoch 8/200] [Batch 40/637] [D loss: 0.178004] [G loss: 0.460241]\n",
      "[Epoch 8/200] [Batch 41/637] [D loss: 0.150921] [G loss: 0.449685]\n",
      "[Epoch 8/200] [Batch 42/637] [D loss: 0.151747] [G loss: 0.487542]\n",
      "[Epoch 8/200] [Batch 43/637] [D loss: 0.165550] [G loss: 0.523116]\n",
      "[Epoch 8/200] [Batch 44/637] [D loss: 0.141822] [G loss: 0.507564]\n",
      "[Epoch 8/200] [Batch 45/637] [D loss: 0.151836] [G loss: 0.492062]\n",
      "[Epoch 8/200] [Batch 46/637] [D loss: 0.138892] [G loss: 0.531991]\n",
      "[Epoch 8/200] [Batch 47/637] [D loss: 0.158196] [G loss: 0.557865]\n",
      "[Epoch 8/200] [Batch 48/637] [D loss: 0.144735] [G loss: 0.594207]\n",
      "[Epoch 8/200] [Batch 49/637] [D loss: 0.141544] [G loss: 0.575892]\n",
      "[Epoch 8/200] [Batch 50/637] [D loss: 0.144525] [G loss: 0.495851]\n",
      "[Epoch 8/200] [Batch 51/637] [D loss: 0.150844] [G loss: 0.533264]\n",
      "[Epoch 8/200] [Batch 52/637] [D loss: 0.123661] [G loss: 0.570861]\n",
      "[Epoch 8/200] [Batch 53/637] [D loss: 0.208312] [G loss: 0.494374]\n",
      "[Epoch 8/200] [Batch 54/637] [D loss: 0.158604] [G loss: 0.602212]\n",
      "[Epoch 8/200] [Batch 55/637] [D loss: 0.141361] [G loss: 0.604240]\n",
      "[Epoch 8/200] [Batch 56/637] [D loss: 0.137020] [G loss: 0.578464]\n",
      "[Epoch 8/200] [Batch 57/637] [D loss: 0.151959] [G loss: 0.528288]\n",
      "[Epoch 8/200] [Batch 58/637] [D loss: 0.156358] [G loss: 0.437704]\n",
      "[Epoch 8/200] [Batch 59/637] [D loss: 0.168013] [G loss: 0.511957]\n",
      "[Epoch 8/200] [Batch 60/637] [D loss: 0.147775] [G loss: 0.565462]\n",
      "[Epoch 8/200] [Batch 61/637] [D loss: 0.146555] [G loss: 0.584367]\n",
      "[Epoch 8/200] [Batch 62/637] [D loss: 0.147562] [G loss: 0.549430]\n",
      "[Epoch 8/200] [Batch 63/637] [D loss: 0.155679] [G loss: 0.530785]\n",
      "[Epoch 8/200] [Batch 64/637] [D loss: 0.207076] [G loss: 0.366474]\n",
      "[Epoch 8/200] [Batch 65/637] [D loss: 0.267227] [G loss: 0.518306]\n",
      "[Epoch 8/200] [Batch 66/637] [D loss: 0.174821] [G loss: 0.714578]\n",
      "[Epoch 8/200] [Batch 67/637] [D loss: 0.173088] [G loss: 0.606000]\n",
      "[Epoch 8/200] [Batch 68/637] [D loss: 0.158585] [G loss: 0.540873]\n",
      "[Epoch 8/200] [Batch 69/637] [D loss: 0.148636] [G loss: 0.524292]\n",
      "[Epoch 8/200] [Batch 70/637] [D loss: 0.152028] [G loss: 0.491127]\n",
      "[Epoch 8/200] [Batch 71/637] [D loss: 0.135758] [G loss: 0.527353]\n",
      "[Epoch 8/200] [Batch 72/637] [D loss: 0.134782] [G loss: 0.576973]\n",
      "[Epoch 8/200] [Batch 73/637] [D loss: 0.124799] [G loss: 0.533037]\n",
      "[Epoch 8/200] [Batch 74/637] [D loss: 0.161285] [G loss: 0.522828]\n",
      "[Epoch 8/200] [Batch 75/637] [D loss: 0.134204] [G loss: 0.511630]\n",
      "[Epoch 8/200] [Batch 76/637] [D loss: 0.134918] [G loss: 0.546847]\n",
      "[Epoch 8/200] [Batch 77/637] [D loss: 0.195437] [G loss: 0.548874]\n",
      "[Epoch 8/200] [Batch 78/637] [D loss: 0.242004] [G loss: 0.637547]\n",
      "[Epoch 8/200] [Batch 79/637] [D loss: 0.202866] [G loss: 0.651660]\n",
      "[Epoch 8/200] [Batch 80/637] [D loss: 0.140698] [G loss: 0.560135]\n",
      "[Epoch 8/200] [Batch 81/637] [D loss: 0.161296] [G loss: 0.443617]\n",
      "[Epoch 8/200] [Batch 82/637] [D loss: 0.140003] [G loss: 0.453398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 83/637] [D loss: 0.148351] [G loss: 0.479758]\n",
      "[Epoch 8/200] [Batch 84/637] [D loss: 0.156328] [G loss: 0.483232]\n",
      "[Epoch 8/200] [Batch 85/637] [D loss: 0.144927] [G loss: 0.537387]\n",
      "[Epoch 8/200] [Batch 86/637] [D loss: 0.140267] [G loss: 0.519612]\n",
      "[Epoch 8/200] [Batch 87/637] [D loss: 0.143622] [G loss: 0.506968]\n",
      "[Epoch 8/200] [Batch 88/637] [D loss: 0.155386] [G loss: 0.459197]\n",
      "[Epoch 8/200] [Batch 89/637] [D loss: 0.139864] [G loss: 0.576720]\n",
      "[Epoch 8/200] [Batch 90/637] [D loss: 0.119753] [G loss: 0.616221]\n",
      "[Epoch 8/200] [Batch 91/637] [D loss: 0.130276] [G loss: 0.616180]\n",
      "[Epoch 8/200] [Batch 92/637] [D loss: 0.146009] [G loss: 0.509399]\n",
      "[Epoch 8/200] [Batch 93/637] [D loss: 0.188853] [G loss: 0.430800]\n",
      "[Epoch 8/200] [Batch 94/637] [D loss: 0.190741] [G loss: 0.555298]\n",
      "[Epoch 8/200] [Batch 95/637] [D loss: 0.157459] [G loss: 0.653213]\n",
      "[Epoch 8/200] [Batch 96/637] [D loss: 0.134738] [G loss: 0.608446]\n",
      "[Epoch 8/200] [Batch 97/637] [D loss: 0.151638] [G loss: 0.531349]\n",
      "[Epoch 8/200] [Batch 98/637] [D loss: 0.177601] [G loss: 0.466426]\n",
      "[Epoch 8/200] [Batch 99/637] [D loss: 0.149258] [G loss: 0.512798]\n",
      "[Epoch 8/200] [Batch 100/637] [D loss: 0.154239] [G loss: 0.477255]\n",
      "[Epoch 8/200] [Batch 101/637] [D loss: 0.142801] [G loss: 0.564286]\n",
      "[Epoch 8/200] [Batch 102/637] [D loss: 0.142352] [G loss: 0.555008]\n",
      "[Epoch 8/200] [Batch 103/637] [D loss: 0.130988] [G loss: 0.592197]\n",
      "[Epoch 8/200] [Batch 104/637] [D loss: 0.153038] [G loss: 0.478582]\n",
      "[Epoch 8/200] [Batch 105/637] [D loss: 0.145921] [G loss: 0.543132]\n",
      "[Epoch 8/200] [Batch 106/637] [D loss: 0.149440] [G loss: 0.583553]\n",
      "[Epoch 8/200] [Batch 107/637] [D loss: 0.147430] [G loss: 0.553883]\n",
      "[Epoch 8/200] [Batch 108/637] [D loss: 0.133244] [G loss: 0.512669]\n",
      "[Epoch 8/200] [Batch 109/637] [D loss: 0.120062] [G loss: 0.521314]\n",
      "[Epoch 8/200] [Batch 110/637] [D loss: 0.179315] [G loss: 0.495730]\n",
      "[Epoch 8/200] [Batch 111/637] [D loss: 0.156215] [G loss: 0.672475]\n",
      "[Epoch 8/200] [Batch 112/637] [D loss: 0.154214] [G loss: 0.624544]\n",
      "[Epoch 8/200] [Batch 113/637] [D loss: 0.166584] [G loss: 0.534847]\n",
      "[Epoch 8/200] [Batch 114/637] [D loss: 0.138266] [G loss: 0.486946]\n",
      "[Epoch 8/200] [Batch 115/637] [D loss: 0.181632] [G loss: 0.444829]\n",
      "[Epoch 8/200] [Batch 116/637] [D loss: 0.160815] [G loss: 0.494968]\n",
      "[Epoch 8/200] [Batch 117/637] [D loss: 0.156897] [G loss: 0.534907]\n",
      "[Epoch 8/200] [Batch 118/637] [D loss: 0.161162] [G loss: 0.468377]\n",
      "[Epoch 8/200] [Batch 119/637] [D loss: 0.132848] [G loss: 0.494569]\n",
      "[Epoch 8/200] [Batch 120/637] [D loss: 0.146449] [G loss: 0.528838]\n",
      "[Epoch 8/200] [Batch 121/637] [D loss: 0.148187] [G loss: 0.507238]\n",
      "[Epoch 8/200] [Batch 122/637] [D loss: 0.161744] [G loss: 0.510706]\n",
      "[Epoch 8/200] [Batch 123/637] [D loss: 0.140094] [G loss: 0.505809]\n",
      "[Epoch 8/200] [Batch 124/637] [D loss: 0.187315] [G loss: 0.460384]\n",
      "[Epoch 8/200] [Batch 125/637] [D loss: 0.178558] [G loss: 0.491044]\n",
      "[Epoch 8/200] [Batch 126/637] [D loss: 0.154008] [G loss: 0.577388]\n",
      "[Epoch 8/200] [Batch 127/637] [D loss: 0.140793] [G loss: 0.506693]\n",
      "[Epoch 8/200] [Batch 128/637] [D loss: 0.136177] [G loss: 0.512401]\n",
      "[Epoch 8/200] [Batch 129/637] [D loss: 0.174926] [G loss: 0.452993]\n",
      "[Epoch 8/200] [Batch 130/637] [D loss: 0.165353] [G loss: 0.583101]\n",
      "[Epoch 8/200] [Batch 131/637] [D loss: 0.150370] [G loss: 0.550200]\n",
      "[Epoch 8/200] [Batch 132/637] [D loss: 0.150345] [G loss: 0.510692]\n",
      "[Epoch 8/200] [Batch 133/637] [D loss: 0.144946] [G loss: 0.518723]\n",
      "[Epoch 8/200] [Batch 134/637] [D loss: 0.163876] [G loss: 0.505439]\n",
      "[Epoch 8/200] [Batch 135/637] [D loss: 0.111202] [G loss: 0.611358]\n",
      "[Epoch 8/200] [Batch 136/637] [D loss: 0.138056] [G loss: 0.551909]\n",
      "[Epoch 8/200] [Batch 137/637] [D loss: 0.128472] [G loss: 0.556026]\n",
      "[Epoch 8/200] [Batch 138/637] [D loss: 0.128901] [G loss: 0.497282]\n",
      "[Epoch 8/200] [Batch 139/637] [D loss: 0.175192] [G loss: 0.480749]\n",
      "[Epoch 8/200] [Batch 140/637] [D loss: 0.193839] [G loss: 0.566941]\n",
      "[Epoch 8/200] [Batch 141/637] [D loss: 0.183523] [G loss: 0.635613]\n",
      "[Epoch 8/200] [Batch 142/637] [D loss: 0.165374] [G loss: 0.535113]\n",
      "[Epoch 8/200] [Batch 143/637] [D loss: 0.172215] [G loss: 0.441858]\n",
      "[Epoch 8/200] [Batch 144/637] [D loss: 0.154490] [G loss: 0.463114]\n",
      "[Epoch 8/200] [Batch 145/637] [D loss: 0.154816] [G loss: 0.536666]\n",
      "[Epoch 8/200] [Batch 146/637] [D loss: 0.150666] [G loss: 0.485731]\n",
      "[Epoch 8/200] [Batch 147/637] [D loss: 0.141568] [G loss: 0.569614]\n",
      "[Epoch 8/200] [Batch 148/637] [D loss: 0.145069] [G loss: 0.510756]\n",
      "[Epoch 8/200] [Batch 149/637] [D loss: 0.156346] [G loss: 0.473763]\n",
      "[Epoch 8/200] [Batch 150/637] [D loss: 0.147613] [G loss: 0.617782]\n",
      "[Epoch 8/200] [Batch 151/637] [D loss: 0.157808] [G loss: 0.659717]\n",
      "[Epoch 8/200] [Batch 152/637] [D loss: 0.133569] [G loss: 0.530369]\n",
      "[Epoch 8/200] [Batch 153/637] [D loss: 0.162949] [G loss: 0.452599]\n",
      "[Epoch 8/200] [Batch 154/637] [D loss: 0.170936] [G loss: 0.700725]\n",
      "[Epoch 8/200] [Batch 155/637] [D loss: 0.167808] [G loss: 0.689166]\n",
      "[Epoch 8/200] [Batch 156/637] [D loss: 0.172611] [G loss: 0.487045]\n",
      "[Epoch 8/200] [Batch 157/637] [D loss: 0.146284] [G loss: 0.559027]\n",
      "[Epoch 8/200] [Batch 158/637] [D loss: 0.147824] [G loss: 0.566129]\n",
      "[Epoch 8/200] [Batch 159/637] [D loss: 0.142232] [G loss: 0.582138]\n",
      "[Epoch 8/200] [Batch 160/637] [D loss: 0.149833] [G loss: 0.600989]\n",
      "[Epoch 8/200] [Batch 161/637] [D loss: 0.143330] [G loss: 0.542081]\n",
      "[Epoch 8/200] [Batch 162/637] [D loss: 0.137479] [G loss: 0.554190]\n",
      "[Epoch 8/200] [Batch 163/637] [D loss: 0.119802] [G loss: 0.627845]\n",
      "[Epoch 8/200] [Batch 164/637] [D loss: 0.135335] [G loss: 0.537238]\n",
      "[Epoch 8/200] [Batch 165/637] [D loss: 0.122888] [G loss: 0.536258]\n",
      "[Epoch 8/200] [Batch 166/637] [D loss: 0.144538] [G loss: 0.611795]\n",
      "[Epoch 8/200] [Batch 167/637] [D loss: 0.137219] [G loss: 0.598432]\n",
      "[Epoch 8/200] [Batch 168/637] [D loss: 0.123831] [G loss: 0.663176]\n",
      "[Epoch 8/200] [Batch 169/637] [D loss: 0.135485] [G loss: 0.530723]\n",
      "[Epoch 8/200] [Batch 170/637] [D loss: 0.127984] [G loss: 0.569168]\n",
      "[Epoch 8/200] [Batch 171/637] [D loss: 0.151532] [G loss: 0.518083]\n",
      "[Epoch 8/200] [Batch 172/637] [D loss: 0.133091] [G loss: 0.522321]\n",
      "[Epoch 8/200] [Batch 173/637] [D loss: 0.138810] [G loss: 0.533700]\n",
      "[Epoch 8/200] [Batch 174/637] [D loss: 0.150696] [G loss: 0.552160]\n",
      "[Epoch 8/200] [Batch 175/637] [D loss: 0.145418] [G loss: 0.544860]\n",
      "[Epoch 8/200] [Batch 176/637] [D loss: 0.183567] [G loss: 0.510844]\n",
      "[Epoch 8/200] [Batch 177/637] [D loss: 0.257317] [G loss: 0.592911]\n",
      "[Epoch 8/200] [Batch 178/637] [D loss: 0.161041] [G loss: 0.653077]\n",
      "[Epoch 8/200] [Batch 179/637] [D loss: 0.159676] [G loss: 0.576060]\n",
      "[Epoch 8/200] [Batch 180/637] [D loss: 0.139102] [G loss: 0.537689]\n",
      "[Epoch 8/200] [Batch 181/637] [D loss: 0.134960] [G loss: 0.543852]\n",
      "[Epoch 8/200] [Batch 182/637] [D loss: 0.133871] [G loss: 0.532661]\n",
      "[Epoch 8/200] [Batch 183/637] [D loss: 0.135029] [G loss: 0.521190]\n",
      "[Epoch 8/200] [Batch 184/637] [D loss: 0.132107] [G loss: 0.488654]\n",
      "[Epoch 8/200] [Batch 185/637] [D loss: 0.123023] [G loss: 0.588354]\n",
      "[Epoch 8/200] [Batch 186/637] [D loss: 0.129252] [G loss: 0.635619]\n",
      "[Epoch 8/200] [Batch 187/637] [D loss: 0.131662] [G loss: 0.544827]\n",
      "[Epoch 8/200] [Batch 188/637] [D loss: 0.135913] [G loss: 0.542789]\n",
      "[Epoch 8/200] [Batch 189/637] [D loss: 0.136575] [G loss: 0.519265]\n",
      "[Epoch 8/200] [Batch 190/637] [D loss: 0.126813] [G loss: 0.582150]\n",
      "[Epoch 8/200] [Batch 191/637] [D loss: 0.157106] [G loss: 0.547499]\n",
      "[Epoch 8/200] [Batch 192/637] [D loss: 0.143928] [G loss: 0.767232]\n",
      "[Epoch 8/200] [Batch 193/637] [D loss: 0.170095] [G loss: 0.554313]\n",
      "[Epoch 8/200] [Batch 194/637] [D loss: 0.154512] [G loss: 0.590256]\n",
      "[Epoch 8/200] [Batch 195/637] [D loss: 0.151337] [G loss: 0.508383]\n",
      "[Epoch 8/200] [Batch 196/637] [D loss: 0.155519] [G loss: 0.457825]\n",
      "[Epoch 8/200] [Batch 197/637] [D loss: 0.181059] [G loss: 0.525635]\n",
      "[Epoch 8/200] [Batch 198/637] [D loss: 0.136535] [G loss: 0.587440]\n",
      "[Epoch 8/200] [Batch 199/637] [D loss: 0.160769] [G loss: 0.547151]\n",
      "[Epoch 8/200] [Batch 200/637] [D loss: 0.160539] [G loss: 0.487492]\n",
      "[Epoch 8/200] [Batch 201/637] [D loss: 0.168486] [G loss: 0.477092]\n",
      "[Epoch 8/200] [Batch 202/637] [D loss: 0.183981] [G loss: 0.489667]\n",
      "[Epoch 8/200] [Batch 203/637] [D loss: 0.165387] [G loss: 0.489828]\n",
      "[Epoch 8/200] [Batch 204/637] [D loss: 0.147481] [G loss: 0.472956]\n",
      "[Epoch 8/200] [Batch 205/637] [D loss: 0.150240] [G loss: 0.508372]\n",
      "[Epoch 8/200] [Batch 206/637] [D loss: 0.155373] [G loss: 0.534708]\n",
      "[Epoch 8/200] [Batch 207/637] [D loss: 0.126519] [G loss: 0.536918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 208/637] [D loss: 0.148535] [G loss: 0.601469]\n",
      "[Epoch 8/200] [Batch 209/637] [D loss: 0.151568] [G loss: 0.505033]\n",
      "[Epoch 8/200] [Batch 210/637] [D loss: 0.155621] [G loss: 0.546898]\n",
      "[Epoch 8/200] [Batch 211/637] [D loss: 0.143878] [G loss: 0.574570]\n",
      "[Epoch 8/200] [Batch 212/637] [D loss: 0.151924] [G loss: 0.556975]\n",
      "[Epoch 8/200] [Batch 213/637] [D loss: 0.135179] [G loss: 0.497114]\n",
      "[Epoch 8/200] [Batch 214/637] [D loss: 0.135799] [G loss: 0.515942]\n",
      "[Epoch 8/200] [Batch 215/637] [D loss: 0.131226] [G loss: 0.556690]\n",
      "[Epoch 8/200] [Batch 216/637] [D loss: 0.142670] [G loss: 0.551824]\n",
      "[Epoch 8/200] [Batch 217/637] [D loss: 0.159000] [G loss: 0.558092]\n",
      "[Epoch 8/200] [Batch 218/637] [D loss: 0.158951] [G loss: 0.528747]\n",
      "[Epoch 8/200] [Batch 219/637] [D loss: 0.159035] [G loss: 0.547801]\n",
      "[Epoch 8/200] [Batch 220/637] [D loss: 0.152846] [G loss: 0.469514]\n",
      "[Epoch 8/200] [Batch 221/637] [D loss: 0.178609] [G loss: 0.515286]\n",
      "[Epoch 8/200] [Batch 222/637] [D loss: 0.177533] [G loss: 0.607127]\n",
      "[Epoch 8/200] [Batch 223/637] [D loss: 0.175941] [G loss: 0.661873]\n",
      "[Epoch 8/200] [Batch 224/637] [D loss: 0.160222] [G loss: 0.564227]\n",
      "[Epoch 8/200] [Batch 225/637] [D loss: 0.170391] [G loss: 0.442739]\n",
      "[Epoch 8/200] [Batch 226/637] [D loss: 0.153775] [G loss: 0.482562]\n",
      "[Epoch 8/200] [Batch 227/637] [D loss: 0.151132] [G loss: 0.449330]\n",
      "[Epoch 8/200] [Batch 228/637] [D loss: 0.135548] [G loss: 0.563646]\n",
      "[Epoch 8/200] [Batch 229/637] [D loss: 0.172584] [G loss: 0.535061]\n",
      "[Epoch 8/200] [Batch 230/637] [D loss: 0.165508] [G loss: 0.490911]\n",
      "[Epoch 8/200] [Batch 231/637] [D loss: 0.183306] [G loss: 0.509958]\n",
      "[Epoch 8/200] [Batch 232/637] [D loss: 0.172935] [G loss: 0.547665]\n",
      "[Epoch 8/200] [Batch 233/637] [D loss: 0.154930] [G loss: 0.539854]\n",
      "[Epoch 8/200] [Batch 234/637] [D loss: 0.165291] [G loss: 0.587970]\n",
      "[Epoch 8/200] [Batch 235/637] [D loss: 0.163590] [G loss: 0.467982]\n",
      "[Epoch 8/200] [Batch 236/637] [D loss: 0.152340] [G loss: 0.519546]\n",
      "[Epoch 8/200] [Batch 237/637] [D loss: 0.121966] [G loss: 0.560778]\n",
      "[Epoch 8/200] [Batch 238/637] [D loss: 0.150029] [G loss: 0.584023]\n",
      "[Epoch 8/200] [Batch 239/637] [D loss: 0.144944] [G loss: 0.574484]\n",
      "[Epoch 8/200] [Batch 240/637] [D loss: 0.138456] [G loss: 0.570966]\n",
      "[Epoch 8/200] [Batch 241/637] [D loss: 0.130769] [G loss: 0.543962]\n",
      "[Epoch 8/200] [Batch 242/637] [D loss: 0.124939] [G loss: 0.543775]\n",
      "[Epoch 8/200] [Batch 243/637] [D loss: 0.127794] [G loss: 0.583884]\n",
      "[Epoch 8/200] [Batch 244/637] [D loss: 0.175438] [G loss: 0.506148]\n",
      "[Epoch 8/200] [Batch 245/637] [D loss: 0.180158] [G loss: 0.583284]\n",
      "[Epoch 8/200] [Batch 246/637] [D loss: 0.144841] [G loss: 0.628872]\n",
      "[Epoch 8/200] [Batch 247/637] [D loss: 0.168240] [G loss: 0.602058]\n",
      "[Epoch 8/200] [Batch 248/637] [D loss: 0.177591] [G loss: 0.501299]\n",
      "[Epoch 8/200] [Batch 249/637] [D loss: 0.171250] [G loss: 0.531932]\n",
      "[Epoch 8/200] [Batch 250/637] [D loss: 0.145950] [G loss: 0.572856]\n",
      "[Epoch 8/200] [Batch 251/637] [D loss: 0.162565] [G loss: 0.522937]\n",
      "[Epoch 8/200] [Batch 252/637] [D loss: 0.146688] [G loss: 0.575517]\n",
      "[Epoch 8/200] [Batch 253/637] [D loss: 0.145067] [G loss: 0.528998]\n",
      "[Epoch 8/200] [Batch 254/637] [D loss: 0.146833] [G loss: 0.501605]\n",
      "[Epoch 8/200] [Batch 255/637] [D loss: 0.162060] [G loss: 0.522172]\n",
      "[Epoch 8/200] [Batch 256/637] [D loss: 0.182781] [G loss: 0.705168]\n",
      "[Epoch 8/200] [Batch 257/637] [D loss: 0.162939] [G loss: 0.632976]\n",
      "[Epoch 8/200] [Batch 258/637] [D loss: 0.150526] [G loss: 0.535715]\n",
      "[Epoch 8/200] [Batch 259/637] [D loss: 0.133628] [G loss: 0.578190]\n",
      "[Epoch 8/200] [Batch 260/637] [D loss: 0.136729] [G loss: 0.552690]\n",
      "[Epoch 8/200] [Batch 261/637] [D loss: 0.117829] [G loss: 0.583779]\n",
      "[Epoch 8/200] [Batch 262/637] [D loss: 0.148692] [G loss: 0.550020]\n",
      "[Epoch 8/200] [Batch 263/637] [D loss: 0.130176] [G loss: 0.618864]\n",
      "[Epoch 8/200] [Batch 264/637] [D loss: 0.125763] [G loss: 0.635827]\n",
      "[Epoch 8/200] [Batch 265/637] [D loss: 0.147111] [G loss: 0.593216]\n",
      "[Epoch 8/200] [Batch 266/637] [D loss: 0.152296] [G loss: 0.513463]\n",
      "[Epoch 8/200] [Batch 267/637] [D loss: 0.172102] [G loss: 0.620124]\n",
      "[Epoch 8/200] [Batch 268/637] [D loss: 0.134689] [G loss: 0.632293]\n",
      "[Epoch 8/200] [Batch 269/637] [D loss: 0.152412] [G loss: 0.525970]\n",
      "[Epoch 8/200] [Batch 270/637] [D loss: 0.144935] [G loss: 0.532012]\n",
      "[Epoch 8/200] [Batch 271/637] [D loss: 0.147121] [G loss: 0.521862]\n",
      "[Epoch 8/200] [Batch 272/637] [D loss: 0.164252] [G loss: 0.523711]\n",
      "[Epoch 8/200] [Batch 273/637] [D loss: 0.138240] [G loss: 0.548801]\n",
      "[Epoch 8/200] [Batch 274/637] [D loss: 0.144505] [G loss: 0.551286]\n",
      "[Epoch 8/200] [Batch 275/637] [D loss: 0.177128] [G loss: 0.498167]\n",
      "[Epoch 8/200] [Batch 276/637] [D loss: 0.128323] [G loss: 0.667671]\n",
      "[Epoch 8/200] [Batch 277/637] [D loss: 0.137631] [G loss: 0.589593]\n",
      "[Epoch 8/200] [Batch 278/637] [D loss: 0.150613] [G loss: 0.522865]\n",
      "[Epoch 8/200] [Batch 279/637] [D loss: 0.161095] [G loss: 0.529271]\n",
      "[Epoch 8/200] [Batch 280/637] [D loss: 0.130277] [G loss: 0.577663]\n",
      "[Epoch 8/200] [Batch 281/637] [D loss: 0.147654] [G loss: 0.561387]\n",
      "[Epoch 8/200] [Batch 282/637] [D loss: 0.156802] [G loss: 0.562673]\n",
      "[Epoch 8/200] [Batch 283/637] [D loss: 0.161692] [G loss: 0.575358]\n",
      "[Epoch 8/200] [Batch 284/637] [D loss: 0.159880] [G loss: 0.533310]\n",
      "[Epoch 8/200] [Batch 285/637] [D loss: 0.146410] [G loss: 0.548648]\n",
      "[Epoch 8/200] [Batch 286/637] [D loss: 0.156423] [G loss: 0.485306]\n",
      "[Epoch 8/200] [Batch 287/637] [D loss: 0.140049] [G loss: 0.490475]\n",
      "[Epoch 8/200] [Batch 288/637] [D loss: 0.144349] [G loss: 0.506225]\n",
      "[Epoch 8/200] [Batch 289/637] [D loss: 0.143842] [G loss: 0.553362]\n",
      "[Epoch 8/200] [Batch 290/637] [D loss: 0.137024] [G loss: 0.536761]\n",
      "[Epoch 8/200] [Batch 291/637] [D loss: 0.135661] [G loss: 0.532708]\n",
      "[Epoch 8/200] [Batch 292/637] [D loss: 0.154603] [G loss: 0.500302]\n",
      "[Epoch 8/200] [Batch 293/637] [D loss: 0.161095] [G loss: 0.488141]\n",
      "[Epoch 8/200] [Batch 294/637] [D loss: 0.132634] [G loss: 0.584985]\n",
      "[Epoch 8/200] [Batch 295/637] [D loss: 0.122573] [G loss: 0.599110]\n",
      "[Epoch 8/200] [Batch 296/637] [D loss: 0.127207] [G loss: 0.551540]\n",
      "[Epoch 8/200] [Batch 297/637] [D loss: 0.117529] [G loss: 0.554942]\n",
      "[Epoch 8/200] [Batch 298/637] [D loss: 0.137465] [G loss: 0.576161]\n",
      "[Epoch 8/200] [Batch 299/637] [D loss: 0.131383] [G loss: 0.508278]\n",
      "[Epoch 8/200] [Batch 300/637] [D loss: 0.162158] [G loss: 0.477010]\n",
      "[Epoch 8/200] [Batch 301/637] [D loss: 0.192277] [G loss: 0.572875]\n",
      "[Epoch 8/200] [Batch 302/637] [D loss: 0.176999] [G loss: 0.652629]\n",
      "[Epoch 8/200] [Batch 303/637] [D loss: 0.145157] [G loss: 0.549609]\n",
      "[Epoch 8/200] [Batch 304/637] [D loss: 0.128196] [G loss: 0.473346]\n",
      "[Epoch 8/200] [Batch 305/637] [D loss: 0.151768] [G loss: 0.447323]\n",
      "[Epoch 8/200] [Batch 306/637] [D loss: 0.123695] [G loss: 0.574204]\n",
      "[Epoch 8/200] [Batch 307/637] [D loss: 0.136792] [G loss: 0.565489]\n",
      "[Epoch 8/200] [Batch 308/637] [D loss: 0.138180] [G loss: 0.537231]\n",
      "[Epoch 8/200] [Batch 309/637] [D loss: 0.126873] [G loss: 0.576095]\n",
      "[Epoch 8/200] [Batch 310/637] [D loss: 0.141531] [G loss: 0.508543]\n",
      "[Epoch 8/200] [Batch 311/637] [D loss: 0.209893] [G loss: 0.538122]\n",
      "[Epoch 8/200] [Batch 312/637] [D loss: 0.174340] [G loss: 0.528184]\n",
      "[Epoch 8/200] [Batch 313/637] [D loss: 0.164296] [G loss: 0.549589]\n",
      "[Epoch 8/200] [Batch 314/637] [D loss: 0.161534] [G loss: 0.513850]\n",
      "[Epoch 8/200] [Batch 315/637] [D loss: 0.154362] [G loss: 0.510831]\n",
      "[Epoch 8/200] [Batch 316/637] [D loss: 0.167962] [G loss: 0.533838]\n",
      "[Epoch 8/200] [Batch 317/637] [D loss: 0.163075] [G loss: 0.562043]\n",
      "[Epoch 8/200] [Batch 318/637] [D loss: 0.166005] [G loss: 0.525271]\n",
      "[Epoch 8/200] [Batch 319/637] [D loss: 0.158538] [G loss: 0.549294]\n",
      "[Epoch 8/200] [Batch 320/637] [D loss: 0.147550] [G loss: 0.583845]\n",
      "[Epoch 8/200] [Batch 321/637] [D loss: 0.132880] [G loss: 0.497443]\n",
      "[Epoch 8/200] [Batch 322/637] [D loss: 0.137070] [G loss: 0.528623]\n",
      "[Epoch 8/200] [Batch 323/637] [D loss: 0.141960] [G loss: 0.620124]\n",
      "[Epoch 8/200] [Batch 324/637] [D loss: 0.145812] [G loss: 0.529157]\n",
      "[Epoch 8/200] [Batch 325/637] [D loss: 0.150017] [G loss: 0.570319]\n",
      "[Epoch 8/200] [Batch 326/637] [D loss: 0.115127] [G loss: 0.639210]\n",
      "[Epoch 8/200] [Batch 327/637] [D loss: 0.131017] [G loss: 0.539567]\n",
      "[Epoch 8/200] [Batch 328/637] [D loss: 0.101346] [G loss: 0.634421]\n",
      "[Epoch 8/200] [Batch 329/637] [D loss: 0.120439] [G loss: 0.544625]\n",
      "[Epoch 8/200] [Batch 330/637] [D loss: 0.141247] [G loss: 0.549041]\n",
      "[Epoch 8/200] [Batch 331/637] [D loss: 0.154698] [G loss: 0.591909]\n",
      "[Epoch 8/200] [Batch 332/637] [D loss: 0.149882] [G loss: 0.647462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 333/637] [D loss: 0.146146] [G loss: 0.557230]\n",
      "[Epoch 8/200] [Batch 334/637] [D loss: 0.150026] [G loss: 0.583572]\n",
      "[Epoch 8/200] [Batch 335/637] [D loss: 0.149029] [G loss: 0.637080]\n",
      "[Epoch 8/200] [Batch 336/637] [D loss: 0.145259] [G loss: 0.576602]\n",
      "[Epoch 8/200] [Batch 337/637] [D loss: 0.132330] [G loss: 0.502982]\n",
      "[Epoch 8/200] [Batch 338/637] [D loss: 0.154590] [G loss: 0.533316]\n",
      "[Epoch 8/200] [Batch 339/637] [D loss: 0.139231] [G loss: 0.618550]\n",
      "[Epoch 8/200] [Batch 340/637] [D loss: 0.152685] [G loss: 0.584076]\n",
      "[Epoch 8/200] [Batch 341/637] [D loss: 0.128683] [G loss: 0.655178]\n",
      "[Epoch 8/200] [Batch 342/637] [D loss: 0.189549] [G loss: 0.509455]\n",
      "[Epoch 8/200] [Batch 343/637] [D loss: 0.252557] [G loss: 0.550342]\n",
      "[Epoch 8/200] [Batch 344/637] [D loss: 0.142875] [G loss: 0.720592]\n",
      "[Epoch 8/200] [Batch 345/637] [D loss: 0.223882] [G loss: 0.512556]\n",
      "[Epoch 8/200] [Batch 346/637] [D loss: 0.175813] [G loss: 0.552739]\n",
      "[Epoch 8/200] [Batch 347/637] [D loss: 0.184701] [G loss: 0.563870]\n",
      "[Epoch 8/200] [Batch 348/637] [D loss: 0.155973] [G loss: 0.510613]\n",
      "[Epoch 8/200] [Batch 349/637] [D loss: 0.152896] [G loss: 0.495261]\n",
      "[Epoch 8/200] [Batch 350/637] [D loss: 0.161797] [G loss: 0.457924]\n",
      "[Epoch 8/200] [Batch 351/637] [D loss: 0.135742] [G loss: 0.535150]\n",
      "[Epoch 8/200] [Batch 352/637] [D loss: 0.145483] [G loss: 0.495016]\n",
      "[Epoch 8/200] [Batch 353/637] [D loss: 0.127220] [G loss: 0.564895]\n",
      "[Epoch 8/200] [Batch 354/637] [D loss: 0.160008] [G loss: 0.523255]\n",
      "[Epoch 8/200] [Batch 355/637] [D loss: 0.126317] [G loss: 0.586601]\n",
      "[Epoch 8/200] [Batch 356/637] [D loss: 0.163379] [G loss: 0.568812]\n",
      "[Epoch 8/200] [Batch 357/637] [D loss: 0.137901] [G loss: 0.543818]\n",
      "[Epoch 8/200] [Batch 358/637] [D loss: 0.242750] [G loss: 0.451946]\n",
      "[Epoch 8/200] [Batch 359/637] [D loss: 0.221935] [G loss: 0.704775]\n",
      "[Epoch 8/200] [Batch 360/637] [D loss: 0.237213] [G loss: 0.574993]\n",
      "[Epoch 8/200] [Batch 361/637] [D loss: 0.181660] [G loss: 0.579030]\n",
      "[Epoch 8/200] [Batch 362/637] [D loss: 0.171639] [G loss: 0.507904]\n",
      "[Epoch 8/200] [Batch 363/637] [D loss: 0.210317] [G loss: 0.389661]\n",
      "[Epoch 8/200] [Batch 364/637] [D loss: 0.174905] [G loss: 0.447277]\n",
      "[Epoch 8/200] [Batch 365/637] [D loss: 0.152682] [G loss: 0.570405]\n",
      "[Epoch 8/200] [Batch 366/637] [D loss: 0.152142] [G loss: 0.559782]\n",
      "[Epoch 8/200] [Batch 367/637] [D loss: 0.118227] [G loss: 0.560481]\n",
      "[Epoch 8/200] [Batch 368/637] [D loss: 0.119418] [G loss: 0.573796]\n",
      "[Epoch 8/200] [Batch 369/637] [D loss: 0.170373] [G loss: 0.475318]\n",
      "[Epoch 8/200] [Batch 370/637] [D loss: 0.176030] [G loss: 0.672676]\n",
      "[Epoch 8/200] [Batch 371/637] [D loss: 0.168368] [G loss: 0.572874]\n",
      "[Epoch 8/200] [Batch 372/637] [D loss: 0.137232] [G loss: 0.548328]\n",
      "[Epoch 8/200] [Batch 373/637] [D loss: 0.187164] [G loss: 0.438449]\n",
      "[Epoch 8/200] [Batch 374/637] [D loss: 0.161273] [G loss: 0.509141]\n",
      "[Epoch 8/200] [Batch 375/637] [D loss: 0.154098] [G loss: 0.477453]\n",
      "[Epoch 8/200] [Batch 376/637] [D loss: 0.143728] [G loss: 0.582132]\n",
      "[Epoch 8/200] [Batch 377/637] [D loss: 0.139836] [G loss: 0.554766]\n",
      "[Epoch 8/200] [Batch 378/637] [D loss: 0.142727] [G loss: 0.551253]\n",
      "[Epoch 8/200] [Batch 379/637] [D loss: 0.175862] [G loss: 0.526709]\n",
      "[Epoch 8/200] [Batch 380/637] [D loss: 0.184465] [G loss: 0.595915]\n",
      "[Epoch 8/200] [Batch 381/637] [D loss: 0.121300] [G loss: 0.633240]\n",
      "[Epoch 8/200] [Batch 382/637] [D loss: 0.143504] [G loss: 0.596761]\n",
      "[Epoch 8/200] [Batch 383/637] [D loss: 0.118122] [G loss: 0.578326]\n",
      "[Epoch 8/200] [Batch 384/637] [D loss: 0.148098] [G loss: 0.571022]\n",
      "[Epoch 8/200] [Batch 385/637] [D loss: 0.147829] [G loss: 0.603947]\n",
      "[Epoch 8/200] [Batch 386/637] [D loss: 0.149134] [G loss: 0.648250]\n",
      "[Epoch 8/200] [Batch 387/637] [D loss: 0.151932] [G loss: 0.647375]\n",
      "[Epoch 8/200] [Batch 388/637] [D loss: 0.169408] [G loss: 0.529602]\n",
      "[Epoch 8/200] [Batch 389/637] [D loss: 0.173729] [G loss: 0.650834]\n",
      "[Epoch 8/200] [Batch 390/637] [D loss: 0.153749] [G loss: 0.579479]\n",
      "[Epoch 8/200] [Batch 391/637] [D loss: 0.148631] [G loss: 0.588199]\n",
      "[Epoch 8/200] [Batch 392/637] [D loss: 0.141153] [G loss: 0.601622]\n",
      "[Epoch 8/200] [Batch 393/637] [D loss: 0.140447] [G loss: 0.533666]\n",
      "[Epoch 8/200] [Batch 394/637] [D loss: 0.141217] [G loss: 0.485970]\n",
      "[Epoch 8/200] [Batch 395/637] [D loss: 0.148846] [G loss: 0.518553]\n",
      "[Epoch 8/200] [Batch 396/637] [D loss: 0.136832] [G loss: 0.608961]\n",
      "[Epoch 8/200] [Batch 397/637] [D loss: 0.159228] [G loss: 0.549324]\n",
      "[Epoch 8/200] [Batch 398/637] [D loss: 0.156832] [G loss: 0.539702]\n",
      "[Epoch 8/200] [Batch 399/637] [D loss: 0.167886] [G loss: 0.547585]\n",
      "[Epoch 8/200] [Batch 400/637] [D loss: 0.153720] [G loss: 0.583102]\n",
      "[Epoch 8/200] [Batch 401/637] [D loss: 0.163759] [G loss: 0.518597]\n",
      "[Epoch 8/200] [Batch 402/637] [D loss: 0.152441] [G loss: 0.541190]\n",
      "[Epoch 8/200] [Batch 403/637] [D loss: 0.143617] [G loss: 0.566339]\n",
      "[Epoch 8/200] [Batch 404/637] [D loss: 0.182687] [G loss: 0.616734]\n",
      "[Epoch 8/200] [Batch 405/637] [D loss: 0.155322] [G loss: 0.529470]\n",
      "[Epoch 8/200] [Batch 406/637] [D loss: 0.144699] [G loss: 0.539041]\n",
      "[Epoch 8/200] [Batch 407/637] [D loss: 0.124872] [G loss: 0.575302]\n",
      "[Epoch 8/200] [Batch 408/637] [D loss: 0.182455] [G loss: 0.547589]\n",
      "[Epoch 8/200] [Batch 409/637] [D loss: 0.164029] [G loss: 0.610598]\n",
      "[Epoch 8/200] [Batch 410/637] [D loss: 0.141077] [G loss: 0.557600]\n",
      "[Epoch 8/200] [Batch 411/637] [D loss: 0.143968] [G loss: 0.514306]\n",
      "[Epoch 8/200] [Batch 412/637] [D loss: 0.140880] [G loss: 0.548585]\n",
      "[Epoch 8/200] [Batch 413/637] [D loss: 0.136892] [G loss: 0.558340]\n",
      "[Epoch 8/200] [Batch 414/637] [D loss: 0.139434] [G loss: 0.521596]\n",
      "[Epoch 8/200] [Batch 415/637] [D loss: 0.152891] [G loss: 0.538458]\n",
      "[Epoch 8/200] [Batch 416/637] [D loss: 0.149368] [G loss: 0.579682]\n",
      "[Epoch 8/200] [Batch 417/637] [D loss: 0.148524] [G loss: 0.563125]\n",
      "[Epoch 8/200] [Batch 418/637] [D loss: 0.141687] [G loss: 0.519784]\n",
      "[Epoch 8/200] [Batch 419/637] [D loss: 0.139612] [G loss: 0.596181]\n",
      "[Epoch 8/200] [Batch 420/637] [D loss: 0.144806] [G loss: 0.553789]\n",
      "[Epoch 8/200] [Batch 421/637] [D loss: 0.136197] [G loss: 0.548789]\n",
      "[Epoch 8/200] [Batch 422/637] [D loss: 0.135032] [G loss: 0.553681]\n",
      "[Epoch 8/200] [Batch 423/637] [D loss: 0.192148] [G loss: 0.484051]\n",
      "[Epoch 8/200] [Batch 424/637] [D loss: 0.195594] [G loss: 0.595223]\n",
      "[Epoch 8/200] [Batch 425/637] [D loss: 0.136822] [G loss: 0.625173]\n",
      "[Epoch 8/200] [Batch 426/637] [D loss: 0.146755] [G loss: 0.578063]\n",
      "[Epoch 8/200] [Batch 427/637] [D loss: 0.162158] [G loss: 0.429540]\n",
      "[Epoch 8/200] [Batch 428/637] [D loss: 0.141765] [G loss: 0.509666]\n",
      "[Epoch 8/200] [Batch 429/637] [D loss: 0.184575] [G loss: 0.435739]\n",
      "[Epoch 8/200] [Batch 430/637] [D loss: 0.190808] [G loss: 0.588854]\n",
      "[Epoch 8/200] [Batch 431/637] [D loss: 0.144474] [G loss: 0.608192]\n",
      "[Epoch 8/200] [Batch 432/637] [D loss: 0.170095] [G loss: 0.577492]\n",
      "[Epoch 8/200] [Batch 433/637] [D loss: 0.172846] [G loss: 0.499227]\n",
      "[Epoch 8/200] [Batch 434/637] [D loss: 0.133685] [G loss: 0.542264]\n",
      "[Epoch 8/200] [Batch 435/637] [D loss: 0.161331] [G loss: 0.533194]\n",
      "[Epoch 8/200] [Batch 436/637] [D loss: 0.141126] [G loss: 0.557861]\n",
      "[Epoch 8/200] [Batch 437/637] [D loss: 0.139484] [G loss: 0.501042]\n",
      "[Epoch 8/200] [Batch 438/637] [D loss: 0.146529] [G loss: 0.485011]\n",
      "[Epoch 8/200] [Batch 439/637] [D loss: 0.167755] [G loss: 0.483294]\n",
      "[Epoch 8/200] [Batch 440/637] [D loss: 0.145439] [G loss: 0.525365]\n",
      "[Epoch 8/200] [Batch 441/637] [D loss: 0.138877] [G loss: 0.571161]\n",
      "[Epoch 8/200] [Batch 442/637] [D loss: 0.138485] [G loss: 0.545071]\n",
      "[Epoch 8/200] [Batch 443/637] [D loss: 0.128090] [G loss: 0.559044]\n",
      "[Epoch 8/200] [Batch 444/637] [D loss: 0.127073] [G loss: 0.552441]\n",
      "[Epoch 8/200] [Batch 445/637] [D loss: 0.134229] [G loss: 0.594353]\n",
      "[Epoch 8/200] [Batch 446/637] [D loss: 0.120506] [G loss: 0.639801]\n",
      "[Epoch 8/200] [Batch 447/637] [D loss: 0.140443] [G loss: 0.521027]\n",
      "[Epoch 8/200] [Batch 448/637] [D loss: 0.133589] [G loss: 0.610401]\n",
      "[Epoch 8/200] [Batch 449/637] [D loss: 0.155133] [G loss: 0.524957]\n",
      "[Epoch 8/200] [Batch 450/637] [D loss: 0.151536] [G loss: 0.622287]\n",
      "[Epoch 8/200] [Batch 451/637] [D loss: 0.131196] [G loss: 0.659634]\n",
      "[Epoch 8/200] [Batch 452/637] [D loss: 0.148776] [G loss: 0.572513]\n",
      "[Epoch 8/200] [Batch 453/637] [D loss: 0.151505] [G loss: 0.479327]\n",
      "[Epoch 8/200] [Batch 454/637] [D loss: 0.158716] [G loss: 0.522118]\n",
      "[Epoch 8/200] [Batch 455/637] [D loss: 0.151396] [G loss: 0.544658]\n",
      "[Epoch 8/200] [Batch 456/637] [D loss: 0.158061] [G loss: 0.517317]\n",
      "[Epoch 8/200] [Batch 457/637] [D loss: 0.160733] [G loss: 0.482551]\n",
      "[Epoch 8/200] [Batch 458/637] [D loss: 0.156018] [G loss: 0.537632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 459/637] [D loss: 0.137618] [G loss: 0.517920]\n",
      "[Epoch 8/200] [Batch 460/637] [D loss: 0.155482] [G loss: 0.471517]\n",
      "[Epoch 8/200] [Batch 461/637] [D loss: 0.156400] [G loss: 0.563430]\n",
      "[Epoch 8/200] [Batch 462/637] [D loss: 0.138252] [G loss: 0.518569]\n",
      "[Epoch 8/200] [Batch 463/637] [D loss: 0.164478] [G loss: 0.498100]\n",
      "[Epoch 8/200] [Batch 464/637] [D loss: 0.138509] [G loss: 0.611846]\n",
      "[Epoch 8/200] [Batch 465/637] [D loss: 0.148556] [G loss: 0.492355]\n",
      "[Epoch 8/200] [Batch 466/637] [D loss: 0.153238] [G loss: 0.531844]\n",
      "[Epoch 8/200] [Batch 467/637] [D loss: 0.161033] [G loss: 0.559425]\n",
      "[Epoch 8/200] [Batch 468/637] [D loss: 0.138383] [G loss: 0.536920]\n",
      "[Epoch 8/200] [Batch 469/637] [D loss: 0.171620] [G loss: 0.500844]\n",
      "[Epoch 8/200] [Batch 470/637] [D loss: 0.138709] [G loss: 0.523285]\n",
      "[Epoch 8/200] [Batch 471/637] [D loss: 0.156636] [G loss: 0.509943]\n",
      "[Epoch 8/200] [Batch 472/637] [D loss: 0.132839] [G loss: 0.552416]\n",
      "[Epoch 8/200] [Batch 473/637] [D loss: 0.160687] [G loss: 0.522723]\n",
      "[Epoch 8/200] [Batch 474/637] [D loss: 0.150401] [G loss: 0.493908]\n",
      "[Epoch 8/200] [Batch 475/637] [D loss: 0.150452] [G loss: 0.493510]\n",
      "[Epoch 8/200] [Batch 476/637] [D loss: 0.162625] [G loss: 0.475844]\n",
      "[Epoch 8/200] [Batch 477/637] [D loss: 0.163278] [G loss: 0.451074]\n",
      "[Epoch 8/200] [Batch 478/637] [D loss: 0.194185] [G loss: 0.601065]\n",
      "[Epoch 8/200] [Batch 479/637] [D loss: 0.167428] [G loss: 0.537502]\n",
      "[Epoch 8/200] [Batch 480/637] [D loss: 0.178022] [G loss: 0.441924]\n",
      "[Epoch 8/200] [Batch 481/637] [D loss: 0.177167] [G loss: 0.444415]\n",
      "[Epoch 8/200] [Batch 482/637] [D loss: 0.163586] [G loss: 0.515251]\n",
      "[Epoch 8/200] [Batch 483/637] [D loss: 0.159617] [G loss: 0.479428]\n",
      "[Epoch 8/200] [Batch 484/637] [D loss: 0.168896] [G loss: 0.431869]\n",
      "[Epoch 8/200] [Batch 485/637] [D loss: 0.150748] [G loss: 0.490181]\n",
      "[Epoch 8/200] [Batch 486/637] [D loss: 0.142144] [G loss: 0.503348]\n",
      "[Epoch 8/200] [Batch 487/637] [D loss: 0.142813] [G loss: 0.538916]\n",
      "[Epoch 8/200] [Batch 488/637] [D loss: 0.128480] [G loss: 0.554178]\n",
      "[Epoch 8/200] [Batch 489/637] [D loss: 0.133223] [G loss: 0.533913]\n",
      "[Epoch 8/200] [Batch 490/637] [D loss: 0.135095] [G loss: 0.528976]\n",
      "[Epoch 8/200] [Batch 491/637] [D loss: 0.146951] [G loss: 0.512598]\n",
      "[Epoch 8/200] [Batch 492/637] [D loss: 0.124375] [G loss: 0.617316]\n",
      "[Epoch 8/200] [Batch 493/637] [D loss: 0.139944] [G loss: 0.507798]\n",
      "[Epoch 8/200] [Batch 494/637] [D loss: 0.165056] [G loss: 0.519700]\n",
      "[Epoch 8/200] [Batch 495/637] [D loss: 0.152703] [G loss: 0.668377]\n",
      "[Epoch 8/200] [Batch 496/637] [D loss: 0.136684] [G loss: 0.520103]\n",
      "[Epoch 8/200] [Batch 497/637] [D loss: 0.174354] [G loss: 0.456759]\n",
      "[Epoch 8/200] [Batch 498/637] [D loss: 0.177259] [G loss: 0.737118]\n",
      "[Epoch 8/200] [Batch 499/637] [D loss: 0.155600] [G loss: 0.635123]\n",
      "[Epoch 8/200] [Batch 500/637] [D loss: 0.148621] [G loss: 0.547633]\n",
      "[Epoch 8/200] [Batch 501/637] [D loss: 0.152443] [G loss: 0.470751]\n",
      "[Epoch 8/200] [Batch 502/637] [D loss: 0.148010] [G loss: 0.501918]\n",
      "[Epoch 8/200] [Batch 503/637] [D loss: 0.129493] [G loss: 0.534910]\n",
      "[Epoch 8/200] [Batch 504/637] [D loss: 0.128752] [G loss: 0.591009]\n",
      "[Epoch 8/200] [Batch 505/637] [D loss: 0.151969] [G loss: 0.518203]\n",
      "[Epoch 8/200] [Batch 506/637] [D loss: 0.171515] [G loss: 0.530322]\n",
      "[Epoch 8/200] [Batch 507/637] [D loss: 0.148383] [G loss: 0.524843]\n",
      "[Epoch 8/200] [Batch 508/637] [D loss: 0.198615] [G loss: 0.455532]\n",
      "[Epoch 8/200] [Batch 509/637] [D loss: 0.180783] [G loss: 0.521086]\n",
      "[Epoch 8/200] [Batch 510/637] [D loss: 0.141196] [G loss: 0.541423]\n",
      "[Epoch 8/200] [Batch 511/637] [D loss: 0.156367] [G loss: 0.592805]\n",
      "[Epoch 8/200] [Batch 512/637] [D loss: 0.164692] [G loss: 0.500160]\n",
      "[Epoch 8/200] [Batch 513/637] [D loss: 0.141079] [G loss: 0.500938]\n",
      "[Epoch 8/200] [Batch 514/637] [D loss: 0.171904] [G loss: 0.478345]\n",
      "[Epoch 8/200] [Batch 515/637] [D loss: 0.169788] [G loss: 0.603130]\n",
      "[Epoch 8/200] [Batch 516/637] [D loss: 0.150467] [G loss: 0.542965]\n",
      "[Epoch 8/200] [Batch 517/637] [D loss: 0.168363] [G loss: 0.506248]\n",
      "[Epoch 8/200] [Batch 518/637] [D loss: 0.151278] [G loss: 0.560093]\n",
      "[Epoch 8/200] [Batch 519/637] [D loss: 0.148356] [G loss: 0.523505]\n",
      "[Epoch 8/200] [Batch 520/637] [D loss: 0.144374] [G loss: 0.520870]\n",
      "[Epoch 8/200] [Batch 521/637] [D loss: 0.164825] [G loss: 0.529579]\n",
      "[Epoch 8/200] [Batch 522/637] [D loss: 0.131854] [G loss: 0.531354]\n",
      "[Epoch 8/200] [Batch 523/637] [D loss: 0.138673] [G loss: 0.545387]\n",
      "[Epoch 8/200] [Batch 524/637] [D loss: 0.147769] [G loss: 0.529785]\n",
      "[Epoch 8/200] [Batch 525/637] [D loss: 0.118389] [G loss: 0.588266]\n",
      "[Epoch 8/200] [Batch 526/637] [D loss: 0.160196] [G loss: 0.559330]\n",
      "[Epoch 8/200] [Batch 527/637] [D loss: 0.157745] [G loss: 0.514225]\n",
      "[Epoch 8/200] [Batch 528/637] [D loss: 0.126407] [G loss: 0.646046]\n",
      "[Epoch 8/200] [Batch 529/637] [D loss: 0.146226] [G loss: 0.591446]\n",
      "[Epoch 8/200] [Batch 530/637] [D loss: 0.140198] [G loss: 0.531195]\n",
      "[Epoch 8/200] [Batch 531/637] [D loss: 0.147158] [G loss: 0.543044]\n",
      "[Epoch 8/200] [Batch 532/637] [D loss: 0.169870] [G loss: 0.547348]\n",
      "[Epoch 8/200] [Batch 533/637] [D loss: 0.129918] [G loss: 0.553925]\n",
      "[Epoch 8/200] [Batch 534/637] [D loss: 0.156574] [G loss: 0.559889]\n",
      "[Epoch 8/200] [Batch 535/637] [D loss: 0.143026] [G loss: 0.502961]\n",
      "[Epoch 8/200] [Batch 536/637] [D loss: 0.158078] [G loss: 0.538684]\n",
      "[Epoch 8/200] [Batch 537/637] [D loss: 0.242329] [G loss: 0.530777]\n",
      "[Epoch 8/200] [Batch 538/637] [D loss: 0.144669] [G loss: 0.607089]\n",
      "[Epoch 8/200] [Batch 539/637] [D loss: 0.158543] [G loss: 0.594112]\n",
      "[Epoch 8/200] [Batch 540/637] [D loss: 0.155398] [G loss: 0.551038]\n",
      "[Epoch 8/200] [Batch 541/637] [D loss: 0.147390] [G loss: 0.510814]\n",
      "[Epoch 8/200] [Batch 542/637] [D loss: 0.134991] [G loss: 0.505371]\n",
      "[Epoch 8/200] [Batch 543/637] [D loss: 0.153614] [G loss: 0.472214]\n",
      "[Epoch 8/200] [Batch 544/637] [D loss: 0.167952] [G loss: 0.503774]\n",
      "[Epoch 8/200] [Batch 545/637] [D loss: 0.151740] [G loss: 0.591379]\n",
      "[Epoch 8/200] [Batch 546/637] [D loss: 0.129016] [G loss: 0.629412]\n",
      "[Epoch 8/200] [Batch 547/637] [D loss: 0.128383] [G loss: 0.517025]\n",
      "[Epoch 8/200] [Batch 548/637] [D loss: 0.132770] [G loss: 0.538534]\n",
      "[Epoch 8/200] [Batch 549/637] [D loss: 0.120915] [G loss: 0.527299]\n",
      "[Epoch 8/200] [Batch 550/637] [D loss: 0.133519] [G loss: 0.601959]\n",
      "[Epoch 8/200] [Batch 551/637] [D loss: 0.141491] [G loss: 0.596511]\n",
      "[Epoch 8/200] [Batch 552/637] [D loss: 0.117977] [G loss: 0.611895]\n",
      "[Epoch 8/200] [Batch 553/637] [D loss: 0.143535] [G loss: 0.562494]\n",
      "[Epoch 8/200] [Batch 554/637] [D loss: 0.158812] [G loss: 0.592381]\n",
      "[Epoch 8/200] [Batch 555/637] [D loss: 0.132491] [G loss: 0.659712]\n",
      "[Epoch 8/200] [Batch 556/637] [D loss: 0.168358] [G loss: 0.541692]\n",
      "[Epoch 8/200] [Batch 557/637] [D loss: 0.144035] [G loss: 0.603833]\n",
      "[Epoch 8/200] [Batch 558/637] [D loss: 0.151142] [G loss: 0.541347]\n",
      "[Epoch 8/200] [Batch 559/637] [D loss: 0.150059] [G loss: 0.468563]\n",
      "[Epoch 8/200] [Batch 560/637] [D loss: 0.135610] [G loss: 0.522304]\n",
      "[Epoch 8/200] [Batch 561/637] [D loss: 0.145760] [G loss: 0.564865]\n",
      "[Epoch 8/200] [Batch 562/637] [D loss: 0.161278] [G loss: 0.568609]\n",
      "[Epoch 8/200] [Batch 563/637] [D loss: 0.147752] [G loss: 0.582900]\n",
      "[Epoch 8/200] [Batch 564/637] [D loss: 0.149620] [G loss: 0.550393]\n",
      "[Epoch 8/200] [Batch 565/637] [D loss: 0.132029] [G loss: 0.538373]\n",
      "[Epoch 8/200] [Batch 566/637] [D loss: 0.136493] [G loss: 0.564579]\n",
      "[Epoch 8/200] [Batch 567/637] [D loss: 0.141496] [G loss: 0.615770]\n",
      "[Epoch 8/200] [Batch 568/637] [D loss: 0.183714] [G loss: 0.514969]\n",
      "[Epoch 8/200] [Batch 569/637] [D loss: 0.229685] [G loss: 0.599928]\n",
      "[Epoch 8/200] [Batch 570/637] [D loss: 0.158324] [G loss: 0.582739]\n",
      "[Epoch 8/200] [Batch 571/637] [D loss: 0.150064] [G loss: 0.556310]\n",
      "[Epoch 8/200] [Batch 572/637] [D loss: 0.143359] [G loss: 0.524866]\n",
      "[Epoch 8/200] [Batch 573/637] [D loss: 0.169805] [G loss: 0.464016]\n",
      "[Epoch 8/200] [Batch 574/637] [D loss: 0.149304] [G loss: 0.519601]\n",
      "[Epoch 8/200] [Batch 575/637] [D loss: 0.149093] [G loss: 0.521088]\n",
      "[Epoch 8/200] [Batch 576/637] [D loss: 0.150546] [G loss: 0.535590]\n",
      "[Epoch 8/200] [Batch 577/637] [D loss: 0.142141] [G loss: 0.505391]\n",
      "[Epoch 8/200] [Batch 578/637] [D loss: 0.158396] [G loss: 0.475233]\n",
      "[Epoch 8/200] [Batch 579/637] [D loss: 0.163225] [G loss: 0.476479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 580/637] [D loss: 0.134926] [G loss: 0.502060]\n",
      "[Epoch 8/200] [Batch 581/637] [D loss: 0.137895] [G loss: 0.551975]\n",
      "[Epoch 8/200] [Batch 582/637] [D loss: 0.146078] [G loss: 0.527487]\n",
      "[Epoch 8/200] [Batch 583/637] [D loss: 0.156502] [G loss: 0.500643]\n",
      "[Epoch 8/200] [Batch 584/637] [D loss: 0.156815] [G loss: 0.459264]\n",
      "[Epoch 8/200] [Batch 585/637] [D loss: 0.146155] [G loss: 0.536784]\n",
      "[Epoch 8/200] [Batch 586/637] [D loss: 0.145529] [G loss: 0.498876]\n",
      "[Epoch 8/200] [Batch 587/637] [D loss: 0.132677] [G loss: 0.477742]\n",
      "[Epoch 8/200] [Batch 588/637] [D loss: 0.176990] [G loss: 0.499406]\n",
      "[Epoch 8/200] [Batch 589/637] [D loss: 0.155912] [G loss: 0.560945]\n",
      "[Epoch 8/200] [Batch 590/637] [D loss: 0.182190] [G loss: 0.502783]\n",
      "[Epoch 8/200] [Batch 591/637] [D loss: 0.186958] [G loss: 0.540346]\n",
      "[Epoch 8/200] [Batch 592/637] [D loss: 0.175363] [G loss: 0.548093]\n",
      "[Epoch 8/200] [Batch 593/637] [D loss: 0.163043] [G loss: 0.456865]\n",
      "[Epoch 8/200] [Batch 594/637] [D loss: 0.164821] [G loss: 0.516226]\n",
      "[Epoch 8/200] [Batch 595/637] [D loss: 0.132014] [G loss: 0.520466]\n",
      "[Epoch 8/200] [Batch 596/637] [D loss: 0.168652] [G loss: 0.519916]\n",
      "[Epoch 8/200] [Batch 597/637] [D loss: 0.197948] [G loss: 0.366700]\n",
      "[Epoch 8/200] [Batch 598/637] [D loss: 0.226420] [G loss: 0.754470]\n",
      "[Epoch 8/200] [Batch 599/637] [D loss: 0.164447] [G loss: 0.653398]\n",
      "[Epoch 8/200] [Batch 600/637] [D loss: 0.169056] [G loss: 0.587261]\n",
      "[Epoch 8/200] [Batch 601/637] [D loss: 0.157599] [G loss: 0.483020]\n",
      "[Epoch 8/200] [Batch 602/637] [D loss: 0.151948] [G loss: 0.449696]\n",
      "[Epoch 8/200] [Batch 603/637] [D loss: 0.139996] [G loss: 0.502915]\n",
      "[Epoch 8/200] [Batch 604/637] [D loss: 0.129584] [G loss: 0.547851]\n",
      "[Epoch 8/200] [Batch 605/637] [D loss: 0.116913] [G loss: 0.559707]\n",
      "[Epoch 8/200] [Batch 606/637] [D loss: 0.156240] [G loss: 0.528124]\n",
      "[Epoch 8/200] [Batch 607/637] [D loss: 0.139596] [G loss: 0.539019]\n",
      "[Epoch 8/200] [Batch 608/637] [D loss: 0.169566] [G loss: 0.563696]\n",
      "[Epoch 8/200] [Batch 609/637] [D loss: 0.127140] [G loss: 0.631141]\n",
      "[Epoch 8/200] [Batch 610/637] [D loss: 0.137499] [G loss: 0.555740]\n",
      "[Epoch 8/200] [Batch 611/637] [D loss: 0.134260] [G loss: 0.510476]\n",
      "[Epoch 8/200] [Batch 612/637] [D loss: 0.152716] [G loss: 0.496124]\n",
      "[Epoch 8/200] [Batch 613/637] [D loss: 0.169832] [G loss: 0.559678]\n",
      "[Epoch 8/200] [Batch 614/637] [D loss: 0.161260] [G loss: 0.631472]\n",
      "[Epoch 8/200] [Batch 615/637] [D loss: 0.151118] [G loss: 0.557430]\n",
      "[Epoch 8/200] [Batch 616/637] [D loss: 0.175196] [G loss: 0.531273]\n",
      "[Epoch 8/200] [Batch 617/637] [D loss: 0.143425] [G loss: 0.525927]\n",
      "[Epoch 8/200] [Batch 618/637] [D loss: 0.155668] [G loss: 0.551756]\n",
      "[Epoch 8/200] [Batch 619/637] [D loss: 0.138603] [G loss: 0.535218]\n",
      "[Epoch 8/200] [Batch 620/637] [D loss: 0.132680] [G loss: 0.556482]\n",
      "[Epoch 8/200] [Batch 621/637] [D loss: 0.177237] [G loss: 0.515409]\n",
      "[Epoch 8/200] [Batch 622/637] [D loss: 0.145172] [G loss: 0.668717]\n",
      "[Epoch 8/200] [Batch 623/637] [D loss: 0.136200] [G loss: 0.634991]\n",
      "[Epoch 8/200] [Batch 624/637] [D loss: 0.177091] [G loss: 0.466327]\n",
      "[Epoch 8/200] [Batch 625/637] [D loss: 0.139517] [G loss: 0.513136]\n",
      "[Epoch 8/200] [Batch 626/637] [D loss: 0.157800] [G loss: 0.529729]\n",
      "[Epoch 8/200] [Batch 627/637] [D loss: 0.138639] [G loss: 0.559690]\n",
      "[Epoch 8/200] [Batch 628/637] [D loss: 0.148739] [G loss: 0.579430]\n",
      "[Epoch 8/200] [Batch 629/637] [D loss: 0.168414] [G loss: 0.474626]\n",
      "[Epoch 8/200] [Batch 630/637] [D loss: 0.188013] [G loss: 0.618662]\n",
      "[Epoch 8/200] [Batch 631/637] [D loss: 0.150743] [G loss: 0.550679]\n",
      "[Epoch 8/200] [Batch 632/637] [D loss: 0.221611] [G loss: 0.488194]\n",
      "[Epoch 8/200] [Batch 633/637] [D loss: 0.247130] [G loss: 0.527582]\n",
      "[Epoch 8/200] [Batch 634/637] [D loss: 0.184269] [G loss: 0.632653]\n",
      "[Epoch 8/200] [Batch 635/637] [D loss: 0.172443] [G loss: 0.612059]\n",
      "[Epoch 8/200] [Batch 636/637] [D loss: 0.202491] [G loss: 0.478757]\n",
      "[Epoch 9/200] [Batch 0/637] [D loss: 0.165955] [G loss: 0.591365]\n",
      "[Epoch 9/200] [Batch 1/637] [D loss: 0.218650] [G loss: 0.445251]\n",
      "[Epoch 9/200] [Batch 2/637] [D loss: 0.168322] [G loss: 0.533256]\n",
      "[Epoch 9/200] [Batch 3/637] [D loss: 0.147579] [G loss: 0.523952]\n",
      "[Epoch 9/200] [Batch 4/637] [D loss: 0.133447] [G loss: 0.516680]\n",
      "[Epoch 9/200] [Batch 5/637] [D loss: 0.121597] [G loss: 0.553063]\n",
      "[Epoch 9/200] [Batch 6/637] [D loss: 0.103089] [G loss: 0.587220]\n",
      "[Epoch 9/200] [Batch 7/637] [D loss: 0.134849] [G loss: 0.560730]\n",
      "[Epoch 9/200] [Batch 8/637] [D loss: 0.100994] [G loss: 0.558997]\n",
      "[Epoch 9/200] [Batch 9/637] [D loss: 0.102745] [G loss: 0.586378]\n",
      "[Epoch 9/200] [Batch 10/637] [D loss: 0.140720] [G loss: 0.568777]\n",
      "[Epoch 9/200] [Batch 11/637] [D loss: 0.129063] [G loss: 0.576211]\n",
      "[Epoch 9/200] [Batch 12/637] [D loss: 0.164390] [G loss: 0.457895]\n",
      "[Epoch 9/200] [Batch 13/637] [D loss: 0.140903] [G loss: 0.516429]\n",
      "[Epoch 9/200] [Batch 14/637] [D loss: 0.162219] [G loss: 0.499653]\n",
      "[Epoch 9/200] [Batch 15/637] [D loss: 0.146268] [G loss: 0.494865]\n",
      "[Epoch 9/200] [Batch 16/637] [D loss: 0.162830] [G loss: 0.515069]\n",
      "[Epoch 9/200] [Batch 17/637] [D loss: 0.168163] [G loss: 0.485163]\n",
      "[Epoch 9/200] [Batch 18/637] [D loss: 0.141426] [G loss: 0.530710]\n",
      "[Epoch 9/200] [Batch 19/637] [D loss: 0.151545] [G loss: 0.575446]\n",
      "[Epoch 9/200] [Batch 20/637] [D loss: 0.172246] [G loss: 0.517974]\n",
      "[Epoch 9/200] [Batch 21/637] [D loss: 0.191307] [G loss: 0.506841]\n",
      "[Epoch 9/200] [Batch 22/637] [D loss: 0.146564] [G loss: 0.532474]\n",
      "[Epoch 9/200] [Batch 23/637] [D loss: 0.164296] [G loss: 0.455258]\n",
      "[Epoch 9/200] [Batch 24/637] [D loss: 0.167840] [G loss: 0.450187]\n",
      "[Epoch 9/200] [Batch 25/637] [D loss: 0.153874] [G loss: 0.443650]\n",
      "[Epoch 9/200] [Batch 26/637] [D loss: 0.146344] [G loss: 0.503060]\n",
      "[Epoch 9/200] [Batch 27/637] [D loss: 0.157064] [G loss: 0.452091]\n",
      "[Epoch 9/200] [Batch 28/637] [D loss: 0.157162] [G loss: 0.494141]\n",
      "[Epoch 9/200] [Batch 29/637] [D loss: 0.156802] [G loss: 0.476261]\n",
      "[Epoch 9/200] [Batch 30/637] [D loss: 0.146763] [G loss: 0.482959]\n",
      "[Epoch 9/200] [Batch 31/637] [D loss: 0.137728] [G loss: 0.541363]\n",
      "[Epoch 9/200] [Batch 32/637] [D loss: 0.160468] [G loss: 0.545123]\n",
      "[Epoch 9/200] [Batch 33/637] [D loss: 0.159701] [G loss: 0.469522]\n",
      "[Epoch 9/200] [Batch 34/637] [D loss: 0.149374] [G loss: 0.466518]\n",
      "[Epoch 9/200] [Batch 35/637] [D loss: 0.141230] [G loss: 0.565288]\n",
      "[Epoch 9/200] [Batch 36/637] [D loss: 0.164205] [G loss: 0.510760]\n",
      "[Epoch 9/200] [Batch 37/637] [D loss: 0.148543] [G loss: 0.509993]\n",
      "[Epoch 9/200] [Batch 38/637] [D loss: 0.181028] [G loss: 0.594209]\n",
      "[Epoch 9/200] [Batch 39/637] [D loss: 0.167557] [G loss: 0.556205]\n",
      "[Epoch 9/200] [Batch 40/637] [D loss: 0.150223] [G loss: 0.499475]\n",
      "[Epoch 9/200] [Batch 41/637] [D loss: 0.154316] [G loss: 0.527226]\n",
      "[Epoch 9/200] [Batch 42/637] [D loss: 0.148828] [G loss: 0.582181]\n",
      "[Epoch 9/200] [Batch 43/637] [D loss: 0.132982] [G loss: 0.538650]\n",
      "[Epoch 9/200] [Batch 44/637] [D loss: 0.151172] [G loss: 0.525983]\n",
      "[Epoch 9/200] [Batch 45/637] [D loss: 0.150032] [G loss: 0.488382]\n",
      "[Epoch 9/200] [Batch 46/637] [D loss: 0.149098] [G loss: 0.659543]\n",
      "[Epoch 9/200] [Batch 47/637] [D loss: 0.143767] [G loss: 0.576324]\n",
      "[Epoch 9/200] [Batch 48/637] [D loss: 0.147663] [G loss: 0.569712]\n",
      "[Epoch 9/200] [Batch 49/637] [D loss: 0.149794] [G loss: 0.551573]\n",
      "[Epoch 9/200] [Batch 50/637] [D loss: 0.165055] [G loss: 0.485017]\n",
      "[Epoch 9/200] [Batch 51/637] [D loss: 0.152992] [G loss: 0.518507]\n",
      "[Epoch 9/200] [Batch 52/637] [D loss: 0.201918] [G loss: 0.508686]\n",
      "[Epoch 9/200] [Batch 53/637] [D loss: 0.195278] [G loss: 0.567579]\n",
      "[Epoch 9/200] [Batch 54/637] [D loss: 0.169332] [G loss: 0.550610]\n",
      "[Epoch 9/200] [Batch 55/637] [D loss: 0.164144] [G loss: 0.569490]\n",
      "[Epoch 9/200] [Batch 56/637] [D loss: 0.155565] [G loss: 0.470631]\n",
      "[Epoch 9/200] [Batch 57/637] [D loss: 0.147139] [G loss: 0.486162]\n",
      "[Epoch 9/200] [Batch 58/637] [D loss: 0.138808] [G loss: 0.497379]\n",
      "[Epoch 9/200] [Batch 59/637] [D loss: 0.133826] [G loss: 0.494086]\n",
      "[Epoch 9/200] [Batch 60/637] [D loss: 0.128715] [G loss: 0.590519]\n",
      "[Epoch 9/200] [Batch 61/637] [D loss: 0.144427] [G loss: 0.567775]\n",
      "[Epoch 9/200] [Batch 62/637] [D loss: 0.127471] [G loss: 0.568907]\n",
      "[Epoch 9/200] [Batch 63/637] [D loss: 0.127511] [G loss: 0.572186]\n",
      "[Epoch 9/200] [Batch 64/637] [D loss: 0.159131] [G loss: 0.444852]\n",
      "[Epoch 9/200] [Batch 65/637] [D loss: 0.167831] [G loss: 0.545821]\n",
      "[Epoch 9/200] [Batch 66/637] [D loss: 0.155931] [G loss: 0.649059]\n",
      "[Epoch 9/200] [Batch 67/637] [D loss: 0.166340] [G loss: 0.494053]\n",
      "[Epoch 9/200] [Batch 68/637] [D loss: 0.177839] [G loss: 0.538840]\n",
      "[Epoch 9/200] [Batch 69/637] [D loss: 0.147528] [G loss: 0.594590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 70/637] [D loss: 0.173713] [G loss: 0.468550]\n",
      "[Epoch 9/200] [Batch 71/637] [D loss: 0.162373] [G loss: 0.520621]\n",
      "[Epoch 9/200] [Batch 72/637] [D loss: 0.204673] [G loss: 0.445234]\n",
      "[Epoch 9/200] [Batch 73/637] [D loss: 0.164493] [G loss: 0.637324]\n",
      "[Epoch 9/200] [Batch 74/637] [D loss: 0.187901] [G loss: 0.535132]\n",
      "[Epoch 9/200] [Batch 75/637] [D loss: 0.159128] [G loss: 0.551544]\n",
      "[Epoch 9/200] [Batch 76/637] [D loss: 0.195080] [G loss: 0.434045]\n",
      "[Epoch 9/200] [Batch 77/637] [D loss: 0.170000] [G loss: 0.538902]\n",
      "[Epoch 9/200] [Batch 78/637] [D loss: 0.143093] [G loss: 0.519109]\n",
      "[Epoch 9/200] [Batch 79/637] [D loss: 0.148671] [G loss: 0.510839]\n",
      "[Epoch 9/200] [Batch 80/637] [D loss: 0.157000] [G loss: 0.546569]\n",
      "[Epoch 9/200] [Batch 81/637] [D loss: 0.159156] [G loss: 0.594979]\n",
      "[Epoch 9/200] [Batch 82/637] [D loss: 0.149068] [G loss: 0.591598]\n",
      "[Epoch 9/200] [Batch 83/637] [D loss: 0.154075] [G loss: 0.585241]\n",
      "[Epoch 9/200] [Batch 84/637] [D loss: 0.129593] [G loss: 0.555501]\n",
      "[Epoch 9/200] [Batch 85/637] [D loss: 0.126794] [G loss: 0.596135]\n",
      "[Epoch 9/200] [Batch 86/637] [D loss: 0.115935] [G loss: 0.586351]\n",
      "[Epoch 9/200] [Batch 87/637] [D loss: 0.186514] [G loss: 0.445511]\n",
      "[Epoch 9/200] [Batch 88/637] [D loss: 0.282832] [G loss: 0.814214]\n",
      "[Epoch 9/200] [Batch 89/637] [D loss: 0.194562] [G loss: 0.758834]\n",
      "[Epoch 9/200] [Batch 90/637] [D loss: 0.207065] [G loss: 0.612733]\n",
      "[Epoch 9/200] [Batch 91/637] [D loss: 0.183055] [G loss: 0.465186]\n",
      "[Epoch 9/200] [Batch 92/637] [D loss: 0.148994] [G loss: 0.457262]\n",
      "[Epoch 9/200] [Batch 93/637] [D loss: 0.146724] [G loss: 0.476213]\n",
      "[Epoch 9/200] [Batch 94/637] [D loss: 0.126346] [G loss: 0.494132]\n",
      "[Epoch 9/200] [Batch 95/637] [D loss: 0.131915] [G loss: 0.514439]\n",
      "[Epoch 9/200] [Batch 96/637] [D loss: 0.122150] [G loss: 0.595997]\n",
      "[Epoch 9/200] [Batch 97/637] [D loss: 0.114165] [G loss: 0.581257]\n",
      "[Epoch 9/200] [Batch 98/637] [D loss: 0.145619] [G loss: 0.553021]\n",
      "[Epoch 9/200] [Batch 99/637] [D loss: 0.159220] [G loss: 0.467478]\n",
      "[Epoch 9/200] [Batch 100/637] [D loss: 0.216811] [G loss: 0.584140]\n",
      "[Epoch 9/200] [Batch 101/637] [D loss: 0.161079] [G loss: 0.538427]\n",
      "[Epoch 9/200] [Batch 102/637] [D loss: 0.155914] [G loss: 0.515838]\n",
      "[Epoch 9/200] [Batch 103/637] [D loss: 0.143352] [G loss: 0.494745]\n",
      "[Epoch 9/200] [Batch 104/637] [D loss: 0.179796] [G loss: 0.459800]\n",
      "[Epoch 9/200] [Batch 105/637] [D loss: 0.166588] [G loss: 0.476818]\n",
      "[Epoch 9/200] [Batch 106/637] [D loss: 0.141185] [G loss: 0.487696]\n",
      "[Epoch 9/200] [Batch 107/637] [D loss: 0.159325] [G loss: 0.451119]\n",
      "[Epoch 9/200] [Batch 108/637] [D loss: 0.133280] [G loss: 0.512828]\n",
      "[Epoch 9/200] [Batch 109/637] [D loss: 0.156954] [G loss: 0.540818]\n",
      "[Epoch 9/200] [Batch 110/637] [D loss: 0.144816] [G loss: 0.539397]\n",
      "[Epoch 9/200] [Batch 111/637] [D loss: 0.129529] [G loss: 0.555257]\n",
      "[Epoch 9/200] [Batch 112/637] [D loss: 0.144134] [G loss: 0.558764]\n",
      "[Epoch 9/200] [Batch 113/637] [D loss: 0.148719] [G loss: 0.543440]\n",
      "[Epoch 9/200] [Batch 114/637] [D loss: 0.187823] [G loss: 0.472464]\n",
      "[Epoch 9/200] [Batch 115/637] [D loss: 0.194404] [G loss: 0.677765]\n",
      "[Epoch 9/200] [Batch 116/637] [D loss: 0.132130] [G loss: 0.664475]\n",
      "[Epoch 9/200] [Batch 117/637] [D loss: 0.144825] [G loss: 0.512272]\n",
      "[Epoch 9/200] [Batch 118/637] [D loss: 0.125331] [G loss: 0.572659]\n",
      "[Epoch 9/200] [Batch 119/637] [D loss: 0.142885] [G loss: 0.530663]\n",
      "[Epoch 9/200] [Batch 120/637] [D loss: 0.149770] [G loss: 0.538361]\n",
      "[Epoch 9/200] [Batch 121/637] [D loss: 0.141609] [G loss: 0.485342]\n",
      "[Epoch 9/200] [Batch 122/637] [D loss: 0.152228] [G loss: 0.482740]\n",
      "[Epoch 9/200] [Batch 123/637] [D loss: 0.156940] [G loss: 0.516838]\n",
      "[Epoch 9/200] [Batch 124/637] [D loss: 0.150019] [G loss: 0.509256]\n",
      "[Epoch 9/200] [Batch 125/637] [D loss: 0.216913] [G loss: 0.526077]\n",
      "[Epoch 9/200] [Batch 126/637] [D loss: 0.149609] [G loss: 0.625827]\n",
      "[Epoch 9/200] [Batch 127/637] [D loss: 0.165076] [G loss: 0.492703]\n",
      "[Epoch 9/200] [Batch 128/637] [D loss: 0.162135] [G loss: 0.499696]\n",
      "[Epoch 9/200] [Batch 129/637] [D loss: 0.162810] [G loss: 0.450937]\n",
      "[Epoch 9/200] [Batch 130/637] [D loss: 0.157809] [G loss: 0.477659]\n",
      "[Epoch 9/200] [Batch 131/637] [D loss: 0.139984] [G loss: 0.481124]\n",
      "[Epoch 9/200] [Batch 132/637] [D loss: 0.161357] [G loss: 0.483304]\n",
      "[Epoch 9/200] [Batch 133/637] [D loss: 0.166272] [G loss: 0.481923]\n",
      "[Epoch 9/200] [Batch 134/637] [D loss: 0.164953] [G loss: 0.546871]\n",
      "[Epoch 9/200] [Batch 135/637] [D loss: 0.169719] [G loss: 0.531411]\n",
      "[Epoch 9/200] [Batch 136/637] [D loss: 0.132959] [G loss: 0.548445]\n",
      "[Epoch 9/200] [Batch 137/637] [D loss: 0.156165] [G loss: 0.497705]\n",
      "[Epoch 9/200] [Batch 138/637] [D loss: 0.141883] [G loss: 0.534164]\n",
      "[Epoch 9/200] [Batch 139/637] [D loss: 0.153268] [G loss: 0.514759]\n",
      "[Epoch 9/200] [Batch 140/637] [D loss: 0.151288] [G loss: 0.460523]\n",
      "[Epoch 9/200] [Batch 141/637] [D loss: 0.142548] [G loss: 0.562876]\n",
      "[Epoch 9/200] [Batch 142/637] [D loss: 0.168642] [G loss: 0.634763]\n",
      "[Epoch 9/200] [Batch 143/637] [D loss: 0.157080] [G loss: 0.550361]\n",
      "[Epoch 9/200] [Batch 144/637] [D loss: 0.144002] [G loss: 0.503666]\n",
      "[Epoch 9/200] [Batch 145/637] [D loss: 0.160964] [G loss: 0.579518]\n",
      "[Epoch 9/200] [Batch 146/637] [D loss: 0.186129] [G loss: 0.485498]\n",
      "[Epoch 9/200] [Batch 147/637] [D loss: 0.209950] [G loss: 0.527526]\n",
      "[Epoch 9/200] [Batch 148/637] [D loss: 0.143029] [G loss: 0.584838]\n",
      "[Epoch 9/200] [Batch 149/637] [D loss: 0.130576] [G loss: 0.633934]\n",
      "[Epoch 9/200] [Batch 150/637] [D loss: 0.164719] [G loss: 0.471033]\n",
      "[Epoch 9/200] [Batch 151/637] [D loss: 0.151818] [G loss: 0.571101]\n",
      "[Epoch 9/200] [Batch 152/637] [D loss: 0.180940] [G loss: 0.541218]\n",
      "[Epoch 9/200] [Batch 153/637] [D loss: 0.137373] [G loss: 0.553963]\n",
      "[Epoch 9/200] [Batch 154/637] [D loss: 0.148421] [G loss: 0.561375]\n",
      "[Epoch 9/200] [Batch 155/637] [D loss: 0.147347] [G loss: 0.484532]\n",
      "[Epoch 9/200] [Batch 156/637] [D loss: 0.154438] [G loss: 0.511952]\n",
      "[Epoch 9/200] [Batch 157/637] [D loss: 0.157212] [G loss: 0.508430]\n",
      "[Epoch 9/200] [Batch 158/637] [D loss: 0.147144] [G loss: 0.504811]\n",
      "[Epoch 9/200] [Batch 159/637] [D loss: 0.177725] [G loss: 0.463050]\n",
      "[Epoch 9/200] [Batch 160/637] [D loss: 0.171129] [G loss: 0.500098]\n",
      "[Epoch 9/200] [Batch 161/637] [D loss: 0.152302] [G loss: 0.587835]\n",
      "[Epoch 9/200] [Batch 162/637] [D loss: 0.139934] [G loss: 0.606592]\n",
      "[Epoch 9/200] [Batch 163/637] [D loss: 0.162316] [G loss: 0.486292]\n",
      "[Epoch 9/200] [Batch 164/637] [D loss: 0.174170] [G loss: 0.472331]\n",
      "[Epoch 9/200] [Batch 165/637] [D loss: 0.146654] [G loss: 0.581365]\n",
      "[Epoch 9/200] [Batch 166/637] [D loss: 0.207334] [G loss: 0.629335]\n",
      "[Epoch 9/200] [Batch 167/637] [D loss: 0.154048] [G loss: 0.564960]\n",
      "[Epoch 9/200] [Batch 168/637] [D loss: 0.157680] [G loss: 0.542650]\n",
      "[Epoch 9/200] [Batch 169/637] [D loss: 0.157206] [G loss: 0.507989]\n",
      "[Epoch 9/200] [Batch 170/637] [D loss: 0.153714] [G loss: 0.464314]\n",
      "[Epoch 9/200] [Batch 171/637] [D loss: 0.145999] [G loss: 0.464213]\n",
      "[Epoch 9/200] [Batch 172/637] [D loss: 0.141043] [G loss: 0.589255]\n",
      "[Epoch 9/200] [Batch 173/637] [D loss: 0.141715] [G loss: 0.618159]\n",
      "[Epoch 9/200] [Batch 174/637] [D loss: 0.146933] [G loss: 0.507285]\n",
      "[Epoch 9/200] [Batch 175/637] [D loss: 0.158844] [G loss: 0.513757]\n",
      "[Epoch 9/200] [Batch 176/637] [D loss: 0.132552] [G loss: 0.549249]\n",
      "[Epoch 9/200] [Batch 177/637] [D loss: 0.168882] [G loss: 0.459128]\n",
      "[Epoch 9/200] [Batch 178/637] [D loss: 0.197172] [G loss: 0.541936]\n",
      "[Epoch 9/200] [Batch 179/637] [D loss: 0.155122] [G loss: 0.549822]\n",
      "[Epoch 9/200] [Batch 180/637] [D loss: 0.181755] [G loss: 0.485791]\n",
      "[Epoch 9/200] [Batch 181/637] [D loss: 0.157285] [G loss: 0.590326]\n",
      "[Epoch 9/200] [Batch 182/637] [D loss: 0.146290] [G loss: 0.542295]\n",
      "[Epoch 9/200] [Batch 183/637] [D loss: 0.160188] [G loss: 0.457084]\n",
      "[Epoch 9/200] [Batch 184/637] [D loss: 0.167028] [G loss: 0.516283]\n",
      "[Epoch 9/200] [Batch 185/637] [D loss: 0.152647] [G loss: 0.596735]\n",
      "[Epoch 9/200] [Batch 186/637] [D loss: 0.155054] [G loss: 0.541561]\n",
      "[Epoch 9/200] [Batch 187/637] [D loss: 0.163492] [G loss: 0.523257]\n",
      "[Epoch 9/200] [Batch 188/637] [D loss: 0.146445] [G loss: 0.561227]\n",
      "[Epoch 9/200] [Batch 189/637] [D loss: 0.152839] [G loss: 0.491468]\n",
      "[Epoch 9/200] [Batch 190/637] [D loss: 0.138160] [G loss: 0.547222]\n",
      "[Epoch 9/200] [Batch 191/637] [D loss: 0.147236] [G loss: 0.531855]\n",
      "[Epoch 9/200] [Batch 192/637] [D loss: 0.149439] [G loss: 0.522169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 193/637] [D loss: 0.158980] [G loss: 0.552002]\n",
      "[Epoch 9/200] [Batch 194/637] [D loss: 0.148493] [G loss: 0.488918]\n",
      "[Epoch 9/200] [Batch 195/637] [D loss: 0.135872] [G loss: 0.526976]\n",
      "[Epoch 9/200] [Batch 196/637] [D loss: 0.144158] [G loss: 0.514595]\n",
      "[Epoch 9/200] [Batch 197/637] [D loss: 0.155565] [G loss: 0.563365]\n",
      "[Epoch 9/200] [Batch 198/637] [D loss: 0.145015] [G loss: 0.566518]\n",
      "[Epoch 9/200] [Batch 199/637] [D loss: 0.154180] [G loss: 0.490878]\n",
      "[Epoch 9/200] [Batch 200/637] [D loss: 0.140975] [G loss: 0.504100]\n",
      "[Epoch 9/200] [Batch 201/637] [D loss: 0.143132] [G loss: 0.595111]\n",
      "[Epoch 9/200] [Batch 202/637] [D loss: 0.131511] [G loss: 0.538543]\n",
      "[Epoch 9/200] [Batch 203/637] [D loss: 0.134004] [G loss: 0.552974]\n",
      "[Epoch 9/200] [Batch 204/637] [D loss: 0.131638] [G loss: 0.562627]\n",
      "[Epoch 9/200] [Batch 205/637] [D loss: 0.134285] [G loss: 0.541723]\n",
      "[Epoch 9/200] [Batch 206/637] [D loss: 0.149350] [G loss: 0.538186]\n",
      "[Epoch 9/200] [Batch 207/637] [D loss: 0.142249] [G loss: 0.630580]\n",
      "[Epoch 9/200] [Batch 208/637] [D loss: 0.150252] [G loss: 0.554396]\n",
      "[Epoch 9/200] [Batch 209/637] [D loss: 0.161718] [G loss: 0.533749]\n",
      "[Epoch 9/200] [Batch 210/637] [D loss: 0.185452] [G loss: 0.487500]\n",
      "[Epoch 9/200] [Batch 211/637] [D loss: 0.138918] [G loss: 0.489344]\n",
      "[Epoch 9/200] [Batch 212/637] [D loss: 0.154535] [G loss: 0.510909]\n",
      "[Epoch 9/200] [Batch 213/637] [D loss: 0.140844] [G loss: 0.523458]\n",
      "[Epoch 9/200] [Batch 214/637] [D loss: 0.137628] [G loss: 0.500176]\n",
      "[Epoch 9/200] [Batch 215/637] [D loss: 0.142329] [G loss: 0.521650]\n",
      "[Epoch 9/200] [Batch 216/637] [D loss: 0.150641] [G loss: 0.506330]\n",
      "[Epoch 9/200] [Batch 217/637] [D loss: 0.155953] [G loss: 0.524914]\n",
      "[Epoch 9/200] [Batch 218/637] [D loss: 0.161297] [G loss: 0.510165]\n",
      "[Epoch 9/200] [Batch 219/637] [D loss: 0.194097] [G loss: 0.578623]\n",
      "[Epoch 9/200] [Batch 220/637] [D loss: 0.196538] [G loss: 0.475041]\n",
      "[Epoch 9/200] [Batch 221/637] [D loss: 0.192906] [G loss: 0.798338]\n",
      "[Epoch 9/200] [Batch 222/637] [D loss: 0.191514] [G loss: 0.513425]\n",
      "[Epoch 9/200] [Batch 223/637] [D loss: 0.204177] [G loss: 0.463805]\n",
      "[Epoch 9/200] [Batch 224/637] [D loss: 0.184254] [G loss: 0.426383]\n",
      "[Epoch 9/200] [Batch 225/637] [D loss: 0.175708] [G loss: 0.520289]\n",
      "[Epoch 9/200] [Batch 226/637] [D loss: 0.166490] [G loss: 0.562501]\n",
      "[Epoch 9/200] [Batch 227/637] [D loss: 0.142224] [G loss: 0.507961]\n",
      "[Epoch 9/200] [Batch 228/637] [D loss: 0.176592] [G loss: 0.481666]\n",
      "[Epoch 9/200] [Batch 229/637] [D loss: 0.150489] [G loss: 0.486171]\n",
      "[Epoch 9/200] [Batch 230/637] [D loss: 0.147639] [G loss: 0.512871]\n",
      "[Epoch 9/200] [Batch 231/637] [D loss: 0.183015] [G loss: 0.432878]\n",
      "[Epoch 9/200] [Batch 232/637] [D loss: 0.166905] [G loss: 0.621412]\n",
      "[Epoch 9/200] [Batch 233/637] [D loss: 0.142266] [G loss: 0.601613]\n",
      "[Epoch 9/200] [Batch 234/637] [D loss: 0.152975] [G loss: 0.533003]\n",
      "[Epoch 9/200] [Batch 235/637] [D loss: 0.149361] [G loss: 0.586640]\n",
      "[Epoch 9/200] [Batch 236/637] [D loss: 0.109947] [G loss: 0.607463]\n",
      "[Epoch 9/200] [Batch 237/637] [D loss: 0.154474] [G loss: 0.515582]\n",
      "[Epoch 9/200] [Batch 238/637] [D loss: 0.147491] [G loss: 0.469186]\n",
      "[Epoch 9/200] [Batch 239/637] [D loss: 0.133807] [G loss: 0.568174]\n",
      "[Epoch 9/200] [Batch 240/637] [D loss: 0.121464] [G loss: 0.524310]\n",
      "[Epoch 9/200] [Batch 241/637] [D loss: 0.128093] [G loss: 0.552147]\n",
      "[Epoch 9/200] [Batch 242/637] [D loss: 0.118004] [G loss: 0.566592]\n",
      "[Epoch 9/200] [Batch 243/637] [D loss: 0.142986] [G loss: 0.552554]\n",
      "[Epoch 9/200] [Batch 244/637] [D loss: 0.139739] [G loss: 0.456931]\n",
      "[Epoch 9/200] [Batch 245/637] [D loss: 0.172209] [G loss: 0.562197]\n",
      "[Epoch 9/200] [Batch 246/637] [D loss: 0.134994] [G loss: 0.618523]\n",
      "[Epoch 9/200] [Batch 247/637] [D loss: 0.191823] [G loss: 0.473356]\n",
      "[Epoch 9/200] [Batch 248/637] [D loss: 0.214310] [G loss: 0.540836]\n",
      "[Epoch 9/200] [Batch 249/637] [D loss: 0.178483] [G loss: 0.677322]\n",
      "[Epoch 9/200] [Batch 250/637] [D loss: 0.185705] [G loss: 0.548768]\n",
      "[Epoch 9/200] [Batch 251/637] [D loss: 0.145568] [G loss: 0.570651]\n",
      "[Epoch 9/200] [Batch 252/637] [D loss: 0.129650] [G loss: 0.487741]\n",
      "[Epoch 9/200] [Batch 253/637] [D loss: 0.153092] [G loss: 0.503187]\n",
      "[Epoch 9/200] [Batch 254/637] [D loss: 0.183123] [G loss: 0.460813]\n",
      "[Epoch 9/200] [Batch 255/637] [D loss: 0.176095] [G loss: 0.545567]\n",
      "[Epoch 9/200] [Batch 256/637] [D loss: 0.141094] [G loss: 0.574201]\n",
      "[Epoch 9/200] [Batch 257/637] [D loss: 0.136048] [G loss: 0.496263]\n",
      "[Epoch 9/200] [Batch 258/637] [D loss: 0.170544] [G loss: 0.485244]\n",
      "[Epoch 9/200] [Batch 259/637] [D loss: 0.165511] [G loss: 0.433560]\n",
      "[Epoch 9/200] [Batch 260/637] [D loss: 0.150088] [G loss: 0.510606]\n",
      "[Epoch 9/200] [Batch 261/637] [D loss: 0.141072] [G loss: 0.522582]\n",
      "[Epoch 9/200] [Batch 262/637] [D loss: 0.188005] [G loss: 0.412699]\n",
      "[Epoch 9/200] [Batch 263/637] [D loss: 0.154796] [G loss: 0.584960]\n",
      "[Epoch 9/200] [Batch 264/637] [D loss: 0.143819] [G loss: 0.597386]\n",
      "[Epoch 9/200] [Batch 265/637] [D loss: 0.162843] [G loss: 0.514799]\n",
      "[Epoch 9/200] [Batch 266/637] [D loss: 0.159477] [G loss: 0.554503]\n",
      "[Epoch 9/200] [Batch 267/637] [D loss: 0.182710] [G loss: 0.512973]\n",
      "[Epoch 9/200] [Batch 268/637] [D loss: 0.152919] [G loss: 0.552068]\n",
      "[Epoch 9/200] [Batch 269/637] [D loss: 0.142271] [G loss: 0.563083]\n",
      "[Epoch 9/200] [Batch 270/637] [D loss: 0.151613] [G loss: 0.516448]\n",
      "[Epoch 9/200] [Batch 271/637] [D loss: 0.163906] [G loss: 0.444552]\n",
      "[Epoch 9/200] [Batch 272/637] [D loss: 0.159870] [G loss: 0.547531]\n",
      "[Epoch 9/200] [Batch 273/637] [D loss: 0.159567] [G loss: 0.535734]\n",
      "[Epoch 9/200] [Batch 274/637] [D loss: 0.167179] [G loss: 0.489241]\n",
      "[Epoch 9/200] [Batch 275/637] [D loss: 0.220756] [G loss: 0.553477]\n",
      "[Epoch 9/200] [Batch 276/637] [D loss: 0.196300] [G loss: 0.558810]\n",
      "[Epoch 9/200] [Batch 277/637] [D loss: 0.174478] [G loss: 0.599138]\n",
      "[Epoch 9/200] [Batch 278/637] [D loss: 0.190786] [G loss: 0.445828]\n",
      "[Epoch 9/200] [Batch 279/637] [D loss: 0.174740] [G loss: 0.488879]\n",
      "[Epoch 9/200] [Batch 280/637] [D loss: 0.174195] [G loss: 0.431461]\n",
      "[Epoch 9/200] [Batch 281/637] [D loss: 0.163591] [G loss: 0.464709]\n",
      "[Epoch 9/200] [Batch 282/637] [D loss: 0.162375] [G loss: 0.474581]\n",
      "[Epoch 9/200] [Batch 283/637] [D loss: 0.146672] [G loss: 0.470409]\n",
      "[Epoch 9/200] [Batch 284/637] [D loss: 0.147115] [G loss: 0.494217]\n",
      "[Epoch 9/200] [Batch 285/637] [D loss: 0.168784] [G loss: 0.436600]\n",
      "[Epoch 9/200] [Batch 286/637] [D loss: 0.164828] [G loss: 0.553989]\n",
      "[Epoch 9/200] [Batch 287/637] [D loss: 0.150580] [G loss: 0.604517]\n",
      "[Epoch 9/200] [Batch 288/637] [D loss: 0.162158] [G loss: 0.508188]\n",
      "[Epoch 9/200] [Batch 289/637] [D loss: 0.140881] [G loss: 0.573331]\n",
      "[Epoch 9/200] [Batch 290/637] [D loss: 0.147132] [G loss: 0.499923]\n",
      "[Epoch 9/200] [Batch 291/637] [D loss: 0.159683] [G loss: 0.494829]\n",
      "[Epoch 9/200] [Batch 292/637] [D loss: 0.175809] [G loss: 0.496504]\n",
      "[Epoch 9/200] [Batch 293/637] [D loss: 0.173456] [G loss: 0.513101]\n",
      "[Epoch 9/200] [Batch 294/637] [D loss: 0.146636] [G loss: 0.520002]\n",
      "[Epoch 9/200] [Batch 295/637] [D loss: 0.151828] [G loss: 0.586731]\n",
      "[Epoch 9/200] [Batch 296/637] [D loss: 0.159080] [G loss: 0.558236]\n",
      "[Epoch 9/200] [Batch 297/637] [D loss: 0.141340] [G loss: 0.604914]\n",
      "[Epoch 9/200] [Batch 298/637] [D loss: 0.169208] [G loss: 0.539786]\n",
      "[Epoch 9/200] [Batch 299/637] [D loss: 0.160804] [G loss: 0.508816]\n",
      "[Epoch 9/200] [Batch 300/637] [D loss: 0.141168] [G loss: 0.597745]\n",
      "[Epoch 9/200] [Batch 301/637] [D loss: 0.153398] [G loss: 0.585338]\n",
      "[Epoch 9/200] [Batch 302/637] [D loss: 0.131138] [G loss: 0.513298]\n",
      "[Epoch 9/200] [Batch 303/637] [D loss: 0.162641] [G loss: 0.559862]\n",
      "[Epoch 9/200] [Batch 304/637] [D loss: 0.152683] [G loss: 0.576247]\n",
      "[Epoch 9/200] [Batch 305/637] [D loss: 0.162990] [G loss: 0.590563]\n",
      "[Epoch 9/200] [Batch 306/637] [D loss: 0.139737] [G loss: 0.539914]\n",
      "[Epoch 9/200] [Batch 307/637] [D loss: 0.152942] [G loss: 0.515378]\n",
      "[Epoch 9/200] [Batch 308/637] [D loss: 0.140031] [G loss: 0.536941]\n",
      "[Epoch 9/200] [Batch 309/637] [D loss: 0.207602] [G loss: 0.456599]\n",
      "[Epoch 9/200] [Batch 310/637] [D loss: 0.209257] [G loss: 0.567136]\n",
      "[Epoch 9/200] [Batch 311/637] [D loss: 0.154721] [G loss: 0.631117]\n",
      "[Epoch 9/200] [Batch 312/637] [D loss: 0.167192] [G loss: 0.568030]\n",
      "[Epoch 9/200] [Batch 313/637] [D loss: 0.156502] [G loss: 0.485106]\n",
      "[Epoch 9/200] [Batch 314/637] [D loss: 0.174150] [G loss: 0.466071]\n",
      "[Epoch 9/200] [Batch 315/637] [D loss: 0.130843] [G loss: 0.492702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 316/637] [D loss: 0.140564] [G loss: 0.521276]\n",
      "[Epoch 9/200] [Batch 317/637] [D loss: 0.134312] [G loss: 0.501614]\n",
      "[Epoch 9/200] [Batch 318/637] [D loss: 0.126148] [G loss: 0.563480]\n",
      "[Epoch 9/200] [Batch 319/637] [D loss: 0.153271] [G loss: 0.526446]\n",
      "[Epoch 9/200] [Batch 320/637] [D loss: 0.127292] [G loss: 0.578345]\n",
      "[Epoch 9/200] [Batch 321/637] [D loss: 0.201848] [G loss: 0.443118]\n",
      "[Epoch 9/200] [Batch 322/637] [D loss: 0.282914] [G loss: 0.607582]\n",
      "[Epoch 9/200] [Batch 323/637] [D loss: 0.200733] [G loss: 0.642415]\n",
      "[Epoch 9/200] [Batch 324/637] [D loss: 0.196924] [G loss: 0.543673]\n",
      "[Epoch 9/200] [Batch 325/637] [D loss: 0.173923] [G loss: 0.472058]\n",
      "[Epoch 9/200] [Batch 326/637] [D loss: 0.182738] [G loss: 0.408158]\n",
      "[Epoch 9/200] [Batch 327/637] [D loss: 0.161645] [G loss: 0.427565]\n",
      "[Epoch 9/200] [Batch 328/637] [D loss: 0.192544] [G loss: 0.405699]\n",
      "[Epoch 9/200] [Batch 329/637] [D loss: 0.170162] [G loss: 0.478641]\n",
      "[Epoch 9/200] [Batch 330/637] [D loss: 0.149081] [G loss: 0.506167]\n",
      "[Epoch 9/200] [Batch 331/637] [D loss: 0.167491] [G loss: 0.458061]\n",
      "[Epoch 9/200] [Batch 332/637] [D loss: 0.162207] [G loss: 0.503643]\n",
      "[Epoch 9/200] [Batch 333/637] [D loss: 0.151834] [G loss: 0.486876]\n",
      "[Epoch 9/200] [Batch 334/637] [D loss: 0.154716] [G loss: 0.528493]\n",
      "[Epoch 9/200] [Batch 335/637] [D loss: 0.167565] [G loss: 0.540577]\n",
      "[Epoch 9/200] [Batch 336/637] [D loss: 0.142340] [G loss: 0.490687]\n",
      "[Epoch 9/200] [Batch 337/637] [D loss: 0.187510] [G loss: 0.450315]\n",
      "[Epoch 9/200] [Batch 338/637] [D loss: 0.195952] [G loss: 0.591224]\n",
      "[Epoch 9/200] [Batch 339/637] [D loss: 0.156504] [G loss: 0.649822]\n",
      "[Epoch 9/200] [Batch 340/637] [D loss: 0.170929] [G loss: 0.512777]\n",
      "[Epoch 9/200] [Batch 341/637] [D loss: 0.137756] [G loss: 0.550574]\n",
      "[Epoch 9/200] [Batch 342/637] [D loss: 0.153316] [G loss: 0.506724]\n",
      "[Epoch 9/200] [Batch 343/637] [D loss: 0.138757] [G loss: 0.487532]\n",
      "[Epoch 9/200] [Batch 344/637] [D loss: 0.114888] [G loss: 0.516606]\n",
      "[Epoch 9/200] [Batch 345/637] [D loss: 0.170038] [G loss: 0.521579]\n",
      "[Epoch 9/200] [Batch 346/637] [D loss: 0.173918] [G loss: 0.605973]\n",
      "[Epoch 9/200] [Batch 347/637] [D loss: 0.157199] [G loss: 0.577949]\n",
      "[Epoch 9/200] [Batch 348/637] [D loss: 0.148828] [G loss: 0.523882]\n",
      "[Epoch 9/200] [Batch 349/637] [D loss: 0.161257] [G loss: 0.513899]\n",
      "[Epoch 9/200] [Batch 350/637] [D loss: 0.134347] [G loss: 0.495820]\n",
      "[Epoch 9/200] [Batch 351/637] [D loss: 0.158908] [G loss: 0.489637]\n",
      "[Epoch 9/200] [Batch 352/637] [D loss: 0.162938] [G loss: 0.486445]\n",
      "[Epoch 9/200] [Batch 353/637] [D loss: 0.166533] [G loss: 0.458485]\n",
      "[Epoch 9/200] [Batch 354/637] [D loss: 0.151232] [G loss: 0.531486]\n",
      "[Epoch 9/200] [Batch 355/637] [D loss: 0.157189] [G loss: 0.486279]\n",
      "[Epoch 9/200] [Batch 356/637] [D loss: 0.157200] [G loss: 0.476338]\n",
      "[Epoch 9/200] [Batch 357/637] [D loss: 0.152991] [G loss: 0.563808]\n",
      "[Epoch 9/200] [Batch 358/637] [D loss: 0.147537] [G loss: 0.588245]\n",
      "[Epoch 9/200] [Batch 359/637] [D loss: 0.157837] [G loss: 0.531412]\n",
      "[Epoch 9/200] [Batch 360/637] [D loss: 0.178316] [G loss: 0.455747]\n",
      "[Epoch 9/200] [Batch 361/637] [D loss: 0.139711] [G loss: 0.579280]\n",
      "[Epoch 9/200] [Batch 362/637] [D loss: 0.158245] [G loss: 0.536286]\n",
      "[Epoch 9/200] [Batch 363/637] [D loss: 0.156879] [G loss: 0.542075]\n",
      "[Epoch 9/200] [Batch 364/637] [D loss: 0.186229] [G loss: 0.549919]\n",
      "[Epoch 9/200] [Batch 365/637] [D loss: 0.176355] [G loss: 0.611582]\n",
      "[Epoch 9/200] [Batch 366/637] [D loss: 0.163586] [G loss: 0.596460]\n",
      "[Epoch 9/200] [Batch 367/637] [D loss: 0.138179] [G loss: 0.564116]\n",
      "[Epoch 9/200] [Batch 368/637] [D loss: 0.159072] [G loss: 0.508179]\n",
      "[Epoch 9/200] [Batch 369/637] [D loss: 0.157486] [G loss: 0.485970]\n",
      "[Epoch 9/200] [Batch 370/637] [D loss: 0.159204] [G loss: 0.493147]\n",
      "[Epoch 9/200] [Batch 371/637] [D loss: 0.160315] [G loss: 0.427105]\n",
      "[Epoch 9/200] [Batch 372/637] [D loss: 0.172203] [G loss: 0.524121]\n",
      "[Epoch 9/200] [Batch 373/637] [D loss: 0.153254] [G loss: 0.626140]\n",
      "[Epoch 9/200] [Batch 374/637] [D loss: 0.158480] [G loss: 0.568094]\n",
      "[Epoch 9/200] [Batch 375/637] [D loss: 0.124887] [G loss: 0.488581]\n",
      "[Epoch 9/200] [Batch 376/637] [D loss: 0.163209] [G loss: 0.442692]\n",
      "[Epoch 9/200] [Batch 377/637] [D loss: 0.147746] [G loss: 0.516972]\n",
      "[Epoch 9/200] [Batch 378/637] [D loss: 0.154257] [G loss: 0.576437]\n",
      "[Epoch 9/200] [Batch 379/637] [D loss: 0.127609] [G loss: 0.588197]\n",
      "[Epoch 9/200] [Batch 380/637] [D loss: 0.155995] [G loss: 0.548616]\n",
      "[Epoch 9/200] [Batch 381/637] [D loss: 0.148959] [G loss: 0.601642]\n",
      "[Epoch 9/200] [Batch 382/637] [D loss: 0.154085] [G loss: 0.601714]\n",
      "[Epoch 9/200] [Batch 383/637] [D loss: 0.164822] [G loss: 0.411278]\n",
      "[Epoch 9/200] [Batch 384/637] [D loss: 0.152574] [G loss: 0.508817]\n",
      "[Epoch 9/200] [Batch 385/637] [D loss: 0.148075] [G loss: 0.523525]\n",
      "[Epoch 9/200] [Batch 386/637] [D loss: 0.151246] [G loss: 0.573659]\n",
      "[Epoch 9/200] [Batch 387/637] [D loss: 0.161012] [G loss: 0.494886]\n",
      "[Epoch 9/200] [Batch 388/637] [D loss: 0.173409] [G loss: 0.548769]\n",
      "[Epoch 9/200] [Batch 389/637] [D loss: 0.148531] [G loss: 0.524898]\n",
      "[Epoch 9/200] [Batch 390/637] [D loss: 0.166947] [G loss: 0.550819]\n",
      "[Epoch 9/200] [Batch 391/637] [D loss: 0.129440] [G loss: 0.541117]\n",
      "[Epoch 9/200] [Batch 392/637] [D loss: 0.150741] [G loss: 0.529610]\n",
      "[Epoch 9/200] [Batch 393/637] [D loss: 0.139818] [G loss: 0.552583]\n",
      "[Epoch 9/200] [Batch 394/637] [D loss: 0.148997] [G loss: 0.474430]\n",
      "[Epoch 9/200] [Batch 395/637] [D loss: 0.144023] [G loss: 0.499360]\n",
      "[Epoch 9/200] [Batch 396/637] [D loss: 0.155317] [G loss: 0.627329]\n",
      "[Epoch 9/200] [Batch 397/637] [D loss: 0.154196] [G loss: 0.589806]\n",
      "[Epoch 9/200] [Batch 398/637] [D loss: 0.138040] [G loss: 0.523465]\n",
      "[Epoch 9/200] [Batch 399/637] [D loss: 0.153519] [G loss: 0.553239]\n",
      "[Epoch 9/200] [Batch 400/637] [D loss: 0.150296] [G loss: 0.580156]\n",
      "[Epoch 9/200] [Batch 401/637] [D loss: 0.140685] [G loss: 0.523764]\n",
      "[Epoch 9/200] [Batch 402/637] [D loss: 0.123110] [G loss: 0.541653]\n",
      "[Epoch 9/200] [Batch 403/637] [D loss: 0.173042] [G loss: 0.435916]\n",
      "[Epoch 9/200] [Batch 404/637] [D loss: 0.151849] [G loss: 0.712000]\n",
      "[Epoch 9/200] [Batch 405/637] [D loss: 0.170362] [G loss: 0.545802]\n",
      "[Epoch 9/200] [Batch 406/637] [D loss: 0.153702] [G loss: 0.594011]\n",
      "[Epoch 9/200] [Batch 407/637] [D loss: 0.184894] [G loss: 0.533573]\n",
      "[Epoch 9/200] [Batch 408/637] [D loss: 0.175153] [G loss: 0.541913]\n",
      "[Epoch 9/200] [Batch 409/637] [D loss: 0.229128] [G loss: 0.501207]\n",
      "[Epoch 9/200] [Batch 410/637] [D loss: 0.173529] [G loss: 0.556455]\n",
      "[Epoch 9/200] [Batch 411/637] [D loss: 0.139770] [G loss: 0.524925]\n",
      "[Epoch 9/200] [Batch 412/637] [D loss: 0.187446] [G loss: 0.466784]\n",
      "[Epoch 9/200] [Batch 413/637] [D loss: 0.165106] [G loss: 0.530236]\n",
      "[Epoch 9/200] [Batch 414/637] [D loss: 0.154932] [G loss: 0.588905]\n",
      "[Epoch 9/200] [Batch 415/637] [D loss: 0.149758] [G loss: 0.532645]\n",
      "[Epoch 9/200] [Batch 416/637] [D loss: 0.129484] [G loss: 0.544844]\n",
      "[Epoch 9/200] [Batch 417/637] [D loss: 0.193193] [G loss: 0.445156]\n",
      "[Epoch 9/200] [Batch 418/637] [D loss: 0.182884] [G loss: 0.626638]\n",
      "[Epoch 9/200] [Batch 419/637] [D loss: 0.132260] [G loss: 0.606106]\n",
      "[Epoch 9/200] [Batch 420/637] [D loss: 0.171306] [G loss: 0.461266]\n",
      "[Epoch 9/200] [Batch 421/637] [D loss: 0.161228] [G loss: 0.552368]\n",
      "[Epoch 9/200] [Batch 422/637] [D loss: 0.133106] [G loss: 0.627684]\n",
      "[Epoch 9/200] [Batch 423/637] [D loss: 0.136154] [G loss: 0.547546]\n",
      "[Epoch 9/200] [Batch 424/637] [D loss: 0.173198] [G loss: 0.469750]\n",
      "[Epoch 9/200] [Batch 425/637] [D loss: 0.182399] [G loss: 0.577103]\n",
      "[Epoch 9/200] [Batch 426/637] [D loss: 0.146993] [G loss: 0.575323]\n",
      "[Epoch 9/200] [Batch 427/637] [D loss: 0.156310] [G loss: 0.526969]\n",
      "[Epoch 9/200] [Batch 428/637] [D loss: 0.152844] [G loss: 0.510032]\n",
      "[Epoch 9/200] [Batch 429/637] [D loss: 0.172754] [G loss: 0.500180]\n",
      "[Epoch 9/200] [Batch 430/637] [D loss: 0.167667] [G loss: 0.522537]\n",
      "[Epoch 9/200] [Batch 431/637] [D loss: 0.148290] [G loss: 0.527394]\n",
      "[Epoch 9/200] [Batch 432/637] [D loss: 0.204947] [G loss: 0.455953]\n",
      "[Epoch 9/200] [Batch 433/637] [D loss: 0.182423] [G loss: 0.540430]\n",
      "[Epoch 9/200] [Batch 434/637] [D loss: 0.188452] [G loss: 0.512127]\n",
      "[Epoch 9/200] [Batch 435/637] [D loss: 0.169231] [G loss: 0.468842]\n",
      "[Epoch 9/200] [Batch 436/637] [D loss: 0.151617] [G loss: 0.548498]\n",
      "[Epoch 9/200] [Batch 437/637] [D loss: 0.154856] [G loss: 0.578651]\n",
      "[Epoch 9/200] [Batch 438/637] [D loss: 0.183033] [G loss: 0.500489]\n",
      "[Epoch 9/200] [Batch 439/637] [D loss: 0.161730] [G loss: 0.497178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 440/637] [D loss: 0.174297] [G loss: 0.530465]\n",
      "[Epoch 9/200] [Batch 441/637] [D loss: 0.143973] [G loss: 0.599414]\n",
      "[Epoch 9/200] [Batch 442/637] [D loss: 0.143521] [G loss: 0.532481]\n",
      "[Epoch 9/200] [Batch 443/637] [D loss: 0.163463] [G loss: 0.494547]\n",
      "[Epoch 9/200] [Batch 444/637] [D loss: 0.132248] [G loss: 0.572422]\n",
      "[Epoch 9/200] [Batch 445/637] [D loss: 0.157427] [G loss: 0.591671]\n",
      "[Epoch 9/200] [Batch 446/637] [D loss: 0.153387] [G loss: 0.582908]\n",
      "[Epoch 9/200] [Batch 447/637] [D loss: 0.148197] [G loss: 0.582426]\n",
      "[Epoch 9/200] [Batch 448/637] [D loss: 0.143425] [G loss: 0.676550]\n",
      "[Epoch 9/200] [Batch 449/637] [D loss: 0.138769] [G loss: 0.569635]\n",
      "[Epoch 9/200] [Batch 450/637] [D loss: 0.149068] [G loss: 0.516174]\n",
      "[Epoch 9/200] [Batch 451/637] [D loss: 0.122225] [G loss: 0.582390]\n",
      "[Epoch 9/200] [Batch 452/637] [D loss: 0.157270] [G loss: 0.594519]\n",
      "[Epoch 9/200] [Batch 453/637] [D loss: 0.147525] [G loss: 0.542531]\n",
      "[Epoch 9/200] [Batch 454/637] [D loss: 0.191654] [G loss: 0.453431]\n",
      "[Epoch 9/200] [Batch 455/637] [D loss: 0.192019] [G loss: 0.638762]\n",
      "[Epoch 9/200] [Batch 456/637] [D loss: 0.148759] [G loss: 0.505230]\n",
      "[Epoch 9/200] [Batch 457/637] [D loss: 0.147362] [G loss: 0.558085]\n",
      "[Epoch 9/200] [Batch 458/637] [D loss: 0.280683] [G loss: 0.320817]\n",
      "[Epoch 9/200] [Batch 459/637] [D loss: 0.313831] [G loss: 0.693304]\n",
      "[Epoch 9/200] [Batch 460/637] [D loss: 0.228487] [G loss: 0.594374]\n",
      "[Epoch 9/200] [Batch 461/637] [D loss: 0.200682] [G loss: 0.527499]\n",
      "[Epoch 9/200] [Batch 462/637] [D loss: 0.185045] [G loss: 0.470054]\n",
      "[Epoch 9/200] [Batch 463/637] [D loss: 0.191547] [G loss: 0.415781]\n",
      "[Epoch 9/200] [Batch 464/637] [D loss: 0.162028] [G loss: 0.435302]\n",
      "[Epoch 9/200] [Batch 465/637] [D loss: 0.180787] [G loss: 0.417088]\n",
      "[Epoch 9/200] [Batch 466/637] [D loss: 0.159391] [G loss: 0.496651]\n",
      "[Epoch 9/200] [Batch 467/637] [D loss: 0.162442] [G loss: 0.480265]\n",
      "[Epoch 9/200] [Batch 468/637] [D loss: 0.162048] [G loss: 0.481898]\n",
      "[Epoch 9/200] [Batch 469/637] [D loss: 0.143707] [G loss: 0.543536]\n",
      "[Epoch 9/200] [Batch 470/637] [D loss: 0.151839] [G loss: 0.487432]\n",
      "[Epoch 9/200] [Batch 471/637] [D loss: 0.150144] [G loss: 0.502035]\n",
      "[Epoch 9/200] [Batch 472/637] [D loss: 0.156548] [G loss: 0.488487]\n",
      "[Epoch 9/200] [Batch 473/637] [D loss: 0.160032] [G loss: 0.473290]\n",
      "[Epoch 9/200] [Batch 474/637] [D loss: 0.167140] [G loss: 0.645010]\n",
      "[Epoch 9/200] [Batch 475/637] [D loss: 0.148429] [G loss: 0.589097]\n",
      "[Epoch 9/200] [Batch 476/637] [D loss: 0.153327] [G loss: 0.517466]\n",
      "[Epoch 9/200] [Batch 477/637] [D loss: 0.146124] [G loss: 0.459222]\n",
      "[Epoch 9/200] [Batch 478/637] [D loss: 0.127735] [G loss: 0.569286]\n",
      "[Epoch 9/200] [Batch 479/637] [D loss: 0.140726] [G loss: 0.538128]\n",
      "[Epoch 9/200] [Batch 480/637] [D loss: 0.177874] [G loss: 0.498083]\n",
      "[Epoch 9/200] [Batch 481/637] [D loss: 0.161176] [G loss: 0.512618]\n",
      "[Epoch 9/200] [Batch 482/637] [D loss: 0.132539] [G loss: 0.562065]\n",
      "[Epoch 9/200] [Batch 483/637] [D loss: 0.142601] [G loss: 0.579479]\n",
      "[Epoch 9/200] [Batch 484/637] [D loss: 0.155590] [G loss: 0.538173]\n",
      "[Epoch 9/200] [Batch 485/637] [D loss: 0.157922] [G loss: 0.554650]\n",
      "[Epoch 9/200] [Batch 486/637] [D loss: 0.160859] [G loss: 0.598964]\n",
      "[Epoch 9/200] [Batch 487/637] [D loss: 0.154242] [G loss: 0.554228]\n",
      "[Epoch 9/200] [Batch 488/637] [D loss: 0.175978] [G loss: 0.484298]\n",
      "[Epoch 9/200] [Batch 489/637] [D loss: 0.150325] [G loss: 0.469714]\n",
      "[Epoch 9/200] [Batch 490/637] [D loss: 0.161103] [G loss: 0.530401]\n",
      "[Epoch 9/200] [Batch 491/637] [D loss: 0.167439] [G loss: 0.501229]\n",
      "[Epoch 9/200] [Batch 492/637] [D loss: 0.174619] [G loss: 0.444037]\n",
      "[Epoch 9/200] [Batch 493/637] [D loss: 0.136830] [G loss: 0.496301]\n",
      "[Epoch 9/200] [Batch 494/637] [D loss: 0.153532] [G loss: 0.474694]\n",
      "[Epoch 9/200] [Batch 495/637] [D loss: 0.154226] [G loss: 0.495091]\n",
      "[Epoch 9/200] [Batch 496/637] [D loss: 0.164167] [G loss: 0.511921]\n",
      "[Epoch 9/200] [Batch 497/637] [D loss: 0.161221] [G loss: 0.432822]\n",
      "[Epoch 9/200] [Batch 498/637] [D loss: 0.188783] [G loss: 0.490576]\n",
      "[Epoch 9/200] [Batch 499/637] [D loss: 0.172970] [G loss: 0.495133]\n",
      "[Epoch 9/200] [Batch 500/637] [D loss: 0.158277] [G loss: 0.508404]\n",
      "[Epoch 9/200] [Batch 501/637] [D loss: 0.164981] [G loss: 0.513826]\n",
      "[Epoch 9/200] [Batch 502/637] [D loss: 0.186657] [G loss: 0.476331]\n",
      "[Epoch 9/200] [Batch 503/637] [D loss: 0.167420] [G loss: 0.507801]\n",
      "[Epoch 9/200] [Batch 504/637] [D loss: 0.163409] [G loss: 0.512905]\n",
      "[Epoch 9/200] [Batch 505/637] [D loss: 0.179749] [G loss: 0.543054]\n",
      "[Epoch 9/200] [Batch 506/637] [D loss: 0.158308] [G loss: 0.520461]\n",
      "[Epoch 9/200] [Batch 507/637] [D loss: 0.179681] [G loss: 0.495326]\n",
      "[Epoch 9/200] [Batch 508/637] [D loss: 0.172847] [G loss: 0.451731]\n",
      "[Epoch 9/200] [Batch 509/637] [D loss: 0.142988] [G loss: 0.570352]\n",
      "[Epoch 9/200] [Batch 510/637] [D loss: 0.144980] [G loss: 0.529597]\n",
      "[Epoch 9/200] [Batch 511/637] [D loss: 0.149728] [G loss: 0.509470]\n",
      "[Epoch 9/200] [Batch 512/637] [D loss: 0.165055] [G loss: 0.575698]\n",
      "[Epoch 9/200] [Batch 513/637] [D loss: 0.134213] [G loss: 0.591608]\n",
      "[Epoch 9/200] [Batch 514/637] [D loss: 0.174047] [G loss: 0.487909]\n",
      "[Epoch 9/200] [Batch 515/637] [D loss: 0.157243] [G loss: 0.505527]\n",
      "[Epoch 9/200] [Batch 516/637] [D loss: 0.127899] [G loss: 0.613213]\n",
      "[Epoch 9/200] [Batch 517/637] [D loss: 0.146824] [G loss: 0.510618]\n",
      "[Epoch 9/200] [Batch 518/637] [D loss: 0.137567] [G loss: 0.539706]\n",
      "[Epoch 9/200] [Batch 519/637] [D loss: 0.153359] [G loss: 0.533448]\n",
      "[Epoch 9/200] [Batch 520/637] [D loss: 0.154357] [G loss: 0.520264]\n",
      "[Epoch 9/200] [Batch 521/637] [D loss: 0.171043] [G loss: 0.521135]\n",
      "[Epoch 9/200] [Batch 522/637] [D loss: 0.232793] [G loss: 0.577367]\n",
      "[Epoch 9/200] [Batch 523/637] [D loss: 0.150511] [G loss: 0.692399]\n",
      "[Epoch 9/200] [Batch 524/637] [D loss: 0.211780] [G loss: 0.454050]\n",
      "[Epoch 9/200] [Batch 525/637] [D loss: 0.196110] [G loss: 0.529052]\n",
      "[Epoch 9/200] [Batch 526/637] [D loss: 0.188205] [G loss: 0.531063]\n",
      "[Epoch 9/200] [Batch 527/637] [D loss: 0.164138] [G loss: 0.495515]\n",
      "[Epoch 9/200] [Batch 528/637] [D loss: 0.123954] [G loss: 0.530736]\n",
      "[Epoch 9/200] [Batch 529/637] [D loss: 0.150713] [G loss: 0.493368]\n",
      "[Epoch 9/200] [Batch 530/637] [D loss: 0.188454] [G loss: 0.443573]\n",
      "[Epoch 9/200] [Batch 531/637] [D loss: 0.147748] [G loss: 0.579122]\n",
      "[Epoch 9/200] [Batch 532/637] [D loss: 0.183000] [G loss: 0.561990]\n",
      "[Epoch 9/200] [Batch 533/637] [D loss: 0.162952] [G loss: 0.549430]\n",
      "[Epoch 9/200] [Batch 534/637] [D loss: 0.128578] [G loss: 0.606503]\n",
      "[Epoch 9/200] [Batch 535/637] [D loss: 0.148966] [G loss: 0.584996]\n",
      "[Epoch 9/200] [Batch 536/637] [D loss: 0.139405] [G loss: 0.538459]\n",
      "[Epoch 9/200] [Batch 537/637] [D loss: 0.127974] [G loss: 0.600504]\n",
      "[Epoch 9/200] [Batch 538/637] [D loss: 0.160974] [G loss: 0.501679]\n",
      "[Epoch 9/200] [Batch 539/637] [D loss: 0.132557] [G loss: 0.541703]\n",
      "[Epoch 9/200] [Batch 540/637] [D loss: 0.129631] [G loss: 0.594423]\n",
      "[Epoch 9/200] [Batch 541/637] [D loss: 0.133094] [G loss: 0.568783]\n",
      "[Epoch 9/200] [Batch 542/637] [D loss: 0.160404] [G loss: 0.477077]\n",
      "[Epoch 9/200] [Batch 543/637] [D loss: 0.164426] [G loss: 0.487609]\n",
      "[Epoch 9/200] [Batch 544/637] [D loss: 0.144320] [G loss: 0.625032]\n",
      "[Epoch 9/200] [Batch 545/637] [D loss: 0.145399] [G loss: 0.630547]\n",
      "[Epoch 9/200] [Batch 546/637] [D loss: 0.143485] [G loss: 0.510942]\n",
      "[Epoch 9/200] [Batch 547/637] [D loss: 0.140094] [G loss: 0.571381]\n",
      "[Epoch 9/200] [Batch 548/637] [D loss: 0.152039] [G loss: 0.522623]\n",
      "[Epoch 9/200] [Batch 549/637] [D loss: 0.150292] [G loss: 0.585599]\n",
      "[Epoch 9/200] [Batch 550/637] [D loss: 0.133019] [G loss: 0.569335]\n",
      "[Epoch 9/200] [Batch 551/637] [D loss: 0.119689] [G loss: 0.590436]\n",
      "[Epoch 9/200] [Batch 552/637] [D loss: 0.148154] [G loss: 0.557516]\n",
      "[Epoch 9/200] [Batch 553/637] [D loss: 0.136441] [G loss: 0.654518]\n",
      "[Epoch 9/200] [Batch 554/637] [D loss: 0.128288] [G loss: 0.625587]\n",
      "[Epoch 9/200] [Batch 555/637] [D loss: 0.179324] [G loss: 0.479682]\n",
      "[Epoch 9/200] [Batch 556/637] [D loss: 0.212337] [G loss: 0.658014]\n",
      "[Epoch 9/200] [Batch 557/637] [D loss: 0.196734] [G loss: 0.519154]\n",
      "[Epoch 9/200] [Batch 558/637] [D loss: 0.174175] [G loss: 0.573548]\n",
      "[Epoch 9/200] [Batch 559/637] [D loss: 0.138493] [G loss: 0.551918]\n",
      "[Epoch 9/200] [Batch 560/637] [D loss: 0.156572] [G loss: 0.505162]\n",
      "[Epoch 9/200] [Batch 561/637] [D loss: 0.171419] [G loss: 0.468131]\n",
      "[Epoch 9/200] [Batch 562/637] [D loss: 0.146373] [G loss: 0.439491]\n",
      "[Epoch 9/200] [Batch 563/637] [D loss: 0.148944] [G loss: 0.498177]\n",
      "[Epoch 9/200] [Batch 564/637] [D loss: 0.181443] [G loss: 0.590334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 565/637] [D loss: 0.156227] [G loss: 0.557106]\n",
      "[Epoch 9/200] [Batch 566/637] [D loss: 0.152116] [G loss: 0.531454]\n",
      "[Epoch 9/200] [Batch 567/637] [D loss: 0.169509] [G loss: 0.482885]\n",
      "[Epoch 9/200] [Batch 568/637] [D loss: 0.147512] [G loss: 0.525332]\n",
      "[Epoch 9/200] [Batch 569/637] [D loss: 0.153357] [G loss: 0.514123]\n",
      "[Epoch 9/200] [Batch 570/637] [D loss: 0.154947] [G loss: 0.533019]\n",
      "[Epoch 9/200] [Batch 571/637] [D loss: 0.139037] [G loss: 0.517091]\n",
      "[Epoch 9/200] [Batch 572/637] [D loss: 0.162247] [G loss: 0.495868]\n",
      "[Epoch 9/200] [Batch 573/637] [D loss: 0.139081] [G loss: 0.546739]\n",
      "[Epoch 9/200] [Batch 574/637] [D loss: 0.143926] [G loss: 0.567825]\n",
      "[Epoch 9/200] [Batch 575/637] [D loss: 0.151094] [G loss: 0.591960]\n",
      "[Epoch 9/200] [Batch 576/637] [D loss: 0.133520] [G loss: 0.579232]\n",
      "[Epoch 9/200] [Batch 577/637] [D loss: 0.216308] [G loss: 0.402400]\n",
      "[Epoch 9/200] [Batch 578/637] [D loss: 0.215608] [G loss: 0.574252]\n",
      "[Epoch 9/200] [Batch 579/637] [D loss: 0.175485] [G loss: 0.652885]\n",
      "[Epoch 9/200] [Batch 580/637] [D loss: 0.166532] [G loss: 0.563911]\n",
      "[Epoch 9/200] [Batch 581/637] [D loss: 0.178750] [G loss: 0.424812]\n",
      "[Epoch 9/200] [Batch 582/637] [D loss: 0.143918] [G loss: 0.472302]\n",
      "[Epoch 9/200] [Batch 583/637] [D loss: 0.139474] [G loss: 0.478458]\n",
      "[Epoch 9/200] [Batch 584/637] [D loss: 0.130747] [G loss: 0.489193]\n",
      "[Epoch 9/200] [Batch 585/637] [D loss: 0.140503] [G loss: 0.500611]\n",
      "[Epoch 9/200] [Batch 586/637] [D loss: 0.136270] [G loss: 0.520603]\n",
      "[Epoch 9/200] [Batch 587/637] [D loss: 0.136522] [G loss: 0.562052]\n",
      "[Epoch 9/200] [Batch 588/637] [D loss: 0.137088] [G loss: 0.551926]\n",
      "[Epoch 9/200] [Batch 589/637] [D loss: 0.142546] [G loss: 0.495676]\n",
      "[Epoch 9/200] [Batch 590/637] [D loss: 0.152710] [G loss: 0.551821]\n",
      "[Epoch 9/200] [Batch 591/637] [D loss: 0.168487] [G loss: 0.620194]\n",
      "[Epoch 9/200] [Batch 592/637] [D loss: 0.124825] [G loss: 0.607414]\n",
      "[Epoch 9/200] [Batch 593/637] [D loss: 0.161541] [G loss: 0.471714]\n",
      "[Epoch 9/200] [Batch 594/637] [D loss: 0.161044] [G loss: 0.578091]\n",
      "[Epoch 9/200] [Batch 595/637] [D loss: 0.181947] [G loss: 0.484077]\n",
      "[Epoch 9/200] [Batch 596/637] [D loss: 0.135595] [G loss: 0.562944]\n",
      "[Epoch 9/200] [Batch 597/637] [D loss: 0.163992] [G loss: 0.578852]\n",
      "[Epoch 9/200] [Batch 598/637] [D loss: 0.163680] [G loss: 0.593609]\n",
      "[Epoch 9/200] [Batch 599/637] [D loss: 0.163796] [G loss: 0.529067]\n",
      "[Epoch 9/200] [Batch 600/637] [D loss: 0.149782] [G loss: 0.522249]\n",
      "[Epoch 9/200] [Batch 601/637] [D loss: 0.161709] [G loss: 0.550097]\n",
      "[Epoch 9/200] [Batch 602/637] [D loss: 0.158195] [G loss: 0.491224]\n",
      "[Epoch 9/200] [Batch 603/637] [D loss: 0.168440] [G loss: 0.560125]\n",
      "[Epoch 9/200] [Batch 604/637] [D loss: 0.165435] [G loss: 0.535760]\n",
      "[Epoch 9/200] [Batch 605/637] [D loss: 0.164109] [G loss: 0.397965]\n",
      "[Epoch 9/200] [Batch 606/637] [D loss: 0.184922] [G loss: 0.447485]\n",
      "[Epoch 9/200] [Batch 607/637] [D loss: 0.157866] [G loss: 0.505801]\n",
      "[Epoch 9/200] [Batch 608/637] [D loss: 0.161177] [G loss: 0.519264]\n",
      "[Epoch 9/200] [Batch 609/637] [D loss: 0.170088] [G loss: 0.452820]\n",
      "[Epoch 9/200] [Batch 610/637] [D loss: 0.170628] [G loss: 0.501001]\n",
      "[Epoch 9/200] [Batch 611/637] [D loss: 0.173672] [G loss: 0.504639]\n",
      "[Epoch 9/200] [Batch 612/637] [D loss: 0.177545] [G loss: 0.473905]\n",
      "[Epoch 9/200] [Batch 613/637] [D loss: 0.166636] [G loss: 0.546397]\n",
      "[Epoch 9/200] [Batch 614/637] [D loss: 0.176505] [G loss: 0.477492]\n",
      "[Epoch 9/200] [Batch 615/637] [D loss: 0.178499] [G loss: 0.535416]\n",
      "[Epoch 9/200] [Batch 616/637] [D loss: 0.173615] [G loss: 0.483506]\n",
      "[Epoch 9/200] [Batch 617/637] [D loss: 0.130366] [G loss: 0.529107]\n",
      "[Epoch 9/200] [Batch 618/637] [D loss: 0.165687] [G loss: 0.415358]\n",
      "[Epoch 9/200] [Batch 619/637] [D loss: 0.160824] [G loss: 0.488977]\n",
      "[Epoch 9/200] [Batch 620/637] [D loss: 0.147442] [G loss: 0.519892]\n",
      "[Epoch 9/200] [Batch 621/637] [D loss: 0.143110] [G loss: 0.524317]\n",
      "[Epoch 9/200] [Batch 622/637] [D loss: 0.128948] [G loss: 0.497868]\n",
      "[Epoch 9/200] [Batch 623/637] [D loss: 0.179146] [G loss: 0.469927]\n",
      "[Epoch 9/200] [Batch 624/637] [D loss: 0.169060] [G loss: 0.564816]\n",
      "[Epoch 9/200] [Batch 625/637] [D loss: 0.167695] [G loss: 0.625378]\n",
      "[Epoch 9/200] [Batch 626/637] [D loss: 0.167682] [G loss: 0.493043]\n",
      "[Epoch 9/200] [Batch 627/637] [D loss: 0.186092] [G loss: 0.499941]\n",
      "[Epoch 9/200] [Batch 628/637] [D loss: 0.176964] [G loss: 0.501618]\n",
      "[Epoch 9/200] [Batch 629/637] [D loss: 0.150181] [G loss: 0.512380]\n",
      "[Epoch 9/200] [Batch 630/637] [D loss: 0.157535] [G loss: 0.424856]\n",
      "[Epoch 9/200] [Batch 631/637] [D loss: 0.169225] [G loss: 0.439087]\n",
      "[Epoch 9/200] [Batch 632/637] [D loss: 0.161494] [G loss: 0.441710]\n",
      "[Epoch 9/200] [Batch 633/637] [D loss: 0.160602] [G loss: 0.511845]\n",
      "[Epoch 9/200] [Batch 634/637] [D loss: 0.185942] [G loss: 0.485550]\n",
      "[Epoch 9/200] [Batch 635/637] [D loss: 0.147592] [G loss: 0.480084]\n",
      "[Epoch 9/200] [Batch 636/637] [D loss: 0.144828] [G loss: 0.542162]\n",
      "[Epoch 10/200] [Batch 0/637] [D loss: 0.168263] [G loss: 0.514114]\n",
      "[Epoch 10/200] [Batch 1/637] [D loss: 0.155541] [G loss: 0.537934]\n",
      "[Epoch 10/200] [Batch 2/637] [D loss: 0.187217] [G loss: 0.454971]\n",
      "[Epoch 10/200] [Batch 3/637] [D loss: 0.147685] [G loss: 0.640933]\n",
      "[Epoch 10/200] [Batch 4/637] [D loss: 0.162546] [G loss: 0.558705]\n",
      "[Epoch 10/200] [Batch 5/637] [D loss: 0.183693] [G loss: 0.549639]\n",
      "[Epoch 10/200] [Batch 6/637] [D loss: 0.146607] [G loss: 0.587558]\n",
      "[Epoch 10/200] [Batch 7/637] [D loss: 0.154788] [G loss: 0.504646]\n",
      "[Epoch 10/200] [Batch 8/637] [D loss: 0.158139] [G loss: 0.506895]\n",
      "[Epoch 10/200] [Batch 9/637] [D loss: 0.164898] [G loss: 0.558833]\n",
      "[Epoch 10/200] [Batch 10/637] [D loss: 0.156007] [G loss: 0.489115]\n",
      "[Epoch 10/200] [Batch 11/637] [D loss: 0.138509] [G loss: 0.524439]\n",
      "[Epoch 10/200] [Batch 12/637] [D loss: 0.150916] [G loss: 0.504727]\n",
      "[Epoch 10/200] [Batch 13/637] [D loss: 0.114623] [G loss: 0.603317]\n",
      "[Epoch 10/200] [Batch 14/637] [D loss: 0.160399] [G loss: 0.554523]\n",
      "[Epoch 10/200] [Batch 15/637] [D loss: 0.186662] [G loss: 0.442115]\n",
      "[Epoch 10/200] [Batch 16/637] [D loss: 0.153500] [G loss: 0.594132]\n",
      "[Epoch 10/200] [Batch 17/637] [D loss: 0.178708] [G loss: 0.512744]\n",
      "[Epoch 10/200] [Batch 18/637] [D loss: 0.149935] [G loss: 0.486487]\n",
      "[Epoch 10/200] [Batch 19/637] [D loss: 0.196870] [G loss: 0.441702]\n",
      "[Epoch 10/200] [Batch 20/637] [D loss: 0.155044] [G loss: 0.542714]\n",
      "[Epoch 10/200] [Batch 21/637] [D loss: 0.180808] [G loss: 0.503890]\n",
      "[Epoch 10/200] [Batch 22/637] [D loss: 0.156452] [G loss: 0.474852]\n",
      "[Epoch 10/200] [Batch 23/637] [D loss: 0.186471] [G loss: 0.431126]\n",
      "[Epoch 10/200] [Batch 24/637] [D loss: 0.142833] [G loss: 0.522688]\n",
      "[Epoch 10/200] [Batch 25/637] [D loss: 0.147306] [G loss: 0.491519]\n",
      "[Epoch 10/200] [Batch 26/637] [D loss: 0.140176] [G loss: 0.472800]\n",
      "[Epoch 10/200] [Batch 27/637] [D loss: 0.147330] [G loss: 0.472968]\n",
      "[Epoch 10/200] [Batch 28/637] [D loss: 0.140095] [G loss: 0.522962]\n",
      "[Epoch 10/200] [Batch 29/637] [D loss: 0.186453] [G loss: 0.465308]\n",
      "[Epoch 10/200] [Batch 30/637] [D loss: 0.173766] [G loss: 0.576251]\n",
      "[Epoch 10/200] [Batch 31/637] [D loss: 0.148204] [G loss: 0.602190]\n",
      "[Epoch 10/200] [Batch 32/637] [D loss: 0.145550] [G loss: 0.543980]\n",
      "[Epoch 10/200] [Batch 33/637] [D loss: 0.190386] [G loss: 0.456715]\n",
      "[Epoch 10/200] [Batch 34/637] [D loss: 0.168131] [G loss: 0.463582]\n",
      "[Epoch 10/200] [Batch 35/637] [D loss: 0.144645] [G loss: 0.572952]\n",
      "[Epoch 10/200] [Batch 36/637] [D loss: 0.166173] [G loss: 0.552834]\n",
      "[Epoch 10/200] [Batch 37/637] [D loss: 0.146677] [G loss: 0.485432]\n",
      "[Epoch 10/200] [Batch 38/637] [D loss: 0.141743] [G loss: 0.533885]\n",
      "[Epoch 10/200] [Batch 39/637] [D loss: 0.143981] [G loss: 0.510639]\n",
      "[Epoch 10/200] [Batch 40/637] [D loss: 0.158198] [G loss: 0.558245]\n",
      "[Epoch 10/200] [Batch 41/637] [D loss: 0.151497] [G loss: 0.526033]\n",
      "[Epoch 10/200] [Batch 42/637] [D loss: 0.173261] [G loss: 0.456917]\n",
      "[Epoch 10/200] [Batch 43/637] [D loss: 0.169507] [G loss: 0.543822]\n",
      "[Epoch 10/200] [Batch 44/637] [D loss: 0.147895] [G loss: 0.511289]\n",
      "[Epoch 10/200] [Batch 45/637] [D loss: 0.171244] [G loss: 0.555102]\n",
      "[Epoch 10/200] [Batch 46/637] [D loss: 0.199742] [G loss: 0.483804]\n",
      "[Epoch 10/200] [Batch 47/637] [D loss: 0.170484] [G loss: 0.546838]\n",
      "[Epoch 10/200] [Batch 48/637] [D loss: 0.205113] [G loss: 0.593060]\n",
      "[Epoch 10/200] [Batch 49/637] [D loss: 0.168451] [G loss: 0.488480]\n",
      "[Epoch 10/200] [Batch 50/637] [D loss: 0.158422] [G loss: 0.544153]\n",
      "[Epoch 10/200] [Batch 51/637] [D loss: 0.141232] [G loss: 0.550462]\n",
      "[Epoch 10/200] [Batch 52/637] [D loss: 0.157957] [G loss: 0.459991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 53/637] [D loss: 0.138242] [G loss: 0.540011]\n",
      "[Epoch 10/200] [Batch 54/637] [D loss: 0.173663] [G loss: 0.515208]\n",
      "[Epoch 10/200] [Batch 55/637] [D loss: 0.150112] [G loss: 0.526549]\n",
      "[Epoch 10/200] [Batch 56/637] [D loss: 0.131697] [G loss: 0.618511]\n",
      "[Epoch 10/200] [Batch 57/637] [D loss: 0.125595] [G loss: 0.539380]\n",
      "[Epoch 10/200] [Batch 58/637] [D loss: 0.147433] [G loss: 0.456643]\n",
      "[Epoch 10/200] [Batch 59/637] [D loss: 0.171191] [G loss: 0.494773]\n",
      "[Epoch 10/200] [Batch 60/637] [D loss: 0.130369] [G loss: 0.651995]\n",
      "[Epoch 10/200] [Batch 61/637] [D loss: 0.187761] [G loss: 0.494466]\n",
      "[Epoch 10/200] [Batch 62/637] [D loss: 0.157686] [G loss: 0.569936]\n",
      "[Epoch 10/200] [Batch 63/637] [D loss: 0.156855] [G loss: 0.509888]\n",
      "[Epoch 10/200] [Batch 64/637] [D loss: 0.153476] [G loss: 0.505229]\n",
      "[Epoch 10/200] [Batch 65/637] [D loss: 0.135895] [G loss: 0.536888]\n",
      "[Epoch 10/200] [Batch 66/637] [D loss: 0.152164] [G loss: 0.484762]\n",
      "[Epoch 10/200] [Batch 67/637] [D loss: 0.146352] [G loss: 0.564460]\n",
      "[Epoch 10/200] [Batch 68/637] [D loss: 0.162978] [G loss: 0.509448]\n",
      "[Epoch 10/200] [Batch 69/637] [D loss: 0.192388] [G loss: 0.495603]\n",
      "[Epoch 10/200] [Batch 70/637] [D loss: 0.151909] [G loss: 0.489013]\n",
      "[Epoch 10/200] [Batch 71/637] [D loss: 0.142728] [G loss: 0.553634]\n",
      "[Epoch 10/200] [Batch 72/637] [D loss: 0.180435] [G loss: 0.512848]\n",
      "[Epoch 10/200] [Batch 73/637] [D loss: 0.140640] [G loss: 0.536214]\n",
      "[Epoch 10/200] [Batch 74/637] [D loss: 0.142636] [G loss: 0.526283]\n",
      "[Epoch 10/200] [Batch 75/637] [D loss: 0.157468] [G loss: 0.553043]\n",
      "[Epoch 10/200] [Batch 76/637] [D loss: 0.136773] [G loss: 0.578706]\n",
      "[Epoch 10/200] [Batch 77/637] [D loss: 0.182853] [G loss: 0.550093]\n",
      "[Epoch 10/200] [Batch 78/637] [D loss: 0.172449] [G loss: 0.662197]\n",
      "[Epoch 10/200] [Batch 79/637] [D loss: 0.150134] [G loss: 0.625966]\n",
      "[Epoch 10/200] [Batch 80/637] [D loss: 0.153613] [G loss: 0.468988]\n",
      "[Epoch 10/200] [Batch 81/637] [D loss: 0.143539] [G loss: 0.476881]\n",
      "[Epoch 10/200] [Batch 82/637] [D loss: 0.143780] [G loss: 0.511076]\n",
      "[Epoch 10/200] [Batch 83/637] [D loss: 0.135171] [G loss: 0.531362]\n",
      "[Epoch 10/200] [Batch 84/637] [D loss: 0.166186] [G loss: 0.568536]\n",
      "[Epoch 10/200] [Batch 85/637] [D loss: 0.149432] [G loss: 0.523299]\n",
      "[Epoch 10/200] [Batch 86/637] [D loss: 0.149255] [G loss: 0.525837]\n",
      "[Epoch 10/200] [Batch 87/637] [D loss: 0.136277] [G loss: 0.526552]\n",
      "[Epoch 10/200] [Batch 88/637] [D loss: 0.147975] [G loss: 0.570256]\n",
      "[Epoch 10/200] [Batch 89/637] [D loss: 0.154119] [G loss: 0.619705]\n",
      "[Epoch 10/200] [Batch 90/637] [D loss: 0.161475] [G loss: 0.531433]\n",
      "[Epoch 10/200] [Batch 91/637] [D loss: 0.164511] [G loss: 0.427407]\n",
      "[Epoch 10/200] [Batch 92/637] [D loss: 0.175684] [G loss: 0.407466]\n",
      "[Epoch 10/200] [Batch 93/637] [D loss: 0.157514] [G loss: 0.596966]\n",
      "[Epoch 10/200] [Batch 94/637] [D loss: 0.150930] [G loss: 0.615039]\n",
      "[Epoch 10/200] [Batch 95/637] [D loss: 0.160925] [G loss: 0.494721]\n",
      "[Epoch 10/200] [Batch 96/637] [D loss: 0.140106] [G loss: 0.578015]\n",
      "[Epoch 10/200] [Batch 97/637] [D loss: 0.161780] [G loss: 0.574808]\n",
      "[Epoch 10/200] [Batch 98/637] [D loss: 0.157262] [G loss: 0.530283]\n",
      "[Epoch 10/200] [Batch 99/637] [D loss: 0.152592] [G loss: 0.496843]\n",
      "[Epoch 10/200] [Batch 100/637] [D loss: 0.173978] [G loss: 0.507901]\n",
      "[Epoch 10/200] [Batch 101/637] [D loss: 0.305510] [G loss: 0.788322]\n",
      "[Epoch 10/200] [Batch 102/637] [D loss: 0.165540] [G loss: 0.692457]\n",
      "[Epoch 10/200] [Batch 103/637] [D loss: 0.206159] [G loss: 0.523273]\n",
      "[Epoch 10/200] [Batch 104/637] [D loss: 0.156734] [G loss: 0.459039]\n",
      "[Epoch 10/200] [Batch 105/637] [D loss: 0.141606] [G loss: 0.478063]\n",
      "[Epoch 10/200] [Batch 106/637] [D loss: 0.131746] [G loss: 0.476126]\n",
      "[Epoch 10/200] [Batch 107/637] [D loss: 0.146033] [G loss: 0.466119]\n",
      "[Epoch 10/200] [Batch 108/637] [D loss: 0.138060] [G loss: 0.528441]\n",
      "[Epoch 10/200] [Batch 109/637] [D loss: 0.144237] [G loss: 0.518931]\n",
      "[Epoch 10/200] [Batch 110/637] [D loss: 0.175924] [G loss: 0.542686]\n",
      "[Epoch 10/200] [Batch 111/637] [D loss: 0.132126] [G loss: 0.601176]\n",
      "[Epoch 10/200] [Batch 112/637] [D loss: 0.148264] [G loss: 0.501412]\n",
      "[Epoch 10/200] [Batch 113/637] [D loss: 0.126387] [G loss: 0.522918]\n",
      "[Epoch 10/200] [Batch 114/637] [D loss: 0.154750] [G loss: 0.454357]\n",
      "[Epoch 10/200] [Batch 115/637] [D loss: 0.126608] [G loss: 0.542310]\n",
      "[Epoch 10/200] [Batch 116/637] [D loss: 0.156371] [G loss: 0.504506]\n",
      "[Epoch 10/200] [Batch 117/637] [D loss: 0.151999] [G loss: 0.532593]\n",
      "[Epoch 10/200] [Batch 118/637] [D loss: 0.166949] [G loss: 0.480190]\n",
      "[Epoch 10/200] [Batch 119/637] [D loss: 0.165936] [G loss: 0.476376]\n",
      "[Epoch 10/200] [Batch 120/637] [D loss: 0.145763] [G loss: 0.524864]\n",
      "[Epoch 10/200] [Batch 121/637] [D loss: 0.145568] [G loss: 0.529201]\n",
      "[Epoch 10/200] [Batch 122/637] [D loss: 0.162565] [G loss: 0.447944]\n",
      "[Epoch 10/200] [Batch 123/637] [D loss: 0.162553] [G loss: 0.505167]\n",
      "[Epoch 10/200] [Batch 124/637] [D loss: 0.186843] [G loss: 0.441459]\n",
      "[Epoch 10/200] [Batch 125/637] [D loss: 0.158501] [G loss: 0.568131]\n",
      "[Epoch 10/200] [Batch 126/637] [D loss: 0.162798] [G loss: 0.501420]\n",
      "[Epoch 10/200] [Batch 127/637] [D loss: 0.157400] [G loss: 0.540655]\n",
      "[Epoch 10/200] [Batch 128/637] [D loss: 0.139670] [G loss: 0.533001]\n",
      "[Epoch 10/200] [Batch 129/637] [D loss: 0.172600] [G loss: 0.483502]\n",
      "[Epoch 10/200] [Batch 130/637] [D loss: 0.154543] [G loss: 0.521032]\n",
      "[Epoch 10/200] [Batch 131/637] [D loss: 0.148194] [G loss: 0.542558]\n",
      "[Epoch 10/200] [Batch 132/637] [D loss: 0.152953] [G loss: 0.512832]\n",
      "[Epoch 10/200] [Batch 133/637] [D loss: 0.150198] [G loss: 0.553576]\n",
      "[Epoch 10/200] [Batch 134/637] [D loss: 0.149366] [G loss: 0.522748]\n",
      "[Epoch 10/200] [Batch 135/637] [D loss: 0.169761] [G loss: 0.558215]\n",
      "[Epoch 10/200] [Batch 136/637] [D loss: 0.154860] [G loss: 0.569805]\n",
      "[Epoch 10/200] [Batch 137/637] [D loss: 0.183252] [G loss: 0.475145]\n",
      "[Epoch 10/200] [Batch 138/637] [D loss: 0.167023] [G loss: 0.450436]\n",
      "[Epoch 10/200] [Batch 139/637] [D loss: 0.179841] [G loss: 0.447380]\n",
      "[Epoch 10/200] [Batch 140/637] [D loss: 0.148244] [G loss: 0.564003]\n",
      "[Epoch 10/200] [Batch 141/637] [D loss: 0.163954] [G loss: 0.546376]\n",
      "[Epoch 10/200] [Batch 142/637] [D loss: 0.136171] [G loss: 0.545791]\n",
      "[Epoch 10/200] [Batch 143/637] [D loss: 0.174038] [G loss: 0.445015]\n",
      "[Epoch 10/200] [Batch 144/637] [D loss: 0.169508] [G loss: 0.459967]\n",
      "[Epoch 10/200] [Batch 145/637] [D loss: 0.144747] [G loss: 0.516820]\n",
      "[Epoch 10/200] [Batch 146/637] [D loss: 0.147694] [G loss: 0.495696]\n",
      "[Epoch 10/200] [Batch 147/637] [D loss: 0.158419] [G loss: 0.530915]\n",
      "[Epoch 10/200] [Batch 148/637] [D loss: 0.152990] [G loss: 0.514878]\n",
      "[Epoch 10/200] [Batch 149/637] [D loss: 0.182836] [G loss: 0.464366]\n",
      "[Epoch 10/200] [Batch 150/637] [D loss: 0.218644] [G loss: 0.511787]\n",
      "[Epoch 10/200] [Batch 151/637] [D loss: 0.177850] [G loss: 0.538601]\n",
      "[Epoch 10/200] [Batch 152/637] [D loss: 0.169768] [G loss: 0.542908]\n",
      "[Epoch 10/200] [Batch 153/637] [D loss: 0.128442] [G loss: 0.459985]\n",
      "[Epoch 10/200] [Batch 154/637] [D loss: 0.167911] [G loss: 0.413677]\n",
      "[Epoch 10/200] [Batch 155/637] [D loss: 0.134891] [G loss: 0.484448]\n",
      "[Epoch 10/200] [Batch 156/637] [D loss: 0.114978] [G loss: 0.585701]\n",
      "[Epoch 10/200] [Batch 157/637] [D loss: 0.147959] [G loss: 0.544636]\n",
      "[Epoch 10/200] [Batch 158/637] [D loss: 0.130565] [G loss: 0.549437]\n",
      "[Epoch 10/200] [Batch 159/637] [D loss: 0.155134] [G loss: 0.514587]\n",
      "[Epoch 10/200] [Batch 160/637] [D loss: 0.141088] [G loss: 0.576589]\n",
      "[Epoch 10/200] [Batch 161/637] [D loss: 0.131962] [G loss: 0.545660]\n",
      "[Epoch 10/200] [Batch 162/637] [D loss: 0.182640] [G loss: 0.464763]\n",
      "[Epoch 10/200] [Batch 163/637] [D loss: 0.233630] [G loss: 0.543298]\n",
      "[Epoch 10/200] [Batch 164/637] [D loss: 0.175689] [G loss: 0.550009]\n",
      "[Epoch 10/200] [Batch 165/637] [D loss: 0.135978] [G loss: 0.559867]\n",
      "[Epoch 10/200] [Batch 166/637] [D loss: 0.193448] [G loss: 0.427038]\n",
      "[Epoch 10/200] [Batch 167/637] [D loss: 0.167044] [G loss: 0.452295]\n",
      "[Epoch 10/200] [Batch 168/637] [D loss: 0.171052] [G loss: 0.466561]\n",
      "[Epoch 10/200] [Batch 169/637] [D loss: 0.168769] [G loss: 0.473086]\n",
      "[Epoch 10/200] [Batch 170/637] [D loss: 0.157766] [G loss: 0.491840]\n",
      "[Epoch 10/200] [Batch 171/637] [D loss: 0.189313] [G loss: 0.403880]\n",
      "[Epoch 10/200] [Batch 172/637] [D loss: 0.165719] [G loss: 0.484273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 173/637] [D loss: 0.161079] [G loss: 0.487067]\n",
      "[Epoch 10/200] [Batch 174/637] [D loss: 0.162726] [G loss: 0.554478]\n",
      "[Epoch 10/200] [Batch 175/637] [D loss: 0.171843] [G loss: 0.521704]\n",
      "[Epoch 10/200] [Batch 176/637] [D loss: 0.166977] [G loss: 0.491380]\n",
      "[Epoch 10/200] [Batch 177/637] [D loss: 0.158666] [G loss: 0.504991]\n",
      "[Epoch 10/200] [Batch 178/637] [D loss: 0.161736] [G loss: 0.541405]\n",
      "[Epoch 10/200] [Batch 179/637] [D loss: 0.135224] [G loss: 0.614289]\n",
      "[Epoch 10/200] [Batch 180/637] [D loss: 0.139883] [G loss: 0.599645]\n",
      "[Epoch 10/200] [Batch 181/637] [D loss: 0.167515] [G loss: 0.559797]\n",
      "[Epoch 10/200] [Batch 182/637] [D loss: 0.139419] [G loss: 0.583612]\n",
      "[Epoch 10/200] [Batch 183/637] [D loss: 0.163581] [G loss: 0.516777]\n",
      "[Epoch 10/200] [Batch 184/637] [D loss: 0.161756] [G loss: 0.512715]\n",
      "[Epoch 10/200] [Batch 185/637] [D loss: 0.151676] [G loss: 0.581724]\n",
      "[Epoch 10/200] [Batch 186/637] [D loss: 0.168622] [G loss: 0.492196]\n",
      "[Epoch 10/200] [Batch 187/637] [D loss: 0.163007] [G loss: 0.523790]\n",
      "[Epoch 10/200] [Batch 188/637] [D loss: 0.156935] [G loss: 0.589531]\n",
      "[Epoch 10/200] [Batch 189/637] [D loss: 0.160905] [G loss: 0.572310]\n",
      "[Epoch 10/200] [Batch 190/637] [D loss: 0.153520] [G loss: 0.550250]\n",
      "[Epoch 10/200] [Batch 191/637] [D loss: 0.181779] [G loss: 0.527465]\n",
      "[Epoch 10/200] [Batch 192/637] [D loss: 0.165407] [G loss: 0.590852]\n",
      "[Epoch 10/200] [Batch 193/637] [D loss: 0.141040] [G loss: 0.693931]\n",
      "[Epoch 10/200] [Batch 194/637] [D loss: 0.153889] [G loss: 0.495029]\n",
      "[Epoch 10/200] [Batch 195/637] [D loss: 0.162528] [G loss: 0.580522]\n",
      "[Epoch 10/200] [Batch 196/637] [D loss: 0.149168] [G loss: 0.532292]\n",
      "[Epoch 10/200] [Batch 197/637] [D loss: 0.174891] [G loss: 0.536557]\n",
      "[Epoch 10/200] [Batch 198/637] [D loss: 0.134315] [G loss: 0.590892]\n",
      "[Epoch 10/200] [Batch 199/637] [D loss: 0.158096] [G loss: 0.491780]\n",
      "[Epoch 10/200] [Batch 200/637] [D loss: 0.128209] [G loss: 0.523927]\n",
      "[Epoch 10/200] [Batch 201/637] [D loss: 0.142409] [G loss: 0.539900]\n",
      "[Epoch 10/200] [Batch 202/637] [D loss: 0.151442] [G loss: 0.574473]\n",
      "[Epoch 10/200] [Batch 203/637] [D loss: 0.147151] [G loss: 0.597949]\n",
      "[Epoch 10/200] [Batch 204/637] [D loss: 0.156681] [G loss: 0.509851]\n",
      "[Epoch 10/200] [Batch 205/637] [D loss: 0.159030] [G loss: 0.571861]\n",
      "[Epoch 10/200] [Batch 206/637] [D loss: 0.146452] [G loss: 0.592403]\n",
      "[Epoch 10/200] [Batch 207/637] [D loss: 0.161189] [G loss: 0.533070]\n",
      "[Epoch 10/200] [Batch 208/637] [D loss: 0.150420] [G loss: 0.575388]\n",
      "[Epoch 10/200] [Batch 209/637] [D loss: 0.136211] [G loss: 0.487145]\n",
      "[Epoch 10/200] [Batch 210/637] [D loss: 0.138655] [G loss: 0.527211]\n",
      "[Epoch 10/200] [Batch 211/637] [D loss: 0.155002] [G loss: 0.507997]\n",
      "[Epoch 10/200] [Batch 212/637] [D loss: 0.172139] [G loss: 0.680010]\n",
      "[Epoch 10/200] [Batch 213/637] [D loss: 0.124482] [G loss: 0.568060]\n",
      "[Epoch 10/200] [Batch 214/637] [D loss: 0.158767] [G loss: 0.520264]\n",
      "[Epoch 10/200] [Batch 215/637] [D loss: 0.156435] [G loss: 0.540814]\n",
      "[Epoch 10/200] [Batch 216/637] [D loss: 0.159990] [G loss: 0.555248]\n",
      "[Epoch 10/200] [Batch 217/637] [D loss: 0.154833] [G loss: 0.536036]\n",
      "[Epoch 10/200] [Batch 218/637] [D loss: 0.170017] [G loss: 0.512950]\n",
      "[Epoch 10/200] [Batch 219/637] [D loss: 0.160191] [G loss: 0.505413]\n",
      "[Epoch 10/200] [Batch 220/637] [D loss: 0.146665] [G loss: 0.514737]\n",
      "[Epoch 10/200] [Batch 221/637] [D loss: 0.157464] [G loss: 0.486288]\n",
      "[Epoch 10/200] [Batch 222/637] [D loss: 0.143501] [G loss: 0.507999]\n",
      "[Epoch 10/200] [Batch 223/637] [D loss: 0.156761] [G loss: 0.501581]\n",
      "[Epoch 10/200] [Batch 224/637] [D loss: 0.151717] [G loss: 0.551962]\n",
      "[Epoch 10/200] [Batch 225/637] [D loss: 0.156712] [G loss: 0.525921]\n",
      "[Epoch 10/200] [Batch 226/637] [D loss: 0.160043] [G loss: 0.514679]\n",
      "[Epoch 10/200] [Batch 227/637] [D loss: 0.183025] [G loss: 0.409826]\n",
      "[Epoch 10/200] [Batch 228/637] [D loss: 0.237357] [G loss: 0.617596]\n",
      "[Epoch 10/200] [Batch 229/637] [D loss: 0.168285] [G loss: 0.635701]\n",
      "[Epoch 10/200] [Batch 230/637] [D loss: 0.188803] [G loss: 0.498785]\n",
      "[Epoch 10/200] [Batch 231/637] [D loss: 0.159550] [G loss: 0.457147]\n",
      "[Epoch 10/200] [Batch 232/637] [D loss: 0.170535] [G loss: 0.445772]\n",
      "[Epoch 10/200] [Batch 233/637] [D loss: 0.170220] [G loss: 0.418299]\n",
      "[Epoch 10/200] [Batch 234/637] [D loss: 0.158391] [G loss: 0.466421]\n",
      "[Epoch 10/200] [Batch 235/637] [D loss: 0.176489] [G loss: 0.463624]\n",
      "[Epoch 10/200] [Batch 236/637] [D loss: 0.154376] [G loss: 0.517132]\n",
      "[Epoch 10/200] [Batch 237/637] [D loss: 0.154268] [G loss: 0.461882]\n",
      "[Epoch 10/200] [Batch 238/637] [D loss: 0.168662] [G loss: 0.457240]\n",
      "[Epoch 10/200] [Batch 239/637] [D loss: 0.145261] [G loss: 0.496130]\n",
      "[Epoch 10/200] [Batch 240/637] [D loss: 0.163119] [G loss: 0.518292]\n",
      "[Epoch 10/200] [Batch 241/637] [D loss: 0.165933] [G loss: 0.466712]\n",
      "[Epoch 10/200] [Batch 242/637] [D loss: 0.139084] [G loss: 0.532815]\n",
      "[Epoch 10/200] [Batch 243/637] [D loss: 0.139624] [G loss: 0.492633]\n",
      "[Epoch 10/200] [Batch 244/637] [D loss: 0.157501] [G loss: 0.489543]\n",
      "[Epoch 10/200] [Batch 245/637] [D loss: 0.159124] [G loss: 0.458323]\n",
      "[Epoch 10/200] [Batch 246/637] [D loss: 0.164599] [G loss: 0.480743]\n",
      "[Epoch 10/200] [Batch 247/637] [D loss: 0.137737] [G loss: 0.545430]\n",
      "[Epoch 10/200] [Batch 248/637] [D loss: 0.186516] [G loss: 0.426309]\n",
      "[Epoch 10/200] [Batch 249/637] [D loss: 0.159546] [G loss: 0.607704]\n",
      "[Epoch 10/200] [Batch 250/637] [D loss: 0.148763] [G loss: 0.517006]\n",
      "[Epoch 10/200] [Batch 251/637] [D loss: 0.148676] [G loss: 0.504856]\n",
      "[Epoch 10/200] [Batch 252/637] [D loss: 0.130297] [G loss: 0.495103]\n",
      "[Epoch 10/200] [Batch 253/637] [D loss: 0.154707] [G loss: 0.477059]\n",
      "[Epoch 10/200] [Batch 254/637] [D loss: 0.136895] [G loss: 0.532281]\n",
      "[Epoch 10/200] [Batch 255/637] [D loss: 0.147391] [G loss: 0.547930]\n",
      "[Epoch 10/200] [Batch 256/637] [D loss: 0.146217] [G loss: 0.558219]\n",
      "[Epoch 10/200] [Batch 257/637] [D loss: 0.126802] [G loss: 0.528888]\n",
      "[Epoch 10/200] [Batch 258/637] [D loss: 0.135292] [G loss: 0.575857]\n",
      "[Epoch 10/200] [Batch 259/637] [D loss: 0.151051] [G loss: 0.495419]\n",
      "[Epoch 10/200] [Batch 260/637] [D loss: 0.152761] [G loss: 0.525889]\n",
      "[Epoch 10/200] [Batch 261/637] [D loss: 0.185582] [G loss: 0.560508]\n",
      "[Epoch 10/200] [Batch 262/637] [D loss: 0.142425] [G loss: 0.534816]\n",
      "[Epoch 10/200] [Batch 263/637] [D loss: 0.206646] [G loss: 0.468097]\n",
      "[Epoch 10/200] [Batch 264/637] [D loss: 0.215412] [G loss: 0.644814]\n",
      "[Epoch 10/200] [Batch 265/637] [D loss: 0.157999] [G loss: 0.563238]\n",
      "[Epoch 10/200] [Batch 266/637] [D loss: 0.161869] [G loss: 0.501105]\n",
      "[Epoch 10/200] [Batch 267/637] [D loss: 0.144803] [G loss: 0.487980]\n",
      "[Epoch 10/200] [Batch 268/637] [D loss: 0.134057] [G loss: 0.513684]\n",
      "[Epoch 10/200] [Batch 269/637] [D loss: 0.176585] [G loss: 0.543347]\n",
      "[Epoch 10/200] [Batch 270/637] [D loss: 0.159352] [G loss: 0.517333]\n",
      "[Epoch 10/200] [Batch 271/637] [D loss: 0.154756] [G loss: 0.525901]\n",
      "[Epoch 10/200] [Batch 272/637] [D loss: 0.173748] [G loss: 0.459509]\n",
      "[Epoch 10/200] [Batch 273/637] [D loss: 0.161240] [G loss: 0.503011]\n",
      "[Epoch 10/200] [Batch 274/637] [D loss: 0.164555] [G loss: 0.473419]\n",
      "[Epoch 10/200] [Batch 275/637] [D loss: 0.162598] [G loss: 0.529516]\n",
      "[Epoch 10/200] [Batch 276/637] [D loss: 0.170885] [G loss: 0.525521]\n",
      "[Epoch 10/200] [Batch 277/637] [D loss: 0.175745] [G loss: 0.527414]\n",
      "[Epoch 10/200] [Batch 278/637] [D loss: 0.160190] [G loss: 0.615123]\n",
      "[Epoch 10/200] [Batch 279/637] [D loss: 0.175412] [G loss: 0.527861]\n",
      "[Epoch 10/200] [Batch 280/637] [D loss: 0.159084] [G loss: 0.473262]\n",
      "[Epoch 10/200] [Batch 281/637] [D loss: 0.180507] [G loss: 0.419526]\n",
      "[Epoch 10/200] [Batch 282/637] [D loss: 0.180126] [G loss: 0.516823]\n",
      "[Epoch 10/200] [Batch 283/637] [D loss: 0.162304] [G loss: 0.512897]\n",
      "[Epoch 10/200] [Batch 284/637] [D loss: 0.161287] [G loss: 0.540472]\n",
      "[Epoch 10/200] [Batch 285/637] [D loss: 0.146807] [G loss: 0.512551]\n",
      "[Epoch 10/200] [Batch 286/637] [D loss: 0.166752] [G loss: 0.458233]\n",
      "[Epoch 10/200] [Batch 287/637] [D loss: 0.169283] [G loss: 0.530702]\n",
      "[Epoch 10/200] [Batch 288/637] [D loss: 0.145444] [G loss: 0.565035]\n",
      "[Epoch 10/200] [Batch 289/637] [D loss: 0.127916] [G loss: 0.622608]\n",
      "[Epoch 10/200] [Batch 290/637] [D loss: 0.131960] [G loss: 0.501610]\n",
      "[Epoch 10/200] [Batch 291/637] [D loss: 0.124337] [G loss: 0.604040]\n",
      "[Epoch 10/200] [Batch 292/637] [D loss: 0.151532] [G loss: 0.541646]\n",
      "[Epoch 10/200] [Batch 293/637] [D loss: 0.148520] [G loss: 0.546062]\n",
      "[Epoch 10/200] [Batch 294/637] [D loss: 0.135904] [G loss: 0.532607]\n",
      "[Epoch 10/200] [Batch 295/637] [D loss: 0.172786] [G loss: 0.605255]\n",
      "[Epoch 10/200] [Batch 296/637] [D loss: 0.132303] [G loss: 0.586640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 297/637] [D loss: 0.174715] [G loss: 0.486789]\n",
      "[Epoch 10/200] [Batch 298/637] [D loss: 0.164323] [G loss: 0.553693]\n",
      "[Epoch 10/200] [Batch 299/637] [D loss: 0.148751] [G loss: 0.619107]\n",
      "[Epoch 10/200] [Batch 300/637] [D loss: 0.146110] [G loss: 0.529361]\n",
      "[Epoch 10/200] [Batch 301/637] [D loss: 0.149904] [G loss: 0.542646]\n",
      "[Epoch 10/200] [Batch 302/637] [D loss: 0.158784] [G loss: 0.553515]\n",
      "[Epoch 10/200] [Batch 303/637] [D loss: 0.160313] [G loss: 0.467131]\n",
      "[Epoch 10/200] [Batch 304/637] [D loss: 0.150687] [G loss: 0.545281]\n",
      "[Epoch 10/200] [Batch 305/637] [D loss: 0.146065] [G loss: 0.512513]\n",
      "[Epoch 10/200] [Batch 306/637] [D loss: 0.143072] [G loss: 0.488164]\n",
      "[Epoch 10/200] [Batch 307/637] [D loss: 0.149652] [G loss: 0.511659]\n",
      "[Epoch 10/200] [Batch 308/637] [D loss: 0.159148] [G loss: 0.493655]\n",
      "[Epoch 10/200] [Batch 309/637] [D loss: 0.158606] [G loss: 0.517489]\n",
      "[Epoch 10/200] [Batch 310/637] [D loss: 0.156325] [G loss: 0.518481]\n",
      "[Epoch 10/200] [Batch 311/637] [D loss: 0.155387] [G loss: 0.524984]\n",
      "[Epoch 10/200] [Batch 312/637] [D loss: 0.170117] [G loss: 0.453863]\n",
      "[Epoch 10/200] [Batch 313/637] [D loss: 0.178245] [G loss: 0.512313]\n",
      "[Epoch 10/200] [Batch 314/637] [D loss: 0.148531] [G loss: 0.488129]\n",
      "[Epoch 10/200] [Batch 315/637] [D loss: 0.146414] [G loss: 0.472355]\n",
      "[Epoch 10/200] [Batch 316/637] [D loss: 0.167762] [G loss: 0.502027]\n",
      "[Epoch 10/200] [Batch 317/637] [D loss: 0.160205] [G loss: 0.495323]\n",
      "[Epoch 10/200] [Batch 318/637] [D loss: 0.155848] [G loss: 0.545399]\n",
      "[Epoch 10/200] [Batch 319/637] [D loss: 0.164304] [G loss: 0.571423]\n",
      "[Epoch 10/200] [Batch 320/637] [D loss: 0.168820] [G loss: 0.585550]\n",
      "[Epoch 10/200] [Batch 321/637] [D loss: 0.154379] [G loss: 0.534103]\n",
      "[Epoch 10/200] [Batch 322/637] [D loss: 0.130660] [G loss: 0.493598]\n",
      "[Epoch 10/200] [Batch 323/637] [D loss: 0.147116] [G loss: 0.501534]\n",
      "[Epoch 10/200] [Batch 324/637] [D loss: 0.150249] [G loss: 0.522884]\n",
      "[Epoch 10/200] [Batch 325/637] [D loss: 0.157819] [G loss: 0.543101]\n",
      "[Epoch 10/200] [Batch 326/637] [D loss: 0.135574] [G loss: 0.634208]\n",
      "[Epoch 10/200] [Batch 327/637] [D loss: 0.123121] [G loss: 0.698924]\n",
      "[Epoch 10/200] [Batch 328/637] [D loss: 0.155300] [G loss: 0.574308]\n",
      "[Epoch 10/200] [Batch 329/637] [D loss: 0.138952] [G loss: 0.524531]\n",
      "[Epoch 10/200] [Batch 330/637] [D loss: 0.142338] [G loss: 0.498900]\n",
      "[Epoch 10/200] [Batch 331/637] [D loss: 0.142745] [G loss: 0.524798]\n",
      "[Epoch 10/200] [Batch 332/637] [D loss: 0.173218] [G loss: 0.427922]\n",
      "[Epoch 10/200] [Batch 333/637] [D loss: 0.174654] [G loss: 0.504407]\n",
      "[Epoch 10/200] [Batch 334/637] [D loss: 0.151811] [G loss: 0.527098]\n",
      "[Epoch 10/200] [Batch 335/637] [D loss: 0.162952] [G loss: 0.526348]\n",
      "[Epoch 10/200] [Batch 336/637] [D loss: 0.138968] [G loss: 0.537877]\n",
      "[Epoch 10/200] [Batch 337/637] [D loss: 0.206105] [G loss: 0.559036]\n",
      "[Epoch 10/200] [Batch 338/637] [D loss: 0.160019] [G loss: 0.563015]\n",
      "[Epoch 10/200] [Batch 339/637] [D loss: 0.213628] [G loss: 0.459269]\n",
      "[Epoch 10/200] [Batch 340/637] [D loss: 0.185021] [G loss: 0.565862]\n",
      "[Epoch 10/200] [Batch 341/637] [D loss: 0.171244] [G loss: 0.507514]\n",
      "[Epoch 10/200] [Batch 342/637] [D loss: 0.170332] [G loss: 0.456963]\n",
      "[Epoch 10/200] [Batch 343/637] [D loss: 0.157830] [G loss: 0.428073]\n",
      "[Epoch 10/200] [Batch 344/637] [D loss: 0.155838] [G loss: 0.433443]\n",
      "[Epoch 10/200] [Batch 345/637] [D loss: 0.146313] [G loss: 0.514569]\n",
      "[Epoch 10/200] [Batch 346/637] [D loss: 0.141549] [G loss: 0.470966]\n",
      "[Epoch 10/200] [Batch 347/637] [D loss: 0.192241] [G loss: 0.421867]\n",
      "[Epoch 10/200] [Batch 348/637] [D loss: 0.152506] [G loss: 0.545569]\n",
      "[Epoch 10/200] [Batch 349/637] [D loss: 0.158877] [G loss: 0.562390]\n",
      "[Epoch 10/200] [Batch 350/637] [D loss: 0.131826] [G loss: 0.571122]\n",
      "[Epoch 10/200] [Batch 351/637] [D loss: 0.139126] [G loss: 0.508517]\n",
      "[Epoch 10/200] [Batch 352/637] [D loss: 0.142001] [G loss: 0.520516]\n",
      "[Epoch 10/200] [Batch 353/637] [D loss: 0.139817] [G loss: 0.510715]\n",
      "[Epoch 10/200] [Batch 354/637] [D loss: 0.154664] [G loss: 0.512358]\n",
      "[Epoch 10/200] [Batch 355/637] [D loss: 0.166354] [G loss: 0.588982]\n",
      "[Epoch 10/200] [Batch 356/637] [D loss: 0.174565] [G loss: 0.506014]\n",
      "[Epoch 10/200] [Batch 357/637] [D loss: 0.223410] [G loss: 0.592039]\n",
      "[Epoch 10/200] [Batch 358/637] [D loss: 0.167505] [G loss: 0.550603]\n",
      "[Epoch 10/200] [Batch 359/637] [D loss: 0.160475] [G loss: 0.556292]\n",
      "[Epoch 10/200] [Batch 360/637] [D loss: 0.197164] [G loss: 0.449216]\n",
      "[Epoch 10/200] [Batch 361/637] [D loss: 0.174570] [G loss: 0.495827]\n",
      "[Epoch 10/200] [Batch 362/637] [D loss: 0.158036] [G loss: 0.494576]\n",
      "[Epoch 10/200] [Batch 363/637] [D loss: 0.153388] [G loss: 0.513306]\n",
      "[Epoch 10/200] [Batch 364/637] [D loss: 0.167137] [G loss: 0.444946]\n",
      "[Epoch 10/200] [Batch 365/637] [D loss: 0.172661] [G loss: 0.485779]\n",
      "[Epoch 10/200] [Batch 366/637] [D loss: 0.133124] [G loss: 0.497264]\n",
      "[Epoch 10/200] [Batch 367/637] [D loss: 0.166676] [G loss: 0.512707]\n",
      "[Epoch 10/200] [Batch 368/637] [D loss: 0.148181] [G loss: 0.517764]\n",
      "[Epoch 10/200] [Batch 369/637] [D loss: 0.172615] [G loss: 0.521035]\n",
      "[Epoch 10/200] [Batch 370/637] [D loss: 0.166651] [G loss: 0.509492]\n",
      "[Epoch 10/200] [Batch 371/637] [D loss: 0.165955] [G loss: 0.537920]\n",
      "[Epoch 10/200] [Batch 372/637] [D loss: 0.174923] [G loss: 0.520079]\n",
      "[Epoch 10/200] [Batch 373/637] [D loss: 0.142553] [G loss: 0.606430]\n",
      "[Epoch 10/200] [Batch 374/637] [D loss: 0.154880] [G loss: 0.507137]\n",
      "[Epoch 10/200] [Batch 375/637] [D loss: 0.154404] [G loss: 0.490366]\n",
      "[Epoch 10/200] [Batch 376/637] [D loss: 0.170944] [G loss: 0.482619]\n",
      "[Epoch 10/200] [Batch 377/637] [D loss: 0.154880] [G loss: 0.506093]\n",
      "[Epoch 10/200] [Batch 378/637] [D loss: 0.136364] [G loss: 0.619925]\n",
      "[Epoch 10/200] [Batch 379/637] [D loss: 0.162308] [G loss: 0.548838]\n",
      "[Epoch 10/200] [Batch 380/637] [D loss: 0.171022] [G loss: 0.539319]\n",
      "[Epoch 10/200] [Batch 381/637] [D loss: 0.161335] [G loss: 0.505572]\n",
      "[Epoch 10/200] [Batch 382/637] [D loss: 0.179357] [G loss: 0.420964]\n",
      "[Epoch 10/200] [Batch 383/637] [D loss: 0.161441] [G loss: 0.532024]\n",
      "[Epoch 10/200] [Batch 384/637] [D loss: 0.146379] [G loss: 0.551214]\n",
      "[Epoch 10/200] [Batch 385/637] [D loss: 0.181310] [G loss: 0.502955]\n",
      "[Epoch 10/200] [Batch 386/637] [D loss: 0.163589] [G loss: 0.487253]\n",
      "[Epoch 10/200] [Batch 387/637] [D loss: 0.164021] [G loss: 0.457876]\n",
      "[Epoch 10/200] [Batch 388/637] [D loss: 0.166411] [G loss: 0.421924]\n",
      "[Epoch 10/200] [Batch 389/637] [D loss: 0.165037] [G loss: 0.466852]\n",
      "[Epoch 10/200] [Batch 390/637] [D loss: 0.162448] [G loss: 0.519219]\n",
      "[Epoch 10/200] [Batch 391/637] [D loss: 0.156280] [G loss: 0.503315]\n",
      "[Epoch 10/200] [Batch 392/637] [D loss: 0.159138] [G loss: 0.421870]\n",
      "[Epoch 10/200] [Batch 393/637] [D loss: 0.185561] [G loss: 0.498482]\n",
      "[Epoch 10/200] [Batch 394/637] [D loss: 0.163315] [G loss: 0.563596]\n",
      "[Epoch 10/200] [Batch 395/637] [D loss: 0.169581] [G loss: 0.537484]\n",
      "[Epoch 10/200] [Batch 396/637] [D loss: 0.148358] [G loss: 0.477502]\n",
      "[Epoch 10/200] [Batch 397/637] [D loss: 0.162431] [G loss: 0.451288]\n",
      "[Epoch 10/200] [Batch 398/637] [D loss: 0.156040] [G loss: 0.464139]\n",
      "[Epoch 10/200] [Batch 399/637] [D loss: 0.169626] [G loss: 0.496906]\n",
      "[Epoch 10/200] [Batch 400/637] [D loss: 0.203614] [G loss: 0.542010]\n",
      "[Epoch 10/200] [Batch 401/637] [D loss: 0.165044] [G loss: 0.629490]\n",
      "[Epoch 10/200] [Batch 402/637] [D loss: 0.176976] [G loss: 0.572919]\n",
      "[Epoch 10/200] [Batch 403/637] [D loss: 0.159974] [G loss: 0.487916]\n",
      "[Epoch 10/200] [Batch 404/637] [D loss: 0.128767] [G loss: 0.554347]\n",
      "[Epoch 10/200] [Batch 405/637] [D loss: 0.137118] [G loss: 0.524986]\n",
      "[Epoch 10/200] [Batch 406/637] [D loss: 0.128878] [G loss: 0.544628]\n",
      "[Epoch 10/200] [Batch 407/637] [D loss: 0.141426] [G loss: 0.644320]\n",
      "[Epoch 10/200] [Batch 408/637] [D loss: 0.154203] [G loss: 0.531309]\n",
      "[Epoch 10/200] [Batch 409/637] [D loss: 0.166734] [G loss: 0.453379]\n",
      "[Epoch 10/200] [Batch 410/637] [D loss: 0.131157] [G loss: 0.556216]\n",
      "[Epoch 10/200] [Batch 411/637] [D loss: 0.130423] [G loss: 0.573014]\n",
      "[Epoch 10/200] [Batch 412/637] [D loss: 0.163620] [G loss: 0.510977]\n",
      "[Epoch 10/200] [Batch 413/637] [D loss: 0.131440] [G loss: 0.494550]\n",
      "[Epoch 10/200] [Batch 414/637] [D loss: 0.167326] [G loss: 0.482448]\n",
      "[Epoch 10/200] [Batch 415/637] [D loss: 0.132882] [G loss: 0.546281]\n",
      "[Epoch 10/200] [Batch 416/637] [D loss: 0.178568] [G loss: 0.438193]\n",
      "[Epoch 10/200] [Batch 417/637] [D loss: 0.223865] [G loss: 0.605009]\n",
      "[Epoch 10/200] [Batch 418/637] [D loss: 0.170345] [G loss: 0.554248]\n",
      "[Epoch 10/200] [Batch 419/637] [D loss: 0.168400] [G loss: 0.519825]\n",
      "[Epoch 10/200] [Batch 420/637] [D loss: 0.198862] [G loss: 0.478978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 421/637] [D loss: 0.168207] [G loss: 0.447018]\n",
      "[Epoch 10/200] [Batch 422/637] [D loss: 0.176354] [G loss: 0.461647]\n",
      "[Epoch 10/200] [Batch 423/637] [D loss: 0.157975] [G loss: 0.450781]\n",
      "[Epoch 10/200] [Batch 424/637] [D loss: 0.140889] [G loss: 0.503765]\n",
      "[Epoch 10/200] [Batch 425/637] [D loss: 0.173782] [G loss: 0.448923]\n",
      "[Epoch 10/200] [Batch 426/637] [D loss: 0.168397] [G loss: 0.477433]\n",
      "[Epoch 10/200] [Batch 427/637] [D loss: 0.149388] [G loss: 0.549247]\n",
      "[Epoch 10/200] [Batch 428/637] [D loss: 0.153165] [G loss: 0.454796]\n",
      "[Epoch 10/200] [Batch 429/637] [D loss: 0.162480] [G loss: 0.496106]\n",
      "[Epoch 10/200] [Batch 430/637] [D loss: 0.158596] [G loss: 0.497502]\n",
      "[Epoch 10/200] [Batch 431/637] [D loss: 0.147672] [G loss: 0.532520]\n",
      "[Epoch 10/200] [Batch 432/637] [D loss: 0.136132] [G loss: 0.518384]\n",
      "[Epoch 10/200] [Batch 433/637] [D loss: 0.149797] [G loss: 0.540873]\n",
      "[Epoch 10/200] [Batch 434/637] [D loss: 0.141638] [G loss: 0.540611]\n",
      "[Epoch 10/200] [Batch 435/637] [D loss: 0.162314] [G loss: 0.438230]\n",
      "[Epoch 10/200] [Batch 436/637] [D loss: 0.173699] [G loss: 0.532805]\n",
      "[Epoch 10/200] [Batch 437/637] [D loss: 0.147825] [G loss: 0.527146]\n",
      "[Epoch 10/200] [Batch 438/637] [D loss: 0.171533] [G loss: 0.480484]\n",
      "[Epoch 10/200] [Batch 439/637] [D loss: 0.177488] [G loss: 0.562738]\n",
      "[Epoch 10/200] [Batch 440/637] [D loss: 0.135833] [G loss: 0.539699]\n",
      "[Epoch 10/200] [Batch 441/637] [D loss: 0.165926] [G loss: 0.480731]\n",
      "[Epoch 10/200] [Batch 442/637] [D loss: 0.140270] [G loss: 0.531167]\n",
      "[Epoch 10/200] [Batch 443/637] [D loss: 0.133595] [G loss: 0.601199]\n",
      "[Epoch 10/200] [Batch 444/637] [D loss: 0.143201] [G loss: 0.547814]\n",
      "[Epoch 10/200] [Batch 445/637] [D loss: 0.169908] [G loss: 0.422148]\n",
      "[Epoch 10/200] [Batch 446/637] [D loss: 0.164046] [G loss: 0.570099]\n",
      "[Epoch 10/200] [Batch 447/637] [D loss: 0.149297] [G loss: 0.707507]\n",
      "[Epoch 10/200] [Batch 448/637] [D loss: 0.142811] [G loss: 0.575532]\n",
      "[Epoch 10/200] [Batch 449/637] [D loss: 0.150736] [G loss: 0.512135]\n",
      "[Epoch 10/200] [Batch 450/637] [D loss: 0.187010] [G loss: 0.549469]\n",
      "[Epoch 10/200] [Batch 451/637] [D loss: 0.184917] [G loss: 0.565796]\n",
      "[Epoch 10/200] [Batch 452/637] [D loss: 0.130293] [G loss: 0.595307]\n",
      "[Epoch 10/200] [Batch 453/637] [D loss: 0.146963] [G loss: 0.541898]\n",
      "[Epoch 10/200] [Batch 454/637] [D loss: 0.200814] [G loss: 0.521446]\n",
      "[Epoch 10/200] [Batch 455/637] [D loss: 0.247084] [G loss: 0.702236]\n",
      "[Epoch 10/200] [Batch 456/637] [D loss: 0.164055] [G loss: 0.621273]\n",
      "[Epoch 10/200] [Batch 457/637] [D loss: 0.168340] [G loss: 0.473236]\n",
      "[Epoch 10/200] [Batch 458/637] [D loss: 0.168611] [G loss: 0.472612]\n",
      "[Epoch 10/200] [Batch 459/637] [D loss: 0.172263] [G loss: 0.481864]\n",
      "[Epoch 10/200] [Batch 460/637] [D loss: 0.182246] [G loss: 0.530294]\n",
      "[Epoch 10/200] [Batch 461/637] [D loss: 0.171865] [G loss: 0.497113]\n",
      "[Epoch 10/200] [Batch 462/637] [D loss: 0.158872] [G loss: 0.497439]\n",
      "[Epoch 10/200] [Batch 463/637] [D loss: 0.164314] [G loss: 0.487394]\n",
      "[Epoch 10/200] [Batch 464/637] [D loss: 0.146832] [G loss: 0.554482]\n",
      "[Epoch 10/200] [Batch 465/637] [D loss: 0.146937] [G loss: 0.562581]\n",
      "[Epoch 10/200] [Batch 466/637] [D loss: 0.158949] [G loss: 0.491826]\n",
      "[Epoch 10/200] [Batch 467/637] [D loss: 0.172401] [G loss: 0.480808]\n",
      "[Epoch 10/200] [Batch 468/637] [D loss: 0.168296] [G loss: 0.529397]\n",
      "[Epoch 10/200] [Batch 469/637] [D loss: 0.155406] [G loss: 0.560317]\n",
      "[Epoch 10/200] [Batch 470/637] [D loss: 0.169566] [G loss: 0.514816]\n",
      "[Epoch 10/200] [Batch 471/637] [D loss: 0.168498] [G loss: 0.571530]\n",
      "[Epoch 10/200] [Batch 472/637] [D loss: 0.149603] [G loss: 0.550107]\n",
      "[Epoch 10/200] [Batch 473/637] [D loss: 0.154358] [G loss: 0.489132]\n",
      "[Epoch 10/200] [Batch 474/637] [D loss: 0.162903] [G loss: 0.504200]\n",
      "[Epoch 10/200] [Batch 475/637] [D loss: 0.163345] [G loss: 0.529299]\n",
      "[Epoch 10/200] [Batch 476/637] [D loss: 0.177757] [G loss: 0.506878]\n",
      "[Epoch 10/200] [Batch 477/637] [D loss: 0.141720] [G loss: 0.520043]\n",
      "[Epoch 10/200] [Batch 478/637] [D loss: 0.183689] [G loss: 0.475843]\n",
      "[Epoch 10/200] [Batch 479/637] [D loss: 0.197766] [G loss: 0.618897]\n",
      "[Epoch 10/200] [Batch 480/637] [D loss: 0.157252] [G loss: 0.622160]\n",
      "[Epoch 10/200] [Batch 481/637] [D loss: 0.158237] [G loss: 0.527716]\n",
      "[Epoch 10/200] [Batch 482/637] [D loss: 0.175936] [G loss: 0.490753]\n",
      "[Epoch 10/200] [Batch 483/637] [D loss: 0.164313] [G loss: 0.481126]\n",
      "[Epoch 10/200] [Batch 484/637] [D loss: 0.137115] [G loss: 0.497894]\n",
      "[Epoch 10/200] [Batch 485/637] [D loss: 0.148790] [G loss: 0.570761]\n",
      "[Epoch 10/200] [Batch 486/637] [D loss: 0.124083] [G loss: 0.573034]\n",
      "[Epoch 10/200] [Batch 487/637] [D loss: 0.143470] [G loss: 0.510523]\n",
      "[Epoch 10/200] [Batch 488/637] [D loss: 0.174991] [G loss: 0.459818]\n",
      "[Epoch 10/200] [Batch 489/637] [D loss: 0.128286] [G loss: 0.575657]\n",
      "[Epoch 10/200] [Batch 490/637] [D loss: 0.150766] [G loss: 0.557467]\n",
      "[Epoch 10/200] [Batch 491/637] [D loss: 0.150150] [G loss: 0.550709]\n",
      "[Epoch 10/200] [Batch 492/637] [D loss: 0.157397] [G loss: 0.516600]\n",
      "[Epoch 10/200] [Batch 493/637] [D loss: 0.156470] [G loss: 0.557363]\n",
      "[Epoch 10/200] [Batch 494/637] [D loss: 0.140127] [G loss: 0.559554]\n",
      "[Epoch 10/200] [Batch 495/637] [D loss: 0.192964] [G loss: 0.497384]\n",
      "[Epoch 10/200] [Batch 496/637] [D loss: 0.140378] [G loss: 0.579516]\n",
      "[Epoch 10/200] [Batch 497/637] [D loss: 0.133876] [G loss: 0.621497]\n",
      "[Epoch 10/200] [Batch 498/637] [D loss: 0.167815] [G loss: 0.490081]\n",
      "[Epoch 10/200] [Batch 499/637] [D loss: 0.151756] [G loss: 0.541080]\n",
      "[Epoch 10/200] [Batch 500/637] [D loss: 0.157196] [G loss: 0.570863]\n",
      "[Epoch 10/200] [Batch 501/637] [D loss: 0.208821] [G loss: 0.445352]\n",
      "[Epoch 10/200] [Batch 502/637] [D loss: 0.171257] [G loss: 0.541830]\n",
      "[Epoch 10/200] [Batch 503/637] [D loss: 0.156419] [G loss: 0.645498]\n",
      "[Epoch 10/200] [Batch 504/637] [D loss: 0.152266] [G loss: 0.614723]\n",
      "[Epoch 10/200] [Batch 505/637] [D loss: 0.156347] [G loss: 0.548852]\n",
      "[Epoch 10/200] [Batch 506/637] [D loss: 0.169186] [G loss: 0.490980]\n",
      "[Epoch 10/200] [Batch 507/637] [D loss: 0.174397] [G loss: 0.552447]\n",
      "[Epoch 10/200] [Batch 508/637] [D loss: 0.160618] [G loss: 0.546829]\n",
      "[Epoch 10/200] [Batch 509/637] [D loss: 0.182240] [G loss: 0.497128]\n",
      "[Epoch 10/200] [Batch 510/637] [D loss: 0.209797] [G loss: 0.497154]\n",
      "[Epoch 10/200] [Batch 511/637] [D loss: 0.153073] [G loss: 0.590353]\n",
      "[Epoch 10/200] [Batch 512/637] [D loss: 0.185099] [G loss: 0.516191]\n",
      "[Epoch 10/200] [Batch 513/637] [D loss: 0.171555] [G loss: 0.449049]\n",
      "[Epoch 10/200] [Batch 514/637] [D loss: 0.180718] [G loss: 0.466236]\n",
      "[Epoch 10/200] [Batch 515/637] [D loss: 0.170362] [G loss: 0.484310]\n",
      "[Epoch 10/200] [Batch 516/637] [D loss: 0.156252] [G loss: 0.494517]\n",
      "[Epoch 10/200] [Batch 517/637] [D loss: 0.162022] [G loss: 0.483916]\n",
      "[Epoch 10/200] [Batch 518/637] [D loss: 0.185895] [G loss: 0.436004]\n",
      "[Epoch 10/200] [Batch 519/637] [D loss: 0.170580] [G loss: 0.538267]\n",
      "[Epoch 10/200] [Batch 520/637] [D loss: 0.151686] [G loss: 0.617598]\n",
      "[Epoch 10/200] [Batch 521/637] [D loss: 0.141704] [G loss: 0.542958]\n",
      "[Epoch 10/200] [Batch 522/637] [D loss: 0.132139] [G loss: 0.595578]\n",
      "[Epoch 10/200] [Batch 523/637] [D loss: 0.167399] [G loss: 0.517072]\n",
      "[Epoch 10/200] [Batch 524/637] [D loss: 0.186270] [G loss: 0.461289]\n",
      "[Epoch 10/200] [Batch 525/637] [D loss: 0.159152] [G loss: 0.672996]\n",
      "[Epoch 10/200] [Batch 526/637] [D loss: 0.146020] [G loss: 0.622090]\n",
      "[Epoch 10/200] [Batch 527/637] [D loss: 0.165780] [G loss: 0.556684]\n",
      "[Epoch 10/200] [Batch 528/637] [D loss: 0.161862] [G loss: 0.542804]\n",
      "[Epoch 10/200] [Batch 529/637] [D loss: 0.136344] [G loss: 0.505007]\n",
      "[Epoch 10/200] [Batch 530/637] [D loss: 0.148581] [G loss: 0.504384]\n",
      "[Epoch 10/200] [Batch 531/637] [D loss: 0.132383] [G loss: 0.533185]\n",
      "[Epoch 10/200] [Batch 532/637] [D loss: 0.139049] [G loss: 0.507544]\n",
      "[Epoch 10/200] [Batch 533/637] [D loss: 0.180645] [G loss: 0.438643]\n",
      "[Epoch 10/200] [Batch 534/637] [D loss: 0.142790] [G loss: 0.581464]\n",
      "[Epoch 10/200] [Batch 535/637] [D loss: 0.181826] [G loss: 0.497918]\n",
      "[Epoch 10/200] [Batch 536/637] [D loss: 0.149558] [G loss: 0.492513]\n",
      "[Epoch 10/200] [Batch 537/637] [D loss: 0.144560] [G loss: 0.516341]\n",
      "[Epoch 10/200] [Batch 538/637] [D loss: 0.153294] [G loss: 0.421988]\n",
      "[Epoch 10/200] [Batch 539/637] [D loss: 0.153116] [G loss: 0.451443]\n",
      "[Epoch 10/200] [Batch 540/637] [D loss: 0.145809] [G loss: 0.502094]\n",
      "[Epoch 10/200] [Batch 541/637] [D loss: 0.146270] [G loss: 0.509464]\n",
      "[Epoch 10/200] [Batch 542/637] [D loss: 0.157532] [G loss: 0.539093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 543/637] [D loss: 0.180246] [G loss: 0.495338]\n",
      "[Epoch 10/200] [Batch 544/637] [D loss: 0.175166] [G loss: 0.485061]\n",
      "[Epoch 10/200] [Batch 545/637] [D loss: 0.190673] [G loss: 0.398850]\n",
      "[Epoch 10/200] [Batch 546/637] [D loss: 0.169431] [G loss: 0.488435]\n",
      "[Epoch 10/200] [Batch 547/637] [D loss: 0.169815] [G loss: 0.523510]\n",
      "[Epoch 10/200] [Batch 548/637] [D loss: 0.161566] [G loss: 0.490695]\n",
      "[Epoch 10/200] [Batch 549/637] [D loss: 0.168291] [G loss: 0.570439]\n",
      "[Epoch 10/200] [Batch 550/637] [D loss: 0.168804] [G loss: 0.518104]\n",
      "[Epoch 10/200] [Batch 551/637] [D loss: 0.155474] [G loss: 0.455843]\n",
      "[Epoch 10/200] [Batch 552/637] [D loss: 0.170581] [G loss: 0.484875]\n",
      "[Epoch 10/200] [Batch 553/637] [D loss: 0.160207] [G loss: 0.524176]\n",
      "[Epoch 10/200] [Batch 554/637] [D loss: 0.135909] [G loss: 0.563803]\n",
      "[Epoch 10/200] [Batch 555/637] [D loss: 0.136938] [G loss: 0.516579]\n",
      "[Epoch 10/200] [Batch 556/637] [D loss: 0.163979] [G loss: 0.477600]\n",
      "[Epoch 10/200] [Batch 557/637] [D loss: 0.166946] [G loss: 0.511721]\n",
      "[Epoch 10/200] [Batch 558/637] [D loss: 0.158655] [G loss: 0.524280]\n",
      "[Epoch 10/200] [Batch 559/637] [D loss: 0.173497] [G loss: 0.484221]\n",
      "[Epoch 10/200] [Batch 560/637] [D loss: 0.150117] [G loss: 0.535604]\n",
      "[Epoch 10/200] [Batch 561/637] [D loss: 0.199467] [G loss: 0.433102]\n",
      "[Epoch 10/200] [Batch 562/637] [D loss: 0.190737] [G loss: 0.587528]\n",
      "[Epoch 10/200] [Batch 563/637] [D loss: 0.145336] [G loss: 0.607141]\n",
      "[Epoch 10/200] [Batch 564/637] [D loss: 0.111079] [G loss: 0.563206]\n",
      "[Epoch 10/200] [Batch 565/637] [D loss: 0.177523] [G loss: 0.452116]\n",
      "[Epoch 10/200] [Batch 566/637] [D loss: 0.146890] [G loss: 0.533800]\n",
      "[Epoch 10/200] [Batch 567/637] [D loss: 0.148825] [G loss: 0.590109]\n",
      "[Epoch 10/200] [Batch 568/637] [D loss: 0.160545] [G loss: 0.549505]\n",
      "[Epoch 10/200] [Batch 569/637] [D loss: 0.147984] [G loss: 0.531701]\n",
      "[Epoch 10/200] [Batch 570/637] [D loss: 0.161760] [G loss: 0.549710]\n",
      "[Epoch 10/200] [Batch 571/637] [D loss: 0.172889] [G loss: 0.480568]\n",
      "[Epoch 10/200] [Batch 572/637] [D loss: 0.153256] [G loss: 0.603745]\n",
      "[Epoch 10/200] [Batch 573/637] [D loss: 0.160015] [G loss: 0.596873]\n",
      "[Epoch 10/200] [Batch 574/637] [D loss: 0.169422] [G loss: 0.509585]\n",
      "[Epoch 10/200] [Batch 575/637] [D loss: 0.208324] [G loss: 0.402093]\n",
      "[Epoch 10/200] [Batch 576/637] [D loss: 0.146572] [G loss: 0.470025]\n",
      "[Epoch 10/200] [Batch 577/637] [D loss: 0.162392] [G loss: 0.443023]\n",
      "[Epoch 10/200] [Batch 578/637] [D loss: 0.142514] [G loss: 0.497163]\n",
      "[Epoch 10/200] [Batch 579/637] [D loss: 0.147273] [G loss: 0.516129]\n",
      "[Epoch 10/200] [Batch 580/637] [D loss: 0.149552] [G loss: 0.516966]\n",
      "[Epoch 10/200] [Batch 581/637] [D loss: 0.167302] [G loss: 0.446195]\n",
      "[Epoch 10/200] [Batch 582/637] [D loss: 0.173744] [G loss: 0.463265]\n",
      "[Epoch 10/200] [Batch 583/637] [D loss: 0.164483] [G loss: 0.458782]\n",
      "[Epoch 10/200] [Batch 584/637] [D loss: 0.185018] [G loss: 0.519556]\n",
      "[Epoch 10/200] [Batch 585/637] [D loss: 0.191294] [G loss: 0.520073]\n",
      "[Epoch 10/200] [Batch 586/637] [D loss: 0.148155] [G loss: 0.530766]\n",
      "[Epoch 10/200] [Batch 587/637] [D loss: 0.150957] [G loss: 0.503954]\n",
      "[Epoch 10/200] [Batch 588/637] [D loss: 0.145333] [G loss: 0.530771]\n",
      "[Epoch 10/200] [Batch 589/637] [D loss: 0.144938] [G loss: 0.533472]\n",
      "[Epoch 10/200] [Batch 590/637] [D loss: 0.149800] [G loss: 0.483853]\n",
      "[Epoch 10/200] [Batch 591/637] [D loss: 0.156801] [G loss: 0.510834]\n",
      "[Epoch 10/200] [Batch 592/637] [D loss: 0.138668] [G loss: 0.507554]\n",
      "[Epoch 10/200] [Batch 593/637] [D loss: 0.148173] [G loss: 0.564862]\n",
      "[Epoch 10/200] [Batch 594/637] [D loss: 0.144923] [G loss: 0.530034]\n",
      "[Epoch 10/200] [Batch 595/637] [D loss: 0.174352] [G loss: 0.431719]\n",
      "[Epoch 10/200] [Batch 596/637] [D loss: 0.183657] [G loss: 0.626096]\n",
      "[Epoch 10/200] [Batch 597/637] [D loss: 0.155454] [G loss: 0.615979]\n",
      "[Epoch 10/200] [Batch 598/637] [D loss: 0.132188] [G loss: 0.554539]\n",
      "[Epoch 10/200] [Batch 599/637] [D loss: 0.132492] [G loss: 0.501414]\n",
      "[Epoch 10/200] [Batch 600/637] [D loss: 0.127955] [G loss: 0.506061]\n",
      "[Epoch 10/200] [Batch 601/637] [D loss: 0.128419] [G loss: 0.573359]\n",
      "[Epoch 10/200] [Batch 602/637] [D loss: 0.122835] [G loss: 0.556314]\n",
      "[Epoch 10/200] [Batch 603/637] [D loss: 0.169796] [G loss: 0.463353]\n",
      "[Epoch 10/200] [Batch 604/637] [D loss: 0.206713] [G loss: 0.581344]\n",
      "[Epoch 10/200] [Batch 605/637] [D loss: 0.172711] [G loss: 0.572865]\n",
      "[Epoch 10/200] [Batch 606/637] [D loss: 0.167913] [G loss: 0.561306]\n",
      "[Epoch 10/200] [Batch 607/637] [D loss: 0.165352] [G loss: 0.521008]\n",
      "[Epoch 10/200] [Batch 608/637] [D loss: 0.182431] [G loss: 0.497324]\n",
      "[Epoch 10/200] [Batch 609/637] [D loss: 0.158092] [G loss: 0.511600]\n",
      "[Epoch 10/200] [Batch 610/637] [D loss: 0.173035] [G loss: 0.434112]\n",
      "[Epoch 10/200] [Batch 611/637] [D loss: 0.166818] [G loss: 0.481074]\n",
      "[Epoch 10/200] [Batch 612/637] [D loss: 0.178691] [G loss: 0.402839]\n",
      "[Epoch 10/200] [Batch 613/637] [D loss: 0.158119] [G loss: 0.457958]\n",
      "[Epoch 10/200] [Batch 614/637] [D loss: 0.148556] [G loss: 0.544780]\n",
      "[Epoch 10/200] [Batch 615/637] [D loss: 0.165010] [G loss: 0.465196]\n",
      "[Epoch 10/200] [Batch 616/637] [D loss: 0.164437] [G loss: 0.458138]\n",
      "[Epoch 10/200] [Batch 617/637] [D loss: 0.179479] [G loss: 0.419353]\n",
      "[Epoch 10/200] [Batch 618/637] [D loss: 0.213298] [G loss: 0.759935]\n",
      "[Epoch 10/200] [Batch 619/637] [D loss: 0.230787] [G loss: 0.541658]\n",
      "[Epoch 10/200] [Batch 620/637] [D loss: 0.156065] [G loss: 0.524696]\n",
      "[Epoch 10/200] [Batch 621/637] [D loss: 0.184297] [G loss: 0.465351]\n",
      "[Epoch 10/200] [Batch 622/637] [D loss: 0.154535] [G loss: 0.461328]\n",
      "[Epoch 10/200] [Batch 623/637] [D loss: 0.162920] [G loss: 0.480300]\n",
      "[Epoch 10/200] [Batch 624/637] [D loss: 0.148513] [G loss: 0.524342]\n",
      "[Epoch 10/200] [Batch 625/637] [D loss: 0.127550] [G loss: 0.539874]\n",
      "[Epoch 10/200] [Batch 626/637] [D loss: 0.130711] [G loss: 0.541642]\n",
      "[Epoch 10/200] [Batch 627/637] [D loss: 0.144136] [G loss: 0.503679]\n",
      "[Epoch 10/200] [Batch 628/637] [D loss: 0.148444] [G loss: 0.531569]\n",
      "[Epoch 10/200] [Batch 629/637] [D loss: 0.154431] [G loss: 0.563998]\n",
      "[Epoch 10/200] [Batch 630/637] [D loss: 0.165383] [G loss: 0.579536]\n",
      "[Epoch 10/200] [Batch 631/637] [D loss: 0.164285] [G loss: 0.441713]\n",
      "[Epoch 10/200] [Batch 632/637] [D loss: 0.159539] [G loss: 0.524041]\n",
      "[Epoch 10/200] [Batch 633/637] [D loss: 0.140917] [G loss: 0.594328]\n",
      "[Epoch 10/200] [Batch 634/637] [D loss: 0.168360] [G loss: 0.583364]\n",
      "[Epoch 10/200] [Batch 635/637] [D loss: 0.143354] [G loss: 0.518453]\n",
      "[Epoch 10/200] [Batch 636/637] [D loss: 0.146690] [G loss: 0.475222]\n",
      "[Epoch 11/200] [Batch 0/637] [D loss: 0.171471] [G loss: 0.478984]\n",
      "[Epoch 11/200] [Batch 1/637] [D loss: 0.164020] [G loss: 0.557247]\n",
      "[Epoch 11/200] [Batch 2/637] [D loss: 0.160107] [G loss: 0.541010]\n",
      "[Epoch 11/200] [Batch 3/637] [D loss: 0.143690] [G loss: 0.573387]\n",
      "[Epoch 11/200] [Batch 4/637] [D loss: 0.143079] [G loss: 0.550808]\n",
      "[Epoch 11/200] [Batch 5/637] [D loss: 0.147750] [G loss: 0.498862]\n",
      "[Epoch 11/200] [Batch 6/637] [D loss: 0.155975] [G loss: 0.526657]\n",
      "[Epoch 11/200] [Batch 7/637] [D loss: 0.145788] [G loss: 0.617089]\n",
      "[Epoch 11/200] [Batch 8/637] [D loss: 0.127669] [G loss: 0.639559]\n",
      "[Epoch 11/200] [Batch 9/637] [D loss: 0.136973] [G loss: 0.520280]\n",
      "[Epoch 11/200] [Batch 10/637] [D loss: 0.140810] [G loss: 0.520280]\n",
      "[Epoch 11/200] [Batch 11/637] [D loss: 0.159687] [G loss: 0.566865]\n",
      "[Epoch 11/200] [Batch 12/637] [D loss: 0.144895] [G loss: 0.545379]\n",
      "[Epoch 11/200] [Batch 13/637] [D loss: 0.150225] [G loss: 0.555839]\n",
      "[Epoch 11/200] [Batch 14/637] [D loss: 0.171344] [G loss: 0.534211]\n",
      "[Epoch 11/200] [Batch 15/637] [D loss: 0.181199] [G loss: 0.559780]\n",
      "[Epoch 11/200] [Batch 16/637] [D loss: 0.325085] [G loss: 0.363941]\n",
      "[Epoch 11/200] [Batch 17/637] [D loss: 0.276395] [G loss: 0.819913]\n",
      "[Epoch 11/200] [Batch 18/637] [D loss: 0.221824] [G loss: 0.587456]\n",
      "[Epoch 11/200] [Batch 19/637] [D loss: 0.205649] [G loss: 0.438879]\n",
      "[Epoch 11/200] [Batch 20/637] [D loss: 0.211372] [G loss: 0.411943]\n",
      "[Epoch 11/200] [Batch 21/637] [D loss: 0.207129] [G loss: 0.336493]\n",
      "[Epoch 11/200] [Batch 22/637] [D loss: 0.164070] [G loss: 0.435196]\n",
      "[Epoch 11/200] [Batch 23/637] [D loss: 0.175021] [G loss: 0.401804]\n",
      "[Epoch 11/200] [Batch 24/637] [D loss: 0.176661] [G loss: 0.423359]\n",
      "[Epoch 11/200] [Batch 25/637] [D loss: 0.164577] [G loss: 0.481619]\n",
      "[Epoch 11/200] [Batch 26/637] [D loss: 0.185233] [G loss: 0.527321]\n",
      "[Epoch 11/200] [Batch 27/637] [D loss: 0.186227] [G loss: 0.463822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 28/637] [D loss: 0.165684] [G loss: 0.477463]\n",
      "[Epoch 11/200] [Batch 29/637] [D loss: 0.166783] [G loss: 0.509059]\n",
      "[Epoch 11/200] [Batch 30/637] [D loss: 0.159820] [G loss: 0.472713]\n",
      "[Epoch 11/200] [Batch 31/637] [D loss: 0.167732] [G loss: 0.509548]\n",
      "[Epoch 11/200] [Batch 32/637] [D loss: 0.172453] [G loss: 0.610878]\n",
      "[Epoch 11/200] [Batch 33/637] [D loss: 0.173987] [G loss: 0.519673]\n",
      "[Epoch 11/200] [Batch 34/637] [D loss: 0.150449] [G loss: 0.495332]\n",
      "[Epoch 11/200] [Batch 35/637] [D loss: 0.136762] [G loss: 0.506698]\n",
      "[Epoch 11/200] [Batch 36/637] [D loss: 0.141634] [G loss: 0.564335]\n",
      "[Epoch 11/200] [Batch 37/637] [D loss: 0.148195] [G loss: 0.526398]\n",
      "[Epoch 11/200] [Batch 38/637] [D loss: 0.136921] [G loss: 0.506148]\n",
      "[Epoch 11/200] [Batch 39/637] [D loss: 0.147114] [G loss: 0.531490]\n",
      "[Epoch 11/200] [Batch 40/637] [D loss: 0.137725] [G loss: 0.530163]\n",
      "[Epoch 11/200] [Batch 41/637] [D loss: 0.131815] [G loss: 0.557601]\n",
      "[Epoch 11/200] [Batch 42/637] [D loss: 0.131163] [G loss: 0.581885]\n",
      "[Epoch 11/200] [Batch 43/637] [D loss: 0.132926] [G loss: 0.534526]\n",
      "[Epoch 11/200] [Batch 44/637] [D loss: 0.124625] [G loss: 0.541824]\n",
      "[Epoch 11/200] [Batch 45/637] [D loss: 0.158925] [G loss: 0.537949]\n",
      "[Epoch 11/200] [Batch 46/637] [D loss: 0.141582] [G loss: 0.594140]\n",
      "[Epoch 11/200] [Batch 47/637] [D loss: 0.173817] [G loss: 0.530362]\n",
      "[Epoch 11/200] [Batch 48/637] [D loss: 0.163657] [G loss: 0.453564]\n",
      "[Epoch 11/200] [Batch 49/637] [D loss: 0.148753] [G loss: 0.493858]\n",
      "[Epoch 11/200] [Batch 50/637] [D loss: 0.145220] [G loss: 0.512747]\n",
      "[Epoch 11/200] [Batch 51/637] [D loss: 0.200854] [G loss: 0.448363]\n",
      "[Epoch 11/200] [Batch 52/637] [D loss: 0.243273] [G loss: 0.556680]\n",
      "[Epoch 11/200] [Batch 53/637] [D loss: 0.178527] [G loss: 0.606600]\n",
      "[Epoch 11/200] [Batch 54/637] [D loss: 0.153205] [G loss: 0.559926]\n",
      "[Epoch 11/200] [Batch 55/637] [D loss: 0.197418] [G loss: 0.477736]\n",
      "[Epoch 11/200] [Batch 56/637] [D loss: 0.176176] [G loss: 0.449342]\n",
      "[Epoch 11/200] [Batch 57/637] [D loss: 0.200960] [G loss: 0.438753]\n",
      "[Epoch 11/200] [Batch 58/637] [D loss: 0.174226] [G loss: 0.457106]\n",
      "[Epoch 11/200] [Batch 59/637] [D loss: 0.165356] [G loss: 0.435213]\n",
      "[Epoch 11/200] [Batch 60/637] [D loss: 0.163133] [G loss: 0.419921]\n",
      "[Epoch 11/200] [Batch 61/637] [D loss: 0.163146] [G loss: 0.478497]\n",
      "[Epoch 11/200] [Batch 62/637] [D loss: 0.137157] [G loss: 0.515926]\n",
      "[Epoch 11/200] [Batch 63/637] [D loss: 0.160036] [G loss: 0.546461]\n",
      "[Epoch 11/200] [Batch 64/637] [D loss: 0.147360] [G loss: 0.535129]\n",
      "[Epoch 11/200] [Batch 65/637] [D loss: 0.132649] [G loss: 0.573271]\n",
      "[Epoch 11/200] [Batch 66/637] [D loss: 0.154350] [G loss: 0.555792]\n",
      "[Epoch 11/200] [Batch 67/637] [D loss: 0.141406] [G loss: 0.487012]\n",
      "[Epoch 11/200] [Batch 68/637] [D loss: 0.127903] [G loss: 0.564610]\n",
      "[Epoch 11/200] [Batch 69/637] [D loss: 0.161527] [G loss: 0.445690]\n",
      "[Epoch 11/200] [Batch 70/637] [D loss: 0.131198] [G loss: 0.578464]\n",
      "[Epoch 11/200] [Batch 71/637] [D loss: 0.139387] [G loss: 0.547876]\n",
      "[Epoch 11/200] [Batch 72/637] [D loss: 0.138069] [G loss: 0.487796]\n",
      "[Epoch 11/200] [Batch 73/637] [D loss: 0.118925] [G loss: 0.589365]\n",
      "[Epoch 11/200] [Batch 74/637] [D loss: 0.184292] [G loss: 0.417592]\n",
      "[Epoch 11/200] [Batch 75/637] [D loss: 0.196366] [G loss: 0.658240]\n",
      "[Epoch 11/200] [Batch 76/637] [D loss: 0.169911] [G loss: 0.557863]\n",
      "[Epoch 11/200] [Batch 77/637] [D loss: 0.161184] [G loss: 0.459926]\n",
      "[Epoch 11/200] [Batch 78/637] [D loss: 0.157986] [G loss: 0.450137]\n",
      "[Epoch 11/200] [Batch 79/637] [D loss: 0.152787] [G loss: 0.474140]\n",
      "[Epoch 11/200] [Batch 80/637] [D loss: 0.146593] [G loss: 0.488810]\n",
      "[Epoch 11/200] [Batch 81/637] [D loss: 0.150348] [G loss: 0.565822]\n",
      "[Epoch 11/200] [Batch 82/637] [D loss: 0.147175] [G loss: 0.550711]\n",
      "[Epoch 11/200] [Batch 83/637] [D loss: 0.138579] [G loss: 0.511559]\n",
      "[Epoch 11/200] [Batch 84/637] [D loss: 0.138377] [G loss: 0.537129]\n",
      "[Epoch 11/200] [Batch 85/637] [D loss: 0.179845] [G loss: 0.457553]\n",
      "[Epoch 11/200] [Batch 86/637] [D loss: 0.172459] [G loss: 0.543559]\n",
      "[Epoch 11/200] [Batch 87/637] [D loss: 0.156707] [G loss: 0.550239]\n",
      "[Epoch 11/200] [Batch 88/637] [D loss: 0.155926] [G loss: 0.542860]\n",
      "[Epoch 11/200] [Batch 89/637] [D loss: 0.164700] [G loss: 0.495977]\n",
      "[Epoch 11/200] [Batch 90/637] [D loss: 0.168167] [G loss: 0.458929]\n",
      "[Epoch 11/200] [Batch 91/637] [D loss: 0.180924] [G loss: 0.502187]\n",
      "[Epoch 11/200] [Batch 92/637] [D loss: 0.151719] [G loss: 0.551584]\n",
      "[Epoch 11/200] [Batch 93/637] [D loss: 0.181702] [G loss: 0.490356]\n",
      "[Epoch 11/200] [Batch 94/637] [D loss: 0.173969] [G loss: 0.499368]\n",
      "[Epoch 11/200] [Batch 95/637] [D loss: 0.164461] [G loss: 0.502397]\n",
      "[Epoch 11/200] [Batch 96/637] [D loss: 0.166160] [G loss: 0.431420]\n",
      "[Epoch 11/200] [Batch 97/637] [D loss: 0.161570] [G loss: 0.436306]\n",
      "[Epoch 11/200] [Batch 98/637] [D loss: 0.255286] [G loss: 0.376533]\n",
      "[Epoch 11/200] [Batch 99/637] [D loss: 0.214578] [G loss: 0.574876]\n",
      "[Epoch 11/200] [Batch 100/637] [D loss: 0.198838] [G loss: 0.606282]\n",
      "[Epoch 11/200] [Batch 101/637] [D loss: 0.178858] [G loss: 0.512589]\n",
      "[Epoch 11/200] [Batch 102/637] [D loss: 0.181444] [G loss: 0.444713]\n",
      "[Epoch 11/200] [Batch 103/637] [D loss: 0.166624] [G loss: 0.398939]\n",
      "[Epoch 11/200] [Batch 104/637] [D loss: 0.162318] [G loss: 0.410082]\n",
      "[Epoch 11/200] [Batch 105/637] [D loss: 0.167371] [G loss: 0.417961]\n",
      "[Epoch 11/200] [Batch 106/637] [D loss: 0.149094] [G loss: 0.473805]\n",
      "[Epoch 11/200] [Batch 107/637] [D loss: 0.151292] [G loss: 0.520702]\n",
      "[Epoch 11/200] [Batch 108/637] [D loss: 0.156404] [G loss: 0.459055]\n",
      "[Epoch 11/200] [Batch 109/637] [D loss: 0.172924] [G loss: 0.521392]\n",
      "[Epoch 11/200] [Batch 110/637] [D loss: 0.126375] [G loss: 0.510249]\n",
      "[Epoch 11/200] [Batch 111/637] [D loss: 0.156158] [G loss: 0.442538]\n",
      "[Epoch 11/200] [Batch 112/637] [D loss: 0.163568] [G loss: 0.516832]\n",
      "[Epoch 11/200] [Batch 113/637] [D loss: 0.168404] [G loss: 0.566273]\n",
      "[Epoch 11/200] [Batch 114/637] [D loss: 0.137657] [G loss: 0.553624]\n",
      "[Epoch 11/200] [Batch 115/637] [D loss: 0.139150] [G loss: 0.565729]\n",
      "[Epoch 11/200] [Batch 116/637] [D loss: 0.150575] [G loss: 0.492570]\n",
      "[Epoch 11/200] [Batch 117/637] [D loss: 0.154423] [G loss: 0.602639]\n",
      "[Epoch 11/200] [Batch 118/637] [D loss: 0.158509] [G loss: 0.500846]\n",
      "[Epoch 11/200] [Batch 119/637] [D loss: 0.156816] [G loss: 0.509156]\n",
      "[Epoch 11/200] [Batch 120/637] [D loss: 0.158203] [G loss: 0.577932]\n",
      "[Epoch 11/200] [Batch 121/637] [D loss: 0.168883] [G loss: 0.522720]\n",
      "[Epoch 11/200] [Batch 122/637] [D loss: 0.159657] [G loss: 0.576009]\n",
      "[Epoch 11/200] [Batch 123/637] [D loss: 0.199737] [G loss: 0.465714]\n",
      "[Epoch 11/200] [Batch 124/637] [D loss: 0.262541] [G loss: 0.509108]\n",
      "[Epoch 11/200] [Batch 125/637] [D loss: 0.165572] [G loss: 0.541030]\n",
      "[Epoch 11/200] [Batch 126/637] [D loss: 0.192083] [G loss: 0.483144]\n",
      "[Epoch 11/200] [Batch 127/637] [D loss: 0.172242] [G loss: 0.497720]\n",
      "[Epoch 11/200] [Batch 128/637] [D loss: 0.169504] [G loss: 0.493596]\n",
      "[Epoch 11/200] [Batch 129/637] [D loss: 0.181167] [G loss: 0.430600]\n",
      "[Epoch 11/200] [Batch 130/637] [D loss: 0.193232] [G loss: 0.463823]\n",
      "[Epoch 11/200] [Batch 131/637] [D loss: 0.156157] [G loss: 0.564948]\n",
      "[Epoch 11/200] [Batch 132/637] [D loss: 0.153743] [G loss: 0.540123]\n",
      "[Epoch 11/200] [Batch 133/637] [D loss: 0.128895] [G loss: 0.549660]\n",
      "[Epoch 11/200] [Batch 134/637] [D loss: 0.200931] [G loss: 0.403613]\n",
      "[Epoch 11/200] [Batch 135/637] [D loss: 0.183705] [G loss: 0.569548]\n",
      "[Epoch 11/200] [Batch 136/637] [D loss: 0.180046] [G loss: 0.564007]\n",
      "[Epoch 11/200] [Batch 137/637] [D loss: 0.142195] [G loss: 0.569322]\n",
      "[Epoch 11/200] [Batch 138/637] [D loss: 0.154881] [G loss: 0.520422]\n",
      "[Epoch 11/200] [Batch 139/637] [D loss: 0.159771] [G loss: 0.463430]\n",
      "[Epoch 11/200] [Batch 140/637] [D loss: 0.156295] [G loss: 0.574009]\n",
      "[Epoch 11/200] [Batch 141/637] [D loss: 0.150576] [G loss: 0.597531]\n",
      "[Epoch 11/200] [Batch 142/637] [D loss: 0.142359] [G loss: 0.571757]\n",
      "[Epoch 11/200] [Batch 143/637] [D loss: 0.148697] [G loss: 0.549279]\n",
      "[Epoch 11/200] [Batch 144/637] [D loss: 0.159984] [G loss: 0.560319]\n",
      "[Epoch 11/200] [Batch 145/637] [D loss: 0.169908] [G loss: 0.520083]\n",
      "[Epoch 11/200] [Batch 146/637] [D loss: 0.164901] [G loss: 0.466830]\n",
      "[Epoch 11/200] [Batch 147/637] [D loss: 0.165370] [G loss: 0.560910]\n",
      "[Epoch 11/200] [Batch 148/637] [D loss: 0.170965] [G loss: 0.539039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 149/637] [D loss: 0.207136] [G loss: 0.490640]\n",
      "[Epoch 11/200] [Batch 150/637] [D loss: 0.198778] [G loss: 0.545846]\n",
      "[Epoch 11/200] [Batch 151/637] [D loss: 0.191922] [G loss: 0.457483]\n",
      "[Epoch 11/200] [Batch 152/637] [D loss: 0.173442] [G loss: 0.496773]\n",
      "[Epoch 11/200] [Batch 153/637] [D loss: 0.164761] [G loss: 0.489600]\n",
      "[Epoch 11/200] [Batch 154/637] [D loss: 0.155267] [G loss: 0.533946]\n",
      "[Epoch 11/200] [Batch 155/637] [D loss: 0.141307] [G loss: 0.479964]\n",
      "[Epoch 11/200] [Batch 156/637] [D loss: 0.153396] [G loss: 0.437852]\n",
      "[Epoch 11/200] [Batch 157/637] [D loss: 0.163072] [G loss: 0.456403]\n",
      "[Epoch 11/200] [Batch 158/637] [D loss: 0.184637] [G loss: 0.625577]\n",
      "[Epoch 11/200] [Batch 159/637] [D loss: 0.148028] [G loss: 0.601697]\n",
      "[Epoch 11/200] [Batch 160/637] [D loss: 0.121060] [G loss: 0.586791]\n",
      "[Epoch 11/200] [Batch 161/637] [D loss: 0.154869] [G loss: 0.536026]\n",
      "[Epoch 11/200] [Batch 162/637] [D loss: 0.162206] [G loss: 0.543613]\n",
      "[Epoch 11/200] [Batch 163/637] [D loss: 0.173710] [G loss: 0.509570]\n",
      "[Epoch 11/200] [Batch 164/637] [D loss: 0.143725] [G loss: 0.527669]\n",
      "[Epoch 11/200] [Batch 165/637] [D loss: 0.134447] [G loss: 0.573772]\n",
      "[Epoch 11/200] [Batch 166/637] [D loss: 0.151770] [G loss: 0.482705]\n",
      "[Epoch 11/200] [Batch 167/637] [D loss: 0.147002] [G loss: 0.532710]\n",
      "[Epoch 11/200] [Batch 168/637] [D loss: 0.164525] [G loss: 0.525931]\n",
      "[Epoch 11/200] [Batch 169/637] [D loss: 0.197866] [G loss: 0.506174]\n",
      "[Epoch 11/200] [Batch 170/637] [D loss: 0.153246] [G loss: 0.625669]\n",
      "[Epoch 11/200] [Batch 171/637] [D loss: 0.152043] [G loss: 0.525855]\n",
      "[Epoch 11/200] [Batch 172/637] [D loss: 0.161913] [G loss: 0.488788]\n",
      "[Epoch 11/200] [Batch 173/637] [D loss: 0.146851] [G loss: 0.486431]\n",
      "[Epoch 11/200] [Batch 174/637] [D loss: 0.183227] [G loss: 0.439242]\n",
      "[Epoch 11/200] [Batch 175/637] [D loss: 0.178407] [G loss: 0.536904]\n",
      "[Epoch 11/200] [Batch 176/637] [D loss: 0.147909] [G loss: 0.492900]\n",
      "[Epoch 11/200] [Batch 177/637] [D loss: 0.194405] [G loss: 0.445149]\n",
      "[Epoch 11/200] [Batch 178/637] [D loss: 0.143188] [G loss: 0.526098]\n",
      "[Epoch 11/200] [Batch 179/637] [D loss: 0.164207] [G loss: 0.473354]\n",
      "[Epoch 11/200] [Batch 180/637] [D loss: 0.165192] [G loss: 0.445963]\n",
      "[Epoch 11/200] [Batch 181/637] [D loss: 0.149792] [G loss: 0.515334]\n",
      "[Epoch 11/200] [Batch 182/637] [D loss: 0.157470] [G loss: 0.528303]\n",
      "[Epoch 11/200] [Batch 183/637] [D loss: 0.154114] [G loss: 0.511847]\n",
      "[Epoch 11/200] [Batch 184/637] [D loss: 0.203196] [G loss: 0.408596]\n",
      "[Epoch 11/200] [Batch 185/637] [D loss: 0.253997] [G loss: 0.706141]\n",
      "[Epoch 11/200] [Batch 186/637] [D loss: 0.196205] [G loss: 0.606144]\n",
      "[Epoch 11/200] [Batch 187/637] [D loss: 0.166987] [G loss: 0.514506]\n",
      "[Epoch 11/200] [Batch 188/637] [D loss: 0.178782] [G loss: 0.421447]\n",
      "[Epoch 11/200] [Batch 189/637] [D loss: 0.160623] [G loss: 0.472103]\n",
      "[Epoch 11/200] [Batch 190/637] [D loss: 0.175942] [G loss: 0.435572]\n",
      "[Epoch 11/200] [Batch 191/637] [D loss: 0.154833] [G loss: 0.512015]\n",
      "[Epoch 11/200] [Batch 192/637] [D loss: 0.144751] [G loss: 0.464047]\n",
      "[Epoch 11/200] [Batch 193/637] [D loss: 0.156515] [G loss: 0.490140]\n",
      "[Epoch 11/200] [Batch 194/637] [D loss: 0.145926] [G loss: 0.527262]\n",
      "[Epoch 11/200] [Batch 195/637] [D loss: 0.143948] [G loss: 0.545767]\n",
      "[Epoch 11/200] [Batch 196/637] [D loss: 0.158475] [G loss: 0.477984]\n",
      "[Epoch 11/200] [Batch 197/637] [D loss: 0.148809] [G loss: 0.575548]\n",
      "[Epoch 11/200] [Batch 198/637] [D loss: 0.142747] [G loss: 0.496621]\n",
      "[Epoch 11/200] [Batch 199/637] [D loss: 0.162834] [G loss: 0.529482]\n",
      "[Epoch 11/200] [Batch 200/637] [D loss: 0.156452] [G loss: 0.462763]\n",
      "[Epoch 11/200] [Batch 201/637] [D loss: 0.168692] [G loss: 0.442557]\n",
      "[Epoch 11/200] [Batch 202/637] [D loss: 0.150838] [G loss: 0.530885]\n",
      "[Epoch 11/200] [Batch 203/637] [D loss: 0.135377] [G loss: 0.620749]\n",
      "[Epoch 11/200] [Batch 204/637] [D loss: 0.148697] [G loss: 0.580128]\n",
      "[Epoch 11/200] [Batch 205/637] [D loss: 0.147602] [G loss: 0.545772]\n",
      "[Epoch 11/200] [Batch 206/637] [D loss: 0.202943] [G loss: 0.432738]\n",
      "[Epoch 11/200] [Batch 207/637] [D loss: 0.251603] [G loss: 0.705137]\n",
      "[Epoch 11/200] [Batch 208/637] [D loss: 0.146713] [G loss: 0.585741]\n",
      "[Epoch 11/200] [Batch 209/637] [D loss: 0.187216] [G loss: 0.474311]\n",
      "[Epoch 11/200] [Batch 210/637] [D loss: 0.158457] [G loss: 0.474847]\n",
      "[Epoch 11/200] [Batch 211/637] [D loss: 0.148739] [G loss: 0.507910]\n",
      "[Epoch 11/200] [Batch 212/637] [D loss: 0.153255] [G loss: 0.497882]\n",
      "[Epoch 11/200] [Batch 213/637] [D loss: 0.163025] [G loss: 0.456721]\n",
      "[Epoch 11/200] [Batch 214/637] [D loss: 0.146923] [G loss: 0.553560]\n",
      "[Epoch 11/200] [Batch 215/637] [D loss: 0.187086] [G loss: 0.469450]\n",
      "[Epoch 11/200] [Batch 216/637] [D loss: 0.179640] [G loss: 0.476860]\n",
      "[Epoch 11/200] [Batch 217/637] [D loss: 0.171096] [G loss: 0.468922]\n",
      "[Epoch 11/200] [Batch 218/637] [D loss: 0.148272] [G loss: 0.687479]\n",
      "[Epoch 11/200] [Batch 219/637] [D loss: 0.167945] [G loss: 0.623410]\n",
      "[Epoch 11/200] [Batch 220/637] [D loss: 0.177038] [G loss: 0.478793]\n",
      "[Epoch 11/200] [Batch 221/637] [D loss: 0.167032] [G loss: 0.503087]\n",
      "[Epoch 11/200] [Batch 222/637] [D loss: 0.153535] [G loss: 0.504500]\n",
      "[Epoch 11/200] [Batch 223/637] [D loss: 0.165458] [G loss: 0.456876]\n",
      "[Epoch 11/200] [Batch 224/637] [D loss: 0.159671] [G loss: 0.517233]\n",
      "[Epoch 11/200] [Batch 225/637] [D loss: 0.191000] [G loss: 0.456855]\n",
      "[Epoch 11/200] [Batch 226/637] [D loss: 0.136595] [G loss: 0.544766]\n",
      "[Epoch 11/200] [Batch 227/637] [D loss: 0.173694] [G loss: 0.516107]\n",
      "[Epoch 11/200] [Batch 228/637] [D loss: 0.152201] [G loss: 0.546467]\n",
      "[Epoch 11/200] [Batch 229/637] [D loss: 0.160754] [G loss: 0.456247]\n",
      "[Epoch 11/200] [Batch 230/637] [D loss: 0.151224] [G loss: 0.518183]\n",
      "[Epoch 11/200] [Batch 231/637] [D loss: 0.163536] [G loss: 0.494260]\n",
      "[Epoch 11/200] [Batch 232/637] [D loss: 0.149050] [G loss: 0.487037]\n",
      "[Epoch 11/200] [Batch 233/637] [D loss: 0.152630] [G loss: 0.521308]\n",
      "[Epoch 11/200] [Batch 234/637] [D loss: 0.150456] [G loss: 0.562865]\n",
      "[Epoch 11/200] [Batch 235/637] [D loss: 0.143240] [G loss: 0.539424]\n",
      "[Epoch 11/200] [Batch 236/637] [D loss: 0.157460] [G loss: 0.503131]\n",
      "[Epoch 11/200] [Batch 237/637] [D loss: 0.123755] [G loss: 0.506097]\n",
      "[Epoch 11/200] [Batch 238/637] [D loss: 0.147582] [G loss: 0.447544]\n",
      "[Epoch 11/200] [Batch 239/637] [D loss: 0.144076] [G loss: 0.616019]\n",
      "[Epoch 11/200] [Batch 240/637] [D loss: 0.159400] [G loss: 0.625650]\n",
      "[Epoch 11/200] [Batch 241/637] [D loss: 0.208565] [G loss: 0.427709]\n",
      "[Epoch 11/200] [Batch 242/637] [D loss: 0.197465] [G loss: 0.819217]\n",
      "[Epoch 11/200] [Batch 243/637] [D loss: 0.213335] [G loss: 0.546668]\n",
      "[Epoch 11/200] [Batch 244/637] [D loss: 0.167762] [G loss: 0.491157]\n",
      "[Epoch 11/200] [Batch 245/637] [D loss: 0.157408] [G loss: 0.464946]\n",
      "[Epoch 11/200] [Batch 246/637] [D loss: 0.176916] [G loss: 0.498043]\n",
      "[Epoch 11/200] [Batch 247/637] [D loss: 0.157815] [G loss: 0.471852]\n",
      "[Epoch 11/200] [Batch 248/637] [D loss: 0.177947] [G loss: 0.427317]\n",
      "[Epoch 11/200] [Batch 249/637] [D loss: 0.154429] [G loss: 0.455806]\n",
      "[Epoch 11/200] [Batch 250/637] [D loss: 0.147788] [G loss: 0.491761]\n",
      "[Epoch 11/200] [Batch 251/637] [D loss: 0.152860] [G loss: 0.456850]\n",
      "[Epoch 11/200] [Batch 252/637] [D loss: 0.170368] [G loss: 0.465749]\n",
      "[Epoch 11/200] [Batch 253/637] [D loss: 0.154642] [G loss: 0.494434]\n",
      "[Epoch 11/200] [Batch 254/637] [D loss: 0.157894] [G loss: 0.473341]\n",
      "[Epoch 11/200] [Batch 255/637] [D loss: 0.185502] [G loss: 0.494768]\n",
      "[Epoch 11/200] [Batch 256/637] [D loss: 0.165026] [G loss: 0.521168]\n",
      "[Epoch 11/200] [Batch 257/637] [D loss: 0.181747] [G loss: 0.469498]\n",
      "[Epoch 11/200] [Batch 258/637] [D loss: 0.160146] [G loss: 0.493930]\n",
      "[Epoch 11/200] [Batch 259/637] [D loss: 0.151943] [G loss: 0.551424]\n",
      "[Epoch 11/200] [Batch 260/637] [D loss: 0.171227] [G loss: 0.508048]\n",
      "[Epoch 11/200] [Batch 261/637] [D loss: 0.155694] [G loss: 0.485121]\n",
      "[Epoch 11/200] [Batch 262/637] [D loss: 0.145540] [G loss: 0.515679]\n",
      "[Epoch 11/200] [Batch 263/637] [D loss: 0.148864] [G loss: 0.492672]\n",
      "[Epoch 11/200] [Batch 264/637] [D loss: 0.180710] [G loss: 0.465491]\n",
      "[Epoch 11/200] [Batch 265/637] [D loss: 0.191450] [G loss: 0.523922]\n",
      "[Epoch 11/200] [Batch 266/637] [D loss: 0.158687] [G loss: 0.487779]\n",
      "[Epoch 11/200] [Batch 267/637] [D loss: 0.187632] [G loss: 0.503721]\n",
      "[Epoch 11/200] [Batch 268/637] [D loss: 0.158058] [G loss: 0.518642]\n",
      "[Epoch 11/200] [Batch 269/637] [D loss: 0.173958] [G loss: 0.538769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 270/637] [D loss: 0.148699] [G loss: 0.466043]\n",
      "[Epoch 11/200] [Batch 271/637] [D loss: 0.189411] [G loss: 0.454651]\n",
      "[Epoch 11/200] [Batch 272/637] [D loss: 0.179144] [G loss: 0.469624]\n",
      "[Epoch 11/200] [Batch 273/637] [D loss: 0.158800] [G loss: 0.498895]\n",
      "[Epoch 11/200] [Batch 274/637] [D loss: 0.170361] [G loss: 0.432319]\n",
      "[Epoch 11/200] [Batch 275/637] [D loss: 0.186934] [G loss: 0.488036]\n",
      "[Epoch 11/200] [Batch 276/637] [D loss: 0.178311] [G loss: 0.424325]\n",
      "[Epoch 11/200] [Batch 277/637] [D loss: 0.170350] [G loss: 0.538823]\n",
      "[Epoch 11/200] [Batch 278/637] [D loss: 0.169904] [G loss: 0.474386]\n",
      "[Epoch 11/200] [Batch 279/637] [D loss: 0.150790] [G loss: 0.502024]\n",
      "[Epoch 11/200] [Batch 280/637] [D loss: 0.151746] [G loss: 0.484478]\n",
      "[Epoch 11/200] [Batch 281/637] [D loss: 0.150037] [G loss: 0.508358]\n",
      "[Epoch 11/200] [Batch 282/637] [D loss: 0.145457] [G loss: 0.501527]\n",
      "[Epoch 11/200] [Batch 283/637] [D loss: 0.175151] [G loss: 0.525283]\n",
      "[Epoch 11/200] [Batch 284/637] [D loss: 0.156511] [G loss: 0.503973]\n",
      "[Epoch 11/200] [Batch 285/637] [D loss: 0.185563] [G loss: 0.419061]\n",
      "[Epoch 11/200] [Batch 286/637] [D loss: 0.192124] [G loss: 0.572174]\n",
      "[Epoch 11/200] [Batch 287/637] [D loss: 0.181992] [G loss: 0.584560]\n",
      "[Epoch 11/200] [Batch 288/637] [D loss: 0.190302] [G loss: 0.490610]\n",
      "[Epoch 11/200] [Batch 289/637] [D loss: 0.144982] [G loss: 0.515240]\n",
      "[Epoch 11/200] [Batch 290/637] [D loss: 0.155333] [G loss: 0.470277]\n",
      "[Epoch 11/200] [Batch 291/637] [D loss: 0.159894] [G loss: 0.444437]\n",
      "[Epoch 11/200] [Batch 292/637] [D loss: 0.149476] [G loss: 0.496794]\n",
      "[Epoch 11/200] [Batch 293/637] [D loss: 0.152783] [G loss: 0.509051]\n",
      "[Epoch 11/200] [Batch 294/637] [D loss: 0.141650] [G loss: 0.493038]\n",
      "[Epoch 11/200] [Batch 295/637] [D loss: 0.171974] [G loss: 0.466446]\n",
      "[Epoch 11/200] [Batch 296/637] [D loss: 0.145980] [G loss: 0.562258]\n",
      "[Epoch 11/200] [Batch 297/637] [D loss: 0.166900] [G loss: 0.552099]\n",
      "[Epoch 11/200] [Batch 298/637] [D loss: 0.170607] [G loss: 0.422010]\n",
      "[Epoch 11/200] [Batch 299/637] [D loss: 0.176787] [G loss: 0.560806]\n",
      "[Epoch 11/200] [Batch 300/637] [D loss: 0.151779] [G loss: 0.509206]\n",
      "[Epoch 11/200] [Batch 301/637] [D loss: 0.159687] [G loss: 0.512975]\n",
      "[Epoch 11/200] [Batch 302/637] [D loss: 0.160592] [G loss: 0.454835]\n",
      "[Epoch 11/200] [Batch 303/637] [D loss: 0.158600] [G loss: 0.547742]\n",
      "[Epoch 11/200] [Batch 304/637] [D loss: 0.151725] [G loss: 0.528750]\n",
      "[Epoch 11/200] [Batch 305/637] [D loss: 0.147685] [G loss: 0.539624]\n",
      "[Epoch 11/200] [Batch 306/637] [D loss: 0.193827] [G loss: 0.467785]\n",
      "[Epoch 11/200] [Batch 307/637] [D loss: 0.165986] [G loss: 0.530723]\n",
      "[Epoch 11/200] [Batch 308/637] [D loss: 0.166357] [G loss: 0.564528]\n",
      "[Epoch 11/200] [Batch 309/637] [D loss: 0.148057] [G loss: 0.465633]\n",
      "[Epoch 11/200] [Batch 310/637] [D loss: 0.150217] [G loss: 0.452042]\n",
      "[Epoch 11/200] [Batch 311/637] [D loss: 0.192668] [G loss: 0.509473]\n",
      "[Epoch 11/200] [Batch 312/637] [D loss: 0.152265] [G loss: 0.560086]\n",
      "[Epoch 11/200] [Batch 313/637] [D loss: 0.165353] [G loss: 0.444939]\n",
      "[Epoch 11/200] [Batch 314/637] [D loss: 0.148143] [G loss: 0.459426]\n",
      "[Epoch 11/200] [Batch 315/637] [D loss: 0.117682] [G loss: 0.508733]\n",
      "[Epoch 11/200] [Batch 316/637] [D loss: 0.139866] [G loss: 0.582494]\n",
      "[Epoch 11/200] [Batch 317/637] [D loss: 0.155902] [G loss: 0.446968]\n",
      "[Epoch 11/200] [Batch 318/637] [D loss: 0.154340] [G loss: 0.579598]\n",
      "[Epoch 11/200] [Batch 319/637] [D loss: 0.170870] [G loss: 0.579945]\n",
      "[Epoch 11/200] [Batch 320/637] [D loss: 0.141075] [G loss: 0.584698]\n",
      "[Epoch 11/200] [Batch 321/637] [D loss: 0.175136] [G loss: 0.504942]\n",
      "[Epoch 11/200] [Batch 322/637] [D loss: 0.169120] [G loss: 0.498421]\n",
      "[Epoch 11/200] [Batch 323/637] [D loss: 0.143686] [G loss: 0.577119]\n",
      "[Epoch 11/200] [Batch 324/637] [D loss: 0.155035] [G loss: 0.535660]\n",
      "[Epoch 11/200] [Batch 325/637] [D loss: 0.154621] [G loss: 0.547426]\n",
      "[Epoch 11/200] [Batch 326/637] [D loss: 0.136801] [G loss: 0.540884]\n",
      "[Epoch 11/200] [Batch 327/637] [D loss: 0.141631] [G loss: 0.538186]\n",
      "[Epoch 11/200] [Batch 328/637] [D loss: 0.190976] [G loss: 0.448305]\n",
      "[Epoch 11/200] [Batch 329/637] [D loss: 0.182376] [G loss: 0.729967]\n",
      "[Epoch 11/200] [Batch 330/637] [D loss: 0.158972] [G loss: 0.559184]\n",
      "[Epoch 11/200] [Batch 331/637] [D loss: 0.150867] [G loss: 0.549467]\n",
      "[Epoch 11/200] [Batch 332/637] [D loss: 0.156063] [G loss: 0.539896]\n",
      "[Epoch 11/200] [Batch 333/637] [D loss: 0.144961] [G loss: 0.441305]\n",
      "[Epoch 11/200] [Batch 334/637] [D loss: 0.139485] [G loss: 0.546392]\n",
      "[Epoch 11/200] [Batch 335/637] [D loss: 0.130118] [G loss: 0.544209]\n",
      "[Epoch 11/200] [Batch 336/637] [D loss: 0.233163] [G loss: 0.425114]\n",
      "[Epoch 11/200] [Batch 337/637] [D loss: 0.236645] [G loss: 0.606613]\n",
      "[Epoch 11/200] [Batch 338/637] [D loss: 0.187094] [G loss: 0.599584]\n",
      "[Epoch 11/200] [Batch 339/637] [D loss: 0.160058] [G loss: 0.589428]\n",
      "[Epoch 11/200] [Batch 340/637] [D loss: 0.154575] [G loss: 0.443229]\n",
      "[Epoch 11/200] [Batch 341/637] [D loss: 0.157226] [G loss: 0.453344]\n",
      "[Epoch 11/200] [Batch 342/637] [D loss: 0.154149] [G loss: 0.468446]\n",
      "[Epoch 11/200] [Batch 343/637] [D loss: 0.158934] [G loss: 0.474233]\n",
      "[Epoch 11/200] [Batch 344/637] [D loss: 0.136077] [G loss: 0.535540]\n",
      "[Epoch 11/200] [Batch 345/637] [D loss: 0.165195] [G loss: 0.453550]\n",
      "[Epoch 11/200] [Batch 346/637] [D loss: 0.145308] [G loss: 0.517880]\n",
      "[Epoch 11/200] [Batch 347/637] [D loss: 0.157407] [G loss: 0.473201]\n",
      "[Epoch 11/200] [Batch 348/637] [D loss: 0.153256] [G loss: 0.479464]\n",
      "[Epoch 11/200] [Batch 349/637] [D loss: 0.172142] [G loss: 0.448964]\n",
      "[Epoch 11/200] [Batch 350/637] [D loss: 0.162953] [G loss: 0.483617]\n",
      "[Epoch 11/200] [Batch 351/637] [D loss: 0.156872] [G loss: 0.487830]\n",
      "[Epoch 11/200] [Batch 352/637] [D loss: 0.162107] [G loss: 0.503730]\n",
      "[Epoch 11/200] [Batch 353/637] [D loss: 0.153379] [G loss: 0.511527]\n",
      "[Epoch 11/200] [Batch 354/637] [D loss: 0.173907] [G loss: 0.494550]\n",
      "[Epoch 11/200] [Batch 355/637] [D loss: 0.163090] [G loss: 0.415593]\n",
      "[Epoch 11/200] [Batch 356/637] [D loss: 0.157493] [G loss: 0.472432]\n",
      "[Epoch 11/200] [Batch 357/637] [D loss: 0.147015] [G loss: 0.477381]\n",
      "[Epoch 11/200] [Batch 358/637] [D loss: 0.170403] [G loss: 0.486017]\n",
      "[Epoch 11/200] [Batch 359/637] [D loss: 0.156968] [G loss: 0.554446]\n",
      "[Epoch 11/200] [Batch 360/637] [D loss: 0.141569] [G loss: 0.504618]\n",
      "[Epoch 11/200] [Batch 361/637] [D loss: 0.173079] [G loss: 0.489154]\n",
      "[Epoch 11/200] [Batch 362/637] [D loss: 0.156551] [G loss: 0.528835]\n",
      "[Epoch 11/200] [Batch 363/637] [D loss: 0.146541] [G loss: 0.488317]\n",
      "[Epoch 11/200] [Batch 364/637] [D loss: 0.132596] [G loss: 0.509820]\n",
      "[Epoch 11/200] [Batch 365/637] [D loss: 0.150768] [G loss: 0.495624]\n",
      "[Epoch 11/200] [Batch 366/637] [D loss: 0.150052] [G loss: 0.475274]\n",
      "[Epoch 11/200] [Batch 367/637] [D loss: 0.147376] [G loss: 0.523948]\n",
      "[Epoch 11/200] [Batch 368/637] [D loss: 0.143344] [G loss: 0.588708]\n",
      "[Epoch 11/200] [Batch 369/637] [D loss: 0.149683] [G loss: 0.619273]\n",
      "[Epoch 11/200] [Batch 370/637] [D loss: 0.156934] [G loss: 0.466954]\n",
      "[Epoch 11/200] [Batch 371/637] [D loss: 0.156772] [G loss: 0.442592]\n",
      "[Epoch 11/200] [Batch 372/637] [D loss: 0.144790] [G loss: 0.513327]\n",
      "[Epoch 11/200] [Batch 373/637] [D loss: 0.161164] [G loss: 0.481403]\n",
      "[Epoch 11/200] [Batch 374/637] [D loss: 0.158282] [G loss: 0.549055]\n",
      "[Epoch 11/200] [Batch 375/637] [D loss: 0.172142] [G loss: 0.485240]\n",
      "[Epoch 11/200] [Batch 376/637] [D loss: 0.150794] [G loss: 0.486246]\n",
      "[Epoch 11/200] [Batch 377/637] [D loss: 0.130750] [G loss: 0.500708]\n",
      "[Epoch 11/200] [Batch 378/637] [D loss: 0.135877] [G loss: 0.479237]\n",
      "[Epoch 11/200] [Batch 379/637] [D loss: 0.171932] [G loss: 0.455549]\n",
      "[Epoch 11/200] [Batch 380/637] [D loss: 0.149816] [G loss: 0.546230]\n",
      "[Epoch 11/200] [Batch 381/637] [D loss: 0.165893] [G loss: 0.479581]\n",
      "[Epoch 11/200] [Batch 382/637] [D loss: 0.174805] [G loss: 0.621688]\n",
      "[Epoch 11/200] [Batch 383/637] [D loss: 0.144960] [G loss: 0.555894]\n",
      "[Epoch 11/200] [Batch 384/637] [D loss: 0.155299] [G loss: 0.488542]\n",
      "[Epoch 11/200] [Batch 385/637] [D loss: 0.174073] [G loss: 0.471693]\n",
      "[Epoch 11/200] [Batch 386/637] [D loss: 0.169410] [G loss: 0.504073]\n",
      "[Epoch 11/200] [Batch 387/637] [D loss: 0.154769] [G loss: 0.547476]\n",
      "[Epoch 11/200] [Batch 388/637] [D loss: 0.155463] [G loss: 0.543578]\n",
      "[Epoch 11/200] [Batch 389/637] [D loss: 0.170048] [G loss: 0.477982]\n",
      "[Epoch 11/200] [Batch 390/637] [D loss: 0.173173] [G loss: 0.517217]\n",
      "[Epoch 11/200] [Batch 391/637] [D loss: 0.152255] [G loss: 0.463133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 392/637] [D loss: 0.133969] [G loss: 0.587096]\n",
      "[Epoch 11/200] [Batch 393/637] [D loss: 0.154954] [G loss: 0.599497]\n",
      "[Epoch 11/200] [Batch 394/637] [D loss: 0.148086] [G loss: 0.516449]\n",
      "[Epoch 11/200] [Batch 395/637] [D loss: 0.157254] [G loss: 0.509127]\n",
      "[Epoch 11/200] [Batch 396/637] [D loss: 0.175495] [G loss: 0.501922]\n",
      "[Epoch 11/200] [Batch 397/637] [D loss: 0.177418] [G loss: 0.481250]\n",
      "[Epoch 11/200] [Batch 398/637] [D loss: 0.306234] [G loss: 0.518788]\n",
      "[Epoch 11/200] [Batch 399/637] [D loss: 0.232444] [G loss: 0.691375]\n",
      "[Epoch 11/200] [Batch 400/637] [D loss: 0.232426] [G loss: 0.625952]\n",
      "[Epoch 11/200] [Batch 401/637] [D loss: 0.183793] [G loss: 0.521885]\n",
      "[Epoch 11/200] [Batch 402/637] [D loss: 0.169948] [G loss: 0.438295]\n",
      "[Epoch 11/200] [Batch 403/637] [D loss: 0.167813] [G loss: 0.441111]\n",
      "[Epoch 11/200] [Batch 404/637] [D loss: 0.147487] [G loss: 0.471852]\n",
      "[Epoch 11/200] [Batch 405/637] [D loss: 0.155192] [G loss: 0.489278]\n",
      "[Epoch 11/200] [Batch 406/637] [D loss: 0.147518] [G loss: 0.504513]\n",
      "[Epoch 11/200] [Batch 407/637] [D loss: 0.150445] [G loss: 0.483026]\n",
      "[Epoch 11/200] [Batch 408/637] [D loss: 0.185269] [G loss: 0.396576]\n",
      "[Epoch 11/200] [Batch 409/637] [D loss: 0.148101] [G loss: 0.525389]\n",
      "[Epoch 11/200] [Batch 410/637] [D loss: 0.154178] [G loss: 0.498342]\n",
      "[Epoch 11/200] [Batch 411/637] [D loss: 0.159788] [G loss: 0.544418]\n",
      "[Epoch 11/200] [Batch 412/637] [D loss: 0.162433] [G loss: 0.540560]\n",
      "[Epoch 11/200] [Batch 413/637] [D loss: 0.145836] [G loss: 0.476720]\n",
      "[Epoch 11/200] [Batch 414/637] [D loss: 0.164308] [G loss: 0.438466]\n",
      "[Epoch 11/200] [Batch 415/637] [D loss: 0.146503] [G loss: 0.536687]\n",
      "[Epoch 11/200] [Batch 416/637] [D loss: 0.179414] [G loss: 0.499436]\n",
      "[Epoch 11/200] [Batch 417/637] [D loss: 0.179182] [G loss: 0.592839]\n",
      "[Epoch 11/200] [Batch 418/637] [D loss: 0.160459] [G loss: 0.530260]\n",
      "[Epoch 11/200] [Batch 419/637] [D loss: 0.199838] [G loss: 0.427533]\n",
      "[Epoch 11/200] [Batch 420/637] [D loss: 0.169901] [G loss: 0.472464]\n",
      "[Epoch 11/200] [Batch 421/637] [D loss: 0.155358] [G loss: 0.473377]\n",
      "[Epoch 11/200] [Batch 422/637] [D loss: 0.157429] [G loss: 0.553247]\n",
      "[Epoch 11/200] [Batch 423/637] [D loss: 0.147211] [G loss: 0.612441]\n",
      "[Epoch 11/200] [Batch 424/637] [D loss: 0.160165] [G loss: 0.453011]\n",
      "[Epoch 11/200] [Batch 425/637] [D loss: 0.170611] [G loss: 0.489259]\n",
      "[Epoch 11/200] [Batch 426/637] [D loss: 0.149871] [G loss: 0.576903]\n",
      "[Epoch 11/200] [Batch 427/637] [D loss: 0.157825] [G loss: 0.504131]\n",
      "[Epoch 11/200] [Batch 428/637] [D loss: 0.188251] [G loss: 0.471407]\n",
      "[Epoch 11/200] [Batch 429/637] [D loss: 0.180887] [G loss: 0.520229]\n",
      "[Epoch 11/200] [Batch 430/637] [D loss: 0.193680] [G loss: 0.459913]\n",
      "[Epoch 11/200] [Batch 431/637] [D loss: 0.168125] [G loss: 0.495653]\n",
      "[Epoch 11/200] [Batch 432/637] [D loss: 0.150121] [G loss: 0.523540]\n",
      "[Epoch 11/200] [Batch 433/637] [D loss: 0.191045] [G loss: 0.487459]\n",
      "[Epoch 11/200] [Batch 434/637] [D loss: 0.173385] [G loss: 0.436923]\n",
      "[Epoch 11/200] [Batch 435/637] [D loss: 0.156521] [G loss: 0.507555]\n",
      "[Epoch 11/200] [Batch 436/637] [D loss: 0.170882] [G loss: 0.491398]\n",
      "[Epoch 11/200] [Batch 437/637] [D loss: 0.176535] [G loss: 0.475599]\n",
      "[Epoch 11/200] [Batch 438/637] [D loss: 0.163081] [G loss: 0.567434]\n",
      "[Epoch 11/200] [Batch 439/637] [D loss: 0.187006] [G loss: 0.487374]\n",
      "[Epoch 11/200] [Batch 440/637] [D loss: 0.145824] [G loss: 0.537202]\n",
      "[Epoch 11/200] [Batch 441/637] [D loss: 0.154049] [G loss: 0.532231]\n",
      "[Epoch 11/200] [Batch 442/637] [D loss: 0.162234] [G loss: 0.591753]\n",
      "[Epoch 11/200] [Batch 443/637] [D loss: 0.143361] [G loss: 0.515362]\n",
      "[Epoch 11/200] [Batch 444/637] [D loss: 0.156707] [G loss: 0.496760]\n",
      "[Epoch 11/200] [Batch 445/637] [D loss: 0.137141] [G loss: 0.574036]\n",
      "[Epoch 11/200] [Batch 446/637] [D loss: 0.150438] [G loss: 0.553679]\n",
      "[Epoch 11/200] [Batch 447/637] [D loss: 0.166775] [G loss: 0.512559]\n",
      "[Epoch 11/200] [Batch 448/637] [D loss: 0.186398] [G loss: 0.537142]\n",
      "[Epoch 11/200] [Batch 449/637] [D loss: 0.185274] [G loss: 0.629749]\n",
      "[Epoch 11/200] [Batch 450/637] [D loss: 0.157290] [G loss: 0.613857]\n",
      "[Epoch 11/200] [Batch 451/637] [D loss: 0.232513] [G loss: 0.348699]\n",
      "[Epoch 11/200] [Batch 452/637] [D loss: 0.305450] [G loss: 0.654662]\n",
      "[Epoch 11/200] [Batch 453/637] [D loss: 0.197715] [G loss: 0.659738]\n",
      "[Epoch 11/200] [Batch 454/637] [D loss: 0.183696] [G loss: 0.545352]\n",
      "[Epoch 11/200] [Batch 455/637] [D loss: 0.167446] [G loss: 0.512146]\n",
      "[Epoch 11/200] [Batch 456/637] [D loss: 0.201282] [G loss: 0.379252]\n",
      "[Epoch 11/200] [Batch 457/637] [D loss: 0.162811] [G loss: 0.439879]\n",
      "[Epoch 11/200] [Batch 458/637] [D loss: 0.173546] [G loss: 0.511902]\n",
      "[Epoch 11/200] [Batch 459/637] [D loss: 0.190224] [G loss: 0.447937]\n",
      "[Epoch 11/200] [Batch 460/637] [D loss: 0.152380] [G loss: 0.472750]\n",
      "[Epoch 11/200] [Batch 461/637] [D loss: 0.152115] [G loss: 0.487297]\n",
      "[Epoch 11/200] [Batch 462/637] [D loss: 0.168969] [G loss: 0.500665]\n",
      "[Epoch 11/200] [Batch 463/637] [D loss: 0.166745] [G loss: 0.519993]\n",
      "[Epoch 11/200] [Batch 464/637] [D loss: 0.134811] [G loss: 0.574559]\n",
      "[Epoch 11/200] [Batch 465/637] [D loss: 0.162520] [G loss: 0.495163]\n",
      "[Epoch 11/200] [Batch 466/637] [D loss: 0.152721] [G loss: 0.535096]\n",
      "[Epoch 11/200] [Batch 467/637] [D loss: 0.148999] [G loss: 0.506644]\n",
      "[Epoch 11/200] [Batch 468/637] [D loss: 0.158831] [G loss: 0.480702]\n",
      "[Epoch 11/200] [Batch 469/637] [D loss: 0.123743] [G loss: 0.553530]\n",
      "[Epoch 11/200] [Batch 470/637] [D loss: 0.146157] [G loss: 0.495295]\n",
      "[Epoch 11/200] [Batch 471/637] [D loss: 0.145688] [G loss: 0.504698]\n",
      "[Epoch 11/200] [Batch 472/637] [D loss: 0.166322] [G loss: 0.525291]\n",
      "[Epoch 11/200] [Batch 473/637] [D loss: 0.172915] [G loss: 0.462337]\n",
      "[Epoch 11/200] [Batch 474/637] [D loss: 0.179053] [G loss: 0.459432]\n",
      "[Epoch 11/200] [Batch 475/637] [D loss: 0.175460] [G loss: 0.537318]\n",
      "[Epoch 11/200] [Batch 476/637] [D loss: 0.166914] [G loss: 0.517343]\n",
      "[Epoch 11/200] [Batch 477/637] [D loss: 0.179936] [G loss: 0.472349]\n",
      "[Epoch 11/200] [Batch 478/637] [D loss: 0.152789] [G loss: 0.486877]\n",
      "[Epoch 11/200] [Batch 479/637] [D loss: 0.122384] [G loss: 0.542259]\n",
      "[Epoch 11/200] [Batch 480/637] [D loss: 0.174692] [G loss: 0.454664]\n",
      "[Epoch 11/200] [Batch 481/637] [D loss: 0.154870] [G loss: 0.560299]\n",
      "[Epoch 11/200] [Batch 482/637] [D loss: 0.140654] [G loss: 0.537525]\n",
      "[Epoch 11/200] [Batch 483/637] [D loss: 0.160447] [G loss: 0.476366]\n",
      "[Epoch 11/200] [Batch 484/637] [D loss: 0.147968] [G loss: 0.543562]\n",
      "[Epoch 11/200] [Batch 485/637] [D loss: 0.174906] [G loss: 0.459096]\n",
      "[Epoch 11/200] [Batch 486/637] [D loss: 0.149284] [G loss: 0.536974]\n",
      "[Epoch 11/200] [Batch 487/637] [D loss: 0.182761] [G loss: 0.465040]\n",
      "[Epoch 11/200] [Batch 488/637] [D loss: 0.174137] [G loss: 0.528255]\n",
      "[Epoch 11/200] [Batch 489/637] [D loss: 0.134714] [G loss: 0.504589]\n",
      "[Epoch 11/200] [Batch 490/637] [D loss: 0.150688] [G loss: 0.463987]\n",
      "[Epoch 11/200] [Batch 491/637] [D loss: 0.160565] [G loss: 0.474512]\n",
      "[Epoch 11/200] [Batch 492/637] [D loss: 0.133962] [G loss: 0.552155]\n",
      "[Epoch 11/200] [Batch 493/637] [D loss: 0.149955] [G loss: 0.546580]\n",
      "[Epoch 11/200] [Batch 494/637] [D loss: 0.134024] [G loss: 0.534870]\n",
      "[Epoch 11/200] [Batch 495/637] [D loss: 0.159261] [G loss: 0.461027]\n",
      "[Epoch 11/200] [Batch 496/637] [D loss: 0.156696] [G loss: 0.514501]\n",
      "[Epoch 11/200] [Batch 497/637] [D loss: 0.159272] [G loss: 0.609797]\n",
      "[Epoch 11/200] [Batch 498/637] [D loss: 0.191734] [G loss: 0.453339]\n",
      "[Epoch 11/200] [Batch 499/637] [D loss: 0.152482] [G loss: 0.537271]\n",
      "[Epoch 11/200] [Batch 500/637] [D loss: 0.164234] [G loss: 0.512701]\n",
      "[Epoch 11/200] [Batch 501/637] [D loss: 0.160451] [G loss: 0.535920]\n",
      "[Epoch 11/200] [Batch 502/637] [D loss: 0.163204] [G loss: 0.473031]\n",
      "[Epoch 11/200] [Batch 503/637] [D loss: 0.165394] [G loss: 0.474517]\n",
      "[Epoch 11/200] [Batch 504/637] [D loss: 0.140485] [G loss: 0.551282]\n",
      "[Epoch 11/200] [Batch 505/637] [D loss: 0.156135] [G loss: 0.470476]\n",
      "[Epoch 11/200] [Batch 506/637] [D loss: 0.140988] [G loss: 0.599883]\n",
      "[Epoch 11/200] [Batch 507/637] [D loss: 0.162154] [G loss: 0.523818]\n",
      "[Epoch 11/200] [Batch 508/637] [D loss: 0.154084] [G loss: 0.495477]\n",
      "[Epoch 11/200] [Batch 509/637] [D loss: 0.166461] [G loss: 0.546384]\n",
      "[Epoch 11/200] [Batch 510/637] [D loss: 0.160453] [G loss: 0.548507]\n",
      "[Epoch 11/200] [Batch 511/637] [D loss: 0.150108] [G loss: 0.537888]\n",
      "[Epoch 11/200] [Batch 512/637] [D loss: 0.198540] [G loss: 0.374896]\n",
      "[Epoch 11/200] [Batch 513/637] [D loss: 0.230472] [G loss: 0.644532]\n",
      "[Epoch 11/200] [Batch 514/637] [D loss: 0.162149] [G loss: 0.616992]\n",
      "[Epoch 11/200] [Batch 515/637] [D loss: 0.170535] [G loss: 0.541595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 516/637] [D loss: 0.168272] [G loss: 0.502770]\n",
      "[Epoch 11/200] [Batch 517/637] [D loss: 0.163849] [G loss: 0.521194]\n",
      "[Epoch 11/200] [Batch 518/637] [D loss: 0.137436] [G loss: 0.531294]\n",
      "[Epoch 11/200] [Batch 519/637] [D loss: 0.142742] [G loss: 0.543987]\n",
      "[Epoch 11/200] [Batch 520/637] [D loss: 0.139390] [G loss: 0.483144]\n",
      "[Epoch 11/200] [Batch 521/637] [D loss: 0.136461] [G loss: 0.517768]\n",
      "[Epoch 11/200] [Batch 522/637] [D loss: 0.152578] [G loss: 0.531124]\n",
      "[Epoch 11/200] [Batch 523/637] [D loss: 0.152821] [G loss: 0.608588]\n",
      "[Epoch 11/200] [Batch 524/637] [D loss: 0.139874] [G loss: 0.551385]\n",
      "[Epoch 11/200] [Batch 525/637] [D loss: 0.153828] [G loss: 0.471017]\n",
      "[Epoch 11/200] [Batch 526/637] [D loss: 0.170106] [G loss: 0.497955]\n",
      "[Epoch 11/200] [Batch 527/637] [D loss: 0.175539] [G loss: 0.567720]\n",
      "[Epoch 11/200] [Batch 528/637] [D loss: 0.161835] [G loss: 0.609665]\n",
      "[Epoch 11/200] [Batch 529/637] [D loss: 0.154805] [G loss: 0.484506]\n",
      "[Epoch 11/200] [Batch 530/637] [D loss: 0.163895] [G loss: 0.438668]\n",
      "[Epoch 11/200] [Batch 531/637] [D loss: 0.154694] [G loss: 0.558380]\n",
      "[Epoch 11/200] [Batch 532/637] [D loss: 0.182658] [G loss: 0.529003]\n",
      "[Epoch 11/200] [Batch 533/637] [D loss: 0.155143] [G loss: 0.517083]\n",
      "[Epoch 11/200] [Batch 534/637] [D loss: 0.175715] [G loss: 0.489779]\n",
      "[Epoch 11/200] [Batch 535/637] [D loss: 0.152947] [G loss: 0.516571]\n",
      "[Epoch 11/200] [Batch 536/637] [D loss: 0.179517] [G loss: 0.513843]\n",
      "[Epoch 11/200] [Batch 537/637] [D loss: 0.160379] [G loss: 0.478861]\n",
      "[Epoch 11/200] [Batch 538/637] [D loss: 0.156604] [G loss: 0.478405]\n",
      "[Epoch 11/200] [Batch 539/637] [D loss: 0.240851] [G loss: 0.594310]\n",
      "[Epoch 11/200] [Batch 540/637] [D loss: 0.180063] [G loss: 0.593760]\n",
      "[Epoch 11/200] [Batch 541/637] [D loss: 0.166773] [G loss: 0.486283]\n",
      "[Epoch 11/200] [Batch 542/637] [D loss: 0.160141] [G loss: 0.500769]\n",
      "[Epoch 11/200] [Batch 543/637] [D loss: 0.174821] [G loss: 0.434396]\n",
      "[Epoch 11/200] [Batch 544/637] [D loss: 0.160426] [G loss: 0.443631]\n",
      "[Epoch 11/200] [Batch 545/637] [D loss: 0.147784] [G loss: 0.440609]\n",
      "[Epoch 11/200] [Batch 546/637] [D loss: 0.134745] [G loss: 0.450273]\n",
      "[Epoch 11/200] [Batch 547/637] [D loss: 0.139411] [G loss: 0.503525]\n",
      "[Epoch 11/200] [Batch 548/637] [D loss: 0.174729] [G loss: 0.484366]\n",
      "[Epoch 11/200] [Batch 549/637] [D loss: 0.161904] [G loss: 0.542869]\n",
      "[Epoch 11/200] [Batch 550/637] [D loss: 0.154231] [G loss: 0.492841]\n",
      "[Epoch 11/200] [Batch 551/637] [D loss: 0.160899] [G loss: 0.492158]\n",
      "[Epoch 11/200] [Batch 552/637] [D loss: 0.123067] [G loss: 0.544886]\n",
      "[Epoch 11/200] [Batch 553/637] [D loss: 0.151808] [G loss: 0.521962]\n",
      "[Epoch 11/200] [Batch 554/637] [D loss: 0.156276] [G loss: 0.471177]\n",
      "[Epoch 11/200] [Batch 555/637] [D loss: 0.131694] [G loss: 0.560685]\n",
      "[Epoch 11/200] [Batch 556/637] [D loss: 0.187143] [G loss: 0.470200]\n",
      "[Epoch 11/200] [Batch 557/637] [D loss: 0.154299] [G loss: 0.546767]\n",
      "[Epoch 11/200] [Batch 558/637] [D loss: 0.165511] [G loss: 0.499027]\n",
      "[Epoch 11/200] [Batch 559/637] [D loss: 0.141317] [G loss: 0.473120]\n",
      "[Epoch 11/200] [Batch 560/637] [D loss: 0.163863] [G loss: 0.471419]\n",
      "[Epoch 11/200] [Batch 561/637] [D loss: 0.155388] [G loss: 0.552887]\n",
      "[Epoch 11/200] [Batch 562/637] [D loss: 0.138227] [G loss: 0.550958]\n",
      "[Epoch 11/200] [Batch 563/637] [D loss: 0.174583] [G loss: 0.442742]\n",
      "[Epoch 11/200] [Batch 564/637] [D loss: 0.155388] [G loss: 0.475534]\n",
      "[Epoch 11/200] [Batch 565/637] [D loss: 0.148779] [G loss: 0.501242]\n",
      "[Epoch 11/200] [Batch 566/637] [D loss: 0.147158] [G loss: 0.524734]\n",
      "[Epoch 11/200] [Batch 567/637] [D loss: 0.150865] [G loss: 0.499453]\n",
      "[Epoch 11/200] [Batch 568/637] [D loss: 0.177336] [G loss: 0.441472]\n",
      "[Epoch 11/200] [Batch 569/637] [D loss: 0.136760] [G loss: 0.505808]\n",
      "[Epoch 11/200] [Batch 570/637] [D loss: 0.168219] [G loss: 0.471112]\n",
      "[Epoch 11/200] [Batch 571/637] [D loss: 0.147595] [G loss: 0.551537]\n",
      "[Epoch 11/200] [Batch 572/637] [D loss: 0.141239] [G loss: 0.488142]\n",
      "[Epoch 11/200] [Batch 573/637] [D loss: 0.164116] [G loss: 0.484609]\n",
      "[Epoch 11/200] [Batch 574/637] [D loss: 0.184554] [G loss: 0.524266]\n",
      "[Epoch 11/200] [Batch 575/637] [D loss: 0.137525] [G loss: 0.512120]\n",
      "[Epoch 11/200] [Batch 576/637] [D loss: 0.173964] [G loss: 0.448111]\n",
      "[Epoch 11/200] [Batch 577/637] [D loss: 0.180522] [G loss: 0.526125]\n",
      "[Epoch 11/200] [Batch 578/637] [D loss: 0.194486] [G loss: 0.540789]\n",
      "[Epoch 11/200] [Batch 579/637] [D loss: 0.151072] [G loss: 0.563878]\n",
      "[Epoch 11/200] [Batch 580/637] [D loss: 0.188704] [G loss: 0.450818]\n",
      "[Epoch 11/200] [Batch 581/637] [D loss: 0.177727] [G loss: 0.444220]\n",
      "[Epoch 11/200] [Batch 582/637] [D loss: 0.151489] [G loss: 0.459869]\n",
      "[Epoch 11/200] [Batch 583/637] [D loss: 0.165500] [G loss: 0.478314]\n",
      "[Epoch 11/200] [Batch 584/637] [D loss: 0.172728] [G loss: 0.511433]\n",
      "[Epoch 11/200] [Batch 585/637] [D loss: 0.194926] [G loss: 0.475467]\n",
      "[Epoch 11/200] [Batch 586/637] [D loss: 0.156238] [G loss: 0.490597]\n",
      "[Epoch 11/200] [Batch 587/637] [D loss: 0.171373] [G loss: 0.518924]\n",
      "[Epoch 11/200] [Batch 588/637] [D loss: 0.164921] [G loss: 0.496432]\n",
      "[Epoch 11/200] [Batch 589/637] [D loss: 0.173252] [G loss: 0.524047]\n",
      "[Epoch 11/200] [Batch 590/637] [D loss: 0.165879] [G loss: 0.568729]\n",
      "[Epoch 11/200] [Batch 591/637] [D loss: 0.165874] [G loss: 0.497642]\n",
      "[Epoch 11/200] [Batch 592/637] [D loss: 0.146737] [G loss: 0.460827]\n",
      "[Epoch 11/200] [Batch 593/637] [D loss: 0.175189] [G loss: 0.521472]\n",
      "[Epoch 11/200] [Batch 594/637] [D loss: 0.153107] [G loss: 0.574088]\n",
      "[Epoch 11/200] [Batch 595/637] [D loss: 0.175142] [G loss: 0.490121]\n",
      "[Epoch 11/200] [Batch 596/637] [D loss: 0.147508] [G loss: 0.571455]\n",
      "[Epoch 11/200] [Batch 597/637] [D loss: 0.149510] [G loss: 0.526852]\n",
      "[Epoch 11/200] [Batch 598/637] [D loss: 0.162625] [G loss: 0.502947]\n",
      "[Epoch 11/200] [Batch 599/637] [D loss: 0.155248] [G loss: 0.507582]\n",
      "[Epoch 11/200] [Batch 600/637] [D loss: 0.164921] [G loss: 0.661581]\n",
      "[Epoch 11/200] [Batch 601/637] [D loss: 0.169740] [G loss: 0.531544]\n",
      "[Epoch 11/200] [Batch 602/637] [D loss: 0.160851] [G loss: 0.545043]\n",
      "[Epoch 11/200] [Batch 603/637] [D loss: 0.141301] [G loss: 0.595695]\n",
      "[Epoch 11/200] [Batch 604/637] [D loss: 0.166465] [G loss: 0.533123]\n",
      "[Epoch 11/200] [Batch 605/637] [D loss: 0.204945] [G loss: 0.548335]\n",
      "[Epoch 11/200] [Batch 606/637] [D loss: 0.160006] [G loss: 0.584297]\n",
      "[Epoch 11/200] [Batch 607/637] [D loss: 0.165449] [G loss: 0.485247]\n",
      "[Epoch 11/200] [Batch 608/637] [D loss: 0.159355] [G loss: 0.546185]\n",
      "[Epoch 11/200] [Batch 609/637] [D loss: 0.138415] [G loss: 0.573434]\n",
      "[Epoch 11/200] [Batch 610/637] [D loss: 0.162498] [G loss: 0.500662]\n",
      "[Epoch 11/200] [Batch 611/637] [D loss: 0.139549] [G loss: 0.512087]\n",
      "[Epoch 11/200] [Batch 612/637] [D loss: 0.147392] [G loss: 0.558345]\n",
      "[Epoch 11/200] [Batch 613/637] [D loss: 0.172151] [G loss: 0.544677]\n",
      "[Epoch 11/200] [Batch 614/637] [D loss: 0.156642] [G loss: 0.544678]\n",
      "[Epoch 11/200] [Batch 615/637] [D loss: 0.149848] [G loss: 0.558734]\n",
      "[Epoch 11/200] [Batch 616/637] [D loss: 0.153439] [G loss: 0.531423]\n",
      "[Epoch 11/200] [Batch 617/637] [D loss: 0.157021] [G loss: 0.511936]\n",
      "[Epoch 11/200] [Batch 618/637] [D loss: 0.157595] [G loss: 0.496343]\n",
      "[Epoch 11/200] [Batch 619/637] [D loss: 0.147662] [G loss: 0.453482]\n",
      "[Epoch 11/200] [Batch 620/637] [D loss: 0.158533] [G loss: 0.455949]\n",
      "[Epoch 11/200] [Batch 621/637] [D loss: 0.167603] [G loss: 0.496184]\n",
      "[Epoch 11/200] [Batch 622/637] [D loss: 0.146383] [G loss: 0.536086]\n",
      "[Epoch 11/200] [Batch 623/637] [D loss: 0.162543] [G loss: 0.559650]\n",
      "[Epoch 11/200] [Batch 624/637] [D loss: 0.155731] [G loss: 0.563281]\n",
      "[Epoch 11/200] [Batch 625/637] [D loss: 0.170220] [G loss: 0.515891]\n",
      "[Epoch 11/200] [Batch 626/637] [D loss: 0.148214] [G loss: 0.478178]\n",
      "[Epoch 11/200] [Batch 627/637] [D loss: 0.229744] [G loss: 0.558957]\n",
      "[Epoch 11/200] [Batch 628/637] [D loss: 0.164710] [G loss: 0.460161]\n",
      "[Epoch 11/200] [Batch 629/637] [D loss: 0.170831] [G loss: 0.449207]\n",
      "[Epoch 11/200] [Batch 630/637] [D loss: 0.167940] [G loss: 0.462024]\n",
      "[Epoch 11/200] [Batch 631/637] [D loss: 0.135995] [G loss: 0.506187]\n",
      "[Epoch 11/200] [Batch 632/637] [D loss: 0.183342] [G loss: 0.451236]\n",
      "[Epoch 11/200] [Batch 633/637] [D loss: 0.136826] [G loss: 0.498178]\n",
      "[Epoch 11/200] [Batch 634/637] [D loss: 0.160175] [G loss: 0.463493]\n",
      "[Epoch 11/200] [Batch 635/637] [D loss: 0.138288] [G loss: 0.489650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 636/637] [D loss: 0.153963] [G loss: 0.438211]\n",
      "[Epoch 12/200] [Batch 0/637] [D loss: 0.122332] [G loss: 0.555938]\n",
      "[Epoch 12/200] [Batch 1/637] [D loss: 0.131965] [G loss: 0.520508]\n",
      "[Epoch 12/200] [Batch 2/637] [D loss: 0.124713] [G loss: 0.572218]\n",
      "[Epoch 12/200] [Batch 3/637] [D loss: 0.159004] [G loss: 0.501047]\n",
      "[Epoch 12/200] [Batch 4/637] [D loss: 0.162810] [G loss: 0.540636]\n",
      "[Epoch 12/200] [Batch 5/637] [D loss: 0.138975] [G loss: 0.541826]\n",
      "[Epoch 12/200] [Batch 6/637] [D loss: 0.164277] [G loss: 0.442425]\n",
      "[Epoch 12/200] [Batch 7/637] [D loss: 0.145127] [G loss: 0.528807]\n",
      "[Epoch 12/200] [Batch 8/637] [D loss: 0.166913] [G loss: 0.483865]\n",
      "[Epoch 12/200] [Batch 9/637] [D loss: 0.159754] [G loss: 0.525374]\n",
      "[Epoch 12/200] [Batch 10/637] [D loss: 0.171276] [G loss: 0.539312]\n",
      "[Epoch 12/200] [Batch 11/637] [D loss: 0.142453] [G loss: 0.502984]\n",
      "[Epoch 12/200] [Batch 12/637] [D loss: 0.174476] [G loss: 0.440986]\n",
      "[Epoch 12/200] [Batch 13/637] [D loss: 0.163137] [G loss: 0.522669]\n",
      "[Epoch 12/200] [Batch 14/637] [D loss: 0.180968] [G loss: 0.408265]\n",
      "[Epoch 12/200] [Batch 15/637] [D loss: 0.183741] [G loss: 0.464453]\n",
      "[Epoch 12/200] [Batch 16/637] [D loss: 0.163218] [G loss: 0.525862]\n",
      "[Epoch 12/200] [Batch 17/637] [D loss: 0.184393] [G loss: 0.481516]\n",
      "[Epoch 12/200] [Batch 18/637] [D loss: 0.166306] [G loss: 0.459435]\n",
      "[Epoch 12/200] [Batch 19/637] [D loss: 0.157323] [G loss: 0.477457]\n",
      "[Epoch 12/200] [Batch 20/637] [D loss: 0.161872] [G loss: 0.584802]\n",
      "[Epoch 12/200] [Batch 21/637] [D loss: 0.167726] [G loss: 0.551741]\n",
      "[Epoch 12/200] [Batch 22/637] [D loss: 0.156880] [G loss: 0.482463]\n",
      "[Epoch 12/200] [Batch 23/637] [D loss: 0.172310] [G loss: 0.434241]\n",
      "[Epoch 12/200] [Batch 24/637] [D loss: 0.162314] [G loss: 0.496712]\n",
      "[Epoch 12/200] [Batch 25/637] [D loss: 0.150911] [G loss: 0.556514]\n",
      "[Epoch 12/200] [Batch 26/637] [D loss: 0.161125] [G loss: 0.514233]\n",
      "[Epoch 12/200] [Batch 27/637] [D loss: 0.154477] [G loss: 0.443913]\n",
      "[Epoch 12/200] [Batch 28/637] [D loss: 0.162586] [G loss: 0.471351]\n",
      "[Epoch 12/200] [Batch 29/637] [D loss: 0.168150] [G loss: 0.507870]\n",
      "[Epoch 12/200] [Batch 30/637] [D loss: 0.173483] [G loss: 0.551849]\n",
      "[Epoch 12/200] [Batch 31/637] [D loss: 0.153138] [G loss: 0.488491]\n",
      "[Epoch 12/200] [Batch 32/637] [D loss: 0.159518] [G loss: 0.467198]\n",
      "[Epoch 12/200] [Batch 33/637] [D loss: 0.169083] [G loss: 0.463111]\n",
      "[Epoch 12/200] [Batch 34/637] [D loss: 0.159380] [G loss: 0.479783]\n",
      "[Epoch 12/200] [Batch 35/637] [D loss: 0.149003] [G loss: 0.518764]\n",
      "[Epoch 12/200] [Batch 36/637] [D loss: 0.135894] [G loss: 0.530939]\n",
      "[Epoch 12/200] [Batch 37/637] [D loss: 0.166465] [G loss: 0.498652]\n",
      "[Epoch 12/200] [Batch 38/637] [D loss: 0.146659] [G loss: 0.503147]\n",
      "[Epoch 12/200] [Batch 39/637] [D loss: 0.129223] [G loss: 0.550513]\n",
      "[Epoch 12/200] [Batch 40/637] [D loss: 0.164569] [G loss: 0.522142]\n",
      "[Epoch 12/200] [Batch 41/637] [D loss: 0.141965] [G loss: 0.490248]\n",
      "[Epoch 12/200] [Batch 42/637] [D loss: 0.151138] [G loss: 0.532543]\n",
      "[Epoch 12/200] [Batch 43/637] [D loss: 0.136144] [G loss: 0.559107]\n",
      "[Epoch 12/200] [Batch 44/637] [D loss: 0.164866] [G loss: 0.531448]\n",
      "[Epoch 12/200] [Batch 45/637] [D loss: 0.198651] [G loss: 0.504014]\n",
      "[Epoch 12/200] [Batch 46/637] [D loss: 0.168674] [G loss: 0.513083]\n",
      "[Epoch 12/200] [Batch 47/637] [D loss: 0.200207] [G loss: 0.422546]\n",
      "[Epoch 12/200] [Batch 48/637] [D loss: 0.171721] [G loss: 0.607545]\n",
      "[Epoch 12/200] [Batch 49/637] [D loss: 0.231509] [G loss: 0.479266]\n",
      "[Epoch 12/200] [Batch 50/637] [D loss: 0.190329] [G loss: 0.566302]\n",
      "[Epoch 12/200] [Batch 51/637] [D loss: 0.191796] [G loss: 0.468178]\n",
      "[Epoch 12/200] [Batch 52/637] [D loss: 0.172329] [G loss: 0.447818]\n",
      "[Epoch 12/200] [Batch 53/637] [D loss: 0.169008] [G loss: 0.458646]\n",
      "[Epoch 12/200] [Batch 54/637] [D loss: 0.161937] [G loss: 0.433964]\n",
      "[Epoch 12/200] [Batch 55/637] [D loss: 0.200021] [G loss: 0.391150]\n",
      "[Epoch 12/200] [Batch 56/637] [D loss: 0.163920] [G loss: 0.598103]\n",
      "[Epoch 12/200] [Batch 57/637] [D loss: 0.169203] [G loss: 0.544107]\n",
      "[Epoch 12/200] [Batch 58/637] [D loss: 0.155574] [G loss: 0.466026]\n",
      "[Epoch 12/200] [Batch 59/637] [D loss: 0.160788] [G loss: 0.454365]\n",
      "[Epoch 12/200] [Batch 60/637] [D loss: 0.133744] [G loss: 0.508370]\n",
      "[Epoch 12/200] [Batch 61/637] [D loss: 0.148822] [G loss: 0.477361]\n",
      "[Epoch 12/200] [Batch 62/637] [D loss: 0.134358] [G loss: 0.495584]\n",
      "[Epoch 12/200] [Batch 63/637] [D loss: 0.151458] [G loss: 0.526693]\n",
      "[Epoch 12/200] [Batch 64/637] [D loss: 0.131839] [G loss: 0.516079]\n",
      "[Epoch 12/200] [Batch 65/637] [D loss: 0.124937] [G loss: 0.572607]\n",
      "[Epoch 12/200] [Batch 66/637] [D loss: 0.153837] [G loss: 0.506836]\n",
      "[Epoch 12/200] [Batch 67/637] [D loss: 0.153887] [G loss: 0.600674]\n",
      "[Epoch 12/200] [Batch 68/637] [D loss: 0.148438] [G loss: 0.566402]\n",
      "[Epoch 12/200] [Batch 69/637] [D loss: 0.128436] [G loss: 0.539836]\n",
      "[Epoch 12/200] [Batch 70/637] [D loss: 0.167961] [G loss: 0.453449]\n",
      "[Epoch 12/200] [Batch 71/637] [D loss: 0.177053] [G loss: 0.597110]\n",
      "[Epoch 12/200] [Batch 72/637] [D loss: 0.136592] [G loss: 0.518971]\n",
      "[Epoch 12/200] [Batch 73/637] [D loss: 0.165824] [G loss: 0.486143]\n",
      "[Epoch 12/200] [Batch 74/637] [D loss: 0.185539] [G loss: 0.402603]\n",
      "[Epoch 12/200] [Batch 75/637] [D loss: 0.190868] [G loss: 0.584673]\n",
      "[Epoch 12/200] [Batch 76/637] [D loss: 0.167080] [G loss: 0.567016]\n",
      "[Epoch 12/200] [Batch 77/637] [D loss: 0.173211] [G loss: 0.488826]\n",
      "[Epoch 12/200] [Batch 78/637] [D loss: 0.172407] [G loss: 0.469021]\n",
      "[Epoch 12/200] [Batch 79/637] [D loss: 0.179441] [G loss: 0.497242]\n",
      "[Epoch 12/200] [Batch 80/637] [D loss: 0.180188] [G loss: 0.459378]\n",
      "[Epoch 12/200] [Batch 81/637] [D loss: 0.159679] [G loss: 0.571952]\n",
      "[Epoch 12/200] [Batch 82/637] [D loss: 0.142467] [G loss: 0.597488]\n",
      "[Epoch 12/200] [Batch 83/637] [D loss: 0.188260] [G loss: 0.539869]\n",
      "[Epoch 12/200] [Batch 84/637] [D loss: 0.168855] [G loss: 0.506311]\n",
      "[Epoch 12/200] [Batch 85/637] [D loss: 0.189642] [G loss: 0.581739]\n",
      "[Epoch 12/200] [Batch 86/637] [D loss: 0.156714] [G loss: 0.578095]\n",
      "[Epoch 12/200] [Batch 87/637] [D loss: 0.153978] [G loss: 0.570230]\n",
      "[Epoch 12/200] [Batch 88/637] [D loss: 0.168947] [G loss: 0.469959]\n",
      "[Epoch 12/200] [Batch 89/637] [D loss: 0.156877] [G loss: 0.521493]\n",
      "[Epoch 12/200] [Batch 90/637] [D loss: 0.153493] [G loss: 0.503531]\n",
      "[Epoch 12/200] [Batch 91/637] [D loss: 0.159231] [G loss: 0.508278]\n",
      "[Epoch 12/200] [Batch 92/637] [D loss: 0.165358] [G loss: 0.547632]\n",
      "[Epoch 12/200] [Batch 93/637] [D loss: 0.163162] [G loss: 0.485854]\n",
      "[Epoch 12/200] [Batch 94/637] [D loss: 0.135990] [G loss: 0.500450]\n",
      "[Epoch 12/200] [Batch 95/637] [D loss: 0.201278] [G loss: 0.510372]\n",
      "[Epoch 12/200] [Batch 96/637] [D loss: 0.176309] [G loss: 0.762779]\n",
      "[Epoch 12/200] [Batch 97/637] [D loss: 0.182578] [G loss: 0.552017]\n",
      "[Epoch 12/200] [Batch 98/637] [D loss: 0.170273] [G loss: 0.535599]\n",
      "[Epoch 12/200] [Batch 99/637] [D loss: 0.151235] [G loss: 0.512507]\n",
      "[Epoch 12/200] [Batch 100/637] [D loss: 0.152473] [G loss: 0.495954]\n",
      "[Epoch 12/200] [Batch 101/637] [D loss: 0.156628] [G loss: 0.479964]\n",
      "[Epoch 12/200] [Batch 102/637] [D loss: 0.135369] [G loss: 0.521005]\n",
      "[Epoch 12/200] [Batch 103/637] [D loss: 0.168902] [G loss: 0.490984]\n",
      "[Epoch 12/200] [Batch 104/637] [D loss: 0.150933] [G loss: 0.535940]\n",
      "[Epoch 12/200] [Batch 105/637] [D loss: 0.134230] [G loss: 0.516798]\n",
      "[Epoch 12/200] [Batch 106/637] [D loss: 0.142727] [G loss: 0.498222]\n",
      "[Epoch 12/200] [Batch 107/637] [D loss: 0.153744] [G loss: 0.539119]\n",
      "[Epoch 12/200] [Batch 108/637] [D loss: 0.171547] [G loss: 0.519611]\n",
      "[Epoch 12/200] [Batch 109/637] [D loss: 0.149262] [G loss: 0.477590]\n",
      "[Epoch 12/200] [Batch 110/637] [D loss: 0.168396] [G loss: 0.483300]\n",
      "[Epoch 12/200] [Batch 111/637] [D loss: 0.170066] [G loss: 0.514692]\n",
      "[Epoch 12/200] [Batch 112/637] [D loss: 0.157679] [G loss: 0.509875]\n",
      "[Epoch 12/200] [Batch 113/637] [D loss: 0.143421] [G loss: 0.620790]\n",
      "[Epoch 12/200] [Batch 114/637] [D loss: 0.155730] [G loss: 0.520172]\n",
      "[Epoch 12/200] [Batch 115/637] [D loss: 0.178871] [G loss: 0.465549]\n",
      "[Epoch 12/200] [Batch 116/637] [D loss: 0.195165] [G loss: 0.479672]\n",
      "[Epoch 12/200] [Batch 117/637] [D loss: 0.184539] [G loss: 0.477988]\n",
      "[Epoch 12/200] [Batch 118/637] [D loss: 0.170736] [G loss: 0.447501]\n",
      "[Epoch 12/200] [Batch 119/637] [D loss: 0.169131] [G loss: 0.485027]\n",
      "[Epoch 12/200] [Batch 120/637] [D loss: 0.148809] [G loss: 0.512397]\n",
      "[Epoch 12/200] [Batch 121/637] [D loss: 0.169117] [G loss: 0.458404]\n",
      "[Epoch 12/200] [Batch 122/637] [D loss: 0.140456] [G loss: 0.489324]\n",
      "[Epoch 12/200] [Batch 123/637] [D loss: 0.161618] [G loss: 0.461774]\n",
      "[Epoch 12/200] [Batch 124/637] [D loss: 0.174558] [G loss: 0.540965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 125/637] [D loss: 0.142623] [G loss: 0.500685]\n",
      "[Epoch 12/200] [Batch 126/637] [D loss: 0.167693] [G loss: 0.419918]\n",
      "[Epoch 12/200] [Batch 127/637] [D loss: 0.163249] [G loss: 0.509955]\n",
      "[Epoch 12/200] [Batch 128/637] [D loss: 0.168917] [G loss: 0.534650]\n",
      "[Epoch 12/200] [Batch 129/637] [D loss: 0.166958] [G loss: 0.439040]\n",
      "[Epoch 12/200] [Batch 130/637] [D loss: 0.163950] [G loss: 0.456730]\n",
      "[Epoch 12/200] [Batch 131/637] [D loss: 0.158338] [G loss: 0.455504]\n",
      "[Epoch 12/200] [Batch 132/637] [D loss: 0.163283] [G loss: 0.529646]\n",
      "[Epoch 12/200] [Batch 133/637] [D loss: 0.148220] [G loss: 0.469693]\n",
      "[Epoch 12/200] [Batch 134/637] [D loss: 0.135527] [G loss: 0.523900]\n",
      "[Epoch 12/200] [Batch 135/637] [D loss: 0.175520] [G loss: 0.473282]\n",
      "[Epoch 12/200] [Batch 136/637] [D loss: 0.184936] [G loss: 0.547976]\n",
      "[Epoch 12/200] [Batch 137/637] [D loss: 0.182278] [G loss: 0.489497]\n",
      "[Epoch 12/200] [Batch 138/637] [D loss: 0.184092] [G loss: 0.501299]\n",
      "[Epoch 12/200] [Batch 139/637] [D loss: 0.171798] [G loss: 0.483675]\n",
      "[Epoch 12/200] [Batch 140/637] [D loss: 0.173932] [G loss: 0.446477]\n",
      "[Epoch 12/200] [Batch 141/637] [D loss: 0.143243] [G loss: 0.524479]\n",
      "[Epoch 12/200] [Batch 142/637] [D loss: 0.150524] [G loss: 0.535930]\n",
      "[Epoch 12/200] [Batch 143/637] [D loss: 0.161433] [G loss: 0.481630]\n",
      "[Epoch 12/200] [Batch 144/637] [D loss: 0.150331] [G loss: 0.517358]\n",
      "[Epoch 12/200] [Batch 145/637] [D loss: 0.143006] [G loss: 0.537744]\n",
      "[Epoch 12/200] [Batch 146/637] [D loss: 0.150666] [G loss: 0.506515]\n",
      "[Epoch 12/200] [Batch 147/637] [D loss: 0.157278] [G loss: 0.503449]\n",
      "[Epoch 12/200] [Batch 148/637] [D loss: 0.147680] [G loss: 0.549845]\n",
      "[Epoch 12/200] [Batch 149/637] [D loss: 0.151547] [G loss: 0.546846]\n",
      "[Epoch 12/200] [Batch 150/637] [D loss: 0.140929] [G loss: 0.525075]\n",
      "[Epoch 12/200] [Batch 151/637] [D loss: 0.164848] [G loss: 0.487816]\n",
      "[Epoch 12/200] [Batch 152/637] [D loss: 0.128567] [G loss: 0.590204]\n",
      "[Epoch 12/200] [Batch 153/637] [D loss: 0.144623] [G loss: 0.462234]\n",
      "[Epoch 12/200] [Batch 154/637] [D loss: 0.135629] [G loss: 0.543436]\n",
      "[Epoch 12/200] [Batch 155/637] [D loss: 0.164182] [G loss: 0.459578]\n",
      "[Epoch 12/200] [Batch 156/637] [D loss: 0.145951] [G loss: 0.602349]\n",
      "[Epoch 12/200] [Batch 157/637] [D loss: 0.137368] [G loss: 0.599382]\n",
      "[Epoch 12/200] [Batch 158/637] [D loss: 0.116126] [G loss: 0.532689]\n",
      "[Epoch 12/200] [Batch 159/637] [D loss: 0.131801] [G loss: 0.505548]\n",
      "[Epoch 12/200] [Batch 160/637] [D loss: 0.152097] [G loss: 0.551377]\n",
      "[Epoch 12/200] [Batch 161/637] [D loss: 0.149038] [G loss: 0.510936]\n",
      "[Epoch 12/200] [Batch 162/637] [D loss: 0.150847] [G loss: 0.605467]\n",
      "[Epoch 12/200] [Batch 163/637] [D loss: 0.158852] [G loss: 0.461150]\n",
      "[Epoch 12/200] [Batch 164/637] [D loss: 0.171590] [G loss: 0.520513]\n",
      "[Epoch 12/200] [Batch 165/637] [D loss: 0.203614] [G loss: 0.543796]\n",
      "[Epoch 12/200] [Batch 166/637] [D loss: 0.233839] [G loss: 0.523027]\n",
      "[Epoch 12/200] [Batch 167/637] [D loss: 0.161758] [G loss: 0.493216]\n",
      "[Epoch 12/200] [Batch 168/637] [D loss: 0.200499] [G loss: 0.433733]\n",
      "[Epoch 12/200] [Batch 169/637] [D loss: 0.173352] [G loss: 0.573807]\n",
      "[Epoch 12/200] [Batch 170/637] [D loss: 0.164105] [G loss: 0.494428]\n",
      "[Epoch 12/200] [Batch 171/637] [D loss: 0.162995] [G loss: 0.450217]\n",
      "[Epoch 12/200] [Batch 172/637] [D loss: 0.156799] [G loss: 0.446815]\n",
      "[Epoch 12/200] [Batch 173/637] [D loss: 0.161941] [G loss: 0.439764]\n",
      "[Epoch 12/200] [Batch 174/637] [D loss: 0.147833] [G loss: 0.547053]\n",
      "[Epoch 12/200] [Batch 175/637] [D loss: 0.167828] [G loss: 0.519997]\n",
      "[Epoch 12/200] [Batch 176/637] [D loss: 0.140410] [G loss: 0.557345]\n",
      "[Epoch 12/200] [Batch 177/637] [D loss: 0.163480] [G loss: 0.466945]\n",
      "[Epoch 12/200] [Batch 178/637] [D loss: 0.156973] [G loss: 0.517765]\n",
      "[Epoch 12/200] [Batch 179/637] [D loss: 0.168358] [G loss: 0.572006]\n",
      "[Epoch 12/200] [Batch 180/637] [D loss: 0.165998] [G loss: 0.499914]\n",
      "[Epoch 12/200] [Batch 181/637] [D loss: 0.153138] [G loss: 0.529952]\n",
      "[Epoch 12/200] [Batch 182/637] [D loss: 0.165963] [G loss: 0.546381]\n",
      "[Epoch 12/200] [Batch 183/637] [D loss: 0.161669] [G loss: 0.497748]\n",
      "[Epoch 12/200] [Batch 184/637] [D loss: 0.157702] [G loss: 0.470548]\n",
      "[Epoch 12/200] [Batch 185/637] [D loss: 0.179231] [G loss: 0.406740]\n",
      "[Epoch 12/200] [Batch 186/637] [D loss: 0.165450] [G loss: 0.623122]\n",
      "[Epoch 12/200] [Batch 187/637] [D loss: 0.154948] [G loss: 0.536554]\n",
      "[Epoch 12/200] [Batch 188/637] [D loss: 0.158580] [G loss: 0.540921]\n",
      "[Epoch 12/200] [Batch 189/637] [D loss: 0.111966] [G loss: 0.587003]\n",
      "[Epoch 12/200] [Batch 190/637] [D loss: 0.164442] [G loss: 0.511855]\n",
      "[Epoch 12/200] [Batch 191/637] [D loss: 0.141589] [G loss: 0.531898]\n",
      "[Epoch 12/200] [Batch 192/637] [D loss: 0.118032] [G loss: 0.637215]\n",
      "[Epoch 12/200] [Batch 193/637] [D loss: 0.126019] [G loss: 0.617229]\n",
      "[Epoch 12/200] [Batch 194/637] [D loss: 0.171118] [G loss: 0.443256]\n",
      "[Epoch 12/200] [Batch 195/637] [D loss: 0.160165] [G loss: 0.550194]\n",
      "[Epoch 12/200] [Batch 196/637] [D loss: 0.125419] [G loss: 0.594913]\n",
      "[Epoch 12/200] [Batch 197/637] [D loss: 0.160856] [G loss: 0.543412]\n",
      "[Epoch 12/200] [Batch 198/637] [D loss: 0.180171] [G loss: 0.513640]\n",
      "[Epoch 12/200] [Batch 199/637] [D loss: 0.153241] [G loss: 0.520392]\n",
      "[Epoch 12/200] [Batch 200/637] [D loss: 0.164697] [G loss: 0.575887]\n",
      "[Epoch 12/200] [Batch 201/637] [D loss: 0.166866] [G loss: 0.485262]\n",
      "[Epoch 12/200] [Batch 202/637] [D loss: 0.156837] [G loss: 0.422318]\n",
      "[Epoch 12/200] [Batch 203/637] [D loss: 0.164379] [G loss: 0.528546]\n",
      "[Epoch 12/200] [Batch 204/637] [D loss: 0.143063] [G loss: 0.618769]\n",
      "[Epoch 12/200] [Batch 205/637] [D loss: 0.154281] [G loss: 0.555610]\n",
      "[Epoch 12/200] [Batch 206/637] [D loss: 0.191196] [G loss: 0.455342]\n",
      "[Epoch 12/200] [Batch 207/637] [D loss: 0.158645] [G loss: 0.549447]\n",
      "[Epoch 12/200] [Batch 208/637] [D loss: 0.161678] [G loss: 0.579682]\n",
      "[Epoch 12/200] [Batch 209/637] [D loss: 0.142723] [G loss: 0.593267]\n",
      "[Epoch 12/200] [Batch 210/637] [D loss: 0.157652] [G loss: 0.480884]\n",
      "[Epoch 12/200] [Batch 211/637] [D loss: 0.181111] [G loss: 0.467139]\n",
      "[Epoch 12/200] [Batch 212/637] [D loss: 0.140230] [G loss: 0.522985]\n",
      "[Epoch 12/200] [Batch 213/637] [D loss: 0.178635] [G loss: 0.558508]\n",
      "[Epoch 12/200] [Batch 214/637] [D loss: 0.143064] [G loss: 0.519237]\n",
      "[Epoch 12/200] [Batch 215/637] [D loss: 0.172983] [G loss: 0.482042]\n",
      "[Epoch 12/200] [Batch 216/637] [D loss: 0.153632] [G loss: 0.508479]\n",
      "[Epoch 12/200] [Batch 217/637] [D loss: 0.189213] [G loss: 0.519335]\n",
      "[Epoch 12/200] [Batch 218/637] [D loss: 0.156945] [G loss: 0.533611]\n",
      "[Epoch 12/200] [Batch 219/637] [D loss: 0.169972] [G loss: 0.526121]\n",
      "[Epoch 12/200] [Batch 220/637] [D loss: 0.163572] [G loss: 0.554161]\n",
      "[Epoch 12/200] [Batch 221/637] [D loss: 0.155913] [G loss: 0.499270]\n",
      "[Epoch 12/200] [Batch 222/637] [D loss: 0.168437] [G loss: 0.479205]\n",
      "[Epoch 12/200] [Batch 223/637] [D loss: 0.157589] [G loss: 0.502760]\n",
      "[Epoch 12/200] [Batch 224/637] [D loss: 0.158066] [G loss: 0.477576]\n",
      "[Epoch 12/200] [Batch 225/637] [D loss: 0.131518] [G loss: 0.549644]\n",
      "[Epoch 12/200] [Batch 226/637] [D loss: 0.130623] [G loss: 0.559581]\n",
      "[Epoch 12/200] [Batch 227/637] [D loss: 0.207610] [G loss: 0.421703]\n",
      "[Epoch 12/200] [Batch 228/637] [D loss: 0.155945] [G loss: 0.655950]\n",
      "[Epoch 12/200] [Batch 229/637] [D loss: 0.154543] [G loss: 0.560697]\n",
      "[Epoch 12/200] [Batch 230/637] [D loss: 0.140377] [G loss: 0.567898]\n",
      "[Epoch 12/200] [Batch 231/637] [D loss: 0.175259] [G loss: 0.459237]\n",
      "[Epoch 12/200] [Batch 232/637] [D loss: 0.150808] [G loss: 0.530351]\n",
      "[Epoch 12/200] [Batch 233/637] [D loss: 0.163865] [G loss: 0.541046]\n",
      "[Epoch 12/200] [Batch 234/637] [D loss: 0.146504] [G loss: 0.678208]\n",
      "[Epoch 12/200] [Batch 235/637] [D loss: 0.187397] [G loss: 0.504340]\n",
      "[Epoch 12/200] [Batch 236/637] [D loss: 0.156178] [G loss: 0.506068]\n",
      "[Epoch 12/200] [Batch 237/637] [D loss: 0.168713] [G loss: 0.498742]\n",
      "[Epoch 12/200] [Batch 238/637] [D loss: 0.144304] [G loss: 0.632132]\n",
      "[Epoch 12/200] [Batch 239/637] [D loss: 0.193742] [G loss: 0.414361]\n",
      "[Epoch 12/200] [Batch 240/637] [D loss: 0.159752] [G loss: 0.540090]\n",
      "[Epoch 12/200] [Batch 241/637] [D loss: 0.158328] [G loss: 0.491736]\n",
      "[Epoch 12/200] [Batch 242/637] [D loss: 0.163025] [G loss: 0.551790]\n",
      "[Epoch 12/200] [Batch 243/637] [D loss: 0.152961] [G loss: 0.594848]\n",
      "[Epoch 12/200] [Batch 244/637] [D loss: 0.151952] [G loss: 0.552761]\n",
      "[Epoch 12/200] [Batch 245/637] [D loss: 0.151599] [G loss: 0.559809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 246/637] [D loss: 0.132242] [G loss: 0.598030]\n",
      "[Epoch 12/200] [Batch 247/637] [D loss: 0.179994] [G loss: 0.528095]\n",
      "[Epoch 12/200] [Batch 248/637] [D loss: 0.144821] [G loss: 0.542465]\n",
      "[Epoch 12/200] [Batch 249/637] [D loss: 0.159211] [G loss: 0.515575]\n",
      "[Epoch 12/200] [Batch 250/637] [D loss: 0.147766] [G loss: 0.558560]\n",
      "[Epoch 12/200] [Batch 251/637] [D loss: 0.176727] [G loss: 0.551273]\n",
      "[Epoch 12/200] [Batch 252/637] [D loss: 0.183180] [G loss: 0.640181]\n",
      "[Epoch 12/200] [Batch 253/637] [D loss: 0.158666] [G loss: 0.597115]\n",
      "[Epoch 12/200] [Batch 254/637] [D loss: 0.157883] [G loss: 0.506292]\n",
      "[Epoch 12/200] [Batch 255/637] [D loss: 0.165417] [G loss: 0.458207]\n",
      "[Epoch 12/200] [Batch 256/637] [D loss: 0.172435] [G loss: 0.520447]\n",
      "[Epoch 12/200] [Batch 257/637] [D loss: 0.176644] [G loss: 0.535596]\n",
      "[Epoch 12/200] [Batch 258/637] [D loss: 0.157268] [G loss: 0.511494]\n",
      "[Epoch 12/200] [Batch 259/637] [D loss: 0.170078] [G loss: 0.529800]\n",
      "[Epoch 12/200] [Batch 260/637] [D loss: 0.177896] [G loss: 0.505542]\n",
      "[Epoch 12/200] [Batch 261/637] [D loss: 0.174691] [G loss: 0.516007]\n",
      "[Epoch 12/200] [Batch 262/637] [D loss: 0.161034] [G loss: 0.461563]\n",
      "[Epoch 12/200] [Batch 263/637] [D loss: 0.166422] [G loss: 0.500469]\n",
      "[Epoch 12/200] [Batch 264/637] [D loss: 0.174185] [G loss: 0.480331]\n",
      "[Epoch 12/200] [Batch 265/637] [D loss: 0.181803] [G loss: 0.443016]\n",
      "[Epoch 12/200] [Batch 266/637] [D loss: 0.160285] [G loss: 0.582988]\n",
      "[Epoch 12/200] [Batch 267/637] [D loss: 0.171212] [G loss: 0.536969]\n",
      "[Epoch 12/200] [Batch 268/637] [D loss: 0.176901] [G loss: 0.504304]\n",
      "[Epoch 12/200] [Batch 269/637] [D loss: 0.175806] [G loss: 0.473364]\n",
      "[Epoch 12/200] [Batch 270/637] [D loss: 0.155819] [G loss: 0.593331]\n",
      "[Epoch 12/200] [Batch 271/637] [D loss: 0.154251] [G loss: 0.619540]\n",
      "[Epoch 12/200] [Batch 272/637] [D loss: 0.139672] [G loss: 0.573709]\n",
      "[Epoch 12/200] [Batch 273/637] [D loss: 0.158184] [G loss: 0.536972]\n",
      "[Epoch 12/200] [Batch 274/637] [D loss: 0.138468] [G loss: 0.547202]\n",
      "[Epoch 12/200] [Batch 275/637] [D loss: 0.154154] [G loss: 0.504410]\n",
      "[Epoch 12/200] [Batch 276/637] [D loss: 0.122279] [G loss: 0.544018]\n",
      "[Epoch 12/200] [Batch 277/637] [D loss: 0.133841] [G loss: 0.618373]\n",
      "[Epoch 12/200] [Batch 278/637] [D loss: 0.122296] [G loss: 0.555886]\n",
      "[Epoch 12/200] [Batch 279/637] [D loss: 0.154096] [G loss: 0.550415]\n",
      "[Epoch 12/200] [Batch 280/637] [D loss: 0.140402] [G loss: 0.554454]\n",
      "[Epoch 12/200] [Batch 281/637] [D loss: 0.136406] [G loss: 0.536914]\n",
      "[Epoch 12/200] [Batch 282/637] [D loss: 0.144085] [G loss: 0.574520]\n",
      "[Epoch 12/200] [Batch 283/637] [D loss: 0.163196] [G loss: 0.567466]\n",
      "[Epoch 12/200] [Batch 284/637] [D loss: 0.164432] [G loss: 0.467242]\n",
      "[Epoch 12/200] [Batch 285/637] [D loss: 0.178074] [G loss: 0.533498]\n",
      "[Epoch 12/200] [Batch 286/637] [D loss: 0.173984] [G loss: 0.520532]\n",
      "[Epoch 12/200] [Batch 287/637] [D loss: 0.166423] [G loss: 0.574732]\n",
      "[Epoch 12/200] [Batch 288/637] [D loss: 0.155306] [G loss: 0.518256]\n",
      "[Epoch 12/200] [Batch 289/637] [D loss: 0.161967] [G loss: 0.519314]\n",
      "[Epoch 12/200] [Batch 290/637] [D loss: 0.167963] [G loss: 0.528077]\n",
      "[Epoch 12/200] [Batch 291/637] [D loss: 0.167058] [G loss: 0.538267]\n",
      "[Epoch 12/200] [Batch 292/637] [D loss: 0.160555] [G loss: 0.501180]\n",
      "[Epoch 12/200] [Batch 293/637] [D loss: 0.167459] [G loss: 0.450389]\n",
      "[Epoch 12/200] [Batch 294/637] [D loss: 0.149520] [G loss: 0.497293]\n",
      "[Epoch 12/200] [Batch 295/637] [D loss: 0.188853] [G loss: 0.467443]\n",
      "[Epoch 12/200] [Batch 296/637] [D loss: 0.153877] [G loss: 0.456385]\n",
      "[Epoch 12/200] [Batch 297/637] [D loss: 0.140009] [G loss: 0.585406]\n",
      "[Epoch 12/200] [Batch 298/637] [D loss: 0.151952] [G loss: 0.483098]\n",
      "[Epoch 12/200] [Batch 299/637] [D loss: 0.164780] [G loss: 0.526969]\n",
      "[Epoch 12/200] [Batch 300/637] [D loss: 0.174790] [G loss: 0.616804]\n",
      "[Epoch 12/200] [Batch 301/637] [D loss: 0.143881] [G loss: 0.718786]\n",
      "[Epoch 12/200] [Batch 302/637] [D loss: 0.158046] [G loss: 0.598567]\n",
      "[Epoch 12/200] [Batch 303/637] [D loss: 0.146366] [G loss: 0.517971]\n",
      "[Epoch 12/200] [Batch 304/637] [D loss: 0.149473] [G loss: 0.562450]\n",
      "[Epoch 12/200] [Batch 305/637] [D loss: 0.151555] [G loss: 0.495695]\n",
      "[Epoch 12/200] [Batch 306/637] [D loss: 0.120711] [G loss: 0.530306]\n",
      "[Epoch 12/200] [Batch 307/637] [D loss: 0.147230] [G loss: 0.513338]\n",
      "[Epoch 12/200] [Batch 308/637] [D loss: 0.143955] [G loss: 0.574093]\n",
      "[Epoch 12/200] [Batch 309/637] [D loss: 0.139794] [G loss: 0.567092]\n",
      "[Epoch 12/200] [Batch 310/637] [D loss: 0.134788] [G loss: 0.580445]\n",
      "[Epoch 12/200] [Batch 311/637] [D loss: 0.132296] [G loss: 0.571909]\n",
      "[Epoch 12/200] [Batch 312/637] [D loss: 0.156261] [G loss: 0.527011]\n",
      "[Epoch 12/200] [Batch 313/637] [D loss: 0.156385] [G loss: 0.607870]\n",
      "[Epoch 12/200] [Batch 314/637] [D loss: 0.157497] [G loss: 0.592605]\n",
      "[Epoch 12/200] [Batch 315/637] [D loss: 0.143094] [G loss: 0.536595]\n",
      "[Epoch 12/200] [Batch 316/637] [D loss: 0.162045] [G loss: 0.548318]\n",
      "[Epoch 12/200] [Batch 317/637] [D loss: 0.151463] [G loss: 0.535065]\n",
      "[Epoch 12/200] [Batch 318/637] [D loss: 0.167919] [G loss: 0.429601]\n",
      "[Epoch 12/200] [Batch 319/637] [D loss: 0.174167] [G loss: 0.577750]\n",
      "[Epoch 12/200] [Batch 320/637] [D loss: 0.147784] [G loss: 0.515793]\n",
      "[Epoch 12/200] [Batch 321/637] [D loss: 0.162367] [G loss: 0.541473]\n",
      "[Epoch 12/200] [Batch 322/637] [D loss: 0.178113] [G loss: 0.448763]\n",
      "[Epoch 12/200] [Batch 323/637] [D loss: 0.165120] [G loss: 0.548752]\n",
      "[Epoch 12/200] [Batch 324/637] [D loss: 0.162513] [G loss: 0.589546]\n",
      "[Epoch 12/200] [Batch 325/637] [D loss: 0.187292] [G loss: 0.542520]\n",
      "[Epoch 12/200] [Batch 326/637] [D loss: 0.160441] [G loss: 0.497709]\n",
      "[Epoch 12/200] [Batch 327/637] [D loss: 0.172746] [G loss: 0.484376]\n",
      "[Epoch 12/200] [Batch 328/637] [D loss: 0.167126] [G loss: 0.536464]\n",
      "[Epoch 12/200] [Batch 329/637] [D loss: 0.186775] [G loss: 0.457486]\n",
      "[Epoch 12/200] [Batch 330/637] [D loss: 0.172691] [G loss: 0.547350]\n",
      "[Epoch 12/200] [Batch 331/637] [D loss: 0.174766] [G loss: 0.577606]\n",
      "[Epoch 12/200] [Batch 332/637] [D loss: 0.189586] [G loss: 0.473657]\n",
      "[Epoch 12/200] [Batch 333/637] [D loss: 0.170326] [G loss: 0.504554]\n",
      "[Epoch 12/200] [Batch 334/637] [D loss: 0.162335] [G loss: 0.524153]\n",
      "[Epoch 12/200] [Batch 335/637] [D loss: 0.141458] [G loss: 0.520440]\n",
      "[Epoch 12/200] [Batch 336/637] [D loss: 0.162612] [G loss: 0.480743]\n",
      "[Epoch 12/200] [Batch 337/637] [D loss: 0.156021] [G loss: 0.530572]\n",
      "[Epoch 12/200] [Batch 338/637] [D loss: 0.170862] [G loss: 0.453721]\n",
      "[Epoch 12/200] [Batch 339/637] [D loss: 0.147917] [G loss: 0.564428]\n",
      "[Epoch 12/200] [Batch 340/637] [D loss: 0.149134] [G loss: 0.486364]\n",
      "[Epoch 12/200] [Batch 341/637] [D loss: 0.141065] [G loss: 0.536752]\n",
      "[Epoch 12/200] [Batch 342/637] [D loss: 0.156219] [G loss: 0.509011]\n",
      "[Epoch 12/200] [Batch 343/637] [D loss: 0.135700] [G loss: 0.518572]\n",
      "[Epoch 12/200] [Batch 344/637] [D loss: 0.155863] [G loss: 0.608380]\n",
      "[Epoch 12/200] [Batch 345/637] [D loss: 0.133963] [G loss: 0.628027]\n",
      "[Epoch 12/200] [Batch 346/637] [D loss: 0.148352] [G loss: 0.566369]\n",
      "[Epoch 12/200] [Batch 347/637] [D loss: 0.178643] [G loss: 0.445185]\n",
      "[Epoch 12/200] [Batch 348/637] [D loss: 0.179327] [G loss: 0.525625]\n",
      "[Epoch 12/200] [Batch 349/637] [D loss: 0.161551] [G loss: 0.550731]\n",
      "[Epoch 12/200] [Batch 350/637] [D loss: 0.183408] [G loss: 0.499780]\n",
      "[Epoch 12/200] [Batch 351/637] [D loss: 0.172017] [G loss: 0.507341]\n",
      "[Epoch 12/200] [Batch 352/637] [D loss: 0.182000] [G loss: 0.509817]\n",
      "[Epoch 12/200] [Batch 353/637] [D loss: 0.184855] [G loss: 0.510175]\n",
      "[Epoch 12/200] [Batch 354/637] [D loss: 0.152496] [G loss: 0.483981]\n",
      "[Epoch 12/200] [Batch 355/637] [D loss: 0.175196] [G loss: 0.464368]\n",
      "[Epoch 12/200] [Batch 356/637] [D loss: 0.167500] [G loss: 0.507344]\n",
      "[Epoch 12/200] [Batch 357/637] [D loss: 0.205212] [G loss: 0.443499]\n",
      "[Epoch 12/200] [Batch 358/637] [D loss: 0.173915] [G loss: 0.469182]\n",
      "[Epoch 12/200] [Batch 359/637] [D loss: 0.155193] [G loss: 0.508788]\n",
      "[Epoch 12/200] [Batch 360/637] [D loss: 0.156429] [G loss: 0.487225]\n",
      "[Epoch 12/200] [Batch 361/637] [D loss: 0.172507] [G loss: 0.473072]\n",
      "[Epoch 12/200] [Batch 362/637] [D loss: 0.167028] [G loss: 0.544884]\n",
      "[Epoch 12/200] [Batch 363/637] [D loss: 0.174914] [G loss: 0.583623]\n",
      "[Epoch 12/200] [Batch 364/637] [D loss: 0.149832] [G loss: 0.486523]\n",
      "[Epoch 12/200] [Batch 365/637] [D loss: 0.156383] [G loss: 0.483316]\n",
      "[Epoch 12/200] [Batch 366/637] [D loss: 0.162384] [G loss: 0.490131]\n",
      "[Epoch 12/200] [Batch 367/637] [D loss: 0.144571] [G loss: 0.528798]\n",
      "[Epoch 12/200] [Batch 368/637] [D loss: 0.145200] [G loss: 0.554969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 369/637] [D loss: 0.173292] [G loss: 0.467832]\n",
      "[Epoch 12/200] [Batch 370/637] [D loss: 0.146381] [G loss: 0.552808]\n",
      "[Epoch 12/200] [Batch 371/637] [D loss: 0.179379] [G loss: 0.410422]\n",
      "[Epoch 12/200] [Batch 372/637] [D loss: 0.155611] [G loss: 0.535025]\n",
      "[Epoch 12/200] [Batch 373/637] [D loss: 0.161399] [G loss: 0.543205]\n",
      "[Epoch 12/200] [Batch 374/637] [D loss: 0.155552] [G loss: 0.532573]\n",
      "[Epoch 12/200] [Batch 375/637] [D loss: 0.152481] [G loss: 0.567028]\n",
      "[Epoch 12/200] [Batch 376/637] [D loss: 0.155845] [G loss: 0.477629]\n",
      "[Epoch 12/200] [Batch 377/637] [D loss: 0.141984] [G loss: 0.483950]\n",
      "[Epoch 12/200] [Batch 378/637] [D loss: 0.150061] [G loss: 0.513631]\n",
      "[Epoch 12/200] [Batch 379/637] [D loss: 0.157568] [G loss: 0.483409]\n",
      "[Epoch 12/200] [Batch 380/637] [D loss: 0.177195] [G loss: 0.498123]\n",
      "[Epoch 12/200] [Batch 381/637] [D loss: 0.164973] [G loss: 0.509838]\n",
      "[Epoch 12/200] [Batch 382/637] [D loss: 0.152238] [G loss: 0.527867]\n",
      "[Epoch 12/200] [Batch 383/637] [D loss: 0.153483] [G loss: 0.510404]\n",
      "[Epoch 12/200] [Batch 384/637] [D loss: 0.161804] [G loss: 0.486713]\n",
      "[Epoch 12/200] [Batch 385/637] [D loss: 0.179112] [G loss: 0.431159]\n",
      "[Epoch 12/200] [Batch 386/637] [D loss: 0.157913] [G loss: 0.579151]\n",
      "[Epoch 12/200] [Batch 387/637] [D loss: 0.149889] [G loss: 0.552514]\n",
      "[Epoch 12/200] [Batch 388/637] [D loss: 0.131522] [G loss: 0.532505]\n",
      "[Epoch 12/200] [Batch 389/637] [D loss: 0.151131] [G loss: 0.468366]\n",
      "[Epoch 12/200] [Batch 390/637] [D loss: 0.133303] [G loss: 0.478345]\n",
      "[Epoch 12/200] [Batch 391/637] [D loss: 0.169180] [G loss: 0.457993]\n",
      "[Epoch 12/200] [Batch 392/637] [D loss: 0.149112] [G loss: 0.586294]\n",
      "[Epoch 12/200] [Batch 393/637] [D loss: 0.155490] [G loss: 0.535243]\n",
      "[Epoch 12/200] [Batch 394/637] [D loss: 0.142633] [G loss: 0.554811]\n",
      "[Epoch 12/200] [Batch 395/637] [D loss: 0.154581] [G loss: 0.528704]\n",
      "[Epoch 12/200] [Batch 396/637] [D loss: 0.166434] [G loss: 0.548870]\n",
      "[Epoch 12/200] [Batch 397/637] [D loss: 0.155231] [G loss: 0.536374]\n",
      "[Epoch 12/200] [Batch 398/637] [D loss: 0.162665] [G loss: 0.504791]\n",
      "[Epoch 12/200] [Batch 399/637] [D loss: 0.172939] [G loss: 0.554175]\n",
      "[Epoch 12/200] [Batch 400/637] [D loss: 0.168865] [G loss: 0.537625]\n",
      "[Epoch 12/200] [Batch 401/637] [D loss: 0.145497] [G loss: 0.602462]\n",
      "[Epoch 12/200] [Batch 402/637] [D loss: 0.144574] [G loss: 0.552938]\n",
      "[Epoch 12/200] [Batch 403/637] [D loss: 0.155753] [G loss: 0.478695]\n",
      "[Epoch 12/200] [Batch 404/637] [D loss: 0.165764] [G loss: 0.509433]\n",
      "[Epoch 12/200] [Batch 405/637] [D loss: 0.150689] [G loss: 0.489101]\n",
      "[Epoch 12/200] [Batch 406/637] [D loss: 0.132556] [G loss: 0.585163]\n",
      "[Epoch 12/200] [Batch 407/637] [D loss: 0.143901] [G loss: 0.590496]\n",
      "[Epoch 12/200] [Batch 408/637] [D loss: 0.127801] [G loss: 0.579621]\n",
      "[Epoch 12/200] [Batch 409/637] [D loss: 0.183798] [G loss: 0.411078]\n",
      "[Epoch 12/200] [Batch 410/637] [D loss: 0.153128] [G loss: 0.609519]\n",
      "[Epoch 12/200] [Batch 411/637] [D loss: 0.163507] [G loss: 0.568907]\n",
      "[Epoch 12/200] [Batch 412/637] [D loss: 0.188915] [G loss: 0.497598]\n",
      "[Epoch 12/200] [Batch 413/637] [D loss: 0.178561] [G loss: 0.517471]\n",
      "[Epoch 12/200] [Batch 414/637] [D loss: 0.149589] [G loss: 0.704359]\n",
      "[Epoch 12/200] [Batch 415/637] [D loss: 0.163483] [G loss: 0.625910]\n",
      "[Epoch 12/200] [Batch 416/637] [D loss: 0.137734] [G loss: 0.522237]\n",
      "[Epoch 12/200] [Batch 417/637] [D loss: 0.138957] [G loss: 0.468347]\n",
      "[Epoch 12/200] [Batch 418/637] [D loss: 0.137795] [G loss: 0.551343]\n",
      "[Epoch 12/200] [Batch 419/637] [D loss: 0.145950] [G loss: 0.531976]\n",
      "[Epoch 12/200] [Batch 420/637] [D loss: 0.146885] [G loss: 0.501472]\n",
      "[Epoch 12/200] [Batch 421/637] [D loss: 0.140695] [G loss: 0.532322]\n",
      "[Epoch 12/200] [Batch 422/637] [D loss: 0.173653] [G loss: 0.486521]\n",
      "[Epoch 12/200] [Batch 423/637] [D loss: 0.140878] [G loss: 0.571704]\n",
      "[Epoch 12/200] [Batch 424/637] [D loss: 0.148685] [G loss: 0.707596]\n",
      "[Epoch 12/200] [Batch 425/637] [D loss: 0.186274] [G loss: 0.497156]\n",
      "[Epoch 12/200] [Batch 426/637] [D loss: 0.188579] [G loss: 0.482743]\n",
      "[Epoch 12/200] [Batch 427/637] [D loss: 0.165008] [G loss: 0.493591]\n",
      "[Epoch 12/200] [Batch 428/637] [D loss: 0.157917] [G loss: 0.535643]\n",
      "[Epoch 12/200] [Batch 429/637] [D loss: 0.166397] [G loss: 0.529714]\n",
      "[Epoch 12/200] [Batch 430/637] [D loss: 0.158726] [G loss: 0.513064]\n",
      "[Epoch 12/200] [Batch 431/637] [D loss: 0.162214] [G loss: 0.451139]\n",
      "[Epoch 12/200] [Batch 432/637] [D loss: 0.154110] [G loss: 0.523513]\n",
      "[Epoch 12/200] [Batch 433/637] [D loss: 0.173918] [G loss: 0.533608]\n",
      "[Epoch 12/200] [Batch 434/637] [D loss: 0.166326] [G loss: 0.466279]\n",
      "[Epoch 12/200] [Batch 435/637] [D loss: 0.163166] [G loss: 0.481901]\n",
      "[Epoch 12/200] [Batch 436/637] [D loss: 0.143671] [G loss: 0.492077]\n",
      "[Epoch 12/200] [Batch 437/637] [D loss: 0.148538] [G loss: 0.490598]\n",
      "[Epoch 12/200] [Batch 438/637] [D loss: 0.150129] [G loss: 0.474735]\n",
      "[Epoch 12/200] [Batch 439/637] [D loss: 0.130591] [G loss: 0.581267]\n",
      "[Epoch 12/200] [Batch 440/637] [D loss: 0.158052] [G loss: 0.510781]\n",
      "[Epoch 12/200] [Batch 441/637] [D loss: 0.164470] [G loss: 0.478689]\n",
      "[Epoch 12/200] [Batch 442/637] [D loss: 0.166117] [G loss: 0.527986]\n",
      "[Epoch 12/200] [Batch 443/637] [D loss: 0.151191] [G loss: 0.525458]\n",
      "[Epoch 12/200] [Batch 444/637] [D loss: 0.163510] [G loss: 0.465481]\n",
      "[Epoch 12/200] [Batch 445/637] [D loss: 0.141773] [G loss: 0.496243]\n",
      "[Epoch 12/200] [Batch 446/637] [D loss: 0.152666] [G loss: 0.470075]\n",
      "[Epoch 12/200] [Batch 447/637] [D loss: 0.186017] [G loss: 0.466756]\n",
      "[Epoch 12/200] [Batch 448/637] [D loss: 0.153567] [G loss: 0.480043]\n",
      "[Epoch 12/200] [Batch 449/637] [D loss: 0.151825] [G loss: 0.568298]\n",
      "[Epoch 12/200] [Batch 450/637] [D loss: 0.142928] [G loss: 0.515374]\n",
      "[Epoch 12/200] [Batch 451/637] [D loss: 0.169301] [G loss: 0.516513]\n",
      "[Epoch 12/200] [Batch 452/637] [D loss: 0.182657] [G loss: 0.572540]\n",
      "[Epoch 12/200] [Batch 453/637] [D loss: 0.176148] [G loss: 0.447529]\n",
      "[Epoch 12/200] [Batch 454/637] [D loss: 0.155947] [G loss: 0.454487]\n",
      "[Epoch 12/200] [Batch 455/637] [D loss: 0.165935] [G loss: 0.500896]\n",
      "[Epoch 12/200] [Batch 456/637] [D loss: 0.158527] [G loss: 0.551755]\n",
      "[Epoch 12/200] [Batch 457/637] [D loss: 0.149469] [G loss: 0.518979]\n",
      "[Epoch 12/200] [Batch 458/637] [D loss: 0.141497] [G loss: 0.540245]\n",
      "[Epoch 12/200] [Batch 459/637] [D loss: 0.161462] [G loss: 0.483324]\n",
      "[Epoch 12/200] [Batch 460/637] [D loss: 0.134733] [G loss: 0.552006]\n",
      "[Epoch 12/200] [Batch 461/637] [D loss: 0.165407] [G loss: 0.480948]\n",
      "[Epoch 12/200] [Batch 462/637] [D loss: 0.144705] [G loss: 0.554295]\n",
      "[Epoch 12/200] [Batch 463/637] [D loss: 0.132422] [G loss: 0.525202]\n",
      "[Epoch 12/200] [Batch 464/637] [D loss: 0.197758] [G loss: 0.460714]\n",
      "[Epoch 12/200] [Batch 465/637] [D loss: 0.154410] [G loss: 0.696764]\n",
      "[Epoch 12/200] [Batch 466/637] [D loss: 0.143928] [G loss: 0.660603]\n",
      "[Epoch 12/200] [Batch 467/637] [D loss: 0.152839] [G loss: 0.519089]\n",
      "[Epoch 12/200] [Batch 468/637] [D loss: 0.167774] [G loss: 0.477092]\n",
      "[Epoch 12/200] [Batch 469/637] [D loss: 0.162129] [G loss: 0.520896]\n",
      "[Epoch 12/200] [Batch 470/637] [D loss: 0.159640] [G loss: 0.530021]\n",
      "[Epoch 12/200] [Batch 471/637] [D loss: 0.150325] [G loss: 0.577901]\n",
      "[Epoch 12/200] [Batch 472/637] [D loss: 0.170053] [G loss: 0.477440]\n",
      "[Epoch 12/200] [Batch 473/637] [D loss: 0.178906] [G loss: 0.515877]\n",
      "[Epoch 12/200] [Batch 474/637] [D loss: 0.139561] [G loss: 0.478674]\n",
      "[Epoch 12/200] [Batch 475/637] [D loss: 0.174791] [G loss: 0.469105]\n",
      "[Epoch 12/200] [Batch 476/637] [D loss: 0.163401] [G loss: 0.487176]\n",
      "[Epoch 12/200] [Batch 477/637] [D loss: 0.194480] [G loss: 0.512909]\n",
      "[Epoch 12/200] [Batch 478/637] [D loss: 0.172655] [G loss: 0.480512]\n",
      "[Epoch 12/200] [Batch 479/637] [D loss: 0.207971] [G loss: 0.504656]\n",
      "[Epoch 12/200] [Batch 480/637] [D loss: 0.186804] [G loss: 0.588363]\n",
      "[Epoch 12/200] [Batch 481/637] [D loss: 0.183889] [G loss: 0.607482]\n",
      "[Epoch 12/200] [Batch 482/637] [D loss: 0.167978] [G loss: 0.512117]\n",
      "[Epoch 12/200] [Batch 483/637] [D loss: 0.183926] [G loss: 0.492134]\n",
      "[Epoch 12/200] [Batch 484/637] [D loss: 0.153759] [G loss: 0.552619]\n",
      "[Epoch 12/200] [Batch 485/637] [D loss: 0.167597] [G loss: 0.510081]\n",
      "[Epoch 12/200] [Batch 486/637] [D loss: 0.145463] [G loss: 0.529019]\n",
      "[Epoch 12/200] [Batch 487/637] [D loss: 0.148061] [G loss: 0.513470]\n",
      "[Epoch 12/200] [Batch 488/637] [D loss: 0.134042] [G loss: 0.511498]\n",
      "[Epoch 12/200] [Batch 489/637] [D loss: 0.122654] [G loss: 0.522490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 490/637] [D loss: 0.149191] [G loss: 0.445234]\n",
      "[Epoch 12/200] [Batch 491/637] [D loss: 0.118980] [G loss: 0.547213]\n",
      "[Epoch 12/200] [Batch 492/637] [D loss: 0.137066] [G loss: 0.534739]\n",
      "[Epoch 12/200] [Batch 493/637] [D loss: 0.120189] [G loss: 0.636744]\n",
      "[Epoch 12/200] [Batch 494/637] [D loss: 0.165119] [G loss: 0.487965]\n",
      "[Epoch 12/200] [Batch 495/637] [D loss: 0.154079] [G loss: 0.747600]\n",
      "[Epoch 12/200] [Batch 496/637] [D loss: 0.139633] [G loss: 0.574150]\n",
      "[Epoch 12/200] [Batch 497/637] [D loss: 0.178563] [G loss: 0.592835]\n",
      "[Epoch 12/200] [Batch 498/637] [D loss: 0.168614] [G loss: 0.533095]\n",
      "[Epoch 12/200] [Batch 499/637] [D loss: 0.159566] [G loss: 0.527750]\n",
      "[Epoch 12/200] [Batch 500/637] [D loss: 0.136998] [G loss: 0.522330]\n",
      "[Epoch 12/200] [Batch 501/637] [D loss: 0.161898] [G loss: 0.496724]\n",
      "[Epoch 12/200] [Batch 502/637] [D loss: 0.168788] [G loss: 0.461076]\n",
      "[Epoch 12/200] [Batch 503/637] [D loss: 0.162106] [G loss: 0.445768]\n",
      "[Epoch 12/200] [Batch 504/637] [D loss: 0.166680] [G loss: 0.537865]\n",
      "[Epoch 12/200] [Batch 505/637] [D loss: 0.179069] [G loss: 0.492364]\n",
      "[Epoch 12/200] [Batch 506/637] [D loss: 0.160707] [G loss: 0.488919]\n",
      "[Epoch 12/200] [Batch 507/637] [D loss: 0.159314] [G loss: 0.469479]\n",
      "[Epoch 12/200] [Batch 508/637] [D loss: 0.148775] [G loss: 0.468509]\n",
      "[Epoch 12/200] [Batch 509/637] [D loss: 0.151603] [G loss: 0.482828]\n",
      "[Epoch 12/200] [Batch 510/637] [D loss: 0.151212] [G loss: 0.680629]\n",
      "[Epoch 12/200] [Batch 511/637] [D loss: 0.167758] [G loss: 0.495067]\n",
      "[Epoch 12/200] [Batch 512/637] [D loss: 0.171069] [G loss: 0.490572]\n",
      "[Epoch 12/200] [Batch 513/637] [D loss: 0.199439] [G loss: 0.543382]\n",
      "[Epoch 12/200] [Batch 514/637] [D loss: 0.155461] [G loss: 0.553969]\n",
      "[Epoch 12/200] [Batch 515/637] [D loss: 0.167413] [G loss: 0.510420]\n",
      "[Epoch 12/200] [Batch 516/637] [D loss: 0.160430] [G loss: 0.531530]\n",
      "[Epoch 12/200] [Batch 517/637] [D loss: 0.171455] [G loss: 0.443763]\n",
      "[Epoch 12/200] [Batch 518/637] [D loss: 0.173316] [G loss: 0.465629]\n",
      "[Epoch 12/200] [Batch 519/637] [D loss: 0.173587] [G loss: 0.538256]\n",
      "[Epoch 12/200] [Batch 520/637] [D loss: 0.153885] [G loss: 0.560089]\n",
      "[Epoch 12/200] [Batch 521/637] [D loss: 0.161268] [G loss: 0.512534]\n",
      "[Epoch 12/200] [Batch 522/637] [D loss: 0.174809] [G loss: 0.575882]\n",
      "[Epoch 12/200] [Batch 523/637] [D loss: 0.146699] [G loss: 0.533529]\n",
      "[Epoch 12/200] [Batch 524/637] [D loss: 0.146346] [G loss: 0.541112]\n",
      "[Epoch 12/200] [Batch 525/637] [D loss: 0.140870] [G loss: 0.542511]\n",
      "[Epoch 12/200] [Batch 526/637] [D loss: 0.135284] [G loss: 0.616524]\n",
      "[Epoch 12/200] [Batch 527/637] [D loss: 0.170518] [G loss: 0.543283]\n",
      "[Epoch 12/200] [Batch 528/637] [D loss: 0.185841] [G loss: 0.698799]\n",
      "[Epoch 12/200] [Batch 529/637] [D loss: 0.142433] [G loss: 0.553249]\n",
      "[Epoch 12/200] [Batch 530/637] [D loss: 0.174367] [G loss: 0.539792]\n",
      "[Epoch 12/200] [Batch 531/637] [D loss: 0.176111] [G loss: 0.589533]\n",
      "[Epoch 12/200] [Batch 532/637] [D loss: 0.155615] [G loss: 0.545691]\n",
      "[Epoch 12/200] [Batch 533/637] [D loss: 0.163158] [G loss: 0.544106]\n",
      "[Epoch 12/200] [Batch 534/637] [D loss: 0.146412] [G loss: 0.607783]\n",
      "[Epoch 12/200] [Batch 535/637] [D loss: 0.168092] [G loss: 0.518668]\n",
      "[Epoch 12/200] [Batch 536/637] [D loss: 0.152396] [G loss: 0.542563]\n",
      "[Epoch 12/200] [Batch 537/637] [D loss: 0.173763] [G loss: 0.564215]\n",
      "[Epoch 12/200] [Batch 538/637] [D loss: 0.136883] [G loss: 0.615854]\n",
      "[Epoch 12/200] [Batch 539/637] [D loss: 0.146671] [G loss: 0.473480]\n",
      "[Epoch 12/200] [Batch 540/637] [D loss: 0.173027] [G loss: 0.481250]\n",
      "[Epoch 12/200] [Batch 541/637] [D loss: 0.160824] [G loss: 0.482069]\n",
      "[Epoch 12/200] [Batch 542/637] [D loss: 0.172239] [G loss: 0.486287]\n",
      "[Epoch 12/200] [Batch 543/637] [D loss: 0.149372] [G loss: 0.538200]\n",
      "[Epoch 12/200] [Batch 544/637] [D loss: 0.148221] [G loss: 0.519487]\n",
      "[Epoch 12/200] [Batch 545/637] [D loss: 0.170677] [G loss: 0.484042]\n",
      "[Epoch 12/200] [Batch 546/637] [D loss: 0.171625] [G loss: 0.527262]\n",
      "[Epoch 12/200] [Batch 547/637] [D loss: 0.149342] [G loss: 0.512565]\n",
      "[Epoch 12/200] [Batch 548/637] [D loss: 0.163299] [G loss: 0.452660]\n",
      "[Epoch 12/200] [Batch 549/637] [D loss: 0.170735] [G loss: 0.522474]\n",
      "[Epoch 12/200] [Batch 550/637] [D loss: 0.153823] [G loss: 0.568740]\n",
      "[Epoch 12/200] [Batch 551/637] [D loss: 0.193343] [G loss: 0.451742]\n",
      "[Epoch 12/200] [Batch 552/637] [D loss: 0.233316] [G loss: 0.566138]\n",
      "[Epoch 12/200] [Batch 553/637] [D loss: 0.166686] [G loss: 0.603926]\n",
      "[Epoch 12/200] [Batch 554/637] [D loss: 0.138609] [G loss: 0.645518]\n",
      "[Epoch 12/200] [Batch 555/637] [D loss: 0.174762] [G loss: 0.386105]\n",
      "[Epoch 12/200] [Batch 556/637] [D loss: 0.164489] [G loss: 0.477149]\n",
      "[Epoch 12/200] [Batch 557/637] [D loss: 0.151615] [G loss: 0.483126]\n",
      "[Epoch 12/200] [Batch 558/637] [D loss: 0.147029] [G loss: 0.452198]\n",
      "[Epoch 12/200] [Batch 559/637] [D loss: 0.144430] [G loss: 0.502966]\n",
      "[Epoch 12/200] [Batch 560/637] [D loss: 0.135249] [G loss: 0.527215]\n",
      "[Epoch 12/200] [Batch 561/637] [D loss: 0.159442] [G loss: 0.470309]\n",
      "[Epoch 12/200] [Batch 562/637] [D loss: 0.177936] [G loss: 0.503431]\n",
      "[Epoch 12/200] [Batch 563/637] [D loss: 0.145419] [G loss: 0.476349]\n",
      "[Epoch 12/200] [Batch 564/637] [D loss: 0.158065] [G loss: 0.480108]\n",
      "[Epoch 12/200] [Batch 565/637] [D loss: 0.165817] [G loss: 0.456311]\n",
      "[Epoch 12/200] [Batch 566/637] [D loss: 0.150299] [G loss: 0.524905]\n",
      "[Epoch 12/200] [Batch 567/637] [D loss: 0.189017] [G loss: 0.440037]\n",
      "[Epoch 12/200] [Batch 568/637] [D loss: 0.157260] [G loss: 0.454728]\n",
      "[Epoch 12/200] [Batch 569/637] [D loss: 0.199577] [G loss: 0.433468]\n",
      "[Epoch 12/200] [Batch 570/637] [D loss: 0.180610] [G loss: 0.612375]\n",
      "[Epoch 12/200] [Batch 571/637] [D loss: 0.193872] [G loss: 0.491420]\n",
      "[Epoch 12/200] [Batch 572/637] [D loss: 0.160418] [G loss: 0.494997]\n",
      "[Epoch 12/200] [Batch 573/637] [D loss: 0.174017] [G loss: 0.452373]\n",
      "[Epoch 12/200] [Batch 574/637] [D loss: 0.170158] [G loss: 0.428232]\n",
      "[Epoch 12/200] [Batch 575/637] [D loss: 0.153224] [G loss: 0.433261]\n",
      "[Epoch 12/200] [Batch 576/637] [D loss: 0.160854] [G loss: 0.394142]\n",
      "[Epoch 12/200] [Batch 577/637] [D loss: 0.156551] [G loss: 0.446464]\n",
      "[Epoch 12/200] [Batch 578/637] [D loss: 0.138013] [G loss: 0.535808]\n",
      "[Epoch 12/200] [Batch 579/637] [D loss: 0.148478] [G loss: 0.551068]\n",
      "[Epoch 12/200] [Batch 580/637] [D loss: 0.153207] [G loss: 0.536444]\n",
      "[Epoch 12/200] [Batch 581/637] [D loss: 0.147268] [G loss: 0.472026]\n",
      "[Epoch 12/200] [Batch 582/637] [D loss: 0.174515] [G loss: 0.462535]\n",
      "[Epoch 12/200] [Batch 583/637] [D loss: 0.145019] [G loss: 0.468163]\n",
      "[Epoch 12/200] [Batch 584/637] [D loss: 0.162538] [G loss: 0.474183]\n",
      "[Epoch 12/200] [Batch 585/637] [D loss: 0.156698] [G loss: 0.482426]\n",
      "[Epoch 12/200] [Batch 586/637] [D loss: 0.132943] [G loss: 0.514957]\n",
      "[Epoch 12/200] [Batch 587/637] [D loss: 0.170598] [G loss: 0.496297]\n",
      "[Epoch 12/200] [Batch 588/637] [D loss: 0.157095] [G loss: 0.487001]\n",
      "[Epoch 12/200] [Batch 589/637] [D loss: 0.172035] [G loss: 0.482279]\n",
      "[Epoch 12/200] [Batch 590/637] [D loss: 0.157266] [G loss: 0.474856]\n",
      "[Epoch 12/200] [Batch 591/637] [D loss: 0.161830] [G loss: 0.506073]\n",
      "[Epoch 12/200] [Batch 592/637] [D loss: 0.155492] [G loss: 0.491635]\n",
      "[Epoch 12/200] [Batch 593/637] [D loss: 0.163511] [G loss: 0.510525]\n",
      "[Epoch 12/200] [Batch 594/637] [D loss: 0.161545] [G loss: 0.473883]\n",
      "[Epoch 12/200] [Batch 595/637] [D loss: 0.146668] [G loss: 0.476936]\n",
      "[Epoch 12/200] [Batch 596/637] [D loss: 0.171613] [G loss: 0.432894]\n",
      "[Epoch 12/200] [Batch 597/637] [D loss: 0.137168] [G loss: 0.493979]\n",
      "[Epoch 12/200] [Batch 598/637] [D loss: 0.152541] [G loss: 0.518738]\n",
      "[Epoch 12/200] [Batch 599/637] [D loss: 0.171443] [G loss: 0.514251]\n",
      "[Epoch 12/200] [Batch 600/637] [D loss: 0.163405] [G loss: 0.580087]\n",
      "[Epoch 12/200] [Batch 601/637] [D loss: 0.162585] [G loss: 0.620226]\n",
      "[Epoch 12/200] [Batch 602/637] [D loss: 0.140871] [G loss: 0.504277]\n",
      "[Epoch 12/200] [Batch 603/637] [D loss: 0.198147] [G loss: 0.501929]\n",
      "[Epoch 12/200] [Batch 604/637] [D loss: 0.184504] [G loss: 0.540018]\n",
      "[Epoch 12/200] [Batch 605/637] [D loss: 0.169014] [G loss: 0.581778]\n",
      "[Epoch 12/200] [Batch 606/637] [D loss: 0.163958] [G loss: 0.522233]\n",
      "[Epoch 12/200] [Batch 607/637] [D loss: 0.189475] [G loss: 0.401759]\n",
      "[Epoch 12/200] [Batch 608/637] [D loss: 0.190252] [G loss: 0.456331]\n",
      "[Epoch 12/200] [Batch 609/637] [D loss: 0.164290] [G loss: 0.529289]\n",
      "[Epoch 12/200] [Batch 610/637] [D loss: 0.154765] [G loss: 0.584316]\n",
      "[Epoch 12/200] [Batch 611/637] [D loss: 0.163735] [G loss: 0.559342]\n",
      "[Epoch 12/200] [Batch 612/637] [D loss: 0.146581] [G loss: 0.475251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 613/637] [D loss: 0.165073] [G loss: 0.496715]\n",
      "[Epoch 12/200] [Batch 614/637] [D loss: 0.145811] [G loss: 0.504021]\n",
      "[Epoch 12/200] [Batch 615/637] [D loss: 0.138757] [G loss: 0.489048]\n",
      "[Epoch 12/200] [Batch 616/637] [D loss: 0.148399] [G loss: 0.496017]\n",
      "[Epoch 12/200] [Batch 617/637] [D loss: 0.155253] [G loss: 0.581255]\n",
      "[Epoch 12/200] [Batch 618/637] [D loss: 0.143683] [G loss: 0.601587]\n",
      "[Epoch 12/200] [Batch 619/637] [D loss: 0.183278] [G loss: 0.576231]\n",
      "[Epoch 12/200] [Batch 620/637] [D loss: 0.165448] [G loss: 0.485011]\n",
      "[Epoch 12/200] [Batch 621/637] [D loss: 0.148551] [G loss: 0.531372]\n",
      "[Epoch 12/200] [Batch 622/637] [D loss: 0.156280] [G loss: 0.516234]\n",
      "[Epoch 12/200] [Batch 623/637] [D loss: 0.162085] [G loss: 0.495936]\n",
      "[Epoch 12/200] [Batch 624/637] [D loss: 0.151558] [G loss: 0.488372]\n",
      "[Epoch 12/200] [Batch 625/637] [D loss: 0.171754] [G loss: 0.485432]\n",
      "[Epoch 12/200] [Batch 626/637] [D loss: 0.177637] [G loss: 0.512136]\n",
      "[Epoch 12/200] [Batch 627/637] [D loss: 0.166371] [G loss: 0.594313]\n",
      "[Epoch 12/200] [Batch 628/637] [D loss: 0.142492] [G loss: 0.484947]\n",
      "[Epoch 12/200] [Batch 629/637] [D loss: 0.154673] [G loss: 0.476454]\n",
      "[Epoch 12/200] [Batch 630/637] [D loss: 0.149788] [G loss: 0.611591]\n",
      "[Epoch 12/200] [Batch 631/637] [D loss: 0.174693] [G loss: 0.601727]\n",
      "[Epoch 12/200] [Batch 632/637] [D loss: 0.148782] [G loss: 0.516270]\n",
      "[Epoch 12/200] [Batch 633/637] [D loss: 0.142853] [G loss: 0.511159]\n",
      "[Epoch 12/200] [Batch 634/637] [D loss: 0.153250] [G loss: 0.515995]\n",
      "[Epoch 12/200] [Batch 635/637] [D loss: 0.192976] [G loss: 0.536332]\n",
      "[Epoch 12/200] [Batch 636/637] [D loss: 0.159196] [G loss: 0.677571]\n",
      "[Epoch 13/200] [Batch 0/637] [D loss: 0.168340] [G loss: 0.504739]\n",
      "[Epoch 13/200] [Batch 1/637] [D loss: 0.170322] [G loss: 0.543908]\n",
      "[Epoch 13/200] [Batch 2/637] [D loss: 0.200629] [G loss: 0.470966]\n",
      "[Epoch 13/200] [Batch 3/637] [D loss: 0.156425] [G loss: 0.626523]\n",
      "[Epoch 13/200] [Batch 4/637] [D loss: 0.157805] [G loss: 0.578099]\n",
      "[Epoch 13/200] [Batch 5/637] [D loss: 0.157534] [G loss: 0.523220]\n",
      "[Epoch 13/200] [Batch 6/637] [D loss: 0.169560] [G loss: 0.473693]\n",
      "[Epoch 13/200] [Batch 7/637] [D loss: 0.179493] [G loss: 0.463076]\n",
      "[Epoch 13/200] [Batch 8/637] [D loss: 0.148772] [G loss: 0.506829]\n",
      "[Epoch 13/200] [Batch 9/637] [D loss: 0.165980] [G loss: 0.469298]\n",
      "[Epoch 13/200] [Batch 10/637] [D loss: 0.157791] [G loss: 0.557497]\n",
      "[Epoch 13/200] [Batch 11/637] [D loss: 0.162272] [G loss: 0.451166]\n",
      "[Epoch 13/200] [Batch 12/637] [D loss: 0.184371] [G loss: 0.444285]\n",
      "[Epoch 13/200] [Batch 13/637] [D loss: 0.144360] [G loss: 0.551920]\n",
      "[Epoch 13/200] [Batch 14/637] [D loss: 0.186134] [G loss: 0.444506]\n",
      "[Epoch 13/200] [Batch 15/637] [D loss: 0.174604] [G loss: 0.502651]\n",
      "[Epoch 13/200] [Batch 16/637] [D loss: 0.165861] [G loss: 0.512587]\n",
      "[Epoch 13/200] [Batch 17/637] [D loss: 0.168616] [G loss: 0.496287]\n",
      "[Epoch 13/200] [Batch 18/637] [D loss: 0.186645] [G loss: 0.456529]\n",
      "[Epoch 13/200] [Batch 19/637] [D loss: 0.182100] [G loss: 0.443798]\n",
      "[Epoch 13/200] [Batch 20/637] [D loss: 0.168016] [G loss: 0.480950]\n",
      "[Epoch 13/200] [Batch 21/637] [D loss: 0.172521] [G loss: 0.457718]\n",
      "[Epoch 13/200] [Batch 22/637] [D loss: 0.195502] [G loss: 0.526731]\n",
      "[Epoch 13/200] [Batch 23/637] [D loss: 0.149116] [G loss: 0.536707]\n",
      "[Epoch 13/200] [Batch 24/637] [D loss: 0.170638] [G loss: 0.521740]\n",
      "[Epoch 13/200] [Batch 25/637] [D loss: 0.158111] [G loss: 0.535161]\n",
      "[Epoch 13/200] [Batch 26/637] [D loss: 0.160468] [G loss: 0.508231]\n",
      "[Epoch 13/200] [Batch 27/637] [D loss: 0.152829] [G loss: 0.438034]\n",
      "[Epoch 13/200] [Batch 28/637] [D loss: 0.148906] [G loss: 0.474329]\n",
      "[Epoch 13/200] [Batch 29/637] [D loss: 0.134962] [G loss: 0.508030]\n",
      "[Epoch 13/200] [Batch 30/637] [D loss: 0.149281] [G loss: 0.505267]\n",
      "[Epoch 13/200] [Batch 31/637] [D loss: 0.142430] [G loss: 0.520639]\n",
      "[Epoch 13/200] [Batch 32/637] [D loss: 0.133233] [G loss: 0.503492]\n",
      "[Epoch 13/200] [Batch 33/637] [D loss: 0.152861] [G loss: 0.521256]\n",
      "[Epoch 13/200] [Batch 34/637] [D loss: 0.143144] [G loss: 0.564221]\n",
      "[Epoch 13/200] [Batch 35/637] [D loss: 0.174710] [G loss: 0.452658]\n",
      "[Epoch 13/200] [Batch 36/637] [D loss: 0.169524] [G loss: 0.518845]\n",
      "[Epoch 13/200] [Batch 37/637] [D loss: 0.155474] [G loss: 0.480106]\n",
      "[Epoch 13/200] [Batch 38/637] [D loss: 0.178253] [G loss: 0.441292]\n",
      "[Epoch 13/200] [Batch 39/637] [D loss: 0.162346] [G loss: 0.481365]\n",
      "[Epoch 13/200] [Batch 40/637] [D loss: 0.164097] [G loss: 0.508256]\n",
      "[Epoch 13/200] [Batch 41/637] [D loss: 0.173928] [G loss: 0.514190]\n",
      "[Epoch 13/200] [Batch 42/637] [D loss: 0.193470] [G loss: 0.436182]\n",
      "[Epoch 13/200] [Batch 43/637] [D loss: 0.197475] [G loss: 0.549829]\n",
      "[Epoch 13/200] [Batch 44/637] [D loss: 0.196589] [G loss: 0.567038]\n",
      "[Epoch 13/200] [Batch 45/637] [D loss: 0.185258] [G loss: 0.450355]\n",
      "[Epoch 13/200] [Batch 46/637] [D loss: 0.165039] [G loss: 0.453466]\n",
      "[Epoch 13/200] [Batch 47/637] [D loss: 0.161958] [G loss: 0.444373]\n",
      "[Epoch 13/200] [Batch 48/637] [D loss: 0.151788] [G loss: 0.426404]\n",
      "[Epoch 13/200] [Batch 49/637] [D loss: 0.166660] [G loss: 0.431483]\n",
      "[Epoch 13/200] [Batch 50/637] [D loss: 0.167171] [G loss: 0.431828]\n",
      "[Epoch 13/200] [Batch 51/637] [D loss: 0.171568] [G loss: 0.459680]\n",
      "[Epoch 13/200] [Batch 52/637] [D loss: 0.170009] [G loss: 0.492687]\n",
      "[Epoch 13/200] [Batch 53/637] [D loss: 0.159275] [G loss: 0.475643]\n",
      "[Epoch 13/200] [Batch 54/637] [D loss: 0.135700] [G loss: 0.473221]\n",
      "[Epoch 13/200] [Batch 55/637] [D loss: 0.240755] [G loss: 0.354245]\n",
      "[Epoch 13/200] [Batch 56/637] [D loss: 0.259208] [G loss: 0.757638]\n",
      "[Epoch 13/200] [Batch 57/637] [D loss: 0.236851] [G loss: 0.527991]\n",
      "[Epoch 13/200] [Batch 58/637] [D loss: 0.205187] [G loss: 0.552369]\n",
      "[Epoch 13/200] [Batch 59/637] [D loss: 0.196009] [G loss: 0.497190]\n",
      "[Epoch 13/200] [Batch 60/637] [D loss: 0.222657] [G loss: 0.365399]\n",
      "[Epoch 13/200] [Batch 61/637] [D loss: 0.169377] [G loss: 0.404061]\n",
      "[Epoch 13/200] [Batch 62/637] [D loss: 0.174065] [G loss: 0.404909]\n",
      "[Epoch 13/200] [Batch 63/637] [D loss: 0.188579] [G loss: 0.420586]\n",
      "[Epoch 13/200] [Batch 64/637] [D loss: 0.164005] [G loss: 0.437747]\n",
      "[Epoch 13/200] [Batch 65/637] [D loss: 0.152501] [G loss: 0.430116]\n",
      "[Epoch 13/200] [Batch 66/637] [D loss: 0.145934] [G loss: 0.477255]\n",
      "[Epoch 13/200] [Batch 67/637] [D loss: 0.145288] [G loss: 0.479276]\n",
      "[Epoch 13/200] [Batch 68/637] [D loss: 0.126664] [G loss: 0.551257]\n",
      "[Epoch 13/200] [Batch 69/637] [D loss: 0.148124] [G loss: 0.538605]\n",
      "[Epoch 13/200] [Batch 70/637] [D loss: 0.163398] [G loss: 0.463075]\n",
      "[Epoch 13/200] [Batch 71/637] [D loss: 0.140773] [G loss: 0.539877]\n",
      "[Epoch 13/200] [Batch 72/637] [D loss: 0.132501] [G loss: 0.626628]\n",
      "[Epoch 13/200] [Batch 73/637] [D loss: 0.172508] [G loss: 0.472612]\n",
      "[Epoch 13/200] [Batch 74/637] [D loss: 0.182533] [G loss: 0.539999]\n",
      "[Epoch 13/200] [Batch 75/637] [D loss: 0.159806] [G loss: 0.503497]\n",
      "[Epoch 13/200] [Batch 76/637] [D loss: 0.178757] [G loss: 0.482532]\n",
      "[Epoch 13/200] [Batch 77/637] [D loss: 0.165590] [G loss: 0.521927]\n",
      "[Epoch 13/200] [Batch 78/637] [D loss: 0.139708] [G loss: 0.513286]\n",
      "[Epoch 13/200] [Batch 79/637] [D loss: 0.142180] [G loss: 0.541297]\n",
      "[Epoch 13/200] [Batch 80/637] [D loss: 0.156295] [G loss: 0.556815]\n",
      "[Epoch 13/200] [Batch 81/637] [D loss: 0.148518] [G loss: 0.563769]\n",
      "[Epoch 13/200] [Batch 82/637] [D loss: 0.151514] [G loss: 0.523391]\n",
      "[Epoch 13/200] [Batch 83/637] [D loss: 0.138343] [G loss: 0.626727]\n",
      "[Epoch 13/200] [Batch 84/637] [D loss: 0.144086] [G loss: 0.624490]\n",
      "[Epoch 13/200] [Batch 85/637] [D loss: 0.189174] [G loss: 0.435242]\n",
      "[Epoch 13/200] [Batch 86/637] [D loss: 0.193099] [G loss: 0.657123]\n",
      "[Epoch 13/200] [Batch 87/637] [D loss: 0.180841] [G loss: 0.556647]\n",
      "[Epoch 13/200] [Batch 88/637] [D loss: 0.141592] [G loss: 0.571290]\n",
      "[Epoch 13/200] [Batch 89/637] [D loss: 0.176046] [G loss: 0.545203]\n",
      "[Epoch 13/200] [Batch 90/637] [D loss: 0.174073] [G loss: 0.464684]\n",
      "[Epoch 13/200] [Batch 91/637] [D loss: 0.193471] [G loss: 0.403914]\n",
      "[Epoch 13/200] [Batch 92/637] [D loss: 0.186176] [G loss: 0.579541]\n",
      "[Epoch 13/200] [Batch 93/637] [D loss: 0.169736] [G loss: 0.531754]\n",
      "[Epoch 13/200] [Batch 94/637] [D loss: 0.174157] [G loss: 0.555331]\n",
      "[Epoch 13/200] [Batch 95/637] [D loss: 0.167485] [G loss: 0.545960]\n",
      "[Epoch 13/200] [Batch 96/637] [D loss: 0.153453] [G loss: 0.480670]\n",
      "[Epoch 13/200] [Batch 97/637] [D loss: 0.159546] [G loss: 0.507149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 98/637] [D loss: 0.176076] [G loss: 0.470646]\n",
      "[Epoch 13/200] [Batch 99/637] [D loss: 0.138938] [G loss: 0.524411]\n",
      "[Epoch 13/200] [Batch 100/637] [D loss: 0.161681] [G loss: 0.510364]\n",
      "[Epoch 13/200] [Batch 101/637] [D loss: 0.153439] [G loss: 0.498605]\n",
      "[Epoch 13/200] [Batch 102/637] [D loss: 0.161872] [G loss: 0.523550]\n",
      "[Epoch 13/200] [Batch 103/637] [D loss: 0.199297] [G loss: 0.580491]\n",
      "[Epoch 13/200] [Batch 104/637] [D loss: 0.206516] [G loss: 0.546278]\n",
      "[Epoch 13/200] [Batch 105/637] [D loss: 0.172327] [G loss: 0.586505]\n",
      "[Epoch 13/200] [Batch 106/637] [D loss: 0.209041] [G loss: 0.559030]\n",
      "[Epoch 13/200] [Batch 107/637] [D loss: 0.171183] [G loss: 0.462938]\n",
      "[Epoch 13/200] [Batch 108/637] [D loss: 0.214398] [G loss: 0.370980]\n",
      "[Epoch 13/200] [Batch 109/637] [D loss: 0.176290] [G loss: 0.593666]\n",
      "[Epoch 13/200] [Batch 110/637] [D loss: 0.182244] [G loss: 0.615839]\n",
      "[Epoch 13/200] [Batch 111/637] [D loss: 0.161099] [G loss: 0.561265]\n",
      "[Epoch 13/200] [Batch 112/637] [D loss: 0.163619] [G loss: 0.463423]\n",
      "[Epoch 13/200] [Batch 113/637] [D loss: 0.153451] [G loss: 0.457670]\n",
      "[Epoch 13/200] [Batch 114/637] [D loss: 0.153347] [G loss: 0.507813]\n",
      "[Epoch 13/200] [Batch 115/637] [D loss: 0.167139] [G loss: 0.507562]\n",
      "[Epoch 13/200] [Batch 116/637] [D loss: 0.158269] [G loss: 0.544793]\n",
      "[Epoch 13/200] [Batch 117/637] [D loss: 0.136027] [G loss: 0.530372]\n",
      "[Epoch 13/200] [Batch 118/637] [D loss: 0.137753] [G loss: 0.505889]\n",
      "[Epoch 13/200] [Batch 119/637] [D loss: 0.136839] [G loss: 0.483154]\n",
      "[Epoch 13/200] [Batch 120/637] [D loss: 0.137058] [G loss: 0.504651]\n",
      "[Epoch 13/200] [Batch 121/637] [D loss: 0.152035] [G loss: 0.499163]\n",
      "[Epoch 13/200] [Batch 122/637] [D loss: 0.163426] [G loss: 0.481399]\n",
      "[Epoch 13/200] [Batch 123/637] [D loss: 0.136763] [G loss: 0.542039]\n",
      "[Epoch 13/200] [Batch 124/637] [D loss: 0.151901] [G loss: 0.521191]\n",
      "[Epoch 13/200] [Batch 125/637] [D loss: 0.172864] [G loss: 0.476299]\n",
      "[Epoch 13/200] [Batch 126/637] [D loss: 0.146189] [G loss: 0.588502]\n",
      "[Epoch 13/200] [Batch 127/637] [D loss: 0.136519] [G loss: 0.606588]\n",
      "[Epoch 13/200] [Batch 128/637] [D loss: 0.170038] [G loss: 0.511708]\n",
      "[Epoch 13/200] [Batch 129/637] [D loss: 0.157650] [G loss: 0.435762]\n",
      "[Epoch 13/200] [Batch 130/637] [D loss: 0.150659] [G loss: 0.472425]\n",
      "[Epoch 13/200] [Batch 131/637] [D loss: 0.170040] [G loss: 0.450645]\n",
      "[Epoch 13/200] [Batch 132/637] [D loss: 0.142900] [G loss: 0.495160]\n",
      "[Epoch 13/200] [Batch 133/637] [D loss: 0.175410] [G loss: 0.537694]\n",
      "[Epoch 13/200] [Batch 134/637] [D loss: 0.174689] [G loss: 0.447795]\n",
      "[Epoch 13/200] [Batch 135/637] [D loss: 0.152888] [G loss: 0.473926]\n",
      "[Epoch 13/200] [Batch 136/637] [D loss: 0.184630] [G loss: 0.597041]\n",
      "[Epoch 13/200] [Batch 137/637] [D loss: 0.144933] [G loss: 0.614186]\n",
      "[Epoch 13/200] [Batch 138/637] [D loss: 0.154859] [G loss: 0.556577]\n",
      "[Epoch 13/200] [Batch 139/637] [D loss: 0.156008] [G loss: 0.525121]\n",
      "[Epoch 13/200] [Batch 140/637] [D loss: 0.143752] [G loss: 0.519417]\n",
      "[Epoch 13/200] [Batch 141/637] [D loss: 0.141835] [G loss: 0.577491]\n",
      "[Epoch 13/200] [Batch 142/637] [D loss: 0.146189] [G loss: 0.482013]\n",
      "[Epoch 13/200] [Batch 143/637] [D loss: 0.123414] [G loss: 0.578417]\n",
      "[Epoch 13/200] [Batch 144/637] [D loss: 0.135045] [G loss: 0.539667]\n",
      "[Epoch 13/200] [Batch 145/637] [D loss: 0.159111] [G loss: 0.473730]\n",
      "[Epoch 13/200] [Batch 146/637] [D loss: 0.212378] [G loss: 0.549745]\n",
      "[Epoch 13/200] [Batch 147/637] [D loss: 0.143486] [G loss: 0.556619]\n",
      "[Epoch 13/200] [Batch 148/637] [D loss: 0.159225] [G loss: 0.593606]\n",
      "[Epoch 13/200] [Batch 149/637] [D loss: 0.155595] [G loss: 0.495964]\n",
      "[Epoch 13/200] [Batch 150/637] [D loss: 0.174039] [G loss: 0.456392]\n",
      "[Epoch 13/200] [Batch 151/637] [D loss: 0.174455] [G loss: 0.472392]\n",
      "[Epoch 13/200] [Batch 152/637] [D loss: 0.158089] [G loss: 0.428051]\n",
      "[Epoch 13/200] [Batch 153/637] [D loss: 0.185981] [G loss: 0.482965]\n",
      "[Epoch 13/200] [Batch 154/637] [D loss: 0.161382] [G loss: 0.494205]\n",
      "[Epoch 13/200] [Batch 155/637] [D loss: 0.168684] [G loss: 0.441218]\n",
      "[Epoch 13/200] [Batch 156/637] [D loss: 0.163179] [G loss: 0.463172]\n",
      "[Epoch 13/200] [Batch 157/637] [D loss: 0.142941] [G loss: 0.501769]\n",
      "[Epoch 13/200] [Batch 158/637] [D loss: 0.165034] [G loss: 0.491774]\n",
      "[Epoch 13/200] [Batch 159/637] [D loss: 0.171563] [G loss: 0.484732]\n",
      "[Epoch 13/200] [Batch 160/637] [D loss: 0.181203] [G loss: 0.521799]\n",
      "[Epoch 13/200] [Batch 161/637] [D loss: 0.186875] [G loss: 0.548446]\n",
      "[Epoch 13/200] [Batch 162/637] [D loss: 0.201391] [G loss: 0.484924]\n",
      "[Epoch 13/200] [Batch 163/637] [D loss: 0.144579] [G loss: 0.533282]\n",
      "[Epoch 13/200] [Batch 164/637] [D loss: 0.140989] [G loss: 0.467770]\n",
      "[Epoch 13/200] [Batch 165/637] [D loss: 0.167011] [G loss: 0.453802]\n",
      "[Epoch 13/200] [Batch 166/637] [D loss: 0.130176] [G loss: 0.561795]\n",
      "[Epoch 13/200] [Batch 167/637] [D loss: 0.158433] [G loss: 0.500075]\n",
      "[Epoch 13/200] [Batch 168/637] [D loss: 0.162040] [G loss: 0.503055]\n",
      "[Epoch 13/200] [Batch 169/637] [D loss: 0.146652] [G loss: 0.585909]\n",
      "[Epoch 13/200] [Batch 170/637] [D loss: 0.121744] [G loss: 0.587259]\n",
      "[Epoch 13/200] [Batch 171/637] [D loss: 0.141914] [G loss: 0.565485]\n",
      "[Epoch 13/200] [Batch 172/637] [D loss: 0.177467] [G loss: 0.451995]\n",
      "[Epoch 13/200] [Batch 173/637] [D loss: 0.157485] [G loss: 0.602920]\n",
      "[Epoch 13/200] [Batch 174/637] [D loss: 0.144897] [G loss: 0.545761]\n",
      "[Epoch 13/200] [Batch 175/637] [D loss: 0.150978] [G loss: 0.506556]\n",
      "[Epoch 13/200] [Batch 176/637] [D loss: 0.178770] [G loss: 0.467392]\n",
      "[Epoch 13/200] [Batch 177/637] [D loss: 0.165439] [G loss: 0.531072]\n",
      "[Epoch 13/200] [Batch 178/637] [D loss: 0.175263] [G loss: 0.623388]\n",
      "[Epoch 13/200] [Batch 179/637] [D loss: 0.170496] [G loss: 0.533203]\n",
      "[Epoch 13/200] [Batch 180/637] [D loss: 0.152506] [G loss: 0.481461]\n",
      "[Epoch 13/200] [Batch 181/637] [D loss: 0.189825] [G loss: 0.445220]\n",
      "[Epoch 13/200] [Batch 182/637] [D loss: 0.174485] [G loss: 0.576843]\n",
      "[Epoch 13/200] [Batch 183/637] [D loss: 0.139048] [G loss: 0.672285]\n",
      "[Epoch 13/200] [Batch 184/637] [D loss: 0.162553] [G loss: 0.589933]\n",
      "[Epoch 13/200] [Batch 185/637] [D loss: 0.157163] [G loss: 0.503105]\n",
      "[Epoch 13/200] [Batch 186/637] [D loss: 0.176902] [G loss: 0.470060]\n",
      "[Epoch 13/200] [Batch 187/637] [D loss: 0.170112] [G loss: 0.418101]\n",
      "[Epoch 13/200] [Batch 188/637] [D loss: 0.136887] [G loss: 0.536914]\n",
      "[Epoch 13/200] [Batch 189/637] [D loss: 0.149786] [G loss: 0.540823]\n",
      "[Epoch 13/200] [Batch 190/637] [D loss: 0.161814] [G loss: 0.467438]\n",
      "[Epoch 13/200] [Batch 191/637] [D loss: 0.153782] [G loss: 0.566526]\n",
      "[Epoch 13/200] [Batch 192/637] [D loss: 0.181130] [G loss: 0.478805]\n",
      "[Epoch 13/200] [Batch 193/637] [D loss: 0.158085] [G loss: 0.497853]\n",
      "[Epoch 13/200] [Batch 194/637] [D loss: 0.183582] [G loss: 0.486640]\n",
      "[Epoch 13/200] [Batch 195/637] [D loss: 0.183716] [G loss: 0.525901]\n",
      "[Epoch 13/200] [Batch 196/637] [D loss: 0.156989] [G loss: 0.507824]\n",
      "[Epoch 13/200] [Batch 197/637] [D loss: 0.157619] [G loss: 0.526248]\n",
      "[Epoch 13/200] [Batch 198/637] [D loss: 0.183324] [G loss: 0.437731]\n",
      "[Epoch 13/200] [Batch 199/637] [D loss: 0.186940] [G loss: 0.483888]\n",
      "[Epoch 13/200] [Batch 200/637] [D loss: 0.164398] [G loss: 0.468297]\n",
      "[Epoch 13/200] [Batch 201/637] [D loss: 0.169158] [G loss: 0.502384]\n",
      "[Epoch 13/200] [Batch 202/637] [D loss: 0.151817] [G loss: 0.564078]\n",
      "[Epoch 13/200] [Batch 203/637] [D loss: 0.171322] [G loss: 0.476206]\n",
      "[Epoch 13/200] [Batch 204/637] [D loss: 0.160760] [G loss: 0.543493]\n",
      "[Epoch 13/200] [Batch 205/637] [D loss: 0.146991] [G loss: 0.490816]\n",
      "[Epoch 13/200] [Batch 206/637] [D loss: 0.169371] [G loss: 0.475115]\n",
      "[Epoch 13/200] [Batch 207/637] [D loss: 0.157032] [G loss: 0.517983]\n",
      "[Epoch 13/200] [Batch 208/637] [D loss: 0.135845] [G loss: 0.509380]\n",
      "[Epoch 13/200] [Batch 209/637] [D loss: 0.160991] [G loss: 0.444138]\n",
      "[Epoch 13/200] [Batch 210/637] [D loss: 0.198353] [G loss: 0.490002]\n",
      "[Epoch 13/200] [Batch 211/637] [D loss: 0.152319] [G loss: 0.549107]\n",
      "[Epoch 13/200] [Batch 212/637] [D loss: 0.153782] [G loss: 0.517121]\n",
      "[Epoch 13/200] [Batch 213/637] [D loss: 0.175522] [G loss: 0.438289]\n",
      "[Epoch 13/200] [Batch 214/637] [D loss: 0.128373] [G loss: 0.498359]\n",
      "[Epoch 13/200] [Batch 215/637] [D loss: 0.169358] [G loss: 0.483046]\n",
      "[Epoch 13/200] [Batch 216/637] [D loss: 0.183216] [G loss: 0.432824]\n",
      "[Epoch 13/200] [Batch 217/637] [D loss: 0.151852] [G loss: 0.517506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 218/637] [D loss: 0.136858] [G loss: 0.485704]\n",
      "[Epoch 13/200] [Batch 219/637] [D loss: 0.147971] [G loss: 0.549703]\n",
      "[Epoch 13/200] [Batch 220/637] [D loss: 0.155421] [G loss: 0.520639]\n",
      "[Epoch 13/200] [Batch 221/637] [D loss: 0.140457] [G loss: 0.552063]\n",
      "[Epoch 13/200] [Batch 222/637] [D loss: 0.165011] [G loss: 0.427956]\n",
      "[Epoch 13/200] [Batch 223/637] [D loss: 0.183861] [G loss: 0.431308]\n",
      "[Epoch 13/200] [Batch 224/637] [D loss: 0.159912] [G loss: 0.472669]\n",
      "[Epoch 13/200] [Batch 225/637] [D loss: 0.169077] [G loss: 0.494652]\n",
      "[Epoch 13/200] [Batch 226/637] [D loss: 0.187142] [G loss: 0.461606]\n",
      "[Epoch 13/200] [Batch 227/637] [D loss: 0.141868] [G loss: 0.588244]\n",
      "[Epoch 13/200] [Batch 228/637] [D loss: 0.156643] [G loss: 0.576896]\n",
      "[Epoch 13/200] [Batch 229/637] [D loss: 0.139372] [G loss: 0.544522]\n",
      "[Epoch 13/200] [Batch 230/637] [D loss: 0.153263] [G loss: 0.539701]\n",
      "[Epoch 13/200] [Batch 231/637] [D loss: 0.150973] [G loss: 0.426724]\n",
      "[Epoch 13/200] [Batch 232/637] [D loss: 0.162619] [G loss: 0.498909]\n",
      "[Epoch 13/200] [Batch 233/637] [D loss: 0.147802] [G loss: 0.574994]\n",
      "[Epoch 13/200] [Batch 234/637] [D loss: 0.181763] [G loss: 0.481058]\n",
      "[Epoch 13/200] [Batch 235/637] [D loss: 0.173350] [G loss: 0.556415]\n",
      "[Epoch 13/200] [Batch 236/637] [D loss: 0.183117] [G loss: 0.525175]\n",
      "[Epoch 13/200] [Batch 237/637] [D loss: 0.195243] [G loss: 0.538479]\n",
      "[Epoch 13/200] [Batch 238/637] [D loss: 0.186723] [G loss: 0.504309]\n",
      "[Epoch 13/200] [Batch 239/637] [D loss: 0.180057] [G loss: 0.449558]\n",
      "[Epoch 13/200] [Batch 240/637] [D loss: 0.169294] [G loss: 0.490357]\n",
      "[Epoch 13/200] [Batch 241/637] [D loss: 0.192156] [G loss: 0.489951]\n",
      "[Epoch 13/200] [Batch 242/637] [D loss: 0.159964] [G loss: 0.465969]\n",
      "[Epoch 13/200] [Batch 243/637] [D loss: 0.181714] [G loss: 0.433912]\n",
      "[Epoch 13/200] [Batch 244/637] [D loss: 0.144353] [G loss: 0.523767]\n",
      "[Epoch 13/200] [Batch 245/637] [D loss: 0.160185] [G loss: 0.448541]\n",
      "[Epoch 13/200] [Batch 246/637] [D loss: 0.156881] [G loss: 0.491817]\n",
      "[Epoch 13/200] [Batch 247/637] [D loss: 0.171538] [G loss: 0.525072]\n",
      "[Epoch 13/200] [Batch 248/637] [D loss: 0.159917] [G loss: 0.569526]\n",
      "[Epoch 13/200] [Batch 249/637] [D loss: 0.131773] [G loss: 0.603064]\n",
      "[Epoch 13/200] [Batch 250/637] [D loss: 0.146226] [G loss: 0.459411]\n",
      "[Epoch 13/200] [Batch 251/637] [D loss: 0.139678] [G loss: 0.497765]\n",
      "[Epoch 13/200] [Batch 252/637] [D loss: 0.171069] [G loss: 0.513341]\n",
      "[Epoch 13/200] [Batch 253/637] [D loss: 0.140151] [G loss: 0.593811]\n",
      "[Epoch 13/200] [Batch 254/637] [D loss: 0.128333] [G loss: 0.571016]\n",
      "[Epoch 13/200] [Batch 255/637] [D loss: 0.148553] [G loss: 0.504041]\n",
      "[Epoch 13/200] [Batch 256/637] [D loss: 0.145114] [G loss: 0.502539]\n",
      "[Epoch 13/200] [Batch 257/637] [D loss: 0.134623] [G loss: 0.589110]\n",
      "[Epoch 13/200] [Batch 258/637] [D loss: 0.145906] [G loss: 0.572334]\n",
      "[Epoch 13/200] [Batch 259/637] [D loss: 0.152453] [G loss: 0.566193]\n",
      "[Epoch 13/200] [Batch 260/637] [D loss: 0.144402] [G loss: 0.481630]\n",
      "[Epoch 13/200] [Batch 261/637] [D loss: 0.149517] [G loss: 0.540782]\n",
      "[Epoch 13/200] [Batch 262/637] [D loss: 0.152564] [G loss: 0.532829]\n",
      "[Epoch 13/200] [Batch 263/637] [D loss: 0.151560] [G loss: 0.594845]\n",
      "[Epoch 13/200] [Batch 264/637] [D loss: 0.172069] [G loss: 0.481566]\n",
      "[Epoch 13/200] [Batch 265/637] [D loss: 0.166615] [G loss: 0.466136]\n",
      "[Epoch 13/200] [Batch 266/637] [D loss: 0.161010] [G loss: 0.490414]\n",
      "[Epoch 13/200] [Batch 267/637] [D loss: 0.147603] [G loss: 0.551580]\n",
      "[Epoch 13/200] [Batch 268/637] [D loss: 0.173976] [G loss: 0.507100]\n",
      "[Epoch 13/200] [Batch 269/637] [D loss: 0.156660] [G loss: 0.507288]\n",
      "[Epoch 13/200] [Batch 270/637] [D loss: 0.186372] [G loss: 0.462167]\n",
      "[Epoch 13/200] [Batch 271/637] [D loss: 0.158013] [G loss: 0.484097]\n",
      "[Epoch 13/200] [Batch 272/637] [D loss: 0.164948] [G loss: 0.504955]\n",
      "[Epoch 13/200] [Batch 273/637] [D loss: 0.151463] [G loss: 0.499254]\n",
      "[Epoch 13/200] [Batch 274/637] [D loss: 0.176216] [G loss: 0.510923]\n",
      "[Epoch 13/200] [Batch 275/637] [D loss: 0.171886] [G loss: 0.484345]\n",
      "[Epoch 13/200] [Batch 276/637] [D loss: 0.180536] [G loss: 0.504017]\n",
      "[Epoch 13/200] [Batch 277/637] [D loss: 0.161868] [G loss: 0.593122]\n",
      "[Epoch 13/200] [Batch 278/637] [D loss: 0.158557] [G loss: 0.566675]\n",
      "[Epoch 13/200] [Batch 279/637] [D loss: 0.136670] [G loss: 0.515110]\n",
      "[Epoch 13/200] [Batch 280/637] [D loss: 0.149248] [G loss: 0.462108]\n",
      "[Epoch 13/200] [Batch 281/637] [D loss: 0.136971] [G loss: 0.552440]\n",
      "[Epoch 13/200] [Batch 282/637] [D loss: 0.178354] [G loss: 0.464760]\n",
      "[Epoch 13/200] [Batch 283/637] [D loss: 0.201971] [G loss: 0.672604]\n",
      "[Epoch 13/200] [Batch 284/637] [D loss: 0.133273] [G loss: 0.670394]\n",
      "[Epoch 13/200] [Batch 285/637] [D loss: 0.178459] [G loss: 0.564702]\n",
      "[Epoch 13/200] [Batch 286/637] [D loss: 0.173085] [G loss: 0.488255]\n",
      "[Epoch 13/200] [Batch 287/637] [D loss: 0.165190] [G loss: 0.459881]\n",
      "[Epoch 13/200] [Batch 288/637] [D loss: 0.169135] [G loss: 0.414220]\n",
      "[Epoch 13/200] [Batch 289/637] [D loss: 0.186168] [G loss: 0.385352]\n",
      "[Epoch 13/200] [Batch 290/637] [D loss: 0.162773] [G loss: 0.493856]\n",
      "[Epoch 13/200] [Batch 291/637] [D loss: 0.156593] [G loss: 0.525586]\n",
      "[Epoch 13/200] [Batch 292/637] [D loss: 0.159630] [G loss: 0.516227]\n",
      "[Epoch 13/200] [Batch 293/637] [D loss: 0.149666] [G loss: 0.549581]\n",
      "[Epoch 13/200] [Batch 294/637] [D loss: 0.146517] [G loss: 0.486785]\n",
      "[Epoch 13/200] [Batch 295/637] [D loss: 0.158011] [G loss: 0.485713]\n",
      "[Epoch 13/200] [Batch 296/637] [D loss: 0.149630] [G loss: 0.497408]\n",
      "[Epoch 13/200] [Batch 297/637] [D loss: 0.153631] [G loss: 0.477520]\n",
      "[Epoch 13/200] [Batch 298/637] [D loss: 0.156487] [G loss: 0.505207]\n",
      "[Epoch 13/200] [Batch 299/637] [D loss: 0.162602] [G loss: 0.478777]\n",
      "[Epoch 13/200] [Batch 300/637] [D loss: 0.164565] [G loss: 0.467952]\n",
      "[Epoch 13/200] [Batch 301/637] [D loss: 0.170048] [G loss: 0.475677]\n",
      "[Epoch 13/200] [Batch 302/637] [D loss: 0.143642] [G loss: 0.502231]\n",
      "[Epoch 13/200] [Batch 303/637] [D loss: 0.140852] [G loss: 0.522402]\n",
      "[Epoch 13/200] [Batch 304/637] [D loss: 0.169041] [G loss: 0.495276]\n",
      "[Epoch 13/200] [Batch 305/637] [D loss: 0.151897] [G loss: 0.460097]\n",
      "[Epoch 13/200] [Batch 306/637] [D loss: 0.183731] [G loss: 0.440025]\n",
      "[Epoch 13/200] [Batch 307/637] [D loss: 0.157351] [G loss: 0.492580]\n",
      "[Epoch 13/200] [Batch 308/637] [D loss: 0.138402] [G loss: 0.498426]\n",
      "[Epoch 13/200] [Batch 309/637] [D loss: 0.140312] [G loss: 0.497748]\n",
      "[Epoch 13/200] [Batch 310/637] [D loss: 0.138194] [G loss: 0.548086]\n",
      "[Epoch 13/200] [Batch 311/637] [D loss: 0.160409] [G loss: 0.462423]\n",
      "[Epoch 13/200] [Batch 312/637] [D loss: 0.175007] [G loss: 0.453483]\n",
      "[Epoch 13/200] [Batch 313/637] [D loss: 0.158532] [G loss: 0.561809]\n",
      "[Epoch 13/200] [Batch 314/637] [D loss: 0.163247] [G loss: 0.494534]\n",
      "[Epoch 13/200] [Batch 315/637] [D loss: 0.183665] [G loss: 0.472065]\n",
      "[Epoch 13/200] [Batch 316/637] [D loss: 0.170776] [G loss: 0.442711]\n",
      "[Epoch 13/200] [Batch 317/637] [D loss: 0.182798] [G loss: 0.476238]\n",
      "[Epoch 13/200] [Batch 318/637] [D loss: 0.170044] [G loss: 0.459116]\n",
      "[Epoch 13/200] [Batch 319/637] [D loss: 0.157185] [G loss: 0.471545]\n",
      "[Epoch 13/200] [Batch 320/637] [D loss: 0.167938] [G loss: 0.459234]\n",
      "[Epoch 13/200] [Batch 321/637] [D loss: 0.188331] [G loss: 0.542892]\n",
      "[Epoch 13/200] [Batch 322/637] [D loss: 0.170114] [G loss: 0.481059]\n",
      "[Epoch 13/200] [Batch 323/637] [D loss: 0.176645] [G loss: 0.473462]\n",
      "[Epoch 13/200] [Batch 324/637] [D loss: 0.158820] [G loss: 0.469918]\n",
      "[Epoch 13/200] [Batch 325/637] [D loss: 0.168567] [G loss: 0.548432]\n",
      "[Epoch 13/200] [Batch 326/637] [D loss: 0.158875] [G loss: 0.460362]\n",
      "[Epoch 13/200] [Batch 327/637] [D loss: 0.159605] [G loss: 0.510565]\n",
      "[Epoch 13/200] [Batch 328/637] [D loss: 0.142549] [G loss: 0.555062]\n",
      "[Epoch 13/200] [Batch 329/637] [D loss: 0.150227] [G loss: 0.516087]\n",
      "[Epoch 13/200] [Batch 330/637] [D loss: 0.156833] [G loss: 0.515319]\n",
      "[Epoch 13/200] [Batch 331/637] [D loss: 0.172471] [G loss: 0.512258]\n",
      "[Epoch 13/200] [Batch 332/637] [D loss: 0.154321] [G loss: 0.574669]\n",
      "[Epoch 13/200] [Batch 333/637] [D loss: 0.148739] [G loss: 0.500686]\n",
      "[Epoch 13/200] [Batch 334/637] [D loss: 0.186100] [G loss: 0.475260]\n",
      "[Epoch 13/200] [Batch 335/637] [D loss: 0.158449] [G loss: 0.520900]\n",
      "[Epoch 13/200] [Batch 336/637] [D loss: 0.156728] [G loss: 0.469753]\n",
      "[Epoch 13/200] [Batch 337/637] [D loss: 0.162807] [G loss: 0.488064]\n",
      "[Epoch 13/200] [Batch 338/637] [D loss: 0.164065] [G loss: 0.525490]\n",
      "[Epoch 13/200] [Batch 339/637] [D loss: 0.167636] [G loss: 0.546132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 340/637] [D loss: 0.160010] [G loss: 0.544586]\n",
      "[Epoch 13/200] [Batch 341/637] [D loss: 0.170988] [G loss: 0.472404]\n",
      "[Epoch 13/200] [Batch 342/637] [D loss: 0.165932] [G loss: 0.491272]\n",
      "[Epoch 13/200] [Batch 343/637] [D loss: 0.153468] [G loss: 0.532681]\n",
      "[Epoch 13/200] [Batch 344/637] [D loss: 0.174633] [G loss: 0.498039]\n",
      "[Epoch 13/200] [Batch 345/637] [D loss: 0.157569] [G loss: 0.578955]\n",
      "[Epoch 13/200] [Batch 346/637] [D loss: 0.159563] [G loss: 0.489511]\n",
      "[Epoch 13/200] [Batch 347/637] [D loss: 0.161821] [G loss: 0.551794]\n",
      "[Epoch 13/200] [Batch 348/637] [D loss: 0.151445] [G loss: 0.587476]\n",
      "[Epoch 13/200] [Batch 349/637] [D loss: 0.195795] [G loss: 0.535301]\n",
      "[Epoch 13/200] [Batch 350/637] [D loss: 0.169392] [G loss: 0.435898]\n",
      "[Epoch 13/200] [Batch 351/637] [D loss: 0.200763] [G loss: 0.446169]\n",
      "[Epoch 13/200] [Batch 352/637] [D loss: 0.211443] [G loss: 0.625296]\n",
      "[Epoch 13/200] [Batch 353/637] [D loss: 0.202991] [G loss: 0.594288]\n",
      "[Epoch 13/200] [Batch 354/637] [D loss: 0.170620] [G loss: 0.479757]\n",
      "[Epoch 13/200] [Batch 355/637] [D loss: 0.186819] [G loss: 0.463440]\n",
      "[Epoch 13/200] [Batch 356/637] [D loss: 0.165508] [G loss: 0.471410]\n",
      "[Epoch 13/200] [Batch 357/637] [D loss: 0.162903] [G loss: 0.467354]\n",
      "[Epoch 13/200] [Batch 358/637] [D loss: 0.153385] [G loss: 0.430453]\n",
      "[Epoch 13/200] [Batch 359/637] [D loss: 0.137302] [G loss: 0.536798]\n",
      "[Epoch 13/200] [Batch 360/637] [D loss: 0.141544] [G loss: 0.533677]\n",
      "[Epoch 13/200] [Batch 361/637] [D loss: 0.135389] [G loss: 0.633894]\n",
      "[Epoch 13/200] [Batch 362/637] [D loss: 0.165895] [G loss: 0.458254]\n",
      "[Epoch 13/200] [Batch 363/637] [D loss: 0.171510] [G loss: 0.506005]\n",
      "[Epoch 13/200] [Batch 364/637] [D loss: 0.145872] [G loss: 0.521553]\n",
      "[Epoch 13/200] [Batch 365/637] [D loss: 0.178592] [G loss: 0.494024]\n",
      "[Epoch 13/200] [Batch 366/637] [D loss: 0.144510] [G loss: 0.677198]\n",
      "[Epoch 13/200] [Batch 367/637] [D loss: 0.177058] [G loss: 0.607628]\n",
      "[Epoch 13/200] [Batch 368/637] [D loss: 0.164288] [G loss: 0.477695]\n",
      "[Epoch 13/200] [Batch 369/637] [D loss: 0.185689] [G loss: 0.462118]\n",
      "[Epoch 13/200] [Batch 370/637] [D loss: 0.192301] [G loss: 0.608741]\n",
      "[Epoch 13/200] [Batch 371/637] [D loss: 0.174389] [G loss: 0.566751]\n",
      "[Epoch 13/200] [Batch 372/637] [D loss: 0.194843] [G loss: 0.424607]\n",
      "[Epoch 13/200] [Batch 373/637] [D loss: 0.166127] [G loss: 0.448459]\n",
      "[Epoch 13/200] [Batch 374/637] [D loss: 0.181045] [G loss: 0.466102]\n",
      "[Epoch 13/200] [Batch 375/637] [D loss: 0.147598] [G loss: 0.530536]\n",
      "[Epoch 13/200] [Batch 376/637] [D loss: 0.166748] [G loss: 0.508881]\n",
      "[Epoch 13/200] [Batch 377/637] [D loss: 0.181830] [G loss: 0.515803]\n",
      "[Epoch 13/200] [Batch 378/637] [D loss: 0.161089] [G loss: 0.477963]\n",
      "[Epoch 13/200] [Batch 379/637] [D loss: 0.165007] [G loss: 0.495895]\n",
      "[Epoch 13/200] [Batch 380/637] [D loss: 0.148000] [G loss: 0.540478]\n",
      "[Epoch 13/200] [Batch 381/637] [D loss: 0.188076] [G loss: 0.442607]\n",
      "[Epoch 13/200] [Batch 382/637] [D loss: 0.193394] [G loss: 0.482127]\n",
      "[Epoch 13/200] [Batch 383/637] [D loss: 0.174465] [G loss: 0.548228]\n",
      "[Epoch 13/200] [Batch 384/637] [D loss: 0.197727] [G loss: 0.584263]\n",
      "[Epoch 13/200] [Batch 385/637] [D loss: 0.176452] [G loss: 0.499591]\n",
      "[Epoch 13/200] [Batch 386/637] [D loss: 0.172996] [G loss: 0.404792]\n",
      "[Epoch 13/200] [Batch 387/637] [D loss: 0.186795] [G loss: 0.418378]\n",
      "[Epoch 13/200] [Batch 388/637] [D loss: 0.166926] [G loss: 0.458484]\n",
      "[Epoch 13/200] [Batch 389/637] [D loss: 0.182658] [G loss: 0.505244]\n",
      "[Epoch 13/200] [Batch 390/637] [D loss: 0.155268] [G loss: 0.526090]\n",
      "[Epoch 13/200] [Batch 391/637] [D loss: 0.154728] [G loss: 0.513180]\n",
      "[Epoch 13/200] [Batch 392/637] [D loss: 0.158063] [G loss: 0.486942]\n",
      "[Epoch 13/200] [Batch 393/637] [D loss: 0.178843] [G loss: 0.569695]\n",
      "[Epoch 13/200] [Batch 394/637] [D loss: 0.142096] [G loss: 0.530455]\n",
      "[Epoch 13/200] [Batch 395/637] [D loss: 0.144487] [G loss: 0.591215]\n",
      "[Epoch 13/200] [Batch 396/637] [D loss: 0.139332] [G loss: 0.557055]\n",
      "[Epoch 13/200] [Batch 397/637] [D loss: 0.149360] [G loss: 0.566502]\n",
      "[Epoch 13/200] [Batch 398/637] [D loss: 0.174985] [G loss: 0.526240]\n",
      "[Epoch 13/200] [Batch 399/637] [D loss: 0.139438] [G loss: 0.534869]\n",
      "[Epoch 13/200] [Batch 400/637] [D loss: 0.158513] [G loss: 0.563455]\n",
      "[Epoch 13/200] [Batch 401/637] [D loss: 0.158076] [G loss: 0.537630]\n",
      "[Epoch 13/200] [Batch 402/637] [D loss: 0.171863] [G loss: 0.513586]\n",
      "[Epoch 13/200] [Batch 403/637] [D loss: 0.143424] [G loss: 0.498323]\n",
      "[Epoch 13/200] [Batch 404/637] [D loss: 0.148784] [G loss: 0.473216]\n",
      "[Epoch 13/200] [Batch 405/637] [D loss: 0.152145] [G loss: 0.517413]\n",
      "[Epoch 13/200] [Batch 406/637] [D loss: 0.162765] [G loss: 0.485557]\n",
      "[Epoch 13/200] [Batch 407/637] [D loss: 0.142884] [G loss: 0.525485]\n",
      "[Epoch 13/200] [Batch 408/637] [D loss: 0.158741] [G loss: 0.530828]\n",
      "[Epoch 13/200] [Batch 409/637] [D loss: 0.164973] [G loss: 0.433331]\n",
      "[Epoch 13/200] [Batch 410/637] [D loss: 0.164441] [G loss: 0.537391]\n",
      "[Epoch 13/200] [Batch 411/637] [D loss: 0.142505] [G loss: 0.650018]\n",
      "[Epoch 13/200] [Batch 412/637] [D loss: 0.135992] [G loss: 0.551238]\n",
      "[Epoch 13/200] [Batch 413/637] [D loss: 0.151079] [G loss: 0.469191]\n",
      "[Epoch 13/200] [Batch 414/637] [D loss: 0.136277] [G loss: 0.538989]\n",
      "[Epoch 13/200] [Batch 415/637] [D loss: 0.259154] [G loss: 0.466700]\n",
      "[Epoch 13/200] [Batch 416/637] [D loss: 0.182689] [G loss: 0.604836]\n",
      "[Epoch 13/200] [Batch 417/637] [D loss: 0.180774] [G loss: 0.601763]\n",
      "[Epoch 13/200] [Batch 418/637] [D loss: 0.169606] [G loss: 0.520983]\n",
      "[Epoch 13/200] [Batch 419/637] [D loss: 0.154361] [G loss: 0.504226]\n",
      "[Epoch 13/200] [Batch 420/637] [D loss: 0.144580] [G loss: 0.488891]\n",
      "[Epoch 13/200] [Batch 421/637] [D loss: 0.167820] [G loss: 0.428350]\n",
      "[Epoch 13/200] [Batch 422/637] [D loss: 0.175782] [G loss: 0.388673]\n",
      "[Epoch 13/200] [Batch 423/637] [D loss: 0.162524] [G loss: 0.543171]\n",
      "[Epoch 13/200] [Batch 424/637] [D loss: 0.149931] [G loss: 0.564121]\n",
      "[Epoch 13/200] [Batch 425/637] [D loss: 0.157661] [G loss: 0.518531]\n",
      "[Epoch 13/200] [Batch 426/637] [D loss: 0.156964] [G loss: 0.444119]\n",
      "[Epoch 13/200] [Batch 427/637] [D loss: 0.167597] [G loss: 0.408506]\n",
      "[Epoch 13/200] [Batch 428/637] [D loss: 0.132625] [G loss: 0.476799]\n",
      "[Epoch 13/200] [Batch 429/637] [D loss: 0.148484] [G loss: 0.447979]\n",
      "[Epoch 13/200] [Batch 430/637] [D loss: 0.164708] [G loss: 0.434853]\n",
      "[Epoch 13/200] [Batch 431/637] [D loss: 0.142490] [G loss: 0.499666]\n",
      "[Epoch 13/200] [Batch 432/637] [D loss: 0.128767] [G loss: 0.522341]\n",
      "[Epoch 13/200] [Batch 433/637] [D loss: 0.157900] [G loss: 0.441036]\n",
      "[Epoch 13/200] [Batch 434/637] [D loss: 0.149379] [G loss: 0.521023]\n",
      "[Epoch 13/200] [Batch 435/637] [D loss: 0.170374] [G loss: 0.465964]\n",
      "[Epoch 13/200] [Batch 436/637] [D loss: 0.163236] [G loss: 0.510847]\n",
      "[Epoch 13/200] [Batch 437/637] [D loss: 0.170109] [G loss: 0.514601]\n",
      "[Epoch 13/200] [Batch 438/637] [D loss: 0.145669] [G loss: 0.537094]\n",
      "[Epoch 13/200] [Batch 439/637] [D loss: 0.159673] [G loss: 0.531687]\n",
      "[Epoch 13/200] [Batch 440/637] [D loss: 0.156666] [G loss: 0.468120]\n",
      "[Epoch 13/200] [Batch 441/637] [D loss: 0.166586] [G loss: 0.515304]\n",
      "[Epoch 13/200] [Batch 442/637] [D loss: 0.143060] [G loss: 0.591096]\n",
      "[Epoch 13/200] [Batch 443/637] [D loss: 0.139187] [G loss: 0.552668]\n",
      "[Epoch 13/200] [Batch 444/637] [D loss: 0.160442] [G loss: 0.455456]\n",
      "[Epoch 13/200] [Batch 445/637] [D loss: 0.140554] [G loss: 0.466209]\n",
      "[Epoch 13/200] [Batch 446/637] [D loss: 0.171490] [G loss: 0.509474]\n",
      "[Epoch 13/200] [Batch 447/637] [D loss: 0.150974] [G loss: 0.536903]\n",
      "[Epoch 13/200] [Batch 448/637] [D loss: 0.136288] [G loss: 0.493457]\n",
      "[Epoch 13/200] [Batch 449/637] [D loss: 0.140297] [G loss: 0.592482]\n",
      "[Epoch 13/200] [Batch 450/637] [D loss: 0.146305] [G loss: 0.539604]\n",
      "[Epoch 13/200] [Batch 451/637] [D loss: 0.133459] [G loss: 0.501104]\n",
      "[Epoch 13/200] [Batch 452/637] [D loss: 0.145201] [G loss: 0.483977]\n",
      "[Epoch 13/200] [Batch 453/637] [D loss: 0.172876] [G loss: 0.381525]\n",
      "[Epoch 13/200] [Batch 454/637] [D loss: 0.150934] [G loss: 0.482607]\n",
      "[Epoch 13/200] [Batch 455/637] [D loss: 0.153557] [G loss: 0.519358]\n",
      "[Epoch 13/200] [Batch 456/637] [D loss: 0.129410] [G loss: 0.557668]\n",
      "[Epoch 13/200] [Batch 457/637] [D loss: 0.151957] [G loss: 0.582410]\n",
      "[Epoch 13/200] [Batch 458/637] [D loss: 0.153060] [G loss: 0.501740]\n",
      "[Epoch 13/200] [Batch 459/637] [D loss: 0.159992] [G loss: 0.467750]\n",
      "[Epoch 13/200] [Batch 460/637] [D loss: 0.147213] [G loss: 0.490021]\n",
      "[Epoch 13/200] [Batch 461/637] [D loss: 0.146775] [G loss: 0.479034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 462/637] [D loss: 0.152191] [G loss: 0.481249]\n",
      "[Epoch 13/200] [Batch 463/637] [D loss: 0.153659] [G loss: 0.501972]\n",
      "[Epoch 13/200] [Batch 464/637] [D loss: 0.121828] [G loss: 0.587762]\n",
      "[Epoch 13/200] [Batch 465/637] [D loss: 0.176234] [G loss: 0.435903]\n",
      "[Epoch 13/200] [Batch 466/637] [D loss: 0.150767] [G loss: 0.518556]\n",
      "[Epoch 13/200] [Batch 467/637] [D loss: 0.156454] [G loss: 0.488724]\n",
      "[Epoch 13/200] [Batch 468/637] [D loss: 0.136452] [G loss: 0.553086]\n",
      "[Epoch 13/200] [Batch 469/637] [D loss: 0.151403] [G loss: 0.444448]\n",
      "[Epoch 13/200] [Batch 470/637] [D loss: 0.144608] [G loss: 0.469679]\n",
      "[Epoch 13/200] [Batch 471/637] [D loss: 0.130974] [G loss: 0.472218]\n",
      "[Epoch 13/200] [Batch 472/637] [D loss: 0.128688] [G loss: 0.540007]\n",
      "[Epoch 13/200] [Batch 473/637] [D loss: 0.136576] [G loss: 0.525918]\n",
      "[Epoch 13/200] [Batch 474/637] [D loss: 0.137870] [G loss: 0.576250]\n",
      "[Epoch 13/200] [Batch 475/637] [D loss: 0.150823] [G loss: 0.550481]\n",
      "[Epoch 13/200] [Batch 476/637] [D loss: 0.162915] [G loss: 0.502363]\n",
      "[Epoch 13/200] [Batch 477/637] [D loss: 0.141684] [G loss: 0.525149]\n",
      "[Epoch 13/200] [Batch 478/637] [D loss: 0.141422] [G loss: 0.499787]\n",
      "[Epoch 13/200] [Batch 479/637] [D loss: 0.170126] [G loss: 0.479692]\n",
      "[Epoch 13/200] [Batch 480/637] [D loss: 0.143059] [G loss: 0.559648]\n",
      "[Epoch 13/200] [Batch 481/637] [D loss: 0.157427] [G loss: 0.504980]\n",
      "[Epoch 13/200] [Batch 482/637] [D loss: 0.164208] [G loss: 0.497314]\n",
      "[Epoch 13/200] [Batch 483/637] [D loss: 0.149527] [G loss: 0.556161]\n",
      "[Epoch 13/200] [Batch 484/637] [D loss: 0.161018] [G loss: 0.503602]\n",
      "[Epoch 13/200] [Batch 485/637] [D loss: 0.163491] [G loss: 0.571238]\n",
      "[Epoch 13/200] [Batch 486/637] [D loss: 0.164130] [G loss: 0.517726]\n",
      "[Epoch 13/200] [Batch 487/637] [D loss: 0.142832] [G loss: 0.567062]\n",
      "[Epoch 13/200] [Batch 488/637] [D loss: 0.208532] [G loss: 0.452268]\n",
      "[Epoch 13/200] [Batch 489/637] [D loss: 0.211695] [G loss: 0.580521]\n",
      "[Epoch 13/200] [Batch 490/637] [D loss: 0.159899] [G loss: 0.560699]\n",
      "[Epoch 13/200] [Batch 491/637] [D loss: 0.164258] [G loss: 0.496803]\n",
      "[Epoch 13/200] [Batch 492/637] [D loss: 0.146479] [G loss: 0.470124]\n",
      "[Epoch 13/200] [Batch 493/637] [D loss: 0.140949] [G loss: 0.558740]\n",
      "[Epoch 13/200] [Batch 494/637] [D loss: 0.152657] [G loss: 0.504152]\n",
      "[Epoch 13/200] [Batch 495/637] [D loss: 0.156713] [G loss: 0.537707]\n",
      "[Epoch 13/200] [Batch 496/637] [D loss: 0.148220] [G loss: 0.561426]\n",
      "[Epoch 13/200] [Batch 497/637] [D loss: 0.156785] [G loss: 0.540619]\n",
      "[Epoch 13/200] [Batch 498/637] [D loss: 0.162532] [G loss: 0.539491]\n",
      "[Epoch 13/200] [Batch 499/637] [D loss: 0.149666] [G loss: 0.526506]\n",
      "[Epoch 13/200] [Batch 500/637] [D loss: 0.165330] [G loss: 0.549558]\n",
      "[Epoch 13/200] [Batch 501/637] [D loss: 0.160197] [G loss: 0.562408]\n",
      "[Epoch 13/200] [Batch 502/637] [D loss: 0.164950] [G loss: 0.481626]\n",
      "[Epoch 13/200] [Batch 503/637] [D loss: 0.159456] [G loss: 0.555685]\n",
      "[Epoch 13/200] [Batch 504/637] [D loss: 0.146971] [G loss: 0.523508]\n",
      "[Epoch 13/200] [Batch 505/637] [D loss: 0.175115] [G loss: 0.521425]\n",
      "[Epoch 13/200] [Batch 506/637] [D loss: 0.158308] [G loss: 0.595934]\n",
      "[Epoch 13/200] [Batch 507/637] [D loss: 0.156305] [G loss: 0.488473]\n",
      "[Epoch 13/200] [Batch 508/637] [D loss: 0.179406] [G loss: 0.470741]\n",
      "[Epoch 13/200] [Batch 509/637] [D loss: 0.168798] [G loss: 0.509066]\n",
      "[Epoch 13/200] [Batch 510/637] [D loss: 0.151506] [G loss: 0.568082]\n",
      "[Epoch 13/200] [Batch 511/637] [D loss: 0.194477] [G loss: 0.619227]\n",
      "[Epoch 13/200] [Batch 512/637] [D loss: 0.141731] [G loss: 0.539253]\n",
      "[Epoch 13/200] [Batch 513/637] [D loss: 0.159321] [G loss: 0.448944]\n",
      "[Epoch 13/200] [Batch 514/637] [D loss: 0.161808] [G loss: 0.495931]\n",
      "[Epoch 13/200] [Batch 515/637] [D loss: 0.165477] [G loss: 0.538880]\n",
      "[Epoch 13/200] [Batch 516/637] [D loss: 0.149988] [G loss: 0.577600]\n",
      "[Epoch 13/200] [Batch 517/637] [D loss: 0.166837] [G loss: 0.516564]\n",
      "[Epoch 13/200] [Batch 518/637] [D loss: 0.164797] [G loss: 0.518136]\n",
      "[Epoch 13/200] [Batch 519/637] [D loss: 0.136284] [G loss: 0.579285]\n",
      "[Epoch 13/200] [Batch 520/637] [D loss: 0.147403] [G loss: 0.474674]\n",
      "[Epoch 13/200] [Batch 521/637] [D loss: 0.177059] [G loss: 0.452486]\n",
      "[Epoch 13/200] [Batch 522/637] [D loss: 0.169226] [G loss: 0.537572]\n",
      "[Epoch 13/200] [Batch 523/637] [D loss: 0.161512] [G loss: 0.546630]\n",
      "[Epoch 13/200] [Batch 524/637] [D loss: 0.209571] [G loss: 0.445568]\n",
      "[Epoch 13/200] [Batch 525/637] [D loss: 0.172354] [G loss: 0.614653]\n",
      "[Epoch 13/200] [Batch 526/637] [D loss: 0.171915] [G loss: 0.494803]\n",
      "[Epoch 13/200] [Batch 527/637] [D loss: 0.153946] [G loss: 0.490665]\n",
      "[Epoch 13/200] [Batch 528/637] [D loss: 0.153914] [G loss: 0.554090]\n",
      "[Epoch 13/200] [Batch 529/637] [D loss: 0.172912] [G loss: 0.483188]\n",
      "[Epoch 13/200] [Batch 530/637] [D loss: 0.153922] [G loss: 0.558692]\n",
      "[Epoch 13/200] [Batch 531/637] [D loss: 0.177474] [G loss: 0.495139]\n",
      "[Epoch 13/200] [Batch 532/637] [D loss: 0.176039] [G loss: 0.521807]\n",
      "[Epoch 13/200] [Batch 533/637] [D loss: 0.132223] [G loss: 0.566666]\n",
      "[Epoch 13/200] [Batch 534/637] [D loss: 0.174815] [G loss: 0.497207]\n",
      "[Epoch 13/200] [Batch 535/637] [D loss: 0.145310] [G loss: 0.549205]\n",
      "[Epoch 13/200] [Batch 536/637] [D loss: 0.144920] [G loss: 0.543640]\n",
      "[Epoch 13/200] [Batch 537/637] [D loss: 0.162650] [G loss: 0.537678]\n",
      "[Epoch 13/200] [Batch 538/637] [D loss: 0.154175] [G loss: 0.506608]\n",
      "[Epoch 13/200] [Batch 539/637] [D loss: 0.175033] [G loss: 0.516323]\n",
      "[Epoch 13/200] [Batch 540/637] [D loss: 0.170638] [G loss: 0.450831]\n",
      "[Epoch 13/200] [Batch 541/637] [D loss: 0.164422] [G loss: 0.462721]\n",
      "[Epoch 13/200] [Batch 542/637] [D loss: 0.157938] [G loss: 0.522034]\n",
      "[Epoch 13/200] [Batch 543/637] [D loss: 0.162007] [G loss: 0.483643]\n",
      "[Epoch 13/200] [Batch 544/637] [D loss: 0.173518] [G loss: 0.482577]\n",
      "[Epoch 13/200] [Batch 545/637] [D loss: 0.172440] [G loss: 0.460771]\n",
      "[Epoch 13/200] [Batch 546/637] [D loss: 0.157460] [G loss: 0.524683]\n",
      "[Epoch 13/200] [Batch 547/637] [D loss: 0.165936] [G loss: 0.536525]\n",
      "[Epoch 13/200] [Batch 548/637] [D loss: 0.158037] [G loss: 0.523626]\n",
      "[Epoch 13/200] [Batch 549/637] [D loss: 0.165939] [G loss: 0.466012]\n",
      "[Epoch 13/200] [Batch 550/637] [D loss: 0.149683] [G loss: 0.527403]\n",
      "[Epoch 13/200] [Batch 551/637] [D loss: 0.154360] [G loss: 0.598671]\n",
      "[Epoch 13/200] [Batch 552/637] [D loss: 0.150220] [G loss: 0.517470]\n",
      "[Epoch 13/200] [Batch 553/637] [D loss: 0.178265] [G loss: 0.467430]\n",
      "[Epoch 13/200] [Batch 554/637] [D loss: 0.165567] [G loss: 0.586087]\n",
      "[Epoch 13/200] [Batch 555/637] [D loss: 0.140861] [G loss: 0.556333]\n",
      "[Epoch 13/200] [Batch 556/637] [D loss: 0.158997] [G loss: 0.486573]\n",
      "[Epoch 13/200] [Batch 557/637] [D loss: 0.158277] [G loss: 0.507112]\n",
      "[Epoch 13/200] [Batch 558/637] [D loss: 0.160971] [G loss: 0.522685]\n",
      "[Epoch 13/200] [Batch 559/637] [D loss: 0.176267] [G loss: 0.553938]\n",
      "[Epoch 13/200] [Batch 560/637] [D loss: 0.177199] [G loss: 0.507751]\n",
      "[Epoch 13/200] [Batch 561/637] [D loss: 0.168646] [G loss: 0.511806]\n",
      "[Epoch 13/200] [Batch 562/637] [D loss: 0.158516] [G loss: 0.517962]\n",
      "[Epoch 13/200] [Batch 563/637] [D loss: 0.145553] [G loss: 0.576033]\n",
      "[Epoch 13/200] [Batch 564/637] [D loss: 0.136341] [G loss: 0.510554]\n",
      "[Epoch 13/200] [Batch 565/637] [D loss: 0.173731] [G loss: 0.421658]\n",
      "[Epoch 13/200] [Batch 566/637] [D loss: 0.131864] [G loss: 0.504100]\n",
      "[Epoch 13/200] [Batch 567/637] [D loss: 0.157962] [G loss: 0.480452]\n",
      "[Epoch 13/200] [Batch 568/637] [D loss: 0.158564] [G loss: 0.576416]\n",
      "[Epoch 13/200] [Batch 569/637] [D loss: 0.167107] [G loss: 0.490539]\n",
      "[Epoch 13/200] [Batch 570/637] [D loss: 0.169292] [G loss: 0.553429]\n",
      "[Epoch 13/200] [Batch 571/637] [D loss: 0.221347] [G loss: 0.452505]\n",
      "[Epoch 13/200] [Batch 572/637] [D loss: 0.191605] [G loss: 0.604142]\n",
      "[Epoch 13/200] [Batch 573/637] [D loss: 0.176383] [G loss: 0.518303]\n",
      "[Epoch 13/200] [Batch 574/637] [D loss: 0.177120] [G loss: 0.507686]\n",
      "[Epoch 13/200] [Batch 575/637] [D loss: 0.164290] [G loss: 0.535099]\n",
      "[Epoch 13/200] [Batch 576/637] [D loss: 0.164380] [G loss: 0.528323]\n",
      "[Epoch 13/200] [Batch 577/637] [D loss: 0.174145] [G loss: 0.461781]\n",
      "[Epoch 13/200] [Batch 578/637] [D loss: 0.157719] [G loss: 0.510588]\n",
      "[Epoch 13/200] [Batch 579/637] [D loss: 0.165683] [G loss: 0.523377]\n",
      "[Epoch 13/200] [Batch 580/637] [D loss: 0.167652] [G loss: 0.498059]\n",
      "[Epoch 13/200] [Batch 581/637] [D loss: 0.163429] [G loss: 0.490783]\n",
      "[Epoch 13/200] [Batch 582/637] [D loss: 0.164668] [G loss: 0.549726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 583/637] [D loss: 0.174144] [G loss: 0.489447]\n",
      "[Epoch 13/200] [Batch 584/637] [D loss: 0.166399] [G loss: 0.482872]\n",
      "[Epoch 13/200] [Batch 585/637] [D loss: 0.157497] [G loss: 0.554462]\n",
      "[Epoch 13/200] [Batch 586/637] [D loss: 0.131915] [G loss: 0.565313]\n",
      "[Epoch 13/200] [Batch 587/637] [D loss: 0.190829] [G loss: 0.443932]\n",
      "[Epoch 13/200] [Batch 588/637] [D loss: 0.166358] [G loss: 0.639400]\n",
      "[Epoch 13/200] [Batch 589/637] [D loss: 0.158117] [G loss: 0.528947]\n",
      "[Epoch 13/200] [Batch 590/637] [D loss: 0.168789] [G loss: 0.541980]\n",
      "[Epoch 13/200] [Batch 591/637] [D loss: 0.183276] [G loss: 0.427920]\n",
      "[Epoch 13/200] [Batch 592/637] [D loss: 0.162069] [G loss: 0.486105]\n",
      "[Epoch 13/200] [Batch 593/637] [D loss: 0.157003] [G loss: 0.526813]\n",
      "[Epoch 13/200] [Batch 594/637] [D loss: 0.163435] [G loss: 0.522492]\n",
      "[Epoch 13/200] [Batch 595/637] [D loss: 0.162672] [G loss: 0.488718]\n",
      "[Epoch 13/200] [Batch 596/637] [D loss: 0.177374] [G loss: 0.514896]\n",
      "[Epoch 13/200] [Batch 597/637] [D loss: 0.170687] [G loss: 0.467395]\n",
      "[Epoch 13/200] [Batch 598/637] [D loss: 0.160372] [G loss: 0.450144]\n",
      "[Epoch 13/200] [Batch 599/637] [D loss: 0.177915] [G loss: 0.485708]\n",
      "[Epoch 13/200] [Batch 600/637] [D loss: 0.146116] [G loss: 0.482590]\n",
      "[Epoch 13/200] [Batch 601/637] [D loss: 0.155575] [G loss: 0.599393]\n",
      "[Epoch 13/200] [Batch 602/637] [D loss: 0.146863] [G loss: 0.471223]\n",
      "[Epoch 13/200] [Batch 603/637] [D loss: 0.141225] [G loss: 0.607084]\n",
      "[Epoch 13/200] [Batch 604/637] [D loss: 0.146567] [G loss: 0.559603]\n",
      "[Epoch 13/200] [Batch 605/637] [D loss: 0.144986] [G loss: 0.486233]\n",
      "[Epoch 13/200] [Batch 606/637] [D loss: 0.131215] [G loss: 0.611096]\n",
      "[Epoch 13/200] [Batch 607/637] [D loss: 0.121450] [G loss: 0.666166]\n",
      "[Epoch 13/200] [Batch 608/637] [D loss: 0.151826] [G loss: 0.587384]\n",
      "[Epoch 13/200] [Batch 609/637] [D loss: 0.128497] [G loss: 0.659416]\n",
      "[Epoch 13/200] [Batch 610/637] [D loss: 0.138038] [G loss: 0.600440]\n",
      "[Epoch 13/200] [Batch 611/637] [D loss: 0.153537] [G loss: 0.503906]\n",
      "[Epoch 13/200] [Batch 612/637] [D loss: 0.155410] [G loss: 0.570923]\n",
      "[Epoch 13/200] [Batch 613/637] [D loss: 0.140386] [G loss: 0.547778]\n",
      "[Epoch 13/200] [Batch 614/637] [D loss: 0.160869] [G loss: 0.512759]\n",
      "[Epoch 13/200] [Batch 615/637] [D loss: 0.148573] [G loss: 0.535988]\n",
      "[Epoch 13/200] [Batch 616/637] [D loss: 0.142271] [G loss: 0.507907]\n",
      "[Epoch 13/200] [Batch 617/637] [D loss: 0.171322] [G loss: 0.506879]\n",
      "[Epoch 13/200] [Batch 618/637] [D loss: 0.166431] [G loss: 0.424943]\n",
      "[Epoch 13/200] [Batch 619/637] [D loss: 0.176543] [G loss: 0.416316]\n",
      "[Epoch 13/200] [Batch 620/637] [D loss: 0.157018] [G loss: 0.472910]\n",
      "[Epoch 13/200] [Batch 621/637] [D loss: 0.161839] [G loss: 0.506351]\n",
      "[Epoch 13/200] [Batch 622/637] [D loss: 0.208920] [G loss: 0.495471]\n",
      "[Epoch 13/200] [Batch 623/637] [D loss: 0.204133] [G loss: 0.538278]\n",
      "[Epoch 13/200] [Batch 624/637] [D loss: 0.172571] [G loss: 0.531163]\n",
      "[Epoch 13/200] [Batch 625/637] [D loss: 0.153700] [G loss: 0.496147]\n",
      "[Epoch 13/200] [Batch 626/637] [D loss: 0.169384] [G loss: 0.483640]\n",
      "[Epoch 13/200] [Batch 627/637] [D loss: 0.142763] [G loss: 0.450636]\n",
      "[Epoch 13/200] [Batch 628/637] [D loss: 0.160670] [G loss: 0.457480]\n",
      "[Epoch 13/200] [Batch 629/637] [D loss: 0.148427] [G loss: 0.563668]\n",
      "[Epoch 13/200] [Batch 630/637] [D loss: 0.157988] [G loss: 0.474193]\n",
      "[Epoch 13/200] [Batch 631/637] [D loss: 0.187418] [G loss: 0.495575]\n",
      "[Epoch 13/200] [Batch 632/637] [D loss: 0.155308] [G loss: 0.525529]\n",
      "[Epoch 13/200] [Batch 633/637] [D loss: 0.155968] [G loss: 0.576061]\n",
      "[Epoch 13/200] [Batch 634/637] [D loss: 0.150368] [G loss: 0.445573]\n",
      "[Epoch 13/200] [Batch 635/637] [D loss: 0.138581] [G loss: 0.512382]\n",
      "[Epoch 13/200] [Batch 636/637] [D loss: 0.157880] [G loss: 0.556120]\n",
      "[Epoch 14/200] [Batch 0/637] [D loss: 0.167551] [G loss: 0.535717]\n",
      "[Epoch 14/200] [Batch 1/637] [D loss: 0.153827] [G loss: 0.512777]\n",
      "[Epoch 14/200] [Batch 2/637] [D loss: 0.171043] [G loss: 0.547788]\n",
      "[Epoch 14/200] [Batch 3/637] [D loss: 0.173769] [G loss: 0.517075]\n",
      "[Epoch 14/200] [Batch 4/637] [D loss: 0.200514] [G loss: 0.370937]\n",
      "[Epoch 14/200] [Batch 5/637] [D loss: 0.169132] [G loss: 0.503716]\n",
      "[Epoch 14/200] [Batch 6/637] [D loss: 0.156290] [G loss: 0.525985]\n",
      "[Epoch 14/200] [Batch 7/637] [D loss: 0.166759] [G loss: 0.463502]\n",
      "[Epoch 14/200] [Batch 8/637] [D loss: 0.173503] [G loss: 0.424033]\n",
      "[Epoch 14/200] [Batch 9/637] [D loss: 0.175780] [G loss: 0.527553]\n",
      "[Epoch 14/200] [Batch 10/637] [D loss: 0.156183] [G loss: 0.476619]\n",
      "[Epoch 14/200] [Batch 11/637] [D loss: 0.158161] [G loss: 0.530115]\n",
      "[Epoch 14/200] [Batch 12/637] [D loss: 0.164902] [G loss: 0.534980]\n",
      "[Epoch 14/200] [Batch 13/637] [D loss: 0.157659] [G loss: 0.478340]\n",
      "[Epoch 14/200] [Batch 14/637] [D loss: 0.162779] [G loss: 0.513491]\n",
      "[Epoch 14/200] [Batch 15/637] [D loss: 0.157023] [G loss: 0.526549]\n",
      "[Epoch 14/200] [Batch 16/637] [D loss: 0.147117] [G loss: 0.450337]\n",
      "[Epoch 14/200] [Batch 17/637] [D loss: 0.138540] [G loss: 0.569039]\n",
      "[Epoch 14/200] [Batch 18/637] [D loss: 0.169412] [G loss: 0.539617]\n",
      "[Epoch 14/200] [Batch 19/637] [D loss: 0.154688] [G loss: 0.608228]\n",
      "[Epoch 14/200] [Batch 20/637] [D loss: 0.147121] [G loss: 0.584102]\n",
      "[Epoch 14/200] [Batch 21/637] [D loss: 0.157309] [G loss: 0.512700]\n",
      "[Epoch 14/200] [Batch 22/637] [D loss: 0.161995] [G loss: 0.591065]\n",
      "[Epoch 14/200] [Batch 23/637] [D loss: 0.161695] [G loss: 0.534119]\n",
      "[Epoch 14/200] [Batch 24/637] [D loss: 0.165142] [G loss: 0.477397]\n",
      "[Epoch 14/200] [Batch 25/637] [D loss: 0.142789] [G loss: 0.533808]\n",
      "[Epoch 14/200] [Batch 26/637] [D loss: 0.184631] [G loss: 0.487982]\n",
      "[Epoch 14/200] [Batch 27/637] [D loss: 0.133374] [G loss: 0.604050]\n",
      "[Epoch 14/200] [Batch 28/637] [D loss: 0.157496] [G loss: 0.653770]\n",
      "[Epoch 14/200] [Batch 29/637] [D loss: 0.155148] [G loss: 0.588023]\n",
      "[Epoch 14/200] [Batch 30/637] [D loss: 0.156285] [G loss: 0.470110]\n",
      "[Epoch 14/200] [Batch 31/637] [D loss: 0.161596] [G loss: 0.511132]\n",
      "[Epoch 14/200] [Batch 32/637] [D loss: 0.175747] [G loss: 0.635534]\n",
      "[Epoch 14/200] [Batch 33/637] [D loss: 0.158956] [G loss: 0.624113]\n",
      "[Epoch 14/200] [Batch 34/637] [D loss: 0.193738] [G loss: 0.478171]\n",
      "[Epoch 14/200] [Batch 35/637] [D loss: 0.171938] [G loss: 0.581180]\n",
      "[Epoch 14/200] [Batch 36/637] [D loss: 0.171724] [G loss: 0.542769]\n",
      "[Epoch 14/200] [Batch 37/637] [D loss: 0.143799] [G loss: 0.510284]\n",
      "[Epoch 14/200] [Batch 38/637] [D loss: 0.168539] [G loss: 0.434107]\n",
      "[Epoch 14/200] [Batch 39/637] [D loss: 0.170397] [G loss: 0.517242]\n",
      "[Epoch 14/200] [Batch 40/637] [D loss: 0.162751] [G loss: 0.502271]\n",
      "[Epoch 14/200] [Batch 41/637] [D loss: 0.150342] [G loss: 0.563976]\n",
      "[Epoch 14/200] [Batch 42/637] [D loss: 0.138179] [G loss: 0.544021]\n",
      "[Epoch 14/200] [Batch 43/637] [D loss: 0.155953] [G loss: 0.527981]\n",
      "[Epoch 14/200] [Batch 44/637] [D loss: 0.156057] [G loss: 0.495783]\n",
      "[Epoch 14/200] [Batch 45/637] [D loss: 0.193190] [G loss: 0.453061]\n",
      "[Epoch 14/200] [Batch 46/637] [D loss: 0.183758] [G loss: 0.604102]\n",
      "[Epoch 14/200] [Batch 47/637] [D loss: 0.153267] [G loss: 0.536037]\n",
      "[Epoch 14/200] [Batch 48/637] [D loss: 0.171062] [G loss: 0.490008]\n",
      "[Epoch 14/200] [Batch 49/637] [D loss: 0.179590] [G loss: 0.452465]\n",
      "[Epoch 14/200] [Batch 50/637] [D loss: 0.131027] [G loss: 0.503631]\n",
      "[Epoch 14/200] [Batch 51/637] [D loss: 0.167583] [G loss: 0.446979]\n",
      "[Epoch 14/200] [Batch 52/637] [D loss: 0.161977] [G loss: 0.538967]\n",
      "[Epoch 14/200] [Batch 53/637] [D loss: 0.156903] [G loss: 0.503696]\n",
      "[Epoch 14/200] [Batch 54/637] [D loss: 0.165942] [G loss: 0.504631]\n",
      "[Epoch 14/200] [Batch 55/637] [D loss: 0.155472] [G loss: 0.542672]\n",
      "[Epoch 14/200] [Batch 56/637] [D loss: 0.173881] [G loss: 0.533280]\n",
      "[Epoch 14/200] [Batch 57/637] [D loss: 0.153166] [G loss: 0.535063]\n",
      "[Epoch 14/200] [Batch 58/637] [D loss: 0.146369] [G loss: 0.476194]\n",
      "[Epoch 14/200] [Batch 59/637] [D loss: 0.149535] [G loss: 0.552107]\n",
      "[Epoch 14/200] [Batch 60/637] [D loss: 0.151875] [G loss: 0.508208]\n",
      "[Epoch 14/200] [Batch 61/637] [D loss: 0.171803] [G loss: 0.496074]\n",
      "[Epoch 14/200] [Batch 62/637] [D loss: 0.180361] [G loss: 0.543977]\n",
      "[Epoch 14/200] [Batch 63/637] [D loss: 0.168822] [G loss: 0.536073]\n",
      "[Epoch 14/200] [Batch 64/637] [D loss: 0.147701] [G loss: 0.613019]\n",
      "[Epoch 14/200] [Batch 65/637] [D loss: 0.154587] [G loss: 0.427138]\n",
      "[Epoch 14/200] [Batch 66/637] [D loss: 0.180633] [G loss: 0.463826]\n",
      "[Epoch 14/200] [Batch 67/637] [D loss: 0.169683] [G loss: 0.547820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 68/637] [D loss: 0.169031] [G loss: 0.519055]\n",
      "[Epoch 14/200] [Batch 69/637] [D loss: 0.150747] [G loss: 0.511947]\n",
      "[Epoch 14/200] [Batch 70/637] [D loss: 0.190562] [G loss: 0.422571]\n",
      "[Epoch 14/200] [Batch 71/637] [D loss: 0.161427] [G loss: 0.468168]\n",
      "[Epoch 14/200] [Batch 72/637] [D loss: 0.149078] [G loss: 0.517077]\n",
      "[Epoch 14/200] [Batch 73/637] [D loss: 0.177535] [G loss: 0.508245]\n",
      "[Epoch 14/200] [Batch 74/637] [D loss: 0.176273] [G loss: 0.590624]\n",
      "[Epoch 14/200] [Batch 75/637] [D loss: 0.160922] [G loss: 0.529675]\n",
      "[Epoch 14/200] [Batch 76/637] [D loss: 0.135897] [G loss: 0.536382]\n",
      "[Epoch 14/200] [Batch 77/637] [D loss: 0.161751] [G loss: 0.521655]\n",
      "[Epoch 14/200] [Batch 78/637] [D loss: 0.137824] [G loss: 0.564298]\n",
      "[Epoch 14/200] [Batch 79/637] [D loss: 0.155405] [G loss: 0.541724]\n",
      "[Epoch 14/200] [Batch 80/637] [D loss: 0.150501] [G loss: 0.569963]\n",
      "[Epoch 14/200] [Batch 81/637] [D loss: 0.131902] [G loss: 0.476160]\n",
      "[Epoch 14/200] [Batch 82/637] [D loss: 0.139925] [G loss: 0.533353]\n",
      "[Epoch 14/200] [Batch 83/637] [D loss: 0.146141] [G loss: 0.615600]\n",
      "[Epoch 14/200] [Batch 84/637] [D loss: 0.145315] [G loss: 0.560938]\n",
      "[Epoch 14/200] [Batch 85/637] [D loss: 0.127052] [G loss: 0.581032]\n",
      "[Epoch 14/200] [Batch 86/637] [D loss: 0.143220] [G loss: 0.587908]\n",
      "[Epoch 14/200] [Batch 87/637] [D loss: 0.133003] [G loss: 0.556074]\n",
      "[Epoch 14/200] [Batch 88/637] [D loss: 0.172209] [G loss: 0.514654]\n",
      "[Epoch 14/200] [Batch 89/637] [D loss: 0.155002] [G loss: 0.598607]\n",
      "[Epoch 14/200] [Batch 90/637] [D loss: 0.165371] [G loss: 0.535876]\n",
      "[Epoch 14/200] [Batch 91/637] [D loss: 0.160227] [G loss: 0.514902]\n",
      "[Epoch 14/200] [Batch 92/637] [D loss: 0.162127] [G loss: 0.556137]\n",
      "[Epoch 14/200] [Batch 93/637] [D loss: 0.173115] [G loss: 0.496136]\n",
      "[Epoch 14/200] [Batch 94/637] [D loss: 0.145733] [G loss: 0.531433]\n",
      "[Epoch 14/200] [Batch 95/637] [D loss: 0.161306] [G loss: 0.456826]\n",
      "[Epoch 14/200] [Batch 96/637] [D loss: 0.164970] [G loss: 0.496992]\n",
      "[Epoch 14/200] [Batch 97/637] [D loss: 0.147817] [G loss: 0.515904]\n",
      "[Epoch 14/200] [Batch 98/637] [D loss: 0.146237] [G loss: 0.544542]\n",
      "[Epoch 14/200] [Batch 99/637] [D loss: 0.142333] [G loss: 0.517448]\n",
      "[Epoch 14/200] [Batch 100/637] [D loss: 0.164356] [G loss: 0.479814]\n",
      "[Epoch 14/200] [Batch 101/637] [D loss: 0.134713] [G loss: 0.529654]\n",
      "[Epoch 14/200] [Batch 102/637] [D loss: 0.164486] [G loss: 0.564604]\n",
      "[Epoch 14/200] [Batch 103/637] [D loss: 0.163723] [G loss: 0.561992]\n",
      "[Epoch 14/200] [Batch 104/637] [D loss: 0.168675] [G loss: 0.436318]\n",
      "[Epoch 14/200] [Batch 105/637] [D loss: 0.165219] [G loss: 0.502518]\n",
      "[Epoch 14/200] [Batch 106/637] [D loss: 0.153520] [G loss: 0.583740]\n",
      "[Epoch 14/200] [Batch 107/637] [D loss: 0.165930] [G loss: 0.544236]\n",
      "[Epoch 14/200] [Batch 108/637] [D loss: 0.156774] [G loss: 0.500376]\n",
      "[Epoch 14/200] [Batch 109/637] [D loss: 0.145221] [G loss: 0.495368]\n",
      "[Epoch 14/200] [Batch 110/637] [D loss: 0.140862] [G loss: 0.631282]\n",
      "[Epoch 14/200] [Batch 111/637] [D loss: 0.159335] [G loss: 0.557500]\n",
      "[Epoch 14/200] [Batch 112/637] [D loss: 0.154303] [G loss: 0.530696]\n",
      "[Epoch 14/200] [Batch 113/637] [D loss: 0.152359] [G loss: 0.582631]\n",
      "[Epoch 14/200] [Batch 114/637] [D loss: 0.153595] [G loss: 0.477148]\n",
      "[Epoch 14/200] [Batch 115/637] [D loss: 0.165779] [G loss: 0.477102]\n",
      "[Epoch 14/200] [Batch 116/637] [D loss: 0.169335] [G loss: 0.749085]\n",
      "[Epoch 14/200] [Batch 117/637] [D loss: 0.171400] [G loss: 0.542509]\n",
      "[Epoch 14/200] [Batch 118/637] [D loss: 0.171771] [G loss: 0.474899]\n",
      "[Epoch 14/200] [Batch 119/637] [D loss: 0.171965] [G loss: 0.429761]\n",
      "[Epoch 14/200] [Batch 120/637] [D loss: 0.166095] [G loss: 0.502403]\n",
      "[Epoch 14/200] [Batch 121/637] [D loss: 0.173534] [G loss: 0.456980]\n",
      "[Epoch 14/200] [Batch 122/637] [D loss: 0.151746] [G loss: 0.505738]\n",
      "[Epoch 14/200] [Batch 123/637] [D loss: 0.155433] [G loss: 0.510608]\n",
      "[Epoch 14/200] [Batch 124/637] [D loss: 0.149488] [G loss: 0.554439]\n",
      "[Epoch 14/200] [Batch 125/637] [D loss: 0.148699] [G loss: 0.479430]\n",
      "[Epoch 14/200] [Batch 126/637] [D loss: 0.133939] [G loss: 0.511429]\n",
      "[Epoch 14/200] [Batch 127/637] [D loss: 0.154741] [G loss: 0.518621]\n",
      "[Epoch 14/200] [Batch 128/637] [D loss: 0.181459] [G loss: 0.654255]\n",
      "[Epoch 14/200] [Batch 129/637] [D loss: 0.180851] [G loss: 0.572438]\n",
      "[Epoch 14/200] [Batch 130/637] [D loss: 0.157503] [G loss: 0.531320]\n",
      "[Epoch 14/200] [Batch 131/637] [D loss: 0.164131] [G loss: 0.497854]\n",
      "[Epoch 14/200] [Batch 132/637] [D loss: 0.148375] [G loss: 0.463898]\n",
      "[Epoch 14/200] [Batch 133/637] [D loss: 0.145767] [G loss: 0.490022]\n",
      "[Epoch 14/200] [Batch 134/637] [D loss: 0.167960] [G loss: 0.488031]\n",
      "[Epoch 14/200] [Batch 135/637] [D loss: 0.160906] [G loss: 0.551771]\n",
      "[Epoch 14/200] [Batch 136/637] [D loss: 0.152697] [G loss: 0.496268]\n",
      "[Epoch 14/200] [Batch 137/637] [D loss: 0.148343] [G loss: 0.538560]\n",
      "[Epoch 14/200] [Batch 138/637] [D loss: 0.147210] [G loss: 0.528218]\n",
      "[Epoch 14/200] [Batch 139/637] [D loss: 0.148439] [G loss: 0.563631]\n",
      "[Epoch 14/200] [Batch 140/637] [D loss: 0.171291] [G loss: 0.512228]\n",
      "[Epoch 14/200] [Batch 141/637] [D loss: 0.178718] [G loss: 0.413555]\n",
      "[Epoch 14/200] [Batch 142/637] [D loss: 0.156432] [G loss: 0.574021]\n",
      "[Epoch 14/200] [Batch 143/637] [D loss: 0.146048] [G loss: 0.519582]\n",
      "[Epoch 14/200] [Batch 144/637] [D loss: 0.135278] [G loss: 0.502585]\n",
      "[Epoch 14/200] [Batch 145/637] [D loss: 0.163585] [G loss: 0.460400]\n",
      "[Epoch 14/200] [Batch 146/637] [D loss: 0.158454] [G loss: 0.510161]\n",
      "[Epoch 14/200] [Batch 147/637] [D loss: 0.164186] [G loss: 0.480101]\n",
      "[Epoch 14/200] [Batch 148/637] [D loss: 0.166350] [G loss: 0.484237]\n",
      "[Epoch 14/200] [Batch 149/637] [D loss: 0.199524] [G loss: 0.428997]\n",
      "[Epoch 14/200] [Batch 150/637] [D loss: 0.159583] [G loss: 0.510868]\n",
      "[Epoch 14/200] [Batch 151/637] [D loss: 0.165669] [G loss: 0.473877]\n",
      "[Epoch 14/200] [Batch 152/637] [D loss: 0.207342] [G loss: 0.621221]\n",
      "[Epoch 14/200] [Batch 153/637] [D loss: 0.157773] [G loss: 0.522892]\n",
      "[Epoch 14/200] [Batch 154/637] [D loss: 0.168297] [G loss: 0.480230]\n",
      "[Epoch 14/200] [Batch 155/637] [D loss: 0.157593] [G loss: 0.473050]\n",
      "[Epoch 14/200] [Batch 156/637] [D loss: 0.150791] [G loss: 0.485611]\n",
      "[Epoch 14/200] [Batch 157/637] [D loss: 0.145970] [G loss: 0.539920]\n",
      "[Epoch 14/200] [Batch 158/637] [D loss: 0.138536] [G loss: 0.536605]\n",
      "[Epoch 14/200] [Batch 159/637] [D loss: 0.153817] [G loss: 0.534591]\n",
      "[Epoch 14/200] [Batch 160/637] [D loss: 0.152017] [G loss: 0.501873]\n",
      "[Epoch 14/200] [Batch 161/637] [D loss: 0.147790] [G loss: 0.514502]\n",
      "[Epoch 14/200] [Batch 162/637] [D loss: 0.137121] [G loss: 0.507804]\n",
      "[Epoch 14/200] [Batch 163/637] [D loss: 0.145505] [G loss: 0.590360]\n",
      "[Epoch 14/200] [Batch 164/637] [D loss: 0.181835] [G loss: 0.471735]\n",
      "[Epoch 14/200] [Batch 165/637] [D loss: 0.161465] [G loss: 0.506551]\n",
      "[Epoch 14/200] [Batch 166/637] [D loss: 0.148937] [G loss: 0.574873]\n",
      "[Epoch 14/200] [Batch 167/637] [D loss: 0.157019] [G loss: 0.496448]\n",
      "[Epoch 14/200] [Batch 168/637] [D loss: 0.164988] [G loss: 0.479364]\n",
      "[Epoch 14/200] [Batch 169/637] [D loss: 0.172061] [G loss: 0.565432]\n",
      "[Epoch 14/200] [Batch 170/637] [D loss: 0.158774] [G loss: 0.538873]\n",
      "[Epoch 14/200] [Batch 171/637] [D loss: 0.183033] [G loss: 0.569202]\n",
      "[Epoch 14/200] [Batch 172/637] [D loss: 0.163224] [G loss: 0.478322]\n",
      "[Epoch 14/200] [Batch 173/637] [D loss: 0.183183] [G loss: 0.430886]\n",
      "[Epoch 14/200] [Batch 174/637] [D loss: 0.177479] [G loss: 0.489600]\n",
      "[Epoch 14/200] [Batch 175/637] [D loss: 0.159663] [G loss: 0.541816]\n",
      "[Epoch 14/200] [Batch 176/637] [D loss: 0.185174] [G loss: 0.531435]\n",
      "[Epoch 14/200] [Batch 177/637] [D loss: 0.171409] [G loss: 0.489146]\n",
      "[Epoch 14/200] [Batch 178/637] [D loss: 0.171138] [G loss: 0.558369]\n",
      "[Epoch 14/200] [Batch 179/637] [D loss: 0.153043] [G loss: 0.495085]\n",
      "[Epoch 14/200] [Batch 180/637] [D loss: 0.183209] [G loss: 0.432948]\n",
      "[Epoch 14/200] [Batch 181/637] [D loss: 0.162700] [G loss: 0.483482]\n",
      "[Epoch 14/200] [Batch 182/637] [D loss: 0.176393] [G loss: 0.484244]\n",
      "[Epoch 14/200] [Batch 183/637] [D loss: 0.187609] [G loss: 0.438669]\n",
      "[Epoch 14/200] [Batch 184/637] [D loss: 0.171751] [G loss: 0.540829]\n",
      "[Epoch 14/200] [Batch 185/637] [D loss: 0.165309] [G loss: 0.507850]\n",
      "[Epoch 14/200] [Batch 186/637] [D loss: 0.149252] [G loss: 0.498961]\n",
      "[Epoch 14/200] [Batch 187/637] [D loss: 0.158217] [G loss: 0.469166]\n",
      "[Epoch 14/200] [Batch 188/637] [D loss: 0.154393] [G loss: 0.506224]\n",
      "[Epoch 14/200] [Batch 189/637] [D loss: 0.129780] [G loss: 0.526679]\n",
      "[Epoch 14/200] [Batch 190/637] [D loss: 0.162760] [G loss: 0.468921]\n",
      "[Epoch 14/200] [Batch 191/637] [D loss: 0.143763] [G loss: 0.548064]\n",
      "[Epoch 14/200] [Batch 192/637] [D loss: 0.150818] [G loss: 0.479502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 193/637] [D loss: 0.158058] [G loss: 0.519984]\n",
      "[Epoch 14/200] [Batch 194/637] [D loss: 0.158459] [G loss: 0.509620]\n",
      "[Epoch 14/200] [Batch 195/637] [D loss: 0.156941] [G loss: 0.509650]\n",
      "[Epoch 14/200] [Batch 196/637] [D loss: 0.158752] [G loss: 0.519126]\n",
      "[Epoch 14/200] [Batch 197/637] [D loss: 0.170712] [G loss: 0.601550]\n",
      "[Epoch 14/200] [Batch 198/637] [D loss: 0.180601] [G loss: 0.536388]\n",
      "[Epoch 14/200] [Batch 199/637] [D loss: 0.178358] [G loss: 0.519291]\n",
      "[Epoch 14/200] [Batch 200/637] [D loss: 0.163176] [G loss: 0.435494]\n",
      "[Epoch 14/200] [Batch 201/637] [D loss: 0.156784] [G loss: 0.450055]\n",
      "[Epoch 14/200] [Batch 202/637] [D loss: 0.124287] [G loss: 0.530418]\n",
      "[Epoch 14/200] [Batch 203/637] [D loss: 0.142533] [G loss: 0.535371]\n",
      "[Epoch 14/200] [Batch 204/637] [D loss: 0.151608] [G loss: 0.555590]\n",
      "[Epoch 14/200] [Batch 205/637] [D loss: 0.149087] [G loss: 0.526664]\n",
      "[Epoch 14/200] [Batch 206/637] [D loss: 0.174572] [G loss: 0.488935]\n",
      "[Epoch 14/200] [Batch 207/637] [D loss: 0.164712] [G loss: 0.473908]\n",
      "[Epoch 14/200] [Batch 208/637] [D loss: 0.156786] [G loss: 0.586371]\n",
      "[Epoch 14/200] [Batch 209/637] [D loss: 0.147821] [G loss: 0.562960]\n",
      "[Epoch 14/200] [Batch 210/637] [D loss: 0.157219] [G loss: 0.499780]\n",
      "[Epoch 14/200] [Batch 211/637] [D loss: 0.145573] [G loss: 0.525343]\n",
      "[Epoch 14/200] [Batch 212/637] [D loss: 0.162952] [G loss: 0.487060]\n",
      "[Epoch 14/200] [Batch 213/637] [D loss: 0.164401] [G loss: 0.492186]\n",
      "[Epoch 14/200] [Batch 214/637] [D loss: 0.164180] [G loss: 0.539367]\n",
      "[Epoch 14/200] [Batch 215/637] [D loss: 0.132085] [G loss: 0.514099]\n",
      "[Epoch 14/200] [Batch 216/637] [D loss: 0.151781] [G loss: 0.588241]\n",
      "[Epoch 14/200] [Batch 217/637] [D loss: 0.163679] [G loss: 0.507552]\n",
      "[Epoch 14/200] [Batch 218/637] [D loss: 0.163824] [G loss: 0.506211]\n",
      "[Epoch 14/200] [Batch 219/637] [D loss: 0.155823] [G loss: 0.563871]\n",
      "[Epoch 14/200] [Batch 220/637] [D loss: 0.142864] [G loss: 0.527077]\n",
      "[Epoch 14/200] [Batch 221/637] [D loss: 0.149746] [G loss: 0.448001]\n",
      "[Epoch 14/200] [Batch 222/637] [D loss: 0.171367] [G loss: 0.505675]\n",
      "[Epoch 14/200] [Batch 223/637] [D loss: 0.158253] [G loss: 0.520643]\n",
      "[Epoch 14/200] [Batch 224/637] [D loss: 0.175469] [G loss: 0.447786]\n",
      "[Epoch 14/200] [Batch 225/637] [D loss: 0.149424] [G loss: 0.538969]\n",
      "[Epoch 14/200] [Batch 226/637] [D loss: 0.165696] [G loss: 0.562583]\n",
      "[Epoch 14/200] [Batch 227/637] [D loss: 0.168248] [G loss: 0.494001]\n",
      "[Epoch 14/200] [Batch 228/637] [D loss: 0.139260] [G loss: 0.491789]\n",
      "[Epoch 14/200] [Batch 229/637] [D loss: 0.159288] [G loss: 0.504694]\n",
      "[Epoch 14/200] [Batch 230/637] [D loss: 0.184840] [G loss: 0.523396]\n",
      "[Epoch 14/200] [Batch 231/637] [D loss: 0.171556] [G loss: 0.639365]\n",
      "[Epoch 14/200] [Batch 232/637] [D loss: 0.148461] [G loss: 0.552878]\n",
      "[Epoch 14/200] [Batch 233/637] [D loss: 0.181603] [G loss: 0.386440]\n",
      "[Epoch 14/200] [Batch 234/637] [D loss: 0.166313] [G loss: 0.444633]\n",
      "[Epoch 14/200] [Batch 235/637] [D loss: 0.157905] [G loss: 0.523413]\n",
      "[Epoch 14/200] [Batch 236/637] [D loss: 0.150074] [G loss: 0.526246]\n",
      "[Epoch 14/200] [Batch 237/637] [D loss: 0.173158] [G loss: 0.417816]\n",
      "[Epoch 14/200] [Batch 238/637] [D loss: 0.153319] [G loss: 0.543149]\n",
      "[Epoch 14/200] [Batch 239/637] [D loss: 0.146745] [G loss: 0.528162]\n",
      "[Epoch 14/200] [Batch 240/637] [D loss: 0.150890] [G loss: 0.486688]\n",
      "[Epoch 14/200] [Batch 241/637] [D loss: 0.161973] [G loss: 0.479962]\n",
      "[Epoch 14/200] [Batch 242/637] [D loss: 0.149287] [G loss: 0.509343]\n",
      "[Epoch 14/200] [Batch 243/637] [D loss: 0.124707] [G loss: 0.592205]\n",
      "[Epoch 14/200] [Batch 244/637] [D loss: 0.157760] [G loss: 0.536320]\n",
      "[Epoch 14/200] [Batch 245/637] [D loss: 0.158203] [G loss: 0.554370]\n",
      "[Epoch 14/200] [Batch 246/637] [D loss: 0.130418] [G loss: 0.530859]\n",
      "[Epoch 14/200] [Batch 247/637] [D loss: 0.160001] [G loss: 0.526082]\n",
      "[Epoch 14/200] [Batch 248/637] [D loss: 0.148099] [G loss: 0.535185]\n",
      "[Epoch 14/200] [Batch 249/637] [D loss: 0.146226] [G loss: 0.504291]\n",
      "[Epoch 14/200] [Batch 250/637] [D loss: 0.168424] [G loss: 0.502495]\n",
      "[Epoch 14/200] [Batch 251/637] [D loss: 0.147881] [G loss: 0.536924]\n",
      "[Epoch 14/200] [Batch 252/637] [D loss: 0.145546] [G loss: 0.493213]\n",
      "[Epoch 14/200] [Batch 253/637] [D loss: 0.149445] [G loss: 0.441886]\n",
      "[Epoch 14/200] [Batch 254/637] [D loss: 0.149265] [G loss: 0.504745]\n",
      "[Epoch 14/200] [Batch 255/637] [D loss: 0.173149] [G loss: 0.415284]\n",
      "[Epoch 14/200] [Batch 256/637] [D loss: 0.141744] [G loss: 0.547992]\n",
      "[Epoch 14/200] [Batch 257/637] [D loss: 0.136536] [G loss: 0.514462]\n",
      "[Epoch 14/200] [Batch 258/637] [D loss: 0.148679] [G loss: 0.514020]\n",
      "[Epoch 14/200] [Batch 259/637] [D loss: 0.148288] [G loss: 0.465170]\n",
      "[Epoch 14/200] [Batch 260/637] [D loss: 0.136290] [G loss: 0.560921]\n",
      "[Epoch 14/200] [Batch 261/637] [D loss: 0.172030] [G loss: 0.490169]\n",
      "[Epoch 14/200] [Batch 262/637] [D loss: 0.157584] [G loss: 0.526756]\n",
      "[Epoch 14/200] [Batch 263/637] [D loss: 0.149157] [G loss: 0.523796]\n",
      "[Epoch 14/200] [Batch 264/637] [D loss: 0.157752] [G loss: 0.569446]\n",
      "[Epoch 14/200] [Batch 265/637] [D loss: 0.156892] [G loss: 0.521550]\n",
      "[Epoch 14/200] [Batch 266/637] [D loss: 0.148111] [G loss: 0.449673]\n",
      "[Epoch 14/200] [Batch 267/637] [D loss: 0.153448] [G loss: 0.442052]\n",
      "[Epoch 14/200] [Batch 268/637] [D loss: 0.146293] [G loss: 0.571765]\n",
      "[Epoch 14/200] [Batch 269/637] [D loss: 0.167611] [G loss: 0.560144]\n",
      "[Epoch 14/200] [Batch 270/637] [D loss: 0.147159] [G loss: 0.610911]\n",
      "[Epoch 14/200] [Batch 271/637] [D loss: 0.147705] [G loss: 0.530738]\n",
      "[Epoch 14/200] [Batch 272/637] [D loss: 0.164835] [G loss: 0.558808]\n",
      "[Epoch 14/200] [Batch 273/637] [D loss: 0.160084] [G loss: 0.573485]\n",
      "[Epoch 14/200] [Batch 274/637] [D loss: 0.154396] [G loss: 0.527379]\n",
      "[Epoch 14/200] [Batch 275/637] [D loss: 0.161921] [G loss: 0.504902]\n",
      "[Epoch 14/200] [Batch 276/637] [D loss: 0.125002] [G loss: 0.580323]\n",
      "[Epoch 14/200] [Batch 277/637] [D loss: 0.150189] [G loss: 0.518833]\n",
      "[Epoch 14/200] [Batch 278/637] [D loss: 0.170924] [G loss: 0.469766]\n",
      "[Epoch 14/200] [Batch 279/637] [D loss: 0.152458] [G loss: 0.534460]\n",
      "[Epoch 14/200] [Batch 280/637] [D loss: 0.153424] [G loss: 0.514428]\n",
      "[Epoch 14/200] [Batch 281/637] [D loss: 0.171987] [G loss: 0.530003]\n",
      "[Epoch 14/200] [Batch 282/637] [D loss: 0.163584] [G loss: 0.553705]\n",
      "[Epoch 14/200] [Batch 283/637] [D loss: 0.177058] [G loss: 0.510848]\n",
      "[Epoch 14/200] [Batch 284/637] [D loss: 0.154318] [G loss: 0.575894]\n",
      "[Epoch 14/200] [Batch 285/637] [D loss: 0.185617] [G loss: 0.483811]\n",
      "[Epoch 14/200] [Batch 286/637] [D loss: 0.158344] [G loss: 0.552361]\n",
      "[Epoch 14/200] [Batch 287/637] [D loss: 0.170916] [G loss: 0.562861]\n",
      "[Epoch 14/200] [Batch 288/637] [D loss: 0.172787] [G loss: 0.555229]\n",
      "[Epoch 14/200] [Batch 289/637] [D loss: 0.150226] [G loss: 0.531035]\n",
      "[Epoch 14/200] [Batch 290/637] [D loss: 0.158426] [G loss: 0.579131]\n",
      "[Epoch 14/200] [Batch 291/637] [D loss: 0.142372] [G loss: 0.589015]\n",
      "[Epoch 14/200] [Batch 292/637] [D loss: 0.169338] [G loss: 0.568172]\n",
      "[Epoch 14/200] [Batch 293/637] [D loss: 0.143163] [G loss: 0.547392]\n",
      "[Epoch 14/200] [Batch 294/637] [D loss: 0.164553] [G loss: 0.518499]\n",
      "[Epoch 14/200] [Batch 295/637] [D loss: 0.133007] [G loss: 0.668912]\n",
      "[Epoch 14/200] [Batch 296/637] [D loss: 0.157623] [G loss: 0.538257]\n",
      "[Epoch 14/200] [Batch 297/637] [D loss: 0.161797] [G loss: 0.449918]\n",
      "[Epoch 14/200] [Batch 298/637] [D loss: 0.173751] [G loss: 0.605787]\n",
      "[Epoch 14/200] [Batch 299/637] [D loss: 0.158764] [G loss: 0.501640]\n",
      "[Epoch 14/200] [Batch 300/637] [D loss: 0.144794] [G loss: 0.554198]\n",
      "[Epoch 14/200] [Batch 301/637] [D loss: 0.159544] [G loss: 0.471070]\n",
      "[Epoch 14/200] [Batch 302/637] [D loss: 0.141676] [G loss: 0.657588]\n",
      "[Epoch 14/200] [Batch 303/637] [D loss: 0.164415] [G loss: 0.579787]\n",
      "[Epoch 14/200] [Batch 304/637] [D loss: 0.162876] [G loss: 0.496085]\n",
      "[Epoch 14/200] [Batch 305/637] [D loss: 0.139292] [G loss: 0.541801]\n",
      "[Epoch 14/200] [Batch 306/637] [D loss: 0.177760] [G loss: 0.500319]\n",
      "[Epoch 14/200] [Batch 307/637] [D loss: 0.172162] [G loss: 0.577273]\n",
      "[Epoch 14/200] [Batch 308/637] [D loss: 0.159858] [G loss: 0.550037]\n",
      "[Epoch 14/200] [Batch 309/637] [D loss: 0.176370] [G loss: 0.503052]\n",
      "[Epoch 14/200] [Batch 310/637] [D loss: 0.167952] [G loss: 0.626194]\n",
      "[Epoch 14/200] [Batch 311/637] [D loss: 0.174230] [G loss: 0.491872]\n",
      "[Epoch 14/200] [Batch 312/637] [D loss: 0.162631] [G loss: 0.453092]\n",
      "[Epoch 14/200] [Batch 313/637] [D loss: 0.157399] [G loss: 0.479300]\n",
      "[Epoch 14/200] [Batch 314/637] [D loss: 0.158527] [G loss: 0.482621]\n",
      "[Epoch 14/200] [Batch 315/637] [D loss: 0.143188] [G loss: 0.485782]\n",
      "[Epoch 14/200] [Batch 316/637] [D loss: 0.156159] [G loss: 0.569859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 317/637] [D loss: 0.159694] [G loss: 0.595055]\n",
      "[Epoch 14/200] [Batch 318/637] [D loss: 0.157305] [G loss: 0.555744]\n",
      "[Epoch 14/200] [Batch 319/637] [D loss: 0.142673] [G loss: 0.529502]\n",
      "[Epoch 14/200] [Batch 320/637] [D loss: 0.171176] [G loss: 0.504688]\n",
      "[Epoch 14/200] [Batch 321/637] [D loss: 0.166512] [G loss: 0.522421]\n",
      "[Epoch 14/200] [Batch 322/637] [D loss: 0.162470] [G loss: 0.544408]\n",
      "[Epoch 14/200] [Batch 323/637] [D loss: 0.144901] [G loss: 0.562819]\n",
      "[Epoch 14/200] [Batch 324/637] [D loss: 0.204351] [G loss: 0.463860]\n",
      "[Epoch 14/200] [Batch 325/637] [D loss: 0.185702] [G loss: 0.497039]\n",
      "[Epoch 14/200] [Batch 326/637] [D loss: 0.182390] [G loss: 0.481241]\n",
      "[Epoch 14/200] [Batch 327/637] [D loss: 0.159238] [G loss: 0.598997]\n",
      "[Epoch 14/200] [Batch 328/637] [D loss: 0.165434] [G loss: 0.563941]\n",
      "[Epoch 14/200] [Batch 329/637] [D loss: 0.146982] [G loss: 0.519348]\n",
      "[Epoch 14/200] [Batch 330/637] [D loss: 0.156483] [G loss: 0.503837]\n",
      "[Epoch 14/200] [Batch 331/637] [D loss: 0.165268] [G loss: 0.468519]\n",
      "[Epoch 14/200] [Batch 332/637] [D loss: 0.169151] [G loss: 0.455728]\n",
      "[Epoch 14/200] [Batch 333/637] [D loss: 0.169521] [G loss: 0.498159]\n",
      "[Epoch 14/200] [Batch 334/637] [D loss: 0.154811] [G loss: 0.549686]\n",
      "[Epoch 14/200] [Batch 335/637] [D loss: 0.160983] [G loss: 0.564623]\n",
      "[Epoch 14/200] [Batch 336/637] [D loss: 0.159812] [G loss: 0.587388]\n",
      "[Epoch 14/200] [Batch 337/637] [D loss: 0.135872] [G loss: 0.519711]\n",
      "[Epoch 14/200] [Batch 338/637] [D loss: 0.162173] [G loss: 0.482056]\n",
      "[Epoch 14/200] [Batch 339/637] [D loss: 0.177163] [G loss: 0.458722]\n",
      "[Epoch 14/200] [Batch 340/637] [D loss: 0.163329] [G loss: 0.626200]\n",
      "[Epoch 14/200] [Batch 341/637] [D loss: 0.162987] [G loss: 0.595563]\n",
      "[Epoch 14/200] [Batch 342/637] [D loss: 0.132645] [G loss: 0.531959]\n",
      "[Epoch 14/200] [Batch 343/637] [D loss: 0.150114] [G loss: 0.451347]\n",
      "[Epoch 14/200] [Batch 344/637] [D loss: 0.160697] [G loss: 0.475532]\n",
      "[Epoch 14/200] [Batch 345/637] [D loss: 0.133626] [G loss: 0.596812]\n",
      "[Epoch 14/200] [Batch 346/637] [D loss: 0.155245] [G loss: 0.514321]\n",
      "[Epoch 14/200] [Batch 347/637] [D loss: 0.144548] [G loss: 0.580235]\n",
      "[Epoch 14/200] [Batch 348/637] [D loss: 0.148545] [G loss: 0.505889]\n",
      "[Epoch 14/200] [Batch 349/637] [D loss: 0.167220] [G loss: 0.435778]\n",
      "[Epoch 14/200] [Batch 350/637] [D loss: 0.150519] [G loss: 0.552510]\n",
      "[Epoch 14/200] [Batch 351/637] [D loss: 0.126724] [G loss: 0.605124]\n",
      "[Epoch 14/200] [Batch 352/637] [D loss: 0.154683] [G loss: 0.522600]\n",
      "[Epoch 14/200] [Batch 353/637] [D loss: 0.144520] [G loss: 0.564469]\n",
      "[Epoch 14/200] [Batch 354/637] [D loss: 0.161335] [G loss: 0.550035]\n",
      "[Epoch 14/200] [Batch 355/637] [D loss: 0.182151] [G loss: 0.503202]\n",
      "[Epoch 14/200] [Batch 356/637] [D loss: 0.179619] [G loss: 0.486548]\n",
      "[Epoch 14/200] [Batch 357/637] [D loss: 0.149294] [G loss: 0.516550]\n",
      "[Epoch 14/200] [Batch 358/637] [D loss: 0.160943] [G loss: 0.501764]\n",
      "[Epoch 14/200] [Batch 359/637] [D loss: 0.151529] [G loss: 0.471542]\n",
      "[Epoch 14/200] [Batch 360/637] [D loss: 0.172380] [G loss: 0.446162]\n",
      "[Epoch 14/200] [Batch 361/637] [D loss: 0.184362] [G loss: 0.578761]\n",
      "[Epoch 14/200] [Batch 362/637] [D loss: 0.170147] [G loss: 0.535992]\n",
      "[Epoch 14/200] [Batch 363/637] [D loss: 0.161686] [G loss: 0.438187]\n",
      "[Epoch 14/200] [Batch 364/637] [D loss: 0.165756] [G loss: 0.513429]\n",
      "[Epoch 14/200] [Batch 365/637] [D loss: 0.187976] [G loss: 0.465313]\n",
      "[Epoch 14/200] [Batch 366/637] [D loss: 0.152326] [G loss: 0.618172]\n",
      "[Epoch 14/200] [Batch 367/637] [D loss: 0.161100] [G loss: 0.511864]\n",
      "[Epoch 14/200] [Batch 368/637] [D loss: 0.154200] [G loss: 0.453027]\n",
      "[Epoch 14/200] [Batch 369/637] [D loss: 0.161368] [G loss: 0.503555]\n",
      "[Epoch 14/200] [Batch 370/637] [D loss: 0.141901] [G loss: 0.539148]\n",
      "[Epoch 14/200] [Batch 371/637] [D loss: 0.154435] [G loss: 0.567508]\n",
      "[Epoch 14/200] [Batch 372/637] [D loss: 0.128272] [G loss: 0.560676]\n",
      "[Epoch 14/200] [Batch 373/637] [D loss: 0.157650] [G loss: 0.454059]\n",
      "[Epoch 14/200] [Batch 374/637] [D loss: 0.153281] [G loss: 0.567970]\n",
      "[Epoch 14/200] [Batch 375/637] [D loss: 0.166306] [G loss: 0.524974]\n",
      "[Epoch 14/200] [Batch 376/637] [D loss: 0.164663] [G loss: 0.531814]\n",
      "[Epoch 14/200] [Batch 377/637] [D loss: 0.148980] [G loss: 0.531740]\n",
      "[Epoch 14/200] [Batch 378/637] [D loss: 0.150034] [G loss: 0.546692]\n",
      "[Epoch 14/200] [Batch 379/637] [D loss: 0.165507] [G loss: 0.470529]\n",
      "[Epoch 14/200] [Batch 380/637] [D loss: 0.169285] [G loss: 0.533831]\n",
      "[Epoch 14/200] [Batch 381/637] [D loss: 0.164782] [G loss: 0.647344]\n",
      "[Epoch 14/200] [Batch 382/637] [D loss: 0.152326] [G loss: 0.540607]\n",
      "[Epoch 14/200] [Batch 383/637] [D loss: 0.167918] [G loss: 0.433652]\n",
      "[Epoch 14/200] [Batch 384/637] [D loss: 0.183975] [G loss: 0.453172]\n",
      "[Epoch 14/200] [Batch 385/637] [D loss: 0.152240] [G loss: 0.543318]\n",
      "[Epoch 14/200] [Batch 386/637] [D loss: 0.163868] [G loss: 0.516130]\n",
      "[Epoch 14/200] [Batch 387/637] [D loss: 0.193410] [G loss: 0.441181]\n",
      "[Epoch 14/200] [Batch 388/637] [D loss: 0.261075] [G loss: 0.652766]\n",
      "[Epoch 14/200] [Batch 389/637] [D loss: 0.156175] [G loss: 0.599333]\n",
      "[Epoch 14/200] [Batch 390/637] [D loss: 0.180603] [G loss: 0.507049]\n",
      "[Epoch 14/200] [Batch 391/637] [D loss: 0.170492] [G loss: 0.477502]\n",
      "[Epoch 14/200] [Batch 392/637] [D loss: 0.159579] [G loss: 0.484658]\n",
      "[Epoch 14/200] [Batch 393/637] [D loss: 0.127723] [G loss: 0.515458]\n",
      "[Epoch 14/200] [Batch 394/637] [D loss: 0.141564] [G loss: 0.480248]\n",
      "[Epoch 14/200] [Batch 395/637] [D loss: 0.137802] [G loss: 0.516374]\n",
      "[Epoch 14/200] [Batch 396/637] [D loss: 0.166055] [G loss: 0.469783]\n",
      "[Epoch 14/200] [Batch 397/637] [D loss: 0.139721] [G loss: 0.588770]\n",
      "[Epoch 14/200] [Batch 398/637] [D loss: 0.142231] [G loss: 0.509542]\n",
      "[Epoch 14/200] [Batch 399/637] [D loss: 0.141786] [G loss: 0.559414]\n",
      "[Epoch 14/200] [Batch 400/637] [D loss: 0.150951] [G loss: 0.474828]\n",
      "[Epoch 14/200] [Batch 401/637] [D loss: 0.160139] [G loss: 0.430223]\n",
      "[Epoch 14/200] [Batch 402/637] [D loss: 0.152163] [G loss: 0.538683]\n",
      "[Epoch 14/200] [Batch 403/637] [D loss: 0.124948] [G loss: 0.604360]\n",
      "[Epoch 14/200] [Batch 404/637] [D loss: 0.174986] [G loss: 0.488651]\n",
      "[Epoch 14/200] [Batch 405/637] [D loss: 0.172500] [G loss: 0.538342]\n",
      "[Epoch 14/200] [Batch 406/637] [D loss: 0.152106] [G loss: 0.595766]\n",
      "[Epoch 14/200] [Batch 407/637] [D loss: 0.156341] [G loss: 0.487785]\n",
      "[Epoch 14/200] [Batch 408/637] [D loss: 0.159856] [G loss: 0.490913]\n",
      "[Epoch 14/200] [Batch 409/637] [D loss: 0.192079] [G loss: 0.580631]\n",
      "[Epoch 14/200] [Batch 410/637] [D loss: 0.178730] [G loss: 0.507153]\n",
      "[Epoch 14/200] [Batch 411/637] [D loss: 0.150429] [G loss: 0.491790]\n",
      "[Epoch 14/200] [Batch 412/637] [D loss: 0.164184] [G loss: 0.474951]\n",
      "[Epoch 14/200] [Batch 413/637] [D loss: 0.159157] [G loss: 0.541909]\n",
      "[Epoch 14/200] [Batch 414/637] [D loss: 0.150059] [G loss: 0.497863]\n",
      "[Epoch 14/200] [Batch 415/637] [D loss: 0.159385] [G loss: 0.506165]\n",
      "[Epoch 14/200] [Batch 416/637] [D loss: 0.167376] [G loss: 0.553372]\n",
      "[Epoch 14/200] [Batch 417/637] [D loss: 0.152017] [G loss: 0.514592]\n",
      "[Epoch 14/200] [Batch 418/637] [D loss: 0.145452] [G loss: 0.552460]\n",
      "[Epoch 14/200] [Batch 419/637] [D loss: 0.160352] [G loss: 0.549472]\n",
      "[Epoch 14/200] [Batch 420/637] [D loss: 0.151410] [G loss: 0.535555]\n",
      "[Epoch 14/200] [Batch 421/637] [D loss: 0.145904] [G loss: 0.520945]\n",
      "[Epoch 14/200] [Batch 422/637] [D loss: 0.159832] [G loss: 0.605329]\n",
      "[Epoch 14/200] [Batch 423/637] [D loss: 0.166175] [G loss: 0.545386]\n",
      "[Epoch 14/200] [Batch 424/637] [D loss: 0.144222] [G loss: 0.514970]\n",
      "[Epoch 14/200] [Batch 425/637] [D loss: 0.146618] [G loss: 0.511141]\n",
      "[Epoch 14/200] [Batch 426/637] [D loss: 0.164142] [G loss: 0.513753]\n",
      "[Epoch 14/200] [Batch 427/637] [D loss: 0.166901] [G loss: 0.573855]\n",
      "[Epoch 14/200] [Batch 428/637] [D loss: 0.155765] [G loss: 0.458704]\n",
      "[Epoch 14/200] [Batch 429/637] [D loss: 0.147378] [G loss: 0.563488]\n",
      "[Epoch 14/200] [Batch 430/637] [D loss: 0.161468] [G loss: 0.435390]\n",
      "[Epoch 14/200] [Batch 431/637] [D loss: 0.176640] [G loss: 0.529856]\n",
      "[Epoch 14/200] [Batch 432/637] [D loss: 0.187410] [G loss: 0.623970]\n",
      "[Epoch 14/200] [Batch 433/637] [D loss: 0.165487] [G loss: 0.506224]\n",
      "[Epoch 14/200] [Batch 434/637] [D loss: 0.167946] [G loss: 0.459785]\n",
      "[Epoch 14/200] [Batch 435/637] [D loss: 0.176061] [G loss: 0.574981]\n",
      "[Epoch 14/200] [Batch 436/637] [D loss: 0.154342] [G loss: 0.541026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 437/637] [D loss: 0.170685] [G loss: 0.516735]\n",
      "[Epoch 14/200] [Batch 438/637] [D loss: 0.178694] [G loss: 0.562777]\n",
      "[Epoch 14/200] [Batch 439/637] [D loss: 0.182937] [G loss: 0.510965]\n",
      "[Epoch 14/200] [Batch 440/637] [D loss: 0.139259] [G loss: 0.480296]\n",
      "[Epoch 14/200] [Batch 441/637] [D loss: 0.168354] [G loss: 0.467808]\n",
      "[Epoch 14/200] [Batch 442/637] [D loss: 0.146230] [G loss: 0.534262]\n",
      "[Epoch 14/200] [Batch 443/637] [D loss: 0.146939] [G loss: 0.501877]\n",
      "[Epoch 14/200] [Batch 444/637] [D loss: 0.160282] [G loss: 0.463878]\n",
      "[Epoch 14/200] [Batch 445/637] [D loss: 0.145002] [G loss: 0.549813]\n",
      "[Epoch 14/200] [Batch 446/637] [D loss: 0.140130] [G loss: 0.562697]\n",
      "[Epoch 14/200] [Batch 447/637] [D loss: 0.150335] [G loss: 0.537037]\n",
      "[Epoch 14/200] [Batch 448/637] [D loss: 0.156411] [G loss: 0.467904]\n",
      "[Epoch 14/200] [Batch 449/637] [D loss: 0.161005] [G loss: 0.567265]\n",
      "[Epoch 14/200] [Batch 450/637] [D loss: 0.138424] [G loss: 0.517313]\n",
      "[Epoch 14/200] [Batch 451/637] [D loss: 0.177587] [G loss: 0.459021]\n",
      "[Epoch 14/200] [Batch 452/637] [D loss: 0.200907] [G loss: 0.556063]\n",
      "[Epoch 14/200] [Batch 453/637] [D loss: 0.164864] [G loss: 0.617956]\n",
      "[Epoch 14/200] [Batch 454/637] [D loss: 0.152321] [G loss: 0.544245]\n",
      "[Epoch 14/200] [Batch 455/637] [D loss: 0.162615] [G loss: 0.498503]\n",
      "[Epoch 14/200] [Batch 456/637] [D loss: 0.170139] [G loss: 0.477918]\n",
      "[Epoch 14/200] [Batch 457/637] [D loss: 0.153981] [G loss: 0.451345]\n",
      "[Epoch 14/200] [Batch 458/637] [D loss: 0.145365] [G loss: 0.536710]\n",
      "[Epoch 14/200] [Batch 459/637] [D loss: 0.151766] [G loss: 0.523889]\n",
      "[Epoch 14/200] [Batch 460/637] [D loss: 0.139231] [G loss: 0.546162]\n",
      "[Epoch 14/200] [Batch 461/637] [D loss: 0.147215] [G loss: 0.526582]\n",
      "[Epoch 14/200] [Batch 462/637] [D loss: 0.181729] [G loss: 0.504458]\n",
      "[Epoch 14/200] [Batch 463/637] [D loss: 0.165832] [G loss: 0.477828]\n",
      "[Epoch 14/200] [Batch 464/637] [D loss: 0.164113] [G loss: 0.586195]\n",
      "[Epoch 14/200] [Batch 465/637] [D loss: 0.160316] [G loss: 0.519971]\n",
      "[Epoch 14/200] [Batch 466/637] [D loss: 0.158663] [G loss: 0.422885]\n",
      "[Epoch 14/200] [Batch 467/637] [D loss: 0.156081] [G loss: 0.496880]\n",
      "[Epoch 14/200] [Batch 468/637] [D loss: 0.162594] [G loss: 0.505203]\n",
      "[Epoch 14/200] [Batch 469/637] [D loss: 0.164273] [G loss: 0.535580]\n",
      "[Epoch 14/200] [Batch 470/637] [D loss: 0.166656] [G loss: 0.488103]\n",
      "[Epoch 14/200] [Batch 471/637] [D loss: 0.163040] [G loss: 0.467560]\n",
      "[Epoch 14/200] [Batch 472/637] [D loss: 0.158443] [G loss: 0.478094]\n",
      "[Epoch 14/200] [Batch 473/637] [D loss: 0.151051] [G loss: 0.466694]\n",
      "[Epoch 14/200] [Batch 474/637] [D loss: 0.170224] [G loss: 0.443775]\n",
      "[Epoch 14/200] [Batch 475/637] [D loss: 0.174304] [G loss: 0.483630]\n",
      "[Epoch 14/200] [Batch 476/637] [D loss: 0.152336] [G loss: 0.518224]\n",
      "[Epoch 14/200] [Batch 477/637] [D loss: 0.198335] [G loss: 0.457608]\n",
      "[Epoch 14/200] [Batch 478/637] [D loss: 0.179604] [G loss: 0.449575]\n",
      "[Epoch 14/200] [Batch 479/637] [D loss: 0.156687] [G loss: 0.502266]\n",
      "[Epoch 14/200] [Batch 480/637] [D loss: 0.172298] [G loss: 0.462639]\n",
      "[Epoch 14/200] [Batch 481/637] [D loss: 0.183644] [G loss: 0.450745]\n",
      "[Epoch 14/200] [Batch 482/637] [D loss: 0.176692] [G loss: 0.458922]\n",
      "[Epoch 14/200] [Batch 483/637] [D loss: 0.169909] [G loss: 0.461970]\n",
      "[Epoch 14/200] [Batch 484/637] [D loss: 0.162933] [G loss: 0.496948]\n",
      "[Epoch 14/200] [Batch 485/637] [D loss: 0.149273] [G loss: 0.506262]\n",
      "[Epoch 14/200] [Batch 486/637] [D loss: 0.150082] [G loss: 0.474693]\n",
      "[Epoch 14/200] [Batch 487/637] [D loss: 0.164756] [G loss: 0.483380]\n",
      "[Epoch 14/200] [Batch 488/637] [D loss: 0.141216] [G loss: 0.518070]\n",
      "[Epoch 14/200] [Batch 489/637] [D loss: 0.159285] [G loss: 0.550457]\n",
      "[Epoch 14/200] [Batch 490/637] [D loss: 0.138101] [G loss: 0.522050]\n",
      "[Epoch 14/200] [Batch 491/637] [D loss: 0.133225] [G loss: 0.651722]\n",
      "[Epoch 14/200] [Batch 492/637] [D loss: 0.127713] [G loss: 0.563586]\n",
      "[Epoch 14/200] [Batch 493/637] [D loss: 0.157314] [G loss: 0.470645]\n",
      "[Epoch 14/200] [Batch 494/637] [D loss: 0.139487] [G loss: 0.661161]\n",
      "[Epoch 14/200] [Batch 495/637] [D loss: 0.156469] [G loss: 0.574601]\n",
      "[Epoch 14/200] [Batch 496/637] [D loss: 0.178796] [G loss: 0.604500]\n",
      "[Epoch 14/200] [Batch 497/637] [D loss: 0.162839] [G loss: 0.559755]\n",
      "[Epoch 14/200] [Batch 498/637] [D loss: 0.163494] [G loss: 0.524948]\n",
      "[Epoch 14/200] [Batch 499/637] [D loss: 0.154532] [G loss: 0.495283]\n",
      "[Epoch 14/200] [Batch 500/637] [D loss: 0.164581] [G loss: 0.531869]\n",
      "[Epoch 14/200] [Batch 501/637] [D loss: 0.183120] [G loss: 0.559350]\n",
      "[Epoch 14/200] [Batch 502/637] [D loss: 0.175127] [G loss: 0.495811]\n",
      "[Epoch 14/200] [Batch 503/637] [D loss: 0.164581] [G loss: 0.489552]\n",
      "[Epoch 14/200] [Batch 504/637] [D loss: 0.165262] [G loss: 0.486577]\n",
      "[Epoch 14/200] [Batch 505/637] [D loss: 0.144137] [G loss: 0.551866]\n",
      "[Epoch 14/200] [Batch 506/637] [D loss: 0.148035] [G loss: 0.650838]\n",
      "[Epoch 14/200] [Batch 507/637] [D loss: 0.136565] [G loss: 0.541042]\n",
      "[Epoch 14/200] [Batch 508/637] [D loss: 0.126559] [G loss: 0.609831]\n",
      "[Epoch 14/200] [Batch 509/637] [D loss: 0.158797] [G loss: 0.479503]\n",
      "[Epoch 14/200] [Batch 510/637] [D loss: 0.144505] [G loss: 0.588938]\n",
      "[Epoch 14/200] [Batch 511/637] [D loss: 0.143139] [G loss: 0.506755]\n",
      "[Epoch 14/200] [Batch 512/637] [D loss: 0.139338] [G loss: 0.559754]\n",
      "[Epoch 14/200] [Batch 513/637] [D loss: 0.126302] [G loss: 0.564472]\n",
      "[Epoch 14/200] [Batch 514/637] [D loss: 0.155787] [G loss: 0.607226]\n",
      "[Epoch 14/200] [Batch 515/637] [D loss: 0.172821] [G loss: 0.601051]\n",
      "[Epoch 14/200] [Batch 516/637] [D loss: 0.165884] [G loss: 0.578551]\n",
      "[Epoch 14/200] [Batch 517/637] [D loss: 0.145887] [G loss: 0.574202]\n",
      "[Epoch 14/200] [Batch 518/637] [D loss: 0.149390] [G loss: 0.519985]\n",
      "[Epoch 14/200] [Batch 519/637] [D loss: 0.161011] [G loss: 0.462418]\n",
      "[Epoch 14/200] [Batch 520/637] [D loss: 0.135200] [G loss: 0.516980]\n",
      "[Epoch 14/200] [Batch 521/637] [D loss: 0.138386] [G loss: 0.533821]\n",
      "[Epoch 14/200] [Batch 522/637] [D loss: 0.162599] [G loss: 0.535581]\n",
      "[Epoch 14/200] [Batch 523/637] [D loss: 0.171622] [G loss: 0.525999]\n",
      "[Epoch 14/200] [Batch 524/637] [D loss: 0.168024] [G loss: 0.512170]\n",
      "[Epoch 14/200] [Batch 525/637] [D loss: 0.179828] [G loss: 0.577856]\n",
      "[Epoch 14/200] [Batch 526/637] [D loss: 0.141776] [G loss: 0.530668]\n",
      "[Epoch 14/200] [Batch 527/637] [D loss: 0.149125] [G loss: 0.564850]\n",
      "[Epoch 14/200] [Batch 528/637] [D loss: 0.149735] [G loss: 0.529154]\n",
      "[Epoch 14/200] [Batch 529/637] [D loss: 0.145386] [G loss: 0.554805]\n",
      "[Epoch 14/200] [Batch 530/637] [D loss: 0.150993] [G loss: 0.555174]\n",
      "[Epoch 14/200] [Batch 531/637] [D loss: 0.147726] [G loss: 0.557534]\n",
      "[Epoch 14/200] [Batch 532/637] [D loss: 0.151407] [G loss: 0.505512]\n",
      "[Epoch 14/200] [Batch 533/637] [D loss: 0.145330] [G loss: 0.507779]\n",
      "[Epoch 14/200] [Batch 534/637] [D loss: 0.158830] [G loss: 0.512359]\n",
      "[Epoch 14/200] [Batch 535/637] [D loss: 0.169479] [G loss: 0.461549]\n",
      "[Epoch 14/200] [Batch 536/637] [D loss: 0.184656] [G loss: 0.510695]\n",
      "[Epoch 14/200] [Batch 537/637] [D loss: 0.163459] [G loss: 0.521647]\n",
      "[Epoch 14/200] [Batch 538/637] [D loss: 0.151942] [G loss: 0.465694]\n",
      "[Epoch 14/200] [Batch 539/637] [D loss: 0.156975] [G loss: 0.465099]\n",
      "[Epoch 14/200] [Batch 540/637] [D loss: 0.162287] [G loss: 0.467015]\n",
      "[Epoch 14/200] [Batch 541/637] [D loss: 0.146615] [G loss: 0.491971]\n",
      "[Epoch 14/200] [Batch 542/637] [D loss: 0.141818] [G loss: 0.518184]\n",
      "[Epoch 14/200] [Batch 543/637] [D loss: 0.177681] [G loss: 0.461441]\n",
      "[Epoch 14/200] [Batch 544/637] [D loss: 0.187407] [G loss: 0.549702]\n",
      "[Epoch 14/200] [Batch 545/637] [D loss: 0.159411] [G loss: 0.489916]\n",
      "[Epoch 14/200] [Batch 546/637] [D loss: 0.174512] [G loss: 0.552732]\n",
      "[Epoch 14/200] [Batch 547/637] [D loss: 0.172024] [G loss: 0.510646]\n",
      "[Epoch 14/200] [Batch 548/637] [D loss: 0.164420] [G loss: 0.497831]\n",
      "[Epoch 14/200] [Batch 549/637] [D loss: 0.152453] [G loss: 0.501036]\n",
      "[Epoch 14/200] [Batch 550/637] [D loss: 0.140776] [G loss: 0.527267]\n",
      "[Epoch 14/200] [Batch 551/637] [D loss: 0.134889] [G loss: 0.534124]\n",
      "[Epoch 14/200] [Batch 552/637] [D loss: 0.157730] [G loss: 0.425583]\n",
      "[Epoch 14/200] [Batch 553/637] [D loss: 0.136930] [G loss: 0.523028]\n",
      "[Epoch 14/200] [Batch 554/637] [D loss: 0.144484] [G loss: 0.562935]\n",
      "[Epoch 14/200] [Batch 555/637] [D loss: 0.169792] [G loss: 0.515116]\n",
      "[Epoch 14/200] [Batch 556/637] [D loss: 0.147275] [G loss: 0.501808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 557/637] [D loss: 0.163891] [G loss: 0.537695]\n",
      "[Epoch 14/200] [Batch 558/637] [D loss: 0.163522] [G loss: 0.454953]\n",
      "[Epoch 14/200] [Batch 559/637] [D loss: 0.173316] [G loss: 0.492587]\n",
      "[Epoch 14/200] [Batch 560/637] [D loss: 0.179397] [G loss: 0.581875]\n",
      "[Epoch 14/200] [Batch 561/637] [D loss: 0.180831] [G loss: 0.459868]\n",
      "[Epoch 14/200] [Batch 562/637] [D loss: 0.166170] [G loss: 0.503432]\n",
      "[Epoch 14/200] [Batch 563/637] [D loss: 0.159486] [G loss: 0.526290]\n",
      "[Epoch 14/200] [Batch 564/637] [D loss: 0.149457] [G loss: 0.504030]\n",
      "[Epoch 14/200] [Batch 565/637] [D loss: 0.161098] [G loss: 0.534120]\n",
      "[Epoch 14/200] [Batch 566/637] [D loss: 0.151904] [G loss: 0.504339]\n",
      "[Epoch 14/200] [Batch 567/637] [D loss: 0.136967] [G loss: 0.563748]\n",
      "[Epoch 14/200] [Batch 568/637] [D loss: 0.170282] [G loss: 0.491194]\n",
      "[Epoch 14/200] [Batch 569/637] [D loss: 0.133208] [G loss: 0.603410]\n",
      "[Epoch 14/200] [Batch 570/637] [D loss: 0.136066] [G loss: 0.653521]\n",
      "[Epoch 14/200] [Batch 571/637] [D loss: 0.162168] [G loss: 0.545724]\n",
      "[Epoch 14/200] [Batch 572/637] [D loss: 0.174072] [G loss: 0.561076]\n",
      "[Epoch 14/200] [Batch 573/637] [D loss: 0.176733] [G loss: 0.508716]\n",
      "[Epoch 14/200] [Batch 574/637] [D loss: 0.135514] [G loss: 0.527000]\n",
      "[Epoch 14/200] [Batch 575/637] [D loss: 0.152222] [G loss: 0.465446]\n",
      "[Epoch 14/200] [Batch 576/637] [D loss: 0.173748] [G loss: 0.505701]\n",
      "[Epoch 14/200] [Batch 577/637] [D loss: 0.172169] [G loss: 0.551650]\n",
      "[Epoch 14/200] [Batch 578/637] [D loss: 0.157287] [G loss: 0.520890]\n",
      "[Epoch 14/200] [Batch 579/637] [D loss: 0.164019] [G loss: 0.573145]\n",
      "[Epoch 14/200] [Batch 580/637] [D loss: 0.161164] [G loss: 0.598814]\n",
      "[Epoch 14/200] [Batch 581/637] [D loss: 0.157636] [G loss: 0.545311]\n",
      "[Epoch 14/200] [Batch 582/637] [D loss: 0.147202] [G loss: 0.477600]\n",
      "[Epoch 14/200] [Batch 583/637] [D loss: 0.138891] [G loss: 0.529504]\n",
      "[Epoch 14/200] [Batch 584/637] [D loss: 0.163093] [G loss: 0.507441]\n",
      "[Epoch 14/200] [Batch 585/637] [D loss: 0.196010] [G loss: 0.623406]\n",
      "[Epoch 14/200] [Batch 586/637] [D loss: 0.145362] [G loss: 0.574626]\n",
      "[Epoch 14/200] [Batch 587/637] [D loss: 0.192334] [G loss: 0.485120]\n",
      "[Epoch 14/200] [Batch 588/637] [D loss: 0.241830] [G loss: 0.635887]\n",
      "[Epoch 14/200] [Batch 589/637] [D loss: 0.179416] [G loss: 0.574754]\n",
      "[Epoch 14/200] [Batch 590/637] [D loss: 0.161461] [G loss: 0.608939]\n",
      "[Epoch 14/200] [Batch 591/637] [D loss: 0.168737] [G loss: 0.501737]\n",
      "[Epoch 14/200] [Batch 592/637] [D loss: 0.170255] [G loss: 0.427039]\n",
      "[Epoch 14/200] [Batch 593/637] [D loss: 0.169155] [G loss: 0.410515]\n",
      "[Epoch 14/200] [Batch 594/637] [D loss: 0.167885] [G loss: 0.514440]\n",
      "[Epoch 14/200] [Batch 595/637] [D loss: 0.152852] [G loss: 0.496410]\n",
      "[Epoch 14/200] [Batch 596/637] [D loss: 0.176122] [G loss: 0.510215]\n",
      "[Epoch 14/200] [Batch 597/637] [D loss: 0.149798] [G loss: 0.526624]\n",
      "[Epoch 14/200] [Batch 598/637] [D loss: 0.162532] [G loss: 0.490057]\n",
      "[Epoch 14/200] [Batch 599/637] [D loss: 0.160957] [G loss: 0.463490]\n",
      "[Epoch 14/200] [Batch 600/637] [D loss: 0.160739] [G loss: 0.466940]\n",
      "[Epoch 14/200] [Batch 601/637] [D loss: 0.148137] [G loss: 0.512625]\n",
      "[Epoch 14/200] [Batch 602/637] [D loss: 0.149130] [G loss: 0.588368]\n",
      "[Epoch 14/200] [Batch 603/637] [D loss: 0.167037] [G loss: 0.492235]\n",
      "[Epoch 14/200] [Batch 604/637] [D loss: 0.175320] [G loss: 0.547313]\n",
      "[Epoch 14/200] [Batch 605/637] [D loss: 0.170517] [G loss: 0.471306]\n",
      "[Epoch 14/200] [Batch 606/637] [D loss: 0.143563] [G loss: 0.526912]\n",
      "[Epoch 14/200] [Batch 607/637] [D loss: 0.138117] [G loss: 0.524179]\n",
      "[Epoch 14/200] [Batch 608/637] [D loss: 0.184258] [G loss: 0.460518]\n",
      "[Epoch 14/200] [Batch 609/637] [D loss: 0.239247] [G loss: 0.498685]\n",
      "[Epoch 14/200] [Batch 610/637] [D loss: 0.143058] [G loss: 0.654679]\n",
      "[Epoch 14/200] [Batch 611/637] [D loss: 0.241122] [G loss: 0.428775]\n",
      "[Epoch 14/200] [Batch 612/637] [D loss: 0.172351] [G loss: 0.548759]\n",
      "[Epoch 14/200] [Batch 613/637] [D loss: 0.184746] [G loss: 0.511268]\n",
      "[Epoch 14/200] [Batch 614/637] [D loss: 0.161439] [G loss: 0.435894]\n",
      "[Epoch 14/200] [Batch 615/637] [D loss: 0.159990] [G loss: 0.475185]\n",
      "[Epoch 14/200] [Batch 616/637] [D loss: 0.159059] [G loss: 0.412744]\n",
      "[Epoch 14/200] [Batch 617/637] [D loss: 0.162645] [G loss: 0.446038]\n",
      "[Epoch 14/200] [Batch 618/637] [D loss: 0.174667] [G loss: 0.502864]\n",
      "[Epoch 14/200] [Batch 619/637] [D loss: 0.156403] [G loss: 0.519350]\n",
      "[Epoch 14/200] [Batch 620/637] [D loss: 0.163995] [G loss: 0.486541]\n",
      "[Epoch 14/200] [Batch 621/637] [D loss: 0.166457] [G loss: 0.488422]\n",
      "[Epoch 14/200] [Batch 622/637] [D loss: 0.156290] [G loss: 0.488973]\n",
      "[Epoch 14/200] [Batch 623/637] [D loss: 0.178432] [G loss: 0.495070]\n",
      "[Epoch 14/200] [Batch 624/637] [D loss: 0.216174] [G loss: 0.493864]\n",
      "[Epoch 14/200] [Batch 625/637] [D loss: 0.157137] [G loss: 0.555990]\n",
      "[Epoch 14/200] [Batch 626/637] [D loss: 0.188678] [G loss: 0.458333]\n",
      "[Epoch 14/200] [Batch 627/637] [D loss: 0.180051] [G loss: 0.411729]\n",
      "[Epoch 14/200] [Batch 628/637] [D loss: 0.185501] [G loss: 0.447359]\n",
      "[Epoch 14/200] [Batch 629/637] [D loss: 0.169626] [G loss: 0.418718]\n",
      "[Epoch 14/200] [Batch 630/637] [D loss: 0.166267] [G loss: 0.465749]\n",
      "[Epoch 14/200] [Batch 631/637] [D loss: 0.185414] [G loss: 0.457350]\n",
      "[Epoch 14/200] [Batch 632/637] [D loss: 0.161244] [G loss: 0.469934]\n",
      "[Epoch 14/200] [Batch 633/637] [D loss: 0.152571] [G loss: 0.524806]\n",
      "[Epoch 14/200] [Batch 634/637] [D loss: 0.165145] [G loss: 0.508015]\n",
      "[Epoch 14/200] [Batch 635/637] [D loss: 0.159979] [G loss: 0.485328]\n",
      "[Epoch 14/200] [Batch 636/637] [D loss: 0.163098] [G loss: 0.456880]\n",
      "[Epoch 15/200] [Batch 0/637] [D loss: 0.165316] [G loss: 0.472701]\n",
      "[Epoch 15/200] [Batch 1/637] [D loss: 0.199801] [G loss: 0.364408]\n",
      "[Epoch 15/200] [Batch 2/637] [D loss: 0.162367] [G loss: 0.536063]\n",
      "[Epoch 15/200] [Batch 3/637] [D loss: 0.158563] [G loss: 0.554854]\n",
      "[Epoch 15/200] [Batch 4/637] [D loss: 0.168791] [G loss: 0.559273]\n",
      "[Epoch 15/200] [Batch 5/637] [D loss: 0.160954] [G loss: 0.537799]\n",
      "[Epoch 15/200] [Batch 6/637] [D loss: 0.165861] [G loss: 0.515830]\n",
      "[Epoch 15/200] [Batch 7/637] [D loss: 0.159759] [G loss: 0.456144]\n",
      "[Epoch 15/200] [Batch 8/637] [D loss: 0.152788] [G loss: 0.484423]\n",
      "[Epoch 15/200] [Batch 9/637] [D loss: 0.159937] [G loss: 0.484413]\n",
      "[Epoch 15/200] [Batch 10/637] [D loss: 0.192801] [G loss: 0.444926]\n",
      "[Epoch 15/200] [Batch 11/637] [D loss: 0.197819] [G loss: 0.592346]\n",
      "[Epoch 15/200] [Batch 12/637] [D loss: 0.145995] [G loss: 0.478010]\n",
      "[Epoch 15/200] [Batch 13/637] [D loss: 0.179814] [G loss: 0.502156]\n",
      "[Epoch 15/200] [Batch 14/637] [D loss: 0.140663] [G loss: 0.509715]\n",
      "[Epoch 15/200] [Batch 15/637] [D loss: 0.151204] [G loss: 0.504820]\n",
      "[Epoch 15/200] [Batch 16/637] [D loss: 0.164125] [G loss: 0.430353]\n",
      "[Epoch 15/200] [Batch 17/637] [D loss: 0.143299] [G loss: 0.539023]\n",
      "[Epoch 15/200] [Batch 18/637] [D loss: 0.152796] [G loss: 0.478280]\n",
      "[Epoch 15/200] [Batch 19/637] [D loss: 0.136963] [G loss: 0.548107]\n",
      "[Epoch 15/200] [Batch 20/637] [D loss: 0.151925] [G loss: 0.516369]\n",
      "[Epoch 15/200] [Batch 21/637] [D loss: 0.150762] [G loss: 0.483264]\n",
      "[Epoch 15/200] [Batch 22/637] [D loss: 0.131244] [G loss: 0.463648]\n",
      "[Epoch 15/200] [Batch 23/637] [D loss: 0.154734] [G loss: 0.512699]\n",
      "[Epoch 15/200] [Batch 24/637] [D loss: 0.141541] [G loss: 0.496424]\n",
      "[Epoch 15/200] [Batch 25/637] [D loss: 0.147052] [G loss: 0.525822]\n",
      "[Epoch 15/200] [Batch 26/637] [D loss: 0.148003] [G loss: 0.545448]\n",
      "[Epoch 15/200] [Batch 27/637] [D loss: 0.145618] [G loss: 0.498733]\n",
      "[Epoch 15/200] [Batch 28/637] [D loss: 0.167032] [G loss: 0.500471]\n",
      "[Epoch 15/200] [Batch 29/637] [D loss: 0.152672] [G loss: 0.565397]\n",
      "[Epoch 15/200] [Batch 30/637] [D loss: 0.162214] [G loss: 0.503333]\n",
      "[Epoch 15/200] [Batch 31/637] [D loss: 0.166880] [G loss: 0.541174]\n",
      "[Epoch 15/200] [Batch 32/637] [D loss: 0.161315] [G loss: 0.577711]\n",
      "[Epoch 15/200] [Batch 33/637] [D loss: 0.161177] [G loss: 0.510521]\n",
      "[Epoch 15/200] [Batch 34/637] [D loss: 0.158744] [G loss: 0.481737]\n",
      "[Epoch 15/200] [Batch 35/637] [D loss: 0.159595] [G loss: 0.518948]\n",
      "[Epoch 15/200] [Batch 36/637] [D loss: 0.186296] [G loss: 0.504915]\n",
      "[Epoch 15/200] [Batch 37/637] [D loss: 0.159797] [G loss: 0.517711]\n",
      "[Epoch 15/200] [Batch 38/637] [D loss: 0.197023] [G loss: 0.508552]\n",
      "[Epoch 15/200] [Batch 39/637] [D loss: 0.155054] [G loss: 0.561023]\n",
      "[Epoch 15/200] [Batch 40/637] [D loss: 0.153906] [G loss: 0.534462]\n",
      "[Epoch 15/200] [Batch 41/637] [D loss: 0.161889] [G loss: 0.506104]\n",
      "[Epoch 15/200] [Batch 42/637] [D loss: 0.182679] [G loss: 0.493255]\n",
      "[Epoch 15/200] [Batch 43/637] [D loss: 0.167569] [G loss: 0.449154]\n",
      "[Epoch 15/200] [Batch 44/637] [D loss: 0.157049] [G loss: 0.540466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 45/637] [D loss: 0.143660] [G loss: 0.537767]\n",
      "[Epoch 15/200] [Batch 46/637] [D loss: 0.172586] [G loss: 0.449550]\n",
      "[Epoch 15/200] [Batch 47/637] [D loss: 0.183085] [G loss: 0.472513]\n",
      "[Epoch 15/200] [Batch 48/637] [D loss: 0.161721] [G loss: 0.496143]\n",
      "[Epoch 15/200] [Batch 49/637] [D loss: 0.162809] [G loss: 0.598287]\n",
      "[Epoch 15/200] [Batch 50/637] [D loss: 0.185182] [G loss: 0.466444]\n",
      "[Epoch 15/200] [Batch 51/637] [D loss: 0.180417] [G loss: 0.567605]\n",
      "[Epoch 15/200] [Batch 52/637] [D loss: 0.157330] [G loss: 0.539363]\n",
      "[Epoch 15/200] [Batch 53/637] [D loss: 0.145100] [G loss: 0.503658]\n",
      "[Epoch 15/200] [Batch 54/637] [D loss: 0.152682] [G loss: 0.566586]\n",
      "[Epoch 15/200] [Batch 55/637] [D loss: 0.156711] [G loss: 0.520620]\n",
      "[Epoch 15/200] [Batch 56/637] [D loss: 0.139686] [G loss: 0.497525]\n",
      "[Epoch 15/200] [Batch 57/637] [D loss: 0.136547] [G loss: 0.479874]\n",
      "[Epoch 15/200] [Batch 58/637] [D loss: 0.159389] [G loss: 0.495783]\n",
      "[Epoch 15/200] [Batch 59/637] [D loss: 0.158721] [G loss: 0.553822]\n",
      "[Epoch 15/200] [Batch 60/637] [D loss: 0.142965] [G loss: 0.586452]\n",
      "[Epoch 15/200] [Batch 61/637] [D loss: 0.128584] [G loss: 0.537910]\n",
      "[Epoch 15/200] [Batch 62/637] [D loss: 0.155218] [G loss: 0.566415]\n",
      "[Epoch 15/200] [Batch 63/637] [D loss: 0.157154] [G loss: 0.575272]\n",
      "[Epoch 15/200] [Batch 64/637] [D loss: 0.135514] [G loss: 0.514103]\n",
      "[Epoch 15/200] [Batch 65/637] [D loss: 0.146785] [G loss: 0.490596]\n",
      "[Epoch 15/200] [Batch 66/637] [D loss: 0.112959] [G loss: 0.571625]\n",
      "[Epoch 15/200] [Batch 67/637] [D loss: 0.158358] [G loss: 0.444147]\n",
      "[Epoch 15/200] [Batch 68/637] [D loss: 0.133170] [G loss: 0.590313]\n",
      "[Epoch 15/200] [Batch 69/637] [D loss: 0.138266] [G loss: 0.541971]\n",
      "[Epoch 15/200] [Batch 70/637] [D loss: 0.147206] [G loss: 0.545252]\n",
      "[Epoch 15/200] [Batch 71/637] [D loss: 0.136973] [G loss: 0.521635]\n",
      "[Epoch 15/200] [Batch 72/637] [D loss: 0.151831] [G loss: 0.567928]\n",
      "[Epoch 15/200] [Batch 73/637] [D loss: 0.176152] [G loss: 0.489241]\n",
      "[Epoch 15/200] [Batch 74/637] [D loss: 0.144820] [G loss: 0.582358]\n",
      "[Epoch 15/200] [Batch 75/637] [D loss: 0.148828] [G loss: 0.575111]\n",
      "[Epoch 15/200] [Batch 76/637] [D loss: 0.147225] [G loss: 0.531112]\n",
      "[Epoch 15/200] [Batch 77/637] [D loss: 0.179298] [G loss: 0.431847]\n",
      "[Epoch 15/200] [Batch 78/637] [D loss: 0.155296] [G loss: 0.491229]\n",
      "[Epoch 15/200] [Batch 79/637] [D loss: 0.161632] [G loss: 0.505661]\n",
      "[Epoch 15/200] [Batch 80/637] [D loss: 0.155293] [G loss: 0.530161]\n",
      "[Epoch 15/200] [Batch 81/637] [D loss: 0.155847] [G loss: 0.429372]\n",
      "[Epoch 15/200] [Batch 82/637] [D loss: 0.147601] [G loss: 0.476567]\n",
      "[Epoch 15/200] [Batch 83/637] [D loss: 0.165953] [G loss: 0.428046]\n",
      "[Epoch 15/200] [Batch 84/637] [D loss: 0.152925] [G loss: 0.591559]\n",
      "[Epoch 15/200] [Batch 85/637] [D loss: 0.155838] [G loss: 0.538931]\n",
      "[Epoch 15/200] [Batch 86/637] [D loss: 0.163877] [G loss: 0.510424]\n",
      "[Epoch 15/200] [Batch 87/637] [D loss: 0.128438] [G loss: 0.516501]\n",
      "[Epoch 15/200] [Batch 88/637] [D loss: 0.153053] [G loss: 0.435951]\n",
      "[Epoch 15/200] [Batch 89/637] [D loss: 0.164379] [G loss: 0.518188]\n",
      "[Epoch 15/200] [Batch 90/637] [D loss: 0.184487] [G loss: 0.445652]\n",
      "[Epoch 15/200] [Batch 91/637] [D loss: 0.158973] [G loss: 0.551750]\n",
      "[Epoch 15/200] [Batch 92/637] [D loss: 0.138185] [G loss: 0.601777]\n",
      "[Epoch 15/200] [Batch 93/637] [D loss: 0.151606] [G loss: 0.549611]\n",
      "[Epoch 15/200] [Batch 94/637] [D loss: 0.129441] [G loss: 0.519378]\n",
      "[Epoch 15/200] [Batch 95/637] [D loss: 0.145060] [G loss: 0.462424]\n",
      "[Epoch 15/200] [Batch 96/637] [D loss: 0.152198] [G loss: 0.517711]\n",
      "[Epoch 15/200] [Batch 97/637] [D loss: 0.144318] [G loss: 0.553160]\n",
      "[Epoch 15/200] [Batch 98/637] [D loss: 0.155012] [G loss: 0.500877]\n",
      "[Epoch 15/200] [Batch 99/637] [D loss: 0.160757] [G loss: 0.557358]\n",
      "[Epoch 15/200] [Batch 100/637] [D loss: 0.157664] [G loss: 0.525141]\n",
      "[Epoch 15/200] [Batch 101/637] [D loss: 0.131132] [G loss: 0.528872]\n",
      "[Epoch 15/200] [Batch 102/637] [D loss: 0.150465] [G loss: 0.530169]\n",
      "[Epoch 15/200] [Batch 103/637] [D loss: 0.157442] [G loss: 0.526632]\n",
      "[Epoch 15/200] [Batch 104/637] [D loss: 0.153803] [G loss: 0.507739]\n",
      "[Epoch 15/200] [Batch 105/637] [D loss: 0.167636] [G loss: 0.509854]\n",
      "[Epoch 15/200] [Batch 106/637] [D loss: 0.135756] [G loss: 0.549701]\n",
      "[Epoch 15/200] [Batch 107/637] [D loss: 0.143260] [G loss: 0.545331]\n",
      "[Epoch 15/200] [Batch 108/637] [D loss: 0.164251] [G loss: 0.560973]\n",
      "[Epoch 15/200] [Batch 109/637] [D loss: 0.202778] [G loss: 0.679428]\n",
      "[Epoch 15/200] [Batch 110/637] [D loss: 0.163367] [G loss: 0.670134]\n",
      "[Epoch 15/200] [Batch 111/637] [D loss: 0.162733] [G loss: 0.602345]\n",
      "[Epoch 15/200] [Batch 112/637] [D loss: 0.146771] [G loss: 0.554281]\n",
      "[Epoch 15/200] [Batch 113/637] [D loss: 0.143205] [G loss: 0.512088]\n",
      "[Epoch 15/200] [Batch 114/637] [D loss: 0.156719] [G loss: 0.437510]\n",
      "[Epoch 15/200] [Batch 115/637] [D loss: 0.159333] [G loss: 0.594891]\n",
      "[Epoch 15/200] [Batch 116/637] [D loss: 0.157101] [G loss: 0.644125]\n",
      "[Epoch 15/200] [Batch 117/637] [D loss: 0.155187] [G loss: 0.526202]\n",
      "[Epoch 15/200] [Batch 118/637] [D loss: 0.180328] [G loss: 0.479996]\n",
      "[Epoch 15/200] [Batch 119/637] [D loss: 0.180346] [G loss: 0.488948]\n",
      "[Epoch 15/200] [Batch 120/637] [D loss: 0.147830] [G loss: 0.580091]\n",
      "[Epoch 15/200] [Batch 121/637] [D loss: 0.184252] [G loss: 0.463224]\n",
      "[Epoch 15/200] [Batch 122/637] [D loss: 0.166819] [G loss: 0.500468]\n",
      "[Epoch 15/200] [Batch 123/637] [D loss: 0.160163] [G loss: 0.508475]\n",
      "[Epoch 15/200] [Batch 124/637] [D loss: 0.205625] [G loss: 0.464137]\n",
      "[Epoch 15/200] [Batch 125/637] [D loss: 0.171755] [G loss: 0.611735]\n",
      "[Epoch 15/200] [Batch 126/637] [D loss: 0.157034] [G loss: 0.512904]\n",
      "[Epoch 15/200] [Batch 127/637] [D loss: 0.166569] [G loss: 0.500440]\n",
      "[Epoch 15/200] [Batch 128/637] [D loss: 0.154420] [G loss: 0.465766]\n",
      "[Epoch 15/200] [Batch 129/637] [D loss: 0.192805] [G loss: 0.459198]\n",
      "[Epoch 15/200] [Batch 130/637] [D loss: 0.159914] [G loss: 0.570581]\n",
      "[Epoch 15/200] [Batch 131/637] [D loss: 0.175982] [G loss: 0.602182]\n",
      "[Epoch 15/200] [Batch 132/637] [D loss: 0.160868] [G loss: 0.488973]\n",
      "[Epoch 15/200] [Batch 133/637] [D loss: 0.116743] [G loss: 0.557681]\n",
      "[Epoch 15/200] [Batch 134/637] [D loss: 0.162820] [G loss: 0.504761]\n",
      "[Epoch 15/200] [Batch 135/637] [D loss: 0.136427] [G loss: 0.611232]\n",
      "[Epoch 15/200] [Batch 136/637] [D loss: 0.187465] [G loss: 0.508244]\n",
      "[Epoch 15/200] [Batch 137/637] [D loss: 0.193050] [G loss: 0.699988]\n",
      "[Epoch 15/200] [Batch 138/637] [D loss: 0.158923] [G loss: 0.671072]\n",
      "[Epoch 15/200] [Batch 139/637] [D loss: 0.146789] [G loss: 0.594275]\n",
      "[Epoch 15/200] [Batch 140/637] [D loss: 0.152989] [G loss: 0.483267]\n",
      "[Epoch 15/200] [Batch 141/637] [D loss: 0.143456] [G loss: 0.478735]\n",
      "[Epoch 15/200] [Batch 142/637] [D loss: 0.144137] [G loss: 0.458574]\n",
      "[Epoch 15/200] [Batch 143/637] [D loss: 0.159265] [G loss: 0.538734]\n",
      "[Epoch 15/200] [Batch 144/637] [D loss: 0.148117] [G loss: 0.490680]\n",
      "[Epoch 15/200] [Batch 145/637] [D loss: 0.135586] [G loss: 0.539245]\n",
      "[Epoch 15/200] [Batch 146/637] [D loss: 0.143929] [G loss: 0.558145]\n",
      "[Epoch 15/200] [Batch 147/637] [D loss: 0.163304] [G loss: 0.525492]\n",
      "[Epoch 15/200] [Batch 148/637] [D loss: 0.141827] [G loss: 0.550794]\n",
      "[Epoch 15/200] [Batch 149/637] [D loss: 0.179514] [G loss: 0.483184]\n",
      "[Epoch 15/200] [Batch 150/637] [D loss: 0.167033] [G loss: 0.484959]\n",
      "[Epoch 15/200] [Batch 151/637] [D loss: 0.181248] [G loss: 0.431617]\n",
      "[Epoch 15/200] [Batch 152/637] [D loss: 0.147663] [G loss: 0.587332]\n",
      "[Epoch 15/200] [Batch 153/637] [D loss: 0.165594] [G loss: 0.471817]\n",
      "[Epoch 15/200] [Batch 154/637] [D loss: 0.176048] [G loss: 0.474488]\n",
      "[Epoch 15/200] [Batch 155/637] [D loss: 0.158324] [G loss: 0.563202]\n",
      "[Epoch 15/200] [Batch 156/637] [D loss: 0.155428] [G loss: 0.613589]\n",
      "[Epoch 15/200] [Batch 157/637] [D loss: 0.133626] [G loss: 0.601115]\n",
      "[Epoch 15/200] [Batch 158/637] [D loss: 0.179342] [G loss: 0.452357]\n",
      "[Epoch 15/200] [Batch 159/637] [D loss: 0.161075] [G loss: 0.586009]\n",
      "[Epoch 15/200] [Batch 160/637] [D loss: 0.131002] [G loss: 0.657830]\n",
      "[Epoch 15/200] [Batch 161/637] [D loss: 0.143027] [G loss: 0.593490]\n",
      "[Epoch 15/200] [Batch 162/637] [D loss: 0.158895] [G loss: 0.552815]\n",
      "[Epoch 15/200] [Batch 163/637] [D loss: 0.126246] [G loss: 0.486200]\n",
      "[Epoch 15/200] [Batch 164/637] [D loss: 0.147568] [G loss: 0.497485]\n",
      "[Epoch 15/200] [Batch 165/637] [D loss: 0.140863] [G loss: 0.554098]\n",
      "[Epoch 15/200] [Batch 166/637] [D loss: 0.165043] [G loss: 0.539105]\n",
      "[Epoch 15/200] [Batch 167/637] [D loss: 0.149247] [G loss: 0.575083]\n",
      "[Epoch 15/200] [Batch 168/637] [D loss: 0.130767] [G loss: 0.562935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 169/637] [D loss: 0.156973] [G loss: 0.501792]\n",
      "[Epoch 15/200] [Batch 170/637] [D loss: 0.161080] [G loss: 0.549100]\n",
      "[Epoch 15/200] [Batch 171/637] [D loss: 0.139424] [G loss: 0.565581]\n",
      "[Epoch 15/200] [Batch 172/637] [D loss: 0.171283] [G loss: 0.466681]\n",
      "[Epoch 15/200] [Batch 173/637] [D loss: 0.162348] [G loss: 0.526461]\n",
      "[Epoch 15/200] [Batch 174/637] [D loss: 0.163448] [G loss: 0.531733]\n",
      "[Epoch 15/200] [Batch 175/637] [D loss: 0.156061] [G loss: 0.571737]\n",
      "[Epoch 15/200] [Batch 176/637] [D loss: 0.150698] [G loss: 0.475469]\n",
      "[Epoch 15/200] [Batch 177/637] [D loss: 0.142525] [G loss: 0.506137]\n",
      "[Epoch 15/200] [Batch 178/637] [D loss: 0.144292] [G loss: 0.524287]\n",
      "[Epoch 15/200] [Batch 179/637] [D loss: 0.149928] [G loss: 0.567641]\n",
      "[Epoch 15/200] [Batch 180/637] [D loss: 0.149729] [G loss: 0.575147]\n",
      "[Epoch 15/200] [Batch 181/637] [D loss: 0.141593] [G loss: 0.551603]\n",
      "[Epoch 15/200] [Batch 182/637] [D loss: 0.137148] [G loss: 0.544555]\n",
      "[Epoch 15/200] [Batch 183/637] [D loss: 0.158883] [G loss: 0.564198]\n",
      "[Epoch 15/200] [Batch 184/637] [D loss: 0.172815] [G loss: 0.556754]\n",
      "[Epoch 15/200] [Batch 185/637] [D loss: 0.183211] [G loss: 0.573298]\n",
      "[Epoch 15/200] [Batch 186/637] [D loss: 0.153362] [G loss: 0.489350]\n",
      "[Epoch 15/200] [Batch 187/637] [D loss: 0.180613] [G loss: 0.509112]\n",
      "[Epoch 15/200] [Batch 188/637] [D loss: 0.187783] [G loss: 0.555281]\n",
      "[Epoch 15/200] [Batch 189/637] [D loss: 0.185916] [G loss: 0.533529]\n",
      "[Epoch 15/200] [Batch 190/637] [D loss: 0.180975] [G loss: 0.496249]\n",
      "[Epoch 15/200] [Batch 191/637] [D loss: 0.169914] [G loss: 0.500249]\n",
      "[Epoch 15/200] [Batch 192/637] [D loss: 0.163546] [G loss: 0.516194]\n",
      "[Epoch 15/200] [Batch 193/637] [D loss: 0.184518] [G loss: 0.485150]\n",
      "[Epoch 15/200] [Batch 194/637] [D loss: 0.170089] [G loss: 0.601004]\n",
      "[Epoch 15/200] [Batch 195/637] [D loss: 0.172297] [G loss: 0.510285]\n",
      "[Epoch 15/200] [Batch 196/637] [D loss: 0.149209] [G loss: 0.525827]\n",
      "[Epoch 15/200] [Batch 197/637] [D loss: 0.140789] [G loss: 0.580400]\n",
      "[Epoch 15/200] [Batch 198/637] [D loss: 0.182736] [G loss: 0.441333]\n",
      "[Epoch 15/200] [Batch 199/637] [D loss: 0.176902] [G loss: 0.580263]\n",
      "[Epoch 15/200] [Batch 200/637] [D loss: 0.147798] [G loss: 0.601953]\n",
      "[Epoch 15/200] [Batch 201/637] [D loss: 0.145549] [G loss: 0.584153]\n",
      "[Epoch 15/200] [Batch 202/637] [D loss: 0.145596] [G loss: 0.567238]\n",
      "[Epoch 15/200] [Batch 203/637] [D loss: 0.154478] [G loss: 0.532834]\n",
      "[Epoch 15/200] [Batch 204/637] [D loss: 0.147454] [G loss: 0.562675]\n",
      "[Epoch 15/200] [Batch 205/637] [D loss: 0.135440] [G loss: 0.546128]\n",
      "[Epoch 15/200] [Batch 206/637] [D loss: 0.123644] [G loss: 0.584080]\n",
      "[Epoch 15/200] [Batch 207/637] [D loss: 0.153384] [G loss: 0.532948]\n",
      "[Epoch 15/200] [Batch 208/637] [D loss: 0.164098] [G loss: 0.634822]\n",
      "[Epoch 15/200] [Batch 209/637] [D loss: 0.164977] [G loss: 0.491417]\n",
      "[Epoch 15/200] [Batch 210/637] [D loss: 0.118841] [G loss: 0.542915]\n",
      "[Epoch 15/200] [Batch 211/637] [D loss: 0.153771] [G loss: 0.585745]\n",
      "[Epoch 15/200] [Batch 212/637] [D loss: 0.140433] [G loss: 0.608920]\n",
      "[Epoch 15/200] [Batch 213/637] [D loss: 0.190455] [G loss: 0.549135]\n",
      "[Epoch 15/200] [Batch 214/637] [D loss: 0.163776] [G loss: 0.605278]\n",
      "[Epoch 15/200] [Batch 215/637] [D loss: 0.190708] [G loss: 0.534207]\n",
      "[Epoch 15/200] [Batch 216/637] [D loss: 0.161167] [G loss: 0.472181]\n",
      "[Epoch 15/200] [Batch 217/637] [D loss: 0.172512] [G loss: 0.523282]\n",
      "[Epoch 15/200] [Batch 218/637] [D loss: 0.164939] [G loss: 0.449791]\n",
      "[Epoch 15/200] [Batch 219/637] [D loss: 0.160529] [G loss: 0.420141]\n",
      "[Epoch 15/200] [Batch 220/637] [D loss: 0.145889] [G loss: 0.555838]\n",
      "[Epoch 15/200] [Batch 221/637] [D loss: 0.162987] [G loss: 0.524792]\n",
      "[Epoch 15/200] [Batch 222/637] [D loss: 0.178298] [G loss: 0.485141]\n",
      "[Epoch 15/200] [Batch 223/637] [D loss: 0.168411] [G loss: 0.453021]\n",
      "[Epoch 15/200] [Batch 224/637] [D loss: 0.182690] [G loss: 0.449617]\n",
      "[Epoch 15/200] [Batch 225/637] [D loss: 0.151830] [G loss: 0.441966]\n",
      "[Epoch 15/200] [Batch 226/637] [D loss: 0.155553] [G loss: 0.505397]\n",
      "[Epoch 15/200] [Batch 227/637] [D loss: 0.132339] [G loss: 0.552244]\n",
      "[Epoch 15/200] [Batch 228/637] [D loss: 0.137489] [G loss: 0.520657]\n",
      "[Epoch 15/200] [Batch 229/637] [D loss: 0.151598] [G loss: 0.533313]\n",
      "[Epoch 15/200] [Batch 230/637] [D loss: 0.162579] [G loss: 0.492184]\n",
      "[Epoch 15/200] [Batch 231/637] [D loss: 0.161259] [G loss: 0.515274]\n",
      "[Epoch 15/200] [Batch 232/637] [D loss: 0.172993] [G loss: 0.454701]\n",
      "[Epoch 15/200] [Batch 233/637] [D loss: 0.171044] [G loss: 0.514933]\n",
      "[Epoch 15/200] [Batch 234/637] [D loss: 0.158436] [G loss: 0.577793]\n",
      "[Epoch 15/200] [Batch 235/637] [D loss: 0.159457] [G loss: 0.489506]\n",
      "[Epoch 15/200] [Batch 236/637] [D loss: 0.179178] [G loss: 0.401839]\n",
      "[Epoch 15/200] [Batch 237/637] [D loss: 0.146396] [G loss: 0.640118]\n",
      "[Epoch 15/200] [Batch 238/637] [D loss: 0.169925] [G loss: 0.485574]\n",
      "[Epoch 15/200] [Batch 239/637] [D loss: 0.158154] [G loss: 0.525617]\n",
      "[Epoch 15/200] [Batch 240/637] [D loss: 0.159910] [G loss: 0.530784]\n",
      "[Epoch 15/200] [Batch 241/637] [D loss: 0.158222] [G loss: 0.488381]\n",
      "[Epoch 15/200] [Batch 242/637] [D loss: 0.176541] [G loss: 0.508698]\n",
      "[Epoch 15/200] [Batch 243/637] [D loss: 0.150740] [G loss: 0.603980]\n",
      "[Epoch 15/200] [Batch 244/637] [D loss: 0.155725] [G loss: 0.563516]\n",
      "[Epoch 15/200] [Batch 245/637] [D loss: 0.143168] [G loss: 0.559187]\n",
      "[Epoch 15/200] [Batch 246/637] [D loss: 0.149159] [G loss: 0.531787]\n",
      "[Epoch 15/200] [Batch 247/637] [D loss: 0.165442] [G loss: 0.523397]\n",
      "[Epoch 15/200] [Batch 248/637] [D loss: 0.150180] [G loss: 0.499342]\n",
      "[Epoch 15/200] [Batch 249/637] [D loss: 0.135175] [G loss: 0.533869]\n",
      "[Epoch 15/200] [Batch 250/637] [D loss: 0.154097] [G loss: 0.473143]\n",
      "[Epoch 15/200] [Batch 251/637] [D loss: 0.133611] [G loss: 0.597473]\n",
      "[Epoch 15/200] [Batch 252/637] [D loss: 0.158070] [G loss: 0.584840]\n",
      "[Epoch 15/200] [Batch 253/637] [D loss: 0.158819] [G loss: 0.449458]\n",
      "[Epoch 15/200] [Batch 254/637] [D loss: 0.146629] [G loss: 0.546149]\n",
      "[Epoch 15/200] [Batch 255/637] [D loss: 0.159425] [G loss: 0.536440]\n",
      "[Epoch 15/200] [Batch 256/637] [D loss: 0.139788] [G loss: 0.572046]\n",
      "[Epoch 15/200] [Batch 257/637] [D loss: 0.122901] [G loss: 0.586125]\n",
      "[Epoch 15/200] [Batch 258/637] [D loss: 0.127036] [G loss: 0.591285]\n",
      "[Epoch 15/200] [Batch 259/637] [D loss: 0.133654] [G loss: 0.554649]\n",
      "[Epoch 15/200] [Batch 260/637] [D loss: 0.144457] [G loss: 0.550495]\n",
      "[Epoch 15/200] [Batch 261/637] [D loss: 0.143431] [G loss: 0.607169]\n",
      "[Epoch 15/200] [Batch 262/637] [D loss: 0.134336] [G loss: 0.578079]\n",
      "[Epoch 15/200] [Batch 263/637] [D loss: 0.134127] [G loss: 0.527095]\n",
      "[Epoch 15/200] [Batch 264/637] [D loss: 0.139262] [G loss: 0.644829]\n",
      "[Epoch 15/200] [Batch 265/637] [D loss: 0.167243] [G loss: 0.553692]\n",
      "[Epoch 15/200] [Batch 266/637] [D loss: 0.159555] [G loss: 0.507941]\n",
      "[Epoch 15/200] [Batch 267/637] [D loss: 0.183676] [G loss: 0.451980]\n",
      "[Epoch 15/200] [Batch 268/637] [D loss: 0.174144] [G loss: 0.507003]\n",
      "[Epoch 15/200] [Batch 269/637] [D loss: 0.179798] [G loss: 0.572283]\n",
      "[Epoch 15/200] [Batch 270/637] [D loss: 0.177644] [G loss: 0.474639]\n",
      "[Epoch 15/200] [Batch 271/637] [D loss: 0.186118] [G loss: 0.485653]\n",
      "[Epoch 15/200] [Batch 272/637] [D loss: 0.161910] [G loss: 0.532905]\n",
      "[Epoch 15/200] [Batch 273/637] [D loss: 0.167929] [G loss: 0.481082]\n",
      "[Epoch 15/200] [Batch 274/637] [D loss: 0.147851] [G loss: 0.519831]\n",
      "[Epoch 15/200] [Batch 275/637] [D loss: 0.137789] [G loss: 0.514366]\n",
      "[Epoch 15/200] [Batch 276/637] [D loss: 0.168282] [G loss: 0.534460]\n",
      "[Epoch 15/200] [Batch 277/637] [D loss: 0.191803] [G loss: 0.465245]\n",
      "[Epoch 15/200] [Batch 278/637] [D loss: 0.167996] [G loss: 0.508470]\n",
      "[Epoch 15/200] [Batch 279/637] [D loss: 0.155583] [G loss: 0.485368]\n",
      "[Epoch 15/200] [Batch 280/637] [D loss: 0.155392] [G loss: 0.547359]\n",
      "[Epoch 15/200] [Batch 281/637] [D loss: 0.148417] [G loss: 0.549958]\n",
      "[Epoch 15/200] [Batch 282/637] [D loss: 0.167946] [G loss: 0.503852]\n",
      "[Epoch 15/200] [Batch 283/637] [D loss: 0.160138] [G loss: 0.480744]\n",
      "[Epoch 15/200] [Batch 284/637] [D loss: 0.128554] [G loss: 0.580951]\n",
      "[Epoch 15/200] [Batch 285/637] [D loss: 0.166131] [G loss: 0.451122]\n",
      "[Epoch 15/200] [Batch 286/637] [D loss: 0.152523] [G loss: 0.538963]\n",
      "[Epoch 15/200] [Batch 287/637] [D loss: 0.148419] [G loss: 0.568063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 288/637] [D loss: 0.162215] [G loss: 0.496522]\n",
      "[Epoch 15/200] [Batch 289/637] [D loss: 0.149265] [G loss: 0.587909]\n",
      "[Epoch 15/200] [Batch 290/637] [D loss: 0.137572] [G loss: 0.529310]\n",
      "[Epoch 15/200] [Batch 291/637] [D loss: 0.163869] [G loss: 0.459928]\n",
      "[Epoch 15/200] [Batch 292/637] [D loss: 0.149224] [G loss: 0.547612]\n",
      "[Epoch 15/200] [Batch 293/637] [D loss: 0.149891] [G loss: 0.597507]\n",
      "[Epoch 15/200] [Batch 294/637] [D loss: 0.154516] [G loss: 0.526309]\n",
      "[Epoch 15/200] [Batch 295/637] [D loss: 0.140690] [G loss: 0.516242]\n",
      "[Epoch 15/200] [Batch 296/637] [D loss: 0.175840] [G loss: 0.511125]\n",
      "[Epoch 15/200] [Batch 297/637] [D loss: 0.164768] [G loss: 0.559842]\n",
      "[Epoch 15/200] [Batch 298/637] [D loss: 0.154525] [G loss: 0.541046]\n",
      "[Epoch 15/200] [Batch 299/637] [D loss: 0.152155] [G loss: 0.514958]\n",
      "[Epoch 15/200] [Batch 300/637] [D loss: 0.141603] [G loss: 0.519462]\n",
      "[Epoch 15/200] [Batch 301/637] [D loss: 0.156806] [G loss: 0.423493]\n",
      "[Epoch 15/200] [Batch 302/637] [D loss: 0.152486] [G loss: 0.521075]\n",
      "[Epoch 15/200] [Batch 303/637] [D loss: 0.135201] [G loss: 0.524708]\n",
      "[Epoch 15/200] [Batch 304/637] [D loss: 0.158438] [G loss: 0.474396]\n",
      "[Epoch 15/200] [Batch 305/637] [D loss: 0.160706] [G loss: 0.538726]\n",
      "[Epoch 15/200] [Batch 306/637] [D loss: 0.129920] [G loss: 0.507097]\n",
      "[Epoch 15/200] [Batch 307/637] [D loss: 0.144995] [G loss: 0.462381]\n",
      "[Epoch 15/200] [Batch 308/637] [D loss: 0.147070] [G loss: 0.543495]\n",
      "[Epoch 15/200] [Batch 309/637] [D loss: 0.173806] [G loss: 0.561935]\n",
      "[Epoch 15/200] [Batch 310/637] [D loss: 0.138301] [G loss: 0.559245]\n",
      "[Epoch 15/200] [Batch 311/637] [D loss: 0.146174] [G loss: 0.629914]\n",
      "[Epoch 15/200] [Batch 312/637] [D loss: 0.178584] [G loss: 0.463473]\n",
      "[Epoch 15/200] [Batch 313/637] [D loss: 0.152688] [G loss: 0.563958]\n",
      "[Epoch 15/200] [Batch 314/637] [D loss: 0.188819] [G loss: 0.452394]\n",
      "[Epoch 15/200] [Batch 315/637] [D loss: 0.169932] [G loss: 0.510602]\n",
      "[Epoch 15/200] [Batch 316/637] [D loss: 0.163801] [G loss: 0.500914]\n",
      "[Epoch 15/200] [Batch 317/637] [D loss: 0.172223] [G loss: 0.484013]\n",
      "[Epoch 15/200] [Batch 318/637] [D loss: 0.180770] [G loss: 0.418209]\n",
      "[Epoch 15/200] [Batch 319/637] [D loss: 0.163537] [G loss: 0.534713]\n",
      "[Epoch 15/200] [Batch 320/637] [D loss: 0.174301] [G loss: 0.487416]\n",
      "[Epoch 15/200] [Batch 321/637] [D loss: 0.147408] [G loss: 0.532696]\n",
      "[Epoch 15/200] [Batch 322/637] [D loss: 0.163777] [G loss: 0.570897]\n",
      "[Epoch 15/200] [Batch 323/637] [D loss: 0.153360] [G loss: 0.504159]\n",
      "[Epoch 15/200] [Batch 324/637] [D loss: 0.174216] [G loss: 0.445791]\n",
      "[Epoch 15/200] [Batch 325/637] [D loss: 0.158587] [G loss: 0.521030]\n",
      "[Epoch 15/200] [Batch 326/637] [D loss: 0.165794] [G loss: 0.587265]\n",
      "[Epoch 15/200] [Batch 327/637] [D loss: 0.136724] [G loss: 0.550272]\n",
      "[Epoch 15/200] [Batch 328/637] [D loss: 0.154209] [G loss: 0.484601]\n",
      "[Epoch 15/200] [Batch 329/637] [D loss: 0.167731] [G loss: 0.472249]\n",
      "[Epoch 15/200] [Batch 330/637] [D loss: 0.155806] [G loss: 0.454605]\n",
      "[Epoch 15/200] [Batch 331/637] [D loss: 0.158150] [G loss: 0.469840]\n",
      "[Epoch 15/200] [Batch 332/637] [D loss: 0.150265] [G loss: 0.519543]\n",
      "[Epoch 15/200] [Batch 333/637] [D loss: 0.177756] [G loss: 0.485454]\n",
      "[Epoch 15/200] [Batch 334/637] [D loss: 0.160842] [G loss: 0.518320]\n",
      "[Epoch 15/200] [Batch 335/637] [D loss: 0.167006] [G loss: 0.514320]\n",
      "[Epoch 15/200] [Batch 336/637] [D loss: 0.160565] [G loss: 0.522280]\n",
      "[Epoch 15/200] [Batch 337/637] [D loss: 0.162504] [G loss: 0.452011]\n",
      "[Epoch 15/200] [Batch 338/637] [D loss: 0.174972] [G loss: 0.445152]\n",
      "[Epoch 15/200] [Batch 339/637] [D loss: 0.160498] [G loss: 0.537557]\n",
      "[Epoch 15/200] [Batch 340/637] [D loss: 0.166777] [G loss: 0.453535]\n",
      "[Epoch 15/200] [Batch 341/637] [D loss: 0.152358] [G loss: 0.505484]\n",
      "[Epoch 15/200] [Batch 342/637] [D loss: 0.154029] [G loss: 0.507971]\n",
      "[Epoch 15/200] [Batch 343/637] [D loss: 0.172170] [G loss: 0.540257]\n",
      "[Epoch 15/200] [Batch 344/637] [D loss: 0.200271] [G loss: 0.429607]\n",
      "[Epoch 15/200] [Batch 345/637] [D loss: 0.169647] [G loss: 0.628258]\n",
      "[Epoch 15/200] [Batch 346/637] [D loss: 0.148361] [G loss: 0.537272]\n",
      "[Epoch 15/200] [Batch 347/637] [D loss: 0.160779] [G loss: 0.491289]\n",
      "[Epoch 15/200] [Batch 348/637] [D loss: 0.154808] [G loss: 0.515444]\n",
      "[Epoch 15/200] [Batch 349/637] [D loss: 0.154293] [G loss: 0.478441]\n",
      "[Epoch 15/200] [Batch 350/637] [D loss: 0.138115] [G loss: 0.534389]\n",
      "[Epoch 15/200] [Batch 351/637] [D loss: 0.158177] [G loss: 0.435937]\n",
      "[Epoch 15/200] [Batch 352/637] [D loss: 0.160672] [G loss: 0.509413]\n",
      "[Epoch 15/200] [Batch 353/637] [D loss: 0.149967] [G loss: 0.500154]\n",
      "[Epoch 15/200] [Batch 354/637] [D loss: 0.140310] [G loss: 0.545190]\n",
      "[Epoch 15/200] [Batch 355/637] [D loss: 0.164320] [G loss: 0.502534]\n",
      "[Epoch 15/200] [Batch 356/637] [D loss: 0.157508] [G loss: 0.574850]\n",
      "[Epoch 15/200] [Batch 357/637] [D loss: 0.161509] [G loss: 0.429306]\n",
      "[Epoch 15/200] [Batch 358/637] [D loss: 0.150439] [G loss: 0.452056]\n",
      "[Epoch 15/200] [Batch 359/637] [D loss: 0.145456] [G loss: 0.553685]\n",
      "[Epoch 15/200] [Batch 360/637] [D loss: 0.163211] [G loss: 0.519187]\n",
      "[Epoch 15/200] [Batch 361/637] [D loss: 0.140793] [G loss: 0.562174]\n",
      "[Epoch 15/200] [Batch 362/637] [D loss: 0.152829] [G loss: 0.497939]\n",
      "[Epoch 15/200] [Batch 363/637] [D loss: 0.175559] [G loss: 0.434293]\n",
      "[Epoch 15/200] [Batch 364/637] [D loss: 0.205027] [G loss: 0.639022]\n",
      "[Epoch 15/200] [Batch 365/637] [D loss: 0.175201] [G loss: 0.596383]\n",
      "[Epoch 15/200] [Batch 366/637] [D loss: 0.169037] [G loss: 0.474785]\n",
      "[Epoch 15/200] [Batch 367/637] [D loss: 0.149509] [G loss: 0.548399]\n",
      "[Epoch 15/200] [Batch 368/637] [D loss: 0.135637] [G loss: 0.533115]\n",
      "[Epoch 15/200] [Batch 369/637] [D loss: 0.142790] [G loss: 0.514578]\n",
      "[Epoch 15/200] [Batch 370/637] [D loss: 0.144774] [G loss: 0.489173]\n",
      "[Epoch 15/200] [Batch 371/637] [D loss: 0.157950] [G loss: 0.529190]\n",
      "[Epoch 15/200] [Batch 372/637] [D loss: 0.169613] [G loss: 0.568524]\n",
      "[Epoch 15/200] [Batch 373/637] [D loss: 0.160230] [G loss: 0.520097]\n",
      "[Epoch 15/200] [Batch 374/637] [D loss: 0.162857] [G loss: 0.659066]\n",
      "[Epoch 15/200] [Batch 375/637] [D loss: 0.146963] [G loss: 0.543282]\n",
      "[Epoch 15/200] [Batch 376/637] [D loss: 0.157255] [G loss: 0.526329]\n",
      "[Epoch 15/200] [Batch 377/637] [D loss: 0.155973] [G loss: 0.511122]\n",
      "[Epoch 15/200] [Batch 378/637] [D loss: 0.163646] [G loss: 0.582164]\n",
      "[Epoch 15/200] [Batch 379/637] [D loss: 0.149930] [G loss: 0.546154]\n",
      "[Epoch 15/200] [Batch 380/637] [D loss: 0.134840] [G loss: 0.537658]\n",
      "[Epoch 15/200] [Batch 381/637] [D loss: 0.170015] [G loss: 0.507390]\n",
      "[Epoch 15/200] [Batch 382/637] [D loss: 0.172704] [G loss: 0.599248]\n",
      "[Epoch 15/200] [Batch 383/637] [D loss: 0.167122] [G loss: 0.588004]\n",
      "[Epoch 15/200] [Batch 384/637] [D loss: 0.171876] [G loss: 0.535735]\n",
      "[Epoch 15/200] [Batch 385/637] [D loss: 0.145128] [G loss: 0.470057]\n",
      "[Epoch 15/200] [Batch 386/637] [D loss: 0.149042] [G loss: 0.463200]\n",
      "[Epoch 15/200] [Batch 387/637] [D loss: 0.159939] [G loss: 0.456063]\n",
      "[Epoch 15/200] [Batch 388/637] [D loss: 0.154051] [G loss: 0.468476]\n",
      "[Epoch 15/200] [Batch 389/637] [D loss: 0.175221] [G loss: 0.462673]\n",
      "[Epoch 15/200] [Batch 390/637] [D loss: 0.167969] [G loss: 0.551764]\n",
      "[Epoch 15/200] [Batch 391/637] [D loss: 0.169159] [G loss: 0.476161]\n",
      "[Epoch 15/200] [Batch 392/637] [D loss: 0.149927] [G loss: 0.509405]\n",
      "[Epoch 15/200] [Batch 393/637] [D loss: 0.147005] [G loss: 0.518806]\n",
      "[Epoch 15/200] [Batch 394/637] [D loss: 0.144778] [G loss: 0.512508]\n",
      "[Epoch 15/200] [Batch 395/637] [D loss: 0.121029] [G loss: 0.528164]\n",
      "[Epoch 15/200] [Batch 396/637] [D loss: 0.134941] [G loss: 0.556738]\n",
      "[Epoch 15/200] [Batch 397/637] [D loss: 0.147062] [G loss: 0.577808]\n",
      "[Epoch 15/200] [Batch 398/637] [D loss: 0.198430] [G loss: 0.388461]\n",
      "[Epoch 15/200] [Batch 399/637] [D loss: 0.145621] [G loss: 0.627100]\n",
      "[Epoch 15/200] [Batch 400/637] [D loss: 0.169600] [G loss: 0.631276]\n",
      "[Epoch 15/200] [Batch 401/637] [D loss: 0.146572] [G loss: 0.539463]\n",
      "[Epoch 15/200] [Batch 402/637] [D loss: 0.154867] [G loss: 0.516142]\n",
      "[Epoch 15/200] [Batch 403/637] [D loss: 0.163484] [G loss: 0.455468]\n",
      "[Epoch 15/200] [Batch 404/637] [D loss: 0.178008] [G loss: 0.583161]\n",
      "[Epoch 15/200] [Batch 405/637] [D loss: 0.157318] [G loss: 0.491141]\n",
      "[Epoch 15/200] [Batch 406/637] [D loss: 0.192932] [G loss: 0.438807]\n",
      "[Epoch 15/200] [Batch 407/637] [D loss: 0.178351] [G loss: 0.618466]\n",
      "[Epoch 15/200] [Batch 408/637] [D loss: 0.154954] [G loss: 0.555560]\n",
      "[Epoch 15/200] [Batch 409/637] [D loss: 0.161468] [G loss: 0.472398]\n",
      "[Epoch 15/200] [Batch 410/637] [D loss: 0.181038] [G loss: 0.440742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 411/637] [D loss: 0.160421] [G loss: 0.502799]\n",
      "[Epoch 15/200] [Batch 412/637] [D loss: 0.141363] [G loss: 0.516529]\n",
      "[Epoch 15/200] [Batch 413/637] [D loss: 0.152868] [G loss: 0.511967]\n",
      "[Epoch 15/200] [Batch 414/637] [D loss: 0.146427] [G loss: 0.513772]\n",
      "[Epoch 15/200] [Batch 415/637] [D loss: 0.159226] [G loss: 0.526729]\n",
      "[Epoch 15/200] [Batch 416/637] [D loss: 0.165738] [G loss: 0.466205]\n",
      "[Epoch 15/200] [Batch 417/637] [D loss: 0.143365] [G loss: 0.506956]\n",
      "[Epoch 15/200] [Batch 418/637] [D loss: 0.155349] [G loss: 0.522646]\n",
      "[Epoch 15/200] [Batch 419/637] [D loss: 0.156413] [G loss: 0.479664]\n",
      "[Epoch 15/200] [Batch 420/637] [D loss: 0.138965] [G loss: 0.520292]\n",
      "[Epoch 15/200] [Batch 421/637] [D loss: 0.169265] [G loss: 0.566192]\n",
      "[Epoch 15/200] [Batch 422/637] [D loss: 0.167182] [G loss: 0.538861]\n",
      "[Epoch 15/200] [Batch 423/637] [D loss: 0.175531] [G loss: 0.541769]\n",
      "[Epoch 15/200] [Batch 424/637] [D loss: 0.167602] [G loss: 0.487770]\n",
      "[Epoch 15/200] [Batch 425/637] [D loss: 0.163513] [G loss: 0.508940]\n",
      "[Epoch 15/200] [Batch 426/637] [D loss: 0.156755] [G loss: 0.530611]\n",
      "[Epoch 15/200] [Batch 427/637] [D loss: 0.158098] [G loss: 0.532914]\n",
      "[Epoch 15/200] [Batch 428/637] [D loss: 0.155170] [G loss: 0.459116]\n",
      "[Epoch 15/200] [Batch 429/637] [D loss: 0.167921] [G loss: 0.546772]\n",
      "[Epoch 15/200] [Batch 430/637] [D loss: 0.150194] [G loss: 0.473196]\n",
      "[Epoch 15/200] [Batch 431/637] [D loss: 0.149898] [G loss: 0.540082]\n",
      "[Epoch 15/200] [Batch 432/637] [D loss: 0.136850] [G loss: 0.589569]\n",
      "[Epoch 15/200] [Batch 433/637] [D loss: 0.137496] [G loss: 0.539723]\n",
      "[Epoch 15/200] [Batch 434/637] [D loss: 0.171468] [G loss: 0.453193]\n",
      "[Epoch 15/200] [Batch 435/637] [D loss: 0.175758] [G loss: 0.475601]\n",
      "[Epoch 15/200] [Batch 436/637] [D loss: 0.158599] [G loss: 0.530555]\n",
      "[Epoch 15/200] [Batch 437/637] [D loss: 0.149741] [G loss: 0.457374]\n",
      "[Epoch 15/200] [Batch 438/637] [D loss: 0.166506] [G loss: 0.501435]\n",
      "[Epoch 15/200] [Batch 439/637] [D loss: 0.146483] [G loss: 0.590961]\n",
      "[Epoch 15/200] [Batch 440/637] [D loss: 0.161242] [G loss: 0.590893]\n",
      "[Epoch 15/200] [Batch 441/637] [D loss: 0.143780] [G loss: 0.484192]\n",
      "[Epoch 15/200] [Batch 442/637] [D loss: 0.157204] [G loss: 0.481422]\n",
      "[Epoch 15/200] [Batch 443/637] [D loss: 0.157058] [G loss: 0.573411]\n",
      "[Epoch 15/200] [Batch 444/637] [D loss: 0.136840] [G loss: 0.543700]\n",
      "[Epoch 15/200] [Batch 445/637] [D loss: 0.182403] [G loss: 0.502808]\n",
      "[Epoch 15/200] [Batch 446/637] [D loss: 0.153720] [G loss: 0.481596]\n",
      "[Epoch 15/200] [Batch 447/637] [D loss: 0.136248] [G loss: 0.583068]\n",
      "[Epoch 15/200] [Batch 448/637] [D loss: 0.164565] [G loss: 0.490397]\n",
      "[Epoch 15/200] [Batch 449/637] [D loss: 0.201891] [G loss: 0.421866]\n",
      "[Epoch 15/200] [Batch 450/637] [D loss: 0.227030] [G loss: 0.800319]\n",
      "[Epoch 15/200] [Batch 451/637] [D loss: 0.161042] [G loss: 0.574861]\n",
      "[Epoch 15/200] [Batch 452/637] [D loss: 0.215695] [G loss: 0.519549]\n",
      "[Epoch 15/200] [Batch 453/637] [D loss: 0.194114] [G loss: 0.386616]\n",
      "[Epoch 15/200] [Batch 454/637] [D loss: 0.178147] [G loss: 0.463159]\n",
      "[Epoch 15/200] [Batch 455/637] [D loss: 0.153953] [G loss: 0.451314]\n",
      "[Epoch 15/200] [Batch 456/637] [D loss: 0.178080] [G loss: 0.390271]\n",
      "[Epoch 15/200] [Batch 457/637] [D loss: 0.128520] [G loss: 0.545553]\n",
      "[Epoch 15/200] [Batch 458/637] [D loss: 0.153632] [G loss: 0.498504]\n",
      "[Epoch 15/200] [Batch 459/637] [D loss: 0.154337] [G loss: 0.506013]\n",
      "[Epoch 15/200] [Batch 460/637] [D loss: 0.145740] [G loss: 0.548047]\n",
      "[Epoch 15/200] [Batch 461/637] [D loss: 0.160563] [G loss: 0.467289]\n",
      "[Epoch 15/200] [Batch 462/637] [D loss: 0.189054] [G loss: 0.446502]\n",
      "[Epoch 15/200] [Batch 463/637] [D loss: 0.171429] [G loss: 0.435206]\n",
      "[Epoch 15/200] [Batch 464/637] [D loss: 0.155773] [G loss: 0.528616]\n",
      "[Epoch 15/200] [Batch 465/637] [D loss: 0.156098] [G loss: 0.504805]\n",
      "[Epoch 15/200] [Batch 466/637] [D loss: 0.168197] [G loss: 0.457522]\n",
      "[Epoch 15/200] [Batch 467/637] [D loss: 0.182212] [G loss: 0.440492]\n",
      "[Epoch 15/200] [Batch 468/637] [D loss: 0.162654] [G loss: 0.511848]\n",
      "[Epoch 15/200] [Batch 469/637] [D loss: 0.140056] [G loss: 0.516215]\n",
      "[Epoch 15/200] [Batch 470/637] [D loss: 0.147245] [G loss: 0.460080]\n",
      "[Epoch 15/200] [Batch 471/637] [D loss: 0.157139] [G loss: 0.572668]\n",
      "[Epoch 15/200] [Batch 472/637] [D loss: 0.157341] [G loss: 0.502592]\n",
      "[Epoch 15/200] [Batch 473/637] [D loss: 0.149590] [G loss: 0.566573]\n",
      "[Epoch 15/200] [Batch 474/637] [D loss: 0.163159] [G loss: 0.531954]\n",
      "[Epoch 15/200] [Batch 475/637] [D loss: 0.147357] [G loss: 0.600281]\n",
      "[Epoch 15/200] [Batch 476/637] [D loss: 0.153545] [G loss: 0.471248]\n",
      "[Epoch 15/200] [Batch 477/637] [D loss: 0.154133] [G loss: 0.512242]\n",
      "[Epoch 15/200] [Batch 478/637] [D loss: 0.142061] [G loss: 0.640764]\n",
      "[Epoch 15/200] [Batch 479/637] [D loss: 0.148247] [G loss: 0.553944]\n",
      "[Epoch 15/200] [Batch 480/637] [D loss: 0.156284] [G loss: 0.499602]\n",
      "[Epoch 15/200] [Batch 481/637] [D loss: 0.147577] [G loss: 0.517515]\n",
      "[Epoch 15/200] [Batch 482/637] [D loss: 0.142232] [G loss: 0.509022]\n",
      "[Epoch 15/200] [Batch 483/637] [D loss: 0.148006] [G loss: 0.538938]\n",
      "[Epoch 15/200] [Batch 484/637] [D loss: 0.126001] [G loss: 0.578963]\n",
      "[Epoch 15/200] [Batch 485/637] [D loss: 0.166842] [G loss: 0.515571]\n",
      "[Epoch 15/200] [Batch 486/637] [D loss: 0.184426] [G loss: 0.526854]\n",
      "[Epoch 15/200] [Batch 487/637] [D loss: 0.165834] [G loss: 0.599716]\n",
      "[Epoch 15/200] [Batch 488/637] [D loss: 0.158170] [G loss: 0.543119]\n",
      "[Epoch 15/200] [Batch 489/637] [D loss: 0.144116] [G loss: 0.531673]\n",
      "[Epoch 15/200] [Batch 490/637] [D loss: 0.159488] [G loss: 0.469555]\n",
      "[Epoch 15/200] [Batch 491/637] [D loss: 0.162888] [G loss: 0.489350]\n",
      "[Epoch 15/200] [Batch 492/637] [D loss: 0.174139] [G loss: 0.471456]\n",
      "[Epoch 15/200] [Batch 493/637] [D loss: 0.159497] [G loss: 0.514506]\n",
      "[Epoch 15/200] [Batch 494/637] [D loss: 0.169795] [G loss: 0.470769]\n",
      "[Epoch 15/200] [Batch 495/637] [D loss: 0.148763] [G loss: 0.542899]\n",
      "[Epoch 15/200] [Batch 496/637] [D loss: 0.142729] [G loss: 0.525007]\n",
      "[Epoch 15/200] [Batch 497/637] [D loss: 0.141275] [G loss: 0.590918]\n",
      "[Epoch 15/200] [Batch 498/637] [D loss: 0.198873] [G loss: 0.459080]\n",
      "[Epoch 15/200] [Batch 499/637] [D loss: 0.180292] [G loss: 0.526006]\n",
      "[Epoch 15/200] [Batch 500/637] [D loss: 0.170944] [G loss: 0.567735]\n",
      "[Epoch 15/200] [Batch 501/637] [D loss: 0.162700] [G loss: 0.598111]\n",
      "[Epoch 15/200] [Batch 502/637] [D loss: 0.152366] [G loss: 0.497792]\n",
      "[Epoch 15/200] [Batch 503/637] [D loss: 0.192620] [G loss: 0.445269]\n",
      "[Epoch 15/200] [Batch 504/637] [D loss: 0.157356] [G loss: 0.647193]\n",
      "[Epoch 15/200] [Batch 505/637] [D loss: 0.166802] [G loss: 0.571697]\n",
      "[Epoch 15/200] [Batch 506/637] [D loss: 0.143027] [G loss: 0.541032]\n",
      "[Epoch 15/200] [Batch 507/637] [D loss: 0.164493] [G loss: 0.479609]\n",
      "[Epoch 15/200] [Batch 508/637] [D loss: 0.139043] [G loss: 0.501638]\n",
      "[Epoch 15/200] [Batch 509/637] [D loss: 0.153081] [G loss: 0.545924]\n",
      "[Epoch 15/200] [Batch 510/637] [D loss: 0.142648] [G loss: 0.522792]\n",
      "[Epoch 15/200] [Batch 511/637] [D loss: 0.170683] [G loss: 0.501283]\n",
      "[Epoch 15/200] [Batch 512/637] [D loss: 0.142341] [G loss: 0.516437]\n",
      "[Epoch 15/200] [Batch 513/637] [D loss: 0.141757] [G loss: 0.592861]\n",
      "[Epoch 15/200] [Batch 514/637] [D loss: 0.154230] [G loss: 0.596127]\n",
      "[Epoch 15/200] [Batch 515/637] [D loss: 0.157815] [G loss: 0.550614]\n",
      "[Epoch 15/200] [Batch 516/637] [D loss: 0.139006] [G loss: 0.562434]\n",
      "[Epoch 15/200] [Batch 517/637] [D loss: 0.145796] [G loss: 0.499566]\n",
      "[Epoch 15/200] [Batch 518/637] [D loss: 0.140470] [G loss: 0.572548]\n",
      "[Epoch 15/200] [Batch 519/637] [D loss: 0.157074] [G loss: 0.591838]\n",
      "[Epoch 15/200] [Batch 520/637] [D loss: 0.161632] [G loss: 0.530327]\n",
      "[Epoch 15/200] [Batch 521/637] [D loss: 0.120973] [G loss: 0.579607]\n",
      "[Epoch 15/200] [Batch 522/637] [D loss: 0.165757] [G loss: 0.475286]\n",
      "[Epoch 15/200] [Batch 523/637] [D loss: 0.161040] [G loss: 0.553220]\n",
      "[Epoch 15/200] [Batch 524/637] [D loss: 0.157528] [G loss: 0.539280]\n",
      "[Epoch 15/200] [Batch 525/637] [D loss: 0.151007] [G loss: 0.438636]\n",
      "[Epoch 15/200] [Batch 526/637] [D loss: 0.142279] [G loss: 0.461259]\n",
      "[Epoch 15/200] [Batch 527/637] [D loss: 0.158939] [G loss: 0.485614]\n",
      "[Epoch 15/200] [Batch 528/637] [D loss: 0.169210] [G loss: 0.534726]\n",
      "[Epoch 15/200] [Batch 529/637] [D loss: 0.152013] [G loss: 0.552720]\n",
      "[Epoch 15/200] [Batch 530/637] [D loss: 0.172299] [G loss: 0.561828]\n",
      "[Epoch 15/200] [Batch 531/637] [D loss: 0.147167] [G loss: 0.550708]\n",
      "[Epoch 15/200] [Batch 532/637] [D loss: 0.148465] [G loss: 0.497567]\n",
      "[Epoch 15/200] [Batch 533/637] [D loss: 0.154485] [G loss: 0.512168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 534/637] [D loss: 0.147842] [G loss: 0.556454]\n",
      "[Epoch 15/200] [Batch 535/637] [D loss: 0.153801] [G loss: 0.547716]\n",
      "[Epoch 15/200] [Batch 536/637] [D loss: 0.150485] [G loss: 0.541479]\n",
      "[Epoch 15/200] [Batch 537/637] [D loss: 0.129197] [G loss: 0.564498]\n",
      "[Epoch 15/200] [Batch 538/637] [D loss: 0.167631] [G loss: 0.548838]\n",
      "[Epoch 15/200] [Batch 539/637] [D loss: 0.145030] [G loss: 0.540359]\n",
      "[Epoch 15/200] [Batch 540/637] [D loss: 0.136739] [G loss: 0.534439]\n",
      "[Epoch 15/200] [Batch 541/637] [D loss: 0.163477] [G loss: 0.527783]\n",
      "[Epoch 15/200] [Batch 542/637] [D loss: 0.133596] [G loss: 0.556502]\n",
      "[Epoch 15/200] [Batch 543/637] [D loss: 0.146433] [G loss: 0.531512]\n",
      "[Epoch 15/200] [Batch 544/637] [D loss: 0.154273] [G loss: 0.467549]\n",
      "[Epoch 15/200] [Batch 545/637] [D loss: 0.154241] [G loss: 0.554537]\n",
      "[Epoch 15/200] [Batch 546/637] [D loss: 0.138414] [G loss: 0.584472]\n",
      "[Epoch 15/200] [Batch 547/637] [D loss: 0.164972] [G loss: 0.481145]\n",
      "[Epoch 15/200] [Batch 548/637] [D loss: 0.148537] [G loss: 0.483399]\n",
      "[Epoch 15/200] [Batch 549/637] [D loss: 0.163919] [G loss: 0.515341]\n",
      "[Epoch 15/200] [Batch 550/637] [D loss: 0.159548] [G loss: 0.541734]\n",
      "[Epoch 15/200] [Batch 551/637] [D loss: 0.157710] [G loss: 0.524820]\n",
      "[Epoch 15/200] [Batch 552/637] [D loss: 0.165817] [G loss: 0.512664]\n",
      "[Epoch 15/200] [Batch 553/637] [D loss: 0.149343] [G loss: 0.476887]\n",
      "[Epoch 15/200] [Batch 554/637] [D loss: 0.175195] [G loss: 0.448424]\n",
      "[Epoch 15/200] [Batch 555/637] [D loss: 0.170221] [G loss: 0.577393]\n",
      "[Epoch 15/200] [Batch 556/637] [D loss: 0.158914] [G loss: 0.564776]\n",
      "[Epoch 15/200] [Batch 557/637] [D loss: 0.166548] [G loss: 0.477863]\n",
      "[Epoch 15/200] [Batch 558/637] [D loss: 0.163538] [G loss: 0.471795]\n",
      "[Epoch 15/200] [Batch 559/637] [D loss: 0.151518] [G loss: 0.537611]\n",
      "[Epoch 15/200] [Batch 560/637] [D loss: 0.158772] [G loss: 0.505610]\n",
      "[Epoch 15/200] [Batch 561/637] [D loss: 0.159618] [G loss: 0.511809]\n",
      "[Epoch 15/200] [Batch 562/637] [D loss: 0.158843] [G loss: 0.526127]\n",
      "[Epoch 15/200] [Batch 563/637] [D loss: 0.154607] [G loss: 0.510905]\n",
      "[Epoch 15/200] [Batch 564/637] [D loss: 0.162887] [G loss: 0.419941]\n",
      "[Epoch 15/200] [Batch 565/637] [D loss: 0.138299] [G loss: 0.563614]\n",
      "[Epoch 15/200] [Batch 566/637] [D loss: 0.144689] [G loss: 0.543152]\n",
      "[Epoch 15/200] [Batch 567/637] [D loss: 0.138563] [G loss: 0.581395]\n",
      "[Epoch 15/200] [Batch 568/637] [D loss: 0.129214] [G loss: 0.539243]\n",
      "[Epoch 15/200] [Batch 569/637] [D loss: 0.149651] [G loss: 0.524058]\n",
      "[Epoch 15/200] [Batch 570/637] [D loss: 0.165050] [G loss: 0.569513]\n",
      "[Epoch 15/200] [Batch 571/637] [D loss: 0.158528] [G loss: 0.497173]\n",
      "[Epoch 15/200] [Batch 572/637] [D loss: 0.184995] [G loss: 0.519497]\n",
      "[Epoch 15/200] [Batch 573/637] [D loss: 0.164670] [G loss: 0.595030]\n",
      "[Epoch 15/200] [Batch 574/637] [D loss: 0.149751] [G loss: 0.543132]\n",
      "[Epoch 15/200] [Batch 575/637] [D loss: 0.151789] [G loss: 0.500546]\n",
      "[Epoch 15/200] [Batch 576/637] [D loss: 0.143366] [G loss: 0.506971]\n",
      "[Epoch 15/200] [Batch 577/637] [D loss: 0.177840] [G loss: 0.416062]\n",
      "[Epoch 15/200] [Batch 578/637] [D loss: 0.159456] [G loss: 0.567975]\n",
      "[Epoch 15/200] [Batch 579/637] [D loss: 0.156075] [G loss: 0.516726]\n",
      "[Epoch 15/200] [Batch 580/637] [D loss: 0.155125] [G loss: 0.483018]\n",
      "[Epoch 15/200] [Batch 581/637] [D loss: 0.151499] [G loss: 0.462268]\n",
      "[Epoch 15/200] [Batch 582/637] [D loss: 0.139024] [G loss: 0.534818]\n",
      "[Epoch 15/200] [Batch 583/637] [D loss: 0.153601] [G loss: 0.457689]\n",
      "[Epoch 15/200] [Batch 584/637] [D loss: 0.174962] [G loss: 0.456715]\n",
      "[Epoch 15/200] [Batch 585/637] [D loss: 0.183442] [G loss: 0.586033]\n",
      "[Epoch 15/200] [Batch 586/637] [D loss: 0.184027] [G loss: 0.474987]\n",
      "[Epoch 15/200] [Batch 587/637] [D loss: 0.176819] [G loss: 0.503942]\n",
      "[Epoch 15/200] [Batch 588/637] [D loss: 0.166490] [G loss: 0.517317]\n",
      "[Epoch 15/200] [Batch 589/637] [D loss: 0.179155] [G loss: 0.531609]\n",
      "[Epoch 15/200] [Batch 590/637] [D loss: 0.189870] [G loss: 0.532265]\n",
      "[Epoch 15/200] [Batch 591/637] [D loss: 0.199383] [G loss: 0.514802]\n",
      "[Epoch 15/200] [Batch 592/637] [D loss: 0.179389] [G loss: 0.543552]\n",
      "[Epoch 15/200] [Batch 593/637] [D loss: 0.147545] [G loss: 0.513111]\n",
      "[Epoch 15/200] [Batch 594/637] [D loss: 0.153763] [G loss: 0.426326]\n",
      "[Epoch 15/200] [Batch 595/637] [D loss: 0.134121] [G loss: 0.498403]\n",
      "[Epoch 15/200] [Batch 596/637] [D loss: 0.166673] [G loss: 0.492015]\n",
      "[Epoch 15/200] [Batch 597/637] [D loss: 0.143747] [G loss: 0.552661]\n",
      "[Epoch 15/200] [Batch 598/637] [D loss: 0.132661] [G loss: 0.594786]\n",
      "[Epoch 15/200] [Batch 599/637] [D loss: 0.144647] [G loss: 0.534392]\n",
      "[Epoch 15/200] [Batch 600/637] [D loss: 0.157390] [G loss: 0.480698]\n",
      "[Epoch 15/200] [Batch 601/637] [D loss: 0.147236] [G loss: 0.492604]\n",
      "[Epoch 15/200] [Batch 602/637] [D loss: 0.151726] [G loss: 0.478958]\n",
      "[Epoch 15/200] [Batch 603/637] [D loss: 0.150233] [G loss: 0.582964]\n",
      "[Epoch 15/200] [Batch 604/637] [D loss: 0.150770] [G loss: 0.569443]\n",
      "[Epoch 15/200] [Batch 605/637] [D loss: 0.182197] [G loss: 0.491655]\n",
      "[Epoch 15/200] [Batch 606/637] [D loss: 0.149716] [G loss: 0.576137]\n",
      "[Epoch 15/200] [Batch 607/637] [D loss: 0.173174] [G loss: 0.470795]\n",
      "[Epoch 15/200] [Batch 608/637] [D loss: 0.199218] [G loss: 0.660020]\n",
      "[Epoch 15/200] [Batch 609/637] [D loss: 0.149812] [G loss: 0.745513]\n",
      "[Epoch 15/200] [Batch 610/637] [D loss: 0.171110] [G loss: 0.558987]\n",
      "[Epoch 15/200] [Batch 611/637] [D loss: 0.166662] [G loss: 0.479522]\n",
      "[Epoch 15/200] [Batch 612/637] [D loss: 0.152807] [G loss: 0.535966]\n",
      "[Epoch 15/200] [Batch 613/637] [D loss: 0.173921] [G loss: 0.535175]\n",
      "[Epoch 15/200] [Batch 614/637] [D loss: 0.158286] [G loss: 0.499957]\n",
      "[Epoch 15/200] [Batch 615/637] [D loss: 0.171778] [G loss: 0.457063]\n",
      "[Epoch 15/200] [Batch 616/637] [D loss: 0.120233] [G loss: 0.547134]\n",
      "[Epoch 15/200] [Batch 617/637] [D loss: 0.154984] [G loss: 0.479808]\n",
      "[Epoch 15/200] [Batch 618/637] [D loss: 0.172543] [G loss: 0.491877]\n",
      "[Epoch 15/200] [Batch 619/637] [D loss: 0.162757] [G loss: 0.581391]\n",
      "[Epoch 15/200] [Batch 620/637] [D loss: 0.141669] [G loss: 0.528707]\n",
      "[Epoch 15/200] [Batch 621/637] [D loss: 0.173434] [G loss: 0.507639]\n",
      "[Epoch 15/200] [Batch 622/637] [D loss: 0.206917] [G loss: 0.591556]\n",
      "[Epoch 15/200] [Batch 623/637] [D loss: 0.167695] [G loss: 0.543833]\n",
      "[Epoch 15/200] [Batch 624/637] [D loss: 0.150717] [G loss: 0.517805]\n",
      "[Epoch 15/200] [Batch 625/637] [D loss: 0.155387] [G loss: 0.487865]\n",
      "[Epoch 15/200] [Batch 626/637] [D loss: 0.148624] [G loss: 0.541187]\n",
      "[Epoch 15/200] [Batch 627/637] [D loss: 0.154643] [G loss: 0.498457]\n",
      "[Epoch 15/200] [Batch 628/637] [D loss: 0.137628] [G loss: 0.541588]\n",
      "[Epoch 15/200] [Batch 629/637] [D loss: 0.129633] [G loss: 0.542162]\n",
      "[Epoch 15/200] [Batch 630/637] [D loss: 0.140191] [G loss: 0.505194]\n",
      "[Epoch 15/200] [Batch 631/637] [D loss: 0.179247] [G loss: 0.470177]\n",
      "[Epoch 15/200] [Batch 632/637] [D loss: 0.141038] [G loss: 0.570282]\n",
      "[Epoch 15/200] [Batch 633/637] [D loss: 0.124818] [G loss: 0.597782]\n",
      "[Epoch 15/200] [Batch 634/637] [D loss: 0.149150] [G loss: 0.467939]\n",
      "[Epoch 15/200] [Batch 635/637] [D loss: 0.159492] [G loss: 0.457954]\n",
      "[Epoch 15/200] [Batch 636/637] [D loss: 0.206580] [G loss: 0.454801]\n",
      "[Epoch 16/200] [Batch 0/637] [D loss: 0.174446] [G loss: 0.484736]\n",
      "[Epoch 16/200] [Batch 1/637] [D loss: 0.145617] [G loss: 0.661468]\n",
      "[Epoch 16/200] [Batch 2/637] [D loss: 0.144219] [G loss: 0.550849]\n",
      "[Epoch 16/200] [Batch 3/637] [D loss: 0.150015] [G loss: 0.459160]\n",
      "[Epoch 16/200] [Batch 4/637] [D loss: 0.160711] [G loss: 0.509083]\n",
      "[Epoch 16/200] [Batch 5/637] [D loss: 0.173772] [G loss: 0.536867]\n",
      "[Epoch 16/200] [Batch 6/637] [D loss: 0.150400] [G loss: 0.482415]\n",
      "[Epoch 16/200] [Batch 7/637] [D loss: 0.132632] [G loss: 0.620601]\n",
      "[Epoch 16/200] [Batch 8/637] [D loss: 0.148126] [G loss: 0.506151]\n",
      "[Epoch 16/200] [Batch 9/637] [D loss: 0.158173] [G loss: 0.479283]\n",
      "[Epoch 16/200] [Batch 10/637] [D loss: 0.133961] [G loss: 0.479370]\n",
      "[Epoch 16/200] [Batch 11/637] [D loss: 0.141995] [G loss: 0.521286]\n",
      "[Epoch 16/200] [Batch 12/637] [D loss: 0.161263] [G loss: 0.538812]\n",
      "[Epoch 16/200] [Batch 13/637] [D loss: 0.140572] [G loss: 0.537039]\n",
      "[Epoch 16/200] [Batch 14/637] [D loss: 0.138458] [G loss: 0.496407]\n",
      "[Epoch 16/200] [Batch 15/637] [D loss: 0.161215] [G loss: 0.515448]\n",
      "[Epoch 16/200] [Batch 16/637] [D loss: 0.159935] [G loss: 0.454203]\n",
      "[Epoch 16/200] [Batch 17/637] [D loss: 0.156410] [G loss: 0.470441]\n",
      "[Epoch 16/200] [Batch 18/637] [D loss: 0.184272] [G loss: 0.517445]\n",
      "[Epoch 16/200] [Batch 19/637] [D loss: 0.174458] [G loss: 0.588133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 20/637] [D loss: 0.147095] [G loss: 0.563023]\n",
      "[Epoch 16/200] [Batch 21/637] [D loss: 0.164210] [G loss: 0.427081]\n",
      "[Epoch 16/200] [Batch 22/637] [D loss: 0.170741] [G loss: 0.478221]\n",
      "[Epoch 16/200] [Batch 23/637] [D loss: 0.147998] [G loss: 0.507954]\n",
      "[Epoch 16/200] [Batch 24/637] [D loss: 0.177330] [G loss: 0.453914]\n",
      "[Epoch 16/200] [Batch 25/637] [D loss: 0.189813] [G loss: 0.535873]\n",
      "[Epoch 16/200] [Batch 26/637] [D loss: 0.157634] [G loss: 0.526058]\n",
      "[Epoch 16/200] [Batch 27/637] [D loss: 0.155353] [G loss: 0.524977]\n",
      "[Epoch 16/200] [Batch 28/637] [D loss: 0.147305] [G loss: 0.525370]\n",
      "[Epoch 16/200] [Batch 29/637] [D loss: 0.141323] [G loss: 0.517093]\n",
      "[Epoch 16/200] [Batch 30/637] [D loss: 0.166948] [G loss: 0.481123]\n",
      "[Epoch 16/200] [Batch 31/637] [D loss: 0.175478] [G loss: 0.420762]\n",
      "[Epoch 16/200] [Batch 32/637] [D loss: 0.163162] [G loss: 0.514575]\n",
      "[Epoch 16/200] [Batch 33/637] [D loss: 0.175328] [G loss: 0.419538]\n",
      "[Epoch 16/200] [Batch 34/637] [D loss: 0.172526] [G loss: 0.566291]\n",
      "[Epoch 16/200] [Batch 35/637] [D loss: 0.178746] [G loss: 0.492095]\n",
      "[Epoch 16/200] [Batch 36/637] [D loss: 0.166668] [G loss: 0.536639]\n",
      "[Epoch 16/200] [Batch 37/637] [D loss: 0.149522] [G loss: 0.532459]\n",
      "[Epoch 16/200] [Batch 38/637] [D loss: 0.169286] [G loss: 0.466955]\n",
      "[Epoch 16/200] [Batch 39/637] [D loss: 0.168240] [G loss: 0.535032]\n",
      "[Epoch 16/200] [Batch 40/637] [D loss: 0.165010] [G loss: 0.480515]\n",
      "[Epoch 16/200] [Batch 41/637] [D loss: 0.150837] [G loss: 0.506638]\n",
      "[Epoch 16/200] [Batch 42/637] [D loss: 0.153472] [G loss: 0.535433]\n",
      "[Epoch 16/200] [Batch 43/637] [D loss: 0.159985] [G loss: 0.505188]\n",
      "[Epoch 16/200] [Batch 44/637] [D loss: 0.144165] [G loss: 0.493139]\n",
      "[Epoch 16/200] [Batch 45/637] [D loss: 0.173321] [G loss: 0.481403]\n",
      "[Epoch 16/200] [Batch 46/637] [D loss: 0.122756] [G loss: 0.539497]\n",
      "[Epoch 16/200] [Batch 47/637] [D loss: 0.149324] [G loss: 0.501805]\n",
      "[Epoch 16/200] [Batch 48/637] [D loss: 0.163289] [G loss: 0.508790]\n",
      "[Epoch 16/200] [Batch 49/637] [D loss: 0.179928] [G loss: 0.432504]\n",
      "[Epoch 16/200] [Batch 50/637] [D loss: 0.175021] [G loss: 0.570279]\n",
      "[Epoch 16/200] [Batch 51/637] [D loss: 0.168463] [G loss: 0.624647]\n",
      "[Epoch 16/200] [Batch 52/637] [D loss: 0.154610] [G loss: 0.581741]\n",
      "[Epoch 16/200] [Batch 53/637] [D loss: 0.165869] [G loss: 0.467554]\n",
      "[Epoch 16/200] [Batch 54/637] [D loss: 0.166328] [G loss: 0.484872]\n",
      "[Epoch 16/200] [Batch 55/637] [D loss: 0.166100] [G loss: 0.501916]\n",
      "[Epoch 16/200] [Batch 56/637] [D loss: 0.181138] [G loss: 0.481625]\n",
      "[Epoch 16/200] [Batch 57/637] [D loss: 0.155068] [G loss: 0.624696]\n",
      "[Epoch 16/200] [Batch 58/637] [D loss: 0.153927] [G loss: 0.573784]\n",
      "[Epoch 16/200] [Batch 59/637] [D loss: 0.166241] [G loss: 0.498555]\n",
      "[Epoch 16/200] [Batch 60/637] [D loss: 0.154841] [G loss: 0.539929]\n",
      "[Epoch 16/200] [Batch 61/637] [D loss: 0.159848] [G loss: 0.519974]\n",
      "[Epoch 16/200] [Batch 62/637] [D loss: 0.168757] [G loss: 0.498117]\n",
      "[Epoch 16/200] [Batch 63/637] [D loss: 0.176590] [G loss: 0.467027]\n",
      "[Epoch 16/200] [Batch 64/637] [D loss: 0.171055] [G loss: 0.506867]\n",
      "[Epoch 16/200] [Batch 65/637] [D loss: 0.162852] [G loss: 0.504145]\n",
      "[Epoch 16/200] [Batch 66/637] [D loss: 0.187527] [G loss: 0.465847]\n",
      "[Epoch 16/200] [Batch 67/637] [D loss: 0.205003] [G loss: 0.515312]\n",
      "[Epoch 16/200] [Batch 68/637] [D loss: 0.168869] [G loss: 0.574795]\n",
      "[Epoch 16/200] [Batch 69/637] [D loss: 0.156810] [G loss: 0.563085]\n",
      "[Epoch 16/200] [Batch 70/637] [D loss: 0.159838] [G loss: 0.465683]\n",
      "[Epoch 16/200] [Batch 71/637] [D loss: 0.150856] [G loss: 0.455238]\n",
      "[Epoch 16/200] [Batch 72/637] [D loss: 0.154386] [G loss: 0.490958]\n",
      "[Epoch 16/200] [Batch 73/637] [D loss: 0.163854] [G loss: 0.463832]\n",
      "[Epoch 16/200] [Batch 74/637] [D loss: 0.146746] [G loss: 0.591138]\n",
      "[Epoch 16/200] [Batch 75/637] [D loss: 0.122524] [G loss: 0.551080]\n",
      "[Epoch 16/200] [Batch 76/637] [D loss: 0.155053] [G loss: 0.469403]\n",
      "[Epoch 16/200] [Batch 77/637] [D loss: 0.143689] [G loss: 0.514174]\n",
      "[Epoch 16/200] [Batch 78/637] [D loss: 0.139416] [G loss: 0.547683]\n",
      "[Epoch 16/200] [Batch 79/637] [D loss: 0.130255] [G loss: 0.558024]\n",
      "[Epoch 16/200] [Batch 80/637] [D loss: 0.149564] [G loss: 0.539567]\n",
      "[Epoch 16/200] [Batch 81/637] [D loss: 0.153354] [G loss: 0.485880]\n",
      "[Epoch 16/200] [Batch 82/637] [D loss: 0.135520] [G loss: 0.529619]\n",
      "[Epoch 16/200] [Batch 83/637] [D loss: 0.176752] [G loss: 0.509807]\n",
      "[Epoch 16/200] [Batch 84/637] [D loss: 0.133472] [G loss: 0.595730]\n",
      "[Epoch 16/200] [Batch 85/637] [D loss: 0.158701] [G loss: 0.583582]\n",
      "[Epoch 16/200] [Batch 86/637] [D loss: 0.144390] [G loss: 0.537661]\n",
      "[Epoch 16/200] [Batch 87/637] [D loss: 0.175382] [G loss: 0.541345]\n",
      "[Epoch 16/200] [Batch 88/637] [D loss: 0.158252] [G loss: 0.507648]\n",
      "[Epoch 16/200] [Batch 89/637] [D loss: 0.164375] [G loss: 0.536893]\n",
      "[Epoch 16/200] [Batch 90/637] [D loss: 0.203606] [G loss: 0.622227]\n",
      "[Epoch 16/200] [Batch 91/637] [D loss: 0.183544] [G loss: 0.528105]\n",
      "[Epoch 16/200] [Batch 92/637] [D loss: 0.196606] [G loss: 0.420541]\n",
      "[Epoch 16/200] [Batch 93/637] [D loss: 0.171741] [G loss: 0.459176]\n",
      "[Epoch 16/200] [Batch 94/637] [D loss: 0.168834] [G loss: 0.487097]\n",
      "[Epoch 16/200] [Batch 95/637] [D loss: 0.162643] [G loss: 0.449772]\n",
      "[Epoch 16/200] [Batch 96/637] [D loss: 0.160115] [G loss: 0.431036]\n",
      "[Epoch 16/200] [Batch 97/637] [D loss: 0.168617] [G loss: 0.418512]\n",
      "[Epoch 16/200] [Batch 98/637] [D loss: 0.153383] [G loss: 0.465299]\n",
      "[Epoch 16/200] [Batch 99/637] [D loss: 0.163433] [G loss: 0.479105]\n",
      "[Epoch 16/200] [Batch 100/637] [D loss: 0.146011] [G loss: 0.518510]\n",
      "[Epoch 16/200] [Batch 101/637] [D loss: 0.143371] [G loss: 0.505929]\n",
      "[Epoch 16/200] [Batch 102/637] [D loss: 0.152315] [G loss: 0.475953]\n",
      "[Epoch 16/200] [Batch 103/637] [D loss: 0.161986] [G loss: 0.504321]\n",
      "[Epoch 16/200] [Batch 104/637] [D loss: 0.153020] [G loss: 0.486411]\n",
      "[Epoch 16/200] [Batch 105/637] [D loss: 0.141979] [G loss: 0.546202]\n",
      "[Epoch 16/200] [Batch 106/637] [D loss: 0.173059] [G loss: 0.523535]\n",
      "[Epoch 16/200] [Batch 107/637] [D loss: 0.170032] [G loss: 0.522429]\n",
      "[Epoch 16/200] [Batch 108/637] [D loss: 0.183131] [G loss: 0.450275]\n",
      "[Epoch 16/200] [Batch 109/637] [D loss: 0.171506] [G loss: 0.499770]\n",
      "[Epoch 16/200] [Batch 110/637] [D loss: 0.171650] [G loss: 0.491226]\n",
      "[Epoch 16/200] [Batch 111/637] [D loss: 0.140172] [G loss: 0.516967]\n",
      "[Epoch 16/200] [Batch 112/637] [D loss: 0.160050] [G loss: 0.531962]\n",
      "[Epoch 16/200] [Batch 113/637] [D loss: 0.165943] [G loss: 0.503061]\n",
      "[Epoch 16/200] [Batch 114/637] [D loss: 0.141539] [G loss: 0.465592]\n",
      "[Epoch 16/200] [Batch 115/637] [D loss: 0.169889] [G loss: 0.477790]\n",
      "[Epoch 16/200] [Batch 116/637] [D loss: 0.158052] [G loss: 0.516920]\n",
      "[Epoch 16/200] [Batch 117/637] [D loss: 0.152584] [G loss: 0.512387]\n",
      "[Epoch 16/200] [Batch 118/637] [D loss: 0.190238] [G loss: 0.460108]\n",
      "[Epoch 16/200] [Batch 119/637] [D loss: 0.157361] [G loss: 0.443694]\n",
      "[Epoch 16/200] [Batch 120/637] [D loss: 0.145368] [G loss: 0.546224]\n",
      "[Epoch 16/200] [Batch 121/637] [D loss: 0.166593] [G loss: 0.494470]\n",
      "[Epoch 16/200] [Batch 122/637] [D loss: 0.155721] [G loss: 0.537553]\n",
      "[Epoch 16/200] [Batch 123/637] [D loss: 0.175411] [G loss: 0.490724]\n",
      "[Epoch 16/200] [Batch 124/637] [D loss: 0.152246] [G loss: 0.508204]\n",
      "[Epoch 16/200] [Batch 125/637] [D loss: 0.157806] [G loss: 0.554844]\n",
      "[Epoch 16/200] [Batch 126/637] [D loss: 0.171266] [G loss: 0.525026]\n",
      "[Epoch 16/200] [Batch 127/637] [D loss: 0.162739] [G loss: 0.502130]\n",
      "[Epoch 16/200] [Batch 128/637] [D loss: 0.150052] [G loss: 0.528999]\n",
      "[Epoch 16/200] [Batch 129/637] [D loss: 0.145939] [G loss: 0.483999]\n",
      "[Epoch 16/200] [Batch 130/637] [D loss: 0.176457] [G loss: 0.455658]\n",
      "[Epoch 16/200] [Batch 131/637] [D loss: 0.145007] [G loss: 0.584415]\n",
      "[Epoch 16/200] [Batch 132/637] [D loss: 0.157736] [G loss: 0.549030]\n",
      "[Epoch 16/200] [Batch 133/637] [D loss: 0.142661] [G loss: 0.584055]\n",
      "[Epoch 16/200] [Batch 134/637] [D loss: 0.159852] [G loss: 0.483899]\n",
      "[Epoch 16/200] [Batch 135/637] [D loss: 0.186990] [G loss: 0.466004]\n",
      "[Epoch 16/200] [Batch 136/637] [D loss: 0.174122] [G loss: 0.498575]\n",
      "[Epoch 16/200] [Batch 137/637] [D loss: 0.141881] [G loss: 0.580713]\n",
      "[Epoch 16/200] [Batch 138/637] [D loss: 0.156455] [G loss: 0.526967]\n",
      "[Epoch 16/200] [Batch 139/637] [D loss: 0.181691] [G loss: 0.491203]\n",
      "[Epoch 16/200] [Batch 140/637] [D loss: 0.158733] [G loss: 0.468930]\n",
      "[Epoch 16/200] [Batch 141/637] [D loss: 0.179447] [G loss: 0.528588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 142/637] [D loss: 0.146939] [G loss: 0.528768]\n",
      "[Epoch 16/200] [Batch 143/637] [D loss: 0.156524] [G loss: 0.530078]\n",
      "[Epoch 16/200] [Batch 144/637] [D loss: 0.142665] [G loss: 0.477444]\n",
      "[Epoch 16/200] [Batch 145/637] [D loss: 0.159306] [G loss: 0.516228]\n",
      "[Epoch 16/200] [Batch 146/637] [D loss: 0.148051] [G loss: 0.576123]\n",
      "[Epoch 16/200] [Batch 147/637] [D loss: 0.134538] [G loss: 0.622788]\n",
      "[Epoch 16/200] [Batch 148/637] [D loss: 0.147544] [G loss: 0.586024]\n",
      "[Epoch 16/200] [Batch 149/637] [D loss: 0.157608] [G loss: 0.498034]\n",
      "[Epoch 16/200] [Batch 150/637] [D loss: 0.156108] [G loss: 0.455836]\n",
      "[Epoch 16/200] [Batch 151/637] [D loss: 0.184078] [G loss: 0.595248]\n",
      "[Epoch 16/200] [Batch 152/637] [D loss: 0.185496] [G loss: 0.586893]\n",
      "[Epoch 16/200] [Batch 153/637] [D loss: 0.176684] [G loss: 0.503800]\n",
      "[Epoch 16/200] [Batch 154/637] [D loss: 0.160692] [G loss: 0.494817]\n",
      "[Epoch 16/200] [Batch 155/637] [D loss: 0.174140] [G loss: 0.424508]\n",
      "[Epoch 16/200] [Batch 156/637] [D loss: 0.154313] [G loss: 0.475455]\n",
      "[Epoch 16/200] [Batch 157/637] [D loss: 0.153964] [G loss: 0.526450]\n",
      "[Epoch 16/200] [Batch 158/637] [D loss: 0.170565] [G loss: 0.485581]\n",
      "[Epoch 16/200] [Batch 159/637] [D loss: 0.183912] [G loss: 0.431066]\n",
      "[Epoch 16/200] [Batch 160/637] [D loss: 0.166530] [G loss: 0.453341]\n",
      "[Epoch 16/200] [Batch 161/637] [D loss: 0.174994] [G loss: 0.448166]\n",
      "[Epoch 16/200] [Batch 162/637] [D loss: 0.188686] [G loss: 0.492075]\n",
      "[Epoch 16/200] [Batch 163/637] [D loss: 0.183360] [G loss: 0.474205]\n",
      "[Epoch 16/200] [Batch 164/637] [D loss: 0.165065] [G loss: 0.512787]\n",
      "[Epoch 16/200] [Batch 165/637] [D loss: 0.153556] [G loss: 0.434369]\n",
      "[Epoch 16/200] [Batch 166/637] [D loss: 0.136927] [G loss: 0.453126]\n",
      "[Epoch 16/200] [Batch 167/637] [D loss: 0.149958] [G loss: 0.491338]\n",
      "[Epoch 16/200] [Batch 168/637] [D loss: 0.171211] [G loss: 0.434489]\n",
      "[Epoch 16/200] [Batch 169/637] [D loss: 0.153914] [G loss: 0.524468]\n",
      "[Epoch 16/200] [Batch 170/637] [D loss: 0.148631] [G loss: 0.577435]\n",
      "[Epoch 16/200] [Batch 171/637] [D loss: 0.164564] [G loss: 0.558862]\n",
      "[Epoch 16/200] [Batch 172/637] [D loss: 0.162221] [G loss: 0.579390]\n",
      "[Epoch 16/200] [Batch 173/637] [D loss: 0.135725] [G loss: 0.600058]\n",
      "[Epoch 16/200] [Batch 174/637] [D loss: 0.163888] [G loss: 0.476744]\n",
      "[Epoch 16/200] [Batch 175/637] [D loss: 0.158303] [G loss: 0.504474]\n",
      "[Epoch 16/200] [Batch 176/637] [D loss: 0.152789] [G loss: 0.451954]\n",
      "[Epoch 16/200] [Batch 177/637] [D loss: 0.139347] [G loss: 0.502945]\n",
      "[Epoch 16/200] [Batch 178/637] [D loss: 0.137596] [G loss: 0.523768]\n",
      "[Epoch 16/200] [Batch 179/637] [D loss: 0.160915] [G loss: 0.555591]\n",
      "[Epoch 16/200] [Batch 180/637] [D loss: 0.142341] [G loss: 0.554229]\n",
      "[Epoch 16/200] [Batch 181/637] [D loss: 0.160084] [G loss: 0.514902]\n",
      "[Epoch 16/200] [Batch 182/637] [D loss: 0.180743] [G loss: 0.576554]\n",
      "[Epoch 16/200] [Batch 183/637] [D loss: 0.167120] [G loss: 0.469921]\n",
      "[Epoch 16/200] [Batch 184/637] [D loss: 0.164575] [G loss: 0.469611]\n",
      "[Epoch 16/200] [Batch 185/637] [D loss: 0.145114] [G loss: 0.480172]\n",
      "[Epoch 16/200] [Batch 186/637] [D loss: 0.161435] [G loss: 0.411010]\n",
      "[Epoch 16/200] [Batch 187/637] [D loss: 0.145371] [G loss: 0.519068]\n",
      "[Epoch 16/200] [Batch 188/637] [D loss: 0.135440] [G loss: 0.503502]\n",
      "[Epoch 16/200] [Batch 189/637] [D loss: 0.152986] [G loss: 0.447787]\n",
      "[Epoch 16/200] [Batch 190/637] [D loss: 0.164046] [G loss: 0.558178]\n",
      "[Epoch 16/200] [Batch 191/637] [D loss: 0.149298] [G loss: 0.545184]\n",
      "[Epoch 16/200] [Batch 192/637] [D loss: 0.174436] [G loss: 0.479926]\n",
      "[Epoch 16/200] [Batch 193/637] [D loss: 0.176735] [G loss: 0.535371]\n",
      "[Epoch 16/200] [Batch 194/637] [D loss: 0.150213] [G loss: 0.541472]\n",
      "[Epoch 16/200] [Batch 195/637] [D loss: 0.156410] [G loss: 0.462193]\n",
      "[Epoch 16/200] [Batch 196/637] [D loss: 0.160790] [G loss: 0.484368]\n",
      "[Epoch 16/200] [Batch 197/637] [D loss: 0.159006] [G loss: 0.485611]\n",
      "[Epoch 16/200] [Batch 198/637] [D loss: 0.144662] [G loss: 0.489122]\n",
      "[Epoch 16/200] [Batch 199/637] [D loss: 0.158329] [G loss: 0.523604]\n",
      "[Epoch 16/200] [Batch 200/637] [D loss: 0.154819] [G loss: 0.501215]\n",
      "[Epoch 16/200] [Batch 201/637] [D loss: 0.143917] [G loss: 0.574215]\n",
      "[Epoch 16/200] [Batch 202/637] [D loss: 0.140371] [G loss: 0.516570]\n",
      "[Epoch 16/200] [Batch 203/637] [D loss: 0.151363] [G loss: 0.455091]\n",
      "[Epoch 16/200] [Batch 204/637] [D loss: 0.157770] [G loss: 0.553408]\n",
      "[Epoch 16/200] [Batch 205/637] [D loss: 0.118455] [G loss: 0.776067]\n",
      "[Epoch 16/200] [Batch 206/637] [D loss: 0.146660] [G loss: 0.537060]\n",
      "[Epoch 16/200] [Batch 207/637] [D loss: 0.183461] [G loss: 0.541547]\n",
      "[Epoch 16/200] [Batch 208/637] [D loss: 0.175634] [G loss: 0.577979]\n",
      "[Epoch 16/200] [Batch 209/637] [D loss: 0.157231] [G loss: 0.562064]\n",
      "[Epoch 16/200] [Batch 210/637] [D loss: 0.170040] [G loss: 0.423875]\n",
      "[Epoch 16/200] [Batch 211/637] [D loss: 0.180185] [G loss: 0.459855]\n",
      "[Epoch 16/200] [Batch 212/637] [D loss: 0.167525] [G loss: 0.537827]\n",
      "[Epoch 16/200] [Batch 213/637] [D loss: 0.183517] [G loss: 0.497728]\n",
      "[Epoch 16/200] [Batch 214/637] [D loss: 0.186019] [G loss: 0.480838]\n",
      "[Epoch 16/200] [Batch 215/637] [D loss: 0.162896] [G loss: 0.459770]\n",
      "[Epoch 16/200] [Batch 216/637] [D loss: 0.174038] [G loss: 0.487898]\n",
      "[Epoch 16/200] [Batch 217/637] [D loss: 0.138283] [G loss: 0.540874]\n",
      "[Epoch 16/200] [Batch 218/637] [D loss: 0.166898] [G loss: 0.493825]\n",
      "[Epoch 16/200] [Batch 219/637] [D loss: 0.155719] [G loss: 0.504989]\n",
      "[Epoch 16/200] [Batch 220/637] [D loss: 0.185462] [G loss: 0.472027]\n",
      "[Epoch 16/200] [Batch 221/637] [D loss: 0.165238] [G loss: 0.510205]\n",
      "[Epoch 16/200] [Batch 222/637] [D loss: 0.170464] [G loss: 0.470339]\n",
      "[Epoch 16/200] [Batch 223/637] [D loss: 0.123684] [G loss: 0.531124]\n",
      "[Epoch 16/200] [Batch 224/637] [D loss: 0.185358] [G loss: 0.512047]\n",
      "[Epoch 16/200] [Batch 225/637] [D loss: 0.148003] [G loss: 0.562564]\n",
      "[Epoch 16/200] [Batch 226/637] [D loss: 0.154839] [G loss: 0.492132]\n",
      "[Epoch 16/200] [Batch 227/637] [D loss: 0.157095] [G loss: 0.482570]\n",
      "[Epoch 16/200] [Batch 228/637] [D loss: 0.148179] [G loss: 0.564748]\n",
      "[Epoch 16/200] [Batch 229/637] [D loss: 0.156931] [G loss: 0.497716]\n",
      "[Epoch 16/200] [Batch 230/637] [D loss: 0.159269] [G loss: 0.480125]\n",
      "[Epoch 16/200] [Batch 231/637] [D loss: 0.155570] [G loss: 0.476396]\n",
      "[Epoch 16/200] [Batch 232/637] [D loss: 0.163885] [G loss: 0.530146]\n",
      "[Epoch 16/200] [Batch 233/637] [D loss: 0.171305] [G loss: 0.519971]\n",
      "[Epoch 16/200] [Batch 234/637] [D loss: 0.159604] [G loss: 0.589014]\n",
      "[Epoch 16/200] [Batch 235/637] [D loss: 0.172564] [G loss: 0.519795]\n",
      "[Epoch 16/200] [Batch 236/637] [D loss: 0.157101] [G loss: 0.444482]\n",
      "[Epoch 16/200] [Batch 237/637] [D loss: 0.149615] [G loss: 0.494616]\n",
      "[Epoch 16/200] [Batch 238/637] [D loss: 0.165051] [G loss: 0.519735]\n",
      "[Epoch 16/200] [Batch 239/637] [D loss: 0.161582] [G loss: 0.583062]\n",
      "[Epoch 16/200] [Batch 240/637] [D loss: 0.149661] [G loss: 0.540684]\n",
      "[Epoch 16/200] [Batch 241/637] [D loss: 0.157108] [G loss: 0.472480]\n",
      "[Epoch 16/200] [Batch 242/637] [D loss: 0.150209] [G loss: 0.482886]\n",
      "[Epoch 16/200] [Batch 243/637] [D loss: 0.151225] [G loss: 0.539352]\n",
      "[Epoch 16/200] [Batch 244/637] [D loss: 0.149879] [G loss: 0.494892]\n",
      "[Epoch 16/200] [Batch 245/637] [D loss: 0.160477] [G loss: 0.525064]\n",
      "[Epoch 16/200] [Batch 246/637] [D loss: 0.146003] [G loss: 0.550476]\n",
      "[Epoch 16/200] [Batch 247/637] [D loss: 0.165185] [G loss: 0.476264]\n",
      "[Epoch 16/200] [Batch 248/637] [D loss: 0.152535] [G loss: 0.581455]\n",
      "[Epoch 16/200] [Batch 249/637] [D loss: 0.156745] [G loss: 0.477776]\n",
      "[Epoch 16/200] [Batch 250/637] [D loss: 0.173904] [G loss: 0.552394]\n",
      "[Epoch 16/200] [Batch 251/637] [D loss: 0.164211] [G loss: 0.503687]\n",
      "[Epoch 16/200] [Batch 252/637] [D loss: 0.156417] [G loss: 0.472654]\n",
      "[Epoch 16/200] [Batch 253/637] [D loss: 0.169236] [G loss: 0.503879]\n",
      "[Epoch 16/200] [Batch 254/637] [D loss: 0.157400] [G loss: 0.513199]\n",
      "[Epoch 16/200] [Batch 255/637] [D loss: 0.156970] [G loss: 0.482301]\n",
      "[Epoch 16/200] [Batch 256/637] [D loss: 0.158242] [G loss: 0.509281]\n",
      "[Epoch 16/200] [Batch 257/637] [D loss: 0.185513] [G loss: 0.509847]\n",
      "[Epoch 16/200] [Batch 258/637] [D loss: 0.172106] [G loss: 0.535634]\n",
      "[Epoch 16/200] [Batch 259/637] [D loss: 0.162654] [G loss: 0.500163]\n",
      "[Epoch 16/200] [Batch 260/637] [D loss: 0.166572] [G loss: 0.465252]\n",
      "[Epoch 16/200] [Batch 261/637] [D loss: 0.173386] [G loss: 0.440586]\n",
      "[Epoch 16/200] [Batch 262/637] [D loss: 0.179945] [G loss: 0.433861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 263/637] [D loss: 0.205407] [G loss: 0.383070]\n",
      "[Epoch 16/200] [Batch 264/637] [D loss: 0.162606] [G loss: 0.602500]\n",
      "[Epoch 16/200] [Batch 265/637] [D loss: 0.159764] [G loss: 0.546919]\n",
      "[Epoch 16/200] [Batch 266/637] [D loss: 0.151726] [G loss: 0.498199]\n",
      "[Epoch 16/200] [Batch 267/637] [D loss: 0.157730] [G loss: 0.551605]\n",
      "[Epoch 16/200] [Batch 268/637] [D loss: 0.168614] [G loss: 0.528128]\n",
      "[Epoch 16/200] [Batch 269/637] [D loss: 0.130549] [G loss: 0.526049]\n",
      "[Epoch 16/200] [Batch 270/637] [D loss: 0.142805] [G loss: 0.501216]\n",
      "[Epoch 16/200] [Batch 271/637] [D loss: 0.140249] [G loss: 0.514318]\n",
      "[Epoch 16/200] [Batch 272/637] [D loss: 0.151843] [G loss: 0.594571]\n",
      "[Epoch 16/200] [Batch 273/637] [D loss: 0.132221] [G loss: 0.587207]\n",
      "[Epoch 16/200] [Batch 274/637] [D loss: 0.145282] [G loss: 0.491547]\n",
      "[Epoch 16/200] [Batch 275/637] [D loss: 0.140252] [G loss: 0.526319]\n",
      "[Epoch 16/200] [Batch 276/637] [D loss: 0.128913] [G loss: 0.567534]\n",
      "[Epoch 16/200] [Batch 277/637] [D loss: 0.121155] [G loss: 0.545498]\n",
      "[Epoch 16/200] [Batch 278/637] [D loss: 0.159925] [G loss: 0.456283]\n",
      "[Epoch 16/200] [Batch 279/637] [D loss: 0.160471] [G loss: 0.589562]\n",
      "[Epoch 16/200] [Batch 280/637] [D loss: 0.148407] [G loss: 0.572783]\n",
      "[Epoch 16/200] [Batch 281/637] [D loss: 0.148763] [G loss: 0.488898]\n",
      "[Epoch 16/200] [Batch 282/637] [D loss: 0.157728] [G loss: 0.529287]\n",
      "[Epoch 16/200] [Batch 283/637] [D loss: 0.152586] [G loss: 0.570547]\n",
      "[Epoch 16/200] [Batch 284/637] [D loss: 0.138199] [G loss: 0.455631]\n",
      "[Epoch 16/200] [Batch 285/637] [D loss: 0.174820] [G loss: 0.473092]\n",
      "[Epoch 16/200] [Batch 286/637] [D loss: 0.186131] [G loss: 0.547866]\n",
      "[Epoch 16/200] [Batch 287/637] [D loss: 0.166028] [G loss: 0.504544]\n",
      "[Epoch 16/200] [Batch 288/637] [D loss: 0.147845] [G loss: 0.450771]\n",
      "[Epoch 16/200] [Batch 289/637] [D loss: 0.143992] [G loss: 0.474824]\n",
      "[Epoch 16/200] [Batch 290/637] [D loss: 0.143719] [G loss: 0.465001]\n",
      "[Epoch 16/200] [Batch 291/637] [D loss: 0.172991] [G loss: 0.475640]\n",
      "[Epoch 16/200] [Batch 292/637] [D loss: 0.138865] [G loss: 0.549581]\n",
      "[Epoch 16/200] [Batch 293/637] [D loss: 0.171824] [G loss: 0.500782]\n",
      "[Epoch 16/200] [Batch 294/637] [D loss: 0.166231] [G loss: 0.494259]\n",
      "[Epoch 16/200] [Batch 295/637] [D loss: 0.160966] [G loss: 0.460512]\n",
      "[Epoch 16/200] [Batch 296/637] [D loss: 0.194708] [G loss: 0.422818]\n",
      "[Epoch 16/200] [Batch 297/637] [D loss: 0.149312] [G loss: 0.523380]\n",
      "[Epoch 16/200] [Batch 298/637] [D loss: 0.184730] [G loss: 0.439535]\n",
      "[Epoch 16/200] [Batch 299/637] [D loss: 0.148129] [G loss: 0.472811]\n",
      "[Epoch 16/200] [Batch 300/637] [D loss: 0.159408] [G loss: 0.456434]\n",
      "[Epoch 16/200] [Batch 301/637] [D loss: 0.170322] [G loss: 0.407102]\n",
      "[Epoch 16/200] [Batch 302/637] [D loss: 0.174834] [G loss: 0.474878]\n",
      "[Epoch 16/200] [Batch 303/637] [D loss: 0.193930] [G loss: 0.425453]\n",
      "[Epoch 16/200] [Batch 304/637] [D loss: 0.164021] [G loss: 0.568556]\n",
      "[Epoch 16/200] [Batch 305/637] [D loss: 0.152441] [G loss: 0.551078]\n",
      "[Epoch 16/200] [Batch 306/637] [D loss: 0.170846] [G loss: 0.471766]\n",
      "[Epoch 16/200] [Batch 307/637] [D loss: 0.150168] [G loss: 0.542423]\n",
      "[Epoch 16/200] [Batch 308/637] [D loss: 0.130921] [G loss: 0.575308]\n",
      "[Epoch 16/200] [Batch 309/637] [D loss: 0.183912] [G loss: 0.440711]\n",
      "[Epoch 16/200] [Batch 310/637] [D loss: 0.147193] [G loss: 0.504669]\n",
      "[Epoch 16/200] [Batch 311/637] [D loss: 0.153000] [G loss: 0.514542]\n",
      "[Epoch 16/200] [Batch 312/637] [D loss: 0.121596] [G loss: 0.537893]\n",
      "[Epoch 16/200] [Batch 313/637] [D loss: 0.158532] [G loss: 0.508741]\n",
      "[Epoch 16/200] [Batch 314/637] [D loss: 0.161187] [G loss: 0.456898]\n",
      "[Epoch 16/200] [Batch 315/637] [D loss: 0.135402] [G loss: 0.607485]\n",
      "[Epoch 16/200] [Batch 316/637] [D loss: 0.143297] [G loss: 0.657770]\n",
      "[Epoch 16/200] [Batch 317/637] [D loss: 0.135091] [G loss: 0.602809]\n",
      "[Epoch 16/200] [Batch 318/637] [D loss: 0.146548] [G loss: 0.562886]\n",
      "[Epoch 16/200] [Batch 319/637] [D loss: 0.141822] [G loss: 0.564551]\n",
      "[Epoch 16/200] [Batch 320/637] [D loss: 0.137292] [G loss: 0.452492]\n",
      "[Epoch 16/200] [Batch 321/637] [D loss: 0.135543] [G loss: 0.515757]\n",
      "[Epoch 16/200] [Batch 322/637] [D loss: 0.147477] [G loss: 0.493225]\n",
      "[Epoch 16/200] [Batch 323/637] [D loss: 0.159523] [G loss: 0.558034]\n",
      "[Epoch 16/200] [Batch 324/637] [D loss: 0.152756] [G loss: 0.491802]\n",
      "[Epoch 16/200] [Batch 325/637] [D loss: 0.156134] [G loss: 0.542751]\n",
      "[Epoch 16/200] [Batch 326/637] [D loss: 0.199501] [G loss: 0.499460]\n",
      "[Epoch 16/200] [Batch 327/637] [D loss: 0.166283] [G loss: 0.505774]\n",
      "[Epoch 16/200] [Batch 328/637] [D loss: 0.144095] [G loss: 0.537715]\n",
      "[Epoch 16/200] [Batch 329/637] [D loss: 0.130037] [G loss: 0.538757]\n",
      "[Epoch 16/200] [Batch 330/637] [D loss: 0.169998] [G loss: 0.439803]\n",
      "[Epoch 16/200] [Batch 331/637] [D loss: 0.172302] [G loss: 0.413455]\n",
      "[Epoch 16/200] [Batch 332/637] [D loss: 0.150873] [G loss: 0.536449]\n",
      "[Epoch 16/200] [Batch 333/637] [D loss: 0.148908] [G loss: 0.567092]\n",
      "[Epoch 16/200] [Batch 334/637] [D loss: 0.166728] [G loss: 0.527129]\n",
      "[Epoch 16/200] [Batch 335/637] [D loss: 0.155135] [G loss: 0.471857]\n",
      "[Epoch 16/200] [Batch 336/637] [D loss: 0.174131] [G loss: 0.472449]\n",
      "[Epoch 16/200] [Batch 337/637] [D loss: 0.160617] [G loss: 0.521074]\n",
      "[Epoch 16/200] [Batch 338/637] [D loss: 0.148668] [G loss: 0.540663]\n",
      "[Epoch 16/200] [Batch 339/637] [D loss: 0.178520] [G loss: 0.453551]\n",
      "[Epoch 16/200] [Batch 340/637] [D loss: 0.168873] [G loss: 0.574116]\n",
      "[Epoch 16/200] [Batch 341/637] [D loss: 0.175161] [G loss: 0.488784]\n",
      "[Epoch 16/200] [Batch 342/637] [D loss: 0.167345] [G loss: 0.470346]\n",
      "[Epoch 16/200] [Batch 343/637] [D loss: 0.160802] [G loss: 0.484947]\n",
      "[Epoch 16/200] [Batch 344/637] [D loss: 0.162580] [G loss: 0.635890]\n",
      "[Epoch 16/200] [Batch 345/637] [D loss: 0.161755] [G loss: 0.558878]\n",
      "[Epoch 16/200] [Batch 346/637] [D loss: 0.173726] [G loss: 0.421815]\n",
      "[Epoch 16/200] [Batch 347/637] [D loss: 0.170253] [G loss: 0.556316]\n",
      "[Epoch 16/200] [Batch 348/637] [D loss: 0.142906] [G loss: 0.617268]\n",
      "[Epoch 16/200] [Batch 349/637] [D loss: 0.214619] [G loss: 0.460672]\n",
      "[Epoch 16/200] [Batch 350/637] [D loss: 0.173068] [G loss: 0.596175]\n",
      "[Epoch 16/200] [Batch 351/637] [D loss: 0.160465] [G loss: 0.490375]\n",
      "[Epoch 16/200] [Batch 352/637] [D loss: 0.183055] [G loss: 0.406514]\n",
      "[Epoch 16/200] [Batch 353/637] [D loss: 0.156580] [G loss: 0.569176]\n",
      "[Epoch 16/200] [Batch 354/637] [D loss: 0.141287] [G loss: 0.619096]\n",
      "[Epoch 16/200] [Batch 355/637] [D loss: 0.144163] [G loss: 0.524155]\n",
      "[Epoch 16/200] [Batch 356/637] [D loss: 0.164731] [G loss: 0.534822]\n",
      "[Epoch 16/200] [Batch 357/637] [D loss: 0.140971] [G loss: 0.528384]\n",
      "[Epoch 16/200] [Batch 358/637] [D loss: 0.164103] [G loss: 0.565361]\n",
      "[Epoch 16/200] [Batch 359/637] [D loss: 0.228129] [G loss: 0.614939]\n",
      "[Epoch 16/200] [Batch 360/637] [D loss: 0.170082] [G loss: 0.524071]\n",
      "[Epoch 16/200] [Batch 361/637] [D loss: 0.220652] [G loss: 0.462747]\n",
      "[Epoch 16/200] [Batch 362/637] [D loss: 0.174667] [G loss: 0.521943]\n",
      "[Epoch 16/200] [Batch 363/637] [D loss: 0.181067] [G loss: 0.509520]\n",
      "[Epoch 16/200] [Batch 364/637] [D loss: 0.165493] [G loss: 0.473809]\n",
      "[Epoch 16/200] [Batch 365/637] [D loss: 0.184584] [G loss: 0.411965]\n",
      "[Epoch 16/200] [Batch 366/637] [D loss: 0.167332] [G loss: 0.435615]\n",
      "[Epoch 16/200] [Batch 367/637] [D loss: 0.186383] [G loss: 0.563794]\n",
      "[Epoch 16/200] [Batch 368/637] [D loss: 0.160703] [G loss: 0.525559]\n",
      "[Epoch 16/200] [Batch 369/637] [D loss: 0.186674] [G loss: 0.480988]\n",
      "[Epoch 16/200] [Batch 370/637] [D loss: 0.161627] [G loss: 0.542529]\n",
      "[Epoch 16/200] [Batch 371/637] [D loss: 0.173617] [G loss: 0.440790]\n",
      "[Epoch 16/200] [Batch 372/637] [D loss: 0.158099] [G loss: 0.426885]\n",
      "[Epoch 16/200] [Batch 373/637] [D loss: 0.163433] [G loss: 0.510093]\n",
      "[Epoch 16/200] [Batch 374/637] [D loss: 0.140911] [G loss: 0.566202]\n",
      "[Epoch 16/200] [Batch 375/637] [D loss: 0.166261] [G loss: 0.448735]\n",
      "[Epoch 16/200] [Batch 376/637] [D loss: 0.164143] [G loss: 0.468964]\n",
      "[Epoch 16/200] [Batch 377/637] [D loss: 0.132942] [G loss: 0.530522]\n",
      "[Epoch 16/200] [Batch 378/637] [D loss: 0.155271] [G loss: 0.521831]\n",
      "[Epoch 16/200] [Batch 379/637] [D loss: 0.137784] [G loss: 0.538605]\n",
      "[Epoch 16/200] [Batch 380/637] [D loss: 0.175758] [G loss: 0.614566]\n",
      "[Epoch 16/200] [Batch 381/637] [D loss: 0.153144] [G loss: 0.523607]\n",
      "[Epoch 16/200] [Batch 382/637] [D loss: 0.159513] [G loss: 0.532808]\n",
      "[Epoch 16/200] [Batch 383/637] [D loss: 0.155353] [G loss: 0.510034]\n",
      "[Epoch 16/200] [Batch 384/637] [D loss: 0.126787] [G loss: 0.575183]\n",
      "[Epoch 16/200] [Batch 385/637] [D loss: 0.129833] [G loss: 0.545913]\n",
      "[Epoch 16/200] [Batch 386/637] [D loss: 0.165231] [G loss: 0.553488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 387/637] [D loss: 0.171839] [G loss: 0.448306]\n",
      "[Epoch 16/200] [Batch 388/637] [D loss: 0.175914] [G loss: 0.453608]\n",
      "[Epoch 16/200] [Batch 389/637] [D loss: 0.157691] [G loss: 0.597281]\n",
      "[Epoch 16/200] [Batch 390/637] [D loss: 0.173714] [G loss: 0.569707]\n",
      "[Epoch 16/200] [Batch 391/637] [D loss: 0.175597] [G loss: 0.465836]\n",
      "[Epoch 16/200] [Batch 392/637] [D loss: 0.174728] [G loss: 0.453631]\n",
      "[Epoch 16/200] [Batch 393/637] [D loss: 0.154666] [G loss: 0.538313]\n",
      "[Epoch 16/200] [Batch 394/637] [D loss: 0.173650] [G loss: 0.505568]\n",
      "[Epoch 16/200] [Batch 395/637] [D loss: 0.179607] [G loss: 0.478425]\n",
      "[Epoch 16/200] [Batch 396/637] [D loss: 0.155192] [G loss: 0.467373]\n",
      "[Epoch 16/200] [Batch 397/637] [D loss: 0.162693] [G loss: 0.474055]\n",
      "[Epoch 16/200] [Batch 398/637] [D loss: 0.147111] [G loss: 0.509644]\n",
      "[Epoch 16/200] [Batch 399/637] [D loss: 0.142920] [G loss: 0.555448]\n",
      "[Epoch 16/200] [Batch 400/637] [D loss: 0.164711] [G loss: 0.516679]\n",
      "[Epoch 16/200] [Batch 401/637] [D loss: 0.140350] [G loss: 0.519917]\n",
      "[Epoch 16/200] [Batch 402/637] [D loss: 0.140869] [G loss: 0.516655]\n",
      "[Epoch 16/200] [Batch 403/637] [D loss: 0.177250] [G loss: 0.526319]\n",
      "[Epoch 16/200] [Batch 404/637] [D loss: 0.150649] [G loss: 0.496497]\n",
      "[Epoch 16/200] [Batch 405/637] [D loss: 0.145464] [G loss: 0.505176]\n",
      "[Epoch 16/200] [Batch 406/637] [D loss: 0.146744] [G loss: 0.477915]\n",
      "[Epoch 16/200] [Batch 407/637] [D loss: 0.128318] [G loss: 0.587594]\n",
      "[Epoch 16/200] [Batch 408/637] [D loss: 0.140960] [G loss: 0.566283]\n",
      "[Epoch 16/200] [Batch 409/637] [D loss: 0.128225] [G loss: 0.639964]\n",
      "[Epoch 16/200] [Batch 410/637] [D loss: 0.157130] [G loss: 0.645209]\n",
      "[Epoch 16/200] [Batch 411/637] [D loss: 0.139205] [G loss: 0.552393]\n",
      "[Epoch 16/200] [Batch 412/637] [D loss: 0.163118] [G loss: 0.532241]\n",
      "[Epoch 16/200] [Batch 413/637] [D loss: 0.170818] [G loss: 0.557450]\n",
      "[Epoch 16/200] [Batch 414/637] [D loss: 0.149629] [G loss: 0.508169]\n",
      "[Epoch 16/200] [Batch 415/637] [D loss: 0.165144] [G loss: 0.502598]\n",
      "[Epoch 16/200] [Batch 416/637] [D loss: 0.149046] [G loss: 0.493067]\n",
      "[Epoch 16/200] [Batch 417/637] [D loss: 0.163067] [G loss: 0.560888]\n",
      "[Epoch 16/200] [Batch 418/637] [D loss: 0.149574] [G loss: 0.524619]\n",
      "[Epoch 16/200] [Batch 419/637] [D loss: 0.169380] [G loss: 0.447418]\n",
      "[Epoch 16/200] [Batch 420/637] [D loss: 0.156524] [G loss: 0.546685]\n",
      "[Epoch 16/200] [Batch 421/637] [D loss: 0.160652] [G loss: 0.542963]\n",
      "[Epoch 16/200] [Batch 422/637] [D loss: 0.161868] [G loss: 0.529157]\n",
      "[Epoch 16/200] [Batch 423/637] [D loss: 0.161676] [G loss: 0.455237]\n",
      "[Epoch 16/200] [Batch 424/637] [D loss: 0.149793] [G loss: 0.552838]\n",
      "[Epoch 16/200] [Batch 425/637] [D loss: 0.183834] [G loss: 0.488375]\n",
      "[Epoch 16/200] [Batch 426/637] [D loss: 0.173288] [G loss: 0.566300]\n",
      "[Epoch 16/200] [Batch 427/637] [D loss: 0.212829] [G loss: 0.425586]\n",
      "[Epoch 16/200] [Batch 428/637] [D loss: 0.211632] [G loss: 0.654574]\n",
      "[Epoch 16/200] [Batch 429/637] [D loss: 0.175191] [G loss: 0.615602]\n",
      "[Epoch 16/200] [Batch 430/637] [D loss: 0.152068] [G loss: 0.480508]\n",
      "[Epoch 16/200] [Batch 431/637] [D loss: 0.172992] [G loss: 0.435056]\n",
      "[Epoch 16/200] [Batch 432/637] [D loss: 0.150313] [G loss: 0.512269]\n",
      "[Epoch 16/200] [Batch 433/637] [D loss: 0.193490] [G loss: 0.520172]\n",
      "[Epoch 16/200] [Batch 434/637] [D loss: 0.166316] [G loss: 0.558069]\n",
      "[Epoch 16/200] [Batch 435/637] [D loss: 0.160937] [G loss: 0.438697]\n",
      "[Epoch 16/200] [Batch 436/637] [D loss: 0.136753] [G loss: 0.489381]\n",
      "[Epoch 16/200] [Batch 437/637] [D loss: 0.145433] [G loss: 0.516098]\n",
      "[Epoch 16/200] [Batch 438/637] [D loss: 0.173949] [G loss: 0.483198]\n",
      "[Epoch 16/200] [Batch 439/637] [D loss: 0.160937] [G loss: 0.499568]\n",
      "[Epoch 16/200] [Batch 440/637] [D loss: 0.140483] [G loss: 0.570361]\n",
      "[Epoch 16/200] [Batch 441/637] [D loss: 0.161071] [G loss: 0.634996]\n",
      "[Epoch 16/200] [Batch 442/637] [D loss: 0.142155] [G loss: 0.554686]\n",
      "[Epoch 16/200] [Batch 443/637] [D loss: 0.175045] [G loss: 0.542598]\n",
      "[Epoch 16/200] [Batch 444/637] [D loss: 0.174913] [G loss: 0.494435]\n",
      "[Epoch 16/200] [Batch 445/637] [D loss: 0.147221] [G loss: 0.608984]\n",
      "[Epoch 16/200] [Batch 446/637] [D loss: 0.156984] [G loss: 0.530795]\n",
      "[Epoch 16/200] [Batch 447/637] [D loss: 0.149742] [G loss: 0.447339]\n",
      "[Epoch 16/200] [Batch 448/637] [D loss: 0.162024] [G loss: 0.422417]\n",
      "[Epoch 16/200] [Batch 449/637] [D loss: 0.144992] [G loss: 0.546574]\n",
      "[Epoch 16/200] [Batch 450/637] [D loss: 0.170902] [G loss: 0.484692]\n",
      "[Epoch 16/200] [Batch 451/637] [D loss: 0.221894] [G loss: 0.600728]\n",
      "[Epoch 16/200] [Batch 452/637] [D loss: 0.161715] [G loss: 0.579487]\n",
      "[Epoch 16/200] [Batch 453/637] [D loss: 0.211840] [G loss: 0.542384]\n",
      "[Epoch 16/200] [Batch 454/637] [D loss: 0.178888] [G loss: 0.451713]\n",
      "[Epoch 16/200] [Batch 455/637] [D loss: 0.163008] [G loss: 0.464451]\n",
      "[Epoch 16/200] [Batch 456/637] [D loss: 0.166140] [G loss: 0.427685]\n",
      "[Epoch 16/200] [Batch 457/637] [D loss: 0.151608] [G loss: 0.490481]\n",
      "[Epoch 16/200] [Batch 458/637] [D loss: 0.160232] [G loss: 0.444709]\n",
      "[Epoch 16/200] [Batch 459/637] [D loss: 0.143394] [G loss: 0.523680]\n",
      "[Epoch 16/200] [Batch 460/637] [D loss: 0.141679] [G loss: 0.503948]\n",
      "[Epoch 16/200] [Batch 461/637] [D loss: 0.182915] [G loss: 0.534672]\n",
      "[Epoch 16/200] [Batch 462/637] [D loss: 0.161923] [G loss: 0.550468]\n",
      "[Epoch 16/200] [Batch 463/637] [D loss: 0.159337] [G loss: 0.514041]\n",
      "[Epoch 16/200] [Batch 464/637] [D loss: 0.147287] [G loss: 0.468516]\n",
      "[Epoch 16/200] [Batch 465/637] [D loss: 0.143031] [G loss: 0.527546]\n",
      "[Epoch 16/200] [Batch 466/637] [D loss: 0.163162] [G loss: 0.471908]\n",
      "[Epoch 16/200] [Batch 467/637] [D loss: 0.171188] [G loss: 0.497400]\n",
      "[Epoch 16/200] [Batch 468/637] [D loss: 0.132276] [G loss: 0.562271]\n",
      "[Epoch 16/200] [Batch 469/637] [D loss: 0.151596] [G loss: 0.512338]\n",
      "[Epoch 16/200] [Batch 470/637] [D loss: 0.135968] [G loss: 0.524180]\n",
      "[Epoch 16/200] [Batch 471/637] [D loss: 0.125636] [G loss: 0.616516]\n",
      "[Epoch 16/200] [Batch 472/637] [D loss: 0.140488] [G loss: 0.532872]\n",
      "[Epoch 16/200] [Batch 473/637] [D loss: 0.152138] [G loss: 0.568369]\n",
      "[Epoch 16/200] [Batch 474/637] [D loss: 0.124936] [G loss: 0.611438]\n",
      "[Epoch 16/200] [Batch 475/637] [D loss: 0.164607] [G loss: 0.538094]\n",
      "[Epoch 16/200] [Batch 476/637] [D loss: 0.147553] [G loss: 0.593505]\n",
      "[Epoch 16/200] [Batch 477/637] [D loss: 0.151794] [G loss: 0.600225]\n",
      "[Epoch 16/200] [Batch 478/637] [D loss: 0.150273] [G loss: 0.472406]\n",
      "[Epoch 16/200] [Batch 479/637] [D loss: 0.144224] [G loss: 0.452161]\n",
      "[Epoch 16/200] [Batch 480/637] [D loss: 0.157776] [G loss: 0.516382]\n",
      "[Epoch 16/200] [Batch 481/637] [D loss: 0.182639] [G loss: 0.516038]\n",
      "[Epoch 16/200] [Batch 482/637] [D loss: 0.162755] [G loss: 0.479486]\n",
      "[Epoch 16/200] [Batch 483/637] [D loss: 0.146443] [G loss: 0.519481]\n",
      "[Epoch 16/200] [Batch 484/637] [D loss: 0.158235] [G loss: 0.443252]\n",
      "[Epoch 16/200] [Batch 485/637] [D loss: 0.140020] [G loss: 0.498822]\n",
      "[Epoch 16/200] [Batch 486/637] [D loss: 0.136817] [G loss: 0.603464]\n",
      "[Epoch 16/200] [Batch 487/637] [D loss: 0.164121] [G loss: 0.542173]\n",
      "[Epoch 16/200] [Batch 488/637] [D loss: 0.147368] [G loss: 0.456007]\n",
      "[Epoch 16/200] [Batch 489/637] [D loss: 0.160719] [G loss: 0.477941]\n",
      "[Epoch 16/200] [Batch 490/637] [D loss: 0.180518] [G loss: 0.490344]\n",
      "[Epoch 16/200] [Batch 491/637] [D loss: 0.182622] [G loss: 0.539833]\n",
      "[Epoch 16/200] [Batch 492/637] [D loss: 0.171499] [G loss: 0.490855]\n",
      "[Epoch 16/200] [Batch 493/637] [D loss: 0.166719] [G loss: 0.522049]\n",
      "[Epoch 16/200] [Batch 494/637] [D loss: 0.182268] [G loss: 0.496114]\n",
      "[Epoch 16/200] [Batch 495/637] [D loss: 0.158944] [G loss: 0.499956]\n",
      "[Epoch 16/200] [Batch 496/637] [D loss: 0.138928] [G loss: 0.530856]\n",
      "[Epoch 16/200] [Batch 497/637] [D loss: 0.159925] [G loss: 0.510347]\n",
      "[Epoch 16/200] [Batch 498/637] [D loss: 0.141731] [G loss: 0.477550]\n",
      "[Epoch 16/200] [Batch 499/637] [D loss: 0.186435] [G loss: 0.420268]\n",
      "[Epoch 16/200] [Batch 500/637] [D loss: 0.175024] [G loss: 0.643505]\n",
      "[Epoch 16/200] [Batch 501/637] [D loss: 0.163311] [G loss: 0.600810]\n",
      "[Epoch 16/200] [Batch 502/637] [D loss: 0.170075] [G loss: 0.474495]\n",
      "[Epoch 16/200] [Batch 503/637] [D loss: 0.134923] [G loss: 0.524640]\n",
      "[Epoch 16/200] [Batch 504/637] [D loss: 0.133705] [G loss: 0.494344]\n",
      "[Epoch 16/200] [Batch 505/637] [D loss: 0.136864] [G loss: 0.550366]\n",
      "[Epoch 16/200] [Batch 506/637] [D loss: 0.201120] [G loss: 0.455381]\n",
      "[Epoch 16/200] [Batch 507/637] [D loss: 0.173387] [G loss: 0.645369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 508/637] [D loss: 0.145736] [G loss: 0.477179]\n",
      "[Epoch 16/200] [Batch 509/637] [D loss: 0.151894] [G loss: 0.447397]\n",
      "[Epoch 16/200] [Batch 510/637] [D loss: 0.146206] [G loss: 0.551137]\n",
      "[Epoch 16/200] [Batch 511/637] [D loss: 0.147964] [G loss: 0.536381]\n",
      "[Epoch 16/200] [Batch 512/637] [D loss: 0.159556] [G loss: 0.503442]\n",
      "[Epoch 16/200] [Batch 513/637] [D loss: 0.170828] [G loss: 0.559142]\n",
      "[Epoch 16/200] [Batch 514/637] [D loss: 0.158272] [G loss: 0.538219]\n",
      "[Epoch 16/200] [Batch 515/637] [D loss: 0.141673] [G loss: 0.515696]\n",
      "[Epoch 16/200] [Batch 516/637] [D loss: 0.169126] [G loss: 0.396733]\n",
      "[Epoch 16/200] [Batch 517/637] [D loss: 0.162300] [G loss: 0.516657]\n",
      "[Epoch 16/200] [Batch 518/637] [D loss: 0.181602] [G loss: 0.570159]\n",
      "[Epoch 16/200] [Batch 519/637] [D loss: 0.172701] [G loss: 0.500295]\n",
      "[Epoch 16/200] [Batch 520/637] [D loss: 0.164416] [G loss: 0.424839]\n",
      "[Epoch 16/200] [Batch 521/637] [D loss: 0.170373] [G loss: 0.455904]\n",
      "[Epoch 16/200] [Batch 522/637] [D loss: 0.150264] [G loss: 0.499080]\n",
      "[Epoch 16/200] [Batch 523/637] [D loss: 0.171666] [G loss: 0.440692]\n",
      "[Epoch 16/200] [Batch 524/637] [D loss: 0.174857] [G loss: 0.449037]\n",
      "[Epoch 16/200] [Batch 525/637] [D loss: 0.141386] [G loss: 0.539932]\n",
      "[Epoch 16/200] [Batch 526/637] [D loss: 0.163786] [G loss: 0.536865]\n",
      "[Epoch 16/200] [Batch 527/637] [D loss: 0.161028] [G loss: 0.461157]\n",
      "[Epoch 16/200] [Batch 528/637] [D loss: 0.161582] [G loss: 0.533748]\n",
      "[Epoch 16/200] [Batch 529/637] [D loss: 0.160480] [G loss: 0.551878]\n",
      "[Epoch 16/200] [Batch 530/637] [D loss: 0.173581] [G loss: 0.500360]\n",
      "[Epoch 16/200] [Batch 531/637] [D loss: 0.173116] [G loss: 0.535672]\n",
      "[Epoch 16/200] [Batch 532/637] [D loss: 0.145227] [G loss: 0.553410]\n",
      "[Epoch 16/200] [Batch 533/637] [D loss: 0.162583] [G loss: 0.499155]\n",
      "[Epoch 16/200] [Batch 534/637] [D loss: 0.149437] [G loss: 0.549805]\n",
      "[Epoch 16/200] [Batch 535/637] [D loss: 0.173924] [G loss: 0.554399]\n",
      "[Epoch 16/200] [Batch 536/637] [D loss: 0.171562] [G loss: 0.449094]\n",
      "[Epoch 16/200] [Batch 537/637] [D loss: 0.177012] [G loss: 0.617243]\n",
      "[Epoch 16/200] [Batch 538/637] [D loss: 0.143070] [G loss: 0.625695]\n",
      "[Epoch 16/200] [Batch 539/637] [D loss: 0.161826] [G loss: 0.564199]\n",
      "[Epoch 16/200] [Batch 540/637] [D loss: 0.154212] [G loss: 0.468823]\n",
      "[Epoch 16/200] [Batch 541/637] [D loss: 0.170159] [G loss: 0.446388]\n",
      "[Epoch 16/200] [Batch 542/637] [D loss: 0.151482] [G loss: 0.544354]\n",
      "[Epoch 16/200] [Batch 543/637] [D loss: 0.154650] [G loss: 0.673674]\n",
      "[Epoch 16/200] [Batch 544/637] [D loss: 0.141951] [G loss: 0.600637]\n",
      "[Epoch 16/200] [Batch 545/637] [D loss: 0.158985] [G loss: 0.467514]\n",
      "[Epoch 16/200] [Batch 546/637] [D loss: 0.170700] [G loss: 0.415261]\n",
      "[Epoch 16/200] [Batch 547/637] [D loss: 0.162965] [G loss: 0.565636]\n",
      "[Epoch 16/200] [Batch 548/637] [D loss: 0.171603] [G loss: 0.502828]\n",
      "[Epoch 16/200] [Batch 549/637] [D loss: 0.223380] [G loss: 0.570966]\n",
      "[Epoch 16/200] [Batch 550/637] [D loss: 0.146119] [G loss: 0.566529]\n",
      "[Epoch 16/200] [Batch 551/637] [D loss: 0.169593] [G loss: 0.526424]\n",
      "[Epoch 16/200] [Batch 552/637] [D loss: 0.154132] [G loss: 0.486401]\n",
      "[Epoch 16/200] [Batch 553/637] [D loss: 0.149182] [G loss: 0.476977]\n",
      "[Epoch 16/200] [Batch 554/637] [D loss: 0.143478] [G loss: 0.469849]\n",
      "[Epoch 16/200] [Batch 555/637] [D loss: 0.138250] [G loss: 0.497306]\n",
      "[Epoch 16/200] [Batch 556/637] [D loss: 0.146802] [G loss: 0.495477]\n",
      "[Epoch 16/200] [Batch 557/637] [D loss: 0.144223] [G loss: 0.522771]\n",
      "[Epoch 16/200] [Batch 558/637] [D loss: 0.156009] [G loss: 0.478226]\n",
      "[Epoch 16/200] [Batch 559/637] [D loss: 0.151327] [G loss: 0.605775]\n",
      "[Epoch 16/200] [Batch 560/637] [D loss: 0.143084] [G loss: 0.529069]\n",
      "[Epoch 16/200] [Batch 561/637] [D loss: 0.139354] [G loss: 0.496602]\n",
      "[Epoch 16/200] [Batch 562/637] [D loss: 0.136232] [G loss: 0.545819]\n",
      "[Epoch 16/200] [Batch 563/637] [D loss: 0.134752] [G loss: 0.547108]\n",
      "[Epoch 16/200] [Batch 564/637] [D loss: 0.138450] [G loss: 0.455091]\n",
      "[Epoch 16/200] [Batch 565/637] [D loss: 0.139023] [G loss: 0.515471]\n",
      "[Epoch 16/200] [Batch 566/637] [D loss: 0.145454] [G loss: 0.523020]\n",
      "[Epoch 16/200] [Batch 567/637] [D loss: 0.155259] [G loss: 0.488467]\n",
      "[Epoch 16/200] [Batch 568/637] [D loss: 0.150635] [G loss: 0.526928]\n",
      "[Epoch 16/200] [Batch 569/637] [D loss: 0.149913] [G loss: 0.553426]\n",
      "[Epoch 16/200] [Batch 570/637] [D loss: 0.159930] [G loss: 0.516456]\n",
      "[Epoch 16/200] [Batch 571/637] [D loss: 0.166349] [G loss: 0.465060]\n",
      "[Epoch 16/200] [Batch 572/637] [D loss: 0.165438] [G loss: 0.515006]\n",
      "[Epoch 16/200] [Batch 573/637] [D loss: 0.181824] [G loss: 0.480617]\n",
      "[Epoch 16/200] [Batch 574/637] [D loss: 0.157477] [G loss: 0.488579]\n",
      "[Epoch 16/200] [Batch 575/637] [D loss: 0.157046] [G loss: 0.559725]\n",
      "[Epoch 16/200] [Batch 576/637] [D loss: 0.185615] [G loss: 0.499077]\n",
      "[Epoch 16/200] [Batch 577/637] [D loss: 0.176318] [G loss: 0.538328]\n",
      "[Epoch 16/200] [Batch 578/637] [D loss: 0.163200] [G loss: 0.585603]\n",
      "[Epoch 16/200] [Batch 579/637] [D loss: 0.152037] [G loss: 0.637871]\n",
      "[Epoch 16/200] [Batch 580/637] [D loss: 0.184197] [G loss: 0.516549]\n",
      "[Epoch 16/200] [Batch 581/637] [D loss: 0.151004] [G loss: 0.452000]\n",
      "[Epoch 16/200] [Batch 582/637] [D loss: 0.168713] [G loss: 0.401745]\n",
      "[Epoch 16/200] [Batch 583/637] [D loss: 0.153418] [G loss: 0.509369]\n",
      "[Epoch 16/200] [Batch 584/637] [D loss: 0.154084] [G loss: 0.507689]\n",
      "[Epoch 16/200] [Batch 585/637] [D loss: 0.146416] [G loss: 0.502047]\n",
      "[Epoch 16/200] [Batch 586/637] [D loss: 0.137169] [G loss: 0.586672]\n",
      "[Epoch 16/200] [Batch 587/637] [D loss: 0.144079] [G loss: 0.536617]\n",
      "[Epoch 16/200] [Batch 588/637] [D loss: 0.175062] [G loss: 0.579588]\n",
      "[Epoch 16/200] [Batch 589/637] [D loss: 0.156716] [G loss: 0.531901]\n",
      "[Epoch 16/200] [Batch 590/637] [D loss: 0.180527] [G loss: 0.548254]\n",
      "[Epoch 16/200] [Batch 591/637] [D loss: 0.156124] [G loss: 0.509658]\n",
      "[Epoch 16/200] [Batch 592/637] [D loss: 0.167095] [G loss: 0.439060]\n",
      "[Epoch 16/200] [Batch 593/637] [D loss: 0.176932] [G loss: 0.546205]\n",
      "[Epoch 16/200] [Batch 594/637] [D loss: 0.180874] [G loss: 0.492253]\n",
      "[Epoch 16/200] [Batch 595/637] [D loss: 0.154038] [G loss: 0.606750]\n",
      "[Epoch 16/200] [Batch 596/637] [D loss: 0.141450] [G loss: 0.582871]\n",
      "[Epoch 16/200] [Batch 597/637] [D loss: 0.146591] [G loss: 0.523401]\n",
      "[Epoch 16/200] [Batch 598/637] [D loss: 0.157105] [G loss: 0.530908]\n",
      "[Epoch 16/200] [Batch 599/637] [D loss: 0.141922] [G loss: 0.569999]\n",
      "[Epoch 16/200] [Batch 600/637] [D loss: 0.170006] [G loss: 0.500334]\n",
      "[Epoch 16/200] [Batch 601/637] [D loss: 0.140019] [G loss: 0.657595]\n",
      "[Epoch 16/200] [Batch 602/637] [D loss: 0.152136] [G loss: 0.653839]\n",
      "[Epoch 16/200] [Batch 603/637] [D loss: 0.143305] [G loss: 0.543435]\n",
      "[Epoch 16/200] [Batch 604/637] [D loss: 0.152862] [G loss: 0.513127]\n",
      "[Epoch 16/200] [Batch 605/637] [D loss: 0.146327] [G loss: 0.501318]\n",
      "[Epoch 16/200] [Batch 606/637] [D loss: 0.151041] [G loss: 0.614189]\n",
      "[Epoch 16/200] [Batch 607/637] [D loss: 0.154547] [G loss: 0.583108]\n",
      "[Epoch 16/200] [Batch 608/637] [D loss: 0.146415] [G loss: 0.486853]\n",
      "[Epoch 16/200] [Batch 609/637] [D loss: 0.143011] [G loss: 0.510608]\n",
      "[Epoch 16/200] [Batch 610/637] [D loss: 0.153568] [G loss: 0.491062]\n",
      "[Epoch 16/200] [Batch 611/637] [D loss: 0.158545] [G loss: 0.503040]\n",
      "[Epoch 16/200] [Batch 612/637] [D loss: 0.172649] [G loss: 0.591926]\n",
      "[Epoch 16/200] [Batch 613/637] [D loss: 0.165920] [G loss: 0.508965]\n",
      "[Epoch 16/200] [Batch 614/637] [D loss: 0.180860] [G loss: 0.480791]\n",
      "[Epoch 16/200] [Batch 615/637] [D loss: 0.185625] [G loss: 0.433999]\n",
      "[Epoch 16/200] [Batch 616/637] [D loss: 0.161739] [G loss: 0.504621]\n",
      "[Epoch 16/200] [Batch 617/637] [D loss: 0.178488] [G loss: 0.516279]\n",
      "[Epoch 16/200] [Batch 618/637] [D loss: 0.222104] [G loss: 0.398791]\n",
      "[Epoch 16/200] [Batch 619/637] [D loss: 0.177125] [G loss: 0.698404]\n",
      "[Epoch 16/200] [Batch 620/637] [D loss: 0.180052] [G loss: 0.537514]\n",
      "[Epoch 16/200] [Batch 621/637] [D loss: 0.205353] [G loss: 0.429543]\n",
      "[Epoch 16/200] [Batch 622/637] [D loss: 0.182525] [G loss: 0.482284]\n",
      "[Epoch 16/200] [Batch 623/637] [D loss: 0.191829] [G loss: 0.474098]\n",
      "[Epoch 16/200] [Batch 624/637] [D loss: 0.158328] [G loss: 0.472139]\n",
      "[Epoch 16/200] [Batch 625/637] [D loss: 0.153434] [G loss: 0.478335]\n",
      "[Epoch 16/200] [Batch 626/637] [D loss: 0.144130] [G loss: 0.473246]\n",
      "[Epoch 16/200] [Batch 627/637] [D loss: 0.141856] [G loss: 0.476907]\n",
      "[Epoch 16/200] [Batch 628/637] [D loss: 0.149668] [G loss: 0.564227]\n",
      "[Epoch 16/200] [Batch 629/637] [D loss: 0.154145] [G loss: 0.485071]\n",
      "[Epoch 16/200] [Batch 630/637] [D loss: 0.153082] [G loss: 0.470880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 631/637] [D loss: 0.132614] [G loss: 0.549242]\n",
      "[Epoch 16/200] [Batch 632/637] [D loss: 0.141879] [G loss: 0.561786]\n",
      "[Epoch 16/200] [Batch 633/637] [D loss: 0.149818] [G loss: 0.509879]\n",
      "[Epoch 16/200] [Batch 634/637] [D loss: 0.157831] [G loss: 0.489872]\n",
      "[Epoch 16/200] [Batch 635/637] [D loss: 0.134936] [G loss: 0.528006]\n",
      "[Epoch 16/200] [Batch 636/637] [D loss: 0.115747] [G loss: 0.562018]\n",
      "[Epoch 17/200] [Batch 0/637] [D loss: 0.169076] [G loss: 0.502828]\n",
      "[Epoch 17/200] [Batch 1/637] [D loss: 0.152862] [G loss: 0.465919]\n",
      "[Epoch 17/200] [Batch 2/637] [D loss: 0.155758] [G loss: 0.535904]\n",
      "[Epoch 17/200] [Batch 3/637] [D loss: 0.165733] [G loss: 0.537172]\n",
      "[Epoch 17/200] [Batch 4/637] [D loss: 0.152028] [G loss: 0.477043]\n",
      "[Epoch 17/200] [Batch 5/637] [D loss: 0.181444] [G loss: 0.534903]\n",
      "[Epoch 17/200] [Batch 6/637] [D loss: 0.152431] [G loss: 0.481510]\n",
      "[Epoch 17/200] [Batch 7/637] [D loss: 0.144426] [G loss: 0.482303]\n",
      "[Epoch 17/200] [Batch 8/637] [D loss: 0.177831] [G loss: 0.492087]\n",
      "[Epoch 17/200] [Batch 9/637] [D loss: 0.169000] [G loss: 0.549627]\n",
      "[Epoch 17/200] [Batch 10/637] [D loss: 0.150859] [G loss: 0.522650]\n",
      "[Epoch 17/200] [Batch 11/637] [D loss: 0.161336] [G loss: 0.498693]\n",
      "[Epoch 17/200] [Batch 12/637] [D loss: 0.142711] [G loss: 0.538231]\n",
      "[Epoch 17/200] [Batch 13/637] [D loss: 0.138304] [G loss: 0.485401]\n",
      "[Epoch 17/200] [Batch 14/637] [D loss: 0.140936] [G loss: 0.466028]\n",
      "[Epoch 17/200] [Batch 15/637] [D loss: 0.157156] [G loss: 0.440862]\n",
      "[Epoch 17/200] [Batch 16/637] [D loss: 0.145784] [G loss: 0.513354]\n",
      "[Epoch 17/200] [Batch 17/637] [D loss: 0.127549] [G loss: 0.613962]\n",
      "[Epoch 17/200] [Batch 18/637] [D loss: 0.147110] [G loss: 0.558959]\n",
      "[Epoch 17/200] [Batch 19/637] [D loss: 0.144419] [G loss: 0.509772]\n",
      "[Epoch 17/200] [Batch 20/637] [D loss: 0.163221] [G loss: 0.517873]\n",
      "[Epoch 17/200] [Batch 21/637] [D loss: 0.166563] [G loss: 0.577887]\n",
      "[Epoch 17/200] [Batch 22/637] [D loss: 0.161782] [G loss: 0.596128]\n",
      "[Epoch 17/200] [Batch 23/637] [D loss: 0.175082] [G loss: 0.498044]\n",
      "[Epoch 17/200] [Batch 24/637] [D loss: 0.186084] [G loss: 0.483036]\n",
      "[Epoch 17/200] [Batch 25/637] [D loss: 0.171690] [G loss: 0.537084]\n",
      "[Epoch 17/200] [Batch 26/637] [D loss: 0.187110] [G loss: 0.486412]\n",
      "[Epoch 17/200] [Batch 27/637] [D loss: 0.172624] [G loss: 0.496087]\n",
      "[Epoch 17/200] [Batch 28/637] [D loss: 0.158343] [G loss: 0.509781]\n",
      "[Epoch 17/200] [Batch 29/637] [D loss: 0.165263] [G loss: 0.463813]\n",
      "[Epoch 17/200] [Batch 30/637] [D loss: 0.158763] [G loss: 0.488125]\n",
      "[Epoch 17/200] [Batch 31/637] [D loss: 0.150581] [G loss: 0.534050]\n",
      "[Epoch 17/200] [Batch 32/637] [D loss: 0.149842] [G loss: 0.501928]\n",
      "[Epoch 17/200] [Batch 33/637] [D loss: 0.160164] [G loss: 0.504249]\n",
      "[Epoch 17/200] [Batch 34/637] [D loss: 0.153716] [G loss: 0.490651]\n",
      "[Epoch 17/200] [Batch 35/637] [D loss: 0.141931] [G loss: 0.528798]\n",
      "[Epoch 17/200] [Batch 36/637] [D loss: 0.162596] [G loss: 0.580322]\n",
      "[Epoch 17/200] [Batch 37/637] [D loss: 0.153786] [G loss: 0.570258]\n",
      "[Epoch 17/200] [Batch 38/637] [D loss: 0.156823] [G loss: 0.510746]\n",
      "[Epoch 17/200] [Batch 39/637] [D loss: 0.164843] [G loss: 0.485096]\n",
      "[Epoch 17/200] [Batch 40/637] [D loss: 0.162868] [G loss: 0.576311]\n",
      "[Epoch 17/200] [Batch 41/637] [D loss: 0.179592] [G loss: 0.463528]\n",
      "[Epoch 17/200] [Batch 42/637] [D loss: 0.172615] [G loss: 0.565296]\n",
      "[Epoch 17/200] [Batch 43/637] [D loss: 0.138845] [G loss: 0.548954]\n",
      "[Epoch 17/200] [Batch 44/637] [D loss: 0.151920] [G loss: 0.503871]\n",
      "[Epoch 17/200] [Batch 45/637] [D loss: 0.168125] [G loss: 0.486464]\n",
      "[Epoch 17/200] [Batch 46/637] [D loss: 0.152529] [G loss: 0.553954]\n",
      "[Epoch 17/200] [Batch 47/637] [D loss: 0.147348] [G loss: 0.591655]\n",
      "[Epoch 17/200] [Batch 48/637] [D loss: 0.159086] [G loss: 0.525784]\n",
      "[Epoch 17/200] [Batch 49/637] [D loss: 0.150397] [G loss: 0.595048]\n",
      "[Epoch 17/200] [Batch 50/637] [D loss: 0.156802] [G loss: 0.551678]\n",
      "[Epoch 17/200] [Batch 51/637] [D loss: 0.158215] [G loss: 0.490138]\n",
      "[Epoch 17/200] [Batch 52/637] [D loss: 0.161855] [G loss: 0.471481]\n",
      "[Epoch 17/200] [Batch 53/637] [D loss: 0.135886] [G loss: 0.627151]\n",
      "[Epoch 17/200] [Batch 54/637] [D loss: 0.128850] [G loss: 0.581802]\n",
      "[Epoch 17/200] [Batch 55/637] [D loss: 0.143828] [G loss: 0.517128]\n",
      "[Epoch 17/200] [Batch 56/637] [D loss: 0.138320] [G loss: 0.546281]\n",
      "[Epoch 17/200] [Batch 57/637] [D loss: 0.144643] [G loss: 0.557524]\n",
      "[Epoch 17/200] [Batch 58/637] [D loss: 0.145697] [G loss: 0.571522]\n",
      "[Epoch 17/200] [Batch 59/637] [D loss: 0.154074] [G loss: 0.514624]\n",
      "[Epoch 17/200] [Batch 60/637] [D loss: 0.126780] [G loss: 0.578392]\n",
      "[Epoch 17/200] [Batch 61/637] [D loss: 0.166522] [G loss: 0.584301]\n",
      "[Epoch 17/200] [Batch 62/637] [D loss: 0.147124] [G loss: 0.516535]\n",
      "[Epoch 17/200] [Batch 63/637] [D loss: 0.143128] [G loss: 0.557743]\n",
      "[Epoch 17/200] [Batch 64/637] [D loss: 0.148796] [G loss: 0.624744]\n",
      "[Epoch 17/200] [Batch 65/637] [D loss: 0.171232] [G loss: 0.510225]\n",
      "[Epoch 17/200] [Batch 66/637] [D loss: 0.138866] [G loss: 0.569569]\n",
      "[Epoch 17/200] [Batch 67/637] [D loss: 0.152086] [G loss: 0.571970]\n",
      "[Epoch 17/200] [Batch 68/637] [D loss: 0.165018] [G loss: 0.516021]\n",
      "[Epoch 17/200] [Batch 69/637] [D loss: 0.126774] [G loss: 0.554140]\n",
      "[Epoch 17/200] [Batch 70/637] [D loss: 0.118680] [G loss: 0.572973]\n",
      "[Epoch 17/200] [Batch 71/637] [D loss: 0.159507] [G loss: 0.518111]\n",
      "[Epoch 17/200] [Batch 72/637] [D loss: 0.136851] [G loss: 0.527968]\n",
      "[Epoch 17/200] [Batch 73/637] [D loss: 0.160653] [G loss: 0.573512]\n",
      "[Epoch 17/200] [Batch 74/637] [D loss: 0.131086] [G loss: 0.473901]\n",
      "[Epoch 17/200] [Batch 75/637] [D loss: 0.150419] [G loss: 0.539981]\n",
      "[Epoch 17/200] [Batch 76/637] [D loss: 0.159230] [G loss: 0.521800]\n",
      "[Epoch 17/200] [Batch 77/637] [D loss: 0.160961] [G loss: 0.520296]\n",
      "[Epoch 17/200] [Batch 78/637] [D loss: 0.147328] [G loss: 0.550605]\n",
      "[Epoch 17/200] [Batch 79/637] [D loss: 0.164074] [G loss: 0.506871]\n",
      "[Epoch 17/200] [Batch 80/637] [D loss: 0.192172] [G loss: 0.553110]\n",
      "[Epoch 17/200] [Batch 81/637] [D loss: 0.163087] [G loss: 0.593402]\n",
      "[Epoch 17/200] [Batch 82/637] [D loss: 0.173030] [G loss: 0.520372]\n",
      "[Epoch 17/200] [Batch 83/637] [D loss: 0.177871] [G loss: 0.499863]\n",
      "[Epoch 17/200] [Batch 84/637] [D loss: 0.149554] [G loss: 0.486509]\n",
      "[Epoch 17/200] [Batch 85/637] [D loss: 0.156049] [G loss: 0.481251]\n",
      "[Epoch 17/200] [Batch 86/637] [D loss: 0.152763] [G loss: 0.522381]\n",
      "[Epoch 17/200] [Batch 87/637] [D loss: 0.169211] [G loss: 0.507404]\n",
      "[Epoch 17/200] [Batch 88/637] [D loss: 0.156501] [G loss: 0.510216]\n",
      "[Epoch 17/200] [Batch 89/637] [D loss: 0.165406] [G loss: 0.465841]\n",
      "[Epoch 17/200] [Batch 90/637] [D loss: 0.165642] [G loss: 0.482895]\n",
      "[Epoch 17/200] [Batch 91/637] [D loss: 0.147625] [G loss: 0.567120]\n",
      "[Epoch 17/200] [Batch 92/637] [D loss: 0.151751] [G loss: 0.530472]\n",
      "[Epoch 17/200] [Batch 93/637] [D loss: 0.159115] [G loss: 0.453248]\n",
      "[Epoch 17/200] [Batch 94/637] [D loss: 0.142644] [G loss: 0.486898]\n",
      "[Epoch 17/200] [Batch 95/637] [D loss: 0.160951] [G loss: 0.489587]\n",
      "[Epoch 17/200] [Batch 96/637] [D loss: 0.163844] [G loss: 0.535343]\n",
      "[Epoch 17/200] [Batch 97/637] [D loss: 0.137395] [G loss: 0.574188]\n",
      "[Epoch 17/200] [Batch 98/637] [D loss: 0.170393] [G loss: 0.545333]\n",
      "[Epoch 17/200] [Batch 99/637] [D loss: 0.164824] [G loss: 0.565229]\n",
      "[Epoch 17/200] [Batch 100/637] [D loss: 0.162976] [G loss: 0.494100]\n",
      "[Epoch 17/200] [Batch 101/637] [D loss: 0.162810] [G loss: 0.480479]\n",
      "[Epoch 17/200] [Batch 102/637] [D loss: 0.152550] [G loss: 0.527264]\n",
      "[Epoch 17/200] [Batch 103/637] [D loss: 0.157063] [G loss: 0.510271]\n",
      "[Epoch 17/200] [Batch 104/637] [D loss: 0.154689] [G loss: 0.548306]\n",
      "[Epoch 17/200] [Batch 105/637] [D loss: 0.169358] [G loss: 0.496855]\n",
      "[Epoch 17/200] [Batch 106/637] [D loss: 0.176105] [G loss: 0.502442]\n",
      "[Epoch 17/200] [Batch 107/637] [D loss: 0.181173] [G loss: 0.499215]\n",
      "[Epoch 17/200] [Batch 108/637] [D loss: 0.155359] [G loss: 0.519488]\n",
      "[Epoch 17/200] [Batch 109/637] [D loss: 0.154103] [G loss: 0.562252]\n",
      "[Epoch 17/200] [Batch 110/637] [D loss: 0.158650] [G loss: 0.518002]\n",
      "[Epoch 17/200] [Batch 111/637] [D loss: 0.145019] [G loss: 0.484687]\n",
      "[Epoch 17/200] [Batch 112/637] [D loss: 0.174170] [G loss: 0.508863]\n",
      "[Epoch 17/200] [Batch 113/637] [D loss: 0.174525] [G loss: 0.520178]\n",
      "[Epoch 17/200] [Batch 114/637] [D loss: 0.158897] [G loss: 0.469280]\n",
      "[Epoch 17/200] [Batch 115/637] [D loss: 0.148330] [G loss: 0.512563]\n",
      "[Epoch 17/200] [Batch 116/637] [D loss: 0.139157] [G loss: 0.565585]\n",
      "[Epoch 17/200] [Batch 117/637] [D loss: 0.182898] [G loss: 0.422722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 118/637] [D loss: 0.166576] [G loss: 0.506826]\n",
      "[Epoch 17/200] [Batch 119/637] [D loss: 0.162583] [G loss: 0.564705]\n",
      "[Epoch 17/200] [Batch 120/637] [D loss: 0.168693] [G loss: 0.561755]\n",
      "[Epoch 17/200] [Batch 121/637] [D loss: 0.168662] [G loss: 0.510841]\n",
      "[Epoch 17/200] [Batch 122/637] [D loss: 0.151611] [G loss: 0.492755]\n",
      "[Epoch 17/200] [Batch 123/637] [D loss: 0.172880] [G loss: 0.486630]\n",
      "[Epoch 17/200] [Batch 124/637] [D loss: 0.151858] [G loss: 0.483284]\n",
      "[Epoch 17/200] [Batch 125/637] [D loss: 0.150955] [G loss: 0.557865]\n",
      "[Epoch 17/200] [Batch 126/637] [D loss: 0.190281] [G loss: 0.424798]\n",
      "[Epoch 17/200] [Batch 127/637] [D loss: 0.174727] [G loss: 0.522505]\n",
      "[Epoch 17/200] [Batch 128/637] [D loss: 0.148816] [G loss: 0.571904]\n",
      "[Epoch 17/200] [Batch 129/637] [D loss: 0.156736] [G loss: 0.501235]\n",
      "[Epoch 17/200] [Batch 130/637] [D loss: 0.152709] [G loss: 0.496374]\n",
      "[Epoch 17/200] [Batch 131/637] [D loss: 0.139284] [G loss: 0.528063]\n",
      "[Epoch 17/200] [Batch 132/637] [D loss: 0.129187] [G loss: 0.661414]\n",
      "[Epoch 17/200] [Batch 133/637] [D loss: 0.159902] [G loss: 0.588918]\n",
      "[Epoch 17/200] [Batch 134/637] [D loss: 0.146952] [G loss: 0.500207]\n",
      "[Epoch 17/200] [Batch 135/637] [D loss: 0.136744] [G loss: 0.611615]\n",
      "[Epoch 17/200] [Batch 136/637] [D loss: 0.141817] [G loss: 0.560487]\n",
      "[Epoch 17/200] [Batch 137/637] [D loss: 0.150628] [G loss: 0.605807]\n",
      "[Epoch 17/200] [Batch 138/637] [D loss: 0.145885] [G loss: 0.594572]\n",
      "[Epoch 17/200] [Batch 139/637] [D loss: 0.142049] [G loss: 0.614994]\n",
      "[Epoch 17/200] [Batch 140/637] [D loss: 0.159570] [G loss: 0.484843]\n",
      "[Epoch 17/200] [Batch 141/637] [D loss: 0.156561] [G loss: 0.525742]\n",
      "[Epoch 17/200] [Batch 142/637] [D loss: 0.157512] [G loss: 0.577500]\n",
      "[Epoch 17/200] [Batch 143/637] [D loss: 0.201161] [G loss: 0.402444]\n",
      "[Epoch 17/200] [Batch 144/637] [D loss: 0.185546] [G loss: 0.617673]\n",
      "[Epoch 17/200] [Batch 145/637] [D loss: 0.179624] [G loss: 0.567983]\n",
      "[Epoch 17/200] [Batch 146/637] [D loss: 0.144336] [G loss: 0.569665]\n",
      "[Epoch 17/200] [Batch 147/637] [D loss: 0.176708] [G loss: 0.516211]\n",
      "[Epoch 17/200] [Batch 148/637] [D loss: 0.198408] [G loss: 0.468474]\n",
      "[Epoch 17/200] [Batch 149/637] [D loss: 0.156149] [G loss: 0.582878]\n",
      "[Epoch 17/200] [Batch 150/637] [D loss: 0.177175] [G loss: 0.533756]\n",
      "[Epoch 17/200] [Batch 151/637] [D loss: 0.203312] [G loss: 0.440349]\n",
      "[Epoch 17/200] [Batch 152/637] [D loss: 0.175543] [G loss: 0.480331]\n",
      "[Epoch 17/200] [Batch 153/637] [D loss: 0.157049] [G loss: 0.589318]\n",
      "[Epoch 17/200] [Batch 154/637] [D loss: 0.174070] [G loss: 0.573927]\n",
      "[Epoch 17/200] [Batch 155/637] [D loss: 0.163858] [G loss: 0.583508]\n",
      "[Epoch 17/200] [Batch 156/637] [D loss: 0.197635] [G loss: 0.455473]\n",
      "[Epoch 17/200] [Batch 157/637] [D loss: 0.169551] [G loss: 0.546963]\n",
      "[Epoch 17/200] [Batch 158/637] [D loss: 0.167214] [G loss: 0.534837]\n",
      "[Epoch 17/200] [Batch 159/637] [D loss: 0.154850] [G loss: 0.504535]\n",
      "[Epoch 17/200] [Batch 160/637] [D loss: 0.148164] [G loss: 0.516777]\n",
      "[Epoch 17/200] [Batch 161/637] [D loss: 0.142754] [G loss: 0.633440]\n",
      "[Epoch 17/200] [Batch 162/637] [D loss: 0.174696] [G loss: 0.480261]\n",
      "[Epoch 17/200] [Batch 163/637] [D loss: 0.154985] [G loss: 0.493740]\n",
      "[Epoch 17/200] [Batch 164/637] [D loss: 0.148560] [G loss: 0.601253]\n",
      "[Epoch 17/200] [Batch 165/637] [D loss: 0.151649] [G loss: 0.571072]\n",
      "[Epoch 17/200] [Batch 166/637] [D loss: 0.154201] [G loss: 0.558966]\n",
      "[Epoch 17/200] [Batch 167/637] [D loss: 0.162022] [G loss: 0.475745]\n",
      "[Epoch 17/200] [Batch 168/637] [D loss: 0.189660] [G loss: 0.547947]\n",
      "[Epoch 17/200] [Batch 169/637] [D loss: 0.178642] [G loss: 0.494138]\n",
      "[Epoch 17/200] [Batch 170/637] [D loss: 0.168816] [G loss: 0.532752]\n",
      "[Epoch 17/200] [Batch 171/637] [D loss: 0.163975] [G loss: 0.556663]\n",
      "[Epoch 17/200] [Batch 172/637] [D loss: 0.171870] [G loss: 0.476141]\n",
      "[Epoch 17/200] [Batch 173/637] [D loss: 0.161916] [G loss: 0.439197]\n",
      "[Epoch 17/200] [Batch 174/637] [D loss: 0.178686] [G loss: 0.472452]\n",
      "[Epoch 17/200] [Batch 175/637] [D loss: 0.146660] [G loss: 0.563308]\n",
      "[Epoch 17/200] [Batch 176/637] [D loss: 0.149471] [G loss: 0.526023]\n",
      "[Epoch 17/200] [Batch 177/637] [D loss: 0.170329] [G loss: 0.471573]\n",
      "[Epoch 17/200] [Batch 178/637] [D loss: 0.170417] [G loss: 0.431247]\n",
      "[Epoch 17/200] [Batch 179/637] [D loss: 0.149601] [G loss: 0.479186]\n",
      "[Epoch 17/200] [Batch 180/637] [D loss: 0.152603] [G loss: 0.537376]\n",
      "[Epoch 17/200] [Batch 181/637] [D loss: 0.158411] [G loss: 0.511126]\n",
      "[Epoch 17/200] [Batch 182/637] [D loss: 0.151285] [G loss: 0.607641]\n",
      "[Epoch 17/200] [Batch 183/637] [D loss: 0.150327] [G loss: 0.490776]\n",
      "[Epoch 17/200] [Batch 184/637] [D loss: 0.141047] [G loss: 0.499596]\n",
      "[Epoch 17/200] [Batch 185/637] [D loss: 0.155776] [G loss: 0.573488]\n",
      "[Epoch 17/200] [Batch 186/637] [D loss: 0.171916] [G loss: 0.518566]\n",
      "[Epoch 17/200] [Batch 187/637] [D loss: 0.161040] [G loss: 0.473402]\n",
      "[Epoch 17/200] [Batch 188/637] [D loss: 0.148357] [G loss: 0.611981]\n",
      "[Epoch 17/200] [Batch 189/637] [D loss: 0.151745] [G loss: 0.594364]\n",
      "[Epoch 17/200] [Batch 190/637] [D loss: 0.162455] [G loss: 0.488649]\n",
      "[Epoch 17/200] [Batch 191/637] [D loss: 0.155466] [G loss: 0.433007]\n",
      "[Epoch 17/200] [Batch 192/637] [D loss: 0.159711] [G loss: 0.504596]\n",
      "[Epoch 17/200] [Batch 193/637] [D loss: 0.149168] [G loss: 0.529528]\n",
      "[Epoch 17/200] [Batch 194/637] [D loss: 0.146133] [G loss: 0.503440]\n",
      "[Epoch 17/200] [Batch 195/637] [D loss: 0.148233] [G loss: 0.500357]\n",
      "[Epoch 17/200] [Batch 196/637] [D loss: 0.154558] [G loss: 0.418196]\n",
      "[Epoch 17/200] [Batch 197/637] [D loss: 0.163916] [G loss: 0.445714]\n",
      "[Epoch 17/200] [Batch 198/637] [D loss: 0.170101] [G loss: 0.491394]\n",
      "[Epoch 17/200] [Batch 199/637] [D loss: 0.170869] [G loss: 0.462017]\n",
      "[Epoch 17/200] [Batch 200/637] [D loss: 0.156360] [G loss: 0.472099]\n",
      "[Epoch 17/200] [Batch 201/637] [D loss: 0.163600] [G loss: 0.451904]\n",
      "[Epoch 17/200] [Batch 202/637] [D loss: 0.196948] [G loss: 0.426164]\n",
      "[Epoch 17/200] [Batch 203/637] [D loss: 0.177805] [G loss: 0.529041]\n",
      "[Epoch 17/200] [Batch 204/637] [D loss: 0.167367] [G loss: 0.497412]\n",
      "[Epoch 17/200] [Batch 205/637] [D loss: 0.157450] [G loss: 0.498864]\n",
      "[Epoch 17/200] [Batch 206/637] [D loss: 0.166247] [G loss: 0.490764]\n",
      "[Epoch 17/200] [Batch 207/637] [D loss: 0.156685] [G loss: 0.455424]\n",
      "[Epoch 17/200] [Batch 208/637] [D loss: 0.147989] [G loss: 0.549622]\n",
      "[Epoch 17/200] [Batch 209/637] [D loss: 0.161046] [G loss: 0.541948]\n",
      "[Epoch 17/200] [Batch 210/637] [D loss: 0.144366] [G loss: 0.593482]\n",
      "[Epoch 17/200] [Batch 211/637] [D loss: 0.135377] [G loss: 0.540872]\n",
      "[Epoch 17/200] [Batch 212/637] [D loss: 0.167562] [G loss: 0.448210]\n",
      "[Epoch 17/200] [Batch 213/637] [D loss: 0.153897] [G loss: 0.672625]\n",
      "[Epoch 17/200] [Batch 214/637] [D loss: 0.165020] [G loss: 0.571176]\n",
      "[Epoch 17/200] [Batch 215/637] [D loss: 0.157759] [G loss: 0.521448]\n",
      "[Epoch 17/200] [Batch 216/637] [D loss: 0.177461] [G loss: 0.411366]\n",
      "[Epoch 17/200] [Batch 217/637] [D loss: 0.156982] [G loss: 0.476560]\n",
      "[Epoch 17/200] [Batch 218/637] [D loss: 0.158085] [G loss: 0.544841]\n",
      "[Epoch 17/200] [Batch 219/637] [D loss: 0.159367] [G loss: 0.584334]\n",
      "[Epoch 17/200] [Batch 220/637] [D loss: 0.168026] [G loss: 0.524167]\n",
      "[Epoch 17/200] [Batch 221/637] [D loss: 0.160149] [G loss: 0.464549]\n",
      "[Epoch 17/200] [Batch 222/637] [D loss: 0.169529] [G loss: 0.559120]\n",
      "[Epoch 17/200] [Batch 223/637] [D loss: 0.157464] [G loss: 0.467024]\n",
      "[Epoch 17/200] [Batch 224/637] [D loss: 0.145096] [G loss: 0.455499]\n",
      "[Epoch 17/200] [Batch 225/637] [D loss: 0.151335] [G loss: 0.548192]\n",
      "[Epoch 17/200] [Batch 226/637] [D loss: 0.126952] [G loss: 0.531880]\n",
      "[Epoch 17/200] [Batch 227/637] [D loss: 0.167725] [G loss: 0.449103]\n",
      "[Epoch 17/200] [Batch 228/637] [D loss: 0.182879] [G loss: 0.495013]\n",
      "[Epoch 17/200] [Batch 229/637] [D loss: 0.165229] [G loss: 0.640687]\n",
      "[Epoch 17/200] [Batch 230/637] [D loss: 0.179685] [G loss: 0.550191]\n",
      "[Epoch 17/200] [Batch 231/637] [D loss: 0.193732] [G loss: 0.605360]\n",
      "[Epoch 17/200] [Batch 232/637] [D loss: 0.149514] [G loss: 0.520559]\n",
      "[Epoch 17/200] [Batch 233/637] [D loss: 0.156002] [G loss: 0.454054]\n",
      "[Epoch 17/200] [Batch 234/637] [D loss: 0.172438] [G loss: 0.501621]\n",
      "[Epoch 17/200] [Batch 235/637] [D loss: 0.144541] [G loss: 0.529956]\n",
      "[Epoch 17/200] [Batch 236/637] [D loss: 0.152201] [G loss: 0.557656]\n",
      "[Epoch 17/200] [Batch 237/637] [D loss: 0.147818] [G loss: 0.504105]\n",
      "[Epoch 17/200] [Batch 238/637] [D loss: 0.135443] [G loss: 0.493963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 239/637] [D loss: 0.139727] [G loss: 0.549812]\n",
      "[Epoch 17/200] [Batch 240/637] [D loss: 0.139836] [G loss: 0.525364]\n",
      "[Epoch 17/200] [Batch 241/637] [D loss: 0.141718] [G loss: 0.559629]\n",
      "[Epoch 17/200] [Batch 242/637] [D loss: 0.159687] [G loss: 0.531133]\n",
      "[Epoch 17/200] [Batch 243/637] [D loss: 0.140452] [G loss: 0.513643]\n",
      "[Epoch 17/200] [Batch 244/637] [D loss: 0.147107] [G loss: 0.521212]\n",
      "[Epoch 17/200] [Batch 245/637] [D loss: 0.180033] [G loss: 0.546678]\n",
      "[Epoch 17/200] [Batch 246/637] [D loss: 0.161999] [G loss: 0.551738]\n",
      "[Epoch 17/200] [Batch 247/637] [D loss: 0.136872] [G loss: 0.622665]\n",
      "[Epoch 17/200] [Batch 248/637] [D loss: 0.184944] [G loss: 0.542700]\n",
      "[Epoch 17/200] [Batch 249/637] [D loss: 0.193414] [G loss: 0.477986]\n",
      "[Epoch 17/200] [Batch 250/637] [D loss: 0.159233] [G loss: 0.491605]\n",
      "[Epoch 17/200] [Batch 251/637] [D loss: 0.175868] [G loss: 0.424900]\n",
      "[Epoch 17/200] [Batch 252/637] [D loss: 0.154364] [G loss: 0.539634]\n",
      "[Epoch 17/200] [Batch 253/637] [D loss: 0.185636] [G loss: 0.535953]\n",
      "[Epoch 17/200] [Batch 254/637] [D loss: 0.182024] [G loss: 0.508404]\n",
      "[Epoch 17/200] [Batch 255/637] [D loss: 0.148315] [G loss: 0.543942]\n",
      "[Epoch 17/200] [Batch 256/637] [D loss: 0.159215] [G loss: 0.522720]\n",
      "[Epoch 17/200] [Batch 257/637] [D loss: 0.148737] [G loss: 0.596526]\n",
      "[Epoch 17/200] [Batch 258/637] [D loss: 0.164542] [G loss: 0.548968]\n",
      "[Epoch 17/200] [Batch 259/637] [D loss: 0.171428] [G loss: 0.510948]\n",
      "[Epoch 17/200] [Batch 260/637] [D loss: 0.177606] [G loss: 0.588825]\n",
      "[Epoch 17/200] [Batch 261/637] [D loss: 0.157514] [G loss: 0.548733]\n",
      "[Epoch 17/200] [Batch 262/637] [D loss: 0.164676] [G loss: 0.450180]\n",
      "[Epoch 17/200] [Batch 263/637] [D loss: 0.143189] [G loss: 0.496377]\n",
      "[Epoch 17/200] [Batch 264/637] [D loss: 0.147222] [G loss: 0.545526]\n",
      "[Epoch 17/200] [Batch 265/637] [D loss: 0.143839] [G loss: 0.527893]\n",
      "[Epoch 17/200] [Batch 266/637] [D loss: 0.146657] [G loss: 0.473794]\n",
      "[Epoch 17/200] [Batch 267/637] [D loss: 0.165626] [G loss: 0.512497]\n",
      "[Epoch 17/200] [Batch 268/637] [D loss: 0.159713] [G loss: 0.627299]\n",
      "[Epoch 17/200] [Batch 269/637] [D loss: 0.145773] [G loss: 0.527798]\n",
      "[Epoch 17/200] [Batch 270/637] [D loss: 0.161119] [G loss: 0.454632]\n",
      "[Epoch 17/200] [Batch 271/637] [D loss: 0.154333] [G loss: 0.501134]\n",
      "[Epoch 17/200] [Batch 272/637] [D loss: 0.154288] [G loss: 0.480203]\n",
      "[Epoch 17/200] [Batch 273/637] [D loss: 0.147634] [G loss: 0.605911]\n",
      "[Epoch 17/200] [Batch 274/637] [D loss: 0.189216] [G loss: 0.445106]\n",
      "[Epoch 17/200] [Batch 275/637] [D loss: 0.172844] [G loss: 0.487071]\n",
      "[Epoch 17/200] [Batch 276/637] [D loss: 0.192179] [G loss: 0.436426]\n",
      "[Epoch 17/200] [Batch 277/637] [D loss: 0.169305] [G loss: 0.516310]\n",
      "[Epoch 17/200] [Batch 278/637] [D loss: 0.191753] [G loss: 0.483862]\n",
      "[Epoch 17/200] [Batch 279/637] [D loss: 0.165733] [G loss: 0.491616]\n",
      "[Epoch 17/200] [Batch 280/637] [D loss: 0.199868] [G loss: 0.520630]\n",
      "[Epoch 17/200] [Batch 281/637] [D loss: 0.168105] [G loss: 0.536756]\n",
      "[Epoch 17/200] [Batch 282/637] [D loss: 0.182117] [G loss: 0.544232]\n",
      "[Epoch 17/200] [Batch 283/637] [D loss: 0.171665] [G loss: 0.521558]\n",
      "[Epoch 17/200] [Batch 284/637] [D loss: 0.167230] [G loss: 0.482799]\n",
      "[Epoch 17/200] [Batch 285/637] [D loss: 0.132575] [G loss: 0.533695]\n",
      "[Epoch 17/200] [Batch 286/637] [D loss: 0.166951] [G loss: 0.471756]\n",
      "[Epoch 17/200] [Batch 287/637] [D loss: 0.150460] [G loss: 0.523503]\n",
      "[Epoch 17/200] [Batch 288/637] [D loss: 0.140818] [G loss: 0.508017]\n",
      "[Epoch 17/200] [Batch 289/637] [D loss: 0.140985] [G loss: 0.483934]\n",
      "[Epoch 17/200] [Batch 290/637] [D loss: 0.148180] [G loss: 0.565376]\n",
      "[Epoch 17/200] [Batch 291/637] [D loss: 0.169757] [G loss: 0.595231]\n",
      "[Epoch 17/200] [Batch 292/637] [D loss: 0.169361] [G loss: 0.517396]\n",
      "[Epoch 17/200] [Batch 293/637] [D loss: 0.127644] [G loss: 0.481050]\n",
      "[Epoch 17/200] [Batch 294/637] [D loss: 0.144526] [G loss: 0.549535]\n",
      "[Epoch 17/200] [Batch 295/637] [D loss: 0.167498] [G loss: 0.492052]\n",
      "[Epoch 17/200] [Batch 296/637] [D loss: 0.147659] [G loss: 0.575677]\n",
      "[Epoch 17/200] [Batch 297/637] [D loss: 0.153216] [G loss: 0.482892]\n",
      "[Epoch 17/200] [Batch 298/637] [D loss: 0.143800] [G loss: 0.579418]\n",
      "[Epoch 17/200] [Batch 299/637] [D loss: 0.154024] [G loss: 0.464460]\n",
      "[Epoch 17/200] [Batch 300/637] [D loss: 0.169602] [G loss: 0.479777]\n",
      "[Epoch 17/200] [Batch 301/637] [D loss: 0.157715] [G loss: 0.508845]\n",
      "[Epoch 17/200] [Batch 302/637] [D loss: 0.144967] [G loss: 0.524375]\n",
      "[Epoch 17/200] [Batch 303/637] [D loss: 0.161803] [G loss: 0.534053]\n",
      "[Epoch 17/200] [Batch 304/637] [D loss: 0.156832] [G loss: 0.526185]\n",
      "[Epoch 17/200] [Batch 305/637] [D loss: 0.181658] [G loss: 0.575883]\n",
      "[Epoch 17/200] [Batch 306/637] [D loss: 0.197402] [G loss: 0.462192]\n",
      "[Epoch 17/200] [Batch 307/637] [D loss: 0.178846] [G loss: 0.619981]\n",
      "[Epoch 17/200] [Batch 308/637] [D loss: 0.158868] [G loss: 0.583593]\n",
      "[Epoch 17/200] [Batch 309/637] [D loss: 0.156006] [G loss: 0.524305]\n",
      "[Epoch 17/200] [Batch 310/637] [D loss: 0.162226] [G loss: 0.454291]\n",
      "[Epoch 17/200] [Batch 311/637] [D loss: 0.156376] [G loss: 0.585610]\n",
      "[Epoch 17/200] [Batch 312/637] [D loss: 0.157254] [G loss: 0.610145]\n",
      "[Epoch 17/200] [Batch 313/637] [D loss: 0.150826] [G loss: 0.629295]\n",
      "[Epoch 17/200] [Batch 314/637] [D loss: 0.161349] [G loss: 0.507760]\n",
      "[Epoch 17/200] [Batch 315/637] [D loss: 0.197565] [G loss: 0.515267]\n",
      "[Epoch 17/200] [Batch 316/637] [D loss: 0.247325] [G loss: 0.658308]\n",
      "[Epoch 17/200] [Batch 317/637] [D loss: 0.176166] [G loss: 0.589028]\n",
      "[Epoch 17/200] [Batch 318/637] [D loss: 0.174920] [G loss: 0.580978]\n",
      "[Epoch 17/200] [Batch 319/637] [D loss: 0.128927] [G loss: 0.568177]\n",
      "[Epoch 17/200] [Batch 320/637] [D loss: 0.134091] [G loss: 0.457571]\n",
      "[Epoch 17/200] [Batch 321/637] [D loss: 0.170027] [G loss: 0.429052]\n",
      "[Epoch 17/200] [Batch 322/637] [D loss: 0.169764] [G loss: 0.567549]\n",
      "[Epoch 17/200] [Batch 323/637] [D loss: 0.143682] [G loss: 0.517629]\n",
      "[Epoch 17/200] [Batch 324/637] [D loss: 0.167461] [G loss: 0.500925]\n",
      "[Epoch 17/200] [Batch 325/637] [D loss: 0.138349] [G loss: 0.630752]\n",
      "[Epoch 17/200] [Batch 326/637] [D loss: 0.176737] [G loss: 0.516370]\n",
      "[Epoch 17/200] [Batch 327/637] [D loss: 0.162141] [G loss: 0.449619]\n",
      "[Epoch 17/200] [Batch 328/637] [D loss: 0.177732] [G loss: 0.493265]\n",
      "[Epoch 17/200] [Batch 329/637] [D loss: 0.193870] [G loss: 0.542146]\n",
      "[Epoch 17/200] [Batch 330/637] [D loss: 0.158522] [G loss: 0.552496]\n",
      "[Epoch 17/200] [Batch 331/637] [D loss: 0.163483] [G loss: 0.507727]\n",
      "[Epoch 17/200] [Batch 332/637] [D loss: 0.169123] [G loss: 0.447793]\n",
      "[Epoch 17/200] [Batch 333/637] [D loss: 0.132006] [G loss: 0.523935]\n",
      "[Epoch 17/200] [Batch 334/637] [D loss: 0.166261] [G loss: 0.441625]\n",
      "[Epoch 17/200] [Batch 335/637] [D loss: 0.163678] [G loss: 0.479191]\n",
      "[Epoch 17/200] [Batch 336/637] [D loss: 0.166204] [G loss: 0.549037]\n",
      "[Epoch 17/200] [Batch 337/637] [D loss: 0.135681] [G loss: 0.539693]\n",
      "[Epoch 17/200] [Batch 338/637] [D loss: 0.198510] [G loss: 0.448779]\n",
      "[Epoch 17/200] [Batch 339/637] [D loss: 0.234679] [G loss: 0.647605]\n",
      "[Epoch 17/200] [Batch 340/637] [D loss: 0.169337] [G loss: 0.495061]\n",
      "[Epoch 17/200] [Batch 341/637] [D loss: 0.175158] [G loss: 0.433340]\n",
      "[Epoch 17/200] [Batch 342/637] [D loss: 0.148816] [G loss: 0.457982]\n",
      "[Epoch 17/200] [Batch 343/637] [D loss: 0.202878] [G loss: 0.454179]\n",
      "[Epoch 17/200] [Batch 344/637] [D loss: 0.169058] [G loss: 0.441003]\n",
      "[Epoch 17/200] [Batch 345/637] [D loss: 0.151787] [G loss: 0.458566]\n",
      "[Epoch 17/200] [Batch 346/637] [D loss: 0.182578] [G loss: 0.506760]\n",
      "[Epoch 17/200] [Batch 347/637] [D loss: 0.149811] [G loss: 0.539358]\n",
      "[Epoch 17/200] [Batch 348/637] [D loss: 0.151223] [G loss: 0.546330]\n",
      "[Epoch 17/200] [Batch 349/637] [D loss: 0.169072] [G loss: 0.469629]\n",
      "[Epoch 17/200] [Batch 350/637] [D loss: 0.143990] [G loss: 0.513525]\n",
      "[Epoch 17/200] [Batch 351/637] [D loss: 0.150640] [G loss: 0.461434]\n",
      "[Epoch 17/200] [Batch 352/637] [D loss: 0.151857] [G loss: 0.506927]\n",
      "[Epoch 17/200] [Batch 353/637] [D loss: 0.146881] [G loss: 0.525424]\n",
      "[Epoch 17/200] [Batch 354/637] [D loss: 0.133602] [G loss: 0.524084]\n",
      "[Epoch 17/200] [Batch 355/637] [D loss: 0.175092] [G loss: 0.465326]\n",
      "[Epoch 17/200] [Batch 356/637] [D loss: 0.145902] [G loss: 0.512161]\n",
      "[Epoch 17/200] [Batch 357/637] [D loss: 0.177203] [G loss: 0.516953]\n",
      "[Epoch 17/200] [Batch 358/637] [D loss: 0.143979] [G loss: 0.505627]\n",
      "[Epoch 17/200] [Batch 359/637] [D loss: 0.163749] [G loss: 0.485379]\n",
      "[Epoch 17/200] [Batch 360/637] [D loss: 0.152252] [G loss: 0.496091]\n",
      "[Epoch 17/200] [Batch 361/637] [D loss: 0.171923] [G loss: 0.490623]\n",
      "[Epoch 17/200] [Batch 362/637] [D loss: 0.188885] [G loss: 0.438615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 363/637] [D loss: 0.151446] [G loss: 0.536412]\n",
      "[Epoch 17/200] [Batch 364/637] [D loss: 0.159698] [G loss: 0.515073]\n",
      "[Epoch 17/200] [Batch 365/637] [D loss: 0.152049] [G loss: 0.502978]\n",
      "[Epoch 17/200] [Batch 366/637] [D loss: 0.157312] [G loss: 0.540862]\n",
      "[Epoch 17/200] [Batch 367/637] [D loss: 0.170745] [G loss: 0.506091]\n",
      "[Epoch 17/200] [Batch 368/637] [D loss: 0.150610] [G loss: 0.484708]\n",
      "[Epoch 17/200] [Batch 369/637] [D loss: 0.154477] [G loss: 0.486461]\n",
      "[Epoch 17/200] [Batch 370/637] [D loss: 0.136321] [G loss: 0.543794]\n",
      "[Epoch 17/200] [Batch 371/637] [D loss: 0.136990] [G loss: 0.507589]\n",
      "[Epoch 17/200] [Batch 372/637] [D loss: 0.192364] [G loss: 0.442768]\n",
      "[Epoch 17/200] [Batch 373/637] [D loss: 0.169922] [G loss: 0.689966]\n",
      "[Epoch 17/200] [Batch 374/637] [D loss: 0.192360] [G loss: 0.588103]\n",
      "[Epoch 17/200] [Batch 375/637] [D loss: 0.163332] [G loss: 0.481931]\n",
      "[Epoch 17/200] [Batch 376/637] [D loss: 0.187858] [G loss: 0.447790]\n",
      "[Epoch 17/200] [Batch 377/637] [D loss: 0.161584] [G loss: 0.554253]\n",
      "[Epoch 17/200] [Batch 378/637] [D loss: 0.158516] [G loss: 0.538079]\n",
      "[Epoch 17/200] [Batch 379/637] [D loss: 0.164332] [G loss: 0.475028]\n",
      "[Epoch 17/200] [Batch 380/637] [D loss: 0.185780] [G loss: 0.429868]\n",
      "[Epoch 17/200] [Batch 381/637] [D loss: 0.170013] [G loss: 0.552629]\n",
      "[Epoch 17/200] [Batch 382/637] [D loss: 0.167558] [G loss: 0.506464]\n",
      "[Epoch 17/200] [Batch 383/637] [D loss: 0.180373] [G loss: 0.502445]\n",
      "[Epoch 17/200] [Batch 384/637] [D loss: 0.169665] [G loss: 0.491139]\n",
      "[Epoch 17/200] [Batch 385/637] [D loss: 0.158599] [G loss: 0.493554]\n",
      "[Epoch 17/200] [Batch 386/637] [D loss: 0.153366] [G loss: 0.567564]\n",
      "[Epoch 17/200] [Batch 387/637] [D loss: 0.156972] [G loss: 0.556583]\n",
      "[Epoch 17/200] [Batch 388/637] [D loss: 0.162009] [G loss: 0.508918]\n",
      "[Epoch 17/200] [Batch 389/637] [D loss: 0.179712] [G loss: 0.504502]\n",
      "[Epoch 17/200] [Batch 390/637] [D loss: 0.137872] [G loss: 0.577965]\n",
      "[Epoch 17/200] [Batch 391/637] [D loss: 0.171506] [G loss: 0.489687]\n",
      "[Epoch 17/200] [Batch 392/637] [D loss: 0.166255] [G loss: 0.644951]\n",
      "[Epoch 17/200] [Batch 393/637] [D loss: 0.147989] [G loss: 0.587349]\n",
      "[Epoch 17/200] [Batch 394/637] [D loss: 0.151159] [G loss: 0.518593]\n",
      "[Epoch 17/200] [Batch 395/637] [D loss: 0.168995] [G loss: 0.468203]\n",
      "[Epoch 17/200] [Batch 396/637] [D loss: 0.147278] [G loss: 0.531736]\n",
      "[Epoch 17/200] [Batch 397/637] [D loss: 0.206892] [G loss: 0.645357]\n",
      "[Epoch 17/200] [Batch 398/637] [D loss: 0.178898] [G loss: 0.549465]\n",
      "[Epoch 17/200] [Batch 399/637] [D loss: 0.169948] [G loss: 0.547533]\n",
      "[Epoch 17/200] [Batch 400/637] [D loss: 0.163003] [G loss: 0.579592]\n",
      "[Epoch 17/200] [Batch 401/637] [D loss: 0.157970] [G loss: 0.601426]\n",
      "[Epoch 17/200] [Batch 402/637] [D loss: 0.153576] [G loss: 0.535322]\n",
      "[Epoch 17/200] [Batch 403/637] [D loss: 0.188084] [G loss: 0.540721]\n",
      "[Epoch 17/200] [Batch 404/637] [D loss: 0.178451] [G loss: 0.500148]\n",
      "[Epoch 17/200] [Batch 405/637] [D loss: 0.156059] [G loss: 0.520254]\n",
      "[Epoch 17/200] [Batch 406/637] [D loss: 0.139995] [G loss: 0.523995]\n",
      "[Epoch 17/200] [Batch 407/637] [D loss: 0.165841] [G loss: 0.425902]\n",
      "[Epoch 17/200] [Batch 408/637] [D loss: 0.148246] [G loss: 0.493202]\n",
      "[Epoch 17/200] [Batch 409/637] [D loss: 0.152847] [G loss: 0.592132]\n",
      "[Epoch 17/200] [Batch 410/637] [D loss: 0.156199] [G loss: 0.506041]\n",
      "[Epoch 17/200] [Batch 411/637] [D loss: 0.140525] [G loss: 0.548421]\n",
      "[Epoch 17/200] [Batch 412/637] [D loss: 0.167740] [G loss: 0.495517]\n",
      "[Epoch 17/200] [Batch 413/637] [D loss: 0.183451] [G loss: 0.521327]\n",
      "[Epoch 17/200] [Batch 414/637] [D loss: 0.174900] [G loss: 0.465908]\n",
      "[Epoch 17/200] [Batch 415/637] [D loss: 0.137593] [G loss: 0.590254]\n",
      "[Epoch 17/200] [Batch 416/637] [D loss: 0.169435] [G loss: 0.487828]\n",
      "[Epoch 17/200] [Batch 417/637] [D loss: 0.162801] [G loss: 0.588439]\n",
      "[Epoch 17/200] [Batch 418/637] [D loss: 0.168233] [G loss: 0.492353]\n",
      "[Epoch 17/200] [Batch 419/637] [D loss: 0.159804] [G loss: 0.503394]\n",
      "[Epoch 17/200] [Batch 420/637] [D loss: 0.135083] [G loss: 0.532664]\n",
      "[Epoch 17/200] [Batch 421/637] [D loss: 0.143495] [G loss: 0.568834]\n",
      "[Epoch 17/200] [Batch 422/637] [D loss: 0.176688] [G loss: 0.424586]\n",
      "[Epoch 17/200] [Batch 423/637] [D loss: 0.202937] [G loss: 0.568783]\n",
      "[Epoch 17/200] [Batch 424/637] [D loss: 0.173318] [G loss: 0.663803]\n",
      "[Epoch 17/200] [Batch 425/637] [D loss: 0.182495] [G loss: 0.597771]\n",
      "[Epoch 17/200] [Batch 426/637] [D loss: 0.156807] [G loss: 0.526867]\n",
      "[Epoch 17/200] [Batch 427/637] [D loss: 0.184277] [G loss: 0.429413]\n",
      "[Epoch 17/200] [Batch 428/637] [D loss: 0.160319] [G loss: 0.404367]\n",
      "[Epoch 17/200] [Batch 429/637] [D loss: 0.175732] [G loss: 0.379645]\n",
      "[Epoch 17/200] [Batch 430/637] [D loss: 0.159673] [G loss: 0.542827]\n",
      "[Epoch 17/200] [Batch 431/637] [D loss: 0.160803] [G loss: 0.549091]\n",
      "[Epoch 17/200] [Batch 432/637] [D loss: 0.155212] [G loss: 0.525562]\n",
      "[Epoch 17/200] [Batch 433/637] [D loss: 0.187340] [G loss: 0.411497]\n",
      "[Epoch 17/200] [Batch 434/637] [D loss: 0.180672] [G loss: 0.550839]\n",
      "[Epoch 17/200] [Batch 435/637] [D loss: 0.176361] [G loss: 0.518249]\n",
      "[Epoch 17/200] [Batch 436/637] [D loss: 0.178836] [G loss: 0.464844]\n",
      "[Epoch 17/200] [Batch 437/637] [D loss: 0.155864] [G loss: 0.466496]\n",
      "[Epoch 17/200] [Batch 438/637] [D loss: 0.132542] [G loss: 0.561210]\n",
      "[Epoch 17/200] [Batch 439/637] [D loss: 0.170222] [G loss: 0.477219]\n",
      "[Epoch 17/200] [Batch 440/637] [D loss: 0.154826] [G loss: 0.472942]\n",
      "[Epoch 17/200] [Batch 441/637] [D loss: 0.166807] [G loss: 0.456634]\n",
      "[Epoch 17/200] [Batch 442/637] [D loss: 0.147788] [G loss: 0.498815]\n",
      "[Epoch 17/200] [Batch 443/637] [D loss: 0.162153] [G loss: 0.574008]\n",
      "[Epoch 17/200] [Batch 444/637] [D loss: 0.143175] [G loss: 0.563137]\n",
      "[Epoch 17/200] [Batch 445/637] [D loss: 0.160361] [G loss: 0.522054]\n",
      "[Epoch 17/200] [Batch 446/637] [D loss: 0.151952] [G loss: 0.475337]\n",
      "[Epoch 17/200] [Batch 447/637] [D loss: 0.145342] [G loss: 0.486139]\n",
      "[Epoch 17/200] [Batch 448/637] [D loss: 0.179628] [G loss: 0.531828]\n",
      "[Epoch 17/200] [Batch 449/637] [D loss: 0.267113] [G loss: 0.632321]\n",
      "[Epoch 17/200] [Batch 450/637] [D loss: 0.159151] [G loss: 0.532492]\n",
      "[Epoch 17/200] [Batch 451/637] [D loss: 0.178131] [G loss: 0.491203]\n",
      "[Epoch 17/200] [Batch 452/637] [D loss: 0.153596] [G loss: 0.520965]\n",
      "[Epoch 17/200] [Batch 453/637] [D loss: 0.160893] [G loss: 0.513990]\n",
      "[Epoch 17/200] [Batch 454/637] [D loss: 0.167582] [G loss: 0.492466]\n",
      "[Epoch 17/200] [Batch 455/637] [D loss: 0.171558] [G loss: 0.534552]\n",
      "[Epoch 17/200] [Batch 456/637] [D loss: 0.153963] [G loss: 0.507017]\n",
      "[Epoch 17/200] [Batch 457/637] [D loss: 0.153314] [G loss: 0.524394]\n",
      "[Epoch 17/200] [Batch 458/637] [D loss: 0.163342] [G loss: 0.485785]\n",
      "[Epoch 17/200] [Batch 459/637] [D loss: 0.160204] [G loss: 0.506669]\n",
      "[Epoch 17/200] [Batch 460/637] [D loss: 0.163563] [G loss: 0.539915]\n",
      "[Epoch 17/200] [Batch 461/637] [D loss: 0.149397] [G loss: 0.502629]\n",
      "[Epoch 17/200] [Batch 462/637] [D loss: 0.146513] [G loss: 0.517385]\n",
      "[Epoch 17/200] [Batch 463/637] [D loss: 0.158139] [G loss: 0.513365]\n",
      "[Epoch 17/200] [Batch 464/637] [D loss: 0.172391] [G loss: 0.480002]\n",
      "[Epoch 17/200] [Batch 465/637] [D loss: 0.153824] [G loss: 0.549790]\n",
      "[Epoch 17/200] [Batch 466/637] [D loss: 0.144219] [G loss: 0.555724]\n",
      "[Epoch 17/200] [Batch 467/637] [D loss: 0.157671] [G loss: 0.491933]\n",
      "[Epoch 17/200] [Batch 468/637] [D loss: 0.169520] [G loss: 0.517125]\n",
      "[Epoch 17/200] [Batch 469/637] [D loss: 0.188771] [G loss: 0.543914]\n",
      "[Epoch 17/200] [Batch 470/637] [D loss: 0.152871] [G loss: 0.478351]\n",
      "[Epoch 17/200] [Batch 471/637] [D loss: 0.147267] [G loss: 0.486582]\n",
      "[Epoch 17/200] [Batch 472/637] [D loss: 0.151824] [G loss: 0.488191]\n",
      "[Epoch 17/200] [Batch 473/637] [D loss: 0.155499] [G loss: 0.539407]\n",
      "[Epoch 17/200] [Batch 474/637] [D loss: 0.152476] [G loss: 0.499725]\n",
      "[Epoch 17/200] [Batch 475/637] [D loss: 0.144108] [G loss: 0.531755]\n",
      "[Epoch 17/200] [Batch 476/637] [D loss: 0.177564] [G loss: 0.451871]\n",
      "[Epoch 17/200] [Batch 477/637] [D loss: 0.175361] [G loss: 0.520237]\n",
      "[Epoch 17/200] [Batch 478/637] [D loss: 0.168518] [G loss: 0.482192]\n",
      "[Epoch 17/200] [Batch 479/637] [D loss: 0.185714] [G loss: 0.479021]\n",
      "[Epoch 17/200] [Batch 480/637] [D loss: 0.166237] [G loss: 0.472512]\n",
      "[Epoch 17/200] [Batch 481/637] [D loss: 0.155110] [G loss: 0.503922]\n",
      "[Epoch 17/200] [Batch 482/637] [D loss: 0.164493] [G loss: 0.490105]\n",
      "[Epoch 17/200] [Batch 483/637] [D loss: 0.150990] [G loss: 0.497320]\n",
      "[Epoch 17/200] [Batch 484/637] [D loss: 0.169830] [G loss: 0.431185]\n",
      "[Epoch 17/200] [Batch 485/637] [D loss: 0.174833] [G loss: 0.617306]\n",
      "[Epoch 17/200] [Batch 486/637] [D loss: 0.167987] [G loss: 0.533781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 487/637] [D loss: 0.182779] [G loss: 0.428629]\n",
      "[Epoch 17/200] [Batch 488/637] [D loss: 0.181478] [G loss: 0.431436]\n",
      "[Epoch 17/200] [Batch 489/637] [D loss: 0.143577] [G loss: 0.539179]\n",
      "[Epoch 17/200] [Batch 490/637] [D loss: 0.167374] [G loss: 0.523125]\n",
      "[Epoch 17/200] [Batch 491/637] [D loss: 0.188373] [G loss: 0.463213]\n",
      "[Epoch 17/200] [Batch 492/637] [D loss: 0.161611] [G loss: 0.431770]\n",
      "[Epoch 17/200] [Batch 493/637] [D loss: 0.186488] [G loss: 0.409327]\n",
      "[Epoch 17/200] [Batch 494/637] [D loss: 0.175496] [G loss: 0.472575]\n",
      "[Epoch 17/200] [Batch 495/637] [D loss: 0.147775] [G loss: 0.524832]\n",
      "[Epoch 17/200] [Batch 496/637] [D loss: 0.161856] [G loss: 0.513426]\n",
      "[Epoch 17/200] [Batch 497/637] [D loss: 0.158608] [G loss: 0.505196]\n",
      "[Epoch 17/200] [Batch 498/637] [D loss: 0.147056] [G loss: 0.501081]\n",
      "[Epoch 17/200] [Batch 499/637] [D loss: 0.162979] [G loss: 0.526573]\n",
      "[Epoch 17/200] [Batch 500/637] [D loss: 0.169694] [G loss: 0.518609]\n",
      "[Epoch 17/200] [Batch 501/637] [D loss: 0.144757] [G loss: 0.520303]\n",
      "[Epoch 17/200] [Batch 502/637] [D loss: 0.167461] [G loss: 0.505515]\n",
      "[Epoch 17/200] [Batch 503/637] [D loss: 0.153504] [G loss: 0.491506]\n",
      "[Epoch 17/200] [Batch 504/637] [D loss: 0.140502] [G loss: 0.498219]\n",
      "[Epoch 17/200] [Batch 505/637] [D loss: 0.143587] [G loss: 0.493092]\n",
      "[Epoch 17/200] [Batch 506/637] [D loss: 0.173652] [G loss: 0.457848]\n",
      "[Epoch 17/200] [Batch 507/637] [D loss: 0.194060] [G loss: 0.435749]\n",
      "[Epoch 17/200] [Batch 508/637] [D loss: 0.162706] [G loss: 0.560137]\n",
      "[Epoch 17/200] [Batch 509/637] [D loss: 0.168967] [G loss: 0.527866]\n",
      "[Epoch 17/200] [Batch 510/637] [D loss: 0.205731] [G loss: 0.467258]\n",
      "[Epoch 17/200] [Batch 511/637] [D loss: 0.187241] [G loss: 0.501054]\n",
      "[Epoch 17/200] [Batch 512/637] [D loss: 0.157215] [G loss: 0.503553]\n",
      "[Epoch 17/200] [Batch 513/637] [D loss: 0.142750] [G loss: 0.459131]\n",
      "[Epoch 17/200] [Batch 514/637] [D loss: 0.179879] [G loss: 0.421795]\n",
      "[Epoch 17/200] [Batch 515/637] [D loss: 0.154074] [G loss: 0.513110]\n",
      "[Epoch 17/200] [Batch 516/637] [D loss: 0.163166] [G loss: 0.535583]\n",
      "[Epoch 17/200] [Batch 517/637] [D loss: 0.167542] [G loss: 0.523688]\n",
      "[Epoch 17/200] [Batch 518/637] [D loss: 0.162593] [G loss: 0.459332]\n",
      "[Epoch 17/200] [Batch 519/637] [D loss: 0.156189] [G loss: 0.521975]\n",
      "[Epoch 17/200] [Batch 520/637] [D loss: 0.175471] [G loss: 0.453911]\n",
      "[Epoch 17/200] [Batch 521/637] [D loss: 0.182178] [G loss: 0.518337]\n",
      "[Epoch 17/200] [Batch 522/637] [D loss: 0.164196] [G loss: 0.605797]\n",
      "[Epoch 17/200] [Batch 523/637] [D loss: 0.154322] [G loss: 0.568001]\n",
      "[Epoch 17/200] [Batch 524/637] [D loss: 0.161942] [G loss: 0.498455]\n",
      "[Epoch 17/200] [Batch 525/637] [D loss: 0.173325] [G loss: 0.542531]\n",
      "[Epoch 17/200] [Batch 526/637] [D loss: 0.140854] [G loss: 0.563628]\n",
      "[Epoch 17/200] [Batch 527/637] [D loss: 0.130817] [G loss: 0.536526]\n",
      "[Epoch 17/200] [Batch 528/637] [D loss: 0.160189] [G loss: 0.451928]\n",
      "[Epoch 17/200] [Batch 529/637] [D loss: 0.183324] [G loss: 0.521065]\n",
      "[Epoch 17/200] [Batch 530/637] [D loss: 0.139863] [G loss: 0.528689]\n",
      "[Epoch 17/200] [Batch 531/637] [D loss: 0.152870] [G loss: 0.537634]\n",
      "[Epoch 17/200] [Batch 532/637] [D loss: 0.180132] [G loss: 0.524578]\n",
      "[Epoch 17/200] [Batch 533/637] [D loss: 0.169275] [G loss: 0.485664]\n",
      "[Epoch 17/200] [Batch 534/637] [D loss: 0.157148] [G loss: 0.500566]\n",
      "[Epoch 17/200] [Batch 535/637] [D loss: 0.142976] [G loss: 0.473649]\n",
      "[Epoch 17/200] [Batch 536/637] [D loss: 0.163101] [G loss: 0.448296]\n",
      "[Epoch 17/200] [Batch 537/637] [D loss: 0.147163] [G loss: 0.510972]\n",
      "[Epoch 17/200] [Batch 538/637] [D loss: 0.172158] [G loss: 0.479727]\n",
      "[Epoch 17/200] [Batch 539/637] [D loss: 0.163709] [G loss: 0.525211]\n",
      "[Epoch 17/200] [Batch 540/637] [D loss: 0.122704] [G loss: 0.555203]\n",
      "[Epoch 17/200] [Batch 541/637] [D loss: 0.192264] [G loss: 0.487443]\n",
      "[Epoch 17/200] [Batch 542/637] [D loss: 0.164213] [G loss: 0.551971]\n",
      "[Epoch 17/200] [Batch 543/637] [D loss: 0.162294] [G loss: 0.490978]\n",
      "[Epoch 17/200] [Batch 544/637] [D loss: 0.154339] [G loss: 0.516997]\n",
      "[Epoch 17/200] [Batch 545/637] [D loss: 0.155643] [G loss: 0.496953]\n",
      "[Epoch 17/200] [Batch 546/637] [D loss: 0.137745] [G loss: 0.533662]\n",
      "[Epoch 17/200] [Batch 547/637] [D loss: 0.177688] [G loss: 0.477422]\n",
      "[Epoch 17/200] [Batch 548/637] [D loss: 0.181902] [G loss: 0.548801]\n",
      "[Epoch 17/200] [Batch 549/637] [D loss: 0.144498] [G loss: 0.561585]\n",
      "[Epoch 17/200] [Batch 550/637] [D loss: 0.167781] [G loss: 0.506229]\n",
      "[Epoch 17/200] [Batch 551/637] [D loss: 0.151444] [G loss: 0.533982]\n",
      "[Epoch 17/200] [Batch 552/637] [D loss: 0.164496] [G loss: 0.467375]\n",
      "[Epoch 17/200] [Batch 553/637] [D loss: 0.137195] [G loss: 0.601286]\n",
      "[Epoch 17/200] [Batch 554/637] [D loss: 0.170285] [G loss: 0.430443]\n",
      "[Epoch 17/200] [Batch 555/637] [D loss: 0.148212] [G loss: 0.517735]\n",
      "[Epoch 17/200] [Batch 556/637] [D loss: 0.150872] [G loss: 0.509650]\n",
      "[Epoch 17/200] [Batch 557/637] [D loss: 0.136062] [G loss: 0.555064]\n",
      "[Epoch 17/200] [Batch 558/637] [D loss: 0.154687] [G loss: 0.503679]\n",
      "[Epoch 17/200] [Batch 559/637] [D loss: 0.130788] [G loss: 0.537566]\n",
      "[Epoch 17/200] [Batch 560/637] [D loss: 0.164667] [G loss: 0.467182]\n",
      "[Epoch 17/200] [Batch 561/637] [D loss: 0.180903] [G loss: 0.596661]\n",
      "[Epoch 17/200] [Batch 562/637] [D loss: 0.148483] [G loss: 0.560179]\n",
      "[Epoch 17/200] [Batch 563/637] [D loss: 0.162500] [G loss: 0.489163]\n",
      "[Epoch 17/200] [Batch 564/637] [D loss: 0.153889] [G loss: 0.489987]\n",
      "[Epoch 17/200] [Batch 565/637] [D loss: 0.163438] [G loss: 0.433602]\n",
      "[Epoch 17/200] [Batch 566/637] [D loss: 0.168202] [G loss: 0.480686]\n",
      "[Epoch 17/200] [Batch 567/637] [D loss: 0.165493] [G loss: 0.549017]\n",
      "[Epoch 17/200] [Batch 568/637] [D loss: 0.177293] [G loss: 0.487027]\n",
      "[Epoch 17/200] [Batch 569/637] [D loss: 0.176771] [G loss: 0.470898]\n",
      "[Epoch 17/200] [Batch 570/637] [D loss: 0.159248] [G loss: 0.563482]\n",
      "[Epoch 17/200] [Batch 571/637] [D loss: 0.183368] [G loss: 0.426544]\n",
      "[Epoch 17/200] [Batch 572/637] [D loss: 0.173301] [G loss: 0.496009]\n",
      "[Epoch 17/200] [Batch 573/637] [D loss: 0.155920] [G loss: 0.632515]\n",
      "[Epoch 17/200] [Batch 574/637] [D loss: 0.160831] [G loss: 0.540002]\n",
      "[Epoch 17/200] [Batch 575/637] [D loss: 0.161772] [G loss: 0.426953]\n",
      "[Epoch 17/200] [Batch 576/637] [D loss: 0.163892] [G loss: 0.469617]\n",
      "[Epoch 17/200] [Batch 577/637] [D loss: 0.164346] [G loss: 0.509160]\n",
      "[Epoch 17/200] [Batch 578/637] [D loss: 0.187468] [G loss: 0.504362]\n",
      "[Epoch 17/200] [Batch 579/637] [D loss: 0.153615] [G loss: 0.489865]\n",
      "[Epoch 17/200] [Batch 580/637] [D loss: 0.163178] [G loss: 0.472246]\n",
      "[Epoch 17/200] [Batch 581/637] [D loss: 0.166024] [G loss: 0.458961]\n",
      "[Epoch 17/200] [Batch 582/637] [D loss: 0.151927] [G loss: 0.514588]\n",
      "[Epoch 17/200] [Batch 583/637] [D loss: 0.163540] [G loss: 0.587832]\n",
      "[Epoch 17/200] [Batch 584/637] [D loss: 0.125065] [G loss: 0.558028]\n",
      "[Epoch 17/200] [Batch 585/637] [D loss: 0.160371] [G loss: 0.502158]\n",
      "[Epoch 17/200] [Batch 586/637] [D loss: 0.171956] [G loss: 0.503575]\n",
      "[Epoch 17/200] [Batch 587/637] [D loss: 0.157383] [G loss: 0.469009]\n",
      "[Epoch 17/200] [Batch 588/637] [D loss: 0.159218] [G loss: 0.577335]\n",
      "[Epoch 17/200] [Batch 589/637] [D loss: 0.152441] [G loss: 0.572843]\n",
      "[Epoch 17/200] [Batch 590/637] [D loss: 0.156519] [G loss: 0.518236]\n",
      "[Epoch 17/200] [Batch 591/637] [D loss: 0.172992] [G loss: 0.419959]\n",
      "[Epoch 17/200] [Batch 592/637] [D loss: 0.147370] [G loss: 0.522944]\n",
      "[Epoch 17/200] [Batch 593/637] [D loss: 0.147999] [G loss: 0.542935]\n",
      "[Epoch 17/200] [Batch 594/637] [D loss: 0.167114] [G loss: 0.506022]\n",
      "[Epoch 17/200] [Batch 595/637] [D loss: 0.161600] [G loss: 0.589435]\n",
      "[Epoch 17/200] [Batch 596/637] [D loss: 0.168515] [G loss: 0.527018]\n",
      "[Epoch 17/200] [Batch 597/637] [D loss: 0.151202] [G loss: 0.464534]\n",
      "[Epoch 17/200] [Batch 598/637] [D loss: 0.169815] [G loss: 0.437615]\n",
      "[Epoch 17/200] [Batch 599/637] [D loss: 0.173038] [G loss: 0.554085]\n",
      "[Epoch 17/200] [Batch 600/637] [D loss: 0.176593] [G loss: 0.519444]\n",
      "[Epoch 17/200] [Batch 601/637] [D loss: 0.175493] [G loss: 0.466256]\n",
      "[Epoch 17/200] [Batch 602/637] [D loss: 0.166411] [G loss: 0.483987]\n",
      "[Epoch 17/200] [Batch 603/637] [D loss: 0.170998] [G loss: 0.540979]\n",
      "[Epoch 17/200] [Batch 604/637] [D loss: 0.160582] [G loss: 0.491510]\n",
      "[Epoch 17/200] [Batch 605/637] [D loss: 0.158969] [G loss: 0.449704]\n",
      "[Epoch 17/200] [Batch 606/637] [D loss: 0.147326] [G loss: 0.543688]\n",
      "[Epoch 17/200] [Batch 607/637] [D loss: 0.170691] [G loss: 0.534429]\n",
      "[Epoch 17/200] [Batch 608/637] [D loss: 0.177420] [G loss: 0.500158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 609/637] [D loss: 0.167399] [G loss: 0.555543]\n",
      "[Epoch 17/200] [Batch 610/637] [D loss: 0.172532] [G loss: 0.500016]\n",
      "[Epoch 17/200] [Batch 611/637] [D loss: 0.170293] [G loss: 0.425644]\n",
      "[Epoch 17/200] [Batch 612/637] [D loss: 0.189789] [G loss: 0.397208]\n",
      "[Epoch 17/200] [Batch 613/637] [D loss: 0.175111] [G loss: 0.481632]\n",
      "[Epoch 17/200] [Batch 614/637] [D loss: 0.184522] [G loss: 0.477450]\n",
      "[Epoch 17/200] [Batch 615/637] [D loss: 0.147202] [G loss: 0.570048]\n",
      "[Epoch 17/200] [Batch 616/637] [D loss: 0.174783] [G loss: 0.468194]\n",
      "[Epoch 17/200] [Batch 617/637] [D loss: 0.131394] [G loss: 0.538937]\n",
      "[Epoch 17/200] [Batch 618/637] [D loss: 0.166710] [G loss: 0.569841]\n",
      "[Epoch 17/200] [Batch 619/637] [D loss: 0.193902] [G loss: 0.456386]\n",
      "[Epoch 17/200] [Batch 620/637] [D loss: 0.185538] [G loss: 0.576982]\n",
      "[Epoch 17/200] [Batch 621/637] [D loss: 0.178331] [G loss: 0.571918]\n",
      "[Epoch 17/200] [Batch 622/637] [D loss: 0.178214] [G loss: 0.456776]\n",
      "[Epoch 17/200] [Batch 623/637] [D loss: 0.133362] [G loss: 0.524074]\n",
      "[Epoch 17/200] [Batch 624/637] [D loss: 0.191363] [G loss: 0.462730]\n",
      "[Epoch 17/200] [Batch 625/637] [D loss: 0.189664] [G loss: 0.416795]\n",
      "[Epoch 17/200] [Batch 626/637] [D loss: 0.152656] [G loss: 0.621294]\n",
      "[Epoch 17/200] [Batch 627/637] [D loss: 0.161383] [G loss: 0.558758]\n",
      "[Epoch 17/200] [Batch 628/637] [D loss: 0.168902] [G loss: 0.499598]\n",
      "[Epoch 17/200] [Batch 629/637] [D loss: 0.174245] [G loss: 0.554249]\n",
      "[Epoch 17/200] [Batch 630/637] [D loss: 0.167689] [G loss: 0.490906]\n",
      "[Epoch 17/200] [Batch 631/637] [D loss: 0.168562] [G loss: 0.514857]\n",
      "[Epoch 17/200] [Batch 632/637] [D loss: 0.176913] [G loss: 0.501281]\n",
      "[Epoch 17/200] [Batch 633/637] [D loss: 0.161020] [G loss: 0.474208]\n",
      "[Epoch 17/200] [Batch 634/637] [D loss: 0.147119] [G loss: 0.518675]\n",
      "[Epoch 17/200] [Batch 635/637] [D loss: 0.186207] [G loss: 0.498981]\n",
      "[Epoch 17/200] [Batch 636/637] [D loss: 0.161516] [G loss: 0.540857]\n",
      "[Epoch 18/200] [Batch 0/637] [D loss: 0.149631] [G loss: 0.542664]\n",
      "[Epoch 18/200] [Batch 1/637] [D loss: 0.153939] [G loss: 0.539096]\n",
      "[Epoch 18/200] [Batch 2/637] [D loss: 0.155766] [G loss: 0.515424]\n",
      "[Epoch 18/200] [Batch 3/637] [D loss: 0.171035] [G loss: 0.500477]\n",
      "[Epoch 18/200] [Batch 4/637] [D loss: 0.137604] [G loss: 0.557926]\n",
      "[Epoch 18/200] [Batch 5/637] [D loss: 0.135972] [G loss: 0.536158]\n",
      "[Epoch 18/200] [Batch 6/637] [D loss: 0.153484] [G loss: 0.578259]\n",
      "[Epoch 18/200] [Batch 7/637] [D loss: 0.170002] [G loss: 0.551729]\n",
      "[Epoch 18/200] [Batch 8/637] [D loss: 0.159923] [G loss: 0.550473]\n",
      "[Epoch 18/200] [Batch 9/637] [D loss: 0.176860] [G loss: 0.624150]\n",
      "[Epoch 18/200] [Batch 10/637] [D loss: 0.189823] [G loss: 0.617838]\n",
      "[Epoch 18/200] [Batch 11/637] [D loss: 0.217985] [G loss: 0.471400]\n",
      "[Epoch 18/200] [Batch 12/637] [D loss: 0.175243] [G loss: 0.487549]\n",
      "[Epoch 18/200] [Batch 13/637] [D loss: 0.172164] [G loss: 0.526898]\n",
      "[Epoch 18/200] [Batch 14/637] [D loss: 0.154187] [G loss: 0.528660]\n",
      "[Epoch 18/200] [Batch 15/637] [D loss: 0.165126] [G loss: 0.495639]\n",
      "[Epoch 18/200] [Batch 16/637] [D loss: 0.163385] [G loss: 0.482520]\n",
      "[Epoch 18/200] [Batch 17/637] [D loss: 0.170606] [G loss: 0.477395]\n",
      "[Epoch 18/200] [Batch 18/637] [D loss: 0.161880] [G loss: 0.498406]\n",
      "[Epoch 18/200] [Batch 19/637] [D loss: 0.168020] [G loss: 0.476133]\n",
      "[Epoch 18/200] [Batch 20/637] [D loss: 0.127642] [G loss: 0.500051]\n",
      "[Epoch 18/200] [Batch 21/637] [D loss: 0.127809] [G loss: 0.509564]\n",
      "[Epoch 18/200] [Batch 22/637] [D loss: 0.169786] [G loss: 0.469411]\n",
      "[Epoch 18/200] [Batch 23/637] [D loss: 0.135243] [G loss: 0.506644]\n",
      "[Epoch 18/200] [Batch 24/637] [D loss: 0.149331] [G loss: 0.493239]\n",
      "[Epoch 18/200] [Batch 25/637] [D loss: 0.135864] [G loss: 0.556126]\n",
      "[Epoch 18/200] [Batch 26/637] [D loss: 0.172836] [G loss: 0.543890]\n",
      "[Epoch 18/200] [Batch 27/637] [D loss: 0.137825] [G loss: 0.534634]\n",
      "[Epoch 18/200] [Batch 28/637] [D loss: 0.181354] [G loss: 0.448486]\n",
      "[Epoch 18/200] [Batch 29/637] [D loss: 0.175042] [G loss: 0.574693]\n",
      "[Epoch 18/200] [Batch 30/637] [D loss: 0.147145] [G loss: 0.511172]\n",
      "[Epoch 18/200] [Batch 31/637] [D loss: 0.153803] [G loss: 0.474661]\n",
      "[Epoch 18/200] [Batch 32/637] [D loss: 0.152676] [G loss: 0.538629]\n",
      "[Epoch 18/200] [Batch 33/637] [D loss: 0.150344] [G loss: 0.527095]\n",
      "[Epoch 18/200] [Batch 34/637] [D loss: 0.152737] [G loss: 0.572236]\n",
      "[Epoch 18/200] [Batch 35/637] [D loss: 0.155353] [G loss: 0.473790]\n",
      "[Epoch 18/200] [Batch 36/637] [D loss: 0.149833] [G loss: 0.505642]\n",
      "[Epoch 18/200] [Batch 37/637] [D loss: 0.179330] [G loss: 0.476147]\n",
      "[Epoch 18/200] [Batch 38/637] [D loss: 0.160204] [G loss: 0.549975]\n",
      "[Epoch 18/200] [Batch 39/637] [D loss: 0.153726] [G loss: 0.489776]\n",
      "[Epoch 18/200] [Batch 40/637] [D loss: 0.148715] [G loss: 0.513576]\n",
      "[Epoch 18/200] [Batch 41/637] [D loss: 0.175301] [G loss: 0.429053]\n",
      "[Epoch 18/200] [Batch 42/637] [D loss: 0.174579] [G loss: 0.488757]\n",
      "[Epoch 18/200] [Batch 43/637] [D loss: 0.139479] [G loss: 0.559479]\n",
      "[Epoch 18/200] [Batch 44/637] [D loss: 0.159880] [G loss: 0.484628]\n",
      "[Epoch 18/200] [Batch 45/637] [D loss: 0.175128] [G loss: 0.425538]\n",
      "[Epoch 18/200] [Batch 46/637] [D loss: 0.136548] [G loss: 0.623670]\n",
      "[Epoch 18/200] [Batch 47/637] [D loss: 0.148081] [G loss: 0.486017]\n",
      "[Epoch 18/200] [Batch 48/637] [D loss: 0.166382] [G loss: 0.498484]\n",
      "[Epoch 18/200] [Batch 49/637] [D loss: 0.186544] [G loss: 0.618192]\n",
      "[Epoch 18/200] [Batch 50/637] [D loss: 0.151759] [G loss: 0.541336]\n",
      "[Epoch 18/200] [Batch 51/637] [D loss: 0.150011] [G loss: 0.500482]\n",
      "[Epoch 18/200] [Batch 52/637] [D loss: 0.136123] [G loss: 0.487799]\n",
      "[Epoch 18/200] [Batch 53/637] [D loss: 0.160486] [G loss: 0.494573]\n",
      "[Epoch 18/200] [Batch 54/637] [D loss: 0.143470] [G loss: 0.584099]\n",
      "[Epoch 18/200] [Batch 55/637] [D loss: 0.156466] [G loss: 0.462606]\n",
      "[Epoch 18/200] [Batch 56/637] [D loss: 0.144586] [G loss: 0.578804]\n",
      "[Epoch 18/200] [Batch 57/637] [D loss: 0.151664] [G loss: 0.491321]\n",
      "[Epoch 18/200] [Batch 58/637] [D loss: 0.160426] [G loss: 0.443549]\n",
      "[Epoch 18/200] [Batch 59/637] [D loss: 0.155524] [G loss: 0.463756]\n",
      "[Epoch 18/200] [Batch 60/637] [D loss: 0.151269] [G loss: 0.476331]\n",
      "[Epoch 18/200] [Batch 61/637] [D loss: 0.169839] [G loss: 0.446390]\n",
      "[Epoch 18/200] [Batch 62/637] [D loss: 0.165565] [G loss: 0.542906]\n",
      "[Epoch 18/200] [Batch 63/637] [D loss: 0.172324] [G loss: 0.445867]\n",
      "[Epoch 18/200] [Batch 64/637] [D loss: 0.179952] [G loss: 0.485738]\n",
      "[Epoch 18/200] [Batch 65/637] [D loss: 0.170101] [G loss: 0.471310]\n",
      "[Epoch 18/200] [Batch 66/637] [D loss: 0.147427] [G loss: 0.497213]\n",
      "[Epoch 18/200] [Batch 67/637] [D loss: 0.145636] [G loss: 0.477309]\n",
      "[Epoch 18/200] [Batch 68/637] [D loss: 0.183467] [G loss: 0.447875]\n",
      "[Epoch 18/200] [Batch 69/637] [D loss: 0.159501] [G loss: 0.510917]\n",
      "[Epoch 18/200] [Batch 70/637] [D loss: 0.223783] [G loss: 0.404504]\n",
      "[Epoch 18/200] [Batch 71/637] [D loss: 0.213513] [G loss: 0.566581]\n",
      "[Epoch 18/200] [Batch 72/637] [D loss: 0.165380] [G loss: 0.561358]\n",
      "[Epoch 18/200] [Batch 73/637] [D loss: 0.200272] [G loss: 0.542072]\n",
      "[Epoch 18/200] [Batch 74/637] [D loss: 0.171484] [G loss: 0.575817]\n",
      "[Epoch 18/200] [Batch 75/637] [D loss: 0.170903] [G loss: 0.433790]\n",
      "[Epoch 18/200] [Batch 76/637] [D loss: 0.189052] [G loss: 0.408048]\n",
      "[Epoch 18/200] [Batch 77/637] [D loss: 0.182732] [G loss: 0.374952]\n",
      "[Epoch 18/200] [Batch 78/637] [D loss: 0.159804] [G loss: 0.473212]\n",
      "[Epoch 18/200] [Batch 79/637] [D loss: 0.147130] [G loss: 0.543342]\n",
      "[Epoch 18/200] [Batch 80/637] [D loss: 0.158915] [G loss: 0.522541]\n",
      "[Epoch 18/200] [Batch 81/637] [D loss: 0.181363] [G loss: 0.549148]\n",
      "[Epoch 18/200] [Batch 82/637] [D loss: 0.171058] [G loss: 0.501242]\n",
      "[Epoch 18/200] [Batch 83/637] [D loss: 0.163818] [G loss: 0.487873]\n",
      "[Epoch 18/200] [Batch 84/637] [D loss: 0.144319] [G loss: 0.550354]\n",
      "[Epoch 18/200] [Batch 85/637] [D loss: 0.173105] [G loss: 0.461882]\n",
      "[Epoch 18/200] [Batch 86/637] [D loss: 0.171717] [G loss: 0.520280]\n",
      "[Epoch 18/200] [Batch 87/637] [D loss: 0.158970] [G loss: 0.561176]\n",
      "[Epoch 18/200] [Batch 88/637] [D loss: 0.125831] [G loss: 0.538364]\n",
      "[Epoch 18/200] [Batch 89/637] [D loss: 0.205519] [G loss: 0.359643]\n",
      "[Epoch 18/200] [Batch 90/637] [D loss: 0.212917] [G loss: 0.634800]\n",
      "[Epoch 18/200] [Batch 91/637] [D loss: 0.154825] [G loss: 0.592798]\n",
      "[Epoch 18/200] [Batch 92/637] [D loss: 0.168392] [G loss: 0.469906]\n",
      "[Epoch 18/200] [Batch 93/637] [D loss: 0.166607] [G loss: 0.520728]\n",
      "[Epoch 18/200] [Batch 94/637] [D loss: 0.170550] [G loss: 0.509492]\n",
      "[Epoch 18/200] [Batch 95/637] [D loss: 0.168740] [G loss: 0.473865]\n",
      "[Epoch 18/200] [Batch 96/637] [D loss: 0.163544] [G loss: 0.480552]\n",
      "[Epoch 18/200] [Batch 97/637] [D loss: 0.179136] [G loss: 0.494262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 98/637] [D loss: 0.187102] [G loss: 0.532081]\n",
      "[Epoch 18/200] [Batch 99/637] [D loss: 0.153252] [G loss: 0.478277]\n",
      "[Epoch 18/200] [Batch 100/637] [D loss: 0.165469] [G loss: 0.459128]\n",
      "[Epoch 18/200] [Batch 101/637] [D loss: 0.150861] [G loss: 0.486061]\n",
      "[Epoch 18/200] [Batch 102/637] [D loss: 0.163482] [G loss: 0.549060]\n",
      "[Epoch 18/200] [Batch 103/637] [D loss: 0.167317] [G loss: 0.521243]\n",
      "[Epoch 18/200] [Batch 104/637] [D loss: 0.174661] [G loss: 0.468405]\n",
      "[Epoch 18/200] [Batch 105/637] [D loss: 0.181659] [G loss: 0.506655]\n",
      "[Epoch 18/200] [Batch 106/637] [D loss: 0.172453] [G loss: 0.540061]\n",
      "[Epoch 18/200] [Batch 107/637] [D loss: 0.142909] [G loss: 0.571944]\n",
      "[Epoch 18/200] [Batch 108/637] [D loss: 0.145476] [G loss: 0.474014]\n",
      "[Epoch 18/200] [Batch 109/637] [D loss: 0.146510] [G loss: 0.466069]\n",
      "[Epoch 18/200] [Batch 110/637] [D loss: 0.135811] [G loss: 0.508976]\n",
      "[Epoch 18/200] [Batch 111/637] [D loss: 0.177837] [G loss: 0.499315]\n",
      "[Epoch 18/200] [Batch 112/637] [D loss: 0.168129] [G loss: 0.645542]\n",
      "[Epoch 18/200] [Batch 113/637] [D loss: 0.148898] [G loss: 0.547171]\n",
      "[Epoch 18/200] [Batch 114/637] [D loss: 0.141340] [G loss: 0.589804]\n",
      "[Epoch 18/200] [Batch 115/637] [D loss: 0.141319] [G loss: 0.572950]\n",
      "[Epoch 18/200] [Batch 116/637] [D loss: 0.135034] [G loss: 0.538996]\n",
      "[Epoch 18/200] [Batch 117/637] [D loss: 0.143915] [G loss: 0.473778]\n",
      "[Epoch 18/200] [Batch 118/637] [D loss: 0.139222] [G loss: 0.562103]\n",
      "[Epoch 18/200] [Batch 119/637] [D loss: 0.170113] [G loss: 0.534085]\n",
      "[Epoch 18/200] [Batch 120/637] [D loss: 0.186732] [G loss: 0.646745]\n",
      "[Epoch 18/200] [Batch 121/637] [D loss: 0.138886] [G loss: 0.527284]\n",
      "[Epoch 18/200] [Batch 122/637] [D loss: 0.140182] [G loss: 0.539995]\n",
      "[Epoch 18/200] [Batch 123/637] [D loss: 0.146597] [G loss: 0.590751]\n",
      "[Epoch 18/200] [Batch 124/637] [D loss: 0.143902] [G loss: 0.512425]\n",
      "[Epoch 18/200] [Batch 125/637] [D loss: 0.138025] [G loss: 0.505583]\n",
      "[Epoch 18/200] [Batch 126/637] [D loss: 0.172231] [G loss: 0.445402]\n",
      "[Epoch 18/200] [Batch 127/637] [D loss: 0.130596] [G loss: 0.547902]\n",
      "[Epoch 18/200] [Batch 128/637] [D loss: 0.185842] [G loss: 0.539695]\n",
      "[Epoch 18/200] [Batch 129/637] [D loss: 0.136321] [G loss: 0.573057]\n",
      "[Epoch 18/200] [Batch 130/637] [D loss: 0.134595] [G loss: 0.446091]\n",
      "[Epoch 18/200] [Batch 131/637] [D loss: 0.182456] [G loss: 0.502728]\n",
      "[Epoch 18/200] [Batch 132/637] [D loss: 0.153332] [G loss: 0.432508]\n",
      "[Epoch 18/200] [Batch 133/637] [D loss: 0.171334] [G loss: 0.499441]\n",
      "[Epoch 18/200] [Batch 134/637] [D loss: 0.162158] [G loss: 0.573528]\n",
      "[Epoch 18/200] [Batch 135/637] [D loss: 0.167980] [G loss: 0.504414]\n",
      "[Epoch 18/200] [Batch 136/637] [D loss: 0.162853] [G loss: 0.471815]\n",
      "[Epoch 18/200] [Batch 137/637] [D loss: 0.159594] [G loss: 0.452176]\n",
      "[Epoch 18/200] [Batch 138/637] [D loss: 0.141786] [G loss: 0.512143]\n",
      "[Epoch 18/200] [Batch 139/637] [D loss: 0.160342] [G loss: 0.529794]\n",
      "[Epoch 18/200] [Batch 140/637] [D loss: 0.210617] [G loss: 0.378318]\n",
      "[Epoch 18/200] [Batch 141/637] [D loss: 0.226598] [G loss: 0.644419]\n",
      "[Epoch 18/200] [Batch 142/637] [D loss: 0.157235] [G loss: 0.630952]\n",
      "[Epoch 18/200] [Batch 143/637] [D loss: 0.159814] [G loss: 0.501851]\n",
      "[Epoch 18/200] [Batch 144/637] [D loss: 0.193158] [G loss: 0.469465]\n",
      "[Epoch 18/200] [Batch 145/637] [D loss: 0.167151] [G loss: 0.488294]\n",
      "[Epoch 18/200] [Batch 146/637] [D loss: 0.160826] [G loss: 0.552102]\n",
      "[Epoch 18/200] [Batch 147/637] [D loss: 0.145557] [G loss: 0.539042]\n",
      "[Epoch 18/200] [Batch 148/637] [D loss: 0.142122] [G loss: 0.478854]\n",
      "[Epoch 18/200] [Batch 149/637] [D loss: 0.123983] [G loss: 0.517109]\n",
      "[Epoch 18/200] [Batch 150/637] [D loss: 0.162069] [G loss: 0.425151]\n",
      "[Epoch 18/200] [Batch 151/637] [D loss: 0.121806] [G loss: 0.547149]\n",
      "[Epoch 18/200] [Batch 152/637] [D loss: 0.172195] [G loss: 0.452614]\n",
      "[Epoch 18/200] [Batch 153/637] [D loss: 0.150186] [G loss: 0.520659]\n",
      "[Epoch 18/200] [Batch 154/637] [D loss: 0.179666] [G loss: 0.457847]\n",
      "[Epoch 18/200] [Batch 155/637] [D loss: 0.152596] [G loss: 0.482079]\n",
      "[Epoch 18/200] [Batch 156/637] [D loss: 0.158348] [G loss: 0.592126]\n",
      "[Epoch 18/200] [Batch 157/637] [D loss: 0.162893] [G loss: 0.507458]\n",
      "[Epoch 18/200] [Batch 158/637] [D loss: 0.190223] [G loss: 0.463344]\n",
      "[Epoch 18/200] [Batch 159/637] [D loss: 0.198626] [G loss: 0.576454]\n",
      "[Epoch 18/200] [Batch 160/637] [D loss: 0.159930] [G loss: 0.600240]\n",
      "[Epoch 18/200] [Batch 161/637] [D loss: 0.149758] [G loss: 0.495772]\n",
      "[Epoch 18/200] [Batch 162/637] [D loss: 0.145691] [G loss: 0.499477]\n",
      "[Epoch 18/200] [Batch 163/637] [D loss: 0.159313] [G loss: 0.522691]\n",
      "[Epoch 18/200] [Batch 164/637] [D loss: 0.149688] [G loss: 0.506011]\n",
      "[Epoch 18/200] [Batch 165/637] [D loss: 0.164276] [G loss: 0.485820]\n",
      "[Epoch 18/200] [Batch 166/637] [D loss: 0.171917] [G loss: 0.437407]\n",
      "[Epoch 18/200] [Batch 167/637] [D loss: 0.160630] [G loss: 0.542631]\n",
      "[Epoch 18/200] [Batch 168/637] [D loss: 0.163445] [G loss: 0.521347]\n",
      "[Epoch 18/200] [Batch 169/637] [D loss: 0.157603] [G loss: 0.473489]\n",
      "[Epoch 18/200] [Batch 170/637] [D loss: 0.160792] [G loss: 0.447583]\n",
      "[Epoch 18/200] [Batch 171/637] [D loss: 0.164978] [G loss: 0.570315]\n",
      "[Epoch 18/200] [Batch 172/637] [D loss: 0.164689] [G loss: 0.464213]\n",
      "[Epoch 18/200] [Batch 173/637] [D loss: 0.144153] [G loss: 0.511185]\n",
      "[Epoch 18/200] [Batch 174/637] [D loss: 0.144868] [G loss: 0.554631]\n",
      "[Epoch 18/200] [Batch 175/637] [D loss: 0.150754] [G loss: 0.534622]\n",
      "[Epoch 18/200] [Batch 176/637] [D loss: 0.158377] [G loss: 0.456589]\n",
      "[Epoch 18/200] [Batch 177/637] [D loss: 0.149171] [G loss: 0.508008]\n",
      "[Epoch 18/200] [Batch 178/637] [D loss: 0.160180] [G loss: 0.455733]\n",
      "[Epoch 18/200] [Batch 179/637] [D loss: 0.170115] [G loss: 0.505598]\n",
      "[Epoch 18/200] [Batch 180/637] [D loss: 0.158107] [G loss: 0.575618]\n",
      "[Epoch 18/200] [Batch 181/637] [D loss: 0.152886] [G loss: 0.484225]\n",
      "[Epoch 18/200] [Batch 182/637] [D loss: 0.167522] [G loss: 0.579216]\n",
      "[Epoch 18/200] [Batch 183/637] [D loss: 0.158334] [G loss: 0.484777]\n",
      "[Epoch 18/200] [Batch 184/637] [D loss: 0.168574] [G loss: 0.502273]\n",
      "[Epoch 18/200] [Batch 185/637] [D loss: 0.163249] [G loss: 0.397570]\n",
      "[Epoch 18/200] [Batch 186/637] [D loss: 0.132245] [G loss: 0.585019]\n",
      "[Epoch 18/200] [Batch 187/637] [D loss: 0.157628] [G loss: 0.565217]\n",
      "[Epoch 18/200] [Batch 188/637] [D loss: 0.153389] [G loss: 0.530140]\n",
      "[Epoch 18/200] [Batch 189/637] [D loss: 0.154474] [G loss: 0.514374]\n",
      "[Epoch 18/200] [Batch 190/637] [D loss: 0.162526] [G loss: 0.470589]\n",
      "[Epoch 18/200] [Batch 191/637] [D loss: 0.175307] [G loss: 0.574906]\n",
      "[Epoch 18/200] [Batch 192/637] [D loss: 0.142863] [G loss: 0.515316]\n",
      "[Epoch 18/200] [Batch 193/637] [D loss: 0.147586] [G loss: 0.492325]\n",
      "[Epoch 18/200] [Batch 194/637] [D loss: 0.140150] [G loss: 0.512268]\n",
      "[Epoch 18/200] [Batch 195/637] [D loss: 0.119009] [G loss: 0.559733]\n",
      "[Epoch 18/200] [Batch 196/637] [D loss: 0.131966] [G loss: 0.538537]\n",
      "[Epoch 18/200] [Batch 197/637] [D loss: 0.147187] [G loss: 0.524760]\n",
      "[Epoch 18/200] [Batch 198/637] [D loss: 0.149204] [G loss: 0.534442]\n",
      "[Epoch 18/200] [Batch 199/637] [D loss: 0.129876] [G loss: 0.590662]\n",
      "[Epoch 18/200] [Batch 200/637] [D loss: 0.131876] [G loss: 0.483643]\n",
      "[Epoch 18/200] [Batch 201/637] [D loss: 0.166779] [G loss: 0.580842]\n",
      "[Epoch 18/200] [Batch 202/637] [D loss: 0.156550] [G loss: 0.515504]\n",
      "[Epoch 18/200] [Batch 203/637] [D loss: 0.161506] [G loss: 0.539782]\n",
      "[Epoch 18/200] [Batch 204/637] [D loss: 0.141057] [G loss: 0.517911]\n",
      "[Epoch 18/200] [Batch 205/637] [D loss: 0.146964] [G loss: 0.522477]\n",
      "[Epoch 18/200] [Batch 206/637] [D loss: 0.166248] [G loss: 0.540648]\n",
      "[Epoch 18/200] [Batch 207/637] [D loss: 0.170045] [G loss: 0.561483]\n",
      "[Epoch 18/200] [Batch 208/637] [D loss: 0.162834] [G loss: 0.501517]\n",
      "[Epoch 18/200] [Batch 209/637] [D loss: 0.159529] [G loss: 0.514167]\n",
      "[Epoch 18/200] [Batch 210/637] [D loss: 0.179927] [G loss: 0.459381]\n",
      "[Epoch 18/200] [Batch 211/637] [D loss: 0.167863] [G loss: 0.511491]\n",
      "[Epoch 18/200] [Batch 212/637] [D loss: 0.151217] [G loss: 0.488050]\n",
      "[Epoch 18/200] [Batch 213/637] [D loss: 0.194332] [G loss: 0.376025]\n",
      "[Epoch 18/200] [Batch 214/637] [D loss: 0.156482] [G loss: 0.543853]\n",
      "[Epoch 18/200] [Batch 215/637] [D loss: 0.156572] [G loss: 0.509982]\n",
      "[Epoch 18/200] [Batch 216/637] [D loss: 0.153548] [G loss: 0.494513]\n",
      "[Epoch 18/200] [Batch 217/637] [D loss: 0.151830] [G loss: 0.559181]\n",
      "[Epoch 18/200] [Batch 218/637] [D loss: 0.156817] [G loss: 0.511509]\n",
      "[Epoch 18/200] [Batch 219/637] [D loss: 0.162337] [G loss: 0.549582]\n",
      "[Epoch 18/200] [Batch 220/637] [D loss: 0.175472] [G loss: 0.512880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 221/637] [D loss: 0.164754] [G loss: 0.563436]\n",
      "[Epoch 18/200] [Batch 222/637] [D loss: 0.129675] [G loss: 0.533985]\n",
      "[Epoch 18/200] [Batch 223/637] [D loss: 0.133516] [G loss: 0.535738]\n",
      "[Epoch 18/200] [Batch 224/637] [D loss: 0.183959] [G loss: 0.525069]\n",
      "[Epoch 18/200] [Batch 225/637] [D loss: 0.150326] [G loss: 0.575209]\n",
      "[Epoch 18/200] [Batch 226/637] [D loss: 0.140741] [G loss: 0.565304]\n",
      "[Epoch 18/200] [Batch 227/637] [D loss: 0.137927] [G loss: 0.473632]\n",
      "[Epoch 18/200] [Batch 228/637] [D loss: 0.182545] [G loss: 0.468297]\n",
      "[Epoch 18/200] [Batch 229/637] [D loss: 0.197680] [G loss: 0.615730]\n",
      "[Epoch 18/200] [Batch 230/637] [D loss: 0.170442] [G loss: 0.625119]\n",
      "[Epoch 18/200] [Batch 231/637] [D loss: 0.156599] [G loss: 0.592744]\n",
      "[Epoch 18/200] [Batch 232/637] [D loss: 0.168231] [G loss: 0.483314]\n",
      "[Epoch 18/200] [Batch 233/637] [D loss: 0.159674] [G loss: 0.507561]\n",
      "[Epoch 18/200] [Batch 234/637] [D loss: 0.180047] [G loss: 0.556178]\n",
      "[Epoch 18/200] [Batch 235/637] [D loss: 0.154494] [G loss: 0.575625]\n",
      "[Epoch 18/200] [Batch 236/637] [D loss: 0.145751] [G loss: 0.525802]\n",
      "[Epoch 18/200] [Batch 237/637] [D loss: 0.156458] [G loss: 0.506761]\n",
      "[Epoch 18/200] [Batch 238/637] [D loss: 0.199657] [G loss: 0.421749]\n",
      "[Epoch 18/200] [Batch 239/637] [D loss: 0.188310] [G loss: 0.592951]\n",
      "[Epoch 18/200] [Batch 240/637] [D loss: 0.167107] [G loss: 0.544068]\n",
      "[Epoch 18/200] [Batch 241/637] [D loss: 0.167570] [G loss: 0.504346]\n",
      "[Epoch 18/200] [Batch 242/637] [D loss: 0.172678] [G loss: 0.496136]\n",
      "[Epoch 18/200] [Batch 243/637] [D loss: 0.158921] [G loss: 0.504636]\n",
      "[Epoch 18/200] [Batch 244/637] [D loss: 0.144669] [G loss: 0.489378]\n",
      "[Epoch 18/200] [Batch 245/637] [D loss: 0.142928] [G loss: 0.543861]\n",
      "[Epoch 18/200] [Batch 246/637] [D loss: 0.151869] [G loss: 0.515576]\n",
      "[Epoch 18/200] [Batch 247/637] [D loss: 0.151299] [G loss: 0.585506]\n",
      "[Epoch 18/200] [Batch 248/637] [D loss: 0.167614] [G loss: 0.603357]\n",
      "[Epoch 18/200] [Batch 249/637] [D loss: 0.180221] [G loss: 0.538655]\n",
      "[Epoch 18/200] [Batch 250/637] [D loss: 0.145060] [G loss: 0.499035]\n",
      "[Epoch 18/200] [Batch 251/637] [D loss: 0.160242] [G loss: 0.519141]\n",
      "[Epoch 18/200] [Batch 252/637] [D loss: 0.163700] [G loss: 0.485334]\n",
      "[Epoch 18/200] [Batch 253/637] [D loss: 0.160217] [G loss: 0.543027]\n",
      "[Epoch 18/200] [Batch 254/637] [D loss: 0.148335] [G loss: 0.527743]\n",
      "[Epoch 18/200] [Batch 255/637] [D loss: 0.151295] [G loss: 0.537258]\n",
      "[Epoch 18/200] [Batch 256/637] [D loss: 0.165767] [G loss: 0.484318]\n",
      "[Epoch 18/200] [Batch 257/637] [D loss: 0.162216] [G loss: 0.575036]\n",
      "[Epoch 18/200] [Batch 258/637] [D loss: 0.144933] [G loss: 0.571524]\n",
      "[Epoch 18/200] [Batch 259/637] [D loss: 0.155376] [G loss: 0.534856]\n",
      "[Epoch 18/200] [Batch 260/637] [D loss: 0.152485] [G loss: 0.520818]\n",
      "[Epoch 18/200] [Batch 261/637] [D loss: 0.147405] [G loss: 0.478903]\n",
      "[Epoch 18/200] [Batch 262/637] [D loss: 0.135216] [G loss: 0.517962]\n",
      "[Epoch 18/200] [Batch 263/637] [D loss: 0.163980] [G loss: 0.525101]\n",
      "[Epoch 18/200] [Batch 264/637] [D loss: 0.136395] [G loss: 0.553991]\n",
      "[Epoch 18/200] [Batch 265/637] [D loss: 0.133209] [G loss: 0.571497]\n",
      "[Epoch 18/200] [Batch 266/637] [D loss: 0.148589] [G loss: 0.534442]\n",
      "[Epoch 18/200] [Batch 267/637] [D loss: 0.134741] [G loss: 0.578109]\n",
      "[Epoch 18/200] [Batch 268/637] [D loss: 0.177514] [G loss: 0.444698]\n",
      "[Epoch 18/200] [Batch 269/637] [D loss: 0.189696] [G loss: 0.627142]\n",
      "[Epoch 18/200] [Batch 270/637] [D loss: 0.192455] [G loss: 0.534191]\n",
      "[Epoch 18/200] [Batch 271/637] [D loss: 0.193060] [G loss: 0.540300]\n",
      "[Epoch 18/200] [Batch 272/637] [D loss: 0.155009] [G loss: 0.615706]\n",
      "[Epoch 18/200] [Batch 273/637] [D loss: 0.162011] [G loss: 0.516187]\n",
      "[Epoch 18/200] [Batch 274/637] [D loss: 0.178905] [G loss: 0.401068]\n",
      "[Epoch 18/200] [Batch 275/637] [D loss: 0.156985] [G loss: 0.505792]\n",
      "[Epoch 18/200] [Batch 276/637] [D loss: 0.149608] [G loss: 0.540765]\n",
      "[Epoch 18/200] [Batch 277/637] [D loss: 0.136713] [G loss: 0.523664]\n",
      "[Epoch 18/200] [Batch 278/637] [D loss: 0.158365] [G loss: 0.556114]\n",
      "[Epoch 18/200] [Batch 279/637] [D loss: 0.157617] [G loss: 0.517015]\n",
      "[Epoch 18/200] [Batch 280/637] [D loss: 0.155752] [G loss: 0.540434]\n",
      "[Epoch 18/200] [Batch 281/637] [D loss: 0.153622] [G loss: 0.483381]\n",
      "[Epoch 18/200] [Batch 282/637] [D loss: 0.150921] [G loss: 0.497812]\n",
      "[Epoch 18/200] [Batch 283/637] [D loss: 0.148226] [G loss: 0.665771]\n",
      "[Epoch 18/200] [Batch 284/637] [D loss: 0.168451] [G loss: 0.586771]\n",
      "[Epoch 18/200] [Batch 285/637] [D loss: 0.194057] [G loss: 0.432065]\n",
      "[Epoch 18/200] [Batch 286/637] [D loss: 0.182329] [G loss: 0.628235]\n",
      "[Epoch 18/200] [Batch 287/637] [D loss: 0.164445] [G loss: 0.556183]\n",
      "[Epoch 18/200] [Batch 288/637] [D loss: 0.142981] [G loss: 0.624592]\n",
      "[Epoch 18/200] [Batch 289/637] [D loss: 0.177058] [G loss: 0.513403]\n",
      "[Epoch 18/200] [Batch 290/637] [D loss: 0.159698] [G loss: 0.474717]\n",
      "[Epoch 18/200] [Batch 291/637] [D loss: 0.158134] [G loss: 0.489985]\n",
      "[Epoch 18/200] [Batch 292/637] [D loss: 0.164693] [G loss: 0.568853]\n",
      "[Epoch 18/200] [Batch 293/637] [D loss: 0.156807] [G loss: 0.573759]\n",
      "[Epoch 18/200] [Batch 294/637] [D loss: 0.126152] [G loss: 0.478810]\n",
      "[Epoch 18/200] [Batch 295/637] [D loss: 0.159101] [G loss: 0.555560]\n",
      "[Epoch 18/200] [Batch 296/637] [D loss: 0.145883] [G loss: 0.575061]\n",
      "[Epoch 18/200] [Batch 297/637] [D loss: 0.136644] [G loss: 0.462751]\n",
      "[Epoch 18/200] [Batch 298/637] [D loss: 0.163838] [G loss: 0.454043]\n",
      "[Epoch 18/200] [Batch 299/637] [D loss: 0.138579] [G loss: 0.644398]\n",
      "[Epoch 18/200] [Batch 300/637] [D loss: 0.153217] [G loss: 0.605975]\n",
      "[Epoch 18/200] [Batch 301/637] [D loss: 0.145393] [G loss: 0.592509]\n",
      "[Epoch 18/200] [Batch 302/637] [D loss: 0.132788] [G loss: 0.503053]\n",
      "[Epoch 18/200] [Batch 303/637] [D loss: 0.160542] [G loss: 0.482278]\n",
      "[Epoch 18/200] [Batch 304/637] [D loss: 0.180681] [G loss: 0.584229]\n",
      "[Epoch 18/200] [Batch 305/637] [D loss: 0.208145] [G loss: 0.449248]\n",
      "[Epoch 18/200] [Batch 306/637] [D loss: 0.154232] [G loss: 0.551944]\n",
      "[Epoch 18/200] [Batch 307/637] [D loss: 0.140575] [G loss: 0.588071]\n",
      "[Epoch 18/200] [Batch 308/637] [D loss: 0.157764] [G loss: 0.516681]\n",
      "[Epoch 18/200] [Batch 309/637] [D loss: 0.144332] [G loss: 0.501877]\n",
      "[Epoch 18/200] [Batch 310/637] [D loss: 0.139019] [G loss: 0.510612]\n",
      "[Epoch 18/200] [Batch 311/637] [D loss: 0.166212] [G loss: 0.462949]\n",
      "[Epoch 18/200] [Batch 312/637] [D loss: 0.186251] [G loss: 0.412199]\n",
      "[Epoch 18/200] [Batch 313/637] [D loss: 0.162878] [G loss: 0.469086]\n",
      "[Epoch 18/200] [Batch 314/637] [D loss: 0.171570] [G loss: 0.501684]\n",
      "[Epoch 18/200] [Batch 315/637] [D loss: 0.158092] [G loss: 0.524038]\n",
      "[Epoch 18/200] [Batch 316/637] [D loss: 0.167718] [G loss: 0.461132]\n",
      "[Epoch 18/200] [Batch 317/637] [D loss: 0.142986] [G loss: 0.541040]\n",
      "[Epoch 18/200] [Batch 318/637] [D loss: 0.178749] [G loss: 0.532987]\n",
      "[Epoch 18/200] [Batch 319/637] [D loss: 0.163179] [G loss: 0.513890]\n",
      "[Epoch 18/200] [Batch 320/637] [D loss: 0.156481] [G loss: 0.513385]\n",
      "[Epoch 18/200] [Batch 321/637] [D loss: 0.157877] [G loss: 0.520479]\n",
      "[Epoch 18/200] [Batch 322/637] [D loss: 0.197184] [G loss: 0.486959]\n",
      "[Epoch 18/200] [Batch 323/637] [D loss: 0.170002] [G loss: 0.470227]\n",
      "[Epoch 18/200] [Batch 324/637] [D loss: 0.173544] [G loss: 0.458973]\n",
      "[Epoch 18/200] [Batch 325/637] [D loss: 0.164792] [G loss: 0.517965]\n",
      "[Epoch 18/200] [Batch 326/637] [D loss: 0.163317] [G loss: 0.461149]\n",
      "[Epoch 18/200] [Batch 327/637] [D loss: 0.164112] [G loss: 0.497220]\n",
      "[Epoch 18/200] [Batch 328/637] [D loss: 0.161223] [G loss: 0.487712]\n",
      "[Epoch 18/200] [Batch 329/637] [D loss: 0.163223] [G loss: 0.466865]\n",
      "[Epoch 18/200] [Batch 330/637] [D loss: 0.169585] [G loss: 0.477051]\n",
      "[Epoch 18/200] [Batch 331/637] [D loss: 0.139214] [G loss: 0.548921]\n",
      "[Epoch 18/200] [Batch 332/637] [D loss: 0.199948] [G loss: 0.391226]\n",
      "[Epoch 18/200] [Batch 333/637] [D loss: 0.161957] [G loss: 0.534422]\n",
      "[Epoch 18/200] [Batch 334/637] [D loss: 0.162384] [G loss: 0.504881]\n",
      "[Epoch 18/200] [Batch 335/637] [D loss: 0.175207] [G loss: 0.576587]\n",
      "[Epoch 18/200] [Batch 336/637] [D loss: 0.184807] [G loss: 0.508145]\n",
      "[Epoch 18/200] [Batch 337/637] [D loss: 0.161858] [G loss: 0.552528]\n",
      "[Epoch 18/200] [Batch 338/637] [D loss: 0.149735] [G loss: 0.551973]\n",
      "[Epoch 18/200] [Batch 339/637] [D loss: 0.157201] [G loss: 0.504762]\n",
      "[Epoch 18/200] [Batch 340/637] [D loss: 0.165651] [G loss: 0.430974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 341/637] [D loss: 0.167959] [G loss: 0.451137]\n",
      "[Epoch 18/200] [Batch 342/637] [D loss: 0.169510] [G loss: 0.532585]\n",
      "[Epoch 18/200] [Batch 343/637] [D loss: 0.169386] [G loss: 0.507791]\n",
      "[Epoch 18/200] [Batch 344/637] [D loss: 0.178716] [G loss: 0.467090]\n",
      "[Epoch 18/200] [Batch 345/637] [D loss: 0.145444] [G loss: 0.573674]\n",
      "[Epoch 18/200] [Batch 346/637] [D loss: 0.186208] [G loss: 0.490429]\n",
      "[Epoch 18/200] [Batch 347/637] [D loss: 0.187612] [G loss: 0.419240]\n",
      "[Epoch 18/200] [Batch 348/637] [D loss: 0.169191] [G loss: 0.624535]\n",
      "[Epoch 18/200] [Batch 349/637] [D loss: 0.185159] [G loss: 0.586120]\n",
      "[Epoch 18/200] [Batch 350/637] [D loss: 0.177010] [G loss: 0.445924]\n",
      "[Epoch 18/200] [Batch 351/637] [D loss: 0.167419] [G loss: 0.469726]\n",
      "[Epoch 18/200] [Batch 352/637] [D loss: 0.150423] [G loss: 0.499508]\n",
      "[Epoch 18/200] [Batch 353/637] [D loss: 0.163572] [G loss: 0.545395]\n",
      "[Epoch 18/200] [Batch 354/637] [D loss: 0.158531] [G loss: 0.453109]\n",
      "[Epoch 18/200] [Batch 355/637] [D loss: 0.160511] [G loss: 0.474050]\n",
      "[Epoch 18/200] [Batch 356/637] [D loss: 0.158726] [G loss: 0.495890]\n",
      "[Epoch 18/200] [Batch 357/637] [D loss: 0.168678] [G loss: 0.468181]\n",
      "[Epoch 18/200] [Batch 358/637] [D loss: 0.192335] [G loss: 0.508106]\n",
      "[Epoch 18/200] [Batch 359/637] [D loss: 0.162137] [G loss: 0.513647]\n",
      "[Epoch 18/200] [Batch 360/637] [D loss: 0.159789] [G loss: 0.482807]\n",
      "[Epoch 18/200] [Batch 361/637] [D loss: 0.173646] [G loss: 0.467703]\n",
      "[Epoch 18/200] [Batch 362/637] [D loss: 0.181260] [G loss: 0.448538]\n",
      "[Epoch 18/200] [Batch 363/637] [D loss: 0.184385] [G loss: 0.455105]\n",
      "[Epoch 18/200] [Batch 364/637] [D loss: 0.183166] [G loss: 0.405846]\n",
      "[Epoch 18/200] [Batch 365/637] [D loss: 0.173944] [G loss: 0.439066]\n",
      "[Epoch 18/200] [Batch 366/637] [D loss: 0.172635] [G loss: 0.491192]\n",
      "[Epoch 18/200] [Batch 367/637] [D loss: 0.176332] [G loss: 0.473227]\n",
      "[Epoch 18/200] [Batch 368/637] [D loss: 0.200602] [G loss: 0.504135]\n",
      "[Epoch 18/200] [Batch 369/637] [D loss: 0.181859] [G loss: 0.470133]\n",
      "[Epoch 18/200] [Batch 370/637] [D loss: 0.177580] [G loss: 0.532190]\n",
      "[Epoch 18/200] [Batch 371/637] [D loss: 0.143501] [G loss: 0.546127]\n",
      "[Epoch 18/200] [Batch 372/637] [D loss: 0.132257] [G loss: 0.473143]\n",
      "[Epoch 18/200] [Batch 373/637] [D loss: 0.151741] [G loss: 0.511288]\n",
      "[Epoch 18/200] [Batch 374/637] [D loss: 0.143534] [G loss: 0.503762]\n",
      "[Epoch 18/200] [Batch 375/637] [D loss: 0.146721] [G loss: 0.489956]\n",
      "[Epoch 18/200] [Batch 376/637] [D loss: 0.141632] [G loss: 0.545173]\n",
      "[Epoch 18/200] [Batch 377/637] [D loss: 0.156368] [G loss: 0.501088]\n",
      "[Epoch 18/200] [Batch 378/637] [D loss: 0.160245] [G loss: 0.561172]\n",
      "[Epoch 18/200] [Batch 379/637] [D loss: 0.122082] [G loss: 0.540640]\n",
      "[Epoch 18/200] [Batch 380/637] [D loss: 0.164310] [G loss: 0.506377]\n",
      "[Epoch 18/200] [Batch 381/637] [D loss: 0.160442] [G loss: 0.547621]\n",
      "[Epoch 18/200] [Batch 382/637] [D loss: 0.158736] [G loss: 0.549438]\n",
      "[Epoch 18/200] [Batch 383/637] [D loss: 0.171758] [G loss: 0.596179]\n",
      "[Epoch 18/200] [Batch 384/637] [D loss: 0.210498] [G loss: 0.663129]\n",
      "[Epoch 18/200] [Batch 385/637] [D loss: 0.186665] [G loss: 0.417947]\n",
      "[Epoch 18/200] [Batch 386/637] [D loss: 0.179997] [G loss: 0.440474]\n",
      "[Epoch 18/200] [Batch 387/637] [D loss: 0.142313] [G loss: 0.573175]\n",
      "[Epoch 18/200] [Batch 388/637] [D loss: 0.169189] [G loss: 0.514915]\n",
      "[Epoch 18/200] [Batch 389/637] [D loss: 0.149086] [G loss: 0.508743]\n",
      "[Epoch 18/200] [Batch 390/637] [D loss: 0.147887] [G loss: 0.509780]\n",
      "[Epoch 18/200] [Batch 391/637] [D loss: 0.151356] [G loss: 0.532050]\n",
      "[Epoch 18/200] [Batch 392/637] [D loss: 0.168854] [G loss: 0.609353]\n",
      "[Epoch 18/200] [Batch 393/637] [D loss: 0.159577] [G loss: 0.526061]\n",
      "[Epoch 18/200] [Batch 394/637] [D loss: 0.145041] [G loss: 0.545576]\n",
      "[Epoch 18/200] [Batch 395/637] [D loss: 0.166428] [G loss: 0.460124]\n",
      "[Epoch 18/200] [Batch 396/637] [D loss: 0.178389] [G loss: 0.433593]\n",
      "[Epoch 18/200] [Batch 397/637] [D loss: 0.145027] [G loss: 0.482656]\n",
      "[Epoch 18/200] [Batch 398/637] [D loss: 0.207744] [G loss: 0.436479]\n",
      "[Epoch 18/200] [Batch 399/637] [D loss: 0.230953] [G loss: 0.650271]\n",
      "[Epoch 18/200] [Batch 400/637] [D loss: 0.211864] [G loss: 0.524373]\n",
      "[Epoch 18/200] [Batch 401/637] [D loss: 0.211466] [G loss: 0.391205]\n",
      "[Epoch 18/200] [Batch 402/637] [D loss: 0.168040] [G loss: 0.491806]\n",
      "[Epoch 18/200] [Batch 403/637] [D loss: 0.172989] [G loss: 0.480414]\n",
      "[Epoch 18/200] [Batch 404/637] [D loss: 0.156798] [G loss: 0.500068]\n",
      "[Epoch 18/200] [Batch 405/637] [D loss: 0.160295] [G loss: 0.455287]\n",
      "[Epoch 18/200] [Batch 406/637] [D loss: 0.189707] [G loss: 0.425262]\n",
      "[Epoch 18/200] [Batch 407/637] [D loss: 0.163921] [G loss: 0.516376]\n",
      "[Epoch 18/200] [Batch 408/637] [D loss: 0.151659] [G loss: 0.569582]\n",
      "[Epoch 18/200] [Batch 409/637] [D loss: 0.169414] [G loss: 0.506549]\n",
      "[Epoch 18/200] [Batch 410/637] [D loss: 0.165934] [G loss: 0.542544]\n",
      "[Epoch 18/200] [Batch 411/637] [D loss: 0.159970] [G loss: 0.532916]\n",
      "[Epoch 18/200] [Batch 412/637] [D loss: 0.160952] [G loss: 0.522466]\n",
      "[Epoch 18/200] [Batch 413/637] [D loss: 0.147189] [G loss: 0.460141]\n",
      "[Epoch 18/200] [Batch 414/637] [D loss: 0.158857] [G loss: 0.481752]\n",
      "[Epoch 18/200] [Batch 415/637] [D loss: 0.154070] [G loss: 0.488552]\n",
      "[Epoch 18/200] [Batch 416/637] [D loss: 0.157088] [G loss: 0.453675]\n",
      "[Epoch 18/200] [Batch 417/637] [D loss: 0.159159] [G loss: 0.494275]\n",
      "[Epoch 18/200] [Batch 418/637] [D loss: 0.175901] [G loss: 0.424620]\n",
      "[Epoch 18/200] [Batch 419/637] [D loss: 0.161358] [G loss: 0.509602]\n",
      "[Epoch 18/200] [Batch 420/637] [D loss: 0.146099] [G loss: 0.490182]\n",
      "[Epoch 18/200] [Batch 421/637] [D loss: 0.154375] [G loss: 0.503263]\n",
      "[Epoch 18/200] [Batch 422/637] [D loss: 0.162687] [G loss: 0.463519]\n",
      "[Epoch 18/200] [Batch 423/637] [D loss: 0.160778] [G loss: 0.541139]\n",
      "[Epoch 18/200] [Batch 424/637] [D loss: 0.161716] [G loss: 0.528847]\n",
      "[Epoch 18/200] [Batch 425/637] [D loss: 0.151223] [G loss: 0.597749]\n",
      "[Epoch 18/200] [Batch 426/637] [D loss: 0.153137] [G loss: 0.516367]\n",
      "[Epoch 18/200] [Batch 427/637] [D loss: 0.158830] [G loss: 0.471234]\n",
      "[Epoch 18/200] [Batch 428/637] [D loss: 0.177526] [G loss: 0.486377]\n",
      "[Epoch 18/200] [Batch 429/637] [D loss: 0.160022] [G loss: 0.461240]\n",
      "[Epoch 18/200] [Batch 430/637] [D loss: 0.139468] [G loss: 0.509724]\n",
      "[Epoch 18/200] [Batch 431/637] [D loss: 0.158296] [G loss: 0.452644]\n",
      "[Epoch 18/200] [Batch 432/637] [D loss: 0.145355] [G loss: 0.476295]\n",
      "[Epoch 18/200] [Batch 433/637] [D loss: 0.180133] [G loss: 0.408685]\n",
      "[Epoch 18/200] [Batch 434/637] [D loss: 0.168773] [G loss: 0.511784]\n",
      "[Epoch 18/200] [Batch 435/637] [D loss: 0.159217] [G loss: 0.511495]\n",
      "[Epoch 18/200] [Batch 436/637] [D loss: 0.150700] [G loss: 0.522357]\n",
      "[Epoch 18/200] [Batch 437/637] [D loss: 0.167013] [G loss: 0.448479]\n",
      "[Epoch 18/200] [Batch 438/637] [D loss: 0.159219] [G loss: 0.509196]\n",
      "[Epoch 18/200] [Batch 439/637] [D loss: 0.182437] [G loss: 0.480908]\n",
      "[Epoch 18/200] [Batch 440/637] [D loss: 0.179569] [G loss: 0.468926]\n",
      "[Epoch 18/200] [Batch 441/637] [D loss: 0.143114] [G loss: 0.525548]\n",
      "[Epoch 18/200] [Batch 442/637] [D loss: 0.179179] [G loss: 0.452774]\n",
      "[Epoch 18/200] [Batch 443/637] [D loss: 0.148477] [G loss: 0.553233]\n",
      "[Epoch 18/200] [Batch 444/637] [D loss: 0.160675] [G loss: 0.576260]\n",
      "[Epoch 18/200] [Batch 445/637] [D loss: 0.138735] [G loss: 0.511325]\n",
      "[Epoch 18/200] [Batch 446/637] [D loss: 0.137654] [G loss: 0.476810]\n",
      "[Epoch 18/200] [Batch 447/637] [D loss: 0.134859] [G loss: 0.531654]\n",
      "[Epoch 18/200] [Batch 448/637] [D loss: 0.131975] [G loss: 0.479156]\n",
      "[Epoch 18/200] [Batch 449/637] [D loss: 0.142495] [G loss: 0.475735]\n",
      "[Epoch 18/200] [Batch 450/637] [D loss: 0.175576] [G loss: 0.479091]\n",
      "[Epoch 18/200] [Batch 451/637] [D loss: 0.154481] [G loss: 0.524871]\n",
      "[Epoch 18/200] [Batch 452/637] [D loss: 0.124038] [G loss: 0.505891]\n",
      "[Epoch 18/200] [Batch 453/637] [D loss: 0.162646] [G loss: 0.484360]\n",
      "[Epoch 18/200] [Batch 454/637] [D loss: 0.156764] [G loss: 0.484993]\n",
      "[Epoch 18/200] [Batch 455/637] [D loss: 0.162471] [G loss: 0.466917]\n",
      "[Epoch 18/200] [Batch 456/637] [D loss: 0.157492] [G loss: 0.569954]\n",
      "[Epoch 18/200] [Batch 457/637] [D loss: 0.195944] [G loss: 0.472496]\n",
      "[Epoch 18/200] [Batch 458/637] [D loss: 0.192981] [G loss: 0.573476]\n",
      "[Epoch 18/200] [Batch 459/637] [D loss: 0.168753] [G loss: 0.534918]\n",
      "[Epoch 18/200] [Batch 460/637] [D loss: 0.189531] [G loss: 0.453231]\n",
      "[Epoch 18/200] [Batch 461/637] [D loss: 0.168094] [G loss: 0.459361]\n",
      "[Epoch 18/200] [Batch 462/637] [D loss: 0.161004] [G loss: 0.424046]\n",
      "[Epoch 18/200] [Batch 463/637] [D loss: 0.138200] [G loss: 0.431127]\n",
      "[Epoch 18/200] [Batch 464/637] [D loss: 0.163272] [G loss: 0.425358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 465/637] [D loss: 0.168677] [G loss: 0.487928]\n",
      "[Epoch 18/200] [Batch 466/637] [D loss: 0.167103] [G loss: 0.490039]\n",
      "[Epoch 18/200] [Batch 467/637] [D loss: 0.144436] [G loss: 0.495080]\n",
      "[Epoch 18/200] [Batch 468/637] [D loss: 0.184993] [G loss: 0.444128]\n",
      "[Epoch 18/200] [Batch 469/637] [D loss: 0.255124] [G loss: 0.542767]\n",
      "[Epoch 18/200] [Batch 470/637] [D loss: 0.148939] [G loss: 0.525206]\n",
      "[Epoch 18/200] [Batch 471/637] [D loss: 0.192251] [G loss: 0.479699]\n",
      "[Epoch 18/200] [Batch 472/637] [D loss: 0.168623] [G loss: 0.445939]\n",
      "[Epoch 18/200] [Batch 473/637] [D loss: 0.172110] [G loss: 0.442094]\n",
      "[Epoch 18/200] [Batch 474/637] [D loss: 0.162372] [G loss: 0.454728]\n",
      "[Epoch 18/200] [Batch 475/637] [D loss: 0.167327] [G loss: 0.429320]\n",
      "[Epoch 18/200] [Batch 476/637] [D loss: 0.147237] [G loss: 0.475673]\n",
      "[Epoch 18/200] [Batch 477/637] [D loss: 0.145482] [G loss: 0.527292]\n",
      "[Epoch 18/200] [Batch 478/637] [D loss: 0.151083] [G loss: 0.556330]\n",
      "[Epoch 18/200] [Batch 479/637] [D loss: 0.142806] [G loss: 0.503998]\n",
      "[Epoch 18/200] [Batch 480/637] [D loss: 0.152770] [G loss: 0.515114]\n",
      "[Epoch 18/200] [Batch 481/637] [D loss: 0.193169] [G loss: 0.423115]\n",
      "[Epoch 18/200] [Batch 482/637] [D loss: 0.180316] [G loss: 0.590568]\n",
      "[Epoch 18/200] [Batch 483/637] [D loss: 0.160125] [G loss: 0.517340]\n",
      "[Epoch 18/200] [Batch 484/637] [D loss: 0.168490] [G loss: 0.456555]\n",
      "[Epoch 18/200] [Batch 485/637] [D loss: 0.157426] [G loss: 0.505897]\n",
      "[Epoch 18/200] [Batch 486/637] [D loss: 0.167487] [G loss: 0.461009]\n",
      "[Epoch 18/200] [Batch 487/637] [D loss: 0.168372] [G loss: 0.536872]\n",
      "[Epoch 18/200] [Batch 488/637] [D loss: 0.148777] [G loss: 0.507304]\n",
      "[Epoch 18/200] [Batch 489/637] [D loss: 0.165853] [G loss: 0.493574]\n",
      "[Epoch 18/200] [Batch 490/637] [D loss: 0.148041] [G loss: 0.476667]\n",
      "[Epoch 18/200] [Batch 491/637] [D loss: 0.141444] [G loss: 0.501973]\n",
      "[Epoch 18/200] [Batch 492/637] [D loss: 0.133431] [G loss: 0.560425]\n",
      "[Epoch 18/200] [Batch 493/637] [D loss: 0.174563] [G loss: 0.493842]\n",
      "[Epoch 18/200] [Batch 494/637] [D loss: 0.173993] [G loss: 0.469887]\n",
      "[Epoch 18/200] [Batch 495/637] [D loss: 0.158965] [G loss: 0.515200]\n",
      "[Epoch 18/200] [Batch 496/637] [D loss: 0.130825] [G loss: 0.577374]\n",
      "[Epoch 18/200] [Batch 497/637] [D loss: 0.143358] [G loss: 0.523481]\n",
      "[Epoch 18/200] [Batch 498/637] [D loss: 0.174737] [G loss: 0.480887]\n",
      "[Epoch 18/200] [Batch 499/637] [D loss: 0.171486] [G loss: 0.516080]\n",
      "[Epoch 18/200] [Batch 500/637] [D loss: 0.158613] [G loss: 0.538671]\n",
      "[Epoch 18/200] [Batch 501/637] [D loss: 0.154767] [G loss: 0.531382]\n",
      "[Epoch 18/200] [Batch 502/637] [D loss: 0.147179] [G loss: 0.566092]\n",
      "[Epoch 18/200] [Batch 503/637] [D loss: 0.181499] [G loss: 0.467408]\n",
      "[Epoch 18/200] [Batch 504/637] [D loss: 0.155592] [G loss: 0.515000]\n",
      "[Epoch 18/200] [Batch 505/637] [D loss: 0.167561] [G loss: 0.527853]\n",
      "[Epoch 18/200] [Batch 506/637] [D loss: 0.148577] [G loss: 0.545366]\n",
      "[Epoch 18/200] [Batch 507/637] [D loss: 0.168640] [G loss: 0.507246]\n",
      "[Epoch 18/200] [Batch 508/637] [D loss: 0.175747] [G loss: 0.443749]\n",
      "[Epoch 18/200] [Batch 509/637] [D loss: 0.249414] [G loss: 0.524545]\n",
      "[Epoch 18/200] [Batch 510/637] [D loss: 0.180427] [G loss: 0.498856]\n",
      "[Epoch 18/200] [Batch 511/637] [D loss: 0.157817] [G loss: 0.556896]\n",
      "[Epoch 18/200] [Batch 512/637] [D loss: 0.147506] [G loss: 0.571096]\n",
      "[Epoch 18/200] [Batch 513/637] [D loss: 0.169650] [G loss: 0.456306]\n",
      "[Epoch 18/200] [Batch 514/637] [D loss: 0.145471] [G loss: 0.451799]\n",
      "[Epoch 18/200] [Batch 515/637] [D loss: 0.160239] [G loss: 0.496884]\n",
      "[Epoch 18/200] [Batch 516/637] [D loss: 0.145406] [G loss: 0.548681]\n",
      "[Epoch 18/200] [Batch 517/637] [D loss: 0.150913] [G loss: 0.525442]\n",
      "[Epoch 18/200] [Batch 518/637] [D loss: 0.162140] [G loss: 0.592718]\n",
      "[Epoch 18/200] [Batch 519/637] [D loss: 0.146918] [G loss: 0.541140]\n",
      "[Epoch 18/200] [Batch 520/637] [D loss: 0.139064] [G loss: 0.534419]\n",
      "[Epoch 18/200] [Batch 521/637] [D loss: 0.139060] [G loss: 0.520454]\n",
      "[Epoch 18/200] [Batch 522/637] [D loss: 0.155791] [G loss: 0.528678]\n",
      "[Epoch 18/200] [Batch 523/637] [D loss: 0.184165] [G loss: 0.530453]\n",
      "[Epoch 18/200] [Batch 524/637] [D loss: 0.175651] [G loss: 0.483834]\n",
      "[Epoch 18/200] [Batch 525/637] [D loss: 0.165794] [G loss: 0.495208]\n",
      "[Epoch 18/200] [Batch 526/637] [D loss: 0.190158] [G loss: 0.424877]\n",
      "[Epoch 18/200] [Batch 527/637] [D loss: 0.151212] [G loss: 0.524178]\n",
      "[Epoch 18/200] [Batch 528/637] [D loss: 0.156217] [G loss: 0.549179]\n",
      "[Epoch 18/200] [Batch 529/637] [D loss: 0.171627] [G loss: 0.486881]\n",
      "[Epoch 18/200] [Batch 530/637] [D loss: 0.212640] [G loss: 0.521151]\n",
      "[Epoch 18/200] [Batch 531/637] [D loss: 0.180112] [G loss: 0.753125]\n",
      "[Epoch 18/200] [Batch 532/637] [D loss: 0.186476] [G loss: 0.557371]\n",
      "[Epoch 18/200] [Batch 533/637] [D loss: 0.188935] [G loss: 0.455946]\n",
      "[Epoch 18/200] [Batch 534/637] [D loss: 0.206581] [G loss: 0.452831]\n",
      "[Epoch 18/200] [Batch 535/637] [D loss: 0.244892] [G loss: 0.491163]\n",
      "[Epoch 18/200] [Batch 536/637] [D loss: 0.175704] [G loss: 0.557508]\n",
      "[Epoch 18/200] [Batch 537/637] [D loss: 0.219955] [G loss: 0.392490]\n",
      "[Epoch 18/200] [Batch 538/637] [D loss: 0.180695] [G loss: 0.558461]\n",
      "[Epoch 18/200] [Batch 539/637] [D loss: 0.160330] [G loss: 0.555758]\n",
      "[Epoch 18/200] [Batch 540/637] [D loss: 0.168468] [G loss: 0.460159]\n",
      "[Epoch 18/200] [Batch 541/637] [D loss: 0.183815] [G loss: 0.466689]\n",
      "[Epoch 18/200] [Batch 542/637] [D loss: 0.161858] [G loss: 0.482410]\n",
      "[Epoch 18/200] [Batch 543/637] [D loss: 0.163082] [G loss: 0.555085]\n",
      "[Epoch 18/200] [Batch 544/637] [D loss: 0.147932] [G loss: 0.572077]\n",
      "[Epoch 18/200] [Batch 545/637] [D loss: 0.147986] [G loss: 0.552179]\n",
      "[Epoch 18/200] [Batch 546/637] [D loss: 0.150394] [G loss: 0.572579]\n",
      "[Epoch 18/200] [Batch 547/637] [D loss: 0.166796] [G loss: 0.477751]\n",
      "[Epoch 18/200] [Batch 548/637] [D loss: 0.169553] [G loss: 0.495357]\n",
      "[Epoch 18/200] [Batch 549/637] [D loss: 0.170908] [G loss: 0.561417]\n",
      "[Epoch 18/200] [Batch 550/637] [D loss: 0.170054] [G loss: 0.563061]\n",
      "[Epoch 18/200] [Batch 551/637] [D loss: 0.158579] [G loss: 0.575219]\n",
      "[Epoch 18/200] [Batch 552/637] [D loss: 0.201573] [G loss: 0.486105]\n",
      "[Epoch 18/200] [Batch 553/637] [D loss: 0.274051] [G loss: 0.610461]\n",
      "[Epoch 18/200] [Batch 554/637] [D loss: 0.203952] [G loss: 0.668951]\n",
      "[Epoch 18/200] [Batch 555/637] [D loss: 0.174428] [G loss: 0.518951]\n",
      "[Epoch 18/200] [Batch 556/637] [D loss: 0.186303] [G loss: 0.397942]\n",
      "[Epoch 18/200] [Batch 557/637] [D loss: 0.189422] [G loss: 0.372504]\n",
      "[Epoch 18/200] [Batch 558/637] [D loss: 0.167614] [G loss: 0.528555]\n",
      "[Epoch 18/200] [Batch 559/637] [D loss: 0.152641] [G loss: 0.566500]\n",
      "[Epoch 18/200] [Batch 560/637] [D loss: 0.161357] [G loss: 0.486276]\n",
      "[Epoch 18/200] [Batch 561/637] [D loss: 0.158752] [G loss: 0.485004]\n",
      "[Epoch 18/200] [Batch 562/637] [D loss: 0.131023] [G loss: 0.549059]\n",
      "[Epoch 18/200] [Batch 563/637] [D loss: 0.180554] [G loss: 0.535556]\n",
      "[Epoch 18/200] [Batch 564/637] [D loss: 0.179322] [G loss: 0.523787]\n",
      "[Epoch 18/200] [Batch 565/637] [D loss: 0.163120] [G loss: 0.473749]\n",
      "[Epoch 18/200] [Batch 566/637] [D loss: 0.181013] [G loss: 0.495232]\n",
      "[Epoch 18/200] [Batch 567/637] [D loss: 0.160514] [G loss: 0.541737]\n",
      "[Epoch 18/200] [Batch 568/637] [D loss: 0.172484] [G loss: 0.525221]\n",
      "[Epoch 18/200] [Batch 569/637] [D loss: 0.170992] [G loss: 0.471980]\n",
      "[Epoch 18/200] [Batch 570/637] [D loss: 0.186141] [G loss: 0.401793]\n",
      "[Epoch 18/200] [Batch 571/637] [D loss: 0.168778] [G loss: 0.480768]\n",
      "[Epoch 18/200] [Batch 572/637] [D loss: 0.194215] [G loss: 0.500914]\n",
      "[Epoch 18/200] [Batch 573/637] [D loss: 0.156725] [G loss: 0.471655]\n",
      "[Epoch 18/200] [Batch 574/637] [D loss: 0.180904] [G loss: 0.444886]\n",
      "[Epoch 18/200] [Batch 575/637] [D loss: 0.160066] [G loss: 0.473323]\n",
      "[Epoch 18/200] [Batch 576/637] [D loss: 0.176489] [G loss: 0.402227]\n",
      "[Epoch 18/200] [Batch 577/637] [D loss: 0.147417] [G loss: 0.487166]\n",
      "[Epoch 18/200] [Batch 578/637] [D loss: 0.178448] [G loss: 0.467460]\n",
      "[Epoch 18/200] [Batch 579/637] [D loss: 0.183001] [G loss: 0.502978]\n",
      "[Epoch 18/200] [Batch 580/637] [D loss: 0.216249] [G loss: 0.448374]\n",
      "[Epoch 18/200] [Batch 581/637] [D loss: 0.167922] [G loss: 0.505902]\n",
      "[Epoch 18/200] [Batch 582/637] [D loss: 0.173424] [G loss: 0.495827]\n",
      "[Epoch 18/200] [Batch 583/637] [D loss: 0.163053] [G loss: 0.496434]\n",
      "[Epoch 18/200] [Batch 584/637] [D loss: 0.152457] [G loss: 0.467628]\n",
      "[Epoch 18/200] [Batch 585/637] [D loss: 0.182985] [G loss: 0.491246]\n",
      "[Epoch 18/200] [Batch 586/637] [D loss: 0.184510] [G loss: 0.452136]\n",
      "[Epoch 18/200] [Batch 587/637] [D loss: 0.177831] [G loss: 0.457967]\n",
      "[Epoch 18/200] [Batch 588/637] [D loss: 0.152176] [G loss: 0.504198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 589/637] [D loss: 0.157996] [G loss: 0.497227]\n",
      "[Epoch 18/200] [Batch 590/637] [D loss: 0.190393] [G loss: 0.425593]\n",
      "[Epoch 18/200] [Batch 591/637] [D loss: 0.167041] [G loss: 0.547621]\n",
      "[Epoch 18/200] [Batch 592/637] [D loss: 0.176069] [G loss: 0.482550]\n",
      "[Epoch 18/200] [Batch 593/637] [D loss: 0.170667] [G loss: 0.518557]\n",
      "[Epoch 18/200] [Batch 594/637] [D loss: 0.170095] [G loss: 0.474739]\n",
      "[Epoch 18/200] [Batch 595/637] [D loss: 0.156791] [G loss: 0.447587]\n",
      "[Epoch 18/200] [Batch 596/637] [D loss: 0.167254] [G loss: 0.481226]\n",
      "[Epoch 18/200] [Batch 597/637] [D loss: 0.174759] [G loss: 0.484780]\n",
      "[Epoch 18/200] [Batch 598/637] [D loss: 0.168554] [G loss: 0.513681]\n",
      "[Epoch 18/200] [Batch 599/637] [D loss: 0.136799] [G loss: 0.529745]\n",
      "[Epoch 18/200] [Batch 600/637] [D loss: 0.159408] [G loss: 0.483506]\n",
      "[Epoch 18/200] [Batch 601/637] [D loss: 0.145517] [G loss: 0.475803]\n",
      "[Epoch 18/200] [Batch 602/637] [D loss: 0.146101] [G loss: 0.478832]\n",
      "[Epoch 18/200] [Batch 603/637] [D loss: 0.143814] [G loss: 0.555533]\n",
      "[Epoch 18/200] [Batch 604/637] [D loss: 0.156355] [G loss: 0.479905]\n",
      "[Epoch 18/200] [Batch 605/637] [D loss: 0.136125] [G loss: 0.552706]\n",
      "[Epoch 18/200] [Batch 606/637] [D loss: 0.146679] [G loss: 0.534087]\n",
      "[Epoch 18/200] [Batch 607/637] [D loss: 0.168889] [G loss: 0.454081]\n",
      "[Epoch 18/200] [Batch 608/637] [D loss: 0.185752] [G loss: 0.515571]\n",
      "[Epoch 18/200] [Batch 609/637] [D loss: 0.158763] [G loss: 0.499192]\n",
      "[Epoch 18/200] [Batch 610/637] [D loss: 0.148332] [G loss: 0.543841]\n",
      "[Epoch 18/200] [Batch 611/637] [D loss: 0.149872] [G loss: 0.524939]\n",
      "[Epoch 18/200] [Batch 612/637] [D loss: 0.190097] [G loss: 0.484966]\n",
      "[Epoch 18/200] [Batch 613/637] [D loss: 0.163919] [G loss: 0.537690]\n",
      "[Epoch 18/200] [Batch 614/637] [D loss: 0.167628] [G loss: 0.472616]\n",
      "[Epoch 18/200] [Batch 615/637] [D loss: 0.176596] [G loss: 0.551740]\n",
      "[Epoch 18/200] [Batch 616/637] [D loss: 0.176105] [G loss: 0.534130]\n",
      "[Epoch 18/200] [Batch 617/637] [D loss: 0.186574] [G loss: 0.479792]\n",
      "[Epoch 18/200] [Batch 618/637] [D loss: 0.176123] [G loss: 0.439795]\n",
      "[Epoch 18/200] [Batch 619/637] [D loss: 0.179106] [G loss: 0.414341]\n",
      "[Epoch 18/200] [Batch 620/637] [D loss: 0.184945] [G loss: 0.504649]\n",
      "[Epoch 18/200] [Batch 621/637] [D loss: 0.160927] [G loss: 0.587195]\n",
      "[Epoch 18/200] [Batch 622/637] [D loss: 0.158640] [G loss: 0.493795]\n",
      "[Epoch 18/200] [Batch 623/637] [D loss: 0.161697] [G loss: 0.477051]\n",
      "[Epoch 18/200] [Batch 624/637] [D loss: 0.149089] [G loss: 0.501171]\n",
      "[Epoch 18/200] [Batch 625/637] [D loss: 0.131573] [G loss: 0.558463]\n",
      "[Epoch 18/200] [Batch 626/637] [D loss: 0.155827] [G loss: 0.574039]\n",
      "[Epoch 18/200] [Batch 627/637] [D loss: 0.177325] [G loss: 0.509066]\n",
      "[Epoch 18/200] [Batch 628/637] [D loss: 0.175470] [G loss: 0.435549]\n",
      "[Epoch 18/200] [Batch 629/637] [D loss: 0.135518] [G loss: 0.489510]\n",
      "[Epoch 18/200] [Batch 630/637] [D loss: 0.171737] [G loss: 0.430881]\n",
      "[Epoch 18/200] [Batch 631/637] [D loss: 0.140987] [G loss: 0.560130]\n",
      "[Epoch 18/200] [Batch 632/637] [D loss: 0.149001] [G loss: 0.523066]\n",
      "[Epoch 18/200] [Batch 633/637] [D loss: 0.151859] [G loss: 0.543038]\n",
      "[Epoch 18/200] [Batch 634/637] [D loss: 0.127459] [G loss: 0.524896]\n",
      "[Epoch 18/200] [Batch 635/637] [D loss: 0.168284] [G loss: 0.534217]\n",
      "[Epoch 18/200] [Batch 636/637] [D loss: 0.168523] [G loss: 0.493223]\n",
      "[Epoch 19/200] [Batch 0/637] [D loss: 0.159906] [G loss: 0.545176]\n",
      "[Epoch 19/200] [Batch 1/637] [D loss: 0.183321] [G loss: 0.469202]\n",
      "[Epoch 19/200] [Batch 2/637] [D loss: 0.156486] [G loss: 0.498851]\n",
      "[Epoch 19/200] [Batch 3/637] [D loss: 0.195059] [G loss: 0.461669]\n",
      "[Epoch 19/200] [Batch 4/637] [D loss: 0.178854] [G loss: 0.501355]\n",
      "[Epoch 19/200] [Batch 5/637] [D loss: 0.189396] [G loss: 0.438030]\n",
      "[Epoch 19/200] [Batch 6/637] [D loss: 0.200303] [G loss: 0.457361]\n",
      "[Epoch 19/200] [Batch 7/637] [D loss: 0.183558] [G loss: 0.449228]\n",
      "[Epoch 19/200] [Batch 8/637] [D loss: 0.174062] [G loss: 0.507076]\n",
      "[Epoch 19/200] [Batch 9/637] [D loss: 0.179742] [G loss: 0.497093]\n",
      "[Epoch 19/200] [Batch 10/637] [D loss: 0.179115] [G loss: 0.460686]\n",
      "[Epoch 19/200] [Batch 11/637] [D loss: 0.192179] [G loss: 0.378363]\n",
      "[Epoch 19/200] [Batch 12/637] [D loss: 0.173022] [G loss: 0.481101]\n",
      "[Epoch 19/200] [Batch 13/637] [D loss: 0.169828] [G loss: 0.533904]\n",
      "[Epoch 19/200] [Batch 14/637] [D loss: 0.226166] [G loss: 0.379575]\n",
      "[Epoch 19/200] [Batch 15/637] [D loss: 0.231081] [G loss: 0.504066]\n",
      "[Epoch 19/200] [Batch 16/637] [D loss: 0.177033] [G loss: 0.669606]\n",
      "[Epoch 19/200] [Batch 17/637] [D loss: 0.168793] [G loss: 0.600289]\n",
      "[Epoch 19/200] [Batch 18/637] [D loss: 0.172313] [G loss: 0.496779]\n",
      "[Epoch 19/200] [Batch 19/637] [D loss: 0.154747] [G loss: 0.446772]\n",
      "[Epoch 19/200] [Batch 20/637] [D loss: 0.164855] [G loss: 0.428389]\n",
      "[Epoch 19/200] [Batch 21/637] [D loss: 0.158882] [G loss: 0.469630]\n",
      "[Epoch 19/200] [Batch 22/637] [D loss: 0.160273] [G loss: 0.467891]\n",
      "[Epoch 19/200] [Batch 23/637] [D loss: 0.163677] [G loss: 0.490168]\n",
      "[Epoch 19/200] [Batch 24/637] [D loss: 0.151373] [G loss: 0.480434]\n",
      "[Epoch 19/200] [Batch 25/637] [D loss: 0.156178] [G loss: 0.562396]\n",
      "[Epoch 19/200] [Batch 26/637] [D loss: 0.179755] [G loss: 0.487027]\n",
      "[Epoch 19/200] [Batch 27/637] [D loss: 0.175761] [G loss: 0.471153]\n",
      "[Epoch 19/200] [Batch 28/637] [D loss: 0.167610] [G loss: 0.459393]\n",
      "[Epoch 19/200] [Batch 29/637] [D loss: 0.152341] [G loss: 0.519018]\n",
      "[Epoch 19/200] [Batch 30/637] [D loss: 0.164523] [G loss: 0.546745]\n",
      "[Epoch 19/200] [Batch 31/637] [D loss: 0.172063] [G loss: 0.473786]\n",
      "[Epoch 19/200] [Batch 32/637] [D loss: 0.149620] [G loss: 0.432080]\n",
      "[Epoch 19/200] [Batch 33/637] [D loss: 0.171684] [G loss: 0.463899]\n",
      "[Epoch 19/200] [Batch 34/637] [D loss: 0.157458] [G loss: 0.451396]\n",
      "[Epoch 19/200] [Batch 35/637] [D loss: 0.174250] [G loss: 0.478178]\n",
      "[Epoch 19/200] [Batch 36/637] [D loss: 0.162659] [G loss: 0.460195]\n",
      "[Epoch 19/200] [Batch 37/637] [D loss: 0.171108] [G loss: 0.486085]\n",
      "[Epoch 19/200] [Batch 38/637] [D loss: 0.167793] [G loss: 0.577669]\n",
      "[Epoch 19/200] [Batch 39/637] [D loss: 0.140200] [G loss: 0.562969]\n",
      "[Epoch 19/200] [Batch 40/637] [D loss: 0.146036] [G loss: 0.510043]\n",
      "[Epoch 19/200] [Batch 41/637] [D loss: 0.133537] [G loss: 0.513741]\n",
      "[Epoch 19/200] [Batch 42/637] [D loss: 0.177221] [G loss: 0.464850]\n",
      "[Epoch 19/200] [Batch 43/637] [D loss: 0.156520] [G loss: 0.489484]\n",
      "[Epoch 19/200] [Batch 44/637] [D loss: 0.161566] [G loss: 0.553376]\n",
      "[Epoch 19/200] [Batch 45/637] [D loss: 0.167839] [G loss: 0.471261]\n",
      "[Epoch 19/200] [Batch 46/637] [D loss: 0.184144] [G loss: 0.411657]\n",
      "[Epoch 19/200] [Batch 47/637] [D loss: 0.168511] [G loss: 0.555675]\n",
      "[Epoch 19/200] [Batch 48/637] [D loss: 0.154522] [G loss: 0.532707]\n",
      "[Epoch 19/200] [Batch 49/637] [D loss: 0.170749] [G loss: 0.483355]\n",
      "[Epoch 19/200] [Batch 50/637] [D loss: 0.188305] [G loss: 0.449619]\n",
      "[Epoch 19/200] [Batch 51/637] [D loss: 0.173523] [G loss: 0.528635]\n",
      "[Epoch 19/200] [Batch 52/637] [D loss: 0.160539] [G loss: 0.457252]\n",
      "[Epoch 19/200] [Batch 53/637] [D loss: 0.211708] [G loss: 0.431304]\n",
      "[Epoch 19/200] [Batch 54/637] [D loss: 0.186545] [G loss: 0.597685]\n",
      "[Epoch 19/200] [Batch 55/637] [D loss: 0.200791] [G loss: 0.531891]\n",
      "[Epoch 19/200] [Batch 56/637] [D loss: 0.152158] [G loss: 0.502830]\n",
      "[Epoch 19/200] [Batch 57/637] [D loss: 0.182166] [G loss: 0.480028]\n",
      "[Epoch 19/200] [Batch 58/637] [D loss: 0.186839] [G loss: 0.466642]\n",
      "[Epoch 19/200] [Batch 59/637] [D loss: 0.180355] [G loss: 0.444001]\n",
      "[Epoch 19/200] [Batch 60/637] [D loss: 0.177076] [G loss: 0.424459]\n",
      "[Epoch 19/200] [Batch 61/637] [D loss: 0.164149] [G loss: 0.433930]\n",
      "[Epoch 19/200] [Batch 62/637] [D loss: 0.160971] [G loss: 0.515008]\n",
      "[Epoch 19/200] [Batch 63/637] [D loss: 0.156696] [G loss: 0.518216]\n",
      "[Epoch 19/200] [Batch 64/637] [D loss: 0.140749] [G loss: 0.513070]\n",
      "[Epoch 19/200] [Batch 65/637] [D loss: 0.149772] [G loss: 0.517363]\n",
      "[Epoch 19/200] [Batch 66/637] [D loss: 0.161944] [G loss: 0.509318]\n",
      "[Epoch 19/200] [Batch 67/637] [D loss: 0.157649] [G loss: 0.493424]\n",
      "[Epoch 19/200] [Batch 68/637] [D loss: 0.131722] [G loss: 0.499309]\n",
      "[Epoch 19/200] [Batch 69/637] [D loss: 0.140811] [G loss: 0.479100]\n",
      "[Epoch 19/200] [Batch 70/637] [D loss: 0.178091] [G loss: 0.476254]\n",
      "[Epoch 19/200] [Batch 71/637] [D loss: 0.161910] [G loss: 0.620668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 72/637] [D loss: 0.180823] [G loss: 0.513238]\n",
      "[Epoch 19/200] [Batch 73/637] [D loss: 0.156613] [G loss: 0.457767]\n",
      "[Epoch 19/200] [Batch 74/637] [D loss: 0.155597] [G loss: 0.441077]\n",
      "[Epoch 19/200] [Batch 75/637] [D loss: 0.138197] [G loss: 0.495721]\n",
      "[Epoch 19/200] [Batch 76/637] [D loss: 0.163253] [G loss: 0.550457]\n",
      "[Epoch 19/200] [Batch 77/637] [D loss: 0.175828] [G loss: 0.429165]\n",
      "[Epoch 19/200] [Batch 78/637] [D loss: 0.200858] [G loss: 0.430272]\n",
      "[Epoch 19/200] [Batch 79/637] [D loss: 0.144785] [G loss: 0.630456]\n",
      "[Epoch 19/200] [Batch 80/637] [D loss: 0.192649] [G loss: 0.511431]\n",
      "[Epoch 19/200] [Batch 81/637] [D loss: 0.190572] [G loss: 0.423711]\n",
      "[Epoch 19/200] [Batch 82/637] [D loss: 0.180132] [G loss: 0.448688]\n",
      "[Epoch 19/200] [Batch 83/637] [D loss: 0.193377] [G loss: 0.474685]\n",
      "[Epoch 19/200] [Batch 84/637] [D loss: 0.179084] [G loss: 0.478645]\n",
      "[Epoch 19/200] [Batch 85/637] [D loss: 0.177187] [G loss: 0.469638]\n",
      "[Epoch 19/200] [Batch 86/637] [D loss: 0.151389] [G loss: 0.495747]\n",
      "[Epoch 19/200] [Batch 87/637] [D loss: 0.184534] [G loss: 0.428016]\n",
      "[Epoch 19/200] [Batch 88/637] [D loss: 0.182398] [G loss: 0.480024]\n",
      "[Epoch 19/200] [Batch 89/637] [D loss: 0.156564] [G loss: 0.433783]\n",
      "[Epoch 19/200] [Batch 90/637] [D loss: 0.160893] [G loss: 0.535608]\n",
      "[Epoch 19/200] [Batch 91/637] [D loss: 0.152050] [G loss: 0.555511]\n",
      "[Epoch 19/200] [Batch 92/637] [D loss: 0.142085] [G loss: 0.521673]\n",
      "[Epoch 19/200] [Batch 93/637] [D loss: 0.230195] [G loss: 0.357413]\n",
      "[Epoch 19/200] [Batch 94/637] [D loss: 0.253917] [G loss: 0.536592]\n",
      "[Epoch 19/200] [Batch 95/637] [D loss: 0.176089] [G loss: 0.560116]\n",
      "[Epoch 19/200] [Batch 96/637] [D loss: 0.163749] [G loss: 0.492264]\n",
      "[Epoch 19/200] [Batch 97/637] [D loss: 0.173418] [G loss: 0.394160]\n",
      "[Epoch 19/200] [Batch 98/637] [D loss: 0.188577] [G loss: 0.408037]\n",
      "[Epoch 19/200] [Batch 99/637] [D loss: 0.181743] [G loss: 0.438354]\n",
      "[Epoch 19/200] [Batch 100/637] [D loss: 0.141892] [G loss: 0.511077]\n",
      "[Epoch 19/200] [Batch 101/637] [D loss: 0.171782] [G loss: 0.503574]\n",
      "[Epoch 19/200] [Batch 102/637] [D loss: 0.141575] [G loss: 0.555745]\n",
      "[Epoch 19/200] [Batch 103/637] [D loss: 0.143766] [G loss: 0.532332]\n",
      "[Epoch 19/200] [Batch 104/637] [D loss: 0.142222] [G loss: 0.475161]\n",
      "[Epoch 19/200] [Batch 105/637] [D loss: 0.178675] [G loss: 0.503176]\n",
      "[Epoch 19/200] [Batch 106/637] [D loss: 0.168733] [G loss: 0.568229]\n",
      "[Epoch 19/200] [Batch 107/637] [D loss: 0.151385] [G loss: 0.530854]\n",
      "[Epoch 19/200] [Batch 108/637] [D loss: 0.161455] [G loss: 0.457008]\n",
      "[Epoch 19/200] [Batch 109/637] [D loss: 0.164360] [G loss: 0.471564]\n",
      "[Epoch 19/200] [Batch 110/637] [D loss: 0.157337] [G loss: 0.469299]\n",
      "[Epoch 19/200] [Batch 111/637] [D loss: 0.179647] [G loss: 0.465251]\n",
      "[Epoch 19/200] [Batch 112/637] [D loss: 0.148113] [G loss: 0.493252]\n",
      "[Epoch 19/200] [Batch 113/637] [D loss: 0.162217] [G loss: 0.474865]\n",
      "[Epoch 19/200] [Batch 114/637] [D loss: 0.156398] [G loss: 0.555550]\n",
      "[Epoch 19/200] [Batch 115/637] [D loss: 0.221483] [G loss: 0.433593]\n",
      "[Epoch 19/200] [Batch 116/637] [D loss: 0.193029] [G loss: 0.443161]\n",
      "[Epoch 19/200] [Batch 117/637] [D loss: 0.158448] [G loss: 0.501144]\n",
      "[Epoch 19/200] [Batch 118/637] [D loss: 0.153838] [G loss: 0.550835]\n",
      "[Epoch 19/200] [Batch 119/637] [D loss: 0.194527] [G loss: 0.380900]\n",
      "[Epoch 19/200] [Batch 120/637] [D loss: 0.161660] [G loss: 0.538597]\n",
      "[Epoch 19/200] [Batch 121/637] [D loss: 0.160993] [G loss: 0.532674]\n",
      "[Epoch 19/200] [Batch 122/637] [D loss: 0.194761] [G loss: 0.388242]\n",
      "[Epoch 19/200] [Batch 123/637] [D loss: 0.166230] [G loss: 0.477384]\n",
      "[Epoch 19/200] [Batch 124/637] [D loss: 0.189117] [G loss: 0.452127]\n",
      "[Epoch 19/200] [Batch 125/637] [D loss: 0.192960] [G loss: 0.519870]\n",
      "[Epoch 19/200] [Batch 126/637] [D loss: 0.156142] [G loss: 0.558735]\n",
      "[Epoch 19/200] [Batch 127/637] [D loss: 0.164414] [G loss: 0.589439]\n",
      "[Epoch 19/200] [Batch 128/637] [D loss: 0.180850] [G loss: 0.484711]\n",
      "[Epoch 19/200] [Batch 129/637] [D loss: 0.164141] [G loss: 0.539010]\n",
      "[Epoch 19/200] [Batch 130/637] [D loss: 0.152694] [G loss: 0.464889]\n",
      "[Epoch 19/200] [Batch 131/637] [D loss: 0.171497] [G loss: 0.440319]\n",
      "[Epoch 19/200] [Batch 132/637] [D loss: 0.185167] [G loss: 0.473768]\n",
      "[Epoch 19/200] [Batch 133/637] [D loss: 0.142715] [G loss: 0.575095]\n",
      "[Epoch 19/200] [Batch 134/637] [D loss: 0.137053] [G loss: 0.511354]\n",
      "[Epoch 19/200] [Batch 135/637] [D loss: 0.150586] [G loss: 0.502440]\n",
      "[Epoch 19/200] [Batch 136/637] [D loss: 0.157232] [G loss: 0.520933]\n",
      "[Epoch 19/200] [Batch 137/637] [D loss: 0.163494] [G loss: 0.525535]\n",
      "[Epoch 19/200] [Batch 138/637] [D loss: 0.164967] [G loss: 0.489548]\n",
      "[Epoch 19/200] [Batch 139/637] [D loss: 0.136258] [G loss: 0.556111]\n",
      "[Epoch 19/200] [Batch 140/637] [D loss: 0.167242] [G loss: 0.612360]\n",
      "[Epoch 19/200] [Batch 141/637] [D loss: 0.174291] [G loss: 0.493268]\n",
      "[Epoch 19/200] [Batch 142/637] [D loss: 0.165858] [G loss: 0.498026]\n",
      "[Epoch 19/200] [Batch 143/637] [D loss: 0.181819] [G loss: 0.475807]\n",
      "[Epoch 19/200] [Batch 144/637] [D loss: 0.172759] [G loss: 0.532271]\n",
      "[Epoch 19/200] [Batch 145/637] [D loss: 0.160256] [G loss: 0.509732]\n",
      "[Epoch 19/200] [Batch 146/637] [D loss: 0.140629] [G loss: 0.576080]\n",
      "[Epoch 19/200] [Batch 147/637] [D loss: 0.177744] [G loss: 0.436609]\n",
      "[Epoch 19/200] [Batch 148/637] [D loss: 0.180068] [G loss: 0.429030]\n",
      "[Epoch 19/200] [Batch 149/637] [D loss: 0.156346] [G loss: 0.587467]\n",
      "[Epoch 19/200] [Batch 150/637] [D loss: 0.182425] [G loss: 0.555616]\n",
      "[Epoch 19/200] [Batch 151/637] [D loss: 0.190567] [G loss: 0.537177]\n",
      "[Epoch 19/200] [Batch 152/637] [D loss: 0.152617] [G loss: 0.487688]\n",
      "[Epoch 19/200] [Batch 153/637] [D loss: 0.143390] [G loss: 0.534528]\n",
      "[Epoch 19/200] [Batch 154/637] [D loss: 0.177602] [G loss: 0.472938]\n",
      "[Epoch 19/200] [Batch 155/637] [D loss: 0.167730] [G loss: 0.470916]\n",
      "[Epoch 19/200] [Batch 156/637] [D loss: 0.158745] [G loss: 0.523162]\n",
      "[Epoch 19/200] [Batch 157/637] [D loss: 0.224022] [G loss: 0.517961]\n",
      "[Epoch 19/200] [Batch 158/637] [D loss: 0.184155] [G loss: 0.491771]\n",
      "[Epoch 19/200] [Batch 159/637] [D loss: 0.152241] [G loss: 0.583873]\n",
      "[Epoch 19/200] [Batch 160/637] [D loss: 0.146639] [G loss: 0.536303]\n",
      "[Epoch 19/200] [Batch 161/637] [D loss: 0.164220] [G loss: 0.481582]\n",
      "[Epoch 19/200] [Batch 162/637] [D loss: 0.148753] [G loss: 0.460221]\n",
      "[Epoch 19/200] [Batch 163/637] [D loss: 0.159278] [G loss: 0.585402]\n",
      "[Epoch 19/200] [Batch 164/637] [D loss: 0.187435] [G loss: 0.515208]\n",
      "[Epoch 19/200] [Batch 165/637] [D loss: 0.181026] [G loss: 0.462872]\n",
      "[Epoch 19/200] [Batch 166/637] [D loss: 0.201402] [G loss: 0.451154]\n",
      "[Epoch 19/200] [Batch 167/637] [D loss: 0.157449] [G loss: 0.652921]\n",
      "[Epoch 19/200] [Batch 168/637] [D loss: 0.188710] [G loss: 0.513110]\n",
      "[Epoch 19/200] [Batch 169/637] [D loss: 0.155134] [G loss: 0.568303]\n",
      "[Epoch 19/200] [Batch 170/637] [D loss: 0.130161] [G loss: 0.562660]\n",
      "[Epoch 19/200] [Batch 171/637] [D loss: 0.174906] [G loss: 0.446367]\n",
      "[Epoch 19/200] [Batch 172/637] [D loss: 0.145172] [G loss: 0.525164]\n",
      "[Epoch 19/200] [Batch 173/637] [D loss: 0.140850] [G loss: 0.566898]\n",
      "[Epoch 19/200] [Batch 174/637] [D loss: 0.173999] [G loss: 0.529088]\n",
      "[Epoch 19/200] [Batch 175/637] [D loss: 0.143327] [G loss: 0.592272]\n",
      "[Epoch 19/200] [Batch 176/637] [D loss: 0.164363] [G loss: 0.451033]\n",
      "[Epoch 19/200] [Batch 177/637] [D loss: 0.182779] [G loss: 0.551574]\n",
      "[Epoch 19/200] [Batch 178/637] [D loss: 0.179179] [G loss: 0.563435]\n",
      "[Epoch 19/200] [Batch 179/637] [D loss: 0.160833] [G loss: 0.486421]\n",
      "[Epoch 19/200] [Batch 180/637] [D loss: 0.152336] [G loss: 0.508154]\n",
      "[Epoch 19/200] [Batch 181/637] [D loss: 0.162532] [G loss: 0.523864]\n",
      "[Epoch 19/200] [Batch 182/637] [D loss: 0.198856] [G loss: 0.514201]\n",
      "[Epoch 19/200] [Batch 183/637] [D loss: 0.154282] [G loss: 0.516960]\n",
      "[Epoch 19/200] [Batch 184/637] [D loss: 0.144371] [G loss: 0.614624]\n",
      "[Epoch 19/200] [Batch 185/637] [D loss: 0.168361] [G loss: 0.512197]\n",
      "[Epoch 19/200] [Batch 186/637] [D loss: 0.148733] [G loss: 0.508043]\n",
      "[Epoch 19/200] [Batch 187/637] [D loss: 0.177081] [G loss: 0.475118]\n",
      "[Epoch 19/200] [Batch 188/637] [D loss: 0.160896] [G loss: 0.529077]\n",
      "[Epoch 19/200] [Batch 189/637] [D loss: 0.160520] [G loss: 0.511515]\n",
      "[Epoch 19/200] [Batch 190/637] [D loss: 0.172943] [G loss: 0.588885]\n",
      "[Epoch 19/200] [Batch 191/637] [D loss: 0.167085] [G loss: 0.490612]\n",
      "[Epoch 19/200] [Batch 192/637] [D loss: 0.151020] [G loss: 0.448869]\n",
      "[Epoch 19/200] [Batch 193/637] [D loss: 0.132706] [G loss: 0.547698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 194/637] [D loss: 0.157169] [G loss: 0.532930]\n",
      "[Epoch 19/200] [Batch 195/637] [D loss: 0.177293] [G loss: 0.470559]\n",
      "[Epoch 19/200] [Batch 196/637] [D loss: 0.182321] [G loss: 0.469739]\n",
      "[Epoch 19/200] [Batch 197/637] [D loss: 0.167989] [G loss: 0.515437]\n",
      "[Epoch 19/200] [Batch 198/637] [D loss: 0.154671] [G loss: 0.562379]\n",
      "[Epoch 19/200] [Batch 199/637] [D loss: 0.165171] [G loss: 0.511173]\n",
      "[Epoch 19/200] [Batch 200/637] [D loss: 0.149733] [G loss: 0.527774]\n",
      "[Epoch 19/200] [Batch 201/637] [D loss: 0.157486] [G loss: 0.466653]\n",
      "[Epoch 19/200] [Batch 202/637] [D loss: 0.168822] [G loss: 0.575706]\n",
      "[Epoch 19/200] [Batch 203/637] [D loss: 0.180355] [G loss: 0.478513]\n",
      "[Epoch 19/200] [Batch 204/637] [D loss: 0.169569] [G loss: 0.561742]\n",
      "[Epoch 19/200] [Batch 205/637] [D loss: 0.161489] [G loss: 0.575548]\n",
      "[Epoch 19/200] [Batch 206/637] [D loss: 0.177818] [G loss: 0.470463]\n",
      "[Epoch 19/200] [Batch 207/637] [D loss: 0.172340] [G loss: 0.419217]\n",
      "[Epoch 19/200] [Batch 208/637] [D loss: 0.157428] [G loss: 0.461860]\n",
      "[Epoch 19/200] [Batch 209/637] [D loss: 0.154730] [G loss: 0.536461]\n",
      "[Epoch 19/200] [Batch 210/637] [D loss: 0.176718] [G loss: 0.495253]\n",
      "[Epoch 19/200] [Batch 211/637] [D loss: 0.156877] [G loss: 0.524633]\n",
      "[Epoch 19/200] [Batch 212/637] [D loss: 0.151816] [G loss: 0.501300]\n",
      "[Epoch 19/200] [Batch 213/637] [D loss: 0.183316] [G loss: 0.503216]\n",
      "[Epoch 19/200] [Batch 214/637] [D loss: 0.174072] [G loss: 0.553617]\n",
      "[Epoch 19/200] [Batch 215/637] [D loss: 0.159742] [G loss: 0.503664]\n",
      "[Epoch 19/200] [Batch 216/637] [D loss: 0.151161] [G loss: 0.475003]\n",
      "[Epoch 19/200] [Batch 217/637] [D loss: 0.186482] [G loss: 0.451308]\n",
      "[Epoch 19/200] [Batch 218/637] [D loss: 0.171361] [G loss: 0.481174]\n",
      "[Epoch 19/200] [Batch 219/637] [D loss: 0.142312] [G loss: 0.526082]\n",
      "[Epoch 19/200] [Batch 220/637] [D loss: 0.175374] [G loss: 0.477142]\n",
      "[Epoch 19/200] [Batch 221/637] [D loss: 0.150815] [G loss: 0.493526]\n",
      "[Epoch 19/200] [Batch 222/637] [D loss: 0.159055] [G loss: 0.460315]\n",
      "[Epoch 19/200] [Batch 223/637] [D loss: 0.156881] [G loss: 0.509223]\n",
      "[Epoch 19/200] [Batch 224/637] [D loss: 0.156232] [G loss: 0.483064]\n",
      "[Epoch 19/200] [Batch 225/637] [D loss: 0.168365] [G loss: 0.510515]\n",
      "[Epoch 19/200] [Batch 226/637] [D loss: 0.153711] [G loss: 0.543509]\n",
      "[Epoch 19/200] [Batch 227/637] [D loss: 0.155008] [G loss: 0.519918]\n",
      "[Epoch 19/200] [Batch 228/637] [D loss: 0.178342] [G loss: 0.461420]\n",
      "[Epoch 19/200] [Batch 229/637] [D loss: 0.153034] [G loss: 0.481157]\n",
      "[Epoch 19/200] [Batch 230/637] [D loss: 0.149059] [G loss: 0.491717]\n",
      "[Epoch 19/200] [Batch 231/637] [D loss: 0.166970] [G loss: 0.429769]\n",
      "[Epoch 19/200] [Batch 232/637] [D loss: 0.185947] [G loss: 0.462357]\n",
      "[Epoch 19/200] [Batch 233/637] [D loss: 0.152636] [G loss: 0.516253]\n",
      "[Epoch 19/200] [Batch 234/637] [D loss: 0.177982] [G loss: 0.472152]\n",
      "[Epoch 19/200] [Batch 235/637] [D loss: 0.164788] [G loss: 0.484385]\n",
      "[Epoch 19/200] [Batch 236/637] [D loss: 0.170434] [G loss: 0.511727]\n",
      "[Epoch 19/200] [Batch 237/637] [D loss: 0.151817] [G loss: 0.521805]\n",
      "[Epoch 19/200] [Batch 238/637] [D loss: 0.156247] [G loss: 0.458954]\n",
      "[Epoch 19/200] [Batch 239/637] [D loss: 0.151780] [G loss: 0.479184]\n",
      "[Epoch 19/200] [Batch 240/637] [D loss: 0.151606] [G loss: 0.522860]\n",
      "[Epoch 19/200] [Batch 241/637] [D loss: 0.173171] [G loss: 0.448414]\n",
      "[Epoch 19/200] [Batch 242/637] [D loss: 0.157462] [G loss: 0.477355]\n",
      "[Epoch 19/200] [Batch 243/637] [D loss: 0.147677] [G loss: 0.522168]\n",
      "[Epoch 19/200] [Batch 244/637] [D loss: 0.241315] [G loss: 0.394922]\n",
      "[Epoch 19/200] [Batch 245/637] [D loss: 0.209146] [G loss: 0.516687]\n",
      "[Epoch 19/200] [Batch 246/637] [D loss: 0.170652] [G loss: 0.487437]\n",
      "[Epoch 19/200] [Batch 247/637] [D loss: 0.165384] [G loss: 0.542410]\n",
      "[Epoch 19/200] [Batch 248/637] [D loss: 0.189379] [G loss: 0.424999]\n",
      "[Epoch 19/200] [Batch 249/637] [D loss: 0.183278] [G loss: 0.502851]\n",
      "[Epoch 19/200] [Batch 250/637] [D loss: 0.170915] [G loss: 0.605152]\n",
      "[Epoch 19/200] [Batch 251/637] [D loss: 0.179987] [G loss: 0.533239]\n",
      "[Epoch 19/200] [Batch 252/637] [D loss: 0.156856] [G loss: 0.492036]\n",
      "[Epoch 19/200] [Batch 253/637] [D loss: 0.210154] [G loss: 0.435798]\n",
      "[Epoch 19/200] [Batch 254/637] [D loss: 0.160438] [G loss: 0.555607]\n",
      "[Epoch 19/200] [Batch 255/637] [D loss: 0.187605] [G loss: 0.552829]\n",
      "[Epoch 19/200] [Batch 256/637] [D loss: 0.174431] [G loss: 0.516200]\n",
      "[Epoch 19/200] [Batch 257/637] [D loss: 0.159832] [G loss: 0.490911]\n",
      "[Epoch 19/200] [Batch 258/637] [D loss: 0.159198] [G loss: 0.451189]\n",
      "[Epoch 19/200] [Batch 259/637] [D loss: 0.164097] [G loss: 0.481795]\n",
      "[Epoch 19/200] [Batch 260/637] [D loss: 0.145361] [G loss: 0.500931]\n",
      "[Epoch 19/200] [Batch 261/637] [D loss: 0.152572] [G loss: 0.530949]\n",
      "[Epoch 19/200] [Batch 262/637] [D loss: 0.182254] [G loss: 0.557602]\n",
      "[Epoch 19/200] [Batch 263/637] [D loss: 0.153638] [G loss: 0.493240]\n",
      "[Epoch 19/200] [Batch 264/637] [D loss: 0.153940] [G loss: 0.488525]\n",
      "[Epoch 19/200] [Batch 265/637] [D loss: 0.188787] [G loss: 0.459554]\n",
      "[Epoch 19/200] [Batch 266/637] [D loss: 0.147905] [G loss: 0.651240]\n",
      "[Epoch 19/200] [Batch 267/637] [D loss: 0.162624] [G loss: 0.497781]\n",
      "[Epoch 19/200] [Batch 268/637] [D loss: 0.153336] [G loss: 0.484642]\n",
      "[Epoch 19/200] [Batch 269/637] [D loss: 0.182529] [G loss: 0.486824]\n",
      "[Epoch 19/200] [Batch 270/637] [D loss: 0.164924] [G loss: 0.448734]\n",
      "[Epoch 19/200] [Batch 271/637] [D loss: 0.145485] [G loss: 0.483865]\n",
      "[Epoch 19/200] [Batch 272/637] [D loss: 0.157253] [G loss: 0.468286]\n",
      "[Epoch 19/200] [Batch 273/637] [D loss: 0.160792] [G loss: 0.465649]\n",
      "[Epoch 19/200] [Batch 274/637] [D loss: 0.155440] [G loss: 0.489243]\n",
      "[Epoch 19/200] [Batch 275/637] [D loss: 0.163887] [G loss: 0.509342]\n",
      "[Epoch 19/200] [Batch 276/637] [D loss: 0.154230] [G loss: 0.517491]\n",
      "[Epoch 19/200] [Batch 277/637] [D loss: 0.175093] [G loss: 0.456100]\n",
      "[Epoch 19/200] [Batch 278/637] [D loss: 0.200910] [G loss: 0.462813]\n",
      "[Epoch 19/200] [Batch 279/637] [D loss: 0.154952] [G loss: 0.468963]\n",
      "[Epoch 19/200] [Batch 280/637] [D loss: 0.168617] [G loss: 0.536619]\n",
      "[Epoch 19/200] [Batch 281/637] [D loss: 0.183271] [G loss: 0.484397]\n",
      "[Epoch 19/200] [Batch 282/637] [D loss: 0.169658] [G loss: 0.520061]\n",
      "[Epoch 19/200] [Batch 283/637] [D loss: 0.169003] [G loss: 0.518997]\n",
      "[Epoch 19/200] [Batch 284/637] [D loss: 0.153669] [G loss: 0.516094]\n",
      "[Epoch 19/200] [Batch 285/637] [D loss: 0.161813] [G loss: 0.422895]\n",
      "[Epoch 19/200] [Batch 286/637] [D loss: 0.161010] [G loss: 0.446904]\n",
      "[Epoch 19/200] [Batch 287/637] [D loss: 0.184969] [G loss: 0.483943]\n",
      "[Epoch 19/200] [Batch 288/637] [D loss: 0.161838] [G loss: 0.524361]\n",
      "[Epoch 19/200] [Batch 289/637] [D loss: 0.134399] [G loss: 0.517781]\n",
      "[Epoch 19/200] [Batch 290/637] [D loss: 0.157360] [G loss: 0.506394]\n",
      "[Epoch 19/200] [Batch 291/637] [D loss: 0.150524] [G loss: 0.505809]\n",
      "[Epoch 19/200] [Batch 292/637] [D loss: 0.156825] [G loss: 0.546255]\n",
      "[Epoch 19/200] [Batch 293/637] [D loss: 0.143706] [G loss: 0.530272]\n",
      "[Epoch 19/200] [Batch 294/637] [D loss: 0.146852] [G loss: 0.549103]\n",
      "[Epoch 19/200] [Batch 295/637] [D loss: 0.197716] [G loss: 0.459077]\n",
      "[Epoch 19/200] [Batch 296/637] [D loss: 0.168521] [G loss: 0.477195]\n",
      "[Epoch 19/200] [Batch 297/637] [D loss: 0.169670] [G loss: 0.500188]\n",
      "[Epoch 19/200] [Batch 298/637] [D loss: 0.166424] [G loss: 0.464439]\n",
      "[Epoch 19/200] [Batch 299/637] [D loss: 0.141576] [G loss: 0.539557]\n",
      "[Epoch 19/200] [Batch 300/637] [D loss: 0.147191] [G loss: 0.583930]\n",
      "[Epoch 19/200] [Batch 301/637] [D loss: 0.169118] [G loss: 0.543490]\n",
      "[Epoch 19/200] [Batch 302/637] [D loss: 0.235257] [G loss: 0.472993]\n",
      "[Epoch 19/200] [Batch 303/637] [D loss: 0.191556] [G loss: 0.612338]\n",
      "[Epoch 19/200] [Batch 304/637] [D loss: 0.198283] [G loss: 0.476806]\n",
      "[Epoch 19/200] [Batch 305/637] [D loss: 0.165128] [G loss: 0.485620]\n",
      "[Epoch 19/200] [Batch 306/637] [D loss: 0.159813] [G loss: 0.556627]\n",
      "[Epoch 19/200] [Batch 307/637] [D loss: 0.162863] [G loss: 0.480815]\n",
      "[Epoch 19/200] [Batch 308/637] [D loss: 0.146831] [G loss: 0.529807]\n",
      "[Epoch 19/200] [Batch 309/637] [D loss: 0.160804] [G loss: 0.551103]\n",
      "[Epoch 19/200] [Batch 310/637] [D loss: 0.153394] [G loss: 0.645883]\n",
      "[Epoch 19/200] [Batch 311/637] [D loss: 0.150930] [G loss: 0.635095]\n",
      "[Epoch 19/200] [Batch 312/637] [D loss: 0.172621] [G loss: 0.573220]\n",
      "[Epoch 19/200] [Batch 313/637] [D loss: 0.146244] [G loss: 0.609091]\n",
      "[Epoch 19/200] [Batch 314/637] [D loss: 0.157145] [G loss: 0.500473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 315/637] [D loss: 0.157136] [G loss: 0.548740]\n",
      "[Epoch 19/200] [Batch 316/637] [D loss: 0.146464] [G loss: 0.558493]\n",
      "[Epoch 19/200] [Batch 317/637] [D loss: 0.206598] [G loss: 0.389591]\n",
      "[Epoch 19/200] [Batch 318/637] [D loss: 0.164413] [G loss: 0.541793]\n",
      "[Epoch 19/200] [Batch 319/637] [D loss: 0.135505] [G loss: 0.584172]\n",
      "[Epoch 19/200] [Batch 320/637] [D loss: 0.163016] [G loss: 0.523495]\n",
      "[Epoch 19/200] [Batch 321/637] [D loss: 0.198132] [G loss: 0.466989]\n",
      "[Epoch 19/200] [Batch 322/637] [D loss: 0.187740] [G loss: 0.475286]\n",
      "[Epoch 19/200] [Batch 323/637] [D loss: 0.190483] [G loss: 0.468712]\n",
      "[Epoch 19/200] [Batch 324/637] [D loss: 0.197912] [G loss: 0.549603]\n",
      "[Epoch 19/200] [Batch 325/637] [D loss: 0.186334] [G loss: 0.481101]\n",
      "[Epoch 19/200] [Batch 326/637] [D loss: 0.158987] [G loss: 0.548100]\n",
      "[Epoch 19/200] [Batch 327/637] [D loss: 0.179054] [G loss: 0.470988]\n",
      "[Epoch 19/200] [Batch 328/637] [D loss: 0.168648] [G loss: 0.446048]\n",
      "[Epoch 19/200] [Batch 329/637] [D loss: 0.155720] [G loss: 0.457772]\n",
      "[Epoch 19/200] [Batch 330/637] [D loss: 0.131333] [G loss: 0.525712]\n",
      "[Epoch 19/200] [Batch 331/637] [D loss: 0.208227] [G loss: 0.423968]\n",
      "[Epoch 19/200] [Batch 332/637] [D loss: 0.201847] [G loss: 0.574049]\n",
      "[Epoch 19/200] [Batch 333/637] [D loss: 0.163305] [G loss: 0.540209]\n",
      "[Epoch 19/200] [Batch 334/637] [D loss: 0.173287] [G loss: 0.437928]\n",
      "[Epoch 19/200] [Batch 335/637] [D loss: 0.182275] [G loss: 0.496747]\n",
      "[Epoch 19/200] [Batch 336/637] [D loss: 0.178376] [G loss: 0.509625]\n",
      "[Epoch 19/200] [Batch 337/637] [D loss: 0.188752] [G loss: 0.480656]\n",
      "[Epoch 19/200] [Batch 338/637] [D loss: 0.158148] [G loss: 0.527681]\n",
      "[Epoch 19/200] [Batch 339/637] [D loss: 0.180346] [G loss: 0.449634]\n",
      "[Epoch 19/200] [Batch 340/637] [D loss: 0.151109] [G loss: 0.492696]\n",
      "[Epoch 19/200] [Batch 341/637] [D loss: 0.163769] [G loss: 0.477182]\n",
      "[Epoch 19/200] [Batch 342/637] [D loss: 0.161017] [G loss: 0.445499]\n",
      "[Epoch 19/200] [Batch 343/637] [D loss: 0.159270] [G loss: 0.440120]\n",
      "[Epoch 19/200] [Batch 344/637] [D loss: 0.150892] [G loss: 0.472647]\n",
      "[Epoch 19/200] [Batch 345/637] [D loss: 0.147400] [G loss: 0.503421]\n",
      "[Epoch 19/200] [Batch 346/637] [D loss: 0.153603] [G loss: 0.591794]\n",
      "[Epoch 19/200] [Batch 347/637] [D loss: 0.151078] [G loss: 0.485747]\n",
      "[Epoch 19/200] [Batch 348/637] [D loss: 0.161088] [G loss: 0.480286]\n",
      "[Epoch 19/200] [Batch 349/637] [D loss: 0.175817] [G loss: 0.521985]\n",
      "[Epoch 19/200] [Batch 350/637] [D loss: 0.174909] [G loss: 0.513762]\n",
      "[Epoch 19/200] [Batch 351/637] [D loss: 0.172905] [G loss: 0.466502]\n",
      "[Epoch 19/200] [Batch 352/637] [D loss: 0.186528] [G loss: 0.479281]\n",
      "[Epoch 19/200] [Batch 353/637] [D loss: 0.161309] [G loss: 0.464474]\n",
      "[Epoch 19/200] [Batch 354/637] [D loss: 0.178830] [G loss: 0.413693]\n",
      "[Epoch 19/200] [Batch 355/637] [D loss: 0.162486] [G loss: 0.492628]\n",
      "[Epoch 19/200] [Batch 356/637] [D loss: 0.156484] [G loss: 0.549774]\n",
      "[Epoch 19/200] [Batch 357/637] [D loss: 0.159704] [G loss: 0.529761]\n",
      "[Epoch 19/200] [Batch 358/637] [D loss: 0.166492] [G loss: 0.461801]\n",
      "[Epoch 19/200] [Batch 359/637] [D loss: 0.155798] [G loss: 0.492944]\n",
      "[Epoch 19/200] [Batch 360/637] [D loss: 0.167428] [G loss: 0.480287]\n",
      "[Epoch 19/200] [Batch 361/637] [D loss: 0.158346] [G loss: 0.531115]\n",
      "[Epoch 19/200] [Batch 362/637] [D loss: 0.157825] [G loss: 0.434684]\n",
      "[Epoch 19/200] [Batch 363/637] [D loss: 0.148234] [G loss: 0.430100]\n",
      "[Epoch 19/200] [Batch 364/637] [D loss: 0.178212] [G loss: 0.493995]\n",
      "[Epoch 19/200] [Batch 365/637] [D loss: 0.207951] [G loss: 0.476878]\n",
      "[Epoch 19/200] [Batch 366/637] [D loss: 0.172553] [G loss: 0.504074]\n",
      "[Epoch 19/200] [Batch 367/637] [D loss: 0.226254] [G loss: 0.434943]\n",
      "[Epoch 19/200] [Batch 368/637] [D loss: 0.172728] [G loss: 0.535130]\n",
      "[Epoch 19/200] [Batch 369/637] [D loss: 0.168224] [G loss: 0.559396]\n",
      "[Epoch 19/200] [Batch 370/637] [D loss: 0.149726] [G loss: 0.477230]\n",
      "[Epoch 19/200] [Batch 371/637] [D loss: 0.156748] [G loss: 0.440990]\n",
      "[Epoch 19/200] [Batch 372/637] [D loss: 0.146488] [G loss: 0.475623]\n",
      "[Epoch 19/200] [Batch 373/637] [D loss: 0.152643] [G loss: 0.484888]\n",
      "[Epoch 19/200] [Batch 374/637] [D loss: 0.146744] [G loss: 0.504466]\n",
      "[Epoch 19/200] [Batch 375/637] [D loss: 0.142955] [G loss: 0.486563]\n",
      "[Epoch 19/200] [Batch 376/637] [D loss: 0.146437] [G loss: 0.512526]\n",
      "[Epoch 19/200] [Batch 377/637] [D loss: 0.157876] [G loss: 0.472391]\n",
      "[Epoch 19/200] [Batch 378/637] [D loss: 0.178349] [G loss: 0.478829]\n",
      "[Epoch 19/200] [Batch 379/637] [D loss: 0.136748] [G loss: 0.549047]\n",
      "[Epoch 19/200] [Batch 380/637] [D loss: 0.182973] [G loss: 0.475819]\n",
      "[Epoch 19/200] [Batch 381/637] [D loss: 0.162725] [G loss: 0.501687]\n",
      "[Epoch 19/200] [Batch 382/637] [D loss: 0.164231] [G loss: 0.488602]\n",
      "[Epoch 19/200] [Batch 383/637] [D loss: 0.168730] [G loss: 0.482962]\n",
      "[Epoch 19/200] [Batch 384/637] [D loss: 0.162798] [G loss: 0.413450]\n",
      "[Epoch 19/200] [Batch 385/637] [D loss: 0.181130] [G loss: 0.519537]\n",
      "[Epoch 19/200] [Batch 386/637] [D loss: 0.162279] [G loss: 0.484754]\n",
      "[Epoch 19/200] [Batch 387/637] [D loss: 0.155321] [G loss: 0.449513]\n",
      "[Epoch 19/200] [Batch 388/637] [D loss: 0.166047] [G loss: 0.452062]\n",
      "[Epoch 19/200] [Batch 389/637] [D loss: 0.147780] [G loss: 0.496895]\n",
      "[Epoch 19/200] [Batch 390/637] [D loss: 0.148868] [G loss: 0.521993]\n",
      "[Epoch 19/200] [Batch 391/637] [D loss: 0.197412] [G loss: 0.461337]\n",
      "[Epoch 19/200] [Batch 392/637] [D loss: 0.260659] [G loss: 0.574132]\n",
      "[Epoch 19/200] [Batch 393/637] [D loss: 0.211966] [G loss: 0.515623]\n",
      "[Epoch 19/200] [Batch 394/637] [D loss: 0.198842] [G loss: 0.475777]\n",
      "[Epoch 19/200] [Batch 395/637] [D loss: 0.177144] [G loss: 0.423900]\n",
      "[Epoch 19/200] [Batch 396/637] [D loss: 0.164454] [G loss: 0.436776]\n",
      "[Epoch 19/200] [Batch 397/637] [D loss: 0.177104] [G loss: 0.446661]\n",
      "[Epoch 19/200] [Batch 398/637] [D loss: 0.139119] [G loss: 0.492706]\n",
      "[Epoch 19/200] [Batch 399/637] [D loss: 0.189160] [G loss: 0.443014]\n",
      "[Epoch 19/200] [Batch 400/637] [D loss: 0.157394] [G loss: 0.467356]\n",
      "[Epoch 19/200] [Batch 401/637] [D loss: 0.166723] [G loss: 0.522283]\n",
      "[Epoch 19/200] [Batch 402/637] [D loss: 0.176179] [G loss: 0.499923]\n",
      "[Epoch 19/200] [Batch 403/637] [D loss: 0.170436] [G loss: 0.505819]\n",
      "[Epoch 19/200] [Batch 404/637] [D loss: 0.164264] [G loss: 0.468483]\n",
      "[Epoch 19/200] [Batch 405/637] [D loss: 0.157007] [G loss: 0.459550]\n",
      "[Epoch 19/200] [Batch 406/637] [D loss: 0.162603] [G loss: 0.500232]\n",
      "[Epoch 19/200] [Batch 407/637] [D loss: 0.197777] [G loss: 0.437806]\n",
      "[Epoch 19/200] [Batch 408/637] [D loss: 0.167501] [G loss: 0.555677]\n",
      "[Epoch 19/200] [Batch 409/637] [D loss: 0.162759] [G loss: 0.502599]\n",
      "[Epoch 19/200] [Batch 410/637] [D loss: 0.135679] [G loss: 0.533447]\n",
      "[Epoch 19/200] [Batch 411/637] [D loss: 0.189460] [G loss: 0.419006]\n",
      "[Epoch 19/200] [Batch 412/637] [D loss: 0.154577] [G loss: 0.505988]\n",
      "[Epoch 19/200] [Batch 413/637] [D loss: 0.152665] [G loss: 0.592411]\n",
      "[Epoch 19/200] [Batch 414/637] [D loss: 0.139774] [G loss: 0.586011]\n",
      "[Epoch 19/200] [Batch 415/637] [D loss: 0.153002] [G loss: 0.583821]\n",
      "[Epoch 19/200] [Batch 416/637] [D loss: 0.194742] [G loss: 0.424918]\n",
      "[Epoch 19/200] [Batch 417/637] [D loss: 0.192724] [G loss: 0.531152]\n",
      "[Epoch 19/200] [Batch 418/637] [D loss: 0.170218] [G loss: 0.535610]\n",
      "[Epoch 19/200] [Batch 419/637] [D loss: 0.155146] [G loss: 0.556265]\n",
      "[Epoch 19/200] [Batch 420/637] [D loss: 0.166144] [G loss: 0.496861]\n",
      "[Epoch 19/200] [Batch 421/637] [D loss: 0.182792] [G loss: 0.507976]\n",
      "[Epoch 19/200] [Batch 422/637] [D loss: 0.179428] [G loss: 0.582041]\n",
      "[Epoch 19/200] [Batch 423/637] [D loss: 0.165730] [G loss: 0.542098]\n",
      "[Epoch 19/200] [Batch 424/637] [D loss: 0.189514] [G loss: 0.457793]\n",
      "[Epoch 19/200] [Batch 425/637] [D loss: 0.156802] [G loss: 0.503015]\n",
      "[Epoch 19/200] [Batch 426/637] [D loss: 0.183449] [G loss: 0.436273]\n",
      "[Epoch 19/200] [Batch 427/637] [D loss: 0.178789] [G loss: 0.442365]\n",
      "[Epoch 19/200] [Batch 428/637] [D loss: 0.162918] [G loss: 0.499563]\n",
      "[Epoch 19/200] [Batch 429/637] [D loss: 0.171188] [G loss: 0.460062]\n",
      "[Epoch 19/200] [Batch 430/637] [D loss: 0.170200] [G loss: 0.504851]\n",
      "[Epoch 19/200] [Batch 431/637] [D loss: 0.167491] [G loss: 0.449081]\n",
      "[Epoch 19/200] [Batch 432/637] [D loss: 0.168712] [G loss: 0.519734]\n",
      "[Epoch 19/200] [Batch 433/637] [D loss: 0.168665] [G loss: 0.554306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 434/637] [D loss: 0.166039] [G loss: 0.474783]\n",
      "[Epoch 19/200] [Batch 435/637] [D loss: 0.160183] [G loss: 0.457891]\n",
      "[Epoch 19/200] [Batch 436/637] [D loss: 0.156607] [G loss: 0.520722]\n",
      "[Epoch 19/200] [Batch 437/637] [D loss: 0.161072] [G loss: 0.476463]\n",
      "[Epoch 19/200] [Batch 438/637] [D loss: 0.147105] [G loss: 0.486642]\n",
      "[Epoch 19/200] [Batch 439/637] [D loss: 0.140858] [G loss: 0.489805]\n",
      "[Epoch 19/200] [Batch 440/637] [D loss: 0.171763] [G loss: 0.539578]\n",
      "[Epoch 19/200] [Batch 441/637] [D loss: 0.170940] [G loss: 0.506885]\n",
      "[Epoch 19/200] [Batch 442/637] [D loss: 0.179378] [G loss: 0.455559]\n",
      "[Epoch 19/200] [Batch 443/637] [D loss: 0.190229] [G loss: 0.421991]\n",
      "[Epoch 19/200] [Batch 444/637] [D loss: 0.171653] [G loss: 0.538296]\n",
      "[Epoch 19/200] [Batch 445/637] [D loss: 0.181042] [G loss: 0.570211]\n",
      "[Epoch 19/200] [Batch 446/637] [D loss: 0.175475] [G loss: 0.526835]\n",
      "[Epoch 19/200] [Batch 447/637] [D loss: 0.173711] [G loss: 0.455360]\n",
      "[Epoch 19/200] [Batch 448/637] [D loss: 0.154035] [G loss: 0.486440]\n",
      "[Epoch 19/200] [Batch 449/637] [D loss: 0.150065] [G loss: 0.563531]\n",
      "[Epoch 19/200] [Batch 450/637] [D loss: 0.157667] [G loss: 0.476124]\n",
      "[Epoch 19/200] [Batch 451/637] [D loss: 0.181468] [G loss: 0.418641]\n",
      "[Epoch 19/200] [Batch 452/637] [D loss: 0.164640] [G loss: 0.487379]\n",
      "[Epoch 19/200] [Batch 453/637] [D loss: 0.162595] [G loss: 0.486677]\n",
      "[Epoch 19/200] [Batch 454/637] [D loss: 0.185939] [G loss: 0.434753]\n",
      "[Epoch 19/200] [Batch 455/637] [D loss: 0.171282] [G loss: 0.534279]\n",
      "[Epoch 19/200] [Batch 456/637] [D loss: 0.152258] [G loss: 0.480209]\n",
      "[Epoch 19/200] [Batch 457/637] [D loss: 0.189025] [G loss: 0.474726]\n",
      "[Epoch 19/200] [Batch 458/637] [D loss: 0.175728] [G loss: 0.465775]\n",
      "[Epoch 19/200] [Batch 459/637] [D loss: 0.172336] [G loss: 0.519539]\n",
      "[Epoch 19/200] [Batch 460/637] [D loss: 0.172690] [G loss: 0.477020]\n",
      "[Epoch 19/200] [Batch 461/637] [D loss: 0.190454] [G loss: 0.463671]\n",
      "[Epoch 19/200] [Batch 462/637] [D loss: 0.163833] [G loss: 0.555078]\n",
      "[Epoch 19/200] [Batch 463/637] [D loss: 0.161639] [G loss: 0.498851]\n",
      "[Epoch 19/200] [Batch 464/637] [D loss: 0.163172] [G loss: 0.414726]\n",
      "[Epoch 19/200] [Batch 465/637] [D loss: 0.176128] [G loss: 0.401105]\n",
      "[Epoch 19/200] [Batch 466/637] [D loss: 0.170902] [G loss: 0.468740]\n",
      "[Epoch 19/200] [Batch 467/637] [D loss: 0.215475] [G loss: 0.562960]\n",
      "[Epoch 19/200] [Batch 468/637] [D loss: 0.188692] [G loss: 0.513338]\n",
      "[Epoch 19/200] [Batch 469/637] [D loss: 0.173430] [G loss: 0.467725]\n",
      "[Epoch 19/200] [Batch 470/637] [D loss: 0.159381] [G loss: 0.464068]\n",
      "[Epoch 19/200] [Batch 471/637] [D loss: 0.140679] [G loss: 0.526968]\n",
      "[Epoch 19/200] [Batch 472/637] [D loss: 0.169652] [G loss: 0.494944]\n",
      "[Epoch 19/200] [Batch 473/637] [D loss: 0.160057] [G loss: 0.467548]\n",
      "[Epoch 19/200] [Batch 474/637] [D loss: 0.149974] [G loss: 0.457262]\n",
      "[Epoch 19/200] [Batch 475/637] [D loss: 0.148895] [G loss: 0.525598]\n",
      "[Epoch 19/200] [Batch 476/637] [D loss: 0.158484] [G loss: 0.496650]\n",
      "[Epoch 19/200] [Batch 477/637] [D loss: 0.158483] [G loss: 0.576249]\n",
      "[Epoch 19/200] [Batch 478/637] [D loss: 0.157537] [G loss: 0.515976]\n",
      "[Epoch 19/200] [Batch 479/637] [D loss: 0.166940] [G loss: 0.454575]\n",
      "[Epoch 19/200] [Batch 480/637] [D loss: 0.191610] [G loss: 0.456008]\n",
      "[Epoch 19/200] [Batch 481/637] [D loss: 0.190156] [G loss: 0.504610]\n",
      "[Epoch 19/200] [Batch 482/637] [D loss: 0.177899] [G loss: 0.464336]\n",
      "[Epoch 19/200] [Batch 483/637] [D loss: 0.191036] [G loss: 0.456258]\n",
      "[Epoch 19/200] [Batch 484/637] [D loss: 0.164815] [G loss: 0.528619]\n",
      "[Epoch 19/200] [Batch 485/637] [D loss: 0.167086] [G loss: 0.506739]\n",
      "[Epoch 19/200] [Batch 486/637] [D loss: 0.162261] [G loss: 0.476237]\n",
      "[Epoch 19/200] [Batch 487/637] [D loss: 0.163857] [G loss: 0.465085]\n",
      "[Epoch 19/200] [Batch 488/637] [D loss: 0.166024] [G loss: 0.484393]\n",
      "[Epoch 19/200] [Batch 489/637] [D loss: 0.169679] [G loss: 0.509268]\n",
      "[Epoch 19/200] [Batch 490/637] [D loss: 0.147849] [G loss: 0.481967]\n",
      "[Epoch 19/200] [Batch 491/637] [D loss: 0.164415] [G loss: 0.483211]\n",
      "[Epoch 19/200] [Batch 492/637] [D loss: 0.161613] [G loss: 0.495125]\n",
      "[Epoch 19/200] [Batch 493/637] [D loss: 0.167907] [G loss: 0.488882]\n",
      "[Epoch 19/200] [Batch 494/637] [D loss: 0.192368] [G loss: 0.413763]\n",
      "[Epoch 19/200] [Batch 495/637] [D loss: 0.181795] [G loss: 0.536565]\n",
      "[Epoch 19/200] [Batch 496/637] [D loss: 0.170349] [G loss: 0.565377]\n",
      "[Epoch 19/200] [Batch 497/637] [D loss: 0.176727] [G loss: 0.481041]\n",
      "[Epoch 19/200] [Batch 498/637] [D loss: 0.161504] [G loss: 0.483574]\n",
      "[Epoch 19/200] [Batch 499/637] [D loss: 0.204524] [G loss: 0.475730]\n",
      "[Epoch 19/200] [Batch 500/637] [D loss: 0.163016] [G loss: 0.493732]\n",
      "[Epoch 19/200] [Batch 501/637] [D loss: 0.143064] [G loss: 0.682501]\n",
      "[Epoch 19/200] [Batch 502/637] [D loss: 0.176284] [G loss: 0.487659]\n",
      "[Epoch 19/200] [Batch 503/637] [D loss: 0.179387] [G loss: 0.478085]\n",
      "[Epoch 19/200] [Batch 504/637] [D loss: 0.186214] [G loss: 0.500568]\n",
      "[Epoch 19/200] [Batch 505/637] [D loss: 0.160421] [G loss: 0.532313]\n",
      "[Epoch 19/200] [Batch 506/637] [D loss: 0.169231] [G loss: 0.515204]\n",
      "[Epoch 19/200] [Batch 507/637] [D loss: 0.206854] [G loss: 0.508319]\n",
      "[Epoch 19/200] [Batch 508/637] [D loss: 0.175000] [G loss: 0.463520]\n",
      "[Epoch 19/200] [Batch 509/637] [D loss: 0.147292] [G loss: 0.475929]\n",
      "[Epoch 19/200] [Batch 510/637] [D loss: 0.166014] [G loss: 0.545198]\n",
      "[Epoch 19/200] [Batch 511/637] [D loss: 0.151919] [G loss: 0.523486]\n",
      "[Epoch 19/200] [Batch 512/637] [D loss: 0.193379] [G loss: 0.416105]\n",
      "[Epoch 19/200] [Batch 513/637] [D loss: 0.187051] [G loss: 0.487801]\n",
      "[Epoch 19/200] [Batch 514/637] [D loss: 0.163510] [G loss: 0.499925]\n",
      "[Epoch 19/200] [Batch 515/637] [D loss: 0.177681] [G loss: 0.482145]\n",
      "[Epoch 19/200] [Batch 516/637] [D loss: 0.167488] [G loss: 0.454395]\n",
      "[Epoch 19/200] [Batch 517/637] [D loss: 0.250952] [G loss: 0.399164]\n",
      "[Epoch 19/200] [Batch 518/637] [D loss: 0.291321] [G loss: 0.763307]\n",
      "[Epoch 19/200] [Batch 519/637] [D loss: 0.181432] [G loss: 0.515030]\n",
      "[Epoch 19/200] [Batch 520/637] [D loss: 0.216798] [G loss: 0.399082]\n",
      "[Epoch 19/200] [Batch 521/637] [D loss: 0.191237] [G loss: 0.389072]\n",
      "[Epoch 19/200] [Batch 522/637] [D loss: 0.168639] [G loss: 0.423383]\n",
      "[Epoch 19/200] [Batch 523/637] [D loss: 0.160717] [G loss: 0.416439]\n",
      "[Epoch 19/200] [Batch 524/637] [D loss: 0.181880] [G loss: 0.549628]\n",
      "[Epoch 19/200] [Batch 525/637] [D loss: 0.159468] [G loss: 0.593467]\n",
      "[Epoch 19/200] [Batch 526/637] [D loss: 0.152251] [G loss: 0.494229]\n",
      "[Epoch 19/200] [Batch 527/637] [D loss: 0.129541] [G loss: 0.531983]\n",
      "[Epoch 19/200] [Batch 528/637] [D loss: 0.153062] [G loss: 0.486085]\n",
      "[Epoch 19/200] [Batch 529/637] [D loss: 0.142698] [G loss: 0.444054]\n",
      "[Epoch 19/200] [Batch 530/637] [D loss: 0.140440] [G loss: 0.583057]\n",
      "[Epoch 19/200] [Batch 531/637] [D loss: 0.157192] [G loss: 0.512219]\n",
      "[Epoch 19/200] [Batch 532/637] [D loss: 0.144135] [G loss: 0.555412]\n",
      "[Epoch 19/200] [Batch 533/637] [D loss: 0.146679] [G loss: 0.531313]\n",
      "[Epoch 19/200] [Batch 534/637] [D loss: 0.190246] [G loss: 0.425599]\n",
      "[Epoch 19/200] [Batch 535/637] [D loss: 0.197324] [G loss: 0.507115]\n",
      "[Epoch 19/200] [Batch 536/637] [D loss: 0.188008] [G loss: 0.486893]\n",
      "[Epoch 19/200] [Batch 537/637] [D loss: 0.164363] [G loss: 0.564512]\n",
      "[Epoch 19/200] [Batch 538/637] [D loss: 0.153801] [G loss: 0.497106]\n",
      "[Epoch 19/200] [Batch 539/637] [D loss: 0.168173] [G loss: 0.435020]\n",
      "[Epoch 19/200] [Batch 540/637] [D loss: 0.147497] [G loss: 0.445905]\n",
      "[Epoch 19/200] [Batch 541/637] [D loss: 0.156006] [G loss: 0.470776]\n",
      "[Epoch 19/200] [Batch 542/637] [D loss: 0.185061] [G loss: 0.435294]\n",
      "[Epoch 19/200] [Batch 543/637] [D loss: 0.186347] [G loss: 0.494667]\n",
      "[Epoch 19/200] [Batch 544/637] [D loss: 0.163819] [G loss: 0.447338]\n",
      "[Epoch 19/200] [Batch 545/637] [D loss: 0.185438] [G loss: 0.453604]\n",
      "[Epoch 19/200] [Batch 546/637] [D loss: 0.159671] [G loss: 0.563621]\n",
      "[Epoch 19/200] [Batch 547/637] [D loss: 0.173869] [G loss: 0.539328]\n",
      "[Epoch 19/200] [Batch 548/637] [D loss: 0.147937] [G loss: 0.461567]\n",
      "[Epoch 19/200] [Batch 549/637] [D loss: 0.147827] [G loss: 0.457654]\n",
      "[Epoch 19/200] [Batch 550/637] [D loss: 0.163279] [G loss: 0.564660]\n",
      "[Epoch 19/200] [Batch 551/637] [D loss: 0.155396] [G loss: 0.538466]\n",
      "[Epoch 19/200] [Batch 552/637] [D loss: 0.197060] [G loss: 0.515083]\n",
      "[Epoch 19/200] [Batch 553/637] [D loss: 0.181745] [G loss: 0.516983]\n",
      "[Epoch 19/200] [Batch 554/637] [D loss: 0.168540] [G loss: 0.627582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 555/637] [D loss: 0.174982] [G loss: 0.526950]\n",
      "[Epoch 19/200] [Batch 556/637] [D loss: 0.162190] [G loss: 0.547810]\n",
      "[Epoch 19/200] [Batch 557/637] [D loss: 0.159598] [G loss: 0.524560]\n",
      "[Epoch 19/200] [Batch 558/637] [D loss: 0.165750] [G loss: 0.443564]\n",
      "[Epoch 19/200] [Batch 559/637] [D loss: 0.168523] [G loss: 0.469236]\n",
      "[Epoch 19/200] [Batch 560/637] [D loss: 0.159966] [G loss: 0.469029]\n",
      "[Epoch 19/200] [Batch 561/637] [D loss: 0.183348] [G loss: 0.433275]\n",
      "[Epoch 19/200] [Batch 562/637] [D loss: 0.165968] [G loss: 0.530940]\n",
      "[Epoch 19/200] [Batch 563/637] [D loss: 0.159720] [G loss: 0.540128]\n",
      "[Epoch 19/200] [Batch 564/637] [D loss: 0.163990] [G loss: 0.496010]\n",
      "[Epoch 19/200] [Batch 565/637] [D loss: 0.176362] [G loss: 0.457811]\n",
      "[Epoch 19/200] [Batch 566/637] [D loss: 0.184500] [G loss: 0.477794]\n",
      "[Epoch 19/200] [Batch 567/637] [D loss: 0.159767] [G loss: 0.481587]\n",
      "[Epoch 19/200] [Batch 568/637] [D loss: 0.154372] [G loss: 0.517172]\n",
      "[Epoch 19/200] [Batch 569/637] [D loss: 0.168255] [G loss: 0.455014]\n",
      "[Epoch 19/200] [Batch 570/637] [D loss: 0.157277] [G loss: 0.493831]\n",
      "[Epoch 19/200] [Batch 571/637] [D loss: 0.161321] [G loss: 0.457704]\n",
      "[Epoch 19/200] [Batch 572/637] [D loss: 0.135683] [G loss: 0.538055]\n",
      "[Epoch 19/200] [Batch 573/637] [D loss: 0.170692] [G loss: 0.513050]\n",
      "[Epoch 19/200] [Batch 574/637] [D loss: 0.166246] [G loss: 0.482696]\n",
      "[Epoch 19/200] [Batch 575/637] [D loss: 0.167860] [G loss: 0.457885]\n",
      "[Epoch 19/200] [Batch 576/637] [D loss: 0.147117] [G loss: 0.593747]\n",
      "[Epoch 19/200] [Batch 577/637] [D loss: 0.160545] [G loss: 0.496214]\n",
      "[Epoch 19/200] [Batch 578/637] [D loss: 0.147105] [G loss: 0.435325]\n",
      "[Epoch 19/200] [Batch 579/637] [D loss: 0.190950] [G loss: 0.431307]\n",
      "[Epoch 19/200] [Batch 580/637] [D loss: 0.162874] [G loss: 0.433395]\n",
      "[Epoch 19/200] [Batch 581/637] [D loss: 0.149936] [G loss: 0.489555]\n",
      "[Epoch 19/200] [Batch 582/637] [D loss: 0.161444] [G loss: 0.455797]\n",
      "[Epoch 19/200] [Batch 583/637] [D loss: 0.168608] [G loss: 0.467119]\n",
      "[Epoch 19/200] [Batch 584/637] [D loss: 0.163938] [G loss: 0.519427]\n",
      "[Epoch 19/200] [Batch 585/637] [D loss: 0.157193] [G loss: 0.509003]\n",
      "[Epoch 19/200] [Batch 586/637] [D loss: 0.171562] [G loss: 0.502615]\n",
      "[Epoch 19/200] [Batch 587/637] [D loss: 0.167840] [G loss: 0.491108]\n",
      "[Epoch 19/200] [Batch 588/637] [D loss: 0.145274] [G loss: 0.537504]\n",
      "[Epoch 19/200] [Batch 589/637] [D loss: 0.164460] [G loss: 0.426642]\n",
      "[Epoch 19/200] [Batch 590/637] [D loss: 0.157360] [G loss: 0.482586]\n",
      "[Epoch 19/200] [Batch 591/637] [D loss: 0.155487] [G loss: 0.504591]\n",
      "[Epoch 19/200] [Batch 592/637] [D loss: 0.138077] [G loss: 0.570150]\n",
      "[Epoch 19/200] [Batch 593/637] [D loss: 0.184723] [G loss: 0.430883]\n",
      "[Epoch 19/200] [Batch 594/637] [D loss: 0.147299] [G loss: 0.499645]\n",
      "[Epoch 19/200] [Batch 595/637] [D loss: 0.144913] [G loss: 0.599741]\n",
      "[Epoch 19/200] [Batch 596/637] [D loss: 0.149807] [G loss: 0.520498]\n",
      "[Epoch 19/200] [Batch 597/637] [D loss: 0.167929] [G loss: 0.486497]\n",
      "[Epoch 19/200] [Batch 598/637] [D loss: 0.164689] [G loss: 0.450048]\n",
      "[Epoch 19/200] [Batch 599/637] [D loss: 0.146193] [G loss: 0.563282]\n",
      "[Epoch 19/200] [Batch 600/637] [D loss: 0.148233] [G loss: 0.512710]\n",
      "[Epoch 19/200] [Batch 601/637] [D loss: 0.140621] [G loss: 0.512204]\n",
      "[Epoch 19/200] [Batch 602/637] [D loss: 0.162456] [G loss: 0.560497]\n",
      "[Epoch 19/200] [Batch 603/637] [D loss: 0.142444] [G loss: 0.581726]\n",
      "[Epoch 19/200] [Batch 604/637] [D loss: 0.169545] [G loss: 0.470140]\n",
      "[Epoch 19/200] [Batch 605/637] [D loss: 0.150517] [G loss: 0.581661]\n",
      "[Epoch 19/200] [Batch 606/637] [D loss: 0.163438] [G loss: 0.492141]\n",
      "[Epoch 19/200] [Batch 607/637] [D loss: 0.193683] [G loss: 0.581951]\n",
      "[Epoch 19/200] [Batch 608/637] [D loss: 0.166019] [G loss: 0.485839]\n",
      "[Epoch 19/200] [Batch 609/637] [D loss: 0.156284] [G loss: 0.540153]\n",
      "[Epoch 19/200] [Batch 610/637] [D loss: 0.155343] [G loss: 0.494423]\n",
      "[Epoch 19/200] [Batch 611/637] [D loss: 0.230181] [G loss: 0.413544]\n",
      "[Epoch 19/200] [Batch 612/637] [D loss: 0.198341] [G loss: 0.557891]\n",
      "[Epoch 19/200] [Batch 613/637] [D loss: 0.153903] [G loss: 0.616890]\n",
      "[Epoch 19/200] [Batch 614/637] [D loss: 0.172480] [G loss: 0.548432]\n",
      "[Epoch 19/200] [Batch 615/637] [D loss: 0.158837] [G loss: 0.453578]\n",
      "[Epoch 19/200] [Batch 616/637] [D loss: 0.200638] [G loss: 0.417330]\n",
      "[Epoch 19/200] [Batch 617/637] [D loss: 0.151742] [G loss: 0.507578]\n",
      "[Epoch 19/200] [Batch 618/637] [D loss: 0.148939] [G loss: 0.472449]\n",
      "[Epoch 19/200] [Batch 619/637] [D loss: 0.158610] [G loss: 0.522135]\n",
      "[Epoch 19/200] [Batch 620/637] [D loss: 0.169505] [G loss: 0.461687]\n",
      "[Epoch 19/200] [Batch 621/637] [D loss: 0.174892] [G loss: 0.509145]\n",
      "[Epoch 19/200] [Batch 622/637] [D loss: 0.183786] [G loss: 0.480839]\n",
      "[Epoch 19/200] [Batch 623/637] [D loss: 0.171402] [G loss: 0.472089]\n",
      "[Epoch 19/200] [Batch 624/637] [D loss: 0.136030] [G loss: 0.570882]\n",
      "[Epoch 19/200] [Batch 625/637] [D loss: 0.153618] [G loss: 0.527341]\n",
      "[Epoch 19/200] [Batch 626/637] [D loss: 0.157953] [G loss: 0.474268]\n",
      "[Epoch 19/200] [Batch 627/637] [D loss: 0.147127] [G loss: 0.463409]\n",
      "[Epoch 19/200] [Batch 628/637] [D loss: 0.165447] [G loss: 0.470116]\n",
      "[Epoch 19/200] [Batch 629/637] [D loss: 0.148557] [G loss: 0.552872]\n",
      "[Epoch 19/200] [Batch 630/637] [D loss: 0.180277] [G loss: 0.534250]\n",
      "[Epoch 19/200] [Batch 631/637] [D loss: 0.162546] [G loss: 0.573540]\n",
      "[Epoch 19/200] [Batch 632/637] [D loss: 0.183331] [G loss: 0.378733]\n",
      "[Epoch 19/200] [Batch 633/637] [D loss: 0.156228] [G loss: 0.443522]\n",
      "[Epoch 19/200] [Batch 634/637] [D loss: 0.173910] [G loss: 0.420901]\n",
      "[Epoch 19/200] [Batch 635/637] [D loss: 0.172671] [G loss: 0.487328]\n",
      "[Epoch 19/200] [Batch 636/637] [D loss: 0.164441] [G loss: 0.497950]\n",
      "[Epoch 20/200] [Batch 0/637] [D loss: 0.185914] [G loss: 0.417617]\n",
      "[Epoch 20/200] [Batch 1/637] [D loss: 0.171611] [G loss: 0.466849]\n",
      "[Epoch 20/200] [Batch 2/637] [D loss: 0.149387] [G loss: 0.536469]\n",
      "[Epoch 20/200] [Batch 3/637] [D loss: 0.176964] [G loss: 0.497100]\n",
      "[Epoch 20/200] [Batch 4/637] [D loss: 0.156361] [G loss: 0.527555]\n",
      "[Epoch 20/200] [Batch 5/637] [D loss: 0.160654] [G loss: 0.517158]\n",
      "[Epoch 20/200] [Batch 6/637] [D loss: 0.194188] [G loss: 0.423757]\n",
      "[Epoch 20/200] [Batch 7/637] [D loss: 0.159444] [G loss: 0.559782]\n",
      "[Epoch 20/200] [Batch 8/637] [D loss: 0.159060] [G loss: 0.535164]\n",
      "[Epoch 20/200] [Batch 9/637] [D loss: 0.159612] [G loss: 0.565739]\n",
      "[Epoch 20/200] [Batch 10/637] [D loss: 0.158389] [G loss: 0.499831]\n",
      "[Epoch 20/200] [Batch 11/637] [D loss: 0.171224] [G loss: 0.544624]\n",
      "[Epoch 20/200] [Batch 12/637] [D loss: 0.173063] [G loss: 0.507773]\n",
      "[Epoch 20/200] [Batch 13/637] [D loss: 0.159099] [G loss: 0.628645]\n",
      "[Epoch 20/200] [Batch 14/637] [D loss: 0.166058] [G loss: 0.543009]\n",
      "[Epoch 20/200] [Batch 15/637] [D loss: 0.177488] [G loss: 0.509712]\n",
      "[Epoch 20/200] [Batch 16/637] [D loss: 0.195914] [G loss: 0.504625]\n",
      "[Epoch 20/200] [Batch 17/637] [D loss: 0.173634] [G loss: 0.606935]\n",
      "[Epoch 20/200] [Batch 18/637] [D loss: 0.165844] [G loss: 0.580475]\n",
      "[Epoch 20/200] [Batch 19/637] [D loss: 0.159789] [G loss: 0.462687]\n",
      "[Epoch 20/200] [Batch 20/637] [D loss: 0.156033] [G loss: 0.433725]\n",
      "[Epoch 20/200] [Batch 21/637] [D loss: 0.166092] [G loss: 0.425229]\n",
      "[Epoch 20/200] [Batch 22/637] [D loss: 0.177824] [G loss: 0.456078]\n",
      "[Epoch 20/200] [Batch 23/637] [D loss: 0.200033] [G loss: 0.460513]\n",
      "[Epoch 20/200] [Batch 24/637] [D loss: 0.183867] [G loss: 0.545098]\n",
      "[Epoch 20/200] [Batch 25/637] [D loss: 0.173181] [G loss: 0.466513]\n",
      "[Epoch 20/200] [Batch 26/637] [D loss: 0.156759] [G loss: 0.505331]\n",
      "[Epoch 20/200] [Batch 27/637] [D loss: 0.150948] [G loss: 0.477024]\n",
      "[Epoch 20/200] [Batch 28/637] [D loss: 0.180429] [G loss: 0.452190]\n",
      "[Epoch 20/200] [Batch 29/637] [D loss: 0.151401] [G loss: 0.492612]\n",
      "[Epoch 20/200] [Batch 30/637] [D loss: 0.155690] [G loss: 0.491927]\n",
      "[Epoch 20/200] [Batch 31/637] [D loss: 0.200070] [G loss: 0.427701]\n",
      "[Epoch 20/200] [Batch 32/637] [D loss: 0.155082] [G loss: 0.468770]\n",
      "[Epoch 20/200] [Batch 33/637] [D loss: 0.154914] [G loss: 0.530771]\n",
      "[Epoch 20/200] [Batch 34/637] [D loss: 0.172425] [G loss: 0.472123]\n",
      "[Epoch 20/200] [Batch 35/637] [D loss: 0.183264] [G loss: 0.449746]\n",
      "[Epoch 20/200] [Batch 36/637] [D loss: 0.191233] [G loss: 0.653220]\n",
      "[Epoch 20/200] [Batch 37/637] [D loss: 0.188322] [G loss: 0.510610]\n",
      "[Epoch 20/200] [Batch 38/637] [D loss: 0.169045] [G loss: 0.512046]\n",
      "[Epoch 20/200] [Batch 39/637] [D loss: 0.166541] [G loss: 0.502779]\n",
      "[Epoch 20/200] [Batch 40/637] [D loss: 0.164048] [G loss: 0.513174]\n",
      "[Epoch 20/200] [Batch 41/637] [D loss: 0.164625] [G loss: 0.501331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 42/637] [D loss: 0.155262] [G loss: 0.518286]\n",
      "[Epoch 20/200] [Batch 43/637] [D loss: 0.166080] [G loss: 0.426389]\n",
      "[Epoch 20/200] [Batch 44/637] [D loss: 0.153058] [G loss: 0.474682]\n",
      "[Epoch 20/200] [Batch 45/637] [D loss: 0.156643] [G loss: 0.507917]\n",
      "[Epoch 20/200] [Batch 46/637] [D loss: 0.174565] [G loss: 0.422284]\n",
      "[Epoch 20/200] [Batch 47/637] [D loss: 0.173984] [G loss: 0.543779]\n",
      "[Epoch 20/200] [Batch 48/637] [D loss: 0.166273] [G loss: 0.508990]\n",
      "[Epoch 20/200] [Batch 49/637] [D loss: 0.164771] [G loss: 0.514116]\n",
      "[Epoch 20/200] [Batch 50/637] [D loss: 0.169711] [G loss: 0.451967]\n",
      "[Epoch 20/200] [Batch 51/637] [D loss: 0.155706] [G loss: 0.467022]\n",
      "[Epoch 20/200] [Batch 52/637] [D loss: 0.156446] [G loss: 0.484507]\n",
      "[Epoch 20/200] [Batch 53/637] [D loss: 0.169886] [G loss: 0.444090]\n",
      "[Epoch 20/200] [Batch 54/637] [D loss: 0.197880] [G loss: 0.426323]\n",
      "[Epoch 20/200] [Batch 55/637] [D loss: 0.232754] [G loss: 0.611109]\n",
      "[Epoch 20/200] [Batch 56/637] [D loss: 0.209337] [G loss: 0.557326]\n",
      "[Epoch 20/200] [Batch 57/637] [D loss: 0.172290] [G loss: 0.471399]\n",
      "[Epoch 20/200] [Batch 58/637] [D loss: 0.167062] [G loss: 0.468173]\n",
      "[Epoch 20/200] [Batch 59/637] [D loss: 0.177229] [G loss: 0.530582]\n",
      "[Epoch 20/200] [Batch 60/637] [D loss: 0.210850] [G loss: 0.474032]\n",
      "[Epoch 20/200] [Batch 61/637] [D loss: 0.184224] [G loss: 0.487304]\n",
      "[Epoch 20/200] [Batch 62/637] [D loss: 0.178731] [G loss: 0.509723]\n",
      "[Epoch 20/200] [Batch 63/637] [D loss: 0.175256] [G loss: 0.498832]\n",
      "[Epoch 20/200] [Batch 64/637] [D loss: 0.158361] [G loss: 0.478798]\n",
      "[Epoch 20/200] [Batch 65/637] [D loss: 0.170962] [G loss: 0.374735]\n",
      "[Epoch 20/200] [Batch 66/637] [D loss: 0.191249] [G loss: 0.427550]\n",
      "[Epoch 20/200] [Batch 67/637] [D loss: 0.195698] [G loss: 0.492447]\n",
      "[Epoch 20/200] [Batch 68/637] [D loss: 0.181129] [G loss: 0.448734]\n",
      "[Epoch 20/200] [Batch 69/637] [D loss: 0.178185] [G loss: 0.404660]\n",
      "[Epoch 20/200] [Batch 70/637] [D loss: 0.162462] [G loss: 0.524936]\n",
      "[Epoch 20/200] [Batch 71/637] [D loss: 0.173699] [G loss: 0.449799]\n",
      "[Epoch 20/200] [Batch 72/637] [D loss: 0.187055] [G loss: 0.417155]\n",
      "[Epoch 20/200] [Batch 73/637] [D loss: 0.181917] [G loss: 0.505586]\n",
      "[Epoch 20/200] [Batch 74/637] [D loss: 0.185906] [G loss: 0.490039]\n",
      "[Epoch 20/200] [Batch 75/637] [D loss: 0.170501] [G loss: 0.491121]\n",
      "[Epoch 20/200] [Batch 76/637] [D loss: 0.165214] [G loss: 0.441621]\n",
      "[Epoch 20/200] [Batch 77/637] [D loss: 0.147343] [G loss: 0.534520]\n",
      "[Epoch 20/200] [Batch 78/637] [D loss: 0.181632] [G loss: 0.527166]\n",
      "[Epoch 20/200] [Batch 79/637] [D loss: 0.152889] [G loss: 0.522698]\n",
      "[Epoch 20/200] [Batch 80/637] [D loss: 0.178108] [G loss: 0.461520]\n",
      "[Epoch 20/200] [Batch 81/637] [D loss: 0.148842] [G loss: 0.552844]\n",
      "[Epoch 20/200] [Batch 82/637] [D loss: 0.159811] [G loss: 0.479034]\n",
      "[Epoch 20/200] [Batch 83/637] [D loss: 0.177979] [G loss: 0.571951]\n",
      "[Epoch 20/200] [Batch 84/637] [D loss: 0.184444] [G loss: 0.445768]\n",
      "[Epoch 20/200] [Batch 85/637] [D loss: 0.175206] [G loss: 0.458221]\n",
      "[Epoch 20/200] [Batch 86/637] [D loss: 0.165121] [G loss: 0.493225]\n",
      "[Epoch 20/200] [Batch 87/637] [D loss: 0.163189] [G loss: 0.573387]\n",
      "[Epoch 20/200] [Batch 88/637] [D loss: 0.166504] [G loss: 0.517568]\n",
      "[Epoch 20/200] [Batch 89/637] [D loss: 0.170278] [G loss: 0.498167]\n",
      "[Epoch 20/200] [Batch 90/637] [D loss: 0.168473] [G loss: 0.526461]\n",
      "[Epoch 20/200] [Batch 91/637] [D loss: 0.168607] [G loss: 0.494525]\n",
      "[Epoch 20/200] [Batch 92/637] [D loss: 0.154066] [G loss: 0.552671]\n",
      "[Epoch 20/200] [Batch 93/637] [D loss: 0.169226] [G loss: 0.557725]\n",
      "[Epoch 20/200] [Batch 94/637] [D loss: 0.167804] [G loss: 0.504549]\n",
      "[Epoch 20/200] [Batch 95/637] [D loss: 0.176056] [G loss: 0.533820]\n",
      "[Epoch 20/200] [Batch 96/637] [D loss: 0.164817] [G loss: 0.559146]\n",
      "[Epoch 20/200] [Batch 97/637] [D loss: 0.217298] [G loss: 0.607888]\n",
      "[Epoch 20/200] [Batch 98/637] [D loss: 0.191412] [G loss: 0.470628]\n",
      "[Epoch 20/200] [Batch 99/637] [D loss: 0.162525] [G loss: 0.553197]\n",
      "[Epoch 20/200] [Batch 100/637] [D loss: 0.153594] [G loss: 0.543836]\n",
      "[Epoch 20/200] [Batch 101/637] [D loss: 0.184418] [G loss: 0.437895]\n",
      "[Epoch 20/200] [Batch 102/637] [D loss: 0.186925] [G loss: 0.488207]\n",
      "[Epoch 20/200] [Batch 103/637] [D loss: 0.159841] [G loss: 0.475839]\n",
      "[Epoch 20/200] [Batch 104/637] [D loss: 0.166914] [G loss: 0.491853]\n",
      "[Epoch 20/200] [Batch 105/637] [D loss: 0.148781] [G loss: 0.490934]\n",
      "[Epoch 20/200] [Batch 106/637] [D loss: 0.161767] [G loss: 0.527403]\n",
      "[Epoch 20/200] [Batch 107/637] [D loss: 0.175990] [G loss: 0.510962]\n",
      "[Epoch 20/200] [Batch 108/637] [D loss: 0.165736] [G loss: 0.470102]\n",
      "[Epoch 20/200] [Batch 109/637] [D loss: 0.162165] [G loss: 0.512739]\n",
      "[Epoch 20/200] [Batch 110/637] [D loss: 0.165474] [G loss: 0.523456]\n",
      "[Epoch 20/200] [Batch 111/637] [D loss: 0.170507] [G loss: 0.494142]\n",
      "[Epoch 20/200] [Batch 112/637] [D loss: 0.176245] [G loss: 0.499148]\n",
      "[Epoch 20/200] [Batch 113/637] [D loss: 0.158812] [G loss: 0.459320]\n",
      "[Epoch 20/200] [Batch 114/637] [D loss: 0.184258] [G loss: 0.432855]\n",
      "[Epoch 20/200] [Batch 115/637] [D loss: 0.171834] [G loss: 0.549731]\n",
      "[Epoch 20/200] [Batch 116/637] [D loss: 0.167100] [G loss: 0.503144]\n",
      "[Epoch 20/200] [Batch 117/637] [D loss: 0.167673] [G loss: 0.443492]\n",
      "[Epoch 20/200] [Batch 118/637] [D loss: 0.170655] [G loss: 0.494613]\n",
      "[Epoch 20/200] [Batch 119/637] [D loss: 0.157280] [G loss: 0.541641]\n",
      "[Epoch 20/200] [Batch 120/637] [D loss: 0.169567] [G loss: 0.458385]\n",
      "[Epoch 20/200] [Batch 121/637] [D loss: 0.182729] [G loss: 0.488749]\n",
      "[Epoch 20/200] [Batch 122/637] [D loss: 0.161275] [G loss: 0.531992]\n",
      "[Epoch 20/200] [Batch 123/637] [D loss: 0.185566] [G loss: 0.508477]\n",
      "[Epoch 20/200] [Batch 124/637] [D loss: 0.161854] [G loss: 0.541163]\n",
      "[Epoch 20/200] [Batch 125/637] [D loss: 0.184369] [G loss: 0.461353]\n",
      "[Epoch 20/200] [Batch 126/637] [D loss: 0.191849] [G loss: 0.465086]\n",
      "[Epoch 20/200] [Batch 127/637] [D loss: 0.169376] [G loss: 0.569207]\n",
      "[Epoch 20/200] [Batch 128/637] [D loss: 0.193909] [G loss: 0.537108]\n",
      "[Epoch 20/200] [Batch 129/637] [D loss: 0.174110] [G loss: 0.506082]\n",
      "[Epoch 20/200] [Batch 130/637] [D loss: 0.163022] [G loss: 0.425057]\n",
      "[Epoch 20/200] [Batch 131/637] [D loss: 0.143457] [G loss: 0.528574]\n",
      "[Epoch 20/200] [Batch 132/637] [D loss: 0.165191] [G loss: 0.512105]\n",
      "[Epoch 20/200] [Batch 133/637] [D loss: 0.173086] [G loss: 0.514388]\n",
      "[Epoch 20/200] [Batch 134/637] [D loss: 0.178086] [G loss: 0.452859]\n",
      "[Epoch 20/200] [Batch 135/637] [D loss: 0.171300] [G loss: 0.529628]\n",
      "[Epoch 20/200] [Batch 136/637] [D loss: 0.134504] [G loss: 0.517429]\n",
      "[Epoch 20/200] [Batch 137/637] [D loss: 0.234311] [G loss: 0.389862]\n",
      "[Epoch 20/200] [Batch 138/637] [D loss: 0.224055] [G loss: 0.529112]\n",
      "[Epoch 20/200] [Batch 139/637] [D loss: 0.177657] [G loss: 0.532985]\n",
      "[Epoch 20/200] [Batch 140/637] [D loss: 0.163884] [G loss: 0.561325]\n",
      "[Epoch 20/200] [Batch 141/637] [D loss: 0.184381] [G loss: 0.457423]\n",
      "[Epoch 20/200] [Batch 142/637] [D loss: 0.153615] [G loss: 0.516070]\n",
      "[Epoch 20/200] [Batch 143/637] [D loss: 0.138371] [G loss: 0.539762]\n",
      "[Epoch 20/200] [Batch 144/637] [D loss: 0.159568] [G loss: 0.479152]\n",
      "[Epoch 20/200] [Batch 145/637] [D loss: 0.176189] [G loss: 0.468372]\n",
      "[Epoch 20/200] [Batch 146/637] [D loss: 0.158602] [G loss: 0.473662]\n",
      "[Epoch 20/200] [Batch 147/637] [D loss: 0.148676] [G loss: 0.497339]\n",
      "[Epoch 20/200] [Batch 148/637] [D loss: 0.167033] [G loss: 0.485173]\n",
      "[Epoch 20/200] [Batch 149/637] [D loss: 0.183602] [G loss: 0.497286]\n",
      "[Epoch 20/200] [Batch 150/637] [D loss: 0.159422] [G loss: 0.507672]\n",
      "[Epoch 20/200] [Batch 151/637] [D loss: 0.164211] [G loss: 0.475038]\n",
      "[Epoch 20/200] [Batch 152/637] [D loss: 0.168092] [G loss: 0.431533]\n",
      "[Epoch 20/200] [Batch 153/637] [D loss: 0.156459] [G loss: 0.466526]\n",
      "[Epoch 20/200] [Batch 154/637] [D loss: 0.181052] [G loss: 0.460197]\n",
      "[Epoch 20/200] [Batch 155/637] [D loss: 0.182578] [G loss: 0.507930]\n",
      "[Epoch 20/200] [Batch 156/637] [D loss: 0.180488] [G loss: 0.421818]\n",
      "[Epoch 20/200] [Batch 157/637] [D loss: 0.181543] [G loss: 0.439272]\n",
      "[Epoch 20/200] [Batch 158/637] [D loss: 0.167108] [G loss: 0.543597]\n",
      "[Epoch 20/200] [Batch 159/637] [D loss: 0.158579] [G loss: 0.538623]\n",
      "[Epoch 20/200] [Batch 160/637] [D loss: 0.164725] [G loss: 0.474435]\n",
      "[Epoch 20/200] [Batch 161/637] [D loss: 0.169050] [G loss: 0.466662]\n",
      "[Epoch 20/200] [Batch 162/637] [D loss: 0.173283] [G loss: 0.466599]\n",
      "[Epoch 20/200] [Batch 163/637] [D loss: 0.164380] [G loss: 0.529707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 164/637] [D loss: 0.162560] [G loss: 0.455555]\n",
      "[Epoch 20/200] [Batch 165/637] [D loss: 0.163858] [G loss: 0.423680]\n",
      "[Epoch 20/200] [Batch 166/637] [D loss: 0.160712] [G loss: 0.587685]\n",
      "[Epoch 20/200] [Batch 167/637] [D loss: 0.154749] [G loss: 0.528619]\n",
      "[Epoch 20/200] [Batch 168/637] [D loss: 0.162431] [G loss: 0.460806]\n",
      "[Epoch 20/200] [Batch 169/637] [D loss: 0.143902] [G loss: 0.497722]\n",
      "[Epoch 20/200] [Batch 170/637] [D loss: 0.138959] [G loss: 0.504265]\n",
      "[Epoch 20/200] [Batch 171/637] [D loss: 0.157677] [G loss: 0.460675]\n",
      "[Epoch 20/200] [Batch 172/637] [D loss: 0.138631] [G loss: 0.494773]\n",
      "[Epoch 20/200] [Batch 173/637] [D loss: 0.164400] [G loss: 0.456298]\n",
      "[Epoch 20/200] [Batch 174/637] [D loss: 0.171219] [G loss: 0.494526]\n",
      "[Epoch 20/200] [Batch 175/637] [D loss: 0.181930] [G loss: 0.581907]\n",
      "[Epoch 20/200] [Batch 176/637] [D loss: 0.166442] [G loss: 0.513283]\n",
      "[Epoch 20/200] [Batch 177/637] [D loss: 0.157160] [G loss: 0.540808]\n",
      "[Epoch 20/200] [Batch 178/637] [D loss: 0.158880] [G loss: 0.515269]\n",
      "[Epoch 20/200] [Batch 179/637] [D loss: 0.182178] [G loss: 0.481163]\n",
      "[Epoch 20/200] [Batch 180/637] [D loss: 0.168258] [G loss: 0.510169]\n",
      "[Epoch 20/200] [Batch 181/637] [D loss: 0.173773] [G loss: 0.511394]\n",
      "[Epoch 20/200] [Batch 182/637] [D loss: 0.178044] [G loss: 0.479113]\n",
      "[Epoch 20/200] [Batch 183/637] [D loss: 0.155389] [G loss: 0.473921]\n",
      "[Epoch 20/200] [Batch 184/637] [D loss: 0.147690] [G loss: 0.489682]\n",
      "[Epoch 20/200] [Batch 185/637] [D loss: 0.159515] [G loss: 0.497898]\n",
      "[Epoch 20/200] [Batch 186/637] [D loss: 0.174127] [G loss: 0.491237]\n",
      "[Epoch 20/200] [Batch 187/637] [D loss: 0.167126] [G loss: 0.540468]\n",
      "[Epoch 20/200] [Batch 188/637] [D loss: 0.167476] [G loss: 0.519165]\n",
      "[Epoch 20/200] [Batch 189/637] [D loss: 0.195014] [G loss: 0.482603]\n",
      "[Epoch 20/200] [Batch 190/637] [D loss: 0.166317] [G loss: 0.578741]\n",
      "[Epoch 20/200] [Batch 191/637] [D loss: 0.176960] [G loss: 0.550549]\n",
      "[Epoch 20/200] [Batch 192/637] [D loss: 0.174949] [G loss: 0.520676]\n",
      "[Epoch 20/200] [Batch 193/637] [D loss: 0.179690] [G loss: 0.470698]\n",
      "[Epoch 20/200] [Batch 194/637] [D loss: 0.163632] [G loss: 0.437652]\n",
      "[Epoch 20/200] [Batch 195/637] [D loss: 0.160157] [G loss: 0.474996]\n",
      "[Epoch 20/200] [Batch 196/637] [D loss: 0.163846] [G loss: 0.481467]\n",
      "[Epoch 20/200] [Batch 197/637] [D loss: 0.174873] [G loss: 0.531385]\n",
      "[Epoch 20/200] [Batch 198/637] [D loss: 0.145250] [G loss: 0.537107]\n",
      "[Epoch 20/200] [Batch 199/637] [D loss: 0.150829] [G loss: 0.538809]\n",
      "[Epoch 20/200] [Batch 200/637] [D loss: 0.178481] [G loss: 0.461182]\n",
      "[Epoch 20/200] [Batch 201/637] [D loss: 0.155674] [G loss: 0.523512]\n",
      "[Epoch 20/200] [Batch 202/637] [D loss: 0.188017] [G loss: 0.422896]\n",
      "[Epoch 20/200] [Batch 203/637] [D loss: 0.160700] [G loss: 0.529436]\n",
      "[Epoch 20/200] [Batch 204/637] [D loss: 0.186489] [G loss: 0.485880]\n",
      "[Epoch 20/200] [Batch 205/637] [D loss: 0.163793] [G loss: 0.462169]\n",
      "[Epoch 20/200] [Batch 206/637] [D loss: 0.161496] [G loss: 0.476623]\n",
      "[Epoch 20/200] [Batch 207/637] [D loss: 0.181663] [G loss: 0.515368]\n",
      "[Epoch 20/200] [Batch 208/637] [D loss: 0.168090] [G loss: 0.465850]\n",
      "[Epoch 20/200] [Batch 209/637] [D loss: 0.166906] [G loss: 0.515785]\n",
      "[Epoch 20/200] [Batch 210/637] [D loss: 0.153274] [G loss: 0.439168]\n",
      "[Epoch 20/200] [Batch 211/637] [D loss: 0.143384] [G loss: 0.526264]\n",
      "[Epoch 20/200] [Batch 212/637] [D loss: 0.172783] [G loss: 0.428216]\n",
      "[Epoch 20/200] [Batch 213/637] [D loss: 0.157511] [G loss: 0.498903]\n",
      "[Epoch 20/200] [Batch 214/637] [D loss: 0.162031] [G loss: 0.557340]\n",
      "[Epoch 20/200] [Batch 215/637] [D loss: 0.148476] [G loss: 0.538455]\n",
      "[Epoch 20/200] [Batch 216/637] [D loss: 0.188883] [G loss: 0.501259]\n",
      "[Epoch 20/200] [Batch 217/637] [D loss: 0.183589] [G loss: 0.408473]\n",
      "[Epoch 20/200] [Batch 218/637] [D loss: 0.144794] [G loss: 0.492221]\n",
      "[Epoch 20/200] [Batch 219/637] [D loss: 0.148807] [G loss: 0.580985]\n",
      "[Epoch 20/200] [Batch 220/637] [D loss: 0.164456] [G loss: 0.495796]\n",
      "[Epoch 20/200] [Batch 221/637] [D loss: 0.173295] [G loss: 0.581488]\n",
      "[Epoch 20/200] [Batch 222/637] [D loss: 0.190759] [G loss: 0.495765]\n",
      "[Epoch 20/200] [Batch 223/637] [D loss: 0.177417] [G loss: 0.474973]\n",
      "[Epoch 20/200] [Batch 224/637] [D loss: 0.213847] [G loss: 0.497108]\n",
      "[Epoch 20/200] [Batch 225/637] [D loss: 0.160936] [G loss: 0.466359]\n",
      "[Epoch 20/200] [Batch 226/637] [D loss: 0.215838] [G loss: 0.366540]\n",
      "[Epoch 20/200] [Batch 227/637] [D loss: 0.194278] [G loss: 0.552504]\n",
      "[Epoch 20/200] [Batch 228/637] [D loss: 0.170346] [G loss: 0.522924]\n",
      "[Epoch 20/200] [Batch 229/637] [D loss: 0.178450] [G loss: 0.432401]\n",
      "[Epoch 20/200] [Batch 230/637] [D loss: 0.180284] [G loss: 0.402315]\n",
      "[Epoch 20/200] [Batch 231/637] [D loss: 0.158849] [G loss: 0.442882]\n",
      "[Epoch 20/200] [Batch 232/637] [D loss: 0.170079] [G loss: 0.507973]\n",
      "[Epoch 20/200] [Batch 233/637] [D loss: 0.145559] [G loss: 0.537043]\n",
      "[Epoch 20/200] [Batch 234/637] [D loss: 0.152175] [G loss: 0.585994]\n",
      "[Epoch 20/200] [Batch 235/637] [D loss: 0.162215] [G loss: 0.544380]\n",
      "[Epoch 20/200] [Batch 236/637] [D loss: 0.170078] [G loss: 0.498729]\n",
      "[Epoch 20/200] [Batch 237/637] [D loss: 0.164786] [G loss: 0.493145]\n",
      "[Epoch 20/200] [Batch 238/637] [D loss: 0.173939] [G loss: 0.446660]\n",
      "[Epoch 20/200] [Batch 239/637] [D loss: 0.157424] [G loss: 0.494203]\n",
      "[Epoch 20/200] [Batch 240/637] [D loss: 0.160752] [G loss: 0.554187]\n",
      "[Epoch 20/200] [Batch 241/637] [D loss: 0.168259] [G loss: 0.469933]\n",
      "[Epoch 20/200] [Batch 242/637] [D loss: 0.178081] [G loss: 0.497082]\n",
      "[Epoch 20/200] [Batch 243/637] [D loss: 0.160743] [G loss: 0.486624]\n",
      "[Epoch 20/200] [Batch 244/637] [D loss: 0.159926] [G loss: 0.552274]\n",
      "[Epoch 20/200] [Batch 245/637] [D loss: 0.187006] [G loss: 0.452061]\n",
      "[Epoch 20/200] [Batch 246/637] [D loss: 0.188593] [G loss: 0.485648]\n",
      "[Epoch 20/200] [Batch 247/637] [D loss: 0.171225] [G loss: 0.493952]\n",
      "[Epoch 20/200] [Batch 248/637] [D loss: 0.165418] [G loss: 0.477698]\n",
      "[Epoch 20/200] [Batch 249/637] [D loss: 0.160426] [G loss: 0.478116]\n",
      "[Epoch 20/200] [Batch 250/637] [D loss: 0.163071] [G loss: 0.481085]\n",
      "[Epoch 20/200] [Batch 251/637] [D loss: 0.163810] [G loss: 0.510166]\n",
      "[Epoch 20/200] [Batch 252/637] [D loss: 0.157746] [G loss: 0.471149]\n",
      "[Epoch 20/200] [Batch 253/637] [D loss: 0.190233] [G loss: 0.354697]\n",
      "[Epoch 20/200] [Batch 254/637] [D loss: 0.160747] [G loss: 0.559200]\n",
      "[Epoch 20/200] [Batch 255/637] [D loss: 0.154446] [G loss: 0.575177]\n",
      "[Epoch 20/200] [Batch 256/637] [D loss: 0.168477] [G loss: 0.452267]\n",
      "[Epoch 20/200] [Batch 257/637] [D loss: 0.186570] [G loss: 0.502600]\n",
      "[Epoch 20/200] [Batch 258/637] [D loss: 0.159975] [G loss: 0.496550]\n",
      "[Epoch 20/200] [Batch 259/637] [D loss: 0.133900] [G loss: 0.553026]\n",
      "[Epoch 20/200] [Batch 260/637] [D loss: 0.147682] [G loss: 0.467092]\n",
      "[Epoch 20/200] [Batch 261/637] [D loss: 0.173543] [G loss: 0.512603]\n",
      "[Epoch 20/200] [Batch 262/637] [D loss: 0.154540] [G loss: 0.528419]\n",
      "[Epoch 20/200] [Batch 263/637] [D loss: 0.159264] [G loss: 0.572287]\n",
      "[Epoch 20/200] [Batch 264/637] [D loss: 0.187840] [G loss: 0.560156]\n",
      "[Epoch 20/200] [Batch 265/637] [D loss: 0.179844] [G loss: 0.499735]\n",
      "[Epoch 20/200] [Batch 266/637] [D loss: 0.159507] [G loss: 0.527791]\n",
      "[Epoch 20/200] [Batch 267/637] [D loss: 0.196922] [G loss: 0.503124]\n",
      "[Epoch 20/200] [Batch 268/637] [D loss: 0.210640] [G loss: 0.421491]\n",
      "[Epoch 20/200] [Batch 269/637] [D loss: 0.193419] [G loss: 0.491524]\n",
      "[Epoch 20/200] [Batch 270/637] [D loss: 0.190913] [G loss: 0.463672]\n",
      "[Epoch 20/200] [Batch 271/637] [D loss: 0.179003] [G loss: 0.466008]\n",
      "[Epoch 20/200] [Batch 272/637] [D loss: 0.163441] [G loss: 0.503479]\n",
      "[Epoch 20/200] [Batch 273/637] [D loss: 0.163491] [G loss: 0.547964]\n",
      "[Epoch 20/200] [Batch 274/637] [D loss: 0.200906] [G loss: 0.418334]\n",
      "[Epoch 20/200] [Batch 275/637] [D loss: 0.168250] [G loss: 0.481873]\n",
      "[Epoch 20/200] [Batch 276/637] [D loss: 0.149973] [G loss: 0.531241]\n",
      "[Epoch 20/200] [Batch 277/637] [D loss: 0.189818] [G loss: 0.463749]\n",
      "[Epoch 20/200] [Batch 278/637] [D loss: 0.167516] [G loss: 0.479312]\n",
      "[Epoch 20/200] [Batch 279/637] [D loss: 0.168140] [G loss: 0.433811]\n",
      "[Epoch 20/200] [Batch 280/637] [D loss: 0.155229] [G loss: 0.481796]\n",
      "[Epoch 20/200] [Batch 281/637] [D loss: 0.155452] [G loss: 0.449723]\n",
      "[Epoch 20/200] [Batch 282/637] [D loss: 0.161155] [G loss: 0.517276]\n",
      "[Epoch 20/200] [Batch 283/637] [D loss: 0.207875] [G loss: 0.479203]\n",
      "[Epoch 20/200] [Batch 284/637] [D loss: 0.161114] [G loss: 0.669802]\n",
      "[Epoch 20/200] [Batch 285/637] [D loss: 0.192822] [G loss: 0.563141]\n",
      "[Epoch 20/200] [Batch 286/637] [D loss: 0.170696] [G loss: 0.465282]\n",
      "[Epoch 20/200] [Batch 287/637] [D loss: 0.146360] [G loss: 0.531841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 288/637] [D loss: 0.140985] [G loss: 0.523078]\n",
      "[Epoch 20/200] [Batch 289/637] [D loss: 0.185081] [G loss: 0.446260]\n",
      "[Epoch 20/200] [Batch 290/637] [D loss: 0.171120] [G loss: 0.482257]\n",
      "[Epoch 20/200] [Batch 291/637] [D loss: 0.150923] [G loss: 0.488353]\n",
      "[Epoch 20/200] [Batch 292/637] [D loss: 0.172985] [G loss: 0.459637]\n",
      "[Epoch 20/200] [Batch 293/637] [D loss: 0.163947] [G loss: 0.592830]\n",
      "[Epoch 20/200] [Batch 294/637] [D loss: 0.192253] [G loss: 0.431519]\n",
      "[Epoch 20/200] [Batch 295/637] [D loss: 0.208070] [G loss: 0.465220]\n",
      "[Epoch 20/200] [Batch 296/637] [D loss: 0.183327] [G loss: 0.491459]\n",
      "[Epoch 20/200] [Batch 297/637] [D loss: 0.166407] [G loss: 0.525077]\n",
      "[Epoch 20/200] [Batch 298/637] [D loss: 0.156758] [G loss: 0.410306]\n",
      "[Epoch 20/200] [Batch 299/637] [D loss: 0.155545] [G loss: 0.457808]\n",
      "[Epoch 20/200] [Batch 300/637] [D loss: 0.162284] [G loss: 0.453606]\n",
      "[Epoch 20/200] [Batch 301/637] [D loss: 0.163796] [G loss: 0.481907]\n",
      "[Epoch 20/200] [Batch 302/637] [D loss: 0.157805] [G loss: 0.520592]\n",
      "[Epoch 20/200] [Batch 303/637] [D loss: 0.158550] [G loss: 0.579108]\n",
      "[Epoch 20/200] [Batch 304/637] [D loss: 0.157713] [G loss: 0.563672]\n",
      "[Epoch 20/200] [Batch 305/637] [D loss: 0.156842] [G loss: 0.507537]\n",
      "[Epoch 20/200] [Batch 306/637] [D loss: 0.152129] [G loss: 0.565762]\n",
      "[Epoch 20/200] [Batch 307/637] [D loss: 0.144287] [G loss: 0.514860]\n",
      "[Epoch 20/200] [Batch 308/637] [D loss: 0.179531] [G loss: 0.443929]\n",
      "[Epoch 20/200] [Batch 309/637] [D loss: 0.152314] [G loss: 0.518115]\n",
      "[Epoch 20/200] [Batch 310/637] [D loss: 0.159139] [G loss: 0.447320]\n",
      "[Epoch 20/200] [Batch 311/637] [D loss: 0.148690] [G loss: 0.435981]\n",
      "[Epoch 20/200] [Batch 312/637] [D loss: 0.159791] [G loss: 0.492119]\n",
      "[Epoch 20/200] [Batch 313/637] [D loss: 0.160161] [G loss: 0.569857]\n",
      "[Epoch 20/200] [Batch 314/637] [D loss: 0.180863] [G loss: 0.509473]\n",
      "[Epoch 20/200] [Batch 315/637] [D loss: 0.153753] [G loss: 0.555366]\n",
      "[Epoch 20/200] [Batch 316/637] [D loss: 0.187345] [G loss: 0.409920]\n",
      "[Epoch 20/200] [Batch 317/637] [D loss: 0.165376] [G loss: 0.522668]\n",
      "[Epoch 20/200] [Batch 318/637] [D loss: 0.162133] [G loss: 0.452294]\n",
      "[Epoch 20/200] [Batch 319/637] [D loss: 0.191028] [G loss: 0.419127]\n",
      "[Epoch 20/200] [Batch 320/637] [D loss: 0.173636] [G loss: 0.607097]\n",
      "[Epoch 20/200] [Batch 321/637] [D loss: 0.152556] [G loss: 0.465989]\n",
      "[Epoch 20/200] [Batch 322/637] [D loss: 0.163389] [G loss: 0.555429]\n",
      "[Epoch 20/200] [Batch 323/637] [D loss: 0.171699] [G loss: 0.440302]\n",
      "[Epoch 20/200] [Batch 324/637] [D loss: 0.188146] [G loss: 0.439979]\n",
      "[Epoch 20/200] [Batch 325/637] [D loss: 0.182821] [G loss: 0.475187]\n",
      "[Epoch 20/200] [Batch 326/637] [D loss: 0.177692] [G loss: 0.483851]\n",
      "[Epoch 20/200] [Batch 327/637] [D loss: 0.190485] [G loss: 0.521342]\n",
      "[Epoch 20/200] [Batch 328/637] [D loss: 0.169277] [G loss: 0.482840]\n",
      "[Epoch 20/200] [Batch 329/637] [D loss: 0.191012] [G loss: 0.386991]\n",
      "[Epoch 20/200] [Batch 330/637] [D loss: 0.202663] [G loss: 0.587408]\n",
      "[Epoch 20/200] [Batch 331/637] [D loss: 0.216300] [G loss: 0.521573]\n",
      "[Epoch 20/200] [Batch 332/637] [D loss: 0.163963] [G loss: 0.473898]\n",
      "[Epoch 20/200] [Batch 333/637] [D loss: 0.170695] [G loss: 0.444320]\n",
      "[Epoch 20/200] [Batch 334/637] [D loss: 0.152470] [G loss: 0.462992]\n",
      "[Epoch 20/200] [Batch 335/637] [D loss: 0.144656] [G loss: 0.476991]\n",
      "[Epoch 20/200] [Batch 336/637] [D loss: 0.188745] [G loss: 0.387614]\n",
      "[Epoch 20/200] [Batch 337/637] [D loss: 0.170875] [G loss: 0.420574]\n",
      "[Epoch 20/200] [Batch 338/637] [D loss: 0.176702] [G loss: 0.467698]\n",
      "[Epoch 20/200] [Batch 339/637] [D loss: 0.154042] [G loss: 0.490586]\n",
      "[Epoch 20/200] [Batch 340/637] [D loss: 0.144746] [G loss: 0.485720]\n",
      "[Epoch 20/200] [Batch 341/637] [D loss: 0.147275] [G loss: 0.453644]\n",
      "[Epoch 20/200] [Batch 342/637] [D loss: 0.184355] [G loss: 0.413505]\n",
      "[Epoch 20/200] [Batch 343/637] [D loss: 0.146910] [G loss: 0.513217]\n",
      "[Epoch 20/200] [Batch 344/637] [D loss: 0.171386] [G loss: 0.438058]\n",
      "[Epoch 20/200] [Batch 345/637] [D loss: 0.179131] [G loss: 0.494172]\n",
      "[Epoch 20/200] [Batch 346/637] [D loss: 0.169234] [G loss: 0.438485]\n",
      "[Epoch 20/200] [Batch 347/637] [D loss: 0.149816] [G loss: 0.552014]\n",
      "[Epoch 20/200] [Batch 348/637] [D loss: 0.147712] [G loss: 0.565344]\n",
      "[Epoch 20/200] [Batch 349/637] [D loss: 0.159901] [G loss: 0.531665]\n",
      "[Epoch 20/200] [Batch 350/637] [D loss: 0.148411] [G loss: 0.476874]\n",
      "[Epoch 20/200] [Batch 351/637] [D loss: 0.166096] [G loss: 0.433685]\n",
      "[Epoch 20/200] [Batch 352/637] [D loss: 0.167543] [G loss: 0.491590]\n",
      "[Epoch 20/200] [Batch 353/637] [D loss: 0.174307] [G loss: 0.423999]\n",
      "[Epoch 20/200] [Batch 354/637] [D loss: 0.154194] [G loss: 0.642170]\n",
      "[Epoch 20/200] [Batch 355/637] [D loss: 0.176328] [G loss: 0.560754]\n",
      "[Epoch 20/200] [Batch 356/637] [D loss: 0.143590] [G loss: 0.458660]\n",
      "[Epoch 20/200] [Batch 357/637] [D loss: 0.162220] [G loss: 0.450686]\n",
      "[Epoch 20/200] [Batch 358/637] [D loss: 0.167670] [G loss: 0.550521]\n",
      "[Epoch 20/200] [Batch 359/637] [D loss: 0.170462] [G loss: 0.505260]\n",
      "[Epoch 20/200] [Batch 360/637] [D loss: 0.154102] [G loss: 0.507688]\n",
      "[Epoch 20/200] [Batch 361/637] [D loss: 0.162999] [G loss: 0.442541]\n",
      "[Epoch 20/200] [Batch 362/637] [D loss: 0.167380] [G loss: 0.444258]\n",
      "[Epoch 20/200] [Batch 363/637] [D loss: 0.212873] [G loss: 0.513518]\n",
      "[Epoch 20/200] [Batch 364/637] [D loss: 0.163238] [G loss: 0.540722]\n",
      "[Epoch 20/200] [Batch 365/637] [D loss: 0.172122] [G loss: 0.546165]\n",
      "[Epoch 20/200] [Batch 366/637] [D loss: 0.145011] [G loss: 0.650977]\n",
      "[Epoch 20/200] [Batch 367/637] [D loss: 0.137820] [G loss: 0.512429]\n",
      "[Epoch 20/200] [Batch 368/637] [D loss: 0.157519] [G loss: 0.451683]\n",
      "[Epoch 20/200] [Batch 369/637] [D loss: 0.146244] [G loss: 0.543552]\n",
      "[Epoch 20/200] [Batch 370/637] [D loss: 0.167875] [G loss: 0.558964]\n",
      "[Epoch 20/200] [Batch 371/637] [D loss: 0.173905] [G loss: 0.494947]\n",
      "[Epoch 20/200] [Batch 372/637] [D loss: 0.165158] [G loss: 0.493334]\n",
      "[Epoch 20/200] [Batch 373/637] [D loss: 0.168888] [G loss: 0.542395]\n",
      "[Epoch 20/200] [Batch 374/637] [D loss: 0.179811] [G loss: 0.523249]\n",
      "[Epoch 20/200] [Batch 375/637] [D loss: 0.161641] [G loss: 0.514454]\n",
      "[Epoch 20/200] [Batch 376/637] [D loss: 0.156217] [G loss: 0.504233]\n",
      "[Epoch 20/200] [Batch 377/637] [D loss: 0.167373] [G loss: 0.521223]\n",
      "[Epoch 20/200] [Batch 378/637] [D loss: 0.199000] [G loss: 0.420856]\n",
      "[Epoch 20/200] [Batch 379/637] [D loss: 0.188267] [G loss: 0.658241]\n",
      "[Epoch 20/200] [Batch 380/637] [D loss: 0.164287] [G loss: 0.593817]\n",
      "[Epoch 20/200] [Batch 381/637] [D loss: 0.173989] [G loss: 0.504198]\n",
      "[Epoch 20/200] [Batch 382/637] [D loss: 0.151954] [G loss: 0.588013]\n",
      "[Epoch 20/200] [Batch 383/637] [D loss: 0.157320] [G loss: 0.546254]\n",
      "[Epoch 20/200] [Batch 384/637] [D loss: 0.188499] [G loss: 0.464489]\n",
      "[Epoch 20/200] [Batch 385/637] [D loss: 0.169366] [G loss: 0.494712]\n",
      "[Epoch 20/200] [Batch 386/637] [D loss: 0.171727] [G loss: 0.553963]\n",
      "[Epoch 20/200] [Batch 387/637] [D loss: 0.185008] [G loss: 0.492613]\n",
      "[Epoch 20/200] [Batch 388/637] [D loss: 0.158806] [G loss: 0.551775]\n",
      "[Epoch 20/200] [Batch 389/637] [D loss: 0.176121] [G loss: 0.561913]\n",
      "[Epoch 20/200] [Batch 390/637] [D loss: 0.153859] [G loss: 0.450927]\n",
      "[Epoch 20/200] [Batch 391/637] [D loss: 0.153071] [G loss: 0.444092]\n",
      "[Epoch 20/200] [Batch 392/637] [D loss: 0.196770] [G loss: 0.512076]\n",
      "[Epoch 20/200] [Batch 393/637] [D loss: 0.171162] [G loss: 0.585800]\n",
      "[Epoch 20/200] [Batch 394/637] [D loss: 0.167012] [G loss: 0.640892]\n",
      "[Epoch 20/200] [Batch 395/637] [D loss: 0.177068] [G loss: 0.513892]\n",
      "[Epoch 20/200] [Batch 396/637] [D loss: 0.165913] [G loss: 0.499073]\n",
      "[Epoch 20/200] [Batch 397/637] [D loss: 0.154354] [G loss: 0.487469]\n",
      "[Epoch 20/200] [Batch 398/637] [D loss: 0.174596] [G loss: 0.463862]\n",
      "[Epoch 20/200] [Batch 399/637] [D loss: 0.154753] [G loss: 0.489122]\n",
      "[Epoch 20/200] [Batch 400/637] [D loss: 0.134302] [G loss: 0.562099]\n",
      "[Epoch 20/200] [Batch 401/637] [D loss: 0.174944] [G loss: 0.489398]\n",
      "[Epoch 20/200] [Batch 402/637] [D loss: 0.185341] [G loss: 0.475503]\n",
      "[Epoch 20/200] [Batch 403/637] [D loss: 0.145787] [G loss: 0.544351]\n",
      "[Epoch 20/200] [Batch 404/637] [D loss: 0.169122] [G loss: 0.445100]\n",
      "[Epoch 20/200] [Batch 405/637] [D loss: 0.200167] [G loss: 0.396581]\n",
      "[Epoch 20/200] [Batch 406/637] [D loss: 0.172483] [G loss: 0.503715]\n",
      "[Epoch 20/200] [Batch 407/637] [D loss: 0.173393] [G loss: 0.489724]\n",
      "[Epoch 20/200] [Batch 408/637] [D loss: 0.146102] [G loss: 0.499248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 409/637] [D loss: 0.139269] [G loss: 0.569183]\n",
      "[Epoch 20/200] [Batch 410/637] [D loss: 0.182786] [G loss: 0.442777]\n",
      "[Epoch 20/200] [Batch 411/637] [D loss: 0.310157] [G loss: 0.556791]\n",
      "[Epoch 20/200] [Batch 412/637] [D loss: 0.161941] [G loss: 0.607890]\n",
      "[Epoch 20/200] [Batch 413/637] [D loss: 0.235601] [G loss: 0.471868]\n",
      "[Epoch 20/200] [Batch 414/637] [D loss: 0.182492] [G loss: 0.512628]\n",
      "[Epoch 20/200] [Batch 415/637] [D loss: 0.194943] [G loss: 0.515504]\n",
      "[Epoch 20/200] [Batch 416/637] [D loss: 0.222463] [G loss: 0.431411]\n",
      "[Epoch 20/200] [Batch 417/637] [D loss: 0.167445] [G loss: 0.461051]\n",
      "[Epoch 20/200] [Batch 418/637] [D loss: 0.205111] [G loss: 0.547685]\n",
      "[Epoch 20/200] [Batch 419/637] [D loss: 0.177241] [G loss: 0.492050]\n",
      "[Epoch 20/200] [Batch 420/637] [D loss: 0.196251] [G loss: 0.474517]\n",
      "[Epoch 20/200] [Batch 421/637] [D loss: 0.178457] [G loss: 0.434287]\n",
      "[Epoch 20/200] [Batch 422/637] [D loss: 0.188352] [G loss: 0.461912]\n",
      "[Epoch 20/200] [Batch 423/637] [D loss: 0.164575] [G loss: 0.515678]\n",
      "[Epoch 20/200] [Batch 424/637] [D loss: 0.191261] [G loss: 0.432521]\n",
      "[Epoch 20/200] [Batch 425/637] [D loss: 0.157092] [G loss: 0.504595]\n",
      "[Epoch 20/200] [Batch 426/637] [D loss: 0.173854] [G loss: 0.561434]\n",
      "[Epoch 20/200] [Batch 427/637] [D loss: 0.170755] [G loss: 0.507209]\n",
      "[Epoch 20/200] [Batch 428/637] [D loss: 0.169662] [G loss: 0.507922]\n",
      "[Epoch 20/200] [Batch 429/637] [D loss: 0.169037] [G loss: 0.492664]\n",
      "[Epoch 20/200] [Batch 430/637] [D loss: 0.155449] [G loss: 0.550788]\n",
      "[Epoch 20/200] [Batch 431/637] [D loss: 0.153031] [G loss: 0.571557]\n",
      "[Epoch 20/200] [Batch 432/637] [D loss: 0.154767] [G loss: 0.559595]\n",
      "[Epoch 20/200] [Batch 433/637] [D loss: 0.195268] [G loss: 0.391073]\n",
      "[Epoch 20/200] [Batch 434/637] [D loss: 0.163653] [G loss: 0.559895]\n",
      "[Epoch 20/200] [Batch 435/637] [D loss: 0.179740] [G loss: 0.497743]\n",
      "[Epoch 20/200] [Batch 436/637] [D loss: 0.179406] [G loss: 0.451751]\n",
      "[Epoch 20/200] [Batch 437/637] [D loss: 0.166188] [G loss: 0.419538]\n",
      "[Epoch 20/200] [Batch 438/637] [D loss: 0.160728] [G loss: 0.473912]\n",
      "[Epoch 20/200] [Batch 439/637] [D loss: 0.162066] [G loss: 0.556328]\n",
      "[Epoch 20/200] [Batch 440/637] [D loss: 0.171359] [G loss: 0.515067]\n",
      "[Epoch 20/200] [Batch 441/637] [D loss: 0.184332] [G loss: 0.474370]\n",
      "[Epoch 20/200] [Batch 442/637] [D loss: 0.182902] [G loss: 0.394638]\n",
      "[Epoch 20/200] [Batch 443/637] [D loss: 0.181617] [G loss: 0.460624]\n",
      "[Epoch 20/200] [Batch 444/637] [D loss: 0.169721] [G loss: 0.506705]\n",
      "[Epoch 20/200] [Batch 445/637] [D loss: 0.161863] [G loss: 0.476716]\n",
      "[Epoch 20/200] [Batch 446/637] [D loss: 0.172554] [G loss: 0.459529]\n",
      "[Epoch 20/200] [Batch 447/637] [D loss: 0.150566] [G loss: 0.552384]\n",
      "[Epoch 20/200] [Batch 448/637] [D loss: 0.192897] [G loss: 0.408835]\n",
      "[Epoch 20/200] [Batch 449/637] [D loss: 0.162135] [G loss: 0.544347]\n",
      "[Epoch 20/200] [Batch 450/637] [D loss: 0.164775] [G loss: 0.504883]\n",
      "[Epoch 20/200] [Batch 451/637] [D loss: 0.173627] [G loss: 0.523820]\n",
      "[Epoch 20/200] [Batch 452/637] [D loss: 0.146026] [G loss: 0.500723]\n",
      "[Epoch 20/200] [Batch 453/637] [D loss: 0.190450] [G loss: 0.518361]\n",
      "[Epoch 20/200] [Batch 454/637] [D loss: 0.179370] [G loss: 0.524570]\n",
      "[Epoch 20/200] [Batch 455/637] [D loss: 0.197532] [G loss: 0.440478]\n",
      "[Epoch 20/200] [Batch 456/637] [D loss: 0.171892] [G loss: 0.523672]\n",
      "[Epoch 20/200] [Batch 457/637] [D loss: 0.189278] [G loss: 0.568838]\n",
      "[Epoch 20/200] [Batch 458/637] [D loss: 0.190394] [G loss: 0.462112]\n",
      "[Epoch 20/200] [Batch 459/637] [D loss: 0.183687] [G loss: 0.371304]\n",
      "[Epoch 20/200] [Batch 460/637] [D loss: 0.182465] [G loss: 0.386825]\n",
      "[Epoch 20/200] [Batch 461/637] [D loss: 0.172659] [G loss: 0.466925]\n",
      "[Epoch 20/200] [Batch 462/637] [D loss: 0.159631] [G loss: 0.480174]\n",
      "[Epoch 20/200] [Batch 463/637] [D loss: 0.183023] [G loss: 0.481595]\n",
      "[Epoch 20/200] [Batch 464/637] [D loss: 0.168620] [G loss: 0.477469]\n",
      "[Epoch 20/200] [Batch 465/637] [D loss: 0.151366] [G loss: 0.515201]\n",
      "[Epoch 20/200] [Batch 466/637] [D loss: 0.175876] [G loss: 0.441464]\n",
      "[Epoch 20/200] [Batch 467/637] [D loss: 0.158594] [G loss: 0.472317]\n",
      "[Epoch 20/200] [Batch 468/637] [D loss: 0.158412] [G loss: 0.476647]\n",
      "[Epoch 20/200] [Batch 469/637] [D loss: 0.189528] [G loss: 0.489916]\n",
      "[Epoch 20/200] [Batch 470/637] [D loss: 0.176076] [G loss: 0.504003]\n",
      "[Epoch 20/200] [Batch 471/637] [D loss: 0.204895] [G loss: 0.472303]\n",
      "[Epoch 20/200] [Batch 472/637] [D loss: 0.183228] [G loss: 0.537563]\n",
      "[Epoch 20/200] [Batch 473/637] [D loss: 0.169665] [G loss: 0.540287]\n",
      "[Epoch 20/200] [Batch 474/637] [D loss: 0.166696] [G loss: 0.488813]\n",
      "[Epoch 20/200] [Batch 475/637] [D loss: 0.163895] [G loss: 0.504205]\n",
      "[Epoch 20/200] [Batch 476/637] [D loss: 0.171565] [G loss: 0.547468]\n",
      "[Epoch 20/200] [Batch 477/637] [D loss: 0.189132] [G loss: 0.540825]\n",
      "[Epoch 20/200] [Batch 478/637] [D loss: 0.166537] [G loss: 0.515110]\n",
      "[Epoch 20/200] [Batch 479/637] [D loss: 0.153763] [G loss: 0.431526]\n",
      "[Epoch 20/200] [Batch 480/637] [D loss: 0.157387] [G loss: 0.557911]\n",
      "[Epoch 20/200] [Batch 481/637] [D loss: 0.161458] [G loss: 0.501010]\n",
      "[Epoch 20/200] [Batch 482/637] [D loss: 0.178934] [G loss: 0.519833]\n",
      "[Epoch 20/200] [Batch 483/637] [D loss: 0.207778] [G loss: 0.547099]\n",
      "[Epoch 20/200] [Batch 484/637] [D loss: 0.147945] [G loss: 0.572755]\n",
      "[Epoch 20/200] [Batch 485/637] [D loss: 0.166877] [G loss: 0.533969]\n",
      "[Epoch 20/200] [Batch 486/637] [D loss: 0.140175] [G loss: 0.567121]\n",
      "[Epoch 20/200] [Batch 487/637] [D loss: 0.159849] [G loss: 0.537564]\n",
      "[Epoch 20/200] [Batch 488/637] [D loss: 0.154221] [G loss: 0.463137]\n",
      "[Epoch 20/200] [Batch 489/637] [D loss: 0.174073] [G loss: 0.529769]\n",
      "[Epoch 20/200] [Batch 490/637] [D loss: 0.146253] [G loss: 0.576346]\n",
      "[Epoch 20/200] [Batch 491/637] [D loss: 0.177305] [G loss: 0.532663]\n",
      "[Epoch 20/200] [Batch 492/637] [D loss: 0.149898] [G loss: 0.539781]\n",
      "[Epoch 20/200] [Batch 493/637] [D loss: 0.168949] [G loss: 0.501627]\n",
      "[Epoch 20/200] [Batch 494/637] [D loss: 0.160375] [G loss: 0.480334]\n",
      "[Epoch 20/200] [Batch 495/637] [D loss: 0.164319] [G loss: 0.480789]\n",
      "[Epoch 20/200] [Batch 496/637] [D loss: 0.150133] [G loss: 0.572209]\n",
      "[Epoch 20/200] [Batch 497/637] [D loss: 0.161174] [G loss: 0.505505]\n",
      "[Epoch 20/200] [Batch 498/637] [D loss: 0.185228] [G loss: 0.399576]\n",
      "[Epoch 20/200] [Batch 499/637] [D loss: 0.153752] [G loss: 0.507222]\n",
      "[Epoch 20/200] [Batch 500/637] [D loss: 0.173256] [G loss: 0.509140]\n",
      "[Epoch 20/200] [Batch 501/637] [D loss: 0.163728] [G loss: 0.551888]\n",
      "[Epoch 20/200] [Batch 502/637] [D loss: 0.156612] [G loss: 0.500186]\n",
      "[Epoch 20/200] [Batch 503/637] [D loss: 0.151887] [G loss: 0.500103]\n",
      "[Epoch 20/200] [Batch 504/637] [D loss: 0.147322] [G loss: 0.513106]\n",
      "[Epoch 20/200] [Batch 505/637] [D loss: 0.176456] [G loss: 0.573403]\n",
      "[Epoch 20/200] [Batch 506/637] [D loss: 0.161413] [G loss: 0.478035]\n",
      "[Epoch 20/200] [Batch 507/637] [D loss: 0.191534] [G loss: 0.483427]\n",
      "[Epoch 20/200] [Batch 508/637] [D loss: 0.181188] [G loss: 0.487005]\n",
      "[Epoch 20/200] [Batch 509/637] [D loss: 0.171005] [G loss: 0.590979]\n",
      "[Epoch 20/200] [Batch 510/637] [D loss: 0.200568] [G loss: 0.505303]\n",
      "[Epoch 20/200] [Batch 511/637] [D loss: 0.174934] [G loss: 0.480818]\n",
      "[Epoch 20/200] [Batch 512/637] [D loss: 0.138486] [G loss: 0.556221]\n",
      "[Epoch 20/200] [Batch 513/637] [D loss: 0.156991] [G loss: 0.554571]\n",
      "[Epoch 20/200] [Batch 514/637] [D loss: 0.167554] [G loss: 0.568408]\n",
      "[Epoch 20/200] [Batch 515/637] [D loss: 0.155707] [G loss: 0.434203]\n",
      "[Epoch 20/200] [Batch 516/637] [D loss: 0.172878] [G loss: 0.408792]\n",
      "[Epoch 20/200] [Batch 517/637] [D loss: 0.159537] [G loss: 0.532639]\n",
      "[Epoch 20/200] [Batch 518/637] [D loss: 0.162385] [G loss: 0.521370]\n",
      "[Epoch 20/200] [Batch 519/637] [D loss: 0.149523] [G loss: 0.448393]\n",
      "[Epoch 20/200] [Batch 520/637] [D loss: 0.149712] [G loss: 0.479388]\n",
      "[Epoch 20/200] [Batch 521/637] [D loss: 0.164704] [G loss: 0.542785]\n",
      "[Epoch 20/200] [Batch 522/637] [D loss: 0.144579] [G loss: 0.579295]\n",
      "[Epoch 20/200] [Batch 523/637] [D loss: 0.168239] [G loss: 0.458738]\n",
      "[Epoch 20/200] [Batch 524/637] [D loss: 0.166489] [G loss: 0.394519]\n",
      "[Epoch 20/200] [Batch 525/637] [D loss: 0.155185] [G loss: 0.434274]\n",
      "[Epoch 20/200] [Batch 526/637] [D loss: 0.148217] [G loss: 0.589631]\n",
      "[Epoch 20/200] [Batch 527/637] [D loss: 0.187443] [G loss: 0.427306]\n",
      "[Epoch 20/200] [Batch 528/637] [D loss: 0.163936] [G loss: 0.470650]\n",
      "[Epoch 20/200] [Batch 529/637] [D loss: 0.160441] [G loss: 0.462667]\n",
      "[Epoch 20/200] [Batch 530/637] [D loss: 0.166508] [G loss: 0.534302]\n",
      "[Epoch 20/200] [Batch 531/637] [D loss: 0.191866] [G loss: 0.424672]\n",
      "[Epoch 20/200] [Batch 532/637] [D loss: 0.196180] [G loss: 0.499793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 533/637] [D loss: 0.192541] [G loss: 0.484947]\n",
      "[Epoch 20/200] [Batch 534/637] [D loss: 0.169981] [G loss: 0.501410]\n",
      "[Epoch 20/200] [Batch 535/637] [D loss: 0.191957] [G loss: 0.401570]\n",
      "[Epoch 20/200] [Batch 536/637] [D loss: 0.155762] [G loss: 0.525764]\n",
      "[Epoch 20/200] [Batch 537/637] [D loss: 0.191448] [G loss: 0.561269]\n",
      "[Epoch 20/200] [Batch 538/637] [D loss: 0.166767] [G loss: 0.474090]\n",
      "[Epoch 20/200] [Batch 539/637] [D loss: 0.188906] [G loss: 0.476177]\n",
      "[Epoch 20/200] [Batch 540/637] [D loss: 0.151216] [G loss: 0.562881]\n",
      "[Epoch 20/200] [Batch 541/637] [D loss: 0.167724] [G loss: 0.492349]\n",
      "[Epoch 20/200] [Batch 542/637] [D loss: 0.159680] [G loss: 0.479729]\n",
      "[Epoch 20/200] [Batch 543/637] [D loss: 0.152803] [G loss: 0.504260]\n",
      "[Epoch 20/200] [Batch 544/637] [D loss: 0.144565] [G loss: 0.508015]\n",
      "[Epoch 20/200] [Batch 545/637] [D loss: 0.152832] [G loss: 0.504770]\n",
      "[Epoch 20/200] [Batch 546/637] [D loss: 0.154399] [G loss: 0.455733]\n",
      "[Epoch 20/200] [Batch 547/637] [D loss: 0.168370] [G loss: 0.475392]\n",
      "[Epoch 20/200] [Batch 548/637] [D loss: 0.144710] [G loss: 0.502993]\n",
      "[Epoch 20/200] [Batch 549/637] [D loss: 0.152107] [G loss: 0.500178]\n",
      "[Epoch 20/200] [Batch 550/637] [D loss: 0.138348] [G loss: 0.530848]\n",
      "[Epoch 20/200] [Batch 551/637] [D loss: 0.149752] [G loss: 0.510688]\n",
      "[Epoch 20/200] [Batch 552/637] [D loss: 0.164416] [G loss: 0.547123]\n",
      "[Epoch 20/200] [Batch 553/637] [D loss: 0.157282] [G loss: 0.474922]\n",
      "[Epoch 20/200] [Batch 554/637] [D loss: 0.152031] [G loss: 0.485436]\n",
      "[Epoch 20/200] [Batch 555/637] [D loss: 0.151607] [G loss: 0.499197]\n",
      "[Epoch 20/200] [Batch 556/637] [D loss: 0.167153] [G loss: 0.477472]\n",
      "[Epoch 20/200] [Batch 557/637] [D loss: 0.175533] [G loss: 0.466897]\n",
      "[Epoch 20/200] [Batch 558/637] [D loss: 0.177849] [G loss: 0.467703]\n",
      "[Epoch 20/200] [Batch 559/637] [D loss: 0.147970] [G loss: 0.604387]\n",
      "[Epoch 20/200] [Batch 560/637] [D loss: 0.170961] [G loss: 0.488792]\n",
      "[Epoch 20/200] [Batch 561/637] [D loss: 0.159159] [G loss: 0.493346]\n",
      "[Epoch 20/200] [Batch 562/637] [D loss: 0.154235] [G loss: 0.523510]\n",
      "[Epoch 20/200] [Batch 563/637] [D loss: 0.153029] [G loss: 0.538771]\n",
      "[Epoch 20/200] [Batch 564/637] [D loss: 0.166052] [G loss: 0.440712]\n",
      "[Epoch 20/200] [Batch 565/637] [D loss: 0.157683] [G loss: 0.556974]\n",
      "[Epoch 20/200] [Batch 566/637] [D loss: 0.147606] [G loss: 0.481006]\n",
      "[Epoch 20/200] [Batch 567/637] [D loss: 0.168096] [G loss: 0.465543]\n",
      "[Epoch 20/200] [Batch 568/637] [D loss: 0.158878] [G loss: 0.488217]\n",
      "[Epoch 20/200] [Batch 569/637] [D loss: 0.164564] [G loss: 0.579988]\n",
      "[Epoch 20/200] [Batch 570/637] [D loss: 0.165314] [G loss: 0.439500]\n",
      "[Epoch 20/200] [Batch 571/637] [D loss: 0.156225] [G loss: 0.495494]\n",
      "[Epoch 20/200] [Batch 572/637] [D loss: 0.135350] [G loss: 0.646336]\n",
      "[Epoch 20/200] [Batch 573/637] [D loss: 0.159624] [G loss: 0.510781]\n",
      "[Epoch 20/200] [Batch 574/637] [D loss: 0.138673] [G loss: 0.557262]\n",
      "[Epoch 20/200] [Batch 575/637] [D loss: 0.146265] [G loss: 0.534267]\n",
      "[Epoch 20/200] [Batch 576/637] [D loss: 0.153089] [G loss: 0.537351]\n",
      "[Epoch 20/200] [Batch 577/637] [D loss: 0.133100] [G loss: 0.568243]\n",
      "[Epoch 20/200] [Batch 578/637] [D loss: 0.141257] [G loss: 0.512898]\n",
      "[Epoch 20/200] [Batch 579/637] [D loss: 0.156706] [G loss: 0.518746]\n",
      "[Epoch 20/200] [Batch 580/637] [D loss: 0.163275] [G loss: 0.555604]\n",
      "[Epoch 20/200] [Batch 581/637] [D loss: 0.150154] [G loss: 0.433706]\n",
      "[Epoch 20/200] [Batch 582/637] [D loss: 0.147852] [G loss: 0.562237]\n",
      "[Epoch 20/200] [Batch 583/637] [D loss: 0.153340] [G loss: 0.526809]\n",
      "[Epoch 20/200] [Batch 584/637] [D loss: 0.167548] [G loss: 0.498946]\n",
      "[Epoch 20/200] [Batch 585/637] [D loss: 0.178394] [G loss: 0.488252]\n",
      "[Epoch 20/200] [Batch 586/637] [D loss: 0.173936] [G loss: 0.500333]\n",
      "[Epoch 20/200] [Batch 587/637] [D loss: 0.189410] [G loss: 0.572588]\n",
      "[Epoch 20/200] [Batch 588/637] [D loss: 0.162869] [G loss: 0.595021]\n",
      "[Epoch 20/200] [Batch 589/637] [D loss: 0.151469] [G loss: 0.476399]\n",
      "[Epoch 20/200] [Batch 590/637] [D loss: 0.182798] [G loss: 0.493955]\n",
      "[Epoch 20/200] [Batch 591/637] [D loss: 0.170432] [G loss: 0.494348]\n",
      "[Epoch 20/200] [Batch 592/637] [D loss: 0.170036] [G loss: 0.478861]\n",
      "[Epoch 20/200] [Batch 593/637] [D loss: 0.166629] [G loss: 0.531054]\n",
      "[Epoch 20/200] [Batch 594/637] [D loss: 0.165563] [G loss: 0.461667]\n",
      "[Epoch 20/200] [Batch 595/637] [D loss: 0.159453] [G loss: 0.497054]\n",
      "[Epoch 20/200] [Batch 596/637] [D loss: 0.164723] [G loss: 0.467224]\n",
      "[Epoch 20/200] [Batch 597/637] [D loss: 0.194868] [G loss: 0.380845]\n",
      "[Epoch 20/200] [Batch 598/637] [D loss: 0.163399] [G loss: 0.632188]\n",
      "[Epoch 20/200] [Batch 599/637] [D loss: 0.152731] [G loss: 0.604932]\n",
      "[Epoch 20/200] [Batch 600/637] [D loss: 0.149042] [G loss: 0.571701]\n",
      "[Epoch 20/200] [Batch 601/637] [D loss: 0.178799] [G loss: 0.442470]\n",
      "[Epoch 20/200] [Batch 602/637] [D loss: 0.157648] [G loss: 0.533529]\n",
      "[Epoch 20/200] [Batch 603/637] [D loss: 0.175567] [G loss: 0.506445]\n",
      "[Epoch 20/200] [Batch 604/637] [D loss: 0.147117] [G loss: 0.515535]\n",
      "[Epoch 20/200] [Batch 605/637] [D loss: 0.147826] [G loss: 0.549056]\n",
      "[Epoch 20/200] [Batch 606/637] [D loss: 0.179188] [G loss: 0.489694]\n",
      "[Epoch 20/200] [Batch 607/637] [D loss: 0.143697] [G loss: 0.632389]\n",
      "[Epoch 20/200] [Batch 608/637] [D loss: 0.201865] [G loss: 0.413539]\n",
      "[Epoch 20/200] [Batch 609/637] [D loss: 0.205896] [G loss: 0.711475]\n",
      "[Epoch 20/200] [Batch 610/637] [D loss: 0.196651] [G loss: 0.540697]\n",
      "[Epoch 20/200] [Batch 611/637] [D loss: 0.195626] [G loss: 0.467077]\n",
      "[Epoch 20/200] [Batch 612/637] [D loss: 0.174856] [G loss: 0.473656]\n",
      "[Epoch 20/200] [Batch 613/637] [D loss: 0.170125] [G loss: 0.425440]\n",
      "[Epoch 20/200] [Batch 614/637] [D loss: 0.161869] [G loss: 0.444965]\n",
      "[Epoch 20/200] [Batch 615/637] [D loss: 0.176034] [G loss: 0.446276]\n",
      "[Epoch 20/200] [Batch 616/637] [D loss: 0.169562] [G loss: 0.470519]\n",
      "[Epoch 20/200] [Batch 617/637] [D loss: 0.134085] [G loss: 0.617805]\n",
      "[Epoch 20/200] [Batch 618/637] [D loss: 0.144443] [G loss: 0.549209]\n",
      "[Epoch 20/200] [Batch 619/637] [D loss: 0.157056] [G loss: 0.524647]\n",
      "[Epoch 20/200] [Batch 620/637] [D loss: 0.142385] [G loss: 0.467987]\n",
      "[Epoch 20/200] [Batch 621/637] [D loss: 0.151224] [G loss: 0.511741]\n",
      "[Epoch 20/200] [Batch 622/637] [D loss: 0.163558] [G loss: 0.500553]\n",
      "[Epoch 20/200] [Batch 623/637] [D loss: 0.152647] [G loss: 0.517812]\n",
      "[Epoch 20/200] [Batch 624/637] [D loss: 0.150086] [G loss: 0.503241]\n",
      "[Epoch 20/200] [Batch 625/637] [D loss: 0.168803] [G loss: 0.464665]\n",
      "[Epoch 20/200] [Batch 626/637] [D loss: 0.160008] [G loss: 0.542251]\n",
      "[Epoch 20/200] [Batch 627/637] [D loss: 0.184939] [G loss: 0.526827]\n",
      "[Epoch 20/200] [Batch 628/637] [D loss: 0.204503] [G loss: 0.478473]\n",
      "[Epoch 20/200] [Batch 629/637] [D loss: 0.160249] [G loss: 0.452407]\n",
      "[Epoch 20/200] [Batch 630/637] [D loss: 0.160163] [G loss: 0.458901]\n",
      "[Epoch 20/200] [Batch 631/637] [D loss: 0.126299] [G loss: 0.469663]\n",
      "[Epoch 20/200] [Batch 632/637] [D loss: 0.138404] [G loss: 0.493265]\n",
      "[Epoch 20/200] [Batch 633/637] [D loss: 0.169423] [G loss: 0.461365]\n",
      "[Epoch 20/200] [Batch 634/637] [D loss: 0.160069] [G loss: 0.479913]\n",
      "[Epoch 20/200] [Batch 635/637] [D loss: 0.155399] [G loss: 0.524474]\n",
      "[Epoch 20/200] [Batch 636/637] [D loss: 0.200052] [G loss: 0.381676]\n",
      "[Epoch 21/200] [Batch 0/637] [D loss: 0.245018] [G loss: 0.721068]\n",
      "[Epoch 21/200] [Batch 1/637] [D loss: 0.213281] [G loss: 0.595965]\n",
      "[Epoch 21/200] [Batch 2/637] [D loss: 0.182947] [G loss: 0.469547]\n",
      "[Epoch 21/200] [Batch 3/637] [D loss: 0.162039] [G loss: 0.493249]\n",
      "[Epoch 21/200] [Batch 4/637] [D loss: 0.170060] [G loss: 0.468068]\n",
      "[Epoch 21/200] [Batch 5/637] [D loss: 0.144359] [G loss: 0.496780]\n",
      "[Epoch 21/200] [Batch 6/637] [D loss: 0.184313] [G loss: 0.460673]\n",
      "[Epoch 21/200] [Batch 7/637] [D loss: 0.157904] [G loss: 0.547992]\n",
      "[Epoch 21/200] [Batch 8/637] [D loss: 0.169911] [G loss: 0.540519]\n",
      "[Epoch 21/200] [Batch 9/637] [D loss: 0.142808] [G loss: 0.547257]\n",
      "[Epoch 21/200] [Batch 10/637] [D loss: 0.179808] [G loss: 0.529741]\n",
      "[Epoch 21/200] [Batch 11/637] [D loss: 0.159042] [G loss: 0.473633]\n",
      "[Epoch 21/200] [Batch 12/637] [D loss: 0.160270] [G loss: 0.500343]\n",
      "[Epoch 21/200] [Batch 13/637] [D loss: 0.151062] [G loss: 0.452511]\n",
      "[Epoch 21/200] [Batch 14/637] [D loss: 0.136905] [G loss: 0.537654]\n",
      "[Epoch 21/200] [Batch 15/637] [D loss: 0.158811] [G loss: 0.503763]\n",
      "[Epoch 21/200] [Batch 16/637] [D loss: 0.168855] [G loss: 0.535567]\n",
      "[Epoch 21/200] [Batch 17/637] [D loss: 0.162824] [G loss: 0.545920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 18/637] [D loss: 0.153352] [G loss: 0.553220]\n",
      "[Epoch 21/200] [Batch 19/637] [D loss: 0.157616] [G loss: 0.489267]\n",
      "[Epoch 21/200] [Batch 20/637] [D loss: 0.160864] [G loss: 0.434051]\n",
      "[Epoch 21/200] [Batch 21/637] [D loss: 0.177243] [G loss: 0.415853]\n",
      "[Epoch 21/200] [Batch 22/637] [D loss: 0.161852] [G loss: 0.460453]\n",
      "[Epoch 21/200] [Batch 23/637] [D loss: 0.146677] [G loss: 0.505848]\n",
      "[Epoch 21/200] [Batch 24/637] [D loss: 0.167013] [G loss: 0.441351]\n",
      "[Epoch 21/200] [Batch 25/637] [D loss: 0.168040] [G loss: 0.445164]\n",
      "[Epoch 21/200] [Batch 26/637] [D loss: 0.155011] [G loss: 0.523013]\n",
      "[Epoch 21/200] [Batch 27/637] [D loss: 0.162429] [G loss: 0.515169]\n",
      "[Epoch 21/200] [Batch 28/637] [D loss: 0.158335] [G loss: 0.448484]\n",
      "[Epoch 21/200] [Batch 29/637] [D loss: 0.154963] [G loss: 0.504502]\n",
      "[Epoch 21/200] [Batch 30/637] [D loss: 0.167451] [G loss: 0.463170]\n",
      "[Epoch 21/200] [Batch 31/637] [D loss: 0.145983] [G loss: 0.485564]\n",
      "[Epoch 21/200] [Batch 32/637] [D loss: 0.157028] [G loss: 0.540819]\n",
      "[Epoch 21/200] [Batch 33/637] [D loss: 0.147271] [G loss: 0.607874]\n",
      "[Epoch 21/200] [Batch 34/637] [D loss: 0.149130] [G loss: 0.540870]\n",
      "[Epoch 21/200] [Batch 35/637] [D loss: 0.166005] [G loss: 0.511350]\n",
      "[Epoch 21/200] [Batch 36/637] [D loss: 0.155111] [G loss: 0.527931]\n",
      "[Epoch 21/200] [Batch 37/637] [D loss: 0.168160] [G loss: 0.511172]\n",
      "[Epoch 21/200] [Batch 38/637] [D loss: 0.161128] [G loss: 0.571905]\n",
      "[Epoch 21/200] [Batch 39/637] [D loss: 0.177032] [G loss: 0.490595]\n",
      "[Epoch 21/200] [Batch 40/637] [D loss: 0.167650] [G loss: 0.441427]\n",
      "[Epoch 21/200] [Batch 41/637] [D loss: 0.194756] [G loss: 0.411437]\n",
      "[Epoch 21/200] [Batch 42/637] [D loss: 0.147757] [G loss: 0.503798]\n",
      "[Epoch 21/200] [Batch 43/637] [D loss: 0.198361] [G loss: 0.475458]\n",
      "[Epoch 21/200] [Batch 44/637] [D loss: 0.165192] [G loss: 0.619386]\n",
      "[Epoch 21/200] [Batch 45/637] [D loss: 0.160301] [G loss: 0.516968]\n",
      "[Epoch 21/200] [Batch 46/637] [D loss: 0.186828] [G loss: 0.413536]\n",
      "[Epoch 21/200] [Batch 47/637] [D loss: 0.165047] [G loss: 0.477932]\n",
      "[Epoch 21/200] [Batch 48/637] [D loss: 0.177005] [G loss: 0.518086]\n",
      "[Epoch 21/200] [Batch 49/637] [D loss: 0.209426] [G loss: 0.422086]\n",
      "[Epoch 21/200] [Batch 50/637] [D loss: 0.166112] [G loss: 0.534691]\n",
      "[Epoch 21/200] [Batch 51/637] [D loss: 0.163710] [G loss: 0.496452]\n",
      "[Epoch 21/200] [Batch 52/637] [D loss: 0.183566] [G loss: 0.430997]\n",
      "[Epoch 21/200] [Batch 53/637] [D loss: 0.163872] [G loss: 0.533319]\n",
      "[Epoch 21/200] [Batch 54/637] [D loss: 0.177948] [G loss: 0.483930]\n",
      "[Epoch 21/200] [Batch 55/637] [D loss: 0.183436] [G loss: 0.535344]\n",
      "[Epoch 21/200] [Batch 56/637] [D loss: 0.164802] [G loss: 0.452703]\n",
      "[Epoch 21/200] [Batch 57/637] [D loss: 0.174869] [G loss: 0.453844]\n",
      "[Epoch 21/200] [Batch 58/637] [D loss: 0.143051] [G loss: 0.504103]\n",
      "[Epoch 21/200] [Batch 59/637] [D loss: 0.138830] [G loss: 0.517158]\n",
      "[Epoch 21/200] [Batch 60/637] [D loss: 0.142888] [G loss: 0.501948]\n",
      "[Epoch 21/200] [Batch 61/637] [D loss: 0.144319] [G loss: 0.561198]\n",
      "[Epoch 21/200] [Batch 62/637] [D loss: 0.179123] [G loss: 0.500038]\n",
      "[Epoch 21/200] [Batch 63/637] [D loss: 0.193321] [G loss: 0.508020]\n",
      "[Epoch 21/200] [Batch 64/637] [D loss: 0.165495] [G loss: 0.564079]\n",
      "[Epoch 21/200] [Batch 65/637] [D loss: 0.171459] [G loss: 0.509408]\n",
      "[Epoch 21/200] [Batch 66/637] [D loss: 0.157632] [G loss: 0.448270]\n",
      "[Epoch 21/200] [Batch 67/637] [D loss: 0.161634] [G loss: 0.410793]\n",
      "[Epoch 21/200] [Batch 68/637] [D loss: 0.176545] [G loss: 0.434099]\n",
      "[Epoch 21/200] [Batch 69/637] [D loss: 0.155293] [G loss: 0.546731]\n",
      "[Epoch 21/200] [Batch 70/637] [D loss: 0.153599] [G loss: 0.563877]\n",
      "[Epoch 21/200] [Batch 71/637] [D loss: 0.153187] [G loss: 0.483642]\n",
      "[Epoch 21/200] [Batch 72/637] [D loss: 0.153355] [G loss: 0.476341]\n",
      "[Epoch 21/200] [Batch 73/637] [D loss: 0.187154] [G loss: 0.473764]\n",
      "[Epoch 21/200] [Batch 74/637] [D loss: 0.160229] [G loss: 0.423705]\n",
      "[Epoch 21/200] [Batch 75/637] [D loss: 0.151297] [G loss: 0.465283]\n",
      "[Epoch 21/200] [Batch 76/637] [D loss: 0.142666] [G loss: 0.508277]\n",
      "[Epoch 21/200] [Batch 77/637] [D loss: 0.172578] [G loss: 0.463272]\n",
      "[Epoch 21/200] [Batch 78/637] [D loss: 0.153111] [G loss: 0.561423]\n",
      "[Epoch 21/200] [Batch 79/637] [D loss: 0.143462] [G loss: 0.538209]\n",
      "[Epoch 21/200] [Batch 80/637] [D loss: 0.177779] [G loss: 0.469344]\n",
      "[Epoch 21/200] [Batch 81/637] [D loss: 0.171219] [G loss: 0.446748]\n",
      "[Epoch 21/200] [Batch 82/637] [D loss: 0.153088] [G loss: 0.545525]\n",
      "[Epoch 21/200] [Batch 83/637] [D loss: 0.150406] [G loss: 0.522384]\n",
      "[Epoch 21/200] [Batch 84/637] [D loss: 0.172974] [G loss: 0.486504]\n",
      "[Epoch 21/200] [Batch 85/637] [D loss: 0.151643] [G loss: 0.497077]\n",
      "[Epoch 21/200] [Batch 86/637] [D loss: 0.151098] [G loss: 0.503855]\n",
      "[Epoch 21/200] [Batch 87/637] [D loss: 0.167896] [G loss: 0.502504]\n",
      "[Epoch 21/200] [Batch 88/637] [D loss: 0.158457] [G loss: 0.485998]\n",
      "[Epoch 21/200] [Batch 89/637] [D loss: 0.161499] [G loss: 0.517239]\n",
      "[Epoch 21/200] [Batch 90/637] [D loss: 0.179153] [G loss: 0.539821]\n",
      "[Epoch 21/200] [Batch 91/637] [D loss: 0.148656] [G loss: 0.520302]\n",
      "[Epoch 21/200] [Batch 92/637] [D loss: 0.200411] [G loss: 0.414174]\n",
      "[Epoch 21/200] [Batch 93/637] [D loss: 0.187929] [G loss: 0.515837]\n",
      "[Epoch 21/200] [Batch 94/637] [D loss: 0.145306] [G loss: 0.555832]\n",
      "[Epoch 21/200] [Batch 95/637] [D loss: 0.178031] [G loss: 0.497037]\n",
      "[Epoch 21/200] [Batch 96/637] [D loss: 0.138199] [G loss: 0.511754]\n",
      "[Epoch 21/200] [Batch 97/637] [D loss: 0.139657] [G loss: 0.491830]\n",
      "[Epoch 21/200] [Batch 98/637] [D loss: 0.160561] [G loss: 0.465521]\n",
      "[Epoch 21/200] [Batch 99/637] [D loss: 0.129741] [G loss: 0.550236]\n",
      "[Epoch 21/200] [Batch 100/637] [D loss: 0.167294] [G loss: 0.450575]\n",
      "[Epoch 21/200] [Batch 101/637] [D loss: 0.148378] [G loss: 0.543509]\n",
      "[Epoch 21/200] [Batch 102/637] [D loss: 0.147577] [G loss: 0.585848]\n",
      "[Epoch 21/200] [Batch 103/637] [D loss: 0.139155] [G loss: 0.521364]\n",
      "[Epoch 21/200] [Batch 104/637] [D loss: 0.166855] [G loss: 0.476415]\n",
      "[Epoch 21/200] [Batch 105/637] [D loss: 0.139979] [G loss: 0.580352]\n",
      "[Epoch 21/200] [Batch 106/637] [D loss: 0.163660] [G loss: 0.522667]\n",
      "[Epoch 21/200] [Batch 107/637] [D loss: 0.137777] [G loss: 0.502707]\n",
      "[Epoch 21/200] [Batch 108/637] [D loss: 0.163157] [G loss: 0.464379]\n",
      "[Epoch 21/200] [Batch 109/637] [D loss: 0.159019] [G loss: 0.473668]\n",
      "[Epoch 21/200] [Batch 110/637] [D loss: 0.171623] [G loss: 0.400711]\n",
      "[Epoch 21/200] [Batch 111/637] [D loss: 0.142858] [G loss: 0.496526]\n",
      "[Epoch 21/200] [Batch 112/637] [D loss: 0.176890] [G loss: 0.532127]\n",
      "[Epoch 21/200] [Batch 113/637] [D loss: 0.141290] [G loss: 0.531755]\n",
      "[Epoch 21/200] [Batch 114/637] [D loss: 0.166119] [G loss: 0.531209]\n",
      "[Epoch 21/200] [Batch 115/637] [D loss: 0.155798] [G loss: 0.485450]\n",
      "[Epoch 21/200] [Batch 116/637] [D loss: 0.164219] [G loss: 0.451121]\n",
      "[Epoch 21/200] [Batch 117/637] [D loss: 0.146480] [G loss: 0.479193]\n",
      "[Epoch 21/200] [Batch 118/637] [D loss: 0.195617] [G loss: 0.444834]\n",
      "[Epoch 21/200] [Batch 119/637] [D loss: 0.159560] [G loss: 0.566222]\n",
      "[Epoch 21/200] [Batch 120/637] [D loss: 0.171415] [G loss: 0.577433]\n",
      "[Epoch 21/200] [Batch 121/637] [D loss: 0.148639] [G loss: 0.490158]\n",
      "[Epoch 21/200] [Batch 122/637] [D loss: 0.141923] [G loss: 0.500130]\n",
      "[Epoch 21/200] [Batch 123/637] [D loss: 0.176530] [G loss: 0.441480]\n",
      "[Epoch 21/200] [Batch 124/637] [D loss: 0.164202] [G loss: 0.534747]\n",
      "[Epoch 21/200] [Batch 125/637] [D loss: 0.146619] [G loss: 0.530213]\n",
      "[Epoch 21/200] [Batch 126/637] [D loss: 0.155910] [G loss: 0.520709]\n",
      "[Epoch 21/200] [Batch 127/637] [D loss: 0.142721] [G loss: 0.480896]\n",
      "[Epoch 21/200] [Batch 128/637] [D loss: 0.147629] [G loss: 0.494391]\n",
      "[Epoch 21/200] [Batch 129/637] [D loss: 0.147916] [G loss: 0.512260]\n",
      "[Epoch 21/200] [Batch 130/637] [D loss: 0.183757] [G loss: 0.494510]\n",
      "[Epoch 21/200] [Batch 131/637] [D loss: 0.170665] [G loss: 0.550855]\n",
      "[Epoch 21/200] [Batch 132/637] [D loss: 0.158858] [G loss: 0.573301]\n",
      "[Epoch 21/200] [Batch 133/637] [D loss: 0.149530] [G loss: 0.545341]\n",
      "[Epoch 21/200] [Batch 134/637] [D loss: 0.153061] [G loss: 0.507828]\n",
      "[Epoch 21/200] [Batch 135/637] [D loss: 0.152640] [G loss: 0.475175]\n",
      "[Epoch 21/200] [Batch 136/637] [D loss: 0.157193] [G loss: 0.497948]\n",
      "[Epoch 21/200] [Batch 137/637] [D loss: 0.150749] [G loss: 0.508713]\n",
      "[Epoch 21/200] [Batch 138/637] [D loss: 0.162679] [G loss: 0.493514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 139/637] [D loss: 0.182324] [G loss: 0.570385]\n",
      "[Epoch 21/200] [Batch 140/637] [D loss: 0.180592] [G loss: 0.533173]\n",
      "[Epoch 21/200] [Batch 141/637] [D loss: 0.153210] [G loss: 0.534759]\n",
      "[Epoch 21/200] [Batch 142/637] [D loss: 0.165386] [G loss: 0.537276]\n",
      "[Epoch 21/200] [Batch 143/637] [D loss: 0.167754] [G loss: 0.542975]\n",
      "[Epoch 21/200] [Batch 144/637] [D loss: 0.167586] [G loss: 0.597158]\n",
      "[Epoch 21/200] [Batch 145/637] [D loss: 0.180789] [G loss: 0.496202]\n",
      "[Epoch 21/200] [Batch 146/637] [D loss: 0.147980] [G loss: 0.500100]\n",
      "[Epoch 21/200] [Batch 147/637] [D loss: 0.175135] [G loss: 0.434025]\n",
      "[Epoch 21/200] [Batch 148/637] [D loss: 0.169221] [G loss: 0.508928]\n",
      "[Epoch 21/200] [Batch 149/637] [D loss: 0.196267] [G loss: 0.394254]\n",
      "[Epoch 21/200] [Batch 150/637] [D loss: 0.155569] [G loss: 0.525347]\n",
      "[Epoch 21/200] [Batch 151/637] [D loss: 0.172874] [G loss: 0.523683]\n",
      "[Epoch 21/200] [Batch 152/637] [D loss: 0.182173] [G loss: 0.482747]\n",
      "[Epoch 21/200] [Batch 153/637] [D loss: 0.173140] [G loss: 0.533909]\n",
      "[Epoch 21/200] [Batch 154/637] [D loss: 0.173272] [G loss: 0.529507]\n",
      "[Epoch 21/200] [Batch 155/637] [D loss: 0.152442] [G loss: 0.566506]\n",
      "[Epoch 21/200] [Batch 156/637] [D loss: 0.167106] [G loss: 0.560038]\n",
      "[Epoch 21/200] [Batch 157/637] [D loss: 0.170976] [G loss: 0.483928]\n",
      "[Epoch 21/200] [Batch 158/637] [D loss: 0.142743] [G loss: 0.538734]\n",
      "[Epoch 21/200] [Batch 159/637] [D loss: 0.145064] [G loss: 0.549202]\n",
      "[Epoch 21/200] [Batch 160/637] [D loss: 0.138654] [G loss: 0.536746]\n",
      "[Epoch 21/200] [Batch 161/637] [D loss: 0.166030] [G loss: 0.476981]\n",
      "[Epoch 21/200] [Batch 162/637] [D loss: 0.141280] [G loss: 0.549328]\n",
      "[Epoch 21/200] [Batch 163/637] [D loss: 0.159401] [G loss: 0.539771]\n",
      "[Epoch 21/200] [Batch 164/637] [D loss: 0.165531] [G loss: 0.558529]\n",
      "[Epoch 21/200] [Batch 165/637] [D loss: 0.177526] [G loss: 0.474367]\n",
      "[Epoch 21/200] [Batch 166/637] [D loss: 0.190178] [G loss: 0.540931]\n",
      "[Epoch 21/200] [Batch 167/637] [D loss: 0.162846] [G loss: 0.505891]\n",
      "[Epoch 21/200] [Batch 168/637] [D loss: 0.176291] [G loss: 0.446130]\n",
      "[Epoch 21/200] [Batch 169/637] [D loss: 0.177481] [G loss: 0.465092]\n",
      "[Epoch 21/200] [Batch 170/637] [D loss: 0.174212] [G loss: 0.512663]\n",
      "[Epoch 21/200] [Batch 171/637] [D loss: 0.163677] [G loss: 0.591724]\n",
      "[Epoch 21/200] [Batch 172/637] [D loss: 0.164091] [G loss: 0.442841]\n",
      "[Epoch 21/200] [Batch 173/637] [D loss: 0.164109] [G loss: 0.521602]\n",
      "[Epoch 21/200] [Batch 174/637] [D loss: 0.172704] [G loss: 0.525925]\n",
      "[Epoch 21/200] [Batch 175/637] [D loss: 0.166482] [G loss: 0.491989]\n",
      "[Epoch 21/200] [Batch 176/637] [D loss: 0.170251] [G loss: 0.551073]\n",
      "[Epoch 21/200] [Batch 177/637] [D loss: 0.217811] [G loss: 0.526490]\n",
      "[Epoch 21/200] [Batch 178/637] [D loss: 0.196963] [G loss: 0.492891]\n",
      "[Epoch 21/200] [Batch 179/637] [D loss: 0.203254] [G loss: 0.656338]\n",
      "[Epoch 21/200] [Batch 180/637] [D loss: 0.175204] [G loss: 0.600816]\n",
      "[Epoch 21/200] [Batch 181/637] [D loss: 0.177801] [G loss: 0.532005]\n",
      "[Epoch 21/200] [Batch 182/637] [D loss: 0.200805] [G loss: 0.500231]\n",
      "[Epoch 21/200] [Batch 183/637] [D loss: 0.197425] [G loss: 0.483826]\n",
      "[Epoch 21/200] [Batch 184/637] [D loss: 0.166166] [G loss: 0.469641]\n",
      "[Epoch 21/200] [Batch 185/637] [D loss: 0.181046] [G loss: 0.419105]\n",
      "[Epoch 21/200] [Batch 186/637] [D loss: 0.181828] [G loss: 0.431951]\n",
      "[Epoch 21/200] [Batch 187/637] [D loss: 0.167658] [G loss: 0.591861]\n",
      "[Epoch 21/200] [Batch 188/637] [D loss: 0.188539] [G loss: 0.492649]\n",
      "[Epoch 21/200] [Batch 189/637] [D loss: 0.179770] [G loss: 0.482785]\n",
      "[Epoch 21/200] [Batch 190/637] [D loss: 0.180669] [G loss: 0.538478]\n",
      "[Epoch 21/200] [Batch 191/637] [D loss: 0.158928] [G loss: 0.529476]\n",
      "[Epoch 21/200] [Batch 192/637] [D loss: 0.171883] [G loss: 0.488522]\n",
      "[Epoch 21/200] [Batch 193/637] [D loss: 0.182287] [G loss: 0.448875]\n",
      "[Epoch 21/200] [Batch 194/637] [D loss: 0.163299] [G loss: 0.560171]\n",
      "[Epoch 21/200] [Batch 195/637] [D loss: 0.163383] [G loss: 0.517289]\n",
      "[Epoch 21/200] [Batch 196/637] [D loss: 0.174750] [G loss: 0.522950]\n",
      "[Epoch 21/200] [Batch 197/637] [D loss: 0.158585] [G loss: 0.528154]\n",
      "[Epoch 21/200] [Batch 198/637] [D loss: 0.193522] [G loss: 0.432269]\n",
      "[Epoch 21/200] [Batch 199/637] [D loss: 0.174624] [G loss: 0.506816]\n",
      "[Epoch 21/200] [Batch 200/637] [D loss: 0.158698] [G loss: 0.515610]\n",
      "[Epoch 21/200] [Batch 201/637] [D loss: 0.159354] [G loss: 0.466357]\n",
      "[Epoch 21/200] [Batch 202/637] [D loss: 0.170387] [G loss: 0.450340]\n",
      "[Epoch 21/200] [Batch 203/637] [D loss: 0.161387] [G loss: 0.511721]\n",
      "[Epoch 21/200] [Batch 204/637] [D loss: 0.167714] [G loss: 0.513961]\n",
      "[Epoch 21/200] [Batch 205/637] [D loss: 0.185723] [G loss: 0.476113]\n",
      "[Epoch 21/200] [Batch 206/637] [D loss: 0.166248] [G loss: 0.457818]\n",
      "[Epoch 21/200] [Batch 207/637] [D loss: 0.179800] [G loss: 0.449147]\n",
      "[Epoch 21/200] [Batch 208/637] [D loss: 0.160791] [G loss: 0.555986]\n",
      "[Epoch 21/200] [Batch 209/637] [D loss: 0.162933] [G loss: 0.509490]\n",
      "[Epoch 21/200] [Batch 210/637] [D loss: 0.154388] [G loss: 0.543296]\n",
      "[Epoch 21/200] [Batch 211/637] [D loss: 0.144468] [G loss: 0.499398]\n",
      "[Epoch 21/200] [Batch 212/637] [D loss: 0.173389] [G loss: 0.491531]\n",
      "[Epoch 21/200] [Batch 213/637] [D loss: 0.158112] [G loss: 0.564131]\n",
      "[Epoch 21/200] [Batch 214/637] [D loss: 0.159802] [G loss: 0.488426]\n",
      "[Epoch 21/200] [Batch 215/637] [D loss: 0.193209] [G loss: 0.455027]\n",
      "[Epoch 21/200] [Batch 216/637] [D loss: 0.150093] [G loss: 0.531860]\n",
      "[Epoch 21/200] [Batch 217/637] [D loss: 0.150821] [G loss: 0.556635]\n",
      "[Epoch 21/200] [Batch 218/637] [D loss: 0.155649] [G loss: 0.479240]\n",
      "[Epoch 21/200] [Batch 219/637] [D loss: 0.209394] [G loss: 0.370999]\n",
      "[Epoch 21/200] [Batch 220/637] [D loss: 0.180593] [G loss: 0.551434]\n",
      "[Epoch 21/200] [Batch 221/637] [D loss: 0.179226] [G loss: 0.472098]\n",
      "[Epoch 21/200] [Batch 222/637] [D loss: 0.173456] [G loss: 0.442335]\n",
      "[Epoch 21/200] [Batch 223/637] [D loss: 0.184884] [G loss: 0.434273]\n",
      "[Epoch 21/200] [Batch 224/637] [D loss: 0.148574] [G loss: 0.545750]\n",
      "[Epoch 21/200] [Batch 225/637] [D loss: 0.156955] [G loss: 0.544884]\n",
      "[Epoch 21/200] [Batch 226/637] [D loss: 0.169485] [G loss: 0.485062]\n",
      "[Epoch 21/200] [Batch 227/637] [D loss: 0.163498] [G loss: 0.513217]\n",
      "[Epoch 21/200] [Batch 228/637] [D loss: 0.167333] [G loss: 0.552520]\n",
      "[Epoch 21/200] [Batch 229/637] [D loss: 0.153585] [G loss: 0.490829]\n",
      "[Epoch 21/200] [Batch 230/637] [D loss: 0.168133] [G loss: 0.497072]\n",
      "[Epoch 21/200] [Batch 231/637] [D loss: 0.155208] [G loss: 0.527748]\n",
      "[Epoch 21/200] [Batch 232/637] [D loss: 0.161823] [G loss: 0.510811]\n",
      "[Epoch 21/200] [Batch 233/637] [D loss: 0.166321] [G loss: 0.499231]\n",
      "[Epoch 21/200] [Batch 234/637] [D loss: 0.177594] [G loss: 0.450128]\n",
      "[Epoch 21/200] [Batch 235/637] [D loss: 0.164169] [G loss: 0.509800]\n",
      "[Epoch 21/200] [Batch 236/637] [D loss: 0.202215] [G loss: 0.471582]\n",
      "[Epoch 21/200] [Batch 237/637] [D loss: 0.204991] [G loss: 0.511738]\n",
      "[Epoch 21/200] [Batch 238/637] [D loss: 0.175107] [G loss: 0.535211]\n",
      "[Epoch 21/200] [Batch 239/637] [D loss: 0.163785] [G loss: 0.466974]\n",
      "[Epoch 21/200] [Batch 240/637] [D loss: 0.171786] [G loss: 0.456455]\n",
      "[Epoch 21/200] [Batch 241/637] [D loss: 0.163057] [G loss: 0.497002]\n",
      "[Epoch 21/200] [Batch 242/637] [D loss: 0.164575] [G loss: 0.434426]\n",
      "[Epoch 21/200] [Batch 243/637] [D loss: 0.188264] [G loss: 0.440101]\n",
      "[Epoch 21/200] [Batch 244/637] [D loss: 0.172082] [G loss: 0.542246]\n",
      "[Epoch 21/200] [Batch 245/637] [D loss: 0.158654] [G loss: 0.523220]\n",
      "[Epoch 21/200] [Batch 246/637] [D loss: 0.173909] [G loss: 0.497734]\n",
      "[Epoch 21/200] [Batch 247/637] [D loss: 0.148691] [G loss: 0.521914]\n",
      "[Epoch 21/200] [Batch 248/637] [D loss: 0.144061] [G loss: 0.489362]\n",
      "[Epoch 21/200] [Batch 249/637] [D loss: 0.152847] [G loss: 0.482480]\n",
      "[Epoch 21/200] [Batch 250/637] [D loss: 0.167924] [G loss: 0.488767]\n",
      "[Epoch 21/200] [Batch 251/637] [D loss: 0.164627] [G loss: 0.436855]\n",
      "[Epoch 21/200] [Batch 252/637] [D loss: 0.164933] [G loss: 0.504062]\n",
      "[Epoch 21/200] [Batch 253/637] [D loss: 0.145784] [G loss: 0.533540]\n",
      "[Epoch 21/200] [Batch 254/637] [D loss: 0.149988] [G loss: 0.510250]\n",
      "[Epoch 21/200] [Batch 255/637] [D loss: 0.162292] [G loss: 0.502740]\n",
      "[Epoch 21/200] [Batch 256/637] [D loss: 0.144724] [G loss: 0.486175]\n",
      "[Epoch 21/200] [Batch 257/637] [D loss: 0.176961] [G loss: 0.436383]\n",
      "[Epoch 21/200] [Batch 258/637] [D loss: 0.142660] [G loss: 0.587942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 259/637] [D loss: 0.157569] [G loss: 0.553599]\n",
      "[Epoch 21/200] [Batch 260/637] [D loss: 0.171185] [G loss: 0.540484]\n",
      "[Epoch 21/200] [Batch 261/637] [D loss: 0.183355] [G loss: 0.499862]\n",
      "[Epoch 21/200] [Batch 262/637] [D loss: 0.156388] [G loss: 0.530252]\n",
      "[Epoch 21/200] [Batch 263/637] [D loss: 0.157509] [G loss: 0.536252]\n",
      "[Epoch 21/200] [Batch 264/637] [D loss: 0.153083] [G loss: 0.544097]\n",
      "[Epoch 21/200] [Batch 265/637] [D loss: 0.158823] [G loss: 0.478718]\n",
      "[Epoch 21/200] [Batch 266/637] [D loss: 0.148717] [G loss: 0.583598]\n",
      "[Epoch 21/200] [Batch 267/637] [D loss: 0.127413] [G loss: 0.537573]\n",
      "[Epoch 21/200] [Batch 268/637] [D loss: 0.152170] [G loss: 0.574612]\n",
      "[Epoch 21/200] [Batch 269/637] [D loss: 0.177161] [G loss: 0.558127]\n",
      "[Epoch 21/200] [Batch 270/637] [D loss: 0.140574] [G loss: 0.587947]\n",
      "[Epoch 21/200] [Batch 271/637] [D loss: 0.177067] [G loss: 0.428616]\n",
      "[Epoch 21/200] [Batch 272/637] [D loss: 0.162023] [G loss: 0.534640]\n",
      "[Epoch 21/200] [Batch 273/637] [D loss: 0.168709] [G loss: 0.569346]\n",
      "[Epoch 21/200] [Batch 274/637] [D loss: 0.174522] [G loss: 0.494379]\n",
      "[Epoch 21/200] [Batch 275/637] [D loss: 0.175823] [G loss: 0.474641]\n",
      "[Epoch 21/200] [Batch 276/637] [D loss: 0.159876] [G loss: 0.521722]\n",
      "[Epoch 21/200] [Batch 277/637] [D loss: 0.190377] [G loss: 0.527410]\n",
      "[Epoch 21/200] [Batch 278/637] [D loss: 0.169473] [G loss: 0.518931]\n",
      "[Epoch 21/200] [Batch 279/637] [D loss: 0.164904] [G loss: 0.500931]\n",
      "[Epoch 21/200] [Batch 280/637] [D loss: 0.175612] [G loss: 0.494259]\n",
      "[Epoch 21/200] [Batch 281/637] [D loss: 0.173531] [G loss: 0.536104]\n",
      "[Epoch 21/200] [Batch 282/637] [D loss: 0.168365] [G loss: 0.467273]\n",
      "[Epoch 21/200] [Batch 283/637] [D loss: 0.163324] [G loss: 0.437299]\n",
      "[Epoch 21/200] [Batch 284/637] [D loss: 0.169033] [G loss: 0.480857]\n",
      "[Epoch 21/200] [Batch 285/637] [D loss: 0.180548] [G loss: 0.465123]\n",
      "[Epoch 21/200] [Batch 286/637] [D loss: 0.146374] [G loss: 0.522135]\n",
      "[Epoch 21/200] [Batch 287/637] [D loss: 0.170290] [G loss: 0.450316]\n",
      "[Epoch 21/200] [Batch 288/637] [D loss: 0.170036] [G loss: 0.433107]\n",
      "[Epoch 21/200] [Batch 289/637] [D loss: 0.161441] [G loss: 0.478448]\n",
      "[Epoch 21/200] [Batch 290/637] [D loss: 0.150484] [G loss: 0.486333]\n",
      "[Epoch 21/200] [Batch 291/637] [D loss: 0.176321] [G loss: 0.451696]\n",
      "[Epoch 21/200] [Batch 292/637] [D loss: 0.186794] [G loss: 0.514316]\n",
      "[Epoch 21/200] [Batch 293/637] [D loss: 0.166765] [G loss: 0.563319]\n",
      "[Epoch 21/200] [Batch 294/637] [D loss: 0.159848] [G loss: 0.569101]\n",
      "[Epoch 21/200] [Batch 295/637] [D loss: 0.167497] [G loss: 0.539276]\n",
      "[Epoch 21/200] [Batch 296/637] [D loss: 0.164594] [G loss: 0.554640]\n",
      "[Epoch 21/200] [Batch 297/637] [D loss: 0.188394] [G loss: 0.496081]\n",
      "[Epoch 21/200] [Batch 298/637] [D loss: 0.160447] [G loss: 0.460523]\n",
      "[Epoch 21/200] [Batch 299/637] [D loss: 0.164257] [G loss: 0.479892]\n",
      "[Epoch 21/200] [Batch 300/637] [D loss: 0.175752] [G loss: 0.432473]\n",
      "[Epoch 21/200] [Batch 301/637] [D loss: 0.158645] [G loss: 0.520684]\n",
      "[Epoch 21/200] [Batch 302/637] [D loss: 0.139667] [G loss: 0.540048]\n",
      "[Epoch 21/200] [Batch 303/637] [D loss: 0.149173] [G loss: 0.542885]\n",
      "[Epoch 21/200] [Batch 304/637] [D loss: 0.179856] [G loss: 0.497009]\n",
      "[Epoch 21/200] [Batch 305/637] [D loss: 0.169390] [G loss: 0.467884]\n",
      "[Epoch 21/200] [Batch 306/637] [D loss: 0.160198] [G loss: 0.468582]\n",
      "[Epoch 21/200] [Batch 307/637] [D loss: 0.145855] [G loss: 0.527023]\n",
      "[Epoch 21/200] [Batch 308/637] [D loss: 0.142830] [G loss: 0.526490]\n",
      "[Epoch 21/200] [Batch 309/637] [D loss: 0.153693] [G loss: 0.584024]\n",
      "[Epoch 21/200] [Batch 310/637] [D loss: 0.153780] [G loss: 0.540046]\n",
      "[Epoch 21/200] [Batch 311/637] [D loss: 0.173802] [G loss: 0.460157]\n",
      "[Epoch 21/200] [Batch 312/637] [D loss: 0.160624] [G loss: 0.480359]\n",
      "[Epoch 21/200] [Batch 313/637] [D loss: 0.165393] [G loss: 0.495418]\n",
      "[Epoch 21/200] [Batch 314/637] [D loss: 0.158477] [G loss: 0.512840]\n",
      "[Epoch 21/200] [Batch 315/637] [D loss: 0.154930] [G loss: 0.465209]\n",
      "[Epoch 21/200] [Batch 316/637] [D loss: 0.135144] [G loss: 0.489572]\n",
      "[Epoch 21/200] [Batch 317/637] [D loss: 0.164161] [G loss: 0.491147]\n",
      "[Epoch 21/200] [Batch 318/637] [D loss: 0.154454] [G loss: 0.516724]\n",
      "[Epoch 21/200] [Batch 319/637] [D loss: 0.164283] [G loss: 0.496233]\n",
      "[Epoch 21/200] [Batch 320/637] [D loss: 0.160476] [G loss: 0.422151]\n",
      "[Epoch 21/200] [Batch 321/637] [D loss: 0.142341] [G loss: 0.554367]\n",
      "[Epoch 21/200] [Batch 322/637] [D loss: 0.155346] [G loss: 0.497080]\n",
      "[Epoch 21/200] [Batch 323/637] [D loss: 0.158906] [G loss: 0.442892]\n",
      "[Epoch 21/200] [Batch 324/637] [D loss: 0.165572] [G loss: 0.500787]\n",
      "[Epoch 21/200] [Batch 325/637] [D loss: 0.152437] [G loss: 0.511209]\n",
      "[Epoch 21/200] [Batch 326/637] [D loss: 0.165738] [G loss: 0.609097]\n",
      "[Epoch 21/200] [Batch 327/637] [D loss: 0.208892] [G loss: 0.423528]\n",
      "[Epoch 21/200] [Batch 328/637] [D loss: 0.227763] [G loss: 0.344988]\n",
      "[Epoch 21/200] [Batch 329/637] [D loss: 0.213375] [G loss: 0.569030]\n",
      "[Epoch 21/200] [Batch 330/637] [D loss: 0.177142] [G loss: 0.513565]\n",
      "[Epoch 21/200] [Batch 331/637] [D loss: 0.158533] [G loss: 0.507582]\n",
      "[Epoch 21/200] [Batch 332/637] [D loss: 0.171170] [G loss: 0.464034]\n",
      "[Epoch 21/200] [Batch 333/637] [D loss: 0.163636] [G loss: 0.442282]\n",
      "[Epoch 21/200] [Batch 334/637] [D loss: 0.149953] [G loss: 0.541767]\n",
      "[Epoch 21/200] [Batch 335/637] [D loss: 0.190457] [G loss: 0.400745]\n",
      "[Epoch 21/200] [Batch 336/637] [D loss: 0.156847] [G loss: 0.519598]\n",
      "[Epoch 21/200] [Batch 337/637] [D loss: 0.153976] [G loss: 0.483715]\n",
      "[Epoch 21/200] [Batch 338/637] [D loss: 0.164791] [G loss: 0.417167]\n",
      "[Epoch 21/200] [Batch 339/637] [D loss: 0.147708] [G loss: 0.512390]\n",
      "[Epoch 21/200] [Batch 340/637] [D loss: 0.160293] [G loss: 0.504832]\n",
      "[Epoch 21/200] [Batch 341/637] [D loss: 0.160344] [G loss: 0.579662]\n",
      "[Epoch 21/200] [Batch 342/637] [D loss: 0.168536] [G loss: 0.539883]\n",
      "[Epoch 21/200] [Batch 343/637] [D loss: 0.164907] [G loss: 0.500554]\n",
      "[Epoch 21/200] [Batch 344/637] [D loss: 0.168171] [G loss: 0.456267]\n",
      "[Epoch 21/200] [Batch 345/637] [D loss: 0.196854] [G loss: 0.501508]\n",
      "[Epoch 21/200] [Batch 346/637] [D loss: 0.182258] [G loss: 0.551958]\n",
      "[Epoch 21/200] [Batch 347/637] [D loss: 0.150306] [G loss: 0.524377]\n",
      "[Epoch 21/200] [Batch 348/637] [D loss: 0.159816] [G loss: 0.457090]\n",
      "[Epoch 21/200] [Batch 349/637] [D loss: 0.135690] [G loss: 0.518419]\n",
      "[Epoch 21/200] [Batch 350/637] [D loss: 0.155293] [G loss: 0.475701]\n",
      "[Epoch 21/200] [Batch 351/637] [D loss: 0.168414] [G loss: 0.498768]\n",
      "[Epoch 21/200] [Batch 352/637] [D loss: 0.157045] [G loss: 0.531058]\n",
      "[Epoch 21/200] [Batch 353/637] [D loss: 0.170338] [G loss: 0.476648]\n",
      "[Epoch 21/200] [Batch 354/637] [D loss: 0.167054] [G loss: 0.525054]\n",
      "[Epoch 21/200] [Batch 355/637] [D loss: 0.142990] [G loss: 0.541090]\n",
      "[Epoch 21/200] [Batch 356/637] [D loss: 0.147062] [G loss: 0.508667]\n",
      "[Epoch 21/200] [Batch 357/637] [D loss: 0.174434] [G loss: 0.551398]\n",
      "[Epoch 21/200] [Batch 358/637] [D loss: 0.155399] [G loss: 0.540174]\n",
      "[Epoch 21/200] [Batch 359/637] [D loss: 0.195991] [G loss: 0.434082]\n",
      "[Epoch 21/200] [Batch 360/637] [D loss: 0.172235] [G loss: 0.484429]\n",
      "[Epoch 21/200] [Batch 361/637] [D loss: 0.156270] [G loss: 0.555638]\n",
      "[Epoch 21/200] [Batch 362/637] [D loss: 0.150314] [G loss: 0.574783]\n",
      "[Epoch 21/200] [Batch 363/637] [D loss: 0.146473] [G loss: 0.506940]\n",
      "[Epoch 21/200] [Batch 364/637] [D loss: 0.156027] [G loss: 0.518691]\n",
      "[Epoch 21/200] [Batch 365/637] [D loss: 0.150751] [G loss: 0.599700]\n",
      "[Epoch 21/200] [Batch 366/637] [D loss: 0.166169] [G loss: 0.542611]\n",
      "[Epoch 21/200] [Batch 367/637] [D loss: 0.179251] [G loss: 0.568520]\n",
      "[Epoch 21/200] [Batch 368/637] [D loss: 0.169377] [G loss: 0.553237]\n",
      "[Epoch 21/200] [Batch 369/637] [D loss: 0.158870] [G loss: 0.540964]\n",
      "[Epoch 21/200] [Batch 370/637] [D loss: 0.152154] [G loss: 0.494877]\n",
      "[Epoch 21/200] [Batch 371/637] [D loss: 0.185678] [G loss: 0.461554]\n",
      "[Epoch 21/200] [Batch 372/637] [D loss: 0.157096] [G loss: 0.546416]\n",
      "[Epoch 21/200] [Batch 373/637] [D loss: 0.162860] [G loss: 0.500914]\n",
      "[Epoch 21/200] [Batch 374/637] [D loss: 0.171048] [G loss: 0.546746]\n",
      "[Epoch 21/200] [Batch 375/637] [D loss: 0.155753] [G loss: 0.586264]\n",
      "[Epoch 21/200] [Batch 376/637] [D loss: 0.197249] [G loss: 0.443608]\n",
      "[Epoch 21/200] [Batch 377/637] [D loss: 0.157084] [G loss: 0.511113]\n",
      "[Epoch 21/200] [Batch 378/637] [D loss: 0.167007] [G loss: 0.533885]\n",
      "[Epoch 21/200] [Batch 379/637] [D loss: 0.167870] [G loss: 0.547612]\n",
      "[Epoch 21/200] [Batch 380/637] [D loss: 0.154335] [G loss: 0.530456]\n",
      "[Epoch 21/200] [Batch 381/637] [D loss: 0.150482] [G loss: 0.543304]\n",
      "[Epoch 21/200] [Batch 382/637] [D loss: 0.149157] [G loss: 0.524762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 383/637] [D loss: 0.159543] [G loss: 0.413792]\n",
      "[Epoch 21/200] [Batch 384/637] [D loss: 0.146057] [G loss: 0.529433]\n",
      "[Epoch 21/200] [Batch 385/637] [D loss: 0.161961] [G loss: 0.534978]\n",
      "[Epoch 21/200] [Batch 386/637] [D loss: 0.172328] [G loss: 0.614718]\n",
      "[Epoch 21/200] [Batch 387/637] [D loss: 0.172617] [G loss: 0.496671]\n",
      "[Epoch 21/200] [Batch 388/637] [D loss: 0.156796] [G loss: 0.563884]\n",
      "[Epoch 21/200] [Batch 389/637] [D loss: 0.151922] [G loss: 0.531082]\n",
      "[Epoch 21/200] [Batch 390/637] [D loss: 0.165120] [G loss: 0.541340]\n",
      "[Epoch 21/200] [Batch 391/637] [D loss: 0.168690] [G loss: 0.460348]\n",
      "[Epoch 21/200] [Batch 392/637] [D loss: 0.171038] [G loss: 0.490755]\n",
      "[Epoch 21/200] [Batch 393/637] [D loss: 0.182660] [G loss: 0.560532]\n",
      "[Epoch 21/200] [Batch 394/637] [D loss: 0.161836] [G loss: 0.591011]\n",
      "[Epoch 21/200] [Batch 395/637] [D loss: 0.162569] [G loss: 0.463920]\n",
      "[Epoch 21/200] [Batch 396/637] [D loss: 0.157199] [G loss: 0.536425]\n",
      "[Epoch 21/200] [Batch 397/637] [D loss: 0.174641] [G loss: 0.478839]\n",
      "[Epoch 21/200] [Batch 398/637] [D loss: 0.157040] [G loss: 0.560552]\n",
      "[Epoch 21/200] [Batch 399/637] [D loss: 0.210060] [G loss: 0.528528]\n",
      "[Epoch 21/200] [Batch 400/637] [D loss: 0.160142] [G loss: 0.525466]\n",
      "[Epoch 21/200] [Batch 401/637] [D loss: 0.164702] [G loss: 0.510200]\n",
      "[Epoch 21/200] [Batch 402/637] [D loss: 0.161609] [G loss: 0.467939]\n",
      "[Epoch 21/200] [Batch 403/637] [D loss: 0.183473] [G loss: 0.570898]\n",
      "[Epoch 21/200] [Batch 404/637] [D loss: 0.144046] [G loss: 0.619846]\n",
      "[Epoch 21/200] [Batch 405/637] [D loss: 0.163878] [G loss: 0.564439]\n",
      "[Epoch 21/200] [Batch 406/637] [D loss: 0.141558] [G loss: 0.469782]\n",
      "[Epoch 21/200] [Batch 407/637] [D loss: 0.163177] [G loss: 0.506217]\n",
      "[Epoch 21/200] [Batch 408/637] [D loss: 0.162371] [G loss: 0.557749]\n",
      "[Epoch 21/200] [Batch 409/637] [D loss: 0.178303] [G loss: 0.527338]\n",
      "[Epoch 21/200] [Batch 410/637] [D loss: 0.196834] [G loss: 0.408965]\n",
      "[Epoch 21/200] [Batch 411/637] [D loss: 0.166476] [G loss: 0.467253]\n",
      "[Epoch 21/200] [Batch 412/637] [D loss: 0.177074] [G loss: 0.453372]\n",
      "[Epoch 21/200] [Batch 413/637] [D loss: 0.173177] [G loss: 0.515386]\n",
      "[Epoch 21/200] [Batch 414/637] [D loss: 0.159640] [G loss: 0.515676]\n",
      "[Epoch 21/200] [Batch 415/637] [D loss: 0.180060] [G loss: 0.495704]\n",
      "[Epoch 21/200] [Batch 416/637] [D loss: 0.168117] [G loss: 0.594316]\n",
      "[Epoch 21/200] [Batch 417/637] [D loss: 0.189222] [G loss: 0.489066]\n",
      "[Epoch 21/200] [Batch 418/637] [D loss: 0.190918] [G loss: 0.421334]\n",
      "[Epoch 21/200] [Batch 419/637] [D loss: 0.149704] [G loss: 0.465958]\n",
      "[Epoch 21/200] [Batch 420/637] [D loss: 0.199775] [G loss: 0.462844]\n",
      "[Epoch 21/200] [Batch 421/637] [D loss: 0.158883] [G loss: 0.534943]\n",
      "[Epoch 21/200] [Batch 422/637] [D loss: 0.156637] [G loss: 0.557435]\n",
      "[Epoch 21/200] [Batch 423/637] [D loss: 0.155969] [G loss: 0.479835]\n",
      "[Epoch 21/200] [Batch 424/637] [D loss: 0.172675] [G loss: 0.459212]\n",
      "[Epoch 21/200] [Batch 425/637] [D loss: 0.154242] [G loss: 0.459118]\n",
      "[Epoch 21/200] [Batch 426/637] [D loss: 0.144993] [G loss: 0.463728]\n",
      "[Epoch 21/200] [Batch 427/637] [D loss: 0.156287] [G loss: 0.511739]\n",
      "[Epoch 21/200] [Batch 428/637] [D loss: 0.149432] [G loss: 0.529871]\n",
      "[Epoch 21/200] [Batch 429/637] [D loss: 0.161212] [G loss: 0.520576]\n",
      "[Epoch 21/200] [Batch 430/637] [D loss: 0.135486] [G loss: 0.575787]\n",
      "[Epoch 21/200] [Batch 431/637] [D loss: 0.168074] [G loss: 0.479888]\n",
      "[Epoch 21/200] [Batch 432/637] [D loss: 0.171635] [G loss: 0.447911]\n",
      "[Epoch 21/200] [Batch 433/637] [D loss: 0.156083] [G loss: 0.552396]\n",
      "[Epoch 21/200] [Batch 434/637] [D loss: 0.148734] [G loss: 0.549238]\n",
      "[Epoch 21/200] [Batch 435/637] [D loss: 0.161225] [G loss: 0.435621]\n",
      "[Epoch 21/200] [Batch 436/637] [D loss: 0.152517] [G loss: 0.471400]\n",
      "[Epoch 21/200] [Batch 437/637] [D loss: 0.145795] [G loss: 0.546400]\n",
      "[Epoch 21/200] [Batch 438/637] [D loss: 0.148057] [G loss: 0.497841]\n",
      "[Epoch 21/200] [Batch 439/637] [D loss: 0.151419] [G loss: 0.481339]\n",
      "[Epoch 21/200] [Batch 440/637] [D loss: 0.151745] [G loss: 0.465240]\n",
      "[Epoch 21/200] [Batch 441/637] [D loss: 0.159527] [G loss: 0.524629]\n",
      "[Epoch 21/200] [Batch 442/637] [D loss: 0.165321] [G loss: 0.549128]\n",
      "[Epoch 21/200] [Batch 443/637] [D loss: 0.147092] [G loss: 0.559249]\n",
      "[Epoch 21/200] [Batch 444/637] [D loss: 0.183300] [G loss: 0.424697]\n",
      "[Epoch 21/200] [Batch 445/637] [D loss: 0.162590] [G loss: 0.492720]\n",
      "[Epoch 21/200] [Batch 446/637] [D loss: 0.158783] [G loss: 0.471094]\n",
      "[Epoch 21/200] [Batch 447/637] [D loss: 0.175145] [G loss: 0.502965]\n",
      "[Epoch 21/200] [Batch 448/637] [D loss: 0.158694] [G loss: 0.522434]\n",
      "[Epoch 21/200] [Batch 449/637] [D loss: 0.162743] [G loss: 0.566658]\n",
      "[Epoch 21/200] [Batch 450/637] [D loss: 0.152819] [G loss: 0.476347]\n",
      "[Epoch 21/200] [Batch 451/637] [D loss: 0.185377] [G loss: 0.434209]\n",
      "[Epoch 21/200] [Batch 452/637] [D loss: 0.149635] [G loss: 0.570570]\n",
      "[Epoch 21/200] [Batch 453/637] [D loss: 0.161885] [G loss: 0.478136]\n",
      "[Epoch 21/200] [Batch 454/637] [D loss: 0.165034] [G loss: 0.499047]\n",
      "[Epoch 21/200] [Batch 455/637] [D loss: 0.160737] [G loss: 0.493730]\n",
      "[Epoch 21/200] [Batch 456/637] [D loss: 0.169189] [G loss: 0.553731]\n",
      "[Epoch 21/200] [Batch 457/637] [D loss: 0.170858] [G loss: 0.495360]\n",
      "[Epoch 21/200] [Batch 458/637] [D loss: 0.157895] [G loss: 0.484445]\n",
      "[Epoch 21/200] [Batch 459/637] [D loss: 0.176144] [G loss: 0.550803]\n",
      "[Epoch 21/200] [Batch 460/637] [D loss: 0.172466] [G loss: 0.477589]\n",
      "[Epoch 21/200] [Batch 461/637] [D loss: 0.147009] [G loss: 0.555143]\n",
      "[Epoch 21/200] [Batch 462/637] [D loss: 0.172630] [G loss: 0.508188]\n",
      "[Epoch 21/200] [Batch 463/637] [D loss: 0.165469] [G loss: 0.503077]\n",
      "[Epoch 21/200] [Batch 464/637] [D loss: 0.145458] [G loss: 0.590371]\n",
      "[Epoch 21/200] [Batch 465/637] [D loss: 0.190022] [G loss: 0.599414]\n",
      "[Epoch 21/200] [Batch 466/637] [D loss: 0.163560] [G loss: 0.511966]\n",
      "[Epoch 21/200] [Batch 467/637] [D loss: 0.145873] [G loss: 0.486001]\n",
      "[Epoch 21/200] [Batch 468/637] [D loss: 0.168299] [G loss: 0.467786]\n",
      "[Epoch 21/200] [Batch 469/637] [D loss: 0.164997] [G loss: 0.480904]\n",
      "[Epoch 21/200] [Batch 470/637] [D loss: 0.186890] [G loss: 0.506681]\n",
      "[Epoch 21/200] [Batch 471/637] [D loss: 0.160345] [G loss: 0.644412]\n",
      "[Epoch 21/200] [Batch 472/637] [D loss: 0.164247] [G loss: 0.610569]\n",
      "[Epoch 21/200] [Batch 473/637] [D loss: 0.158350] [G loss: 0.500750]\n",
      "[Epoch 21/200] [Batch 474/637] [D loss: 0.137270] [G loss: 0.516086]\n",
      "[Epoch 21/200] [Batch 475/637] [D loss: 0.149352] [G loss: 0.575071]\n",
      "[Epoch 21/200] [Batch 476/637] [D loss: 0.161118] [G loss: 0.545842]\n",
      "[Epoch 21/200] [Batch 477/637] [D loss: 0.157157] [G loss: 0.472730]\n",
      "[Epoch 21/200] [Batch 478/637] [D loss: 0.205175] [G loss: 0.465162]\n",
      "[Epoch 21/200] [Batch 479/637] [D loss: 0.218848] [G loss: 0.609422]\n",
      "[Epoch 21/200] [Batch 480/637] [D loss: 0.178505] [G loss: 0.545933]\n",
      "[Epoch 21/200] [Batch 481/637] [D loss: 0.198706] [G loss: 0.489898]\n",
      "[Epoch 21/200] [Batch 482/637] [D loss: 0.146990] [G loss: 0.495429]\n",
      "[Epoch 21/200] [Batch 483/637] [D loss: 0.142999] [G loss: 0.506449]\n",
      "[Epoch 21/200] [Batch 484/637] [D loss: 0.152419] [G loss: 0.504837]\n",
      "[Epoch 21/200] [Batch 485/637] [D loss: 0.165559] [G loss: 0.477249]\n",
      "[Epoch 21/200] [Batch 486/637] [D loss: 0.171531] [G loss: 0.437026]\n",
      "[Epoch 21/200] [Batch 487/637] [D loss: 0.175232] [G loss: 0.464585]\n",
      "[Epoch 21/200] [Batch 488/637] [D loss: 0.158509] [G loss: 0.484008]\n",
      "[Epoch 21/200] [Batch 489/637] [D loss: 0.160711] [G loss: 0.424456]\n",
      "[Epoch 21/200] [Batch 490/637] [D loss: 0.155171] [G loss: 0.516556]\n",
      "[Epoch 21/200] [Batch 491/637] [D loss: 0.160082] [G loss: 0.529315]\n",
      "[Epoch 21/200] [Batch 492/637] [D loss: 0.150410] [G loss: 0.519523]\n",
      "[Epoch 21/200] [Batch 493/637] [D loss: 0.142783] [G loss: 0.467156]\n",
      "[Epoch 21/200] [Batch 494/637] [D loss: 0.156414] [G loss: 0.515130]\n",
      "[Epoch 21/200] [Batch 495/637] [D loss: 0.187625] [G loss: 0.454586]\n",
      "[Epoch 21/200] [Batch 496/637] [D loss: 0.209607] [G loss: 0.568900]\n",
      "[Epoch 21/200] [Batch 497/637] [D loss: 0.152884] [G loss: 0.511397]\n",
      "[Epoch 21/200] [Batch 498/637] [D loss: 0.184801] [G loss: 0.470671]\n",
      "[Epoch 21/200] [Batch 499/637] [D loss: 0.162676] [G loss: 0.558208]\n",
      "[Epoch 21/200] [Batch 500/637] [D loss: 0.157420] [G loss: 0.456323]\n",
      "[Epoch 21/200] [Batch 501/637] [D loss: 0.157556] [G loss: 0.507525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 502/637] [D loss: 0.149804] [G loss: 0.505599]\n",
      "[Epoch 21/200] [Batch 503/637] [D loss: 0.158316] [G loss: 0.529893]\n",
      "[Epoch 21/200] [Batch 504/637] [D loss: 0.172047] [G loss: 0.487256]\n",
      "[Epoch 21/200] [Batch 505/637] [D loss: 0.138146] [G loss: 0.612792]\n",
      "[Epoch 21/200] [Batch 506/637] [D loss: 0.174042] [G loss: 0.494265]\n",
      "[Epoch 21/200] [Batch 507/637] [D loss: 0.161284] [G loss: 0.534406]\n",
      "[Epoch 21/200] [Batch 508/637] [D loss: 0.186670] [G loss: 0.555706]\n",
      "[Epoch 21/200] [Batch 509/637] [D loss: 0.162599] [G loss: 0.496888]\n",
      "[Epoch 21/200] [Batch 510/637] [D loss: 0.171228] [G loss: 0.478307]\n",
      "[Epoch 21/200] [Batch 511/637] [D loss: 0.144974] [G loss: 0.492821]\n",
      "[Epoch 21/200] [Batch 512/637] [D loss: 0.171330] [G loss: 0.460464]\n",
      "[Epoch 21/200] [Batch 513/637] [D loss: 0.144297] [G loss: 0.474979]\n",
      "[Epoch 21/200] [Batch 514/637] [D loss: 0.128697] [G loss: 0.558722]\n",
      "[Epoch 21/200] [Batch 515/637] [D loss: 0.167910] [G loss: 0.536320]\n",
      "[Epoch 21/200] [Batch 516/637] [D loss: 0.161135] [G loss: 0.504526]\n",
      "[Epoch 21/200] [Batch 517/637] [D loss: 0.165890] [G loss: 0.542478]\n",
      "[Epoch 21/200] [Batch 518/637] [D loss: 0.139402] [G loss: 0.586909]\n",
      "[Epoch 21/200] [Batch 519/637] [D loss: 0.162730] [G loss: 0.506901]\n",
      "[Epoch 21/200] [Batch 520/637] [D loss: 0.163820] [G loss: 0.458808]\n",
      "[Epoch 21/200] [Batch 521/637] [D loss: 0.151184] [G loss: 0.518772]\n",
      "[Epoch 21/200] [Batch 522/637] [D loss: 0.163736] [G loss: 0.532171]\n",
      "[Epoch 21/200] [Batch 523/637] [D loss: 0.151514] [G loss: 0.523072]\n",
      "[Epoch 21/200] [Batch 524/637] [D loss: 0.156248] [G loss: 0.528744]\n",
      "[Epoch 21/200] [Batch 525/637] [D loss: 0.156407] [G loss: 0.472509]\n",
      "[Epoch 21/200] [Batch 526/637] [D loss: 0.151985] [G loss: 0.492632]\n",
      "[Epoch 21/200] [Batch 527/637] [D loss: 0.162872] [G loss: 0.499824]\n",
      "[Epoch 21/200] [Batch 528/637] [D loss: 0.153507] [G loss: 0.479420]\n",
      "[Epoch 21/200] [Batch 529/637] [D loss: 0.141174] [G loss: 0.534557]\n",
      "[Epoch 21/200] [Batch 530/637] [D loss: 0.154283] [G loss: 0.560915]\n",
      "[Epoch 21/200] [Batch 531/637] [D loss: 0.156457] [G loss: 0.478999]\n",
      "[Epoch 21/200] [Batch 532/637] [D loss: 0.163034] [G loss: 0.461164]\n",
      "[Epoch 21/200] [Batch 533/637] [D loss: 0.159679] [G loss: 0.477341]\n",
      "[Epoch 21/200] [Batch 534/637] [D loss: 0.160540] [G loss: 0.463776]\n",
      "[Epoch 21/200] [Batch 535/637] [D loss: 0.145640] [G loss: 0.530281]\n",
      "[Epoch 21/200] [Batch 536/637] [D loss: 0.147818] [G loss: 0.570059]\n",
      "[Epoch 21/200] [Batch 537/637] [D loss: 0.196801] [G loss: 0.440307]\n",
      "[Epoch 21/200] [Batch 538/637] [D loss: 0.194188] [G loss: 0.500180]\n",
      "[Epoch 21/200] [Batch 539/637] [D loss: 0.176835] [G loss: 0.536089]\n",
      "[Epoch 21/200] [Batch 540/637] [D loss: 0.192354] [G loss: 0.450191]\n",
      "[Epoch 21/200] [Batch 541/637] [D loss: 0.154042] [G loss: 0.516132]\n",
      "[Epoch 21/200] [Batch 542/637] [D loss: 0.158408] [G loss: 0.484883]\n",
      "[Epoch 21/200] [Batch 543/637] [D loss: 0.138937] [G loss: 0.531308]\n",
      "[Epoch 21/200] [Batch 544/637] [D loss: 0.147414] [G loss: 0.473080]\n",
      "[Epoch 21/200] [Batch 545/637] [D loss: 0.135811] [G loss: 0.510375]\n",
      "[Epoch 21/200] [Batch 546/637] [D loss: 0.144108] [G loss: 0.581516]\n",
      "[Epoch 21/200] [Batch 547/637] [D loss: 0.136186] [G loss: 0.524684]\n",
      "[Epoch 21/200] [Batch 548/637] [D loss: 0.163360] [G loss: 0.493155]\n",
      "[Epoch 21/200] [Batch 549/637] [D loss: 0.145682] [G loss: 0.543828]\n",
      "[Epoch 21/200] [Batch 550/637] [D loss: 0.152331] [G loss: 0.483141]\n",
      "[Epoch 21/200] [Batch 551/637] [D loss: 0.152037] [G loss: 0.484801]\n",
      "[Epoch 21/200] [Batch 552/637] [D loss: 0.188586] [G loss: 0.418365]\n",
      "[Epoch 21/200] [Batch 553/637] [D loss: 0.216717] [G loss: 0.615000]\n",
      "[Epoch 21/200] [Batch 554/637] [D loss: 0.189038] [G loss: 0.547139]\n",
      "[Epoch 21/200] [Batch 555/637] [D loss: 0.178495] [G loss: 0.496832]\n",
      "[Epoch 21/200] [Batch 556/637] [D loss: 0.171735] [G loss: 0.455502]\n",
      "[Epoch 21/200] [Batch 557/637] [D loss: 0.191187] [G loss: 0.476746]\n",
      "[Epoch 21/200] [Batch 558/637] [D loss: 0.169215] [G loss: 0.460015]\n",
      "[Epoch 21/200] [Batch 559/637] [D loss: 0.165993] [G loss: 0.435607]\n",
      "[Epoch 21/200] [Batch 560/637] [D loss: 0.176856] [G loss: 0.487083]\n",
      "[Epoch 21/200] [Batch 561/637] [D loss: 0.160587] [G loss: 0.521183]\n",
      "[Epoch 21/200] [Batch 562/637] [D loss: 0.163533] [G loss: 0.503666]\n",
      "[Epoch 21/200] [Batch 563/637] [D loss: 0.174590] [G loss: 0.510620]\n",
      "[Epoch 21/200] [Batch 564/637] [D loss: 0.149464] [G loss: 0.502317]\n",
      "[Epoch 21/200] [Batch 565/637] [D loss: 0.152714] [G loss: 0.498874]\n",
      "[Epoch 21/200] [Batch 566/637] [D loss: 0.161549] [G loss: 0.524140]\n",
      "[Epoch 21/200] [Batch 567/637] [D loss: 0.152762] [G loss: 0.529059]\n",
      "[Epoch 21/200] [Batch 568/637] [D loss: 0.135731] [G loss: 0.507989]\n",
      "[Epoch 21/200] [Batch 569/637] [D loss: 0.162831] [G loss: 0.493528]\n",
      "[Epoch 21/200] [Batch 570/637] [D loss: 0.129477] [G loss: 0.539095]\n",
      "[Epoch 21/200] [Batch 571/637] [D loss: 0.157053] [G loss: 0.585527]\n",
      "[Epoch 21/200] [Batch 572/637] [D loss: 0.135212] [G loss: 0.609209]\n",
      "[Epoch 21/200] [Batch 573/637] [D loss: 0.130965] [G loss: 0.556548]\n",
      "[Epoch 21/200] [Batch 574/637] [D loss: 0.146451] [G loss: 0.565473]\n",
      "[Epoch 21/200] [Batch 575/637] [D loss: 0.155633] [G loss: 0.462703]\n",
      "[Epoch 21/200] [Batch 576/637] [D loss: 0.161339] [G loss: 0.509990]\n",
      "[Epoch 21/200] [Batch 577/637] [D loss: 0.164615] [G loss: 0.565100]\n",
      "[Epoch 21/200] [Batch 578/637] [D loss: 0.150337] [G loss: 0.528110]\n",
      "[Epoch 21/200] [Batch 579/637] [D loss: 0.166697] [G loss: 0.544977]\n",
      "[Epoch 21/200] [Batch 580/637] [D loss: 0.180540] [G loss: 0.555658]\n",
      "[Epoch 21/200] [Batch 581/637] [D loss: 0.161950] [G loss: 0.532456]\n",
      "[Epoch 21/200] [Batch 582/637] [D loss: 0.143151] [G loss: 0.507263]\n",
      "[Epoch 21/200] [Batch 583/637] [D loss: 0.153846] [G loss: 0.501043]\n",
      "[Epoch 21/200] [Batch 584/637] [D loss: 0.168874] [G loss: 0.504736]\n",
      "[Epoch 21/200] [Batch 585/637] [D loss: 0.161467] [G loss: 0.530297]\n",
      "[Epoch 21/200] [Batch 586/637] [D loss: 0.157630] [G loss: 0.477582]\n",
      "[Epoch 21/200] [Batch 587/637] [D loss: 0.152550] [G loss: 0.467946]\n",
      "[Epoch 21/200] [Batch 588/637] [D loss: 0.166973] [G loss: 0.513208]\n",
      "[Epoch 21/200] [Batch 589/637] [D loss: 0.166148] [G loss: 0.597230]\n",
      "[Epoch 21/200] [Batch 590/637] [D loss: 0.143804] [G loss: 0.520287]\n",
      "[Epoch 21/200] [Batch 591/637] [D loss: 0.156985] [G loss: 0.536356]\n",
      "[Epoch 21/200] [Batch 592/637] [D loss: 0.168646] [G loss: 0.468165]\n",
      "[Epoch 21/200] [Batch 593/637] [D loss: 0.136041] [G loss: 0.616238]\n",
      "[Epoch 21/200] [Batch 594/637] [D loss: 0.175800] [G loss: 0.470769]\n",
      "[Epoch 21/200] [Batch 595/637] [D loss: 0.191778] [G loss: 0.471834]\n",
      "[Epoch 21/200] [Batch 596/637] [D loss: 0.216045] [G loss: 0.521524]\n",
      "[Epoch 21/200] [Batch 597/637] [D loss: 0.176273] [G loss: 0.553681]\n",
      "[Epoch 21/200] [Batch 598/637] [D loss: 0.206956] [G loss: 0.491605]\n",
      "[Epoch 21/200] [Batch 599/637] [D loss: 0.175420] [G loss: 0.464019]\n",
      "[Epoch 21/200] [Batch 600/637] [D loss: 0.172681] [G loss: 0.459899]\n",
      "[Epoch 21/200] [Batch 601/637] [D loss: 0.161638] [G loss: 0.449224]\n",
      "[Epoch 21/200] [Batch 602/637] [D loss: 0.149561] [G loss: 0.445665]\n",
      "[Epoch 21/200] [Batch 603/637] [D loss: 0.163924] [G loss: 0.475448]\n",
      "[Epoch 21/200] [Batch 604/637] [D loss: 0.161552] [G loss: 0.446056]\n",
      "[Epoch 21/200] [Batch 605/637] [D loss: 0.146852] [G loss: 0.621066]\n",
      "[Epoch 21/200] [Batch 606/637] [D loss: 0.163706] [G loss: 0.632843]\n",
      "[Epoch 21/200] [Batch 607/637] [D loss: 0.164747] [G loss: 0.504327]\n",
      "[Epoch 21/200] [Batch 608/637] [D loss: 0.161623] [G loss: 0.487822]\n",
      "[Epoch 21/200] [Batch 609/637] [D loss: 0.162268] [G loss: 0.526036]\n",
      "[Epoch 21/200] [Batch 610/637] [D loss: 0.178223] [G loss: 0.465094]\n",
      "[Epoch 21/200] [Batch 611/637] [D loss: 0.175966] [G loss: 0.437048]\n",
      "[Epoch 21/200] [Batch 612/637] [D loss: 0.194804] [G loss: 0.426432]\n",
      "[Epoch 21/200] [Batch 613/637] [D loss: 0.185541] [G loss: 0.491990]\n",
      "[Epoch 21/200] [Batch 614/637] [D loss: 0.153108] [G loss: 0.506248]\n",
      "[Epoch 21/200] [Batch 615/637] [D loss: 0.174392] [G loss: 0.465612]\n",
      "[Epoch 21/200] [Batch 616/637] [D loss: 0.165723] [G loss: 0.506050]\n",
      "[Epoch 21/200] [Batch 617/637] [D loss: 0.154492] [G loss: 0.526437]\n",
      "[Epoch 21/200] [Batch 618/637] [D loss: 0.158492] [G loss: 0.503518]\n",
      "[Epoch 21/200] [Batch 619/637] [D loss: 0.177494] [G loss: 0.485605]\n",
      "[Epoch 21/200] [Batch 620/637] [D loss: 0.173905] [G loss: 0.533455]\n",
      "[Epoch 21/200] [Batch 621/637] [D loss: 0.166793] [G loss: 0.526563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 622/637] [D loss: 0.153896] [G loss: 0.550961]\n",
      "[Epoch 21/200] [Batch 623/637] [D loss: 0.174126] [G loss: 0.553705]\n",
      "[Epoch 21/200] [Batch 624/637] [D loss: 0.143648] [G loss: 0.664199]\n",
      "[Epoch 21/200] [Batch 625/637] [D loss: 0.146528] [G loss: 0.556780]\n",
      "[Epoch 21/200] [Batch 626/637] [D loss: 0.157949] [G loss: 0.505331]\n",
      "[Epoch 21/200] [Batch 627/637] [D loss: 0.145990] [G loss: 0.496358]\n",
      "[Epoch 21/200] [Batch 628/637] [D loss: 0.127805] [G loss: 0.643300]\n",
      "[Epoch 21/200] [Batch 629/637] [D loss: 0.144688] [G loss: 0.561975]\n",
      "[Epoch 21/200] [Batch 630/637] [D loss: 0.184459] [G loss: 0.486199]\n",
      "[Epoch 21/200] [Batch 631/637] [D loss: 0.137459] [G loss: 0.584681]\n",
      "[Epoch 21/200] [Batch 632/637] [D loss: 0.164253] [G loss: 0.559332]\n",
      "[Epoch 21/200] [Batch 633/637] [D loss: 0.161973] [G loss: 0.549007]\n",
      "[Epoch 21/200] [Batch 634/637] [D loss: 0.178833] [G loss: 0.484392]\n",
      "[Epoch 21/200] [Batch 635/637] [D loss: 0.168416] [G loss: 0.527551]\n",
      "[Epoch 21/200] [Batch 636/637] [D loss: 0.202630] [G loss: 0.405430]\n",
      "[Epoch 22/200] [Batch 0/637] [D loss: 0.167087] [G loss: 0.568644]\n",
      "[Epoch 22/200] [Batch 1/637] [D loss: 0.163707] [G loss: 0.607053]\n",
      "[Epoch 22/200] [Batch 2/637] [D loss: 0.199391] [G loss: 0.486990]\n",
      "[Epoch 22/200] [Batch 3/637] [D loss: 0.168539] [G loss: 0.530037]\n",
      "[Epoch 22/200] [Batch 4/637] [D loss: 0.165823] [G loss: 0.465025]\n",
      "[Epoch 22/200] [Batch 5/637] [D loss: 0.163734] [G loss: 0.458228]\n",
      "[Epoch 22/200] [Batch 6/637] [D loss: 0.175827] [G loss: 0.504549]\n",
      "[Epoch 22/200] [Batch 7/637] [D loss: 0.145716] [G loss: 0.542879]\n",
      "[Epoch 22/200] [Batch 8/637] [D loss: 0.157372] [G loss: 0.601076]\n",
      "[Epoch 22/200] [Batch 9/637] [D loss: 0.162134] [G loss: 0.481983]\n",
      "[Epoch 22/200] [Batch 10/637] [D loss: 0.159210] [G loss: 0.513491]\n",
      "[Epoch 22/200] [Batch 11/637] [D loss: 0.144812] [G loss: 0.521375]\n",
      "[Epoch 22/200] [Batch 12/637] [D loss: 0.137038] [G loss: 0.555671]\n",
      "[Epoch 22/200] [Batch 13/637] [D loss: 0.128173] [G loss: 0.581871]\n",
      "[Epoch 22/200] [Batch 14/637] [D loss: 0.151562] [G loss: 0.528520]\n",
      "[Epoch 22/200] [Batch 15/637] [D loss: 0.141580] [G loss: 0.561632]\n",
      "[Epoch 22/200] [Batch 16/637] [D loss: 0.152889] [G loss: 0.545854]\n",
      "[Epoch 22/200] [Batch 17/637] [D loss: 0.190587] [G loss: 0.457324]\n",
      "[Epoch 22/200] [Batch 18/637] [D loss: 0.253066] [G loss: 0.471183]\n",
      "[Epoch 22/200] [Batch 19/637] [D loss: 0.186306] [G loss: 0.525039]\n",
      "[Epoch 22/200] [Batch 20/637] [D loss: 0.169958] [G loss: 0.519369]\n",
      "[Epoch 22/200] [Batch 21/637] [D loss: 0.173886] [G loss: 0.473230]\n",
      "[Epoch 22/200] [Batch 22/637] [D loss: 0.174042] [G loss: 0.569091]\n",
      "[Epoch 22/200] [Batch 23/637] [D loss: 0.182186] [G loss: 0.565302]\n",
      "[Epoch 22/200] [Batch 24/637] [D loss: 0.160112] [G loss: 0.568695]\n",
      "[Epoch 22/200] [Batch 25/637] [D loss: 0.161083] [G loss: 0.510970]\n",
      "[Epoch 22/200] [Batch 26/637] [D loss: 0.160444] [G loss: 0.484213]\n",
      "[Epoch 22/200] [Batch 27/637] [D loss: 0.168157] [G loss: 0.497428]\n",
      "[Epoch 22/200] [Batch 28/637] [D loss: 0.153075] [G loss: 0.565024]\n",
      "[Epoch 22/200] [Batch 29/637] [D loss: 0.178852] [G loss: 0.497016]\n",
      "[Epoch 22/200] [Batch 30/637] [D loss: 0.181653] [G loss: 0.354074]\n",
      "[Epoch 22/200] [Batch 31/637] [D loss: 0.165497] [G loss: 0.451791]\n",
      "[Epoch 22/200] [Batch 32/637] [D loss: 0.162462] [G loss: 0.544595]\n",
      "[Epoch 22/200] [Batch 33/637] [D loss: 0.180781] [G loss: 0.507915]\n",
      "[Epoch 22/200] [Batch 34/637] [D loss: 0.169986] [G loss: 0.454124]\n",
      "[Epoch 22/200] [Batch 35/637] [D loss: 0.159136] [G loss: 0.451384]\n",
      "[Epoch 22/200] [Batch 36/637] [D loss: 0.153823] [G loss: 0.497689]\n",
      "[Epoch 22/200] [Batch 37/637] [D loss: 0.175021] [G loss: 0.452220]\n",
      "[Epoch 22/200] [Batch 38/637] [D loss: 0.175493] [G loss: 0.509275]\n",
      "[Epoch 22/200] [Batch 39/637] [D loss: 0.157616] [G loss: 0.486722]\n",
      "[Epoch 22/200] [Batch 40/637] [D loss: 0.155584] [G loss: 0.526265]\n",
      "[Epoch 22/200] [Batch 41/637] [D loss: 0.174595] [G loss: 0.511587]\n",
      "[Epoch 22/200] [Batch 42/637] [D loss: 0.176364] [G loss: 0.468512]\n",
      "[Epoch 22/200] [Batch 43/637] [D loss: 0.164654] [G loss: 0.425902]\n",
      "[Epoch 22/200] [Batch 44/637] [D loss: 0.143472] [G loss: 0.497126]\n",
      "[Epoch 22/200] [Batch 45/637] [D loss: 0.149860] [G loss: 0.469564]\n",
      "[Epoch 22/200] [Batch 46/637] [D loss: 0.158795] [G loss: 0.553595]\n",
      "[Epoch 22/200] [Batch 47/637] [D loss: 0.169418] [G loss: 0.540204]\n",
      "[Epoch 22/200] [Batch 48/637] [D loss: 0.149702] [G loss: 0.534884]\n",
      "[Epoch 22/200] [Batch 49/637] [D loss: 0.163258] [G loss: 0.525073]\n",
      "[Epoch 22/200] [Batch 50/637] [D loss: 0.147317] [G loss: 0.499209]\n",
      "[Epoch 22/200] [Batch 51/637] [D loss: 0.143707] [G loss: 0.531079]\n",
      "[Epoch 22/200] [Batch 52/637] [D loss: 0.181741] [G loss: 0.421337]\n",
      "[Epoch 22/200] [Batch 53/637] [D loss: 0.172522] [G loss: 0.485141]\n",
      "[Epoch 22/200] [Batch 54/637] [D loss: 0.165549] [G loss: 0.536427]\n",
      "[Epoch 22/200] [Batch 55/637] [D loss: 0.152371] [G loss: 0.507166]\n",
      "[Epoch 22/200] [Batch 56/637] [D loss: 0.179673] [G loss: 0.527746]\n",
      "[Epoch 22/200] [Batch 57/637] [D loss: 0.171383] [G loss: 0.532492]\n",
      "[Epoch 22/200] [Batch 58/637] [D loss: 0.161503] [G loss: 0.495752]\n",
      "[Epoch 22/200] [Batch 59/637] [D loss: 0.143472] [G loss: 0.496568]\n",
      "[Epoch 22/200] [Batch 60/637] [D loss: 0.161297] [G loss: 0.442901]\n",
      "[Epoch 22/200] [Batch 61/637] [D loss: 0.142094] [G loss: 0.534955]\n",
      "[Epoch 22/200] [Batch 62/637] [D loss: 0.167200] [G loss: 0.531739]\n",
      "[Epoch 22/200] [Batch 63/637] [D loss: 0.170095] [G loss: 0.537794]\n",
      "[Epoch 22/200] [Batch 64/637] [D loss: 0.144530] [G loss: 0.521525]\n",
      "[Epoch 22/200] [Batch 65/637] [D loss: 0.174908] [G loss: 0.519330]\n",
      "[Epoch 22/200] [Batch 66/637] [D loss: 0.158467] [G loss: 0.560801]\n",
      "[Epoch 22/200] [Batch 67/637] [D loss: 0.172940] [G loss: 0.516737]\n",
      "[Epoch 22/200] [Batch 68/637] [D loss: 0.157578] [G loss: 0.469074]\n",
      "[Epoch 22/200] [Batch 69/637] [D loss: 0.166498] [G loss: 0.520244]\n",
      "[Epoch 22/200] [Batch 70/637] [D loss: 0.162443] [G loss: 0.516275]\n",
      "[Epoch 22/200] [Batch 71/637] [D loss: 0.170305] [G loss: 0.570235]\n",
      "[Epoch 22/200] [Batch 72/637] [D loss: 0.136195] [G loss: 0.557839]\n",
      "[Epoch 22/200] [Batch 73/637] [D loss: 0.172241] [G loss: 0.508449]\n",
      "[Epoch 22/200] [Batch 74/637] [D loss: 0.152635] [G loss: 0.512529]\n",
      "[Epoch 22/200] [Batch 75/637] [D loss: 0.166813] [G loss: 0.486731]\n",
      "[Epoch 22/200] [Batch 76/637] [D loss: 0.191824] [G loss: 0.462215]\n",
      "[Epoch 22/200] [Batch 77/637] [D loss: 0.174180] [G loss: 0.523877]\n",
      "[Epoch 22/200] [Batch 78/637] [D loss: 0.163672] [G loss: 0.530613]\n",
      "[Epoch 22/200] [Batch 79/637] [D loss: 0.159554] [G loss: 0.501179]\n",
      "[Epoch 22/200] [Batch 80/637] [D loss: 0.169799] [G loss: 0.470468]\n",
      "[Epoch 22/200] [Batch 81/637] [D loss: 0.176105] [G loss: 0.378661]\n",
      "[Epoch 22/200] [Batch 82/637] [D loss: 0.164012] [G loss: 0.503428]\n",
      "[Epoch 22/200] [Batch 83/637] [D loss: 0.170758] [G loss: 0.480715]\n",
      "[Epoch 22/200] [Batch 84/637] [D loss: 0.165345] [G loss: 0.459825]\n",
      "[Epoch 22/200] [Batch 85/637] [D loss: 0.183550] [G loss: 0.442746]\n",
      "[Epoch 22/200] [Batch 86/637] [D loss: 0.167128] [G loss: 0.508804]\n",
      "[Epoch 22/200] [Batch 87/637] [D loss: 0.178119] [G loss: 0.527530]\n",
      "[Epoch 22/200] [Batch 88/637] [D loss: 0.188496] [G loss: 0.433614]\n",
      "[Epoch 22/200] [Batch 89/637] [D loss: 0.143771] [G loss: 0.507070]\n",
      "[Epoch 22/200] [Batch 90/637] [D loss: 0.124193] [G loss: 0.505665]\n",
      "[Epoch 22/200] [Batch 91/637] [D loss: 0.141209] [G loss: 0.633439]\n",
      "[Epoch 22/200] [Batch 92/637] [D loss: 0.198368] [G loss: 0.455161]\n",
      "[Epoch 22/200] [Batch 93/637] [D loss: 0.155150] [G loss: 0.482881]\n",
      "[Epoch 22/200] [Batch 94/637] [D loss: 0.155786] [G loss: 0.534311]\n",
      "[Epoch 22/200] [Batch 95/637] [D loss: 0.170630] [G loss: 0.481966]\n",
      "[Epoch 22/200] [Batch 96/637] [D loss: 0.171886] [G loss: 0.451962]\n",
      "[Epoch 22/200] [Batch 97/637] [D loss: 0.148971] [G loss: 0.552898]\n",
      "[Epoch 22/200] [Batch 98/637] [D loss: 0.166709] [G loss: 0.467128]\n",
      "[Epoch 22/200] [Batch 99/637] [D loss: 0.169553] [G loss: 0.506470]\n",
      "[Epoch 22/200] [Batch 100/637] [D loss: 0.154079] [G loss: 0.542989]\n",
      "[Epoch 22/200] [Batch 101/637] [D loss: 0.174573] [G loss: 0.543782]\n",
      "[Epoch 22/200] [Batch 102/637] [D loss: 0.149757] [G loss: 0.578486]\n",
      "[Epoch 22/200] [Batch 103/637] [D loss: 0.147790] [G loss: 0.529532]\n",
      "[Epoch 22/200] [Batch 104/637] [D loss: 0.163509] [G loss: 0.477099]\n",
      "[Epoch 22/200] [Batch 105/637] [D loss: 0.175318] [G loss: 0.487967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/200] [Batch 106/637] [D loss: 0.155301] [G loss: 0.557796]\n",
      "[Epoch 22/200] [Batch 107/637] [D loss: 0.151182] [G loss: 0.524646]\n",
      "[Epoch 22/200] [Batch 108/637] [D loss: 0.152918] [G loss: 0.532408]\n",
      "[Epoch 22/200] [Batch 109/637] [D loss: 0.145507] [G loss: 0.512204]\n",
      "[Epoch 22/200] [Batch 110/637] [D loss: 0.149504] [G loss: 0.538590]\n",
      "[Epoch 22/200] [Batch 111/637] [D loss: 0.167429] [G loss: 0.469605]\n",
      "[Epoch 22/200] [Batch 112/637] [D loss: 0.160174] [G loss: 0.514729]\n",
      "[Epoch 22/200] [Batch 113/637] [D loss: 0.157664] [G loss: 0.505025]\n",
      "[Epoch 22/200] [Batch 114/637] [D loss: 0.158200] [G loss: 0.493318]\n",
      "[Epoch 22/200] [Batch 115/637] [D loss: 0.132571] [G loss: 0.552100]\n",
      "[Epoch 22/200] [Batch 116/637] [D loss: 0.152588] [G loss: 0.520283]\n",
      "[Epoch 22/200] [Batch 117/637] [D loss: 0.161293] [G loss: 0.440406]\n",
      "[Epoch 22/200] [Batch 118/637] [D loss: 0.179959] [G loss: 0.494550]\n",
      "[Epoch 22/200] [Batch 119/637] [D loss: 0.174940] [G loss: 0.489489]\n",
      "[Epoch 22/200] [Batch 120/637] [D loss: 0.181837] [G loss: 0.512010]\n",
      "[Epoch 22/200] [Batch 121/637] [D loss: 0.174223] [G loss: 0.518766]\n",
      "[Epoch 22/200] [Batch 122/637] [D loss: 0.156717] [G loss: 0.531951]\n",
      "[Epoch 22/200] [Batch 123/637] [D loss: 0.163054] [G loss: 0.503366]\n",
      "[Epoch 22/200] [Batch 124/637] [D loss: 0.155325] [G loss: 0.565095]\n",
      "[Epoch 22/200] [Batch 125/637] [D loss: 0.167558] [G loss: 0.648898]\n",
      "[Epoch 22/200] [Batch 126/637] [D loss: 0.176710] [G loss: 0.433656]\n",
      "[Epoch 22/200] [Batch 127/637] [D loss: 0.172495] [G loss: 0.470169]\n",
      "[Epoch 22/200] [Batch 128/637] [D loss: 0.152127] [G loss: 0.492441]\n",
      "[Epoch 22/200] [Batch 129/637] [D loss: 0.166771] [G loss: 0.548162]\n",
      "[Epoch 22/200] [Batch 130/637] [D loss: 0.158853] [G loss: 0.536841]\n",
      "[Epoch 22/200] [Batch 131/637] [D loss: 0.157210] [G loss: 0.496560]\n",
      "[Epoch 22/200] [Batch 132/637] [D loss: 0.176611] [G loss: 0.530428]\n",
      "[Epoch 22/200] [Batch 133/637] [D loss: 0.172888] [G loss: 0.502635]\n",
      "[Epoch 22/200] [Batch 134/637] [D loss: 0.142747] [G loss: 0.565252]\n",
      "[Epoch 22/200] [Batch 135/637] [D loss: 0.144564] [G loss: 0.625942]\n",
      "[Epoch 22/200] [Batch 136/637] [D loss: 0.163022] [G loss: 0.526041]\n",
      "[Epoch 22/200] [Batch 137/637] [D loss: 0.217907] [G loss: 0.412427]\n",
      "[Epoch 22/200] [Batch 138/637] [D loss: 0.181260] [G loss: 0.555979]\n",
      "[Epoch 22/200] [Batch 139/637] [D loss: 0.146758] [G loss: 0.574328]\n",
      "[Epoch 22/200] [Batch 140/637] [D loss: 0.151337] [G loss: 0.577629]\n",
      "[Epoch 22/200] [Batch 141/637] [D loss: 0.145104] [G loss: 0.506219]\n",
      "[Epoch 22/200] [Batch 142/637] [D loss: 0.179303] [G loss: 0.422950]\n",
      "[Epoch 22/200] [Batch 143/637] [D loss: 0.183489] [G loss: 0.449338]\n",
      "[Epoch 22/200] [Batch 144/637] [D loss: 0.163454] [G loss: 0.543811]\n",
      "[Epoch 22/200] [Batch 145/637] [D loss: 0.167192] [G loss: 0.502166]\n",
      "[Epoch 22/200] [Batch 146/637] [D loss: 0.145656] [G loss: 0.522313]\n",
      "[Epoch 22/200] [Batch 147/637] [D loss: 0.166094] [G loss: 0.488850]\n",
      "[Epoch 22/200] [Batch 148/637] [D loss: 0.170659] [G loss: 0.508324]\n",
      "[Epoch 22/200] [Batch 149/637] [D loss: 0.140767] [G loss: 0.589728]\n",
      "[Epoch 22/200] [Batch 150/637] [D loss: 0.158577] [G loss: 0.585329]\n",
      "[Epoch 22/200] [Batch 151/637] [D loss: 0.130020] [G loss: 0.530955]\n",
      "[Epoch 22/200] [Batch 152/637] [D loss: 0.160567] [G loss: 0.464502]\n",
      "[Epoch 22/200] [Batch 153/637] [D loss: 0.141657] [G loss: 0.548964]\n",
      "[Epoch 22/200] [Batch 154/637] [D loss: 0.157908] [G loss: 0.527067]\n",
      "[Epoch 22/200] [Batch 155/637] [D loss: 0.163869] [G loss: 0.559283]\n",
      "[Epoch 22/200] [Batch 156/637] [D loss: 0.150613] [G loss: 0.493147]\n",
      "[Epoch 22/200] [Batch 157/637] [D loss: 0.195276] [G loss: 0.500848]\n",
      "[Epoch 22/200] [Batch 158/637] [D loss: 0.181539] [G loss: 0.650836]\n",
      "[Epoch 22/200] [Batch 159/637] [D loss: 0.177632] [G loss: 0.541532]\n",
      "[Epoch 22/200] [Batch 160/637] [D loss: 0.162145] [G loss: 0.495891]\n",
      "[Epoch 22/200] [Batch 161/637] [D loss: 0.180820] [G loss: 0.475829]\n",
      "[Epoch 22/200] [Batch 162/637] [D loss: 0.169729] [G loss: 0.445442]\n",
      "[Epoch 22/200] [Batch 163/637] [D loss: 0.147995] [G loss: 0.532804]\n",
      "[Epoch 22/200] [Batch 164/637] [D loss: 0.152132] [G loss: 0.572848]\n",
      "[Epoch 22/200] [Batch 165/637] [D loss: 0.141285] [G loss: 0.518851]\n",
      "[Epoch 22/200] [Batch 166/637] [D loss: 0.152467] [G loss: 0.562913]\n",
      "[Epoch 22/200] [Batch 167/637] [D loss: 0.140370] [G loss: 0.583022]\n",
      "[Epoch 22/200] [Batch 168/637] [D loss: 0.145246] [G loss: 0.534674]\n",
      "[Epoch 22/200] [Batch 169/637] [D loss: 0.137329] [G loss: 0.496860]\n",
      "[Epoch 22/200] [Batch 170/637] [D loss: 0.143583] [G loss: 0.536511]\n",
      "[Epoch 22/200] [Batch 171/637] [D loss: 0.125550] [G loss: 0.598804]\n",
      "[Epoch 22/200] [Batch 172/637] [D loss: 0.167808] [G loss: 0.485993]\n",
      "[Epoch 22/200] [Batch 173/637] [D loss: 0.173409] [G loss: 0.508615]\n",
      "[Epoch 22/200] [Batch 174/637] [D loss: 0.160301] [G loss: 0.576530]\n",
      "[Epoch 22/200] [Batch 175/637] [D loss: 0.154979] [G loss: 0.473914]\n",
      "[Epoch 22/200] [Batch 176/637] [D loss: 0.164367] [G loss: 0.553984]\n",
      "[Epoch 22/200] [Batch 177/637] [D loss: 0.216617] [G loss: 0.650971]\n",
      "[Epoch 22/200] [Batch 178/637] [D loss: 0.181758] [G loss: 0.642906]\n",
      "[Epoch 22/200] [Batch 179/637] [D loss: 0.180874] [G loss: 0.561550]\n",
      "[Epoch 22/200] [Batch 180/637] [D loss: 0.195267] [G loss: 0.508077]\n",
      "[Epoch 22/200] [Batch 181/637] [D loss: 0.160300] [G loss: 0.451725]\n",
      "[Epoch 22/200] [Batch 182/637] [D loss: 0.165096] [G loss: 0.501113]\n",
      "[Epoch 22/200] [Batch 183/637] [D loss: 0.176591] [G loss: 0.465997]\n",
      "[Epoch 22/200] [Batch 184/637] [D loss: 0.154987] [G loss: 0.525439]\n",
      "[Epoch 22/200] [Batch 185/637] [D loss: 0.172417] [G loss: 0.523021]\n",
      "[Epoch 22/200] [Batch 186/637] [D loss: 0.182949] [G loss: 0.518155]\n",
      "[Epoch 22/200] [Batch 187/637] [D loss: 0.184341] [G loss: 0.530892]\n",
      "[Epoch 22/200] [Batch 188/637] [D loss: 0.178967] [G loss: 0.483018]\n",
      "[Epoch 22/200] [Batch 189/637] [D loss: 0.170845] [G loss: 0.488498]\n",
      "[Epoch 22/200] [Batch 190/637] [D loss: 0.152367] [G loss: 0.504244]\n",
      "[Epoch 22/200] [Batch 191/637] [D loss: 0.141999] [G loss: 0.562434]\n",
      "[Epoch 22/200] [Batch 192/637] [D loss: 0.173155] [G loss: 0.511316]\n",
      "[Epoch 22/200] [Batch 193/637] [D loss: 0.143551] [G loss: 0.605781]\n",
      "[Epoch 22/200] [Batch 194/637] [D loss: 0.153628] [G loss: 0.593457]\n",
      "[Epoch 22/200] [Batch 195/637] [D loss: 0.153480] [G loss: 0.514499]\n",
      "[Epoch 22/200] [Batch 196/637] [D loss: 0.167341] [G loss: 0.540640]\n",
      "[Epoch 22/200] [Batch 197/637] [D loss: 0.154145] [G loss: 0.517922]\n",
      "[Epoch 22/200] [Batch 198/637] [D loss: 0.189057] [G loss: 0.525758]\n",
      "[Epoch 22/200] [Batch 199/637] [D loss: 0.175898] [G loss: 0.528544]\n",
      "[Epoch 22/200] [Batch 200/637] [D loss: 0.151444] [G loss: 0.530664]\n",
      "[Epoch 22/200] [Batch 201/637] [D loss: 0.163460] [G loss: 0.482959]\n",
      "[Epoch 22/200] [Batch 202/637] [D loss: 0.159789] [G loss: 0.502276]\n",
      "[Epoch 22/200] [Batch 203/637] [D loss: 0.157118] [G loss: 0.614465]\n",
      "[Epoch 22/200] [Batch 204/637] [D loss: 0.126973] [G loss: 0.530816]\n",
      "[Epoch 22/200] [Batch 205/637] [D loss: 0.177834] [G loss: 0.418451]\n",
      "[Epoch 22/200] [Batch 206/637] [D loss: 0.139381] [G loss: 0.538336]\n",
      "[Epoch 22/200] [Batch 207/637] [D loss: 0.154837] [G loss: 0.493329]\n",
      "[Epoch 22/200] [Batch 208/637] [D loss: 0.154020] [G loss: 0.482987]\n",
      "[Epoch 22/200] [Batch 209/637] [D loss: 0.189036] [G loss: 0.490333]\n",
      "[Epoch 22/200] [Batch 210/637] [D loss: 0.172566] [G loss: 0.496225]\n",
      "[Epoch 22/200] [Batch 211/637] [D loss: 0.180039] [G loss: 0.479496]\n",
      "[Epoch 22/200] [Batch 212/637] [D loss: 0.174049] [G loss: 0.450279]\n",
      "[Epoch 22/200] [Batch 213/637] [D loss: 0.151433] [G loss: 0.453890]\n",
      "[Epoch 22/200] [Batch 214/637] [D loss: 0.148348] [G loss: 0.417390]\n",
      "[Epoch 22/200] [Batch 215/637] [D loss: 0.156861] [G loss: 0.484867]\n",
      "[Epoch 22/200] [Batch 216/637] [D loss: 0.172031] [G loss: 0.567540]\n",
      "[Epoch 22/200] [Batch 217/637] [D loss: 0.149187] [G loss: 0.446637]\n",
      "[Epoch 22/200] [Batch 218/637] [D loss: 0.173751] [G loss: 0.490997]\n",
      "[Epoch 22/200] [Batch 219/637] [D loss: 0.134494] [G loss: 0.509495]\n",
      "[Epoch 22/200] [Batch 220/637] [D loss: 0.181559] [G loss: 0.491396]\n",
      "[Epoch 22/200] [Batch 221/637] [D loss: 0.154772] [G loss: 0.516727]\n",
      "[Epoch 22/200] [Batch 222/637] [D loss: 0.162990] [G loss: 0.511386]\n",
      "[Epoch 22/200] [Batch 223/637] [D loss: 0.160307] [G loss: 0.558113]\n",
      "[Epoch 22/200] [Batch 224/637] [D loss: 0.172502] [G loss: 0.485907]\n",
      "[Epoch 22/200] [Batch 225/637] [D loss: 0.168504] [G loss: 0.475234]\n",
      "[Epoch 22/200] [Batch 226/637] [D loss: 0.155945] [G loss: 0.543397]\n",
      "[Epoch 22/200] [Batch 227/637] [D loss: 0.170357] [G loss: 0.552664]\n",
      "[Epoch 22/200] [Batch 228/637] [D loss: 0.161144] [G loss: 0.458031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/200] [Batch 229/637] [D loss: 0.162165] [G loss: 0.439059]\n",
      "[Epoch 22/200] [Batch 230/637] [D loss: 0.168279] [G loss: 0.436167]\n",
      "[Epoch 22/200] [Batch 231/637] [D loss: 0.156291] [G loss: 0.525746]\n",
      "[Epoch 22/200] [Batch 232/637] [D loss: 0.155017] [G loss: 0.491023]\n",
      "[Epoch 22/200] [Batch 233/637] [D loss: 0.166247] [G loss: 0.500389]\n",
      "[Epoch 22/200] [Batch 234/637] [D loss: 0.169097] [G loss: 0.507927]\n",
      "[Epoch 22/200] [Batch 235/637] [D loss: 0.158283] [G loss: 0.525995]\n",
      "[Epoch 22/200] [Batch 236/637] [D loss: 0.186002] [G loss: 0.491265]\n",
      "[Epoch 22/200] [Batch 237/637] [D loss: 0.182501] [G loss: 0.405993]\n",
      "[Epoch 22/200] [Batch 238/637] [D loss: 0.170405] [G loss: 0.488838]\n",
      "[Epoch 22/200] [Batch 239/637] [D loss: 0.158903] [G loss: 0.539672]\n",
      "[Epoch 22/200] [Batch 240/637] [D loss: 0.187899] [G loss: 0.503519]\n",
      "[Epoch 22/200] [Batch 241/637] [D loss: 0.181961] [G loss: 0.554613]\n",
      "[Epoch 22/200] [Batch 242/637] [D loss: 0.162199] [G loss: 0.521232]\n",
      "[Epoch 22/200] [Batch 243/637] [D loss: 0.165074] [G loss: 0.497055]\n",
      "[Epoch 22/200] [Batch 244/637] [D loss: 0.143729] [G loss: 0.462243]\n",
      "[Epoch 22/200] [Batch 245/637] [D loss: 0.158106] [G loss: 0.513233]\n",
      "[Epoch 22/200] [Batch 246/637] [D loss: 0.166982] [G loss: 0.565844]\n",
      "[Epoch 22/200] [Batch 247/637] [D loss: 0.154964] [G loss: 0.605844]\n",
      "[Epoch 22/200] [Batch 248/637] [D loss: 0.136791] [G loss: 0.586802]\n",
      "[Epoch 22/200] [Batch 249/637] [D loss: 0.139818] [G loss: 0.524947]\n",
      "[Epoch 22/200] [Batch 250/637] [D loss: 0.196930] [G loss: 0.421991]\n",
      "[Epoch 22/200] [Batch 251/637] [D loss: 0.167236] [G loss: 0.563248]\n",
      "[Epoch 22/200] [Batch 252/637] [D loss: 0.176170] [G loss: 0.582601]\n",
      "[Epoch 22/200] [Batch 253/637] [D loss: 0.140516] [G loss: 0.536396]\n",
      "[Epoch 22/200] [Batch 254/637] [D loss: 0.161221] [G loss: 0.467497]\n",
      "[Epoch 22/200] [Batch 255/637] [D loss: 0.171228] [G loss: 0.471727]\n",
      "[Epoch 22/200] [Batch 256/637] [D loss: 0.158590] [G loss: 0.505882]\n",
      "[Epoch 22/200] [Batch 257/637] [D loss: 0.169101] [G loss: 0.482375]\n",
      "[Epoch 22/200] [Batch 258/637] [D loss: 0.175999] [G loss: 0.461741]\n",
      "[Epoch 22/200] [Batch 259/637] [D loss: 0.159786] [G loss: 0.527552]\n",
      "[Epoch 22/200] [Batch 260/637] [D loss: 0.164692] [G loss: 0.490611]\n",
      "[Epoch 22/200] [Batch 261/637] [D loss: 0.172337] [G loss: 0.456805]\n",
      "[Epoch 22/200] [Batch 262/637] [D loss: 0.189475] [G loss: 0.432917]\n",
      "[Epoch 22/200] [Batch 263/637] [D loss: 0.171892] [G loss: 0.439741]\n",
      "[Epoch 22/200] [Batch 264/637] [D loss: 0.166999] [G loss: 0.483390]\n",
      "[Epoch 22/200] [Batch 265/637] [D loss: 0.166138] [G loss: 0.439899]\n",
      "[Epoch 22/200] [Batch 266/637] [D loss: 0.158216] [G loss: 0.509538]\n",
      "[Epoch 22/200] [Batch 267/637] [D loss: 0.194296] [G loss: 0.504811]\n",
      "[Epoch 22/200] [Batch 268/637] [D loss: 0.202715] [G loss: 0.536891]\n",
      "[Epoch 22/200] [Batch 269/637] [D loss: 0.153570] [G loss: 0.495584]\n",
      "[Epoch 22/200] [Batch 270/637] [D loss: 0.165473] [G loss: 0.437530]\n",
      "[Epoch 22/200] [Batch 271/637] [D loss: 0.173495] [G loss: 0.460919]\n",
      "[Epoch 22/200] [Batch 272/637] [D loss: 0.139242] [G loss: 0.547395]\n",
      "[Epoch 22/200] [Batch 273/637] [D loss: 0.147233] [G loss: 0.525188]\n",
      "[Epoch 22/200] [Batch 274/637] [D loss: 0.133806] [G loss: 0.529013]\n",
      "[Epoch 22/200] [Batch 275/637] [D loss: 0.185708] [G loss: 0.436766]\n",
      "[Epoch 22/200] [Batch 276/637] [D loss: 0.215261] [G loss: 0.533739]\n",
      "[Epoch 22/200] [Batch 277/637] [D loss: 0.150161] [G loss: 0.573578]\n",
      "[Epoch 22/200] [Batch 278/637] [D loss: 0.169739] [G loss: 0.509565]\n",
      "[Epoch 22/200] [Batch 279/637] [D loss: 0.165884] [G loss: 0.409468]\n",
      "[Epoch 22/200] [Batch 280/637] [D loss: 0.163353] [G loss: 0.414279]\n",
      "[Epoch 22/200] [Batch 281/637] [D loss: 0.160958] [G loss: 0.588217]\n",
      "[Epoch 22/200] [Batch 282/637] [D loss: 0.158172] [G loss: 0.554830]\n",
      "[Epoch 22/200] [Batch 283/637] [D loss: 0.152743] [G loss: 0.508735]\n",
      "[Epoch 22/200] [Batch 284/637] [D loss: 0.175070] [G loss: 0.443357]\n",
      "[Epoch 22/200] [Batch 285/637] [D loss: 0.175763] [G loss: 0.492956]\n",
      "[Epoch 22/200] [Batch 286/637] [D loss: 0.178354] [G loss: 0.463370]\n",
      "[Epoch 22/200] [Batch 287/637] [D loss: 0.153381] [G loss: 0.506386]\n",
      "[Epoch 22/200] [Batch 288/637] [D loss: 0.165808] [G loss: 0.543315]\n",
      "[Epoch 22/200] [Batch 289/637] [D loss: 0.195765] [G loss: 0.488208]\n",
      "[Epoch 22/200] [Batch 290/637] [D loss: 0.175061] [G loss: 0.516170]\n",
      "[Epoch 22/200] [Batch 291/637] [D loss: 0.168558] [G loss: 0.493851]\n",
      "[Epoch 22/200] [Batch 292/637] [D loss: 0.173007] [G loss: 0.491615]\n",
      "[Epoch 22/200] [Batch 293/637] [D loss: 0.178293] [G loss: 0.559225]\n",
      "[Epoch 22/200] [Batch 294/637] [D loss: 0.160642] [G loss: 0.474915]\n",
      "[Epoch 22/200] [Batch 295/637] [D loss: 0.201612] [G loss: 0.478304]\n",
      "[Epoch 22/200] [Batch 296/637] [D loss: 0.166011] [G loss: 0.479175]\n",
      "[Epoch 22/200] [Batch 297/637] [D loss: 0.172231] [G loss: 0.572222]\n",
      "[Epoch 22/200] [Batch 298/637] [D loss: 0.145052] [G loss: 0.504226]\n",
      "[Epoch 22/200] [Batch 299/637] [D loss: 0.205621] [G loss: 0.420284]\n",
      "[Epoch 22/200] [Batch 300/637] [D loss: 0.210598] [G loss: 0.535696]\n",
      "[Epoch 22/200] [Batch 301/637] [D loss: 0.168796] [G loss: 0.518255]\n",
      "[Epoch 22/200] [Batch 302/637] [D loss: 0.172561] [G loss: 0.536892]\n",
      "[Epoch 22/200] [Batch 303/637] [D loss: 0.156885] [G loss: 0.553519]\n",
      "[Epoch 22/200] [Batch 304/637] [D loss: 0.164770] [G loss: 0.518336]\n",
      "[Epoch 22/200] [Batch 305/637] [D loss: 0.153905] [G loss: 0.487758]\n",
      "[Epoch 22/200] [Batch 306/637] [D loss: 0.154257] [G loss: 0.491233]\n",
      "[Epoch 22/200] [Batch 307/637] [D loss: 0.179595] [G loss: 0.528573]\n",
      "[Epoch 22/200] [Batch 308/637] [D loss: 0.145977] [G loss: 0.583021]\n",
      "[Epoch 22/200] [Batch 309/637] [D loss: 0.146736] [G loss: 0.551128]\n",
      "[Epoch 22/200] [Batch 310/637] [D loss: 0.155055] [G loss: 0.510996]\n",
      "[Epoch 22/200] [Batch 311/637] [D loss: 0.169543] [G loss: 0.505528]\n",
      "[Epoch 22/200] [Batch 312/637] [D loss: 0.129002] [G loss: 0.500392]\n",
      "[Epoch 22/200] [Batch 313/637] [D loss: 0.150620] [G loss: 0.503593]\n",
      "[Epoch 22/200] [Batch 314/637] [D loss: 0.165922] [G loss: 0.539492]\n",
      "[Epoch 22/200] [Batch 315/637] [D loss: 0.137827] [G loss: 0.546491]\n",
      "[Epoch 22/200] [Batch 316/637] [D loss: 0.160643] [G loss: 0.504649]\n",
      "[Epoch 22/200] [Batch 317/637] [D loss: 0.153390] [G loss: 0.507153]\n",
      "[Epoch 22/200] [Batch 318/637] [D loss: 0.137479] [G loss: 0.640078]\n",
      "[Epoch 22/200] [Batch 319/637] [D loss: 0.177466] [G loss: 0.434691]\n",
      "[Epoch 22/200] [Batch 320/637] [D loss: 0.144370] [G loss: 0.551718]\n",
      "[Epoch 22/200] [Batch 321/637] [D loss: 0.162378] [G loss: 0.475143]\n",
      "[Epoch 22/200] [Batch 322/637] [D loss: 0.165874] [G loss: 0.475312]\n",
      "[Epoch 22/200] [Batch 323/637] [D loss: 0.181994] [G loss: 0.483632]\n",
      "[Epoch 22/200] [Batch 324/637] [D loss: 0.171937] [G loss: 0.473814]\n",
      "[Epoch 22/200] [Batch 325/637] [D loss: 0.175577] [G loss: 0.493989]\n",
      "[Epoch 22/200] [Batch 326/637] [D loss: 0.194066] [G loss: 0.513447]\n",
      "[Epoch 22/200] [Batch 327/637] [D loss: 0.189693] [G loss: 0.450496]\n",
      "[Epoch 22/200] [Batch 328/637] [D loss: 0.199294] [G loss: 0.436181]\n",
      "[Epoch 22/200] [Batch 329/637] [D loss: 0.170911] [G loss: 0.583615]\n",
      "[Epoch 22/200] [Batch 330/637] [D loss: 0.200834] [G loss: 0.437695]\n",
      "[Epoch 22/200] [Batch 331/637] [D loss: 0.174678] [G loss: 0.476377]\n",
      "[Epoch 22/200] [Batch 332/637] [D loss: 0.170010] [G loss: 0.446184]\n",
      "[Epoch 22/200] [Batch 333/637] [D loss: 0.172616] [G loss: 0.447662]\n",
      "[Epoch 22/200] [Batch 334/637] [D loss: 0.155842] [G loss: 0.571197]\n",
      "[Epoch 22/200] [Batch 335/637] [D loss: 0.150383] [G loss: 0.554952]\n",
      "[Epoch 22/200] [Batch 336/637] [D loss: 0.157004] [G loss: 0.482456]\n",
      "[Epoch 22/200] [Batch 337/637] [D loss: 0.156578] [G loss: 0.483726]\n",
      "[Epoch 22/200] [Batch 338/637] [D loss: 0.163604] [G loss: 0.490162]\n",
      "[Epoch 22/200] [Batch 339/637] [D loss: 0.178457] [G loss: 0.532330]\n",
      "[Epoch 22/200] [Batch 340/637] [D loss: 0.141212] [G loss: 0.545844]\n",
      "[Epoch 22/200] [Batch 341/637] [D loss: 0.165371] [G loss: 0.535482]\n",
      "[Epoch 22/200] [Batch 342/637] [D loss: 0.146047] [G loss: 0.494838]\n",
      "[Epoch 22/200] [Batch 343/637] [D loss: 0.138524] [G loss: 0.520986]\n",
      "[Epoch 22/200] [Batch 344/637] [D loss: 0.179878] [G loss: 0.474471]\n",
      "[Epoch 22/200] [Batch 345/637] [D loss: 0.145792] [G loss: 0.575857]\n",
      "[Epoch 22/200] [Batch 346/637] [D loss: 0.167882] [G loss: 0.543254]\n",
      "[Epoch 22/200] [Batch 347/637] [D loss: 0.160250] [G loss: 0.481894]\n",
      "[Epoch 22/200] [Batch 348/637] [D loss: 0.165276] [G loss: 0.468805]\n",
      "[Epoch 22/200] [Batch 349/637] [D loss: 0.151912] [G loss: 0.527547]\n",
      "[Epoch 22/200] [Batch 350/637] [D loss: 0.156685] [G loss: 0.574110]\n",
      "[Epoch 22/200] [Batch 351/637] [D loss: 0.160724] [G loss: 0.522463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/200] [Batch 352/637] [D loss: 0.174673] [G loss: 0.530806]\n",
      "[Epoch 22/200] [Batch 353/637] [D loss: 0.171869] [G loss: 0.535574]\n",
      "[Epoch 22/200] [Batch 354/637] [D loss: 0.158130] [G loss: 0.521956]\n",
      "[Epoch 22/200] [Batch 355/637] [D loss: 0.166008] [G loss: 0.533912]\n",
      "[Epoch 22/200] [Batch 356/637] [D loss: 0.164428] [G loss: 0.552317]\n",
      "[Epoch 22/200] [Batch 357/637] [D loss: 0.169165] [G loss: 0.487296]\n",
      "[Epoch 22/200] [Batch 358/637] [D loss: 0.164191] [G loss: 0.618691]\n",
      "[Epoch 22/200] [Batch 359/637] [D loss: 0.159642] [G loss: 0.585456]\n",
      "[Epoch 22/200] [Batch 360/637] [D loss: 0.173283] [G loss: 0.548075]\n",
      "[Epoch 22/200] [Batch 361/637] [D loss: 0.141111] [G loss: 0.464923]\n",
      "[Epoch 22/200] [Batch 362/637] [D loss: 0.155223] [G loss: 0.528267]\n",
      "[Epoch 22/200] [Batch 363/637] [D loss: 0.139629] [G loss: 0.529905]\n",
      "[Epoch 22/200] [Batch 364/637] [D loss: 0.221543] [G loss: 0.464290]\n",
      "[Epoch 22/200] [Batch 365/637] [D loss: 0.156938] [G loss: 0.532338]\n",
      "[Epoch 22/200] [Batch 366/637] [D loss: 0.204547] [G loss: 0.513297]\n",
      "[Epoch 22/200] [Batch 367/637] [D loss: 0.145121] [G loss: 0.614676]\n",
      "[Epoch 22/200] [Batch 368/637] [D loss: 0.168262] [G loss: 0.550110]\n",
      "[Epoch 22/200] [Batch 369/637] [D loss: 0.176928] [G loss: 0.449955]\n",
      "[Epoch 22/200] [Batch 370/637] [D loss: 0.170482] [G loss: 0.517005]\n",
      "[Epoch 22/200] [Batch 371/637] [D loss: 0.175752] [G loss: 0.419130]\n",
      "[Epoch 22/200] [Batch 372/637] [D loss: 0.180025] [G loss: 0.516614]\n",
      "[Epoch 22/200] [Batch 373/637] [D loss: 0.173597] [G loss: 0.512770]\n",
      "[Epoch 22/200] [Batch 374/637] [D loss: 0.142875] [G loss: 0.554785]\n",
      "[Epoch 22/200] [Batch 375/637] [D loss: 0.179015] [G loss: 0.450153]\n",
      "[Epoch 22/200] [Batch 376/637] [D loss: 0.179251] [G loss: 0.432221]\n",
      "[Epoch 22/200] [Batch 377/637] [D loss: 0.156028] [G loss: 0.491917]\n",
      "[Epoch 22/200] [Batch 378/637] [D loss: 0.165346] [G loss: 0.490907]\n",
      "[Epoch 22/200] [Batch 379/637] [D loss: 0.162597] [G loss: 0.492121]\n",
      "[Epoch 22/200] [Batch 380/637] [D loss: 0.184264] [G loss: 0.415478]\n",
      "[Epoch 22/200] [Batch 381/637] [D loss: 0.183001] [G loss: 0.507788]\n",
      "[Epoch 22/200] [Batch 382/637] [D loss: 0.150694] [G loss: 0.501753]\n",
      "[Epoch 22/200] [Batch 383/637] [D loss: 0.165057] [G loss: 0.496170]\n",
      "[Epoch 22/200] [Batch 384/637] [D loss: 0.165174] [G loss: 0.481182]\n",
      "[Epoch 22/200] [Batch 385/637] [D loss: 0.182976] [G loss: 0.475244]\n",
      "[Epoch 22/200] [Batch 386/637] [D loss: 0.170751] [G loss: 0.521640]\n",
      "[Epoch 22/200] [Batch 387/637] [D loss: 0.179422] [G loss: 0.479856]\n",
      "[Epoch 22/200] [Batch 388/637] [D loss: 0.189752] [G loss: 0.506645]\n",
      "[Epoch 22/200] [Batch 389/637] [D loss: 0.166330] [G loss: 0.463966]\n",
      "[Epoch 22/200] [Batch 390/637] [D loss: 0.156353] [G loss: 0.498248]\n",
      "[Epoch 22/200] [Batch 391/637] [D loss: 0.185337] [G loss: 0.476889]\n",
      "[Epoch 22/200] [Batch 392/637] [D loss: 0.180312] [G loss: 0.450158]\n",
      "[Epoch 22/200] [Batch 393/637] [D loss: 0.155959] [G loss: 0.506475]\n",
      "[Epoch 22/200] [Batch 394/637] [D loss: 0.152809] [G loss: 0.530542]\n",
      "[Epoch 22/200] [Batch 395/637] [D loss: 0.166949] [G loss: 0.462323]\n",
      "[Epoch 22/200] [Batch 396/637] [D loss: 0.176954] [G loss: 0.494513]\n",
      "[Epoch 22/200] [Batch 397/637] [D loss: 0.154746] [G loss: 0.524454]\n",
      "[Epoch 22/200] [Batch 398/637] [D loss: 0.161214] [G loss: 0.534133]\n",
      "[Epoch 22/200] [Batch 399/637] [D loss: 0.169434] [G loss: 0.428886]\n",
      "[Epoch 22/200] [Batch 400/637] [D loss: 0.146208] [G loss: 0.518637]\n",
      "[Epoch 22/200] [Batch 401/637] [D loss: 0.162166] [G loss: 0.509540]\n",
      "[Epoch 22/200] [Batch 402/637] [D loss: 0.148570] [G loss: 0.473879]\n",
      "[Epoch 22/200] [Batch 403/637] [D loss: 0.167086] [G loss: 0.510155]\n",
      "[Epoch 22/200] [Batch 404/637] [D loss: 0.141990] [G loss: 0.553175]\n",
      "[Epoch 22/200] [Batch 405/637] [D loss: 0.153344] [G loss: 0.529039]\n",
      "[Epoch 22/200] [Batch 406/637] [D loss: 0.162318] [G loss: 0.520533]\n",
      "[Epoch 22/200] [Batch 407/637] [D loss: 0.165421] [G loss: 0.479747]\n",
      "[Epoch 22/200] [Batch 408/637] [D loss: 0.149370] [G loss: 0.477755]\n",
      "[Epoch 22/200] [Batch 409/637] [D loss: 0.150023] [G loss: 0.488065]\n",
      "[Epoch 22/200] [Batch 410/637] [D loss: 0.143566] [G loss: 0.551908]\n",
      "[Epoch 22/200] [Batch 411/637] [D loss: 0.162495] [G loss: 0.491298]\n",
      "[Epoch 22/200] [Batch 412/637] [D loss: 0.183674] [G loss: 0.469733]\n",
      "[Epoch 22/200] [Batch 413/637] [D loss: 0.168979] [G loss: 0.481098]\n",
      "[Epoch 22/200] [Batch 414/637] [D loss: 0.125514] [G loss: 0.518318]\n",
      "[Epoch 22/200] [Batch 415/637] [D loss: 0.150736] [G loss: 0.538276]\n",
      "[Epoch 22/200] [Batch 416/637] [D loss: 0.191329] [G loss: 0.458844]\n",
      "[Epoch 22/200] [Batch 417/637] [D loss: 0.152414] [G loss: 0.507782]\n",
      "[Epoch 22/200] [Batch 418/637] [D loss: 0.181835] [G loss: 0.463621]\n",
      "[Epoch 22/200] [Batch 419/637] [D loss: 0.161552] [G loss: 0.516150]\n",
      "[Epoch 22/200] [Batch 420/637] [D loss: 0.146281] [G loss: 0.491967]\n",
      "[Epoch 22/200] [Batch 421/637] [D loss: 0.146686] [G loss: 0.471596]\n",
      "[Epoch 22/200] [Batch 422/637] [D loss: 0.159063] [G loss: 0.490848]\n",
      "[Epoch 22/200] [Batch 423/637] [D loss: 0.166064] [G loss: 0.517463]\n",
      "[Epoch 22/200] [Batch 424/637] [D loss: 0.185014] [G loss: 0.443631]\n",
      "[Epoch 22/200] [Batch 425/637] [D loss: 0.157621] [G loss: 0.529989]\n",
      "[Epoch 22/200] [Batch 426/637] [D loss: 0.174363] [G loss: 0.443568]\n",
      "[Epoch 22/200] [Batch 427/637] [D loss: 0.167376] [G loss: 0.468118]\n",
      "[Epoch 22/200] [Batch 428/637] [D loss: 0.161675] [G loss: 0.506686]\n",
      "[Epoch 22/200] [Batch 429/637] [D loss: 0.161128] [G loss: 0.508302]\n",
      "[Epoch 22/200] [Batch 430/637] [D loss: 0.167156] [G loss: 0.513882]\n",
      "[Epoch 22/200] [Batch 431/637] [D loss: 0.186937] [G loss: 0.454097]\n",
      "[Epoch 22/200] [Batch 432/637] [D loss: 0.149464] [G loss: 0.584919]\n",
      "[Epoch 22/200] [Batch 433/637] [D loss: 0.154214] [G loss: 0.520349]\n",
      "[Epoch 22/200] [Batch 434/637] [D loss: 0.154220] [G loss: 0.531709]\n",
      "[Epoch 22/200] [Batch 435/637] [D loss: 0.142825] [G loss: 0.524314]\n",
      "[Epoch 22/200] [Batch 436/637] [D loss: 0.161272] [G loss: 0.468888]\n",
      "[Epoch 22/200] [Batch 437/637] [D loss: 0.195366] [G loss: 0.515282]\n",
      "[Epoch 22/200] [Batch 438/637] [D loss: 0.163461] [G loss: 0.537624]\n",
      "[Epoch 22/200] [Batch 439/637] [D loss: 0.210008] [G loss: 0.437448]\n",
      "[Epoch 22/200] [Batch 440/637] [D loss: 0.189995] [G loss: 0.480070]\n",
      "[Epoch 22/200] [Batch 441/637] [D loss: 0.185913] [G loss: 0.480699]\n",
      "[Epoch 22/200] [Batch 442/637] [D loss: 0.165734] [G loss: 0.452534]\n",
      "[Epoch 22/200] [Batch 443/637] [D loss: 0.156646] [G loss: 0.472798]\n",
      "[Epoch 22/200] [Batch 444/637] [D loss: 0.164575] [G loss: 0.507404]\n",
      "[Epoch 22/200] [Batch 445/637] [D loss: 0.170139] [G loss: 0.459322]\n",
      "[Epoch 22/200] [Batch 446/637] [D loss: 0.173073] [G loss: 0.465472]\n",
      "[Epoch 22/200] [Batch 447/637] [D loss: 0.173380] [G loss: 0.443464]\n",
      "[Epoch 22/200] [Batch 448/637] [D loss: 0.176575] [G loss: 0.489021]\n",
      "[Epoch 22/200] [Batch 449/637] [D loss: 0.162325] [G loss: 0.499455]\n",
      "[Epoch 22/200] [Batch 450/637] [D loss: 0.161558] [G loss: 0.545963]\n",
      "[Epoch 22/200] [Batch 451/637] [D loss: 0.164665] [G loss: 0.505292]\n",
      "[Epoch 22/200] [Batch 452/637] [D loss: 0.159618] [G loss: 0.511176]\n",
      "[Epoch 22/200] [Batch 453/637] [D loss: 0.167660] [G loss: 0.499367]\n",
      "[Epoch 22/200] [Batch 454/637] [D loss: 0.162435] [G loss: 0.471168]\n",
      "[Epoch 22/200] [Batch 455/637] [D loss: 0.147368] [G loss: 0.555830]\n",
      "[Epoch 22/200] [Batch 456/637] [D loss: 0.148471] [G loss: 0.547889]\n",
      "[Epoch 22/200] [Batch 457/637] [D loss: 0.161433] [G loss: 0.527764]\n",
      "[Epoch 22/200] [Batch 458/637] [D loss: 0.166989] [G loss: 0.460696]\n",
      "[Epoch 22/200] [Batch 459/637] [D loss: 0.161590] [G loss: 0.509318]\n",
      "[Epoch 22/200] [Batch 460/637] [D loss: 0.178676] [G loss: 0.476184]\n",
      "[Epoch 22/200] [Batch 461/637] [D loss: 0.159442] [G loss: 0.519169]\n",
      "[Epoch 22/200] [Batch 462/637] [D loss: 0.170625] [G loss: 0.514343]\n",
      "[Epoch 22/200] [Batch 463/637] [D loss: 0.143103] [G loss: 0.503001]\n",
      "[Epoch 22/200] [Batch 464/637] [D loss: 0.161514] [G loss: 0.490345]\n",
      "[Epoch 22/200] [Batch 465/637] [D loss: 0.180945] [G loss: 0.435531]\n",
      "[Epoch 22/200] [Batch 466/637] [D loss: 0.146189] [G loss: 0.585905]\n",
      "[Epoch 22/200] [Batch 467/637] [D loss: 0.187890] [G loss: 0.583010]\n",
      "[Epoch 22/200] [Batch 468/637] [D loss: 0.137830] [G loss: 0.511419]\n",
      "[Epoch 22/200] [Batch 469/637] [D loss: 0.142322] [G loss: 0.544996]\n",
      "[Epoch 22/200] [Batch 470/637] [D loss: 0.165684] [G loss: 0.534562]\n",
      "[Epoch 22/200] [Batch 471/637] [D loss: 0.182099] [G loss: 0.593498]\n",
      "[Epoch 22/200] [Batch 472/637] [D loss: 0.178345] [G loss: 0.482126]\n",
      "[Epoch 22/200] [Batch 473/637] [D loss: 0.158402] [G loss: 0.559500]\n",
      "[Epoch 22/200] [Batch 474/637] [D loss: 0.151486] [G loss: 0.476793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/200] [Batch 475/637] [D loss: 0.194513] [G loss: 0.482060]\n",
      "[Epoch 22/200] [Batch 476/637] [D loss: 0.169048] [G loss: 0.583013]\n",
      "[Epoch 22/200] [Batch 477/637] [D loss: 0.162347] [G loss: 0.572673]\n",
      "[Epoch 22/200] [Batch 478/637] [D loss: 0.187897] [G loss: 0.396550]\n",
      "[Epoch 22/200] [Batch 479/637] [D loss: 0.186852] [G loss: 0.458494]\n",
      "[Epoch 22/200] [Batch 480/637] [D loss: 0.142368] [G loss: 0.563543]\n",
      "[Epoch 22/200] [Batch 481/637] [D loss: 0.174889] [G loss: 0.448218]\n",
      "[Epoch 22/200] [Batch 482/637] [D loss: 0.162175] [G loss: 0.541751]\n",
      "[Epoch 22/200] [Batch 483/637] [D loss: 0.174364] [G loss: 0.519822]\n",
      "[Epoch 22/200] [Batch 484/637] [D loss: 0.179112] [G loss: 0.546531]\n",
      "[Epoch 22/200] [Batch 485/637] [D loss: 0.206282] [G loss: 0.421521]\n",
      "[Epoch 22/200] [Batch 486/637] [D loss: 0.213263] [G loss: 0.411954]\n",
      "[Epoch 22/200] [Batch 487/637] [D loss: 0.224067] [G loss: 0.653139]\n",
      "[Epoch 22/200] [Batch 488/637] [D loss: 0.190557] [G loss: 0.586018]\n",
      "[Epoch 22/200] [Batch 489/637] [D loss: 0.160500] [G loss: 0.515447]\n",
      "[Epoch 22/200] [Batch 490/637] [D loss: 0.178600] [G loss: 0.538502]\n",
      "[Epoch 22/200] [Batch 491/637] [D loss: 0.177478] [G loss: 0.515664]\n",
      "[Epoch 22/200] [Batch 492/637] [D loss: 0.159015] [G loss: 0.556500]\n",
      "[Epoch 22/200] [Batch 493/637] [D loss: 0.154025] [G loss: 0.494659]\n",
      "[Epoch 22/200] [Batch 494/637] [D loss: 0.173533] [G loss: 0.520762]\n",
      "[Epoch 22/200] [Batch 495/637] [D loss: 0.183080] [G loss: 0.441389]\n",
      "[Epoch 22/200] [Batch 496/637] [D loss: 0.155400] [G loss: 0.524545]\n",
      "[Epoch 22/200] [Batch 497/637] [D loss: 0.146933] [G loss: 0.523374]\n",
      "[Epoch 22/200] [Batch 498/637] [D loss: 0.182746] [G loss: 0.463164]\n",
      "[Epoch 22/200] [Batch 499/637] [D loss: 0.143211] [G loss: 0.586383]\n",
      "[Epoch 22/200] [Batch 500/637] [D loss: 0.168759] [G loss: 0.557650]\n",
      "[Epoch 22/200] [Batch 501/637] [D loss: 0.147655] [G loss: 0.561159]\n",
      "[Epoch 22/200] [Batch 502/637] [D loss: 0.186484] [G loss: 0.449930]\n",
      "[Epoch 22/200] [Batch 503/637] [D loss: 0.173053] [G loss: 0.521675]\n",
      "[Epoch 22/200] [Batch 504/637] [D loss: 0.161069] [G loss: 0.497537]\n",
      "[Epoch 22/200] [Batch 505/637] [D loss: 0.163245] [G loss: 0.494643]\n",
      "[Epoch 22/200] [Batch 506/637] [D loss: 0.161861] [G loss: 0.524316]\n",
      "[Epoch 22/200] [Batch 507/637] [D loss: 0.176410] [G loss: 0.466771]\n",
      "[Epoch 22/200] [Batch 508/637] [D loss: 0.159617] [G loss: 0.532171]\n",
      "[Epoch 22/200] [Batch 509/637] [D loss: 0.164449] [G loss: 0.477219]\n",
      "[Epoch 22/200] [Batch 510/637] [D loss: 0.165267] [G loss: 0.490416]\n",
      "[Epoch 22/200] [Batch 511/637] [D loss: 0.130903] [G loss: 0.597181]\n",
      "[Epoch 22/200] [Batch 512/637] [D loss: 0.167110] [G loss: 0.517120]\n",
      "[Epoch 22/200] [Batch 513/637] [D loss: 0.159937] [G loss: 0.509309]\n",
      "[Epoch 22/200] [Batch 514/637] [D loss: 0.175186] [G loss: 0.480222]\n",
      "[Epoch 22/200] [Batch 515/637] [D loss: 0.189167] [G loss: 0.518029]\n",
      "[Epoch 22/200] [Batch 516/637] [D loss: 0.173127] [G loss: 0.494311]\n",
      "[Epoch 22/200] [Batch 517/637] [D loss: 0.168554] [G loss: 0.500481]\n",
      "[Epoch 22/200] [Batch 518/637] [D loss: 0.165508] [G loss: 0.534502]\n",
      "[Epoch 22/200] [Batch 519/637] [D loss: 0.165885] [G loss: 0.547752]\n",
      "[Epoch 22/200] [Batch 520/637] [D loss: 0.179141] [G loss: 0.564676]\n",
      "[Epoch 22/200] [Batch 521/637] [D loss: 0.158432] [G loss: 0.513538]\n",
      "[Epoch 22/200] [Batch 522/637] [D loss: 0.153317] [G loss: 0.455791]\n",
      "[Epoch 22/200] [Batch 523/637] [D loss: 0.154086] [G loss: 0.482871]\n",
      "[Epoch 22/200] [Batch 524/637] [D loss: 0.140142] [G loss: 0.511952]\n",
      "[Epoch 22/200] [Batch 525/637] [D loss: 0.153723] [G loss: 0.532143]\n",
      "[Epoch 22/200] [Batch 526/637] [D loss: 0.159016] [G loss: 0.514127]\n",
      "[Epoch 22/200] [Batch 527/637] [D loss: 0.150982] [G loss: 0.558592]\n",
      "[Epoch 22/200] [Batch 528/637] [D loss: 0.165598] [G loss: 0.525005]\n",
      "[Epoch 22/200] [Batch 529/637] [D loss: 0.175893] [G loss: 0.466122]\n",
      "[Epoch 22/200] [Batch 530/637] [D loss: 0.151092] [G loss: 0.506213]\n",
      "[Epoch 22/200] [Batch 531/637] [D loss: 0.165110] [G loss: 0.506478]\n",
      "[Epoch 22/200] [Batch 532/637] [D loss: 0.139424] [G loss: 0.587381]\n",
      "[Epoch 22/200] [Batch 533/637] [D loss: 0.145685] [G loss: 0.561812]\n",
      "[Epoch 22/200] [Batch 534/637] [D loss: 0.183706] [G loss: 0.465842]\n",
      "[Epoch 22/200] [Batch 535/637] [D loss: 0.184026] [G loss: 0.500945]\n",
      "[Epoch 22/200] [Batch 536/637] [D loss: 0.153112] [G loss: 0.556575]\n",
      "[Epoch 22/200] [Batch 537/637] [D loss: 0.164735] [G loss: 0.559732]\n",
      "[Epoch 22/200] [Batch 538/637] [D loss: 0.159232] [G loss: 0.488802]\n",
      "[Epoch 22/200] [Batch 539/637] [D loss: 0.167787] [G loss: 0.524161]\n",
      "[Epoch 22/200] [Batch 540/637] [D loss: 0.167838] [G loss: 0.472756]\n",
      "[Epoch 22/200] [Batch 541/637] [D loss: 0.156294] [G loss: 0.498436]\n",
      "[Epoch 22/200] [Batch 542/637] [D loss: 0.153169] [G loss: 0.512784]\n",
      "[Epoch 22/200] [Batch 543/637] [D loss: 0.181557] [G loss: 0.543175]\n",
      "[Epoch 22/200] [Batch 544/637] [D loss: 0.160039] [G loss: 0.524437]\n",
      "[Epoch 22/200] [Batch 545/637] [D loss: 0.185022] [G loss: 0.459079]\n",
      "[Epoch 22/200] [Batch 546/637] [D loss: 0.175288] [G loss: 0.556902]\n",
      "[Epoch 22/200] [Batch 547/637] [D loss: 0.153724] [G loss: 0.541626]\n",
      "[Epoch 22/200] [Batch 548/637] [D loss: 0.154150] [G loss: 0.473590]\n",
      "[Epoch 22/200] [Batch 549/637] [D loss: 0.160846] [G loss: 0.511069]\n",
      "[Epoch 22/200] [Batch 550/637] [D loss: 0.148362] [G loss: 0.471258]\n",
      "[Epoch 22/200] [Batch 551/637] [D loss: 0.137854] [G loss: 0.557254]\n",
      "[Epoch 22/200] [Batch 552/637] [D loss: 0.150677] [G loss: 0.573332]\n",
      "[Epoch 22/200] [Batch 553/637] [D loss: 0.161174] [G loss: 0.509238]\n",
      "[Epoch 22/200] [Batch 554/637] [D loss: 0.173917] [G loss: 0.483027]\n",
      "[Epoch 22/200] [Batch 555/637] [D loss: 0.164352] [G loss: 0.638352]\n",
      "[Epoch 22/200] [Batch 556/637] [D loss: 0.139183] [G loss: 0.548316]\n",
      "[Epoch 22/200] [Batch 557/637] [D loss: 0.176715] [G loss: 0.569587]\n",
      "[Epoch 22/200] [Batch 558/637] [D loss: 0.161381] [G loss: 0.494111]\n",
      "[Epoch 22/200] [Batch 559/637] [D loss: 0.179995] [G loss: 0.465560]\n",
      "[Epoch 22/200] [Batch 560/637] [D loss: 0.150027] [G loss: 0.510730]\n",
      "[Epoch 22/200] [Batch 561/637] [D loss: 0.172421] [G loss: 0.497547]\n",
      "[Epoch 22/200] [Batch 562/637] [D loss: 0.163033] [G loss: 0.553209]\n",
      "[Epoch 22/200] [Batch 563/637] [D loss: 0.142927] [G loss: 0.570178]\n",
      "[Epoch 22/200] [Batch 564/637] [D loss: 0.162970] [G loss: 0.477892]\n",
      "[Epoch 22/200] [Batch 565/637] [D loss: 0.166903] [G loss: 0.487988]\n",
      "[Epoch 22/200] [Batch 566/637] [D loss: 0.159537] [G loss: 0.594942]\n",
      "[Epoch 22/200] [Batch 567/637] [D loss: 0.165583] [G loss: 0.619003]\n",
      "[Epoch 22/200] [Batch 568/637] [D loss: 0.142575] [G loss: 0.569833]\n",
      "[Epoch 22/200] [Batch 569/637] [D loss: 0.172683] [G loss: 0.515513]\n",
      "[Epoch 22/200] [Batch 570/637] [D loss: 0.169334] [G loss: 0.542419]\n",
      "[Epoch 22/200] [Batch 571/637] [D loss: 0.174065] [G loss: 0.570447]\n",
      "[Epoch 22/200] [Batch 572/637] [D loss: 0.158909] [G loss: 0.501186]\n",
      "[Epoch 22/200] [Batch 573/637] [D loss: 0.152568] [G loss: 0.561308]\n",
      "[Epoch 22/200] [Batch 574/637] [D loss: 0.140113] [G loss: 0.521558]\n",
      "[Epoch 22/200] [Batch 575/637] [D loss: 0.207700] [G loss: 0.451655]\n",
      "[Epoch 22/200] [Batch 576/637] [D loss: 0.221425] [G loss: 0.656033]\n",
      "[Epoch 22/200] [Batch 577/637] [D loss: 0.149324] [G loss: 0.637573]\n",
      "[Epoch 22/200] [Batch 578/637] [D loss: 0.192029] [G loss: 0.486599]\n",
      "[Epoch 22/200] [Batch 579/637] [D loss: 0.148484] [G loss: 0.487103]\n",
      "[Epoch 22/200] [Batch 580/637] [D loss: 0.162673] [G loss: 0.488689]\n",
      "[Epoch 22/200] [Batch 581/637] [D loss: 0.159380] [G loss: 0.602232]\n",
      "[Epoch 22/200] [Batch 582/637] [D loss: 0.178055] [G loss: 0.562895]\n",
      "[Epoch 22/200] [Batch 583/637] [D loss: 0.140473] [G loss: 0.524186]\n",
      "[Epoch 22/200] [Batch 584/637] [D loss: 0.162203] [G loss: 0.514934]\n",
      "[Epoch 22/200] [Batch 585/637] [D loss: 0.164341] [G loss: 0.535744]\n",
      "[Epoch 22/200] [Batch 586/637] [D loss: 0.157430] [G loss: 0.488993]\n",
      "[Epoch 22/200] [Batch 587/637] [D loss: 0.180082] [G loss: 0.495612]\n",
      "[Epoch 22/200] [Batch 588/637] [D loss: 0.162205] [G loss: 0.493039]\n",
      "[Epoch 22/200] [Batch 589/637] [D loss: 0.165664] [G loss: 0.498689]\n",
      "[Epoch 22/200] [Batch 590/637] [D loss: 0.159457] [G loss: 0.485135]\n",
      "[Epoch 22/200] [Batch 591/637] [D loss: 0.165907] [G loss: 0.514644]\n",
      "[Epoch 22/200] [Batch 592/637] [D loss: 0.185223] [G loss: 0.426232]\n",
      "[Epoch 22/200] [Batch 593/637] [D loss: 0.186428] [G loss: 0.445213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/200] [Batch 594/637] [D loss: 0.170042] [G loss: 0.539212]\n",
      "[Epoch 22/200] [Batch 595/637] [D loss: 0.155314] [G loss: 0.552651]\n",
      "[Epoch 22/200] [Batch 596/637] [D loss: 0.155150] [G loss: 0.481176]\n",
      "[Epoch 22/200] [Batch 597/637] [D loss: 0.187021] [G loss: 0.475742]\n",
      "[Epoch 22/200] [Batch 598/637] [D loss: 0.149343] [G loss: 0.551160]\n",
      "[Epoch 22/200] [Batch 599/637] [D loss: 0.150457] [G loss: 0.546627]\n",
      "[Epoch 22/200] [Batch 600/637] [D loss: 0.157653] [G loss: 0.508470]\n",
      "[Epoch 22/200] [Batch 601/637] [D loss: 0.173127] [G loss: 0.498791]\n",
      "[Epoch 22/200] [Batch 602/637] [D loss: 0.161178] [G loss: 0.581009]\n",
      "[Epoch 22/200] [Batch 603/637] [D loss: 0.154595] [G loss: 0.567732]\n",
      "[Epoch 22/200] [Batch 604/637] [D loss: 0.157872] [G loss: 0.532783]\n",
      "[Epoch 22/200] [Batch 605/637] [D loss: 0.148773] [G loss: 0.505993]\n",
      "[Epoch 22/200] [Batch 606/637] [D loss: 0.143019] [G loss: 0.497799]\n",
      "[Epoch 22/200] [Batch 607/637] [D loss: 0.169737] [G loss: 0.492063]\n",
      "[Epoch 22/200] [Batch 608/637] [D loss: 0.163849] [G loss: 0.591046]\n",
      "[Epoch 22/200] [Batch 609/637] [D loss: 0.146305] [G loss: 0.595978]\n",
      "[Epoch 22/200] [Batch 610/637] [D loss: 0.166547] [G loss: 0.508951]\n",
      "[Epoch 22/200] [Batch 611/637] [D loss: 0.168152] [G loss: 0.475531]\n",
      "[Epoch 22/200] [Batch 612/637] [D loss: 0.158896] [G loss: 0.525607]\n",
      "[Epoch 22/200] [Batch 613/637] [D loss: 0.150407] [G loss: 0.535969]\n",
      "[Epoch 22/200] [Batch 614/637] [D loss: 0.164820] [G loss: 0.484235]\n",
      "[Epoch 22/200] [Batch 615/637] [D loss: 0.196218] [G loss: 0.460251]\n",
      "[Epoch 22/200] [Batch 616/637] [D loss: 0.184746] [G loss: 0.485369]\n",
      "[Epoch 22/200] [Batch 617/637] [D loss: 0.171486] [G loss: 0.443556]\n",
      "[Epoch 22/200] [Batch 618/637] [D loss: 0.161541] [G loss: 0.475077]\n",
      "[Epoch 22/200] [Batch 619/637] [D loss: 0.168977] [G loss: 0.554385]\n",
      "[Epoch 22/200] [Batch 620/637] [D loss: 0.152155] [G loss: 0.499186]\n",
      "[Epoch 22/200] [Batch 621/637] [D loss: 0.155453] [G loss: 0.469923]\n",
      "[Epoch 22/200] [Batch 622/637] [D loss: 0.162531] [G loss: 0.467291]\n",
      "[Epoch 22/200] [Batch 623/637] [D loss: 0.152998] [G loss: 0.515792]\n",
      "[Epoch 22/200] [Batch 624/637] [D loss: 0.152854] [G loss: 0.568858]\n",
      "[Epoch 22/200] [Batch 625/637] [D loss: 0.158370] [G loss: 0.501103]\n",
      "[Epoch 22/200] [Batch 626/637] [D loss: 0.172453] [G loss: 0.480902]\n",
      "[Epoch 22/200] [Batch 627/637] [D loss: 0.176131] [G loss: 0.516173]\n",
      "[Epoch 22/200] [Batch 628/637] [D loss: 0.140654] [G loss: 0.555055]\n",
      "[Epoch 22/200] [Batch 629/637] [D loss: 0.162184] [G loss: 0.487786]\n",
      "[Epoch 22/200] [Batch 630/637] [D loss: 0.169195] [G loss: 0.444290]\n",
      "[Epoch 22/200] [Batch 631/637] [D loss: 0.163015] [G loss: 0.459957]\n",
      "[Epoch 22/200] [Batch 632/637] [D loss: 0.162274] [G loss: 0.571450]\n",
      "[Epoch 22/200] [Batch 633/637] [D loss: 0.203058] [G loss: 0.583705]\n",
      "[Epoch 22/200] [Batch 634/637] [D loss: 0.164340] [G loss: 0.574709]\n",
      "[Epoch 22/200] [Batch 635/637] [D loss: 0.145013] [G loss: 0.563816]\n",
      "[Epoch 22/200] [Batch 636/637] [D loss: 0.216704] [G loss: 0.314755]\n",
      "[Epoch 23/200] [Batch 0/637] [D loss: 0.210138] [G loss: 0.493180]\n",
      "[Epoch 23/200] [Batch 1/637] [D loss: 0.177900] [G loss: 0.556096]\n",
      "[Epoch 23/200] [Batch 2/637] [D loss: 0.189896] [G loss: 0.473207]\n",
      "[Epoch 23/200] [Batch 3/637] [D loss: 0.176058] [G loss: 0.412302]\n",
      "[Epoch 23/200] [Batch 4/637] [D loss: 0.184464] [G loss: 0.400816]\n",
      "[Epoch 23/200] [Batch 5/637] [D loss: 0.153341] [G loss: 0.519423]\n",
      "[Epoch 23/200] [Batch 6/637] [D loss: 0.187556] [G loss: 0.469835]\n",
      "[Epoch 23/200] [Batch 7/637] [D loss: 0.185793] [G loss: 0.461234]\n",
      "[Epoch 23/200] [Batch 8/637] [D loss: 0.164594] [G loss: 0.463698]\n",
      "[Epoch 23/200] [Batch 9/637] [D loss: 0.179265] [G loss: 0.485590]\n",
      "[Epoch 23/200] [Batch 10/637] [D loss: 0.181507] [G loss: 0.450554]\n",
      "[Epoch 23/200] [Batch 11/637] [D loss: 0.153999] [G loss: 0.459216]\n",
      "[Epoch 23/200] [Batch 12/637] [D loss: 0.167236] [G loss: 0.437452]\n",
      "[Epoch 23/200] [Batch 13/637] [D loss: 0.150888] [G loss: 0.548872]\n",
      "[Epoch 23/200] [Batch 14/637] [D loss: 0.157028] [G loss: 0.505349]\n",
      "[Epoch 23/200] [Batch 15/637] [D loss: 0.174146] [G loss: 0.512101]\n",
      "[Epoch 23/200] [Batch 16/637] [D loss: 0.165704] [G loss: 0.533739]\n",
      "[Epoch 23/200] [Batch 17/637] [D loss: 0.158861] [G loss: 0.508479]\n",
      "[Epoch 23/200] [Batch 18/637] [D loss: 0.162655] [G loss: 0.473309]\n",
      "[Epoch 23/200] [Batch 19/637] [D loss: 0.149871] [G loss: 0.453392]\n",
      "[Epoch 23/200] [Batch 20/637] [D loss: 0.139988] [G loss: 0.474380]\n",
      "[Epoch 23/200] [Batch 21/637] [D loss: 0.177549] [G loss: 0.469642]\n",
      "[Epoch 23/200] [Batch 22/637] [D loss: 0.174345] [G loss: 0.437473]\n",
      "[Epoch 23/200] [Batch 23/637] [D loss: 0.153927] [G loss: 0.469257]\n",
      "[Epoch 23/200] [Batch 24/637] [D loss: 0.157182] [G loss: 0.541068]\n",
      "[Epoch 23/200] [Batch 25/637] [D loss: 0.235194] [G loss: 0.576610]\n",
      "[Epoch 23/200] [Batch 26/637] [D loss: 0.147259] [G loss: 0.565330]\n",
      "[Epoch 23/200] [Batch 27/637] [D loss: 0.159362] [G loss: 0.451866]\n",
      "[Epoch 23/200] [Batch 28/637] [D loss: 0.178702] [G loss: 0.416032]\n",
      "[Epoch 23/200] [Batch 29/637] [D loss: 0.134056] [G loss: 0.550394]\n",
      "[Epoch 23/200] [Batch 30/637] [D loss: 0.197665] [G loss: 0.506493]\n",
      "[Epoch 23/200] [Batch 31/637] [D loss: 0.175180] [G loss: 0.430331]\n",
      "[Epoch 23/200] [Batch 32/637] [D loss: 0.178870] [G loss: 0.464370]\n",
      "[Epoch 23/200] [Batch 33/637] [D loss: 0.157830] [G loss: 0.466795]\n",
      "[Epoch 23/200] [Batch 34/637] [D loss: 0.164095] [G loss: 0.451176]\n",
      "[Epoch 23/200] [Batch 35/637] [D loss: 0.177494] [G loss: 0.466795]\n",
      "[Epoch 23/200] [Batch 36/637] [D loss: 0.152935] [G loss: 0.496830]\n",
      "[Epoch 23/200] [Batch 37/637] [D loss: 0.157522] [G loss: 0.447205]\n",
      "[Epoch 23/200] [Batch 38/637] [D loss: 0.154301] [G loss: 0.469867]\n",
      "[Epoch 23/200] [Batch 39/637] [D loss: 0.159381] [G loss: 0.446417]\n",
      "[Epoch 23/200] [Batch 40/637] [D loss: 0.168372] [G loss: 0.463301]\n",
      "[Epoch 23/200] [Batch 41/637] [D loss: 0.163856] [G loss: 0.515321]\n",
      "[Epoch 23/200] [Batch 42/637] [D loss: 0.199771] [G loss: 0.466967]\n",
      "[Epoch 23/200] [Batch 43/637] [D loss: 0.189104] [G loss: 0.475987]\n",
      "[Epoch 23/200] [Batch 44/637] [D loss: 0.150324] [G loss: 0.485817]\n",
      "[Epoch 23/200] [Batch 45/637] [D loss: 0.156505] [G loss: 0.460743]\n",
      "[Epoch 23/200] [Batch 46/637] [D loss: 0.154946] [G loss: 0.413213]\n",
      "[Epoch 23/200] [Batch 47/637] [D loss: 0.159340] [G loss: 0.461617]\n",
      "[Epoch 23/200] [Batch 48/637] [D loss: 0.147377] [G loss: 0.472267]\n",
      "[Epoch 23/200] [Batch 49/637] [D loss: 0.155981] [G loss: 0.484661]\n",
      "[Epoch 23/200] [Batch 50/637] [D loss: 0.192547] [G loss: 0.405781]\n",
      "[Epoch 23/200] [Batch 51/637] [D loss: 0.177696] [G loss: 0.489483]\n",
      "[Epoch 23/200] [Batch 52/637] [D loss: 0.151388] [G loss: 0.462400]\n",
      "[Epoch 23/200] [Batch 53/637] [D loss: 0.179763] [G loss: 0.429998]\n",
      "[Epoch 23/200] [Batch 54/637] [D loss: 0.165997] [G loss: 0.552294]\n",
      "[Epoch 23/200] [Batch 55/637] [D loss: 0.174800] [G loss: 0.467280]\n",
      "[Epoch 23/200] [Batch 56/637] [D loss: 0.151263] [G loss: 0.505499]\n",
      "[Epoch 23/200] [Batch 57/637] [D loss: 0.152055] [G loss: 0.491647]\n",
      "[Epoch 23/200] [Batch 58/637] [D loss: 0.146424] [G loss: 0.461959]\n",
      "[Epoch 23/200] [Batch 59/637] [D loss: 0.136936] [G loss: 0.481447]\n",
      "[Epoch 23/200] [Batch 60/637] [D loss: 0.173561] [G loss: 0.483128]\n",
      "[Epoch 23/200] [Batch 61/637] [D loss: 0.149444] [G loss: 0.507403]\n",
      "[Epoch 23/200] [Batch 62/637] [D loss: 0.168106] [G loss: 0.450302]\n",
      "[Epoch 23/200] [Batch 63/637] [D loss: 0.177451] [G loss: 0.476961]\n",
      "[Epoch 23/200] [Batch 64/637] [D loss: 0.167884] [G loss: 0.496613]\n",
      "[Epoch 23/200] [Batch 65/637] [D loss: 0.154466] [G loss: 0.547221]\n",
      "[Epoch 23/200] [Batch 66/637] [D loss: 0.177090] [G loss: 0.489403]\n",
      "[Epoch 23/200] [Batch 67/637] [D loss: 0.159469] [G loss: 0.479823]\n",
      "[Epoch 23/200] [Batch 68/637] [D loss: 0.157992] [G loss: 0.521479]\n",
      "[Epoch 23/200] [Batch 69/637] [D loss: 0.170159] [G loss: 0.465206]\n",
      "[Epoch 23/200] [Batch 70/637] [D loss: 0.151431] [G loss: 0.553819]\n",
      "[Epoch 23/200] [Batch 71/637] [D loss: 0.155712] [G loss: 0.539172]\n",
      "[Epoch 23/200] [Batch 72/637] [D loss: 0.150696] [G loss: 0.497024]\n",
      "[Epoch 23/200] [Batch 73/637] [D loss: 0.172324] [G loss: 0.506125]\n",
      "[Epoch 23/200] [Batch 74/637] [D loss: 0.153471] [G loss: 0.489309]\n",
      "[Epoch 23/200] [Batch 75/637] [D loss: 0.156325] [G loss: 0.461668]\n",
      "[Epoch 23/200] [Batch 76/637] [D loss: 0.156401] [G loss: 0.479251]\n",
      "[Epoch 23/200] [Batch 77/637] [D loss: 0.154914] [G loss: 0.509180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/200] [Batch 78/637] [D loss: 0.167969] [G loss: 0.512887]\n",
      "[Epoch 23/200] [Batch 79/637] [D loss: 0.152576] [G loss: 0.525065]\n",
      "[Epoch 23/200] [Batch 80/637] [D loss: 0.150198] [G loss: 0.503990]\n",
      "[Epoch 23/200] [Batch 81/637] [D loss: 0.169241] [G loss: 0.413835]\n",
      "[Epoch 23/200] [Batch 82/637] [D loss: 0.183241] [G loss: 0.517978]\n",
      "[Epoch 23/200] [Batch 83/637] [D loss: 0.166905] [G loss: 0.579081]\n",
      "[Epoch 23/200] [Batch 84/637] [D loss: 0.169751] [G loss: 0.463551]\n",
      "[Epoch 23/200] [Batch 85/637] [D loss: 0.166341] [G loss: 0.449320]\n",
      "[Epoch 23/200] [Batch 86/637] [D loss: 0.171589] [G loss: 0.530368]\n",
      "[Epoch 23/200] [Batch 87/637] [D loss: 0.130977] [G loss: 0.540628]\n",
      "[Epoch 23/200] [Batch 88/637] [D loss: 0.159425] [G loss: 0.510241]\n",
      "[Epoch 23/200] [Batch 89/637] [D loss: 0.174742] [G loss: 0.427005]\n",
      "[Epoch 23/200] [Batch 90/637] [D loss: 0.196482] [G loss: 0.513301]\n",
      "[Epoch 23/200] [Batch 91/637] [D loss: 0.159638] [G loss: 0.551367]\n",
      "[Epoch 23/200] [Batch 92/637] [D loss: 0.162312] [G loss: 0.537575]\n",
      "[Epoch 23/200] [Batch 93/637] [D loss: 0.157090] [G loss: 0.559977]\n",
      "[Epoch 23/200] [Batch 94/637] [D loss: 0.153953] [G loss: 0.487651]\n",
      "[Epoch 23/200] [Batch 95/637] [D loss: 0.174506] [G loss: 0.445825]\n",
      "[Epoch 23/200] [Batch 96/637] [D loss: 0.176275] [G loss: 0.466943]\n",
      "[Epoch 23/200] [Batch 97/637] [D loss: 0.134182] [G loss: 0.560291]\n",
      "[Epoch 23/200] [Batch 98/637] [D loss: 0.153524] [G loss: 0.525907]\n",
      "[Epoch 23/200] [Batch 99/637] [D loss: 0.150072] [G loss: 0.496775]\n",
      "[Epoch 23/200] [Batch 100/637] [D loss: 0.146095] [G loss: 0.538680]\n",
      "[Epoch 23/200] [Batch 101/637] [D loss: 0.149854] [G loss: 0.555501]\n",
      "[Epoch 23/200] [Batch 102/637] [D loss: 0.179601] [G loss: 0.395023]\n",
      "[Epoch 23/200] [Batch 103/637] [D loss: 0.164976] [G loss: 0.526300]\n",
      "[Epoch 23/200] [Batch 104/637] [D loss: 0.169569] [G loss: 0.489594]\n",
      "[Epoch 23/200] [Batch 105/637] [D loss: 0.158301] [G loss: 0.543913]\n",
      "[Epoch 23/200] [Batch 106/637] [D loss: 0.168625] [G loss: 0.512882]\n",
      "[Epoch 23/200] [Batch 107/637] [D loss: 0.153998] [G loss: 0.545270]\n",
      "[Epoch 23/200] [Batch 108/637] [D loss: 0.152294] [G loss: 0.451154]\n",
      "[Epoch 23/200] [Batch 109/637] [D loss: 0.174552] [G loss: 0.554406]\n",
      "[Epoch 23/200] [Batch 110/637] [D loss: 0.169107] [G loss: 0.593545]\n",
      "[Epoch 23/200] [Batch 111/637] [D loss: 0.154102] [G loss: 0.484677]\n",
      "[Epoch 23/200] [Batch 112/637] [D loss: 0.159674] [G loss: 0.520244]\n",
      "[Epoch 23/200] [Batch 113/637] [D loss: 0.188268] [G loss: 0.408676]\n",
      "[Epoch 23/200] [Batch 114/637] [D loss: 0.155544] [G loss: 0.552071]\n",
      "[Epoch 23/200] [Batch 115/637] [D loss: 0.179562] [G loss: 0.519032]\n",
      "[Epoch 23/200] [Batch 116/637] [D loss: 0.161054] [G loss: 0.506213]\n",
      "[Epoch 23/200] [Batch 117/637] [D loss: 0.188082] [G loss: 0.567309]\n",
      "[Epoch 23/200] [Batch 118/637] [D loss: 0.168239] [G loss: 0.527733]\n",
      "[Epoch 23/200] [Batch 119/637] [D loss: 0.196300] [G loss: 0.465749]\n",
      "[Epoch 23/200] [Batch 120/637] [D loss: 0.188922] [G loss: 0.428490]\n",
      "[Epoch 23/200] [Batch 121/637] [D loss: 0.152618] [G loss: 0.592188]\n",
      "[Epoch 23/200] [Batch 122/637] [D loss: 0.156706] [G loss: 0.539852]\n",
      "[Epoch 23/200] [Batch 123/637] [D loss: 0.130040] [G loss: 0.563379]\n",
      "[Epoch 23/200] [Batch 124/637] [D loss: 0.142739] [G loss: 0.494839]\n",
      "[Epoch 23/200] [Batch 125/637] [D loss: 0.154237] [G loss: 0.513231]\n",
      "[Epoch 23/200] [Batch 126/637] [D loss: 0.165947] [G loss: 0.472274]\n",
      "[Epoch 23/200] [Batch 127/637] [D loss: 0.170011] [G loss: 0.512725]\n",
      "[Epoch 23/200] [Batch 128/637] [D loss: 0.147588] [G loss: 0.543625]\n",
      "[Epoch 23/200] [Batch 129/637] [D loss: 0.174592] [G loss: 0.490243]\n",
      "[Epoch 23/200] [Batch 130/637] [D loss: 0.174461] [G loss: 0.475892]\n",
      "[Epoch 23/200] [Batch 131/637] [D loss: 0.145711] [G loss: 0.553563]\n",
      "[Epoch 23/200] [Batch 132/637] [D loss: 0.179018] [G loss: 0.507198]\n",
      "[Epoch 23/200] [Batch 133/637] [D loss: 0.149495] [G loss: 0.499716]\n",
      "[Epoch 23/200] [Batch 134/637] [D loss: 0.141876] [G loss: 0.537156]\n",
      "[Epoch 23/200] [Batch 135/637] [D loss: 0.137364] [G loss: 0.514411]\n",
      "[Epoch 23/200] [Batch 136/637] [D loss: 0.126355] [G loss: 0.528074]\n",
      "[Epoch 23/200] [Batch 137/637] [D loss: 0.130556] [G loss: 0.525981]\n",
      "[Epoch 23/200] [Batch 138/637] [D loss: 0.156092] [G loss: 0.487985]\n",
      "[Epoch 23/200] [Batch 139/637] [D loss: 0.140851] [G loss: 0.568811]\n",
      "[Epoch 23/200] [Batch 140/637] [D loss: 0.146887] [G loss: 0.545654]\n",
      "[Epoch 23/200] [Batch 141/637] [D loss: 0.150231] [G loss: 0.546052]\n",
      "[Epoch 23/200] [Batch 142/637] [D loss: 0.159421] [G loss: 0.507998]\n",
      "[Epoch 23/200] [Batch 143/637] [D loss: 0.166768] [G loss: 0.483994]\n",
      "[Epoch 23/200] [Batch 144/637] [D loss: 0.178830] [G loss: 0.492553]\n",
      "[Epoch 23/200] [Batch 145/637] [D loss: 0.204076] [G loss: 0.500898]\n",
      "[Epoch 23/200] [Batch 146/637] [D loss: 0.196613] [G loss: 0.512307]\n",
      "[Epoch 23/200] [Batch 147/637] [D loss: 0.161311] [G loss: 0.547552]\n",
      "[Epoch 23/200] [Batch 148/637] [D loss: 0.155195] [G loss: 0.501559]\n",
      "[Epoch 23/200] [Batch 149/637] [D loss: 0.178024] [G loss: 0.449540]\n",
      "[Epoch 23/200] [Batch 150/637] [D loss: 0.183736] [G loss: 0.467048]\n",
      "[Epoch 23/200] [Batch 151/637] [D loss: 0.180679] [G loss: 0.428242]\n",
      "[Epoch 23/200] [Batch 152/637] [D loss: 0.190636] [G loss: 0.473866]\n",
      "[Epoch 23/200] [Batch 153/637] [D loss: 0.158781] [G loss: 0.514916]\n",
      "[Epoch 23/200] [Batch 154/637] [D loss: 0.177425] [G loss: 0.487678]\n",
      "[Epoch 23/200] [Batch 155/637] [D loss: 0.170206] [G loss: 0.524181]\n",
      "[Epoch 23/200] [Batch 156/637] [D loss: 0.158587] [G loss: 0.472453]\n",
      "[Epoch 23/200] [Batch 157/637] [D loss: 0.162432] [G loss: 0.442762]\n",
      "[Epoch 23/200] [Batch 158/637] [D loss: 0.158900] [G loss: 0.507279]\n",
      "[Epoch 23/200] [Batch 159/637] [D loss: 0.135238] [G loss: 0.606503]\n",
      "[Epoch 23/200] [Batch 160/637] [D loss: 0.159929] [G loss: 0.481886]\n",
      "[Epoch 23/200] [Batch 161/637] [D loss: 0.169841] [G loss: 0.561936]\n",
      "[Epoch 23/200] [Batch 162/637] [D loss: 0.151857] [G loss: 0.497756]\n",
      "[Epoch 23/200] [Batch 163/637] [D loss: 0.154289] [G loss: 0.484424]\n",
      "[Epoch 23/200] [Batch 164/637] [D loss: 0.155986] [G loss: 0.534276]\n",
      "[Epoch 23/200] [Batch 165/637] [D loss: 0.153509] [G loss: 0.574903]\n",
      "[Epoch 23/200] [Batch 166/637] [D loss: 0.176895] [G loss: 0.477765]\n",
      "[Epoch 23/200] [Batch 167/637] [D loss: 0.151386] [G loss: 0.584823]\n",
      "[Epoch 23/200] [Batch 168/637] [D loss: 0.187743] [G loss: 0.440823]\n",
      "[Epoch 23/200] [Batch 169/637] [D loss: 0.169289] [G loss: 0.480869]\n",
      "[Epoch 23/200] [Batch 170/637] [D loss: 0.168088] [G loss: 0.500256]\n",
      "[Epoch 23/200] [Batch 171/637] [D loss: 0.156527] [G loss: 0.540418]\n",
      "[Epoch 23/200] [Batch 172/637] [D loss: 0.174321] [G loss: 0.446976]\n",
      "[Epoch 23/200] [Batch 173/637] [D loss: 0.177808] [G loss: 0.473291]\n",
      "[Epoch 23/200] [Batch 174/637] [D loss: 0.137434] [G loss: 0.540433]\n",
      "[Epoch 23/200] [Batch 175/637] [D loss: 0.164311] [G loss: 0.480435]\n",
      "[Epoch 23/200] [Batch 176/637] [D loss: 0.163420] [G loss: 0.512322]\n",
      "[Epoch 23/200] [Batch 177/637] [D loss: 0.155824] [G loss: 0.565421]\n",
      "[Epoch 23/200] [Batch 178/637] [D loss: 0.176633] [G loss: 0.507085]\n",
      "[Epoch 23/200] [Batch 179/637] [D loss: 0.161022] [G loss: 0.434886]\n",
      "[Epoch 23/200] [Batch 180/637] [D loss: 0.138778] [G loss: 0.545723]\n",
      "[Epoch 23/200] [Batch 181/637] [D loss: 0.155008] [G loss: 0.565616]\n",
      "[Epoch 23/200] [Batch 182/637] [D loss: 0.159474] [G loss: 0.514553]\n",
      "[Epoch 23/200] [Batch 183/637] [D loss: 0.164812] [G loss: 0.476330]\n",
      "[Epoch 23/200] [Batch 184/637] [D loss: 0.170127] [G loss: 0.506997]\n",
      "[Epoch 23/200] [Batch 185/637] [D loss: 0.140329] [G loss: 0.595557]\n",
      "[Epoch 23/200] [Batch 186/637] [D loss: 0.170372] [G loss: 0.499869]\n",
      "[Epoch 23/200] [Batch 187/637] [D loss: 0.180580] [G loss: 0.540712]\n",
      "[Epoch 23/200] [Batch 188/637] [D loss: 0.160661] [G loss: 0.578507]\n",
      "[Epoch 23/200] [Batch 189/637] [D loss: 0.176149] [G loss: 0.442715]\n",
      "[Epoch 23/200] [Batch 190/637] [D loss: 0.190931] [G loss: 0.399309]\n",
      "[Epoch 23/200] [Batch 191/637] [D loss: 0.192217] [G loss: 0.547932]\n",
      "[Epoch 23/200] [Batch 192/637] [D loss: 0.139658] [G loss: 0.602638]\n",
      "[Epoch 23/200] [Batch 193/637] [D loss: 0.154559] [G loss: 0.504368]\n",
      "[Epoch 23/200] [Batch 194/637] [D loss: 0.143574] [G loss: 0.502302]\n",
      "[Epoch 23/200] [Batch 195/637] [D loss: 0.168061] [G loss: 0.485109]\n",
      "[Epoch 23/200] [Batch 196/637] [D loss: 0.156952] [G loss: 0.564471]\n",
      "[Epoch 23/200] [Batch 197/637] [D loss: 0.195267] [G loss: 0.430387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/200] [Batch 198/637] [D loss: 0.149950] [G loss: 0.554965]\n",
      "[Epoch 23/200] [Batch 199/637] [D loss: 0.172385] [G loss: 0.505655]\n",
      "[Epoch 23/200] [Batch 200/637] [D loss: 0.153487] [G loss: 0.537561]\n",
      "[Epoch 23/200] [Batch 201/637] [D loss: 0.171134] [G loss: 0.476313]\n",
      "[Epoch 23/200] [Batch 202/637] [D loss: 0.141667] [G loss: 0.457753]\n",
      "[Epoch 23/200] [Batch 203/637] [D loss: 0.181419] [G loss: 0.482709]\n",
      "[Epoch 23/200] [Batch 204/637] [D loss: 0.172203] [G loss: 0.526679]\n",
      "[Epoch 23/200] [Batch 205/637] [D loss: 0.171031] [G loss: 0.553387]\n",
      "[Epoch 23/200] [Batch 206/637] [D loss: 0.152940] [G loss: 0.516680]\n",
      "[Epoch 23/200] [Batch 207/637] [D loss: 0.148254] [G loss: 0.512694]\n",
      "[Epoch 23/200] [Batch 208/637] [D loss: 0.173865] [G loss: 0.474796]\n",
      "[Epoch 23/200] [Batch 209/637] [D loss: 0.164298] [G loss: 0.468139]\n",
      "[Epoch 23/200] [Batch 210/637] [D loss: 0.162945] [G loss: 0.515622]\n",
      "[Epoch 23/200] [Batch 211/637] [D loss: 0.160940] [G loss: 0.455144]\n",
      "[Epoch 23/200] [Batch 212/637] [D loss: 0.139343] [G loss: 0.551329]\n",
      "[Epoch 23/200] [Batch 213/637] [D loss: 0.186046] [G loss: 0.464632]\n",
      "[Epoch 23/200] [Batch 214/637] [D loss: 0.148723] [G loss: 0.601384]\n",
      "[Epoch 23/200] [Batch 215/637] [D loss: 0.185845] [G loss: 0.489102]\n",
      "[Epoch 23/200] [Batch 216/637] [D loss: 0.156626] [G loss: 0.518238]\n",
      "[Epoch 23/200] [Batch 217/637] [D loss: 0.170956] [G loss: 0.478023]\n",
      "[Epoch 23/200] [Batch 218/637] [D loss: 0.175919] [G loss: 0.554471]\n",
      "[Epoch 23/200] [Batch 219/637] [D loss: 0.177849] [G loss: 0.492163]\n",
      "[Epoch 23/200] [Batch 220/637] [D loss: 0.164550] [G loss: 0.581239]\n",
      "[Epoch 23/200] [Batch 221/637] [D loss: 0.199632] [G loss: 0.557680]\n",
      "[Epoch 23/200] [Batch 222/637] [D loss: 0.181726] [G loss: 0.532884]\n",
      "[Epoch 23/200] [Batch 223/637] [D loss: 0.178192] [G loss: 0.522572]\n",
      "[Epoch 23/200] [Batch 224/637] [D loss: 0.164766] [G loss: 0.538771]\n",
      "[Epoch 23/200] [Batch 225/637] [D loss: 0.177144] [G loss: 0.424824]\n",
      "[Epoch 23/200] [Batch 226/637] [D loss: 0.170348] [G loss: 0.518547]\n",
      "[Epoch 23/200] [Batch 227/637] [D loss: 0.166328] [G loss: 0.497468]\n",
      "[Epoch 23/200] [Batch 228/637] [D loss: 0.149297] [G loss: 0.572038]\n",
      "[Epoch 23/200] [Batch 229/637] [D loss: 0.156782] [G loss: 0.545739]\n",
      "[Epoch 23/200] [Batch 230/637] [D loss: 0.168713] [G loss: 0.521066]\n",
      "[Epoch 23/200] [Batch 231/637] [D loss: 0.161169] [G loss: 0.502228]\n",
      "[Epoch 23/200] [Batch 232/637] [D loss: 0.174081] [G loss: 0.485689]\n",
      "[Epoch 23/200] [Batch 233/637] [D loss: 0.150974] [G loss: 0.521314]\n",
      "[Epoch 23/200] [Batch 234/637] [D loss: 0.163017] [G loss: 0.514970]\n",
      "[Epoch 23/200] [Batch 235/637] [D loss: 0.148549] [G loss: 0.467822]\n",
      "[Epoch 23/200] [Batch 236/637] [D loss: 0.154342] [G loss: 0.511218]\n",
      "[Epoch 23/200] [Batch 237/637] [D loss: 0.132592] [G loss: 0.529188]\n",
      "[Epoch 23/200] [Batch 238/637] [D loss: 0.170493] [G loss: 0.514985]\n",
      "[Epoch 23/200] [Batch 239/637] [D loss: 0.167898] [G loss: 0.611982]\n",
      "[Epoch 23/200] [Batch 240/637] [D loss: 0.175884] [G loss: 0.545410]\n",
      "[Epoch 23/200] [Batch 241/637] [D loss: 0.181491] [G loss: 0.617980]\n",
      "[Epoch 23/200] [Batch 242/637] [D loss: 0.162534] [G loss: 0.547807]\n",
      "[Epoch 23/200] [Batch 243/637] [D loss: 0.179278] [G loss: 0.468367]\n",
      "[Epoch 23/200] [Batch 244/637] [D loss: 0.206948] [G loss: 0.377523]\n",
      "[Epoch 23/200] [Batch 245/637] [D loss: 0.167201] [G loss: 0.536646]\n",
      "[Epoch 23/200] [Batch 246/637] [D loss: 0.174587] [G loss: 0.565490]\n",
      "[Epoch 23/200] [Batch 247/637] [D loss: 0.147484] [G loss: 0.505221]\n",
      "[Epoch 23/200] [Batch 248/637] [D loss: 0.166597] [G loss: 0.498095]\n",
      "[Epoch 23/200] [Batch 249/637] [D loss: 0.163192] [G loss: 0.573298]\n",
      "[Epoch 23/200] [Batch 250/637] [D loss: 0.150587] [G loss: 0.510435]\n",
      "[Epoch 23/200] [Batch 251/637] [D loss: 0.169045] [G loss: 0.503269]\n",
      "[Epoch 23/200] [Batch 252/637] [D loss: 0.167564] [G loss: 0.505941]\n",
      "[Epoch 23/200] [Batch 253/637] [D loss: 0.163793] [G loss: 0.523493]\n",
      "[Epoch 23/200] [Batch 254/637] [D loss: 0.162374] [G loss: 0.485471]\n",
      "[Epoch 23/200] [Batch 255/637] [D loss: 0.179221] [G loss: 0.485610]\n",
      "[Epoch 23/200] [Batch 256/637] [D loss: 0.151905] [G loss: 0.577317]\n",
      "[Epoch 23/200] [Batch 257/637] [D loss: 0.174334] [G loss: 0.529576]\n",
      "[Epoch 23/200] [Batch 258/637] [D loss: 0.186368] [G loss: 0.526901]\n",
      "[Epoch 23/200] [Batch 259/637] [D loss: 0.186381] [G loss: 0.526607]\n",
      "[Epoch 23/200] [Batch 260/637] [D loss: 0.153227] [G loss: 0.436828]\n",
      "[Epoch 23/200] [Batch 261/637] [D loss: 0.190479] [G loss: 0.378275]\n",
      "[Epoch 23/200] [Batch 262/637] [D loss: 0.157479] [G loss: 0.474598]\n",
      "[Epoch 23/200] [Batch 263/637] [D loss: 0.139732] [G loss: 0.587894]\n",
      "[Epoch 23/200] [Batch 264/637] [D loss: 0.158887] [G loss: 0.474375]\n",
      "[Epoch 23/200] [Batch 265/637] [D loss: 0.158394] [G loss: 0.453011]\n",
      "[Epoch 23/200] [Batch 266/637] [D loss: 0.168161] [G loss: 0.508684]\n",
      "[Epoch 23/200] [Batch 267/637] [D loss: 0.138880] [G loss: 0.518169]\n",
      "[Epoch 23/200] [Batch 268/637] [D loss: 0.159785] [G loss: 0.575009]\n",
      "[Epoch 23/200] [Batch 269/637] [D loss: 0.179875] [G loss: 0.507313]\n",
      "[Epoch 23/200] [Batch 270/637] [D loss: 0.173790] [G loss: 0.529666]\n",
      "[Epoch 23/200] [Batch 271/637] [D loss: 0.168750] [G loss: 0.472556]\n",
      "[Epoch 23/200] [Batch 272/637] [D loss: 0.161742] [G loss: 0.470666]\n",
      "[Epoch 23/200] [Batch 273/637] [D loss: 0.177104] [G loss: 0.492328]\n",
      "[Epoch 23/200] [Batch 274/637] [D loss: 0.155496] [G loss: 0.504747]\n",
      "[Epoch 23/200] [Batch 275/637] [D loss: 0.182161] [G loss: 0.544613]\n",
      "[Epoch 23/200] [Batch 276/637] [D loss: 0.159246] [G loss: 0.505641]\n",
      "[Epoch 23/200] [Batch 277/637] [D loss: 0.173273] [G loss: 0.464763]\n",
      "[Epoch 23/200] [Batch 278/637] [D loss: 0.172953] [G loss: 0.463615]\n",
      "[Epoch 23/200] [Batch 279/637] [D loss: 0.173429] [G loss: 0.480820]\n",
      "[Epoch 23/200] [Batch 280/637] [D loss: 0.136722] [G loss: 0.614799]\n",
      "[Epoch 23/200] [Batch 281/637] [D loss: 0.181096] [G loss: 0.540302]\n",
      "[Epoch 23/200] [Batch 282/637] [D loss: 0.164672] [G loss: 0.537849]\n",
      "[Epoch 23/200] [Batch 283/637] [D loss: 0.167397] [G loss: 0.547766]\n",
      "[Epoch 23/200] [Batch 284/637] [D loss: 0.168755] [G loss: 0.510702]\n",
      "[Epoch 23/200] [Batch 285/637] [D loss: 0.170401] [G loss: 0.437314]\n",
      "[Epoch 23/200] [Batch 286/637] [D loss: 0.154196] [G loss: 0.535554]\n",
      "[Epoch 23/200] [Batch 287/637] [D loss: 0.151911] [G loss: 0.539844]\n",
      "[Epoch 23/200] [Batch 288/637] [D loss: 0.153711] [G loss: 0.523200]\n",
      "[Epoch 23/200] [Batch 289/637] [D loss: 0.155988] [G loss: 0.570657]\n",
      "[Epoch 23/200] [Batch 290/637] [D loss: 0.157949] [G loss: 0.484165]\n",
      "[Epoch 23/200] [Batch 291/637] [D loss: 0.173200] [G loss: 0.553073]\n",
      "[Epoch 23/200] [Batch 292/637] [D loss: 0.153452] [G loss: 0.629617]\n",
      "[Epoch 23/200] [Batch 293/637] [D loss: 0.144464] [G loss: 0.596538]\n",
      "[Epoch 23/200] [Batch 294/637] [D loss: 0.169855] [G loss: 0.420300]\n",
      "[Epoch 23/200] [Batch 295/637] [D loss: 0.153271] [G loss: 0.470666]\n",
      "[Epoch 23/200] [Batch 296/637] [D loss: 0.164610] [G loss: 0.470465]\n",
      "[Epoch 23/200] [Batch 297/637] [D loss: 0.133088] [G loss: 0.528645]\n",
      "[Epoch 23/200] [Batch 298/637] [D loss: 0.151833] [G loss: 0.467812]\n",
      "[Epoch 23/200] [Batch 299/637] [D loss: 0.144307] [G loss: 0.563851]\n",
      "[Epoch 23/200] [Batch 300/637] [D loss: 0.151809] [G loss: 0.545846]\n",
      "[Epoch 23/200] [Batch 301/637] [D loss: 0.143509] [G loss: 0.513295]\n",
      "[Epoch 23/200] [Batch 302/637] [D loss: 0.153494] [G loss: 0.577947]\n",
      "[Epoch 23/200] [Batch 303/637] [D loss: 0.148648] [G loss: 0.524101]\n",
      "[Epoch 23/200] [Batch 304/637] [D loss: 0.179148] [G loss: 0.447427]\n",
      "[Epoch 23/200] [Batch 305/637] [D loss: 0.182066] [G loss: 0.425122]\n",
      "[Epoch 23/200] [Batch 306/637] [D loss: 0.198101] [G loss: 0.427841]\n",
      "[Epoch 23/200] [Batch 307/637] [D loss: 0.191566] [G loss: 0.532913]\n",
      "[Epoch 23/200] [Batch 308/637] [D loss: 0.206882] [G loss: 0.497205]\n",
      "[Epoch 23/200] [Batch 309/637] [D loss: 0.178175] [G loss: 0.522602]\n",
      "[Epoch 23/200] [Batch 310/637] [D loss: 0.171471] [G loss: 0.499566]\n",
      "[Epoch 23/200] [Batch 311/637] [D loss: 0.178052] [G loss: 0.498802]\n",
      "[Epoch 23/200] [Batch 312/637] [D loss: 0.171467] [G loss: 0.485715]\n",
      "[Epoch 23/200] [Batch 313/637] [D loss: 0.155229] [G loss: 0.573498]\n",
      "[Epoch 23/200] [Batch 314/637] [D loss: 0.171240] [G loss: 0.427361]\n",
      "[Epoch 23/200] [Batch 315/637] [D loss: 0.164117] [G loss: 0.503473]\n",
      "[Epoch 23/200] [Batch 316/637] [D loss: 0.164072] [G loss: 0.543909]\n",
      "[Epoch 23/200] [Batch 317/637] [D loss: 0.167781] [G loss: 0.478018]\n",
      "[Epoch 23/200] [Batch 318/637] [D loss: 0.159696] [G loss: 0.494628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/200] [Batch 319/637] [D loss: 0.162152] [G loss: 0.605399]\n",
      "[Epoch 23/200] [Batch 320/637] [D loss: 0.167814] [G loss: 0.535089]\n",
      "[Epoch 23/200] [Batch 321/637] [D loss: 0.143693] [G loss: 0.528557]\n",
      "[Epoch 23/200] [Batch 322/637] [D loss: 0.149260] [G loss: 0.479421]\n",
      "[Epoch 23/200] [Batch 323/637] [D loss: 0.159349] [G loss: 0.498606]\n",
      "[Epoch 23/200] [Batch 324/637] [D loss: 0.162738] [G loss: 0.524477]\n",
      "[Epoch 23/200] [Batch 325/637] [D loss: 0.147410] [G loss: 0.506292]\n",
      "[Epoch 23/200] [Batch 326/637] [D loss: 0.142525] [G loss: 0.560405]\n",
      "[Epoch 23/200] [Batch 327/637] [D loss: 0.167889] [G loss: 0.594923]\n",
      "[Epoch 23/200] [Batch 328/637] [D loss: 0.166190] [G loss: 0.490666]\n",
      "[Epoch 23/200] [Batch 329/637] [D loss: 0.173657] [G loss: 0.553704]\n",
      "[Epoch 23/200] [Batch 330/637] [D loss: 0.181875] [G loss: 0.495367]\n",
      "[Epoch 23/200] [Batch 331/637] [D loss: 0.160427] [G loss: 0.449157]\n",
      "[Epoch 23/200] [Batch 332/637] [D loss: 0.163249] [G loss: 0.459632]\n",
      "[Epoch 23/200] [Batch 333/637] [D loss: 0.162697] [G loss: 0.523621]\n",
      "[Epoch 23/200] [Batch 334/637] [D loss: 0.166176] [G loss: 0.518792]\n",
      "[Epoch 23/200] [Batch 335/637] [D loss: 0.161308] [G loss: 0.493187]\n",
      "[Epoch 23/200] [Batch 336/637] [D loss: 0.173418] [G loss: 0.422629]\n",
      "[Epoch 23/200] [Batch 337/637] [D loss: 0.154929] [G loss: 0.461885]\n",
      "[Epoch 23/200] [Batch 338/637] [D loss: 0.152811] [G loss: 0.533885]\n",
      "[Epoch 23/200] [Batch 339/637] [D loss: 0.158938] [G loss: 0.508464]\n",
      "[Epoch 23/200] [Batch 340/637] [D loss: 0.152461] [G loss: 0.503602]\n",
      "[Epoch 23/200] [Batch 341/637] [D loss: 0.157541] [G loss: 0.494475]\n",
      "[Epoch 23/200] [Batch 342/637] [D loss: 0.148021] [G loss: 0.514487]\n",
      "[Epoch 23/200] [Batch 343/637] [D loss: 0.175955] [G loss: 0.502101]\n",
      "[Epoch 23/200] [Batch 344/637] [D loss: 0.141847] [G loss: 0.534149]\n",
      "[Epoch 23/200] [Batch 345/637] [D loss: 0.181011] [G loss: 0.455259]\n",
      "[Epoch 23/200] [Batch 346/637] [D loss: 0.166267] [G loss: 0.570973]\n",
      "[Epoch 23/200] [Batch 347/637] [D loss: 0.170284] [G loss: 0.545720]\n",
      "[Epoch 23/200] [Batch 348/637] [D loss: 0.172888] [G loss: 0.480735]\n",
      "[Epoch 23/200] [Batch 349/637] [D loss: 0.172763] [G loss: 0.509271]\n",
      "[Epoch 23/200] [Batch 350/637] [D loss: 0.163652] [G loss: 0.477685]\n",
      "[Epoch 23/200] [Batch 351/637] [D loss: 0.149190] [G loss: 0.471894]\n",
      "[Epoch 23/200] [Batch 352/637] [D loss: 0.146784] [G loss: 0.480015]\n",
      "[Epoch 23/200] [Batch 353/637] [D loss: 0.178947] [G loss: 0.466510]\n",
      "[Epoch 23/200] [Batch 354/637] [D loss: 0.169111] [G loss: 0.532787]\n",
      "[Epoch 23/200] [Batch 355/637] [D loss: 0.150995] [G loss: 0.542276]\n",
      "[Epoch 23/200] [Batch 356/637] [D loss: 0.156535] [G loss: 0.507406]\n",
      "[Epoch 23/200] [Batch 357/637] [D loss: 0.182374] [G loss: 0.404470]\n",
      "[Epoch 23/200] [Batch 358/637] [D loss: 0.213684] [G loss: 0.543892]\n",
      "[Epoch 23/200] [Batch 359/637] [D loss: 0.174515] [G loss: 0.546009]\n",
      "[Epoch 23/200] [Batch 360/637] [D loss: 0.158337] [G loss: 0.518309]\n",
      "[Epoch 23/200] [Batch 361/637] [D loss: 0.168967] [G loss: 0.430530]\n",
      "[Epoch 23/200] [Batch 362/637] [D loss: 0.170909] [G loss: 0.458346]\n",
      "[Epoch 23/200] [Batch 363/637] [D loss: 0.145891] [G loss: 0.570434]\n",
      "[Epoch 23/200] [Batch 364/637] [D loss: 0.155868] [G loss: 0.604202]\n",
      "[Epoch 23/200] [Batch 365/637] [D loss: 0.157439] [G loss: 0.506657]\n",
      "[Epoch 23/200] [Batch 366/637] [D loss: 0.161159] [G loss: 0.444795]\n",
      "[Epoch 23/200] [Batch 367/637] [D loss: 0.142405] [G loss: 0.570402]\n",
      "[Epoch 23/200] [Batch 368/637] [D loss: 0.167542] [G loss: 0.613270]\n",
      "[Epoch 23/200] [Batch 369/637] [D loss: 0.148674] [G loss: 0.493931]\n",
      "[Epoch 23/200] [Batch 370/637] [D loss: 0.127182] [G loss: 0.614627]\n",
      "[Epoch 23/200] [Batch 371/637] [D loss: 0.168616] [G loss: 0.613732]\n",
      "[Epoch 23/200] [Batch 372/637] [D loss: 0.150772] [G loss: 0.581260]\n",
      "[Epoch 23/200] [Batch 373/637] [D loss: 0.133366] [G loss: 0.575857]\n",
      "[Epoch 23/200] [Batch 374/637] [D loss: 0.152461] [G loss: 0.515110]\n",
      "[Epoch 23/200] [Batch 375/637] [D loss: 0.202108] [G loss: 0.546156]\n",
      "[Epoch 23/200] [Batch 376/637] [D loss: 0.162731] [G loss: 0.527737]\n",
      "[Epoch 23/200] [Batch 377/637] [D loss: 0.160199] [G loss: 0.528373]\n",
      "[Epoch 23/200] [Batch 378/637] [D loss: 0.161471] [G loss: 0.616036]\n",
      "[Epoch 23/200] [Batch 379/637] [D loss: 0.151656] [G loss: 0.501523]\n",
      "[Epoch 23/200] [Batch 380/637] [D loss: 0.182719] [G loss: 0.439062]\n",
      "[Epoch 23/200] [Batch 381/637] [D loss: 0.190254] [G loss: 0.655116]\n",
      "[Epoch 23/200] [Batch 382/637] [D loss: 0.158702] [G loss: 0.605521]\n",
      "[Epoch 23/200] [Batch 383/637] [D loss: 0.143751] [G loss: 0.488642]\n",
      "[Epoch 23/200] [Batch 384/637] [D loss: 0.172171] [G loss: 0.418073]\n",
      "[Epoch 23/200] [Batch 385/637] [D loss: 0.158284] [G loss: 0.565520]\n",
      "[Epoch 23/200] [Batch 386/637] [D loss: 0.167341] [G loss: 0.564083]\n",
      "[Epoch 23/200] [Batch 387/637] [D loss: 0.180924] [G loss: 0.445859]\n",
      "[Epoch 23/200] [Batch 388/637] [D loss: 0.179012] [G loss: 0.506001]\n",
      "[Epoch 23/200] [Batch 389/637] [D loss: 0.168193] [G loss: 0.466733]\n",
      "[Epoch 23/200] [Batch 390/637] [D loss: 0.199558] [G loss: 0.563264]\n",
      "[Epoch 23/200] [Batch 391/637] [D loss: 0.168006] [G loss: 0.465483]\n",
      "[Epoch 23/200] [Batch 392/637] [D loss: 0.167871] [G loss: 0.485168]\n",
      "[Epoch 23/200] [Batch 393/637] [D loss: 0.186725] [G loss: 0.482889]\n",
      "[Epoch 23/200] [Batch 394/637] [D loss: 0.201738] [G loss: 0.475586]\n",
      "[Epoch 23/200] [Batch 395/637] [D loss: 0.153658] [G loss: 0.504597]\n",
      "[Epoch 23/200] [Batch 396/637] [D loss: 0.196337] [G loss: 0.493852]\n",
      "[Epoch 23/200] [Batch 397/637] [D loss: 0.168731] [G loss: 0.443992]\n",
      "[Epoch 23/200] [Batch 398/637] [D loss: 0.156192] [G loss: 0.480336]\n",
      "[Epoch 23/200] [Batch 399/637] [D loss: 0.144430] [G loss: 0.504401]\n",
      "[Epoch 23/200] [Batch 400/637] [D loss: 0.155761] [G loss: 0.529435]\n",
      "[Epoch 23/200] [Batch 401/637] [D loss: 0.148967] [G loss: 0.468808]\n",
      "[Epoch 23/200] [Batch 402/637] [D loss: 0.144734] [G loss: 0.494361]\n",
      "[Epoch 23/200] [Batch 403/637] [D loss: 0.179439] [G loss: 0.465954]\n",
      "[Epoch 23/200] [Batch 404/637] [D loss: 0.143903] [G loss: 0.496977]\n",
      "[Epoch 23/200] [Batch 405/637] [D loss: 0.153620] [G loss: 0.493323]\n",
      "[Epoch 23/200] [Batch 406/637] [D loss: 0.175511] [G loss: 0.523009]\n",
      "[Epoch 23/200] [Batch 407/637] [D loss: 0.140650] [G loss: 0.550281]\n",
      "[Epoch 23/200] [Batch 408/637] [D loss: 0.162879] [G loss: 0.525931]\n",
      "[Epoch 23/200] [Batch 409/637] [D loss: 0.178700] [G loss: 0.486626]\n",
      "[Epoch 23/200] [Batch 410/637] [D loss: 0.152825] [G loss: 0.509104]\n",
      "[Epoch 23/200] [Batch 411/637] [D loss: 0.186920] [G loss: 0.425138]\n",
      "[Epoch 23/200] [Batch 412/637] [D loss: 0.194720] [G loss: 0.598086]\n",
      "[Epoch 23/200] [Batch 413/637] [D loss: 0.173055] [G loss: 0.426707]\n",
      "[Epoch 23/200] [Batch 414/637] [D loss: 0.170028] [G loss: 0.466113]\n",
      "[Epoch 23/200] [Batch 415/637] [D loss: 0.187627] [G loss: 0.485979]\n",
      "[Epoch 23/200] [Batch 416/637] [D loss: 0.158338] [G loss: 0.611576]\n",
      "[Epoch 23/200] [Batch 417/637] [D loss: 0.172218] [G loss: 0.465912]\n",
      "[Epoch 23/200] [Batch 418/637] [D loss: 0.153514] [G loss: 0.478778]\n",
      "[Epoch 23/200] [Batch 419/637] [D loss: 0.148915] [G loss: 0.474633]\n",
      "[Epoch 23/200] [Batch 420/637] [D loss: 0.168833] [G loss: 0.462332]\n",
      "[Epoch 23/200] [Batch 421/637] [D loss: 0.174572] [G loss: 0.493140]\n",
      "[Epoch 23/200] [Batch 422/637] [D loss: 0.164429] [G loss: 0.531075]\n",
      "[Epoch 23/200] [Batch 423/637] [D loss: 0.172383] [G loss: 0.499526]\n",
      "[Epoch 23/200] [Batch 424/637] [D loss: 0.145839] [G loss: 0.534657]\n",
      "[Epoch 23/200] [Batch 425/637] [D loss: 0.155904] [G loss: 0.527186]\n",
      "[Epoch 23/200] [Batch 426/637] [D loss: 0.201050] [G loss: 0.466849]\n",
      "[Epoch 23/200] [Batch 427/637] [D loss: 0.162757] [G loss: 0.453109]\n",
      "[Epoch 23/200] [Batch 428/637] [D loss: 0.148820] [G loss: 0.573542]\n",
      "[Epoch 23/200] [Batch 429/637] [D loss: 0.149412] [G loss: 0.495143]\n",
      "[Epoch 23/200] [Batch 430/637] [D loss: 0.138266] [G loss: 0.539393]\n",
      "[Epoch 23/200] [Batch 431/637] [D loss: 0.163871] [G loss: 0.492343]\n",
      "[Epoch 23/200] [Batch 432/637] [D loss: 0.158043] [G loss: 0.515211]\n",
      "[Epoch 23/200] [Batch 433/637] [D loss: 0.157252] [G loss: 0.511221]\n",
      "[Epoch 23/200] [Batch 434/637] [D loss: 0.148637] [G loss: 0.468360]\n",
      "[Epoch 23/200] [Batch 435/637] [D loss: 0.180237] [G loss: 0.440852]\n",
      "[Epoch 23/200] [Batch 436/637] [D loss: 0.180215] [G loss: 0.493998]\n",
      "[Epoch 23/200] [Batch 437/637] [D loss: 0.173812] [G loss: 0.484118]\n",
      "[Epoch 23/200] [Batch 438/637] [D loss: 0.183858] [G loss: 0.419017]\n",
      "[Epoch 23/200] [Batch 439/637] [D loss: 0.156225] [G loss: 0.559944]\n",
      "[Epoch 23/200] [Batch 440/637] [D loss: 0.169242] [G loss: 0.484669]\n",
      "[Epoch 23/200] [Batch 441/637] [D loss: 0.164612] [G loss: 0.472269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/200] [Batch 442/637] [D loss: 0.183480] [G loss: 0.404410]\n",
      "[Epoch 23/200] [Batch 443/637] [D loss: 0.156121] [G loss: 0.523104]\n",
      "[Epoch 23/200] [Batch 444/637] [D loss: 0.163331] [G loss: 0.481414]\n",
      "[Epoch 23/200] [Batch 445/637] [D loss: 0.149475] [G loss: 0.489538]\n",
      "[Epoch 23/200] [Batch 446/637] [D loss: 0.171394] [G loss: 0.483371]\n",
      "[Epoch 23/200] [Batch 447/637] [D loss: 0.184486] [G loss: 0.483116]\n",
      "[Epoch 23/200] [Batch 448/637] [D loss: 0.178114] [G loss: 0.518033]\n",
      "[Epoch 23/200] [Batch 449/637] [D loss: 0.179184] [G loss: 0.469199]\n",
      "[Epoch 23/200] [Batch 450/637] [D loss: 0.167816] [G loss: 0.491624]\n",
      "[Epoch 23/200] [Batch 451/637] [D loss: 0.167702] [G loss: 0.461053]\n",
      "[Epoch 23/200] [Batch 452/637] [D loss: 0.155221] [G loss: 0.531280]\n",
      "[Epoch 23/200] [Batch 453/637] [D loss: 0.135876] [G loss: 0.577338]\n",
      "[Epoch 23/200] [Batch 454/637] [D loss: 0.165229] [G loss: 0.480647]\n",
      "[Epoch 23/200] [Batch 455/637] [D loss: 0.161028] [G loss: 0.488472]\n",
      "[Epoch 23/200] [Batch 456/637] [D loss: 0.191151] [G loss: 0.559014]\n",
      "[Epoch 23/200] [Batch 457/637] [D loss: 0.164751] [G loss: 0.483760]\n",
      "[Epoch 23/200] [Batch 458/637] [D loss: 0.160237] [G loss: 0.505606]\n",
      "[Epoch 23/200] [Batch 459/637] [D loss: 0.136900] [G loss: 0.528050]\n",
      "[Epoch 23/200] [Batch 460/637] [D loss: 0.155373] [G loss: 0.517644]\n",
      "[Epoch 23/200] [Batch 461/637] [D loss: 0.148028] [G loss: 0.536169]\n",
      "[Epoch 23/200] [Batch 462/637] [D loss: 0.176654] [G loss: 0.445373]\n",
      "[Epoch 23/200] [Batch 463/637] [D loss: 0.146948] [G loss: 0.545672]\n",
      "[Epoch 23/200] [Batch 464/637] [D loss: 0.157321] [G loss: 0.569824]\n",
      "[Epoch 23/200] [Batch 465/637] [D loss: 0.176704] [G loss: 0.453806]\n",
      "[Epoch 23/200] [Batch 466/637] [D loss: 0.173546] [G loss: 0.559925]\n",
      "[Epoch 23/200] [Batch 467/637] [D loss: 0.160176] [G loss: 0.457211]\n",
      "[Epoch 23/200] [Batch 468/637] [D loss: 0.163893] [G loss: 0.535643]\n",
      "[Epoch 23/200] [Batch 469/637] [D loss: 0.180194] [G loss: 0.543835]\n",
      "[Epoch 23/200] [Batch 470/637] [D loss: 0.144923] [G loss: 0.566611]\n",
      "[Epoch 23/200] [Batch 471/637] [D loss: 0.157424] [G loss: 0.527379]\n",
      "[Epoch 23/200] [Batch 472/637] [D loss: 0.157361] [G loss: 0.493575]\n",
      "[Epoch 23/200] [Batch 473/637] [D loss: 0.154224] [G loss: 0.525394]\n",
      "[Epoch 23/200] [Batch 474/637] [D loss: 0.172323] [G loss: 0.466331]\n",
      "[Epoch 23/200] [Batch 475/637] [D loss: 0.173240] [G loss: 0.537737]\n",
      "[Epoch 23/200] [Batch 476/637] [D loss: 0.183626] [G loss: 0.504858]\n",
      "[Epoch 23/200] [Batch 477/637] [D loss: 0.173464] [G loss: 0.637473]\n",
      "[Epoch 23/200] [Batch 478/637] [D loss: 0.153593] [G loss: 0.528842]\n",
      "[Epoch 23/200] [Batch 479/637] [D loss: 0.178621] [G loss: 0.463815]\n",
      "[Epoch 23/200] [Batch 480/637] [D loss: 0.145260] [G loss: 0.592285]\n",
      "[Epoch 23/200] [Batch 481/637] [D loss: 0.181909] [G loss: 0.606389]\n",
      "[Epoch 23/200] [Batch 482/637] [D loss: 0.212382] [G loss: 0.362293]\n",
      "[Epoch 23/200] [Batch 483/637] [D loss: 0.177982] [G loss: 0.561543]\n",
      "[Epoch 23/200] [Batch 484/637] [D loss: 0.187941] [G loss: 0.456397]\n",
      "[Epoch 23/200] [Batch 485/637] [D loss: 0.163510] [G loss: 0.480131]\n",
      "[Epoch 23/200] [Batch 486/637] [D loss: 0.182249] [G loss: 0.532851]\n",
      "[Epoch 23/200] [Batch 487/637] [D loss: 0.171117] [G loss: 0.572836]\n",
      "[Epoch 23/200] [Batch 488/637] [D loss: 0.159503] [G loss: 0.556543]\n",
      "[Epoch 23/200] [Batch 489/637] [D loss: 0.155427] [G loss: 0.485894]\n",
      "[Epoch 23/200] [Batch 490/637] [D loss: 0.183367] [G loss: 0.441203]\n",
      "[Epoch 23/200] [Batch 491/637] [D loss: 0.163867] [G loss: 0.495091]\n",
      "[Epoch 23/200] [Batch 492/637] [D loss: 0.163045] [G loss: 0.551634]\n",
      "[Epoch 23/200] [Batch 493/637] [D loss: 0.193589] [G loss: 0.475935]\n",
      "[Epoch 23/200] [Batch 494/637] [D loss: 0.182877] [G loss: 0.495784]\n",
      "[Epoch 23/200] [Batch 495/637] [D loss: 0.184429] [G loss: 0.500307]\n",
      "[Epoch 23/200] [Batch 496/637] [D loss: 0.146581] [G loss: 0.490897]\n",
      "[Epoch 23/200] [Batch 497/637] [D loss: 0.195919] [G loss: 0.403011]\n",
      "[Epoch 23/200] [Batch 498/637] [D loss: 0.171898] [G loss: 0.544102]\n",
      "[Epoch 23/200] [Batch 499/637] [D loss: 0.171302] [G loss: 0.571921]\n",
      "[Epoch 23/200] [Batch 500/637] [D loss: 0.147809] [G loss: 0.541912]\n",
      "[Epoch 23/200] [Batch 501/637] [D loss: 0.168511] [G loss: 0.479242]\n",
      "[Epoch 23/200] [Batch 502/637] [D loss: 0.175254] [G loss: 0.421902]\n",
      "[Epoch 23/200] [Batch 503/637] [D loss: 0.173161] [G loss: 0.474363]\n",
      "[Epoch 23/200] [Batch 504/637] [D loss: 0.165458] [G loss: 0.487213]\n",
      "[Epoch 23/200] [Batch 505/637] [D loss: 0.176177] [G loss: 0.506292]\n",
      "[Epoch 23/200] [Batch 506/637] [D loss: 0.159579] [G loss: 0.433642]\n",
      "[Epoch 23/200] [Batch 507/637] [D loss: 0.161924] [G loss: 0.513196]\n",
      "[Epoch 23/200] [Batch 508/637] [D loss: 0.162035] [G loss: 0.470668]\n",
      "[Epoch 23/200] [Batch 509/637] [D loss: 0.190039] [G loss: 0.433168]\n",
      "[Epoch 23/200] [Batch 510/637] [D loss: 0.186948] [G loss: 0.682402]\n",
      "[Epoch 23/200] [Batch 511/637] [D loss: 0.167136] [G loss: 0.535343]\n",
      "[Epoch 23/200] [Batch 512/637] [D loss: 0.165678] [G loss: 0.462052]\n",
      "[Epoch 23/200] [Batch 513/637] [D loss: 0.170366] [G loss: 0.501031]\n",
      "[Epoch 23/200] [Batch 514/637] [D loss: 0.150136] [G loss: 0.543486]\n",
      "[Epoch 23/200] [Batch 515/637] [D loss: 0.207945] [G loss: 0.481777]\n",
      "[Epoch 23/200] [Batch 516/637] [D loss: 0.177348] [G loss: 0.582980]\n",
      "[Epoch 23/200] [Batch 517/637] [D loss: 0.162308] [G loss: 0.542661]\n",
      "[Epoch 23/200] [Batch 518/637] [D loss: 0.161796] [G loss: 0.432211]\n",
      "[Epoch 23/200] [Batch 519/637] [D loss: 0.160032] [G loss: 0.429744]\n",
      "[Epoch 23/200] [Batch 520/637] [D loss: 0.179298] [G loss: 0.529973]\n",
      "[Epoch 23/200] [Batch 521/637] [D loss: 0.220038] [G loss: 0.506691]\n",
      "[Epoch 23/200] [Batch 522/637] [D loss: 0.175951] [G loss: 0.621792]\n",
      "[Epoch 23/200] [Batch 523/637] [D loss: 0.174129] [G loss: 0.603065]\n",
      "[Epoch 23/200] [Batch 524/637] [D loss: 0.177363] [G loss: 0.439840]\n",
      "[Epoch 23/200] [Batch 525/637] [D loss: 0.156333] [G loss: 0.467930]\n",
      "[Epoch 23/200] [Batch 526/637] [D loss: 0.175936] [G loss: 0.395165]\n",
      "[Epoch 23/200] [Batch 527/637] [D loss: 0.154080] [G loss: 0.583825]\n",
      "[Epoch 23/200] [Batch 528/637] [D loss: 0.180080] [G loss: 0.503313]\n",
      "[Epoch 23/200] [Batch 529/637] [D loss: 0.156740] [G loss: 0.448749]\n",
      "[Epoch 23/200] [Batch 530/637] [D loss: 0.169767] [G loss: 0.468641]\n",
      "[Epoch 23/200] [Batch 531/637] [D loss: 0.145797] [G loss: 0.462232]\n",
      "[Epoch 23/200] [Batch 532/637] [D loss: 0.171689] [G loss: 0.507552]\n",
      "[Epoch 23/200] [Batch 533/637] [D loss: 0.155659] [G loss: 0.462881]\n",
      "[Epoch 23/200] [Batch 534/637] [D loss: 0.161884] [G loss: 0.491484]\n",
      "[Epoch 23/200] [Batch 535/637] [D loss: 0.187714] [G loss: 0.453098]\n",
      "[Epoch 23/200] [Batch 536/637] [D loss: 0.171808] [G loss: 0.466142]\n",
      "[Epoch 23/200] [Batch 537/637] [D loss: 0.151719] [G loss: 0.474275]\n",
      "[Epoch 23/200] [Batch 538/637] [D loss: 0.178176] [G loss: 0.415852]\n",
      "[Epoch 23/200] [Batch 539/637] [D loss: 0.149283] [G loss: 0.550407]\n",
      "[Epoch 23/200] [Batch 540/637] [D loss: 0.153970] [G loss: 0.526576]\n",
      "[Epoch 23/200] [Batch 541/637] [D loss: 0.163659] [G loss: 0.508707]\n",
      "[Epoch 23/200] [Batch 542/637] [D loss: 0.182133] [G loss: 0.422624]\n",
      "[Epoch 23/200] [Batch 543/637] [D loss: 0.172662] [G loss: 0.470999]\n",
      "[Epoch 23/200] [Batch 544/637] [D loss: 0.169474] [G loss: 0.669827]\n",
      "[Epoch 23/200] [Batch 545/637] [D loss: 0.189723] [G loss: 0.499211]\n",
      "[Epoch 23/200] [Batch 546/637] [D loss: 0.146089] [G loss: 0.478193]\n",
      "[Epoch 23/200] [Batch 547/637] [D loss: 0.138872] [G loss: 0.582787]\n",
      "[Epoch 23/200] [Batch 548/637] [D loss: 0.167829] [G loss: 0.487448]\n",
      "[Epoch 23/200] [Batch 549/637] [D loss: 0.154566] [G loss: 0.559710]\n",
      "[Epoch 23/200] [Batch 550/637] [D loss: 0.175778] [G loss: 0.529294]\n",
      "[Epoch 23/200] [Batch 551/637] [D loss: 0.198056] [G loss: 0.421058]\n",
      "[Epoch 23/200] [Batch 552/637] [D loss: 0.146590] [G loss: 0.468634]\n",
      "[Epoch 23/200] [Batch 553/637] [D loss: 0.174123] [G loss: 0.463541]\n",
      "[Epoch 23/200] [Batch 554/637] [D loss: 0.170446] [G loss: 0.476886]\n",
      "[Epoch 23/200] [Batch 555/637] [D loss: 0.132147] [G loss: 0.539692]\n",
      "[Epoch 23/200] [Batch 556/637] [D loss: 0.166046] [G loss: 0.578762]\n",
      "[Epoch 23/200] [Batch 557/637] [D loss: 0.182194] [G loss: 0.450095]\n",
      "[Epoch 23/200] [Batch 558/637] [D loss: 0.156848] [G loss: 0.406324]\n",
      "[Epoch 23/200] [Batch 559/637] [D loss: 0.155175] [G loss: 0.509365]\n",
      "[Epoch 23/200] [Batch 560/637] [D loss: 0.155430] [G loss: 0.550802]\n",
      "[Epoch 23/200] [Batch 561/637] [D loss: 0.163210] [G loss: 0.580749]\n",
      "[Epoch 23/200] [Batch 562/637] [D loss: 0.177190] [G loss: 0.450494]\n",
      "[Epoch 23/200] [Batch 563/637] [D loss: 0.183580] [G loss: 0.432935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/200] [Batch 564/637] [D loss: 0.185362] [G loss: 0.486343]\n",
      "[Epoch 23/200] [Batch 565/637] [D loss: 0.164371] [G loss: 0.596539]\n",
      "[Epoch 23/200] [Batch 566/637] [D loss: 0.174571] [G loss: 0.489252]\n",
      "[Epoch 23/200] [Batch 567/637] [D loss: 0.138017] [G loss: 0.519972]\n",
      "[Epoch 23/200] [Batch 568/637] [D loss: 0.169989] [G loss: 0.456668]\n",
      "[Epoch 23/200] [Batch 569/637] [D loss: 0.161932] [G loss: 0.479560]\n",
      "[Epoch 23/200] [Batch 570/637] [D loss: 0.133544] [G loss: 0.496614]\n",
      "[Epoch 23/200] [Batch 571/637] [D loss: 0.178231] [G loss: 0.457852]\n",
      "[Epoch 23/200] [Batch 572/637] [D loss: 0.151687] [G loss: 0.608255]\n",
      "[Epoch 23/200] [Batch 573/637] [D loss: 0.147093] [G loss: 0.515609]\n",
      "[Epoch 23/200] [Batch 574/637] [D loss: 0.179785] [G loss: 0.417431]\n",
      "[Epoch 23/200] [Batch 575/637] [D loss: 0.169682] [G loss: 0.456846]\n",
      "[Epoch 23/200] [Batch 576/637] [D loss: 0.165066] [G loss: 0.601639]\n",
      "[Epoch 23/200] [Batch 577/637] [D loss: 0.168280] [G loss: 0.484182]\n",
      "[Epoch 23/200] [Batch 578/637] [D loss: 0.152553] [G loss: 0.577734]\n",
      "[Epoch 23/200] [Batch 579/637] [D loss: 0.221650] [G loss: 0.400833]\n",
      "[Epoch 23/200] [Batch 580/637] [D loss: 0.244267] [G loss: 0.396124]\n",
      "[Epoch 23/200] [Batch 581/637] [D loss: 0.238370] [G loss: 0.765255]\n",
      "[Epoch 23/200] [Batch 582/637] [D loss: 0.202824] [G loss: 0.578705]\n",
      "[Epoch 23/200] [Batch 583/637] [D loss: 0.166936] [G loss: 0.456005]\n",
      "[Epoch 23/200] [Batch 584/637] [D loss: 0.180224] [G loss: 0.405466]\n",
      "[Epoch 23/200] [Batch 585/637] [D loss: 0.157643] [G loss: 0.467945]\n",
      "[Epoch 23/200] [Batch 586/637] [D loss: 0.147483] [G loss: 0.514175]\n",
      "[Epoch 23/200] [Batch 587/637] [D loss: 0.161126] [G loss: 0.498408]\n",
      "[Epoch 23/200] [Batch 588/637] [D loss: 0.198279] [G loss: 0.460490]\n",
      "[Epoch 23/200] [Batch 589/637] [D loss: 0.168407] [G loss: 0.504547]\n",
      "[Epoch 23/200] [Batch 590/637] [D loss: 0.177407] [G loss: 0.486032]\n",
      "[Epoch 23/200] [Batch 591/637] [D loss: 0.193950] [G loss: 0.458904]\n",
      "[Epoch 23/200] [Batch 592/637] [D loss: 0.161471] [G loss: 0.475290]\n",
      "[Epoch 23/200] [Batch 593/637] [D loss: 0.153156] [G loss: 0.464860]\n",
      "[Epoch 23/200] [Batch 594/637] [D loss: 0.185936] [G loss: 0.468282]\n",
      "[Epoch 23/200] [Batch 595/637] [D loss: 0.168445] [G loss: 0.528867]\n",
      "[Epoch 23/200] [Batch 596/637] [D loss: 0.150808] [G loss: 0.580837]\n",
      "[Epoch 23/200] [Batch 597/637] [D loss: 0.173702] [G loss: 0.446266]\n",
      "[Epoch 23/200] [Batch 598/637] [D loss: 0.187409] [G loss: 0.438528]\n",
      "[Epoch 23/200] [Batch 599/637] [D loss: 0.157410] [G loss: 0.503610]\n",
      "[Epoch 23/200] [Batch 600/637] [D loss: 0.151765] [G loss: 0.517726]\n",
      "[Epoch 23/200] [Batch 601/637] [D loss: 0.136388] [G loss: 0.545918]\n",
      "[Epoch 23/200] [Batch 602/637] [D loss: 0.160023] [G loss: 0.501467]\n",
      "[Epoch 23/200] [Batch 603/637] [D loss: 0.173818] [G loss: 0.474026]\n",
      "[Epoch 23/200] [Batch 604/637] [D loss: 0.176115] [G loss: 0.574588]\n",
      "[Epoch 23/200] [Batch 605/637] [D loss: 0.142532] [G loss: 0.548092]\n",
      "[Epoch 23/200] [Batch 606/637] [D loss: 0.181958] [G loss: 0.474483]\n",
      "[Epoch 23/200] [Batch 607/637] [D loss: 0.156301] [G loss: 0.552397]\n",
      "[Epoch 23/200] [Batch 608/637] [D loss: 0.167587] [G loss: 0.510599]\n",
      "[Epoch 23/200] [Batch 609/637] [D loss: 0.158680] [G loss: 0.595275]\n",
      "[Epoch 23/200] [Batch 610/637] [D loss: 0.161792] [G loss: 0.581422]\n",
      "[Epoch 23/200] [Batch 611/637] [D loss: 0.179231] [G loss: 0.437420]\n",
      "[Epoch 23/200] [Batch 612/637] [D loss: 0.178757] [G loss: 0.451394]\n",
      "[Epoch 23/200] [Batch 613/637] [D loss: 0.172542] [G loss: 0.682143]\n",
      "[Epoch 23/200] [Batch 614/637] [D loss: 0.164207] [G loss: 0.601804]\n",
      "[Epoch 23/200] [Batch 615/637] [D loss: 0.142010] [G loss: 0.486723]\n",
      "[Epoch 23/200] [Batch 616/637] [D loss: 0.135355] [G loss: 0.490615]\n",
      "[Epoch 23/200] [Batch 617/637] [D loss: 0.173436] [G loss: 0.472955]\n",
      "[Epoch 23/200] [Batch 618/637] [D loss: 0.190987] [G loss: 0.522573]\n",
      "[Epoch 23/200] [Batch 619/637] [D loss: 0.158899] [G loss: 0.510924]\n",
      "[Epoch 23/200] [Batch 620/637] [D loss: 0.186322] [G loss: 0.438381]\n",
      "[Epoch 23/200] [Batch 621/637] [D loss: 0.183987] [G loss: 0.494599]\n",
      "[Epoch 23/200] [Batch 622/637] [D loss: 0.160099] [G loss: 0.410165]\n",
      "[Epoch 23/200] [Batch 623/637] [D loss: 0.194839] [G loss: 0.445412]\n",
      "[Epoch 23/200] [Batch 624/637] [D loss: 0.170040] [G loss: 0.468848]\n",
      "[Epoch 23/200] [Batch 625/637] [D loss: 0.172624] [G loss: 0.524911]\n",
      "[Epoch 23/200] [Batch 626/637] [D loss: 0.168444] [G loss: 0.553995]\n",
      "[Epoch 23/200] [Batch 627/637] [D loss: 0.168390] [G loss: 0.558315]\n",
      "[Epoch 23/200] [Batch 628/637] [D loss: 0.171029] [G loss: 0.495005]\n",
      "[Epoch 23/200] [Batch 629/637] [D loss: 0.131875] [G loss: 0.531583]\n",
      "[Epoch 23/200] [Batch 630/637] [D loss: 0.226409] [G loss: 0.409729]\n",
      "[Epoch 23/200] [Batch 631/637] [D loss: 0.183094] [G loss: 0.477133]\n",
      "[Epoch 23/200] [Batch 632/637] [D loss: 0.177857] [G loss: 0.562222]\n",
      "[Epoch 23/200] [Batch 633/637] [D loss: 0.161777] [G loss: 0.500095]\n",
      "[Epoch 23/200] [Batch 634/637] [D loss: 0.182910] [G loss: 0.479752]\n",
      "[Epoch 23/200] [Batch 635/637] [D loss: 0.141113] [G loss: 0.474991]\n",
      "[Epoch 23/200] [Batch 636/637] [D loss: 0.124767] [G loss: 0.598875]\n",
      "[Epoch 24/200] [Batch 0/637] [D loss: 0.157876] [G loss: 0.538566]\n",
      "[Epoch 24/200] [Batch 1/637] [D loss: 0.139302] [G loss: 0.551572]\n",
      "[Epoch 24/200] [Batch 2/637] [D loss: 0.194166] [G loss: 0.430541]\n",
      "[Epoch 24/200] [Batch 3/637] [D loss: 0.179789] [G loss: 0.538446]\n",
      "[Epoch 24/200] [Batch 4/637] [D loss: 0.162949] [G loss: 0.526536]\n",
      "[Epoch 24/200] [Batch 5/637] [D loss: 0.171423] [G loss: 0.544488]\n",
      "[Epoch 24/200] [Batch 6/637] [D loss: 0.181631] [G loss: 0.455447]\n",
      "[Epoch 24/200] [Batch 7/637] [D loss: 0.161421] [G loss: 0.546510]\n",
      "[Epoch 24/200] [Batch 8/637] [D loss: 0.162580] [G loss: 0.480822]\n",
      "[Epoch 24/200] [Batch 9/637] [D loss: 0.186822] [G loss: 0.468400]\n",
      "[Epoch 24/200] [Batch 10/637] [D loss: 0.153589] [G loss: 0.650255]\n",
      "[Epoch 24/200] [Batch 11/637] [D loss: 0.160489] [G loss: 0.595859]\n",
      "[Epoch 24/200] [Batch 12/637] [D loss: 0.164518] [G loss: 0.521200]\n",
      "[Epoch 24/200] [Batch 13/637] [D loss: 0.159031] [G loss: 0.502393]\n",
      "[Epoch 24/200] [Batch 14/637] [D loss: 0.165331] [G loss: 0.514378]\n",
      "[Epoch 24/200] [Batch 15/637] [D loss: 0.166385] [G loss: 0.526808]\n",
      "[Epoch 24/200] [Batch 16/637] [D loss: 0.155452] [G loss: 0.464977]\n",
      "[Epoch 24/200] [Batch 17/637] [D loss: 0.168868] [G loss: 0.460155]\n",
      "[Epoch 24/200] [Batch 18/637] [D loss: 0.157155] [G loss: 0.480974]\n",
      "[Epoch 24/200] [Batch 19/637] [D loss: 0.194165] [G loss: 0.462991]\n",
      "[Epoch 24/200] [Batch 20/637] [D loss: 0.139979] [G loss: 0.574507]\n",
      "[Epoch 24/200] [Batch 21/637] [D loss: 0.149126] [G loss: 0.465513]\n",
      "[Epoch 24/200] [Batch 22/637] [D loss: 0.163518] [G loss: 0.439384]\n",
      "[Epoch 24/200] [Batch 23/637] [D loss: 0.153880] [G loss: 0.478881]\n",
      "[Epoch 24/200] [Batch 24/637] [D loss: 0.179299] [G loss: 0.494418]\n",
      "[Epoch 24/200] [Batch 25/637] [D loss: 0.148268] [G loss: 0.540499]\n",
      "[Epoch 24/200] [Batch 26/637] [D loss: 0.166364] [G loss: 0.502304]\n",
      "[Epoch 24/200] [Batch 27/637] [D loss: 0.174619] [G loss: 0.436015]\n",
      "[Epoch 24/200] [Batch 28/637] [D loss: 0.158946] [G loss: 0.420660]\n",
      "[Epoch 24/200] [Batch 29/637] [D loss: 0.137726] [G loss: 0.504327]\n",
      "[Epoch 24/200] [Batch 30/637] [D loss: 0.159416] [G loss: 0.454323]\n",
      "[Epoch 24/200] [Batch 31/637] [D loss: 0.165740] [G loss: 0.532818]\n",
      "[Epoch 24/200] [Batch 32/637] [D loss: 0.174372] [G loss: 0.518855]\n",
      "[Epoch 24/200] [Batch 33/637] [D loss: 0.187982] [G loss: 0.476431]\n",
      "[Epoch 24/200] [Batch 34/637] [D loss: 0.152922] [G loss: 0.516197]\n",
      "[Epoch 24/200] [Batch 35/637] [D loss: 0.171653] [G loss: 0.494987]\n",
      "[Epoch 24/200] [Batch 36/637] [D loss: 0.163602] [G loss: 0.513772]\n",
      "[Epoch 24/200] [Batch 37/637] [D loss: 0.172688] [G loss: 0.465429]\n",
      "[Epoch 24/200] [Batch 38/637] [D loss: 0.165836] [G loss: 0.459833]\n",
      "[Epoch 24/200] [Batch 39/637] [D loss: 0.176863] [G loss: 0.559427]\n",
      "[Epoch 24/200] [Batch 40/637] [D loss: 0.175590] [G loss: 0.573670]\n",
      "[Epoch 24/200] [Batch 41/637] [D loss: 0.170283] [G loss: 0.502576]\n",
      "[Epoch 24/200] [Batch 42/637] [D loss: 0.163575] [G loss: 0.553505]\n",
      "[Epoch 24/200] [Batch 43/637] [D loss: 0.185598] [G loss: 0.492532]\n",
      "[Epoch 24/200] [Batch 44/637] [D loss: 0.146819] [G loss: 0.554549]\n",
      "[Epoch 24/200] [Batch 45/637] [D loss: 0.163525] [G loss: 0.465787]\n",
      "[Epoch 24/200] [Batch 46/637] [D loss: 0.184400] [G loss: 0.441322]\n",
      "[Epoch 24/200] [Batch 47/637] [D loss: 0.199684] [G loss: 0.411396]\n",
      "[Epoch 24/200] [Batch 48/637] [D loss: 0.167903] [G loss: 0.544859]\n",
      "[Epoch 24/200] [Batch 49/637] [D loss: 0.172853] [G loss: 0.495256]\n",
      "[Epoch 24/200] [Batch 50/637] [D loss: 0.156398] [G loss: 0.508481]\n",
      "[Epoch 24/200] [Batch 51/637] [D loss: 0.152708] [G loss: 0.480378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 52/637] [D loss: 0.178820] [G loss: 0.479270]\n",
      "[Epoch 24/200] [Batch 53/637] [D loss: 0.180782] [G loss: 0.474473]\n",
      "[Epoch 24/200] [Batch 54/637] [D loss: 0.163246] [G loss: 0.590840]\n",
      "[Epoch 24/200] [Batch 55/637] [D loss: 0.156806] [G loss: 0.523680]\n",
      "[Epoch 24/200] [Batch 56/637] [D loss: 0.166643] [G loss: 0.513792]\n",
      "[Epoch 24/200] [Batch 57/637] [D loss: 0.165913] [G loss: 0.520820]\n",
      "[Epoch 24/200] [Batch 58/637] [D loss: 0.165429] [G loss: 0.447627]\n",
      "[Epoch 24/200] [Batch 59/637] [D loss: 0.161506] [G loss: 0.477538]\n",
      "[Epoch 24/200] [Batch 60/637] [D loss: 0.201884] [G loss: 0.568832]\n",
      "[Epoch 24/200] [Batch 61/637] [D loss: 0.177250] [G loss: 0.551736]\n",
      "[Epoch 24/200] [Batch 62/637] [D loss: 0.166110] [G loss: 0.483070]\n",
      "[Epoch 24/200] [Batch 63/637] [D loss: 0.187336] [G loss: 0.488915]\n",
      "[Epoch 24/200] [Batch 64/637] [D loss: 0.161778] [G loss: 0.499320]\n",
      "[Epoch 24/200] [Batch 65/637] [D loss: 0.169191] [G loss: 0.483956]\n",
      "[Epoch 24/200] [Batch 66/637] [D loss: 0.169893] [G loss: 0.490478]\n",
      "[Epoch 24/200] [Batch 67/637] [D loss: 0.160453] [G loss: 0.501932]\n",
      "[Epoch 24/200] [Batch 68/637] [D loss: 0.167665] [G loss: 0.471584]\n",
      "[Epoch 24/200] [Batch 69/637] [D loss: 0.167913] [G loss: 0.520680]\n",
      "[Epoch 24/200] [Batch 70/637] [D loss: 0.148713] [G loss: 0.515119]\n",
      "[Epoch 24/200] [Batch 71/637] [D loss: 0.164084] [G loss: 0.534580]\n",
      "[Epoch 24/200] [Batch 72/637] [D loss: 0.152366] [G loss: 0.522621]\n",
      "[Epoch 24/200] [Batch 73/637] [D loss: 0.187494] [G loss: 0.491248]\n",
      "[Epoch 24/200] [Batch 74/637] [D loss: 0.179323] [G loss: 0.738498]\n",
      "[Epoch 24/200] [Batch 75/637] [D loss: 0.165529] [G loss: 0.574821]\n",
      "[Epoch 24/200] [Batch 76/637] [D loss: 0.152283] [G loss: 0.475240]\n",
      "[Epoch 24/200] [Batch 77/637] [D loss: 0.166117] [G loss: 0.417336]\n",
      "[Epoch 24/200] [Batch 78/637] [D loss: 0.154188] [G loss: 0.536355]\n",
      "[Epoch 24/200] [Batch 79/637] [D loss: 0.142997] [G loss: 0.523690]\n",
      "[Epoch 24/200] [Batch 80/637] [D loss: 0.193219] [G loss: 0.465652]\n",
      "[Epoch 24/200] [Batch 81/637] [D loss: 0.191709] [G loss: 0.548726]\n",
      "[Epoch 24/200] [Batch 82/637] [D loss: 0.169748] [G loss: 0.460240]\n",
      "[Epoch 24/200] [Batch 83/637] [D loss: 0.181261] [G loss: 0.403784]\n",
      "[Epoch 24/200] [Batch 84/637] [D loss: 0.170998] [G loss: 0.531053]\n",
      "[Epoch 24/200] [Batch 85/637] [D loss: 0.150123] [G loss: 0.491856]\n",
      "[Epoch 24/200] [Batch 86/637] [D loss: 0.154308] [G loss: 0.550882]\n",
      "[Epoch 24/200] [Batch 87/637] [D loss: 0.172608] [G loss: 0.437161]\n",
      "[Epoch 24/200] [Batch 88/637] [D loss: 0.149976] [G loss: 0.488254]\n",
      "[Epoch 24/200] [Batch 89/637] [D loss: 0.157238] [G loss: 0.474011]\n",
      "[Epoch 24/200] [Batch 90/637] [D loss: 0.153458] [G loss: 0.533064]\n",
      "[Epoch 24/200] [Batch 91/637] [D loss: 0.123534] [G loss: 0.623217]\n",
      "[Epoch 24/200] [Batch 92/637] [D loss: 0.136199] [G loss: 0.556441]\n",
      "[Epoch 24/200] [Batch 93/637] [D loss: 0.157832] [G loss: 0.519190]\n",
      "[Epoch 24/200] [Batch 94/637] [D loss: 0.176176] [G loss: 0.507595]\n",
      "[Epoch 24/200] [Batch 95/637] [D loss: 0.146084] [G loss: 0.538977]\n",
      "[Epoch 24/200] [Batch 96/637] [D loss: 0.163405] [G loss: 0.510249]\n",
      "[Epoch 24/200] [Batch 97/637] [D loss: 0.162655] [G loss: 0.516659]\n",
      "[Epoch 24/200] [Batch 98/637] [D loss: 0.164350] [G loss: 0.530401]\n",
      "[Epoch 24/200] [Batch 99/637] [D loss: 0.160959] [G loss: 0.460591]\n",
      "[Epoch 24/200] [Batch 100/637] [D loss: 0.149496] [G loss: 0.464072]\n",
      "[Epoch 24/200] [Batch 101/637] [D loss: 0.153350] [G loss: 0.525440]\n",
      "[Epoch 24/200] [Batch 102/637] [D loss: 0.172803] [G loss: 0.413365]\n",
      "[Epoch 24/200] [Batch 103/637] [D loss: 0.175527] [G loss: 0.462831]\n",
      "[Epoch 24/200] [Batch 104/637] [D loss: 0.173974] [G loss: 0.542156]\n",
      "[Epoch 24/200] [Batch 105/637] [D loss: 0.148610] [G loss: 0.548898]\n",
      "[Epoch 24/200] [Batch 106/637] [D loss: 0.156891] [G loss: 0.485328]\n",
      "[Epoch 24/200] [Batch 107/637] [D loss: 0.180317] [G loss: 0.446157]\n",
      "[Epoch 24/200] [Batch 108/637] [D loss: 0.181195] [G loss: 0.483417]\n",
      "[Epoch 24/200] [Batch 109/637] [D loss: 0.166526] [G loss: 0.534657]\n",
      "[Epoch 24/200] [Batch 110/637] [D loss: 0.173534] [G loss: 0.521026]\n",
      "[Epoch 24/200] [Batch 111/637] [D loss: 0.166082] [G loss: 0.472335]\n",
      "[Epoch 24/200] [Batch 112/637] [D loss: 0.167929] [G loss: 0.484584]\n",
      "[Epoch 24/200] [Batch 113/637] [D loss: 0.161576] [G loss: 0.529878]\n",
      "[Epoch 24/200] [Batch 114/637] [D loss: 0.159291] [G loss: 0.522977]\n",
      "[Epoch 24/200] [Batch 115/637] [D loss: 0.155470] [G loss: 0.546294]\n",
      "[Epoch 24/200] [Batch 116/637] [D loss: 0.186149] [G loss: 0.557554]\n",
      "[Epoch 24/200] [Batch 117/637] [D loss: 0.178363] [G loss: 0.363298]\n",
      "[Epoch 24/200] [Batch 118/637] [D loss: 0.170037] [G loss: 0.403181]\n",
      "[Epoch 24/200] [Batch 119/637] [D loss: 0.163240] [G loss: 0.603058]\n",
      "[Epoch 24/200] [Batch 120/637] [D loss: 0.184553] [G loss: 0.486636]\n",
      "[Epoch 24/200] [Batch 121/637] [D loss: 0.155232] [G loss: 0.473964]\n",
      "[Epoch 24/200] [Batch 122/637] [D loss: 0.179590] [G loss: 0.465059]\n",
      "[Epoch 24/200] [Batch 123/637] [D loss: 0.198792] [G loss: 0.454047]\n",
      "[Epoch 24/200] [Batch 124/637] [D loss: 0.182296] [G loss: 0.491023]\n",
      "[Epoch 24/200] [Batch 125/637] [D loss: 0.178894] [G loss: 0.469554]\n",
      "[Epoch 24/200] [Batch 126/637] [D loss: 0.157240] [G loss: 0.459084]\n",
      "[Epoch 24/200] [Batch 127/637] [D loss: 0.158638] [G loss: 0.460128]\n",
      "[Epoch 24/200] [Batch 128/637] [D loss: 0.157714] [G loss: 0.494169]\n",
      "[Epoch 24/200] [Batch 129/637] [D loss: 0.177144] [G loss: 0.542712]\n",
      "[Epoch 24/200] [Batch 130/637] [D loss: 0.169551] [G loss: 0.545001]\n",
      "[Epoch 24/200] [Batch 131/637] [D loss: 0.151472] [G loss: 0.531452]\n",
      "[Epoch 24/200] [Batch 132/637] [D loss: 0.171152] [G loss: 0.489905]\n",
      "[Epoch 24/200] [Batch 133/637] [D loss: 0.187267] [G loss: 0.484287]\n",
      "[Epoch 24/200] [Batch 134/637] [D loss: 0.172655] [G loss: 0.445027]\n",
      "[Epoch 24/200] [Batch 135/637] [D loss: 0.143992] [G loss: 0.537205]\n",
      "[Epoch 24/200] [Batch 136/637] [D loss: 0.165250] [G loss: 0.498549]\n",
      "[Epoch 24/200] [Batch 137/637] [D loss: 0.145583] [G loss: 0.506423]\n",
      "[Epoch 24/200] [Batch 138/637] [D loss: 0.178475] [G loss: 0.506907]\n",
      "[Epoch 24/200] [Batch 139/637] [D loss: 0.174642] [G loss: 0.487136]\n",
      "[Epoch 24/200] [Batch 140/637] [D loss: 0.175086] [G loss: 0.575477]\n",
      "[Epoch 24/200] [Batch 141/637] [D loss: 0.165084] [G loss: 0.477666]\n",
      "[Epoch 24/200] [Batch 142/637] [D loss: 0.160841] [G loss: 0.434783]\n",
      "[Epoch 24/200] [Batch 143/637] [D loss: 0.155235] [G loss: 0.474356]\n",
      "[Epoch 24/200] [Batch 144/637] [D loss: 0.171417] [G loss: 0.513898]\n",
      "[Epoch 24/200] [Batch 145/637] [D loss: 0.175282] [G loss: 0.482230]\n",
      "[Epoch 24/200] [Batch 146/637] [D loss: 0.154086] [G loss: 0.474313]\n",
      "[Epoch 24/200] [Batch 147/637] [D loss: 0.165355] [G loss: 0.456022]\n",
      "[Epoch 24/200] [Batch 148/637] [D loss: 0.185619] [G loss: 0.465423]\n",
      "[Epoch 24/200] [Batch 149/637] [D loss: 0.146694] [G loss: 0.514922]\n",
      "[Epoch 24/200] [Batch 150/637] [D loss: 0.185177] [G loss: 0.506651]\n",
      "[Epoch 24/200] [Batch 151/637] [D loss: 0.164323] [G loss: 0.468096]\n",
      "[Epoch 24/200] [Batch 152/637] [D loss: 0.171854] [G loss: 0.497320]\n",
      "[Epoch 24/200] [Batch 153/637] [D loss: 0.162396] [G loss: 0.519011]\n",
      "[Epoch 24/200] [Batch 154/637] [D loss: 0.192504] [G loss: 0.384290]\n",
      "[Epoch 24/200] [Batch 155/637] [D loss: 0.160920] [G loss: 0.499586]\n",
      "[Epoch 24/200] [Batch 156/637] [D loss: 0.176737] [G loss: 0.503041]\n",
      "[Epoch 24/200] [Batch 157/637] [D loss: 0.152655] [G loss: 0.556672]\n",
      "[Epoch 24/200] [Batch 158/637] [D loss: 0.184570] [G loss: 0.476780]\n",
      "[Epoch 24/200] [Batch 159/637] [D loss: 0.162739] [G loss: 0.497390]\n",
      "[Epoch 24/200] [Batch 160/637] [D loss: 0.158971] [G loss: 0.529150]\n",
      "[Epoch 24/200] [Batch 161/637] [D loss: 0.153234] [G loss: 0.500085]\n",
      "[Epoch 24/200] [Batch 162/637] [D loss: 0.185927] [G loss: 0.401913]\n",
      "[Epoch 24/200] [Batch 163/637] [D loss: 0.151066] [G loss: 0.489903]\n",
      "[Epoch 24/200] [Batch 164/637] [D loss: 0.187437] [G loss: 0.536562]\n",
      "[Epoch 24/200] [Batch 165/637] [D loss: 0.198302] [G loss: 0.482135]\n",
      "[Epoch 24/200] [Batch 166/637] [D loss: 0.167911] [G loss: 0.581492]\n",
      "[Epoch 24/200] [Batch 167/637] [D loss: 0.142232] [G loss: 0.525245]\n",
      "[Epoch 24/200] [Batch 168/637] [D loss: 0.195249] [G loss: 0.416724]\n",
      "[Epoch 24/200] [Batch 169/637] [D loss: 0.207072] [G loss: 0.450945]\n",
      "[Epoch 24/200] [Batch 170/637] [D loss: 0.167771] [G loss: 0.585947]\n",
      "[Epoch 24/200] [Batch 171/637] [D loss: 0.182502] [G loss: 0.460805]\n",
      "[Epoch 24/200] [Batch 172/637] [D loss: 0.169874] [G loss: 0.512065]\n",
      "[Epoch 24/200] [Batch 173/637] [D loss: 0.174968] [G loss: 0.495961]\n",
      "[Epoch 24/200] [Batch 174/637] [D loss: 0.173181] [G loss: 0.418627]\n",
      "[Epoch 24/200] [Batch 175/637] [D loss: 0.190770] [G loss: 0.417850]\n",
      "[Epoch 24/200] [Batch 176/637] [D loss: 0.166675] [G loss: 0.406231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 177/637] [D loss: 0.162711] [G loss: 0.472251]\n",
      "[Epoch 24/200] [Batch 178/637] [D loss: 0.177306] [G loss: 0.481001]\n",
      "[Epoch 24/200] [Batch 179/637] [D loss: 0.165179] [G loss: 0.496545]\n",
      "[Epoch 24/200] [Batch 180/637] [D loss: 0.163722] [G loss: 0.477919]\n",
      "[Epoch 24/200] [Batch 181/637] [D loss: 0.182263] [G loss: 0.464451]\n",
      "[Epoch 24/200] [Batch 182/637] [D loss: 0.158318] [G loss: 0.501275]\n",
      "[Epoch 24/200] [Batch 183/637] [D loss: 0.167065] [G loss: 0.522372]\n",
      "[Epoch 24/200] [Batch 184/637] [D loss: 0.171978] [G loss: 0.473134]\n",
      "[Epoch 24/200] [Batch 185/637] [D loss: 0.160943] [G loss: 0.488513]\n",
      "[Epoch 24/200] [Batch 186/637] [D loss: 0.171140] [G loss: 0.459087]\n",
      "[Epoch 24/200] [Batch 187/637] [D loss: 0.152767] [G loss: 0.509817]\n",
      "[Epoch 24/200] [Batch 188/637] [D loss: 0.149489] [G loss: 0.487015]\n",
      "[Epoch 24/200] [Batch 189/637] [D loss: 0.145520] [G loss: 0.459081]\n",
      "[Epoch 24/200] [Batch 190/637] [D loss: 0.180047] [G loss: 0.474954]\n",
      "[Epoch 24/200] [Batch 191/637] [D loss: 0.154198] [G loss: 0.513859]\n",
      "[Epoch 24/200] [Batch 192/637] [D loss: 0.175726] [G loss: 0.507704]\n",
      "[Epoch 24/200] [Batch 193/637] [D loss: 0.160489] [G loss: 0.509986]\n",
      "[Epoch 24/200] [Batch 194/637] [D loss: 0.174245] [G loss: 0.475233]\n",
      "[Epoch 24/200] [Batch 195/637] [D loss: 0.152815] [G loss: 0.540042]\n",
      "[Epoch 24/200] [Batch 196/637] [D loss: 0.155682] [G loss: 0.565802]\n",
      "[Epoch 24/200] [Batch 197/637] [D loss: 0.156433] [G loss: 0.440375]\n",
      "[Epoch 24/200] [Batch 198/637] [D loss: 0.144058] [G loss: 0.478554]\n",
      "[Epoch 24/200] [Batch 199/637] [D loss: 0.153509] [G loss: 0.456766]\n",
      "[Epoch 24/200] [Batch 200/637] [D loss: 0.156268] [G loss: 0.522743]\n",
      "[Epoch 24/200] [Batch 201/637] [D loss: 0.149234] [G loss: 0.510583]\n",
      "[Epoch 24/200] [Batch 202/637] [D loss: 0.149803] [G loss: 0.556521]\n",
      "[Epoch 24/200] [Batch 203/637] [D loss: 0.140998] [G loss: 0.586312]\n",
      "[Epoch 24/200] [Batch 204/637] [D loss: 0.153971] [G loss: 0.558030]\n",
      "[Epoch 24/200] [Batch 205/637] [D loss: 0.192055] [G loss: 0.456848]\n",
      "[Epoch 24/200] [Batch 206/637] [D loss: 0.158852] [G loss: 0.571571]\n",
      "[Epoch 24/200] [Batch 207/637] [D loss: 0.186073] [G loss: 0.535639]\n",
      "[Epoch 24/200] [Batch 208/637] [D loss: 0.207082] [G loss: 0.534256]\n",
      "[Epoch 24/200] [Batch 209/637] [D loss: 0.185089] [G loss: 0.646705]\n",
      "[Epoch 24/200] [Batch 210/637] [D loss: 0.159016] [G loss: 0.526120]\n",
      "[Epoch 24/200] [Batch 211/637] [D loss: 0.160605] [G loss: 0.457999]\n",
      "[Epoch 24/200] [Batch 212/637] [D loss: 0.202941] [G loss: 0.418744]\n",
      "[Epoch 24/200] [Batch 213/637] [D loss: 0.168489] [G loss: 0.520446]\n",
      "[Epoch 24/200] [Batch 214/637] [D loss: 0.179675] [G loss: 0.538060]\n",
      "[Epoch 24/200] [Batch 215/637] [D loss: 0.179066] [G loss: 0.521882]\n",
      "[Epoch 24/200] [Batch 216/637] [D loss: 0.150452] [G loss: 0.495088]\n",
      "[Epoch 24/200] [Batch 217/637] [D loss: 0.175926] [G loss: 0.469416]\n",
      "[Epoch 24/200] [Batch 218/637] [D loss: 0.196547] [G loss: 0.473321]\n",
      "[Epoch 24/200] [Batch 219/637] [D loss: 0.153165] [G loss: 0.500321]\n",
      "[Epoch 24/200] [Batch 220/637] [D loss: 0.179354] [G loss: 0.554904]\n",
      "[Epoch 24/200] [Batch 221/637] [D loss: 0.154834] [G loss: 0.591507]\n",
      "[Epoch 24/200] [Batch 222/637] [D loss: 0.166082] [G loss: 0.459263]\n",
      "[Epoch 24/200] [Batch 223/637] [D loss: 0.172504] [G loss: 0.569198]\n",
      "[Epoch 24/200] [Batch 224/637] [D loss: 0.177234] [G loss: 0.478159]\n",
      "[Epoch 24/200] [Batch 225/637] [D loss: 0.159246] [G loss: 0.561975]\n",
      "[Epoch 24/200] [Batch 226/637] [D loss: 0.165462] [G loss: 0.527443]\n",
      "[Epoch 24/200] [Batch 227/637] [D loss: 0.147358] [G loss: 0.491158]\n",
      "[Epoch 24/200] [Batch 228/637] [D loss: 0.165868] [G loss: 0.501359]\n",
      "[Epoch 24/200] [Batch 229/637] [D loss: 0.172919] [G loss: 0.473705]\n",
      "[Epoch 24/200] [Batch 230/637] [D loss: 0.179029] [G loss: 0.449106]\n",
      "[Epoch 24/200] [Batch 231/637] [D loss: 0.194084] [G loss: 0.482740]\n",
      "[Epoch 24/200] [Batch 232/637] [D loss: 0.171279] [G loss: 0.571092]\n",
      "[Epoch 24/200] [Batch 233/637] [D loss: 0.130202] [G loss: 0.602363]\n",
      "[Epoch 24/200] [Batch 234/637] [D loss: 0.154289] [G loss: 0.554009]\n",
      "[Epoch 24/200] [Batch 235/637] [D loss: 0.155382] [G loss: 0.499761]\n",
      "[Epoch 24/200] [Batch 236/637] [D loss: 0.196016] [G loss: 0.409156]\n",
      "[Epoch 24/200] [Batch 237/637] [D loss: 0.179126] [G loss: 0.558317]\n",
      "[Epoch 24/200] [Batch 238/637] [D loss: 0.197887] [G loss: 0.533525]\n",
      "[Epoch 24/200] [Batch 239/637] [D loss: 0.168594] [G loss: 0.597029]\n",
      "[Epoch 24/200] [Batch 240/637] [D loss: 0.174944] [G loss: 0.603331]\n",
      "[Epoch 24/200] [Batch 241/637] [D loss: 0.178583] [G loss: 0.425689]\n",
      "[Epoch 24/200] [Batch 242/637] [D loss: 0.161169] [G loss: 0.443986]\n",
      "[Epoch 24/200] [Batch 243/637] [D loss: 0.147392] [G loss: 0.525228]\n",
      "[Epoch 24/200] [Batch 244/637] [D loss: 0.149977] [G loss: 0.515171]\n",
      "[Epoch 24/200] [Batch 245/637] [D loss: 0.168575] [G loss: 0.548037]\n",
      "[Epoch 24/200] [Batch 246/637] [D loss: 0.163698] [G loss: 0.478868]\n",
      "[Epoch 24/200] [Batch 247/637] [D loss: 0.181985] [G loss: 0.459125]\n",
      "[Epoch 24/200] [Batch 248/637] [D loss: 0.162550] [G loss: 0.567523]\n",
      "[Epoch 24/200] [Batch 249/637] [D loss: 0.153368] [G loss: 0.548974]\n",
      "[Epoch 24/200] [Batch 250/637] [D loss: 0.165403] [G loss: 0.498802]\n",
      "[Epoch 24/200] [Batch 251/637] [D loss: 0.164609] [G loss: 0.595965]\n",
      "[Epoch 24/200] [Batch 252/637] [D loss: 0.176326] [G loss: 0.469414]\n",
      "[Epoch 24/200] [Batch 253/637] [D loss: 0.149364] [G loss: 0.504588]\n",
      "[Epoch 24/200] [Batch 254/637] [D loss: 0.174619] [G loss: 0.558859]\n",
      "[Epoch 24/200] [Batch 255/637] [D loss: 0.175932] [G loss: 0.506003]\n",
      "[Epoch 24/200] [Batch 256/637] [D loss: 0.164253] [G loss: 0.462059]\n",
      "[Epoch 24/200] [Batch 257/637] [D loss: 0.187919] [G loss: 0.500729]\n",
      "[Epoch 24/200] [Batch 258/637] [D loss: 0.165920] [G loss: 0.520489]\n",
      "[Epoch 24/200] [Batch 259/637] [D loss: 0.156346] [G loss: 0.551144]\n",
      "[Epoch 24/200] [Batch 260/637] [D loss: 0.147515] [G loss: 0.554085]\n",
      "[Epoch 24/200] [Batch 261/637] [D loss: 0.154951] [G loss: 0.485866]\n",
      "[Epoch 24/200] [Batch 262/637] [D loss: 0.145835] [G loss: 0.477420]\n",
      "[Epoch 24/200] [Batch 263/637] [D loss: 0.164927] [G loss: 0.442732]\n",
      "[Epoch 24/200] [Batch 264/637] [D loss: 0.154224] [G loss: 0.530187]\n",
      "[Epoch 24/200] [Batch 265/637] [D loss: 0.153193] [G loss: 0.602948]\n",
      "[Epoch 24/200] [Batch 266/637] [D loss: 0.191691] [G loss: 0.569043]\n",
      "[Epoch 24/200] [Batch 267/637] [D loss: 0.205919] [G loss: 0.507838]\n",
      "[Epoch 24/200] [Batch 268/637] [D loss: 0.183396] [G loss: 0.536649]\n",
      "[Epoch 24/200] [Batch 269/637] [D loss: 0.154063] [G loss: 0.571517]\n",
      "[Epoch 24/200] [Batch 270/637] [D loss: 0.172887] [G loss: 0.474395]\n",
      "[Epoch 24/200] [Batch 271/637] [D loss: 0.175486] [G loss: 0.518401]\n",
      "[Epoch 24/200] [Batch 272/637] [D loss: 0.167903] [G loss: 0.477652]\n",
      "[Epoch 24/200] [Batch 273/637] [D loss: 0.166882] [G loss: 0.477034]\n",
      "[Epoch 24/200] [Batch 274/637] [D loss: 0.164323] [G loss: 0.484749]\n",
      "[Epoch 24/200] [Batch 275/637] [D loss: 0.148312] [G loss: 0.603634]\n",
      "[Epoch 24/200] [Batch 276/637] [D loss: 0.155312] [G loss: 0.638093]\n",
      "[Epoch 24/200] [Batch 277/637] [D loss: 0.157854] [G loss: 0.519653]\n",
      "[Epoch 24/200] [Batch 278/637] [D loss: 0.128882] [G loss: 0.473762]\n",
      "[Epoch 24/200] [Batch 279/637] [D loss: 0.155214] [G loss: 0.486339]\n",
      "[Epoch 24/200] [Batch 280/637] [D loss: 0.153010] [G loss: 0.587269]\n",
      "[Epoch 24/200] [Batch 281/637] [D loss: 0.189564] [G loss: 0.527010]\n",
      "[Epoch 24/200] [Batch 282/637] [D loss: 0.219929] [G loss: 0.564305]\n",
      "[Epoch 24/200] [Batch 283/637] [D loss: 0.193602] [G loss: 0.600150]\n",
      "[Epoch 24/200] [Batch 284/637] [D loss: 0.191653] [G loss: 0.530398]\n",
      "[Epoch 24/200] [Batch 285/637] [D loss: 0.171694] [G loss: 0.458886]\n",
      "[Epoch 24/200] [Batch 286/637] [D loss: 0.175743] [G loss: 0.357747]\n",
      "[Epoch 24/200] [Batch 287/637] [D loss: 0.177823] [G loss: 0.465403]\n",
      "[Epoch 24/200] [Batch 288/637] [D loss: 0.171330] [G loss: 0.477287]\n",
      "[Epoch 24/200] [Batch 289/637] [D loss: 0.154691] [G loss: 0.462916]\n",
      "[Epoch 24/200] [Batch 290/637] [D loss: 0.158090] [G loss: 0.492733]\n",
      "[Epoch 24/200] [Batch 291/637] [D loss: 0.144659] [G loss: 0.506275]\n",
      "[Epoch 24/200] [Batch 292/637] [D loss: 0.162564] [G loss: 0.569137]\n",
      "[Epoch 24/200] [Batch 293/637] [D loss: 0.173827] [G loss: 0.469914]\n",
      "[Epoch 24/200] [Batch 294/637] [D loss: 0.176728] [G loss: 0.447544]\n",
      "[Epoch 24/200] [Batch 295/637] [D loss: 0.168966] [G loss: 0.543986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 296/637] [D loss: 0.146513] [G loss: 0.508508]\n",
      "[Epoch 24/200] [Batch 297/637] [D loss: 0.142552] [G loss: 0.540089]\n",
      "[Epoch 24/200] [Batch 298/637] [D loss: 0.138547] [G loss: 0.502383]\n",
      "[Epoch 24/200] [Batch 299/637] [D loss: 0.166140] [G loss: 0.435626]\n",
      "[Epoch 24/200] [Batch 300/637] [D loss: 0.167226] [G loss: 0.448236]\n",
      "[Epoch 24/200] [Batch 301/637] [D loss: 0.175756] [G loss: 0.446861]\n",
      "[Epoch 24/200] [Batch 302/637] [D loss: 0.193296] [G loss: 0.575756]\n",
      "[Epoch 24/200] [Batch 303/637] [D loss: 0.154936] [G loss: 0.730822]\n",
      "[Epoch 24/200] [Batch 304/637] [D loss: 0.192332] [G loss: 0.520099]\n",
      "[Epoch 24/200] [Batch 305/637] [D loss: 0.174286] [G loss: 0.439666]\n",
      "[Epoch 24/200] [Batch 306/637] [D loss: 0.184523] [G loss: 0.514116]\n",
      "[Epoch 24/200] [Batch 307/637] [D loss: 0.165507] [G loss: 0.482216]\n",
      "[Epoch 24/200] [Batch 308/637] [D loss: 0.144765] [G loss: 0.519796]\n",
      "[Epoch 24/200] [Batch 309/637] [D loss: 0.159376] [G loss: 0.500744]\n",
      "[Epoch 24/200] [Batch 310/637] [D loss: 0.188853] [G loss: 0.450224]\n",
      "[Epoch 24/200] [Batch 311/637] [D loss: 0.155242] [G loss: 0.538327]\n",
      "[Epoch 24/200] [Batch 312/637] [D loss: 0.170260] [G loss: 0.463284]\n",
      "[Epoch 24/200] [Batch 313/637] [D loss: 0.182355] [G loss: 0.493882]\n",
      "[Epoch 24/200] [Batch 314/637] [D loss: 0.190035] [G loss: 0.471344]\n",
      "[Epoch 24/200] [Batch 315/637] [D loss: 0.144793] [G loss: 0.580628]\n",
      "[Epoch 24/200] [Batch 316/637] [D loss: 0.146523] [G loss: 0.544228]\n",
      "[Epoch 24/200] [Batch 317/637] [D loss: 0.156926] [G loss: 0.471730]\n",
      "[Epoch 24/200] [Batch 318/637] [D loss: 0.137361] [G loss: 0.504550]\n",
      "[Epoch 24/200] [Batch 319/637] [D loss: 0.162946] [G loss: 0.554675]\n",
      "[Epoch 24/200] [Batch 320/637] [D loss: 0.162799] [G loss: 0.538289]\n",
      "[Epoch 24/200] [Batch 321/637] [D loss: 0.149692] [G loss: 0.506555]\n",
      "[Epoch 24/200] [Batch 322/637] [D loss: 0.158584] [G loss: 0.519558]\n",
      "[Epoch 24/200] [Batch 323/637] [D loss: 0.162721] [G loss: 0.474711]\n",
      "[Epoch 24/200] [Batch 324/637] [D loss: 0.142347] [G loss: 0.544449]\n",
      "[Epoch 24/200] [Batch 325/637] [D loss: 0.173648] [G loss: 0.481464]\n",
      "[Epoch 24/200] [Batch 326/637] [D loss: 0.157172] [G loss: 0.620538]\n",
      "[Epoch 24/200] [Batch 327/637] [D loss: 0.167903] [G loss: 0.543383]\n",
      "[Epoch 24/200] [Batch 328/637] [D loss: 0.206996] [G loss: 0.439848]\n",
      "[Epoch 24/200] [Batch 329/637] [D loss: 0.174278] [G loss: 0.450531]\n",
      "[Epoch 24/200] [Batch 330/637] [D loss: 0.156191] [G loss: 0.496565]\n",
      "[Epoch 24/200] [Batch 331/637] [D loss: 0.153903] [G loss: 0.497817]\n",
      "[Epoch 24/200] [Batch 332/637] [D loss: 0.160814] [G loss: 0.451286]\n",
      "[Epoch 24/200] [Batch 333/637] [D loss: 0.141923] [G loss: 0.526555]\n",
      "[Epoch 24/200] [Batch 334/637] [D loss: 0.172986] [G loss: 0.440757]\n",
      "[Epoch 24/200] [Batch 335/637] [D loss: 0.152291] [G loss: 0.510615]\n",
      "[Epoch 24/200] [Batch 336/637] [D loss: 0.180812] [G loss: 0.497607]\n",
      "[Epoch 24/200] [Batch 337/637] [D loss: 0.152719] [G loss: 0.572194]\n",
      "[Epoch 24/200] [Batch 338/637] [D loss: 0.183319] [G loss: 0.458961]\n",
      "[Epoch 24/200] [Batch 339/637] [D loss: 0.185412] [G loss: 0.473613]\n",
      "[Epoch 24/200] [Batch 340/637] [D loss: 0.151444] [G loss: 0.464501]\n",
      "[Epoch 24/200] [Batch 341/637] [D loss: 0.156687] [G loss: 0.481348]\n",
      "[Epoch 24/200] [Batch 342/637] [D loss: 0.149219] [G loss: 0.503012]\n",
      "[Epoch 24/200] [Batch 343/637] [D loss: 0.185313] [G loss: 0.462872]\n",
      "[Epoch 24/200] [Batch 344/637] [D loss: 0.175318] [G loss: 0.523136]\n",
      "[Epoch 24/200] [Batch 345/637] [D loss: 0.164901] [G loss: 0.495227]\n",
      "[Epoch 24/200] [Batch 346/637] [D loss: 0.183718] [G loss: 0.448348]\n",
      "[Epoch 24/200] [Batch 347/637] [D loss: 0.175358] [G loss: 0.479870]\n",
      "[Epoch 24/200] [Batch 348/637] [D loss: 0.199996] [G loss: 0.472000]\n",
      "[Epoch 24/200] [Batch 349/637] [D loss: 0.149617] [G loss: 0.501434]\n",
      "[Epoch 24/200] [Batch 350/637] [D loss: 0.162726] [G loss: 0.488801]\n",
      "[Epoch 24/200] [Batch 351/637] [D loss: 0.168229] [G loss: 0.502074]\n",
      "[Epoch 24/200] [Batch 352/637] [D loss: 0.166530] [G loss: 0.428992]\n",
      "[Epoch 24/200] [Batch 353/637] [D loss: 0.166286] [G loss: 0.436398]\n",
      "[Epoch 24/200] [Batch 354/637] [D loss: 0.185749] [G loss: 0.413905]\n",
      "[Epoch 24/200] [Batch 355/637] [D loss: 0.158223] [G loss: 0.468472]\n",
      "[Epoch 24/200] [Batch 356/637] [D loss: 0.168309] [G loss: 0.497200]\n",
      "[Epoch 24/200] [Batch 357/637] [D loss: 0.165536] [G loss: 0.468063]\n",
      "[Epoch 24/200] [Batch 358/637] [D loss: 0.159668] [G loss: 0.433941]\n",
      "[Epoch 24/200] [Batch 359/637] [D loss: 0.162360] [G loss: 0.495443]\n",
      "[Epoch 24/200] [Batch 360/637] [D loss: 0.166917] [G loss: 0.455673]\n",
      "[Epoch 24/200] [Batch 361/637] [D loss: 0.150988] [G loss: 0.540787]\n",
      "[Epoch 24/200] [Batch 362/637] [D loss: 0.137077] [G loss: 0.555758]\n",
      "[Epoch 24/200] [Batch 363/637] [D loss: 0.152950] [G loss: 0.494520]\n",
      "[Epoch 24/200] [Batch 364/637] [D loss: 0.175579] [G loss: 0.411814]\n",
      "[Epoch 24/200] [Batch 365/637] [D loss: 0.170154] [G loss: 0.534559]\n",
      "[Epoch 24/200] [Batch 366/637] [D loss: 0.182631] [G loss: 0.519207]\n",
      "[Epoch 24/200] [Batch 367/637] [D loss: 0.170602] [G loss: 0.519082]\n",
      "[Epoch 24/200] [Batch 368/637] [D loss: 0.176128] [G loss: 0.492378]\n",
      "[Epoch 24/200] [Batch 369/637] [D loss: 0.169350] [G loss: 0.571361]\n",
      "[Epoch 24/200] [Batch 370/637] [D loss: 0.179789] [G loss: 0.416629]\n",
      "[Epoch 24/200] [Batch 371/637] [D loss: 0.162993] [G loss: 0.471481]\n",
      "[Epoch 24/200] [Batch 372/637] [D loss: 0.155879] [G loss: 0.528068]\n",
      "[Epoch 24/200] [Batch 373/637] [D loss: 0.160688] [G loss: 0.466175]\n",
      "[Epoch 24/200] [Batch 374/637] [D loss: 0.141433] [G loss: 0.566109]\n",
      "[Epoch 24/200] [Batch 375/637] [D loss: 0.149327] [G loss: 0.465169]\n",
      "[Epoch 24/200] [Batch 376/637] [D loss: 0.173502] [G loss: 0.493956]\n",
      "[Epoch 24/200] [Batch 377/637] [D loss: 0.169564] [G loss: 0.445722]\n",
      "[Epoch 24/200] [Batch 378/637] [D loss: 0.148177] [G loss: 0.542465]\n",
      "[Epoch 24/200] [Batch 379/637] [D loss: 0.160318] [G loss: 0.573633]\n",
      "[Epoch 24/200] [Batch 380/637] [D loss: 0.174716] [G loss: 0.511541]\n",
      "[Epoch 24/200] [Batch 381/637] [D loss: 0.161780] [G loss: 0.483385]\n",
      "[Epoch 24/200] [Batch 382/637] [D loss: 0.165456] [G loss: 0.528660]\n",
      "[Epoch 24/200] [Batch 383/637] [D loss: 0.134639] [G loss: 0.532608]\n",
      "[Epoch 24/200] [Batch 384/637] [D loss: 0.160589] [G loss: 0.524182]\n",
      "[Epoch 24/200] [Batch 385/637] [D loss: 0.157969] [G loss: 0.516761]\n",
      "[Epoch 24/200] [Batch 386/637] [D loss: 0.160709] [G loss: 0.492107]\n",
      "[Epoch 24/200] [Batch 387/637] [D loss: 0.196688] [G loss: 0.426304]\n",
      "[Epoch 24/200] [Batch 388/637] [D loss: 0.188858] [G loss: 0.519960]\n",
      "[Epoch 24/200] [Batch 389/637] [D loss: 0.188418] [G loss: 0.420541]\n",
      "[Epoch 24/200] [Batch 390/637] [D loss: 0.188237] [G loss: 0.470206]\n",
      "[Epoch 24/200] [Batch 391/637] [D loss: 0.162258] [G loss: 0.482665]\n",
      "[Epoch 24/200] [Batch 392/637] [D loss: 0.144430] [G loss: 0.503372]\n",
      "[Epoch 24/200] [Batch 393/637] [D loss: 0.171527] [G loss: 0.527638]\n",
      "[Epoch 24/200] [Batch 394/637] [D loss: 0.165891] [G loss: 0.559390]\n",
      "[Epoch 24/200] [Batch 395/637] [D loss: 0.177332] [G loss: 0.528962]\n",
      "[Epoch 24/200] [Batch 396/637] [D loss: 0.150911] [G loss: 0.473978]\n",
      "[Epoch 24/200] [Batch 397/637] [D loss: 0.181431] [G loss: 0.442835]\n",
      "[Epoch 24/200] [Batch 398/637] [D loss: 0.155645] [G loss: 0.583153]\n",
      "[Epoch 24/200] [Batch 399/637] [D loss: 0.165937] [G loss: 0.472511]\n",
      "[Epoch 24/200] [Batch 400/637] [D loss: 0.168094] [G loss: 0.571610]\n",
      "[Epoch 24/200] [Batch 401/637] [D loss: 0.151119] [G loss: 0.521511]\n",
      "[Epoch 24/200] [Batch 402/637] [D loss: 0.156108] [G loss: 0.483594]\n",
      "[Epoch 24/200] [Batch 403/637] [D loss: 0.164517] [G loss: 0.515986]\n",
      "[Epoch 24/200] [Batch 404/637] [D loss: 0.185281] [G loss: 0.460524]\n",
      "[Epoch 24/200] [Batch 405/637] [D loss: 0.162717] [G loss: 0.607950]\n",
      "[Epoch 24/200] [Batch 406/637] [D loss: 0.177138] [G loss: 0.514077]\n",
      "[Epoch 24/200] [Batch 407/637] [D loss: 0.186735] [G loss: 0.418869]\n",
      "[Epoch 24/200] [Batch 408/637] [D loss: 0.152194] [G loss: 0.461271]\n",
      "[Epoch 24/200] [Batch 409/637] [D loss: 0.170941] [G loss: 0.495791]\n",
      "[Epoch 24/200] [Batch 410/637] [D loss: 0.215954] [G loss: 0.465324]\n",
      "[Epoch 24/200] [Batch 411/637] [D loss: 0.188697] [G loss: 0.513708]\n",
      "[Epoch 24/200] [Batch 412/637] [D loss: 0.161146] [G loss: 0.592948]\n",
      "[Epoch 24/200] [Batch 413/637] [D loss: 0.148730] [G loss: 0.551216]\n",
      "[Epoch 24/200] [Batch 414/637] [D loss: 0.174748] [G loss: 0.487194]\n",
      "[Epoch 24/200] [Batch 415/637] [D loss: 0.184291] [G loss: 0.502826]\n",
      "[Epoch 24/200] [Batch 416/637] [D loss: 0.150764] [G loss: 0.499598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 417/637] [D loss: 0.162669] [G loss: 0.513454]\n",
      "[Epoch 24/200] [Batch 418/637] [D loss: 0.163061] [G loss: 0.505390]\n",
      "[Epoch 24/200] [Batch 419/637] [D loss: 0.144342] [G loss: 0.548425]\n",
      "[Epoch 24/200] [Batch 420/637] [D loss: 0.165672] [G loss: 0.487385]\n",
      "[Epoch 24/200] [Batch 421/637] [D loss: 0.153102] [G loss: 0.528461]\n",
      "[Epoch 24/200] [Batch 422/637] [D loss: 0.151389] [G loss: 0.544692]\n",
      "[Epoch 24/200] [Batch 423/637] [D loss: 0.176388] [G loss: 0.419532]\n",
      "[Epoch 24/200] [Batch 424/637] [D loss: 0.168658] [G loss: 0.562416]\n",
      "[Epoch 24/200] [Batch 425/637] [D loss: 0.183288] [G loss: 0.516951]\n",
      "[Epoch 24/200] [Batch 426/637] [D loss: 0.182386] [G loss: 0.622689]\n",
      "[Epoch 24/200] [Batch 427/637] [D loss: 0.171151] [G loss: 0.505701]\n",
      "[Epoch 24/200] [Batch 428/637] [D loss: 0.164939] [G loss: 0.455175]\n",
      "[Epoch 24/200] [Batch 429/637] [D loss: 0.167031] [G loss: 0.499636]\n",
      "[Epoch 24/200] [Batch 430/637] [D loss: 0.176113] [G loss: 0.523257]\n",
      "[Epoch 24/200] [Batch 431/637] [D loss: 0.155464] [G loss: 0.547948]\n",
      "[Epoch 24/200] [Batch 432/637] [D loss: 0.174674] [G loss: 0.483802]\n",
      "[Epoch 24/200] [Batch 433/637] [D loss: 0.136925] [G loss: 0.551076]\n",
      "[Epoch 24/200] [Batch 434/637] [D loss: 0.172754] [G loss: 0.523288]\n",
      "[Epoch 24/200] [Batch 435/637] [D loss: 0.153760] [G loss: 0.571684]\n",
      "[Epoch 24/200] [Batch 436/637] [D loss: 0.153488] [G loss: 0.494119]\n",
      "[Epoch 24/200] [Batch 437/637] [D loss: 0.172239] [G loss: 0.471324]\n",
      "[Epoch 24/200] [Batch 438/637] [D loss: 0.171068] [G loss: 0.621433]\n",
      "[Epoch 24/200] [Batch 439/637] [D loss: 0.174108] [G loss: 0.517586]\n",
      "[Epoch 24/200] [Batch 440/637] [D loss: 0.184324] [G loss: 0.482407]\n",
      "[Epoch 24/200] [Batch 441/637] [D loss: 0.175209] [G loss: 0.481383]\n",
      "[Epoch 24/200] [Batch 442/637] [D loss: 0.167013] [G loss: 0.496198]\n",
      "[Epoch 24/200] [Batch 443/637] [D loss: 0.172619] [G loss: 0.536931]\n",
      "[Epoch 24/200] [Batch 444/637] [D loss: 0.174421] [G loss: 0.492907]\n",
      "[Epoch 24/200] [Batch 445/637] [D loss: 0.162162] [G loss: 0.578441]\n",
      "[Epoch 24/200] [Batch 446/637] [D loss: 0.171761] [G loss: 0.464172]\n",
      "[Epoch 24/200] [Batch 447/637] [D loss: 0.211969] [G loss: 0.403526]\n",
      "[Epoch 24/200] [Batch 448/637] [D loss: 0.153486] [G loss: 0.483388]\n",
      "[Epoch 24/200] [Batch 449/637] [D loss: 0.171215] [G loss: 0.524333]\n",
      "[Epoch 24/200] [Batch 450/637] [D loss: 0.172014] [G loss: 0.474645]\n",
      "[Epoch 24/200] [Batch 451/637] [D loss: 0.170999] [G loss: 0.511044]\n",
      "[Epoch 24/200] [Batch 452/637] [D loss: 0.169729] [G loss: 0.470011]\n",
      "[Epoch 24/200] [Batch 453/637] [D loss: 0.176743] [G loss: 0.534595]\n",
      "[Epoch 24/200] [Batch 454/637] [D loss: 0.134488] [G loss: 0.599713]\n",
      "[Epoch 24/200] [Batch 455/637] [D loss: 0.136294] [G loss: 0.608520]\n",
      "[Epoch 24/200] [Batch 456/637] [D loss: 0.159148] [G loss: 0.462405]\n",
      "[Epoch 24/200] [Batch 457/637] [D loss: 0.172442] [G loss: 0.465701]\n",
      "[Epoch 24/200] [Batch 458/637] [D loss: 0.146468] [G loss: 0.513018]\n",
      "[Epoch 24/200] [Batch 459/637] [D loss: 0.117916] [G loss: 0.575609]\n",
      "[Epoch 24/200] [Batch 460/637] [D loss: 0.134327] [G loss: 0.517899]\n",
      "[Epoch 24/200] [Batch 461/637] [D loss: 0.168774] [G loss: 0.469047]\n",
      "[Epoch 24/200] [Batch 462/637] [D loss: 0.210389] [G loss: 0.602804]\n",
      "[Epoch 24/200] [Batch 463/637] [D loss: 0.184236] [G loss: 0.536724]\n",
      "[Epoch 24/200] [Batch 464/637] [D loss: 0.170742] [G loss: 0.509263]\n",
      "[Epoch 24/200] [Batch 465/637] [D loss: 0.197789] [G loss: 0.453674]\n",
      "[Epoch 24/200] [Batch 466/637] [D loss: 0.179814] [G loss: 0.521530]\n",
      "[Epoch 24/200] [Batch 467/637] [D loss: 0.193548] [G loss: 0.437185]\n",
      "[Epoch 24/200] [Batch 468/637] [D loss: 0.194659] [G loss: 0.598046]\n",
      "[Epoch 24/200] [Batch 469/637] [D loss: 0.184745] [G loss: 0.473055]\n",
      "[Epoch 24/200] [Batch 470/637] [D loss: 0.170279] [G loss: 0.472247]\n",
      "[Epoch 24/200] [Batch 471/637] [D loss: 0.197965] [G loss: 0.438377]\n",
      "[Epoch 24/200] [Batch 472/637] [D loss: 0.163985] [G loss: 0.429278]\n",
      "[Epoch 24/200] [Batch 473/637] [D loss: 0.169234] [G loss: 0.440383]\n",
      "[Epoch 24/200] [Batch 474/637] [D loss: 0.145382] [G loss: 0.483001]\n",
      "[Epoch 24/200] [Batch 475/637] [D loss: 0.148937] [G loss: 0.527356]\n",
      "[Epoch 24/200] [Batch 476/637] [D loss: 0.147959] [G loss: 0.555826]\n",
      "[Epoch 24/200] [Batch 477/637] [D loss: 0.149465] [G loss: 0.487425]\n",
      "[Epoch 24/200] [Batch 478/637] [D loss: 0.149172] [G loss: 0.540866]\n",
      "[Epoch 24/200] [Batch 479/637] [D loss: 0.177953] [G loss: 0.454762]\n",
      "[Epoch 24/200] [Batch 480/637] [D loss: 0.140796] [G loss: 0.474680]\n",
      "[Epoch 24/200] [Batch 481/637] [D loss: 0.150655] [G loss: 0.492438]\n",
      "[Epoch 24/200] [Batch 482/637] [D loss: 0.158366] [G loss: 0.450059]\n",
      "[Epoch 24/200] [Batch 483/637] [D loss: 0.139412] [G loss: 0.534721]\n",
      "[Epoch 24/200] [Batch 484/637] [D loss: 0.153591] [G loss: 0.491710]\n",
      "[Epoch 24/200] [Batch 485/637] [D loss: 0.162968] [G loss: 0.498399]\n",
      "[Epoch 24/200] [Batch 486/637] [D loss: 0.146291] [G loss: 0.549287]\n",
      "[Epoch 24/200] [Batch 487/637] [D loss: 0.167956] [G loss: 0.562110]\n",
      "[Epoch 24/200] [Batch 488/637] [D loss: 0.152753] [G loss: 0.476732]\n",
      "[Epoch 24/200] [Batch 489/637] [D loss: 0.186075] [G loss: 0.457620]\n",
      "[Epoch 24/200] [Batch 490/637] [D loss: 0.175248] [G loss: 0.512846]\n",
      "[Epoch 24/200] [Batch 491/637] [D loss: 0.158463] [G loss: 0.486283]\n",
      "[Epoch 24/200] [Batch 492/637] [D loss: 0.165766] [G loss: 0.508940]\n",
      "[Epoch 24/200] [Batch 493/637] [D loss: 0.181682] [G loss: 0.508755]\n",
      "[Epoch 24/200] [Batch 494/637] [D loss: 0.187369] [G loss: 0.521307]\n",
      "[Epoch 24/200] [Batch 495/637] [D loss: 0.173269] [G loss: 0.458640]\n",
      "[Epoch 24/200] [Batch 496/637] [D loss: 0.189610] [G loss: 0.496222]\n",
      "[Epoch 24/200] [Batch 497/637] [D loss: 0.165871] [G loss: 0.554045]\n",
      "[Epoch 24/200] [Batch 498/637] [D loss: 0.129550] [G loss: 0.541924]\n",
      "[Epoch 24/200] [Batch 499/637] [D loss: 0.156475] [G loss: 0.467639]\n",
      "[Epoch 24/200] [Batch 500/637] [D loss: 0.144970] [G loss: 0.554604]\n",
      "[Epoch 24/200] [Batch 501/637] [D loss: 0.160232] [G loss: 0.542275]\n",
      "[Epoch 24/200] [Batch 502/637] [D loss: 0.156401] [G loss: 0.476959]\n",
      "[Epoch 24/200] [Batch 503/637] [D loss: 0.153944] [G loss: 0.582612]\n",
      "[Epoch 24/200] [Batch 504/637] [D loss: 0.161807] [G loss: 0.509384]\n",
      "[Epoch 24/200] [Batch 505/637] [D loss: 0.145136] [G loss: 0.638318]\n",
      "[Epoch 24/200] [Batch 506/637] [D loss: 0.183002] [G loss: 0.509520]\n",
      "[Epoch 24/200] [Batch 507/637] [D loss: 0.171565] [G loss: 0.424878]\n",
      "[Epoch 24/200] [Batch 508/637] [D loss: 0.156001] [G loss: 0.513257]\n",
      "[Epoch 24/200] [Batch 509/637] [D loss: 0.149220] [G loss: 0.494954]\n",
      "[Epoch 24/200] [Batch 510/637] [D loss: 0.180860] [G loss: 0.465601]\n",
      "[Epoch 24/200] [Batch 511/637] [D loss: 0.157659] [G loss: 0.497422]\n",
      "[Epoch 24/200] [Batch 512/637] [D loss: 0.164877] [G loss: 0.578162]\n",
      "[Epoch 24/200] [Batch 513/637] [D loss: 0.151258] [G loss: 0.579587]\n",
      "[Epoch 24/200] [Batch 514/637] [D loss: 0.141636] [G loss: 0.604795]\n",
      "[Epoch 24/200] [Batch 515/637] [D loss: 0.160146] [G loss: 0.535303]\n",
      "[Epoch 24/200] [Batch 516/637] [D loss: 0.170021] [G loss: 0.465064]\n",
      "[Epoch 24/200] [Batch 517/637] [D loss: 0.158749] [G loss: 0.507721]\n",
      "[Epoch 24/200] [Batch 518/637] [D loss: 0.168423] [G loss: 0.507111]\n",
      "[Epoch 24/200] [Batch 519/637] [D loss: 0.156642] [G loss: 0.528075]\n",
      "[Epoch 24/200] [Batch 520/637] [D loss: 0.172585] [G loss: 0.479700]\n",
      "[Epoch 24/200] [Batch 521/637] [D loss: 0.181086] [G loss: 0.539469]\n",
      "[Epoch 24/200] [Batch 522/637] [D loss: 0.164137] [G loss: 0.560074]\n",
      "[Epoch 24/200] [Batch 523/637] [D loss: 0.161777] [G loss: 0.435668]\n",
      "[Epoch 24/200] [Batch 524/637] [D loss: 0.138787] [G loss: 0.519214]\n",
      "[Epoch 24/200] [Batch 525/637] [D loss: 0.143475] [G loss: 0.542036]\n",
      "[Epoch 24/200] [Batch 526/637] [D loss: 0.157701] [G loss: 0.529550]\n",
      "[Epoch 24/200] [Batch 527/637] [D loss: 0.174384] [G loss: 0.486373]\n",
      "[Epoch 24/200] [Batch 528/637] [D loss: 0.183221] [G loss: 0.495042]\n",
      "[Epoch 24/200] [Batch 529/637] [D loss: 0.152539] [G loss: 0.560976]\n",
      "[Epoch 24/200] [Batch 530/637] [D loss: 0.169212] [G loss: 0.523264]\n",
      "[Epoch 24/200] [Batch 531/637] [D loss: 0.175259] [G loss: 0.446286]\n",
      "[Epoch 24/200] [Batch 532/637] [D loss: 0.171475] [G loss: 0.502096]\n",
      "[Epoch 24/200] [Batch 533/637] [D loss: 0.164966] [G loss: 0.522621]\n",
      "[Epoch 24/200] [Batch 534/637] [D loss: 0.151561] [G loss: 0.529052]\n",
      "[Epoch 24/200] [Batch 535/637] [D loss: 0.192612] [G loss: 0.478893]\n",
      "[Epoch 24/200] [Batch 536/637] [D loss: 0.184013] [G loss: 0.542224]\n",
      "[Epoch 24/200] [Batch 537/637] [D loss: 0.198059] [G loss: 0.517849]\n",
      "[Epoch 24/200] [Batch 538/637] [D loss: 0.159512] [G loss: 0.494911]\n",
      "[Epoch 24/200] [Batch 539/637] [D loss: 0.150944] [G loss: 0.503043]\n",
      "[Epoch 24/200] [Batch 540/637] [D loss: 0.176446] [G loss: 0.464478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 541/637] [D loss: 0.157888] [G loss: 0.516878]\n",
      "[Epoch 24/200] [Batch 542/637] [D loss: 0.173019] [G loss: 0.547355]\n",
      "[Epoch 24/200] [Batch 543/637] [D loss: 0.143320] [G loss: 0.484043]\n",
      "[Epoch 24/200] [Batch 544/637] [D loss: 0.169576] [G loss: 0.454177]\n",
      "[Epoch 24/200] [Batch 545/637] [D loss: 0.144079] [G loss: 0.554547]\n",
      "[Epoch 24/200] [Batch 546/637] [D loss: 0.182277] [G loss: 0.488303]\n",
      "[Epoch 24/200] [Batch 547/637] [D loss: 0.145016] [G loss: 0.552850]\n",
      "[Epoch 24/200] [Batch 548/637] [D loss: 0.156594] [G loss: 0.534608]\n",
      "[Epoch 24/200] [Batch 549/637] [D loss: 0.157093] [G loss: 0.466604]\n",
      "[Epoch 24/200] [Batch 550/637] [D loss: 0.165074] [G loss: 0.459383]\n",
      "[Epoch 24/200] [Batch 551/637] [D loss: 0.156281] [G loss: 0.548761]\n",
      "[Epoch 24/200] [Batch 552/637] [D loss: 0.159237] [G loss: 0.570802]\n",
      "[Epoch 24/200] [Batch 553/637] [D loss: 0.180162] [G loss: 0.522300]\n",
      "[Epoch 24/200] [Batch 554/637] [D loss: 0.186910] [G loss: 0.447722]\n",
      "[Epoch 24/200] [Batch 555/637] [D loss: 0.160154] [G loss: 0.529071]\n",
      "[Epoch 24/200] [Batch 556/637] [D loss: 0.165240] [G loss: 0.518036]\n",
      "[Epoch 24/200] [Batch 557/637] [D loss: 0.168257] [G loss: 0.556459]\n",
      "[Epoch 24/200] [Batch 558/637] [D loss: 0.166002] [G loss: 0.522558]\n",
      "[Epoch 24/200] [Batch 559/637] [D loss: 0.191059] [G loss: 0.429529]\n",
      "[Epoch 24/200] [Batch 560/637] [D loss: 0.181566] [G loss: 0.496874]\n",
      "[Epoch 24/200] [Batch 561/637] [D loss: 0.165333] [G loss: 0.514392]\n",
      "[Epoch 24/200] [Batch 562/637] [D loss: 0.185971] [G loss: 0.434124]\n",
      "[Epoch 24/200] [Batch 563/637] [D loss: 0.182579] [G loss: 0.502465]\n",
      "[Epoch 24/200] [Batch 564/637] [D loss: 0.171699] [G loss: 0.454238]\n",
      "[Epoch 24/200] [Batch 565/637] [D loss: 0.192894] [G loss: 0.443752]\n",
      "[Epoch 24/200] [Batch 566/637] [D loss: 0.188353] [G loss: 0.537762]\n",
      "[Epoch 24/200] [Batch 567/637] [D loss: 0.168756] [G loss: 0.511665]\n",
      "[Epoch 24/200] [Batch 568/637] [D loss: 0.187534] [G loss: 0.392461]\n",
      "[Epoch 24/200] [Batch 569/637] [D loss: 0.163665] [G loss: 0.459413]\n",
      "[Epoch 24/200] [Batch 570/637] [D loss: 0.170326] [G loss: 0.566905]\n",
      "[Epoch 24/200] [Batch 571/637] [D loss: 0.190811] [G loss: 0.590902]\n",
      "[Epoch 24/200] [Batch 572/637] [D loss: 0.180402] [G loss: 0.585597]\n",
      "[Epoch 24/200] [Batch 573/637] [D loss: 0.171194] [G loss: 0.471011]\n",
      "[Epoch 24/200] [Batch 574/637] [D loss: 0.199156] [G loss: 0.400698]\n",
      "[Epoch 24/200] [Batch 575/637] [D loss: 0.149591] [G loss: 0.567424]\n",
      "[Epoch 24/200] [Batch 576/637] [D loss: 0.171366] [G loss: 0.546515]\n",
      "[Epoch 24/200] [Batch 577/637] [D loss: 0.157226] [G loss: 0.520047]\n",
      "[Epoch 24/200] [Batch 578/637] [D loss: 0.156872] [G loss: 0.493270]\n",
      "[Epoch 24/200] [Batch 579/637] [D loss: 0.165480] [G loss: 0.532734]\n",
      "[Epoch 24/200] [Batch 580/637] [D loss: 0.186689] [G loss: 0.497008]\n",
      "[Epoch 24/200] [Batch 581/637] [D loss: 0.188647] [G loss: 0.543468]\n",
      "[Epoch 24/200] [Batch 582/637] [D loss: 0.184331] [G loss: 0.444508]\n",
      "[Epoch 24/200] [Batch 583/637] [D loss: 0.156622] [G loss: 0.523814]\n",
      "[Epoch 24/200] [Batch 584/637] [D loss: 0.166689] [G loss: 0.528656]\n",
      "[Epoch 24/200] [Batch 585/637] [D loss: 0.152964] [G loss: 0.503379]\n",
      "[Epoch 24/200] [Batch 586/637] [D loss: 0.161980] [G loss: 0.507027]\n",
      "[Epoch 24/200] [Batch 587/637] [D loss: 0.157704] [G loss: 0.532651]\n",
      "[Epoch 24/200] [Batch 588/637] [D loss: 0.167257] [G loss: 0.512599]\n",
      "[Epoch 24/200] [Batch 589/637] [D loss: 0.164707] [G loss: 0.506305]\n",
      "[Epoch 24/200] [Batch 590/637] [D loss: 0.167700] [G loss: 0.497893]\n",
      "[Epoch 24/200] [Batch 591/637] [D loss: 0.176859] [G loss: 0.545863]\n",
      "[Epoch 24/200] [Batch 592/637] [D loss: 0.191620] [G loss: 0.490764]\n",
      "[Epoch 24/200] [Batch 593/637] [D loss: 0.170576] [G loss: 0.496294]\n",
      "[Epoch 24/200] [Batch 594/637] [D loss: 0.160327] [G loss: 0.493312]\n",
      "[Epoch 24/200] [Batch 595/637] [D loss: 0.166940] [G loss: 0.525524]\n",
      "[Epoch 24/200] [Batch 596/637] [D loss: 0.148067] [G loss: 0.551560]\n",
      "[Epoch 24/200] [Batch 597/637] [D loss: 0.167101] [G loss: 0.469070]\n",
      "[Epoch 24/200] [Batch 598/637] [D loss: 0.171869] [G loss: 0.539930]\n",
      "[Epoch 24/200] [Batch 599/637] [D loss: 0.155308] [G loss: 0.532305]\n",
      "[Epoch 24/200] [Batch 600/637] [D loss: 0.206526] [G loss: 0.437502]\n",
      "[Epoch 24/200] [Batch 601/637] [D loss: 0.170352] [G loss: 0.497142]\n",
      "[Epoch 24/200] [Batch 602/637] [D loss: 0.181545] [G loss: 0.489112]\n",
      "[Epoch 24/200] [Batch 603/637] [D loss: 0.162657] [G loss: 0.460184]\n",
      "[Epoch 24/200] [Batch 604/637] [D loss: 0.152825] [G loss: 0.486613]\n",
      "[Epoch 24/200] [Batch 605/637] [D loss: 0.192108] [G loss: 0.422127]\n",
      "[Epoch 24/200] [Batch 606/637] [D loss: 0.193752] [G loss: 0.444359]\n",
      "[Epoch 24/200] [Batch 607/637] [D loss: 0.165451] [G loss: 0.488547]\n",
      "[Epoch 24/200] [Batch 608/637] [D loss: 0.176234] [G loss: 0.443550]\n",
      "[Epoch 24/200] [Batch 609/637] [D loss: 0.148401] [G loss: 0.454808]\n",
      "[Epoch 24/200] [Batch 610/637] [D loss: 0.164635] [G loss: 0.456636]\n",
      "[Epoch 24/200] [Batch 611/637] [D loss: 0.152261] [G loss: 0.526343]\n",
      "[Epoch 24/200] [Batch 612/637] [D loss: 0.163392] [G loss: 0.466376]\n",
      "[Epoch 24/200] [Batch 613/637] [D loss: 0.162284] [G loss: 0.477691]\n",
      "[Epoch 24/200] [Batch 614/637] [D loss: 0.157008] [G loss: 0.539449]\n",
      "[Epoch 24/200] [Batch 615/637] [D loss: 0.157045] [G loss: 0.521026]\n",
      "[Epoch 24/200] [Batch 616/637] [D loss: 0.154436] [G loss: 0.458088]\n",
      "[Epoch 24/200] [Batch 617/637] [D loss: 0.167812] [G loss: 0.451887]\n",
      "[Epoch 24/200] [Batch 618/637] [D loss: 0.127462] [G loss: 0.465860]\n",
      "[Epoch 24/200] [Batch 619/637] [D loss: 0.182984] [G loss: 0.524166]\n",
      "[Epoch 24/200] [Batch 620/637] [D loss: 0.159441] [G loss: 0.444069]\n",
      "[Epoch 24/200] [Batch 621/637] [D loss: 0.165471] [G loss: 0.483708]\n",
      "[Epoch 24/200] [Batch 622/637] [D loss: 0.172850] [G loss: 0.518463]\n",
      "[Epoch 24/200] [Batch 623/637] [D loss: 0.156377] [G loss: 0.455129]\n",
      "[Epoch 24/200] [Batch 624/637] [D loss: 0.150144] [G loss: 0.444725]\n",
      "[Epoch 24/200] [Batch 625/637] [D loss: 0.164664] [G loss: 0.411867]\n",
      "[Epoch 24/200] [Batch 626/637] [D loss: 0.173430] [G loss: 0.431085]\n",
      "[Epoch 24/200] [Batch 627/637] [D loss: 0.144984] [G loss: 0.470692]\n",
      "[Epoch 24/200] [Batch 628/637] [D loss: 0.196111] [G loss: 0.424453]\n",
      "[Epoch 24/200] [Batch 629/637] [D loss: 0.178695] [G loss: 0.593783]\n",
      "[Epoch 24/200] [Batch 630/637] [D loss: 0.178799] [G loss: 0.523858]\n",
      "[Epoch 24/200] [Batch 631/637] [D loss: 0.153133] [G loss: 0.526471]\n",
      "[Epoch 24/200] [Batch 632/637] [D loss: 0.162701] [G loss: 0.480067]\n",
      "[Epoch 24/200] [Batch 633/637] [D loss: 0.142495] [G loss: 0.585900]\n",
      "[Epoch 24/200] [Batch 634/637] [D loss: 0.140345] [G loss: 0.531575]\n",
      "[Epoch 24/200] [Batch 635/637] [D loss: 0.172376] [G loss: 0.517890]\n",
      "[Epoch 24/200] [Batch 636/637] [D loss: 0.187554] [G loss: 0.433606]\n",
      "[Epoch 25/200] [Batch 0/637] [D loss: 0.183455] [G loss: 0.484256]\n",
      "[Epoch 25/200] [Batch 1/637] [D loss: 0.169704] [G loss: 0.505909]\n",
      "[Epoch 25/200] [Batch 2/637] [D loss: 0.141810] [G loss: 0.448765]\n",
      "[Epoch 25/200] [Batch 3/637] [D loss: 0.159932] [G loss: 0.439052]\n",
      "[Epoch 25/200] [Batch 4/637] [D loss: 0.161343] [G loss: 0.406453]\n",
      "[Epoch 25/200] [Batch 5/637] [D loss: 0.150333] [G loss: 0.489291]\n",
      "[Epoch 25/200] [Batch 6/637] [D loss: 0.152598] [G loss: 0.497278]\n",
      "[Epoch 25/200] [Batch 7/637] [D loss: 0.187330] [G loss: 0.489690]\n",
      "[Epoch 25/200] [Batch 8/637] [D loss: 0.171469] [G loss: 0.466165]\n",
      "[Epoch 25/200] [Batch 9/637] [D loss: 0.172315] [G loss: 0.492250]\n",
      "[Epoch 25/200] [Batch 10/637] [D loss: 0.184512] [G loss: 0.489854]\n",
      "[Epoch 25/200] [Batch 11/637] [D loss: 0.175165] [G loss: 0.498464]\n",
      "[Epoch 25/200] [Batch 12/637] [D loss: 0.162316] [G loss: 0.426196]\n",
      "[Epoch 25/200] [Batch 13/637] [D loss: 0.146488] [G loss: 0.486493]\n",
      "[Epoch 25/200] [Batch 14/637] [D loss: 0.160643] [G loss: 0.479064]\n",
      "[Epoch 25/200] [Batch 15/637] [D loss: 0.141378] [G loss: 0.509365]\n",
      "[Epoch 25/200] [Batch 16/637] [D loss: 0.179290] [G loss: 0.480758]\n",
      "[Epoch 25/200] [Batch 17/637] [D loss: 0.156210] [G loss: 0.522992]\n",
      "[Epoch 25/200] [Batch 18/637] [D loss: 0.178654] [G loss: 0.546083]\n",
      "[Epoch 25/200] [Batch 19/637] [D loss: 0.148345] [G loss: 0.549013]\n",
      "[Epoch 25/200] [Batch 20/637] [D loss: 0.159439] [G loss: 0.525054]\n",
      "[Epoch 25/200] [Batch 21/637] [D loss: 0.170550] [G loss: 0.481470]\n",
      "[Epoch 25/200] [Batch 22/637] [D loss: 0.143957] [G loss: 0.599220]\n",
      "[Epoch 25/200] [Batch 23/637] [D loss: 0.177975] [G loss: 0.536978]\n",
      "[Epoch 25/200] [Batch 24/637] [D loss: 0.178568] [G loss: 0.472341]\n",
      "[Epoch 25/200] [Batch 25/637] [D loss: 0.170045] [G loss: 0.534834]\n",
      "[Epoch 25/200] [Batch 26/637] [D loss: 0.182116] [G loss: 0.515802]\n",
      "[Epoch 25/200] [Batch 27/637] [D loss: 0.173723] [G loss: 0.450840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/200] [Batch 28/637] [D loss: 0.167415] [G loss: 0.501358]\n",
      "[Epoch 25/200] [Batch 29/637] [D loss: 0.157907] [G loss: 0.511099]\n",
      "[Epoch 25/200] [Batch 30/637] [D loss: 0.165425] [G loss: 0.547128]\n",
      "[Epoch 25/200] [Batch 31/637] [D loss: 0.146457] [G loss: 0.516607]\n",
      "[Epoch 25/200] [Batch 32/637] [D loss: 0.161443] [G loss: 0.553571]\n",
      "[Epoch 25/200] [Batch 33/637] [D loss: 0.154572] [G loss: 0.521482]\n",
      "[Epoch 25/200] [Batch 34/637] [D loss: 0.137089] [G loss: 0.517815]\n",
      "[Epoch 25/200] [Batch 35/637] [D loss: 0.185258] [G loss: 0.588453]\n",
      "[Epoch 25/200] [Batch 36/637] [D loss: 0.155833] [G loss: 0.549553]\n",
      "[Epoch 25/200] [Batch 37/637] [D loss: 0.145355] [G loss: 0.531776]\n",
      "[Epoch 25/200] [Batch 38/637] [D loss: 0.185164] [G loss: 0.415909]\n",
      "[Epoch 25/200] [Batch 39/637] [D loss: 0.217531] [G loss: 0.628297]\n",
      "[Epoch 25/200] [Batch 40/637] [D loss: 0.177840] [G loss: 0.490017]\n",
      "[Epoch 25/200] [Batch 41/637] [D loss: 0.214100] [G loss: 0.470607]\n",
      "[Epoch 25/200] [Batch 42/637] [D loss: 0.170917] [G loss: 0.477293]\n",
      "[Epoch 25/200] [Batch 43/637] [D loss: 0.174443] [G loss: 0.548019]\n",
      "[Epoch 25/200] [Batch 44/637] [D loss: 0.164595] [G loss: 0.521483]\n",
      "[Epoch 25/200] [Batch 45/637] [D loss: 0.155933] [G loss: 0.480614]\n",
      "[Epoch 25/200] [Batch 46/637] [D loss: 0.186866] [G loss: 0.508675]\n",
      "[Epoch 25/200] [Batch 47/637] [D loss: 0.154396] [G loss: 0.473618]\n",
      "[Epoch 25/200] [Batch 48/637] [D loss: 0.157871] [G loss: 0.545781]\n",
      "[Epoch 25/200] [Batch 49/637] [D loss: 0.152103] [G loss: 0.538428]\n",
      "[Epoch 25/200] [Batch 50/637] [D loss: 0.147360] [G loss: 0.535049]\n",
      "[Epoch 25/200] [Batch 51/637] [D loss: 0.144636] [G loss: 0.511383]\n",
      "[Epoch 25/200] [Batch 52/637] [D loss: 0.117589] [G loss: 0.542056]\n",
      "[Epoch 25/200] [Batch 53/637] [D loss: 0.179776] [G loss: 0.451020]\n",
      "[Epoch 25/200] [Batch 54/637] [D loss: 0.141571] [G loss: 0.578687]\n",
      "[Epoch 25/200] [Batch 55/637] [D loss: 0.176699] [G loss: 0.558245]\n",
      "[Epoch 25/200] [Batch 56/637] [D loss: 0.160028] [G loss: 0.532772]\n",
      "[Epoch 25/200] [Batch 57/637] [D loss: 0.156670] [G loss: 0.482855]\n",
      "[Epoch 25/200] [Batch 58/637] [D loss: 0.154543] [G loss: 0.479290]\n",
      "[Epoch 25/200] [Batch 59/637] [D loss: 0.163027] [G loss: 0.486241]\n",
      "[Epoch 25/200] [Batch 60/637] [D loss: 0.167988] [G loss: 0.491251]\n",
      "[Epoch 25/200] [Batch 61/637] [D loss: 0.167114] [G loss: 0.529567]\n",
      "[Epoch 25/200] [Batch 62/637] [D loss: 0.149827] [G loss: 0.524498]\n",
      "[Epoch 25/200] [Batch 63/637] [D loss: 0.145593] [G loss: 0.539497]\n",
      "[Epoch 25/200] [Batch 64/637] [D loss: 0.157212] [G loss: 0.450535]\n",
      "[Epoch 25/200] [Batch 65/637] [D loss: 0.162230] [G loss: 0.480455]\n",
      "[Epoch 25/200] [Batch 66/637] [D loss: 0.221156] [G loss: 0.468512]\n",
      "[Epoch 25/200] [Batch 67/637] [D loss: 0.189443] [G loss: 0.529834]\n",
      "[Epoch 25/200] [Batch 68/637] [D loss: 0.166996] [G loss: 0.515723]\n",
      "[Epoch 25/200] [Batch 69/637] [D loss: 0.161420] [G loss: 0.419417]\n",
      "[Epoch 25/200] [Batch 70/637] [D loss: 0.140871] [G loss: 0.527081]\n",
      "[Epoch 25/200] [Batch 71/637] [D loss: 0.196053] [G loss: 0.516780]\n",
      "[Epoch 25/200] [Batch 72/637] [D loss: 0.176602] [G loss: 0.478619]\n",
      "[Epoch 25/200] [Batch 73/637] [D loss: 0.172595] [G loss: 0.469472]\n",
      "[Epoch 25/200] [Batch 74/637] [D loss: 0.169967] [G loss: 0.520498]\n",
      "[Epoch 25/200] [Batch 75/637] [D loss: 0.175956] [G loss: 0.469693]\n",
      "[Epoch 25/200] [Batch 76/637] [D loss: 0.162477] [G loss: 0.561152]\n",
      "[Epoch 25/200] [Batch 77/637] [D loss: 0.150508] [G loss: 0.540361]\n",
      "[Epoch 25/200] [Batch 78/637] [D loss: 0.180050] [G loss: 0.441458]\n",
      "[Epoch 25/200] [Batch 79/637] [D loss: 0.155569] [G loss: 0.510822]\n",
      "[Epoch 25/200] [Batch 80/637] [D loss: 0.149688] [G loss: 0.540713]\n",
      "[Epoch 25/200] [Batch 81/637] [D loss: 0.160393] [G loss: 0.467785]\n",
      "[Epoch 25/200] [Batch 82/637] [D loss: 0.154428] [G loss: 0.446384]\n",
      "[Epoch 25/200] [Batch 83/637] [D loss: 0.147365] [G loss: 0.476706]\n",
      "[Epoch 25/200] [Batch 84/637] [D loss: 0.178408] [G loss: 0.491675]\n",
      "[Epoch 25/200] [Batch 85/637] [D loss: 0.163862] [G loss: 0.590801]\n",
      "[Epoch 25/200] [Batch 86/637] [D loss: 0.153169] [G loss: 0.593527]\n",
      "[Epoch 25/200] [Batch 87/637] [D loss: 0.146304] [G loss: 0.479393]\n",
      "[Epoch 25/200] [Batch 88/637] [D loss: 0.165212] [G loss: 0.419749]\n",
      "[Epoch 25/200] [Batch 89/637] [D loss: 0.169672] [G loss: 0.415384]\n",
      "[Epoch 25/200] [Batch 90/637] [D loss: 0.167060] [G loss: 0.484946]\n",
      "[Epoch 25/200] [Batch 91/637] [D loss: 0.153616] [G loss: 0.574237]\n",
      "[Epoch 25/200] [Batch 92/637] [D loss: 0.194373] [G loss: 0.458961]\n",
      "[Epoch 25/200] [Batch 93/637] [D loss: 0.185342] [G loss: 0.525530]\n",
      "[Epoch 25/200] [Batch 94/637] [D loss: 0.154109] [G loss: 0.545814]\n",
      "[Epoch 25/200] [Batch 95/637] [D loss: 0.164173] [G loss: 0.472602]\n",
      "[Epoch 25/200] [Batch 96/637] [D loss: 0.188229] [G loss: 0.428173]\n",
      "[Epoch 25/200] [Batch 97/637] [D loss: 0.192372] [G loss: 0.457199]\n",
      "[Epoch 25/200] [Batch 98/637] [D loss: 0.183665] [G loss: 0.477239]\n",
      "[Epoch 25/200] [Batch 99/637] [D loss: 0.166299] [G loss: 0.544557]\n",
      "[Epoch 25/200] [Batch 100/637] [D loss: 0.132000] [G loss: 0.546181]\n",
      "[Epoch 25/200] [Batch 101/637] [D loss: 0.153257] [G loss: 0.476826]\n",
      "[Epoch 25/200] [Batch 102/637] [D loss: 0.159526] [G loss: 0.569403]\n",
      "[Epoch 25/200] [Batch 103/637] [D loss: 0.182642] [G loss: 0.495651]\n",
      "[Epoch 25/200] [Batch 104/637] [D loss: 0.177465] [G loss: 0.559916]\n",
      "[Epoch 25/200] [Batch 105/637] [D loss: 0.147660] [G loss: 0.545594]\n",
      "[Epoch 25/200] [Batch 106/637] [D loss: 0.164941] [G loss: 0.444539]\n",
      "[Epoch 25/200] [Batch 107/637] [D loss: 0.160934] [G loss: 0.462055]\n",
      "[Epoch 25/200] [Batch 108/637] [D loss: 0.163276] [G loss: 0.452525]\n",
      "[Epoch 25/200] [Batch 109/637] [D loss: 0.166542] [G loss: 0.533723]\n",
      "[Epoch 25/200] [Batch 110/637] [D loss: 0.155722] [G loss: 0.540068]\n",
      "[Epoch 25/200] [Batch 111/637] [D loss: 0.166562] [G loss: 0.491987]\n",
      "[Epoch 25/200] [Batch 112/637] [D loss: 0.163602] [G loss: 0.504666]\n",
      "[Epoch 25/200] [Batch 113/637] [D loss: 0.145618] [G loss: 0.563835]\n",
      "[Epoch 25/200] [Batch 114/637] [D loss: 0.169165] [G loss: 0.476646]\n",
      "[Epoch 25/200] [Batch 115/637] [D loss: 0.157728] [G loss: 0.466311]\n",
      "[Epoch 25/200] [Batch 116/637] [D loss: 0.178118] [G loss: 0.462722]\n",
      "[Epoch 25/200] [Batch 117/637] [D loss: 0.203987] [G loss: 0.448608]\n",
      "[Epoch 25/200] [Batch 118/637] [D loss: 0.159780] [G loss: 0.575108]\n",
      "[Epoch 25/200] [Batch 119/637] [D loss: 0.184652] [G loss: 0.493089]\n",
      "[Epoch 25/200] [Batch 120/637] [D loss: 0.183224] [G loss: 0.482892]\n",
      "[Epoch 25/200] [Batch 121/637] [D loss: 0.216132] [G loss: 0.469559]\n",
      "[Epoch 25/200] [Batch 122/637] [D loss: 0.172384] [G loss: 0.506820]\n",
      "[Epoch 25/200] [Batch 123/637] [D loss: 0.208571] [G loss: 0.453150]\n",
      "[Epoch 25/200] [Batch 124/637] [D loss: 0.173169] [G loss: 0.473806]\n",
      "[Epoch 25/200] [Batch 125/637] [D loss: 0.165885] [G loss: 0.434369]\n",
      "[Epoch 25/200] [Batch 126/637] [D loss: 0.180507] [G loss: 0.432139]\n",
      "[Epoch 25/200] [Batch 127/637] [D loss: 0.174408] [G loss: 0.453671]\n",
      "[Epoch 25/200] [Batch 128/637] [D loss: 0.184762] [G loss: 0.489703]\n",
      "[Epoch 25/200] [Batch 129/637] [D loss: 0.166055] [G loss: 0.544866]\n",
      "[Epoch 25/200] [Batch 130/637] [D loss: 0.167670] [G loss: 0.581801]\n",
      "[Epoch 25/200] [Batch 131/637] [D loss: 0.159715] [G loss: 0.557605]\n",
      "[Epoch 25/200] [Batch 132/637] [D loss: 0.160731] [G loss: 0.505419]\n",
      "[Epoch 25/200] [Batch 133/637] [D loss: 0.161350] [G loss: 0.466577]\n",
      "[Epoch 25/200] [Batch 134/637] [D loss: 0.169934] [G loss: 0.463769]\n",
      "[Epoch 25/200] [Batch 135/637] [D loss: 0.144534] [G loss: 0.515559]\n",
      "[Epoch 25/200] [Batch 136/637] [D loss: 0.162123] [G loss: 0.493850]\n",
      "[Epoch 25/200] [Batch 137/637] [D loss: 0.157572] [G loss: 0.510958]\n",
      "[Epoch 25/200] [Batch 138/637] [D loss: 0.176705] [G loss: 0.468273]\n",
      "[Epoch 25/200] [Batch 139/637] [D loss: 0.173650] [G loss: 0.518308]\n",
      "[Epoch 25/200] [Batch 140/637] [D loss: 0.159250] [G loss: 0.527086]\n",
      "[Epoch 25/200] [Batch 141/637] [D loss: 0.171820] [G loss: 0.458725]\n",
      "[Epoch 25/200] [Batch 142/637] [D loss: 0.164349] [G loss: 0.509650]\n",
      "[Epoch 25/200] [Batch 143/637] [D loss: 0.167353] [G loss: 0.471646]\n",
      "[Epoch 25/200] [Batch 144/637] [D loss: 0.168240] [G loss: 0.483201]\n",
      "[Epoch 25/200] [Batch 145/637] [D loss: 0.193853] [G loss: 0.475610]\n",
      "[Epoch 25/200] [Batch 146/637] [D loss: 0.161460] [G loss: 0.549838]\n",
      "[Epoch 25/200] [Batch 147/637] [D loss: 0.188425] [G loss: 0.473190]\n",
      "[Epoch 25/200] [Batch 148/637] [D loss: 0.175512] [G loss: 0.461419]\n",
      "[Epoch 25/200] [Batch 149/637] [D loss: 0.185855] [G loss: 0.484586]\n",
      "[Epoch 25/200] [Batch 150/637] [D loss: 0.164537] [G loss: 0.494865]\n",
      "[Epoch 25/200] [Batch 151/637] [D loss: 0.168816] [G loss: 0.451112]\n",
      "[Epoch 25/200] [Batch 152/637] [D loss: 0.171022] [G loss: 0.515246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/200] [Batch 153/637] [D loss: 0.147759] [G loss: 0.500551]\n",
      "[Epoch 25/200] [Batch 154/637] [D loss: 0.151101] [G loss: 0.509692]\n",
      "[Epoch 25/200] [Batch 155/637] [D loss: 0.139995] [G loss: 0.509374]\n",
      "[Epoch 25/200] [Batch 156/637] [D loss: 0.160188] [G loss: 0.526479]\n",
      "[Epoch 25/200] [Batch 157/637] [D loss: 0.140438] [G loss: 0.533190]\n",
      "[Epoch 25/200] [Batch 158/637] [D loss: 0.142675] [G loss: 0.540064]\n",
      "[Epoch 25/200] [Batch 159/637] [D loss: 0.151893] [G loss: 0.493060]\n",
      "[Epoch 25/200] [Batch 160/637] [D loss: 0.149991] [G loss: 0.522861]\n",
      "[Epoch 25/200] [Batch 161/637] [D loss: 0.157109] [G loss: 0.511054]\n",
      "[Epoch 25/200] [Batch 162/637] [D loss: 0.176141] [G loss: 0.559227]\n",
      "[Epoch 25/200] [Batch 163/637] [D loss: 0.170648] [G loss: 0.500599]\n",
      "[Epoch 25/200] [Batch 164/637] [D loss: 0.177758] [G loss: 0.457675]\n",
      "[Epoch 25/200] [Batch 165/637] [D loss: 0.179371] [G loss: 0.557797]\n",
      "[Epoch 25/200] [Batch 166/637] [D loss: 0.218084] [G loss: 0.492397]\n",
      "[Epoch 25/200] [Batch 167/637] [D loss: 0.174915] [G loss: 0.600642]\n",
      "[Epoch 25/200] [Batch 168/637] [D loss: 0.159108] [G loss: 0.467837]\n",
      "[Epoch 25/200] [Batch 169/637] [D loss: 0.178800] [G loss: 0.486609]\n",
      "[Epoch 25/200] [Batch 170/637] [D loss: 0.164735] [G loss: 0.483006]\n",
      "[Epoch 25/200] [Batch 171/637] [D loss: 0.167118] [G loss: 0.490485]\n",
      "[Epoch 25/200] [Batch 172/637] [D loss: 0.158395] [G loss: 0.503214]\n",
      "[Epoch 25/200] [Batch 173/637] [D loss: 0.179761] [G loss: 0.503691]\n",
      "[Epoch 25/200] [Batch 174/637] [D loss: 0.168884] [G loss: 0.502977]\n",
      "[Epoch 25/200] [Batch 175/637] [D loss: 0.182543] [G loss: 0.502875]\n",
      "[Epoch 25/200] [Batch 176/637] [D loss: 0.154325] [G loss: 0.454537]\n",
      "[Epoch 25/200] [Batch 177/637] [D loss: 0.167442] [G loss: 0.500017]\n",
      "[Epoch 25/200] [Batch 178/637] [D loss: 0.149833] [G loss: 0.505932]\n",
      "[Epoch 25/200] [Batch 179/637] [D loss: 0.178783] [G loss: 0.468067]\n",
      "[Epoch 25/200] [Batch 180/637] [D loss: 0.157908] [G loss: 0.524316]\n",
      "[Epoch 25/200] [Batch 181/637] [D loss: 0.178375] [G loss: 0.449926]\n",
      "[Epoch 25/200] [Batch 182/637] [D loss: 0.149133] [G loss: 0.491496]\n",
      "[Epoch 25/200] [Batch 183/637] [D loss: 0.153876] [G loss: 0.476891]\n",
      "[Epoch 25/200] [Batch 184/637] [D loss: 0.163424] [G loss: 0.500670]\n",
      "[Epoch 25/200] [Batch 185/637] [D loss: 0.163208] [G loss: 0.549664]\n",
      "[Epoch 25/200] [Batch 186/637] [D loss: 0.152309] [G loss: 0.595880]\n",
      "[Epoch 25/200] [Batch 187/637] [D loss: 0.153003] [G loss: 0.523894]\n",
      "[Epoch 25/200] [Batch 188/637] [D loss: 0.169273] [G loss: 0.483939]\n",
      "[Epoch 25/200] [Batch 189/637] [D loss: 0.172199] [G loss: 0.482097]\n",
      "[Epoch 25/200] [Batch 190/637] [D loss: 0.174204] [G loss: 0.546455]\n",
      "[Epoch 25/200] [Batch 191/637] [D loss: 0.177397] [G loss: 0.534779]\n",
      "[Epoch 25/200] [Batch 192/637] [D loss: 0.166115] [G loss: 0.522473]\n",
      "[Epoch 25/200] [Batch 193/637] [D loss: 0.171541] [G loss: 0.537516]\n",
      "[Epoch 25/200] [Batch 194/637] [D loss: 0.189920] [G loss: 0.481104]\n",
      "[Epoch 25/200] [Batch 195/637] [D loss: 0.206569] [G loss: 0.490587]\n",
      "[Epoch 25/200] [Batch 196/637] [D loss: 0.173232] [G loss: 0.569251]\n",
      "[Epoch 25/200] [Batch 197/637] [D loss: 0.156306] [G loss: 0.483667]\n",
      "[Epoch 25/200] [Batch 198/637] [D loss: 0.182286] [G loss: 0.430334]\n",
      "[Epoch 25/200] [Batch 199/637] [D loss: 0.172176] [G loss: 0.473644]\n",
      "[Epoch 25/200] [Batch 200/637] [D loss: 0.166474] [G loss: 0.508048]\n",
      "[Epoch 25/200] [Batch 201/637] [D loss: 0.151065] [G loss: 0.474604]\n",
      "[Epoch 25/200] [Batch 202/637] [D loss: 0.143261] [G loss: 0.527842]\n",
      "[Epoch 25/200] [Batch 203/637] [D loss: 0.164246] [G loss: 0.533589]\n",
      "[Epoch 25/200] [Batch 204/637] [D loss: 0.145232] [G loss: 0.498190]\n",
      "[Epoch 25/200] [Batch 205/637] [D loss: 0.149328] [G loss: 0.482383]\n",
      "[Epoch 25/200] [Batch 206/637] [D loss: 0.137719] [G loss: 0.462970]\n",
      "[Epoch 25/200] [Batch 207/637] [D loss: 0.153108] [G loss: 0.563334]\n",
      "[Epoch 25/200] [Batch 208/637] [D loss: 0.168161] [G loss: 0.475989]\n",
      "[Epoch 25/200] [Batch 209/637] [D loss: 0.179611] [G loss: 0.523406]\n",
      "[Epoch 25/200] [Batch 210/637] [D loss: 0.182071] [G loss: 0.584471]\n",
      "[Epoch 25/200] [Batch 211/637] [D loss: 0.198474] [G loss: 0.523026]\n",
      "[Epoch 25/200] [Batch 212/637] [D loss: 0.164679] [G loss: 0.580389]\n",
      "[Epoch 25/200] [Batch 213/637] [D loss: 0.162712] [G loss: 0.535900]\n",
      "[Epoch 25/200] [Batch 214/637] [D loss: 0.165387] [G loss: 0.532363]\n",
      "[Epoch 25/200] [Batch 215/637] [D loss: 0.183641] [G loss: 0.536245]\n",
      "[Epoch 25/200] [Batch 216/637] [D loss: 0.155574] [G loss: 0.546513]\n",
      "[Epoch 25/200] [Batch 217/637] [D loss: 0.186843] [G loss: 0.471949]\n",
      "[Epoch 25/200] [Batch 218/637] [D loss: 0.176394] [G loss: 0.544189]\n",
      "[Epoch 25/200] [Batch 219/637] [D loss: 0.178024] [G loss: 0.526159]\n",
      "[Epoch 25/200] [Batch 220/637] [D loss: 0.164309] [G loss: 0.502851]\n",
      "[Epoch 25/200] [Batch 221/637] [D loss: 0.172047] [G loss: 0.560936]\n",
      "[Epoch 25/200] [Batch 222/637] [D loss: 0.166115] [G loss: 0.486613]\n",
      "[Epoch 25/200] [Batch 223/637] [D loss: 0.174003] [G loss: 0.484681]\n",
      "[Epoch 25/200] [Batch 224/637] [D loss: 0.187799] [G loss: 0.422251]\n",
      "[Epoch 25/200] [Batch 225/637] [D loss: 0.152170] [G loss: 0.477837]\n",
      "[Epoch 25/200] [Batch 226/637] [D loss: 0.168418] [G loss: 0.518250]\n",
      "[Epoch 25/200] [Batch 227/637] [D loss: 0.153814] [G loss: 0.521084]\n",
      "[Epoch 25/200] [Batch 228/637] [D loss: 0.166123] [G loss: 0.479122]\n",
      "[Epoch 25/200] [Batch 229/637] [D loss: 0.181854] [G loss: 0.469965]\n",
      "[Epoch 25/200] [Batch 230/637] [D loss: 0.164494] [G loss: 0.494907]\n",
      "[Epoch 25/200] [Batch 231/637] [D loss: 0.181884] [G loss: 0.489170]\n",
      "[Epoch 25/200] [Batch 232/637] [D loss: 0.206973] [G loss: 0.424450]\n",
      "[Epoch 25/200] [Batch 233/637] [D loss: 0.168359] [G loss: 0.555629]\n",
      "[Epoch 25/200] [Batch 234/637] [D loss: 0.171902] [G loss: 0.553905]\n",
      "[Epoch 25/200] [Batch 235/637] [D loss: 0.168708] [G loss: 0.486073]\n",
      "[Epoch 25/200] [Batch 236/637] [D loss: 0.165839] [G loss: 0.449033]\n",
      "[Epoch 25/200] [Batch 237/637] [D loss: 0.161876] [G loss: 0.528840]\n",
      "[Epoch 25/200] [Batch 238/637] [D loss: 0.167174] [G loss: 0.480412]\n",
      "[Epoch 25/200] [Batch 239/637] [D loss: 0.156959] [G loss: 0.524173]\n",
      "[Epoch 25/200] [Batch 240/637] [D loss: 0.170136] [G loss: 0.494772]\n",
      "[Epoch 25/200] [Batch 241/637] [D loss: 0.161153] [G loss: 0.486945]\n",
      "[Epoch 25/200] [Batch 242/637] [D loss: 0.142023] [G loss: 0.504346]\n",
      "[Epoch 25/200] [Batch 243/637] [D loss: 0.159866] [G loss: 0.483812]\n",
      "[Epoch 25/200] [Batch 244/637] [D loss: 0.142351] [G loss: 0.569750]\n",
      "[Epoch 25/200] [Batch 245/637] [D loss: 0.161836] [G loss: 0.501711]\n",
      "[Epoch 25/200] [Batch 246/637] [D loss: 0.177837] [G loss: 0.476727]\n",
      "[Epoch 25/200] [Batch 247/637] [D loss: 0.151889] [G loss: 0.636494]\n",
      "[Epoch 25/200] [Batch 248/637] [D loss: 0.163210] [G loss: 0.530870]\n",
      "[Epoch 25/200] [Batch 249/637] [D loss: 0.146265] [G loss: 0.521897]\n",
      "[Epoch 25/200] [Batch 250/637] [D loss: 0.160329] [G loss: 0.480387]\n",
      "[Epoch 25/200] [Batch 251/637] [D loss: 0.187823] [G loss: 0.557792]\n",
      "[Epoch 25/200] [Batch 252/637] [D loss: 0.162638] [G loss: 0.491075]\n",
      "[Epoch 25/200] [Batch 253/637] [D loss: 0.176869] [G loss: 0.481889]\n",
      "[Epoch 25/200] [Batch 254/637] [D loss: 0.218226] [G loss: 0.552784]\n",
      "[Epoch 25/200] [Batch 255/637] [D loss: 0.167877] [G loss: 0.568888]\n",
      "[Epoch 25/200] [Batch 256/637] [D loss: 0.164288] [G loss: 0.432991]\n",
      "[Epoch 25/200] [Batch 257/637] [D loss: 0.152405] [G loss: 0.460614]\n",
      "[Epoch 25/200] [Batch 258/637] [D loss: 0.179190] [G loss: 0.402225]\n",
      "[Epoch 25/200] [Batch 259/637] [D loss: 0.174776] [G loss: 0.494013]\n",
      "[Epoch 25/200] [Batch 260/637] [D loss: 0.164254] [G loss: 0.511767]\n",
      "[Epoch 25/200] [Batch 261/637] [D loss: 0.144403] [G loss: 0.549939]\n",
      "[Epoch 25/200] [Batch 262/637] [D loss: 0.156776] [G loss: 0.509159]\n",
      "[Epoch 25/200] [Batch 263/637] [D loss: 0.170658] [G loss: 0.488482]\n",
      "[Epoch 25/200] [Batch 264/637] [D loss: 0.147856] [G loss: 0.529233]\n",
      "[Epoch 25/200] [Batch 265/637] [D loss: 0.143077] [G loss: 0.536776]\n",
      "[Epoch 25/200] [Batch 266/637] [D loss: 0.166913] [G loss: 0.518810]\n",
      "[Epoch 25/200] [Batch 267/637] [D loss: 0.203539] [G loss: 0.431260]\n",
      "[Epoch 25/200] [Batch 268/637] [D loss: 0.174278] [G loss: 0.495167]\n",
      "[Epoch 25/200] [Batch 269/637] [D loss: 0.185830] [G loss: 0.505402]\n",
      "[Epoch 25/200] [Batch 270/637] [D loss: 0.194068] [G loss: 0.403480]\n",
      "[Epoch 25/200] [Batch 271/637] [D loss: 0.241485] [G loss: 0.455425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/200] [Batch 272/637] [D loss: 0.182843] [G loss: 0.498978]\n",
      "[Epoch 25/200] [Batch 273/637] [D loss: 0.185673] [G loss: 0.473371]\n",
      "[Epoch 25/200] [Batch 274/637] [D loss: 0.173589] [G loss: 0.471565]\n",
      "[Epoch 25/200] [Batch 275/637] [D loss: 0.174798] [G loss: 0.485977]\n",
      "[Epoch 25/200] [Batch 276/637] [D loss: 0.179528] [G loss: 0.435596]\n",
      "[Epoch 25/200] [Batch 277/637] [D loss: 0.171442] [G loss: 0.477352]\n",
      "[Epoch 25/200] [Batch 278/637] [D loss: 0.180731] [G loss: 0.472224]\n",
      "[Epoch 25/200] [Batch 279/637] [D loss: 0.174087] [G loss: 0.435518]\n",
      "[Epoch 25/200] [Batch 280/637] [D loss: 0.164300] [G loss: 0.519572]\n",
      "[Epoch 25/200] [Batch 281/637] [D loss: 0.168797] [G loss: 0.445706]\n",
      "[Epoch 25/200] [Batch 282/637] [D loss: 0.177316] [G loss: 0.434268]\n",
      "[Epoch 25/200] [Batch 283/637] [D loss: 0.162357] [G loss: 0.424774]\n",
      "[Epoch 25/200] [Batch 284/637] [D loss: 0.169904] [G loss: 0.442706]\n",
      "[Epoch 25/200] [Batch 285/637] [D loss: 0.164766] [G loss: 0.589673]\n",
      "[Epoch 25/200] [Batch 286/637] [D loss: 0.151464] [G loss: 0.518425]\n",
      "[Epoch 25/200] [Batch 287/637] [D loss: 0.144492] [G loss: 0.480514]\n",
      "[Epoch 25/200] [Batch 288/637] [D loss: 0.185266] [G loss: 0.428596]\n",
      "[Epoch 25/200] [Batch 289/637] [D loss: 0.128960] [G loss: 0.572470]\n",
      "[Epoch 25/200] [Batch 290/637] [D loss: 0.141329] [G loss: 0.567831]\n",
      "[Epoch 25/200] [Batch 291/637] [D loss: 0.192796] [G loss: 0.455836]\n",
      "[Epoch 25/200] [Batch 292/637] [D loss: 0.173596] [G loss: 0.507354]\n",
      "[Epoch 25/200] [Batch 293/637] [D loss: 0.157645] [G loss: 0.494445]\n",
      "[Epoch 25/200] [Batch 294/637] [D loss: 0.167326] [G loss: 0.503510]\n",
      "[Epoch 25/200] [Batch 295/637] [D loss: 0.176619] [G loss: 0.516252]\n",
      "[Epoch 25/200] [Batch 296/637] [D loss: 0.176587] [G loss: 0.457154]\n",
      "[Epoch 25/200] [Batch 297/637] [D loss: 0.156314] [G loss: 0.468413]\n",
      "[Epoch 25/200] [Batch 298/637] [D loss: 0.194479] [G loss: 0.423280]\n",
      "[Epoch 25/200] [Batch 299/637] [D loss: 0.164354] [G loss: 0.494911]\n",
      "[Epoch 25/200] [Batch 300/637] [D loss: 0.192495] [G loss: 0.484336]\n",
      "[Epoch 25/200] [Batch 301/637] [D loss: 0.151460] [G loss: 0.538111]\n",
      "[Epoch 25/200] [Batch 302/637] [D loss: 0.169884] [G loss: 0.478600]\n",
      "[Epoch 25/200] [Batch 303/637] [D loss: 0.195423] [G loss: 0.448010]\n",
      "[Epoch 25/200] [Batch 304/637] [D loss: 0.152874] [G loss: 0.536332]\n",
      "[Epoch 25/200] [Batch 305/637] [D loss: 0.153198] [G loss: 0.509416]\n",
      "[Epoch 25/200] [Batch 306/637] [D loss: 0.166640] [G loss: 0.458336]\n",
      "[Epoch 25/200] [Batch 307/637] [D loss: 0.150818] [G loss: 0.547162]\n",
      "[Epoch 25/200] [Batch 308/637] [D loss: 0.186600] [G loss: 0.466409]\n",
      "[Epoch 25/200] [Batch 309/637] [D loss: 0.184459] [G loss: 0.479430]\n",
      "[Epoch 25/200] [Batch 310/637] [D loss: 0.184582] [G loss: 0.465133]\n",
      "[Epoch 25/200] [Batch 311/637] [D loss: 0.182214] [G loss: 0.517893]\n",
      "[Epoch 25/200] [Batch 312/637] [D loss: 0.180181] [G loss: 0.524720]\n",
      "[Epoch 25/200] [Batch 313/637] [D loss: 0.180527] [G loss: 0.492745]\n",
      "[Epoch 25/200] [Batch 314/637] [D loss: 0.169509] [G loss: 0.531807]\n",
      "[Epoch 25/200] [Batch 315/637] [D loss: 0.175709] [G loss: 0.484894]\n",
      "[Epoch 25/200] [Batch 316/637] [D loss: 0.189527] [G loss: 0.440224]\n",
      "[Epoch 25/200] [Batch 317/637] [D loss: 0.167907] [G loss: 0.518183]\n",
      "[Epoch 25/200] [Batch 318/637] [D loss: 0.161352] [G loss: 0.507938]\n",
      "[Epoch 25/200] [Batch 319/637] [D loss: 0.176621] [G loss: 0.492550]\n",
      "[Epoch 25/200] [Batch 320/637] [D loss: 0.155678] [G loss: 0.490768]\n",
      "[Epoch 25/200] [Batch 321/637] [D loss: 0.163011] [G loss: 0.513428]\n",
      "[Epoch 25/200] [Batch 322/637] [D loss: 0.170172] [G loss: 0.582492]\n",
      "[Epoch 25/200] [Batch 323/637] [D loss: 0.155581] [G loss: 0.588142]\n",
      "[Epoch 25/200] [Batch 324/637] [D loss: 0.159933] [G loss: 0.477800]\n",
      "[Epoch 25/200] [Batch 325/637] [D loss: 0.203610] [G loss: 0.505849]\n",
      "[Epoch 25/200] [Batch 326/637] [D loss: 0.205213] [G loss: 0.479191]\n",
      "[Epoch 25/200] [Batch 327/637] [D loss: 0.157916] [G loss: 0.592602]\n",
      "[Epoch 25/200] [Batch 328/637] [D loss: 0.181437] [G loss: 0.524058]\n",
      "[Epoch 25/200] [Batch 329/637] [D loss: 0.187096] [G loss: 0.509227]\n",
      "[Epoch 25/200] [Batch 330/637] [D loss: 0.182673] [G loss: 0.475893]\n",
      "[Epoch 25/200] [Batch 331/637] [D loss: 0.180681] [G loss: 0.478301]\n",
      "[Epoch 25/200] [Batch 332/637] [D loss: 0.166606] [G loss: 0.430126]\n",
      "[Epoch 25/200] [Batch 333/637] [D loss: 0.204317] [G loss: 0.375247]\n",
      "[Epoch 25/200] [Batch 334/637] [D loss: 0.163062] [G loss: 0.533757]\n",
      "[Epoch 25/200] [Batch 335/637] [D loss: 0.174370] [G loss: 0.550634]\n",
      "[Epoch 25/200] [Batch 336/637] [D loss: 0.173462] [G loss: 0.497527]\n",
      "[Epoch 25/200] [Batch 337/637] [D loss: 0.207664] [G loss: 0.439095]\n",
      "[Epoch 25/200] [Batch 338/637] [D loss: 0.205859] [G loss: 0.447192]\n",
      "[Epoch 25/200] [Batch 339/637] [D loss: 0.167902] [G loss: 0.461536]\n",
      "[Epoch 25/200] [Batch 340/637] [D loss: 0.163216] [G loss: 0.533317]\n",
      "[Epoch 25/200] [Batch 341/637] [D loss: 0.168257] [G loss: 0.490141]\n",
      "[Epoch 25/200] [Batch 342/637] [D loss: 0.126481] [G loss: 0.469393]\n",
      "[Epoch 25/200] [Batch 343/637] [D loss: 0.150102] [G loss: 0.441031]\n",
      "[Epoch 25/200] [Batch 344/637] [D loss: 0.160973] [G loss: 0.475173]\n",
      "[Epoch 25/200] [Batch 345/637] [D loss: 0.164915] [G loss: 0.572046]\n",
      "[Epoch 25/200] [Batch 346/637] [D loss: 0.151822] [G loss: 0.596086]\n",
      "[Epoch 25/200] [Batch 347/637] [D loss: 0.164865] [G loss: 0.491197]\n",
      "[Epoch 25/200] [Batch 348/637] [D loss: 0.167029] [G loss: 0.501619]\n",
      "[Epoch 25/200] [Batch 349/637] [D loss: 0.168955] [G loss: 0.440621]\n",
      "[Epoch 25/200] [Batch 350/637] [D loss: 0.164498] [G loss: 0.495521]\n",
      "[Epoch 25/200] [Batch 351/637] [D loss: 0.168260] [G loss: 0.419705]\n",
      "[Epoch 25/200] [Batch 352/637] [D loss: 0.167297] [G loss: 0.430976]\n",
      "[Epoch 25/200] [Batch 353/637] [D loss: 0.166771] [G loss: 0.498004]\n",
      "[Epoch 25/200] [Batch 354/637] [D loss: 0.143980] [G loss: 0.459133]\n",
      "[Epoch 25/200] [Batch 355/637] [D loss: 0.168627] [G loss: 0.440895]\n",
      "[Epoch 25/200] [Batch 356/637] [D loss: 0.163164] [G loss: 0.462366]\n",
      "[Epoch 25/200] [Batch 357/637] [D loss: 0.164648] [G loss: 0.478479]\n",
      "[Epoch 25/200] [Batch 358/637] [D loss: 0.144108] [G loss: 0.536913]\n",
      "[Epoch 25/200] [Batch 359/637] [D loss: 0.152968] [G loss: 0.568325]\n",
      "[Epoch 25/200] [Batch 360/637] [D loss: 0.154906] [G loss: 0.513345]\n",
      "[Epoch 25/200] [Batch 361/637] [D loss: 0.151268] [G loss: 0.533485]\n",
      "[Epoch 25/200] [Batch 362/637] [D loss: 0.164177] [G loss: 0.478777]\n",
      "[Epoch 25/200] [Batch 363/637] [D loss: 0.157720] [G loss: 0.489213]\n",
      "[Epoch 25/200] [Batch 364/637] [D loss: 0.169912] [G loss: 0.454473]\n",
      "[Epoch 25/200] [Batch 365/637] [D loss: 0.182783] [G loss: 0.466952]\n",
      "[Epoch 25/200] [Batch 366/637] [D loss: 0.152491] [G loss: 0.448160]\n",
      "[Epoch 25/200] [Batch 367/637] [D loss: 0.167623] [G loss: 0.433404]\n",
      "[Epoch 25/200] [Batch 368/637] [D loss: 0.154769] [G loss: 0.582034]\n",
      "[Epoch 25/200] [Batch 369/637] [D loss: 0.149088] [G loss: 0.477862]\n",
      "[Epoch 25/200] [Batch 370/637] [D loss: 0.150095] [G loss: 0.477421]\n",
      "[Epoch 25/200] [Batch 371/637] [D loss: 0.158687] [G loss: 0.488483]\n",
      "[Epoch 25/200] [Batch 372/637] [D loss: 0.162877] [G loss: 0.487267]\n",
      "[Epoch 25/200] [Batch 373/637] [D loss: 0.159610] [G loss: 0.538034]\n",
      "[Epoch 25/200] [Batch 374/637] [D loss: 0.170908] [G loss: 0.446876]\n",
      "[Epoch 25/200] [Batch 375/637] [D loss: 0.149897] [G loss: 0.508476]\n",
      "[Epoch 25/200] [Batch 376/637] [D loss: 0.170926] [G loss: 0.456035]\n",
      "[Epoch 25/200] [Batch 377/637] [D loss: 0.152924] [G loss: 0.501150]\n",
      "[Epoch 25/200] [Batch 378/637] [D loss: 0.223130] [G loss: 0.387722]\n",
      "[Epoch 25/200] [Batch 379/637] [D loss: 0.183594] [G loss: 0.479313]\n",
      "[Epoch 25/200] [Batch 380/637] [D loss: 0.184180] [G loss: 0.529935]\n",
      "[Epoch 25/200] [Batch 381/637] [D loss: 0.201488] [G loss: 0.445389]\n",
      "[Epoch 25/200] [Batch 382/637] [D loss: 0.161132] [G loss: 0.532885]\n",
      "[Epoch 25/200] [Batch 383/637] [D loss: 0.162755] [G loss: 0.530693]\n",
      "[Epoch 25/200] [Batch 384/637] [D loss: 0.181179] [G loss: 0.468436]\n",
      "[Epoch 25/200] [Batch 385/637] [D loss: 0.165785] [G loss: 0.453425]\n",
      "[Epoch 25/200] [Batch 386/637] [D loss: 0.184992] [G loss: 0.497608]\n",
      "[Epoch 25/200] [Batch 387/637] [D loss: 0.143192] [G loss: 0.564337]\n",
      "[Epoch 25/200] [Batch 388/637] [D loss: 0.164495] [G loss: 0.560764]\n",
      "[Epoch 25/200] [Batch 389/637] [D loss: 0.175238] [G loss: 0.475552]\n",
      "[Epoch 25/200] [Batch 390/637] [D loss: 0.156860] [G loss: 0.426649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/200] [Batch 391/637] [D loss: 0.155612] [G loss: 0.516845]\n",
      "[Epoch 25/200] [Batch 392/637] [D loss: 0.136036] [G loss: 0.495453]\n",
      "[Epoch 25/200] [Batch 393/637] [D loss: 0.163537] [G loss: 0.536958]\n",
      "[Epoch 25/200] [Batch 394/637] [D loss: 0.158333] [G loss: 0.515870]\n",
      "[Epoch 25/200] [Batch 395/637] [D loss: 0.155062] [G loss: 0.449344]\n",
      "[Epoch 25/200] [Batch 396/637] [D loss: 0.145546] [G loss: 0.519611]\n",
      "[Epoch 25/200] [Batch 397/637] [D loss: 0.192582] [G loss: 0.403977]\n",
      "[Epoch 25/200] [Batch 398/637] [D loss: 0.143967] [G loss: 0.520953]\n",
      "[Epoch 25/200] [Batch 399/637] [D loss: 0.156058] [G loss: 0.525799]\n",
      "[Epoch 25/200] [Batch 400/637] [D loss: 0.164835] [G loss: 0.533521]\n",
      "[Epoch 25/200] [Batch 401/637] [D loss: 0.178913] [G loss: 0.512075]\n",
      "[Epoch 25/200] [Batch 402/637] [D loss: 0.163081] [G loss: 0.494442]\n",
      "[Epoch 25/200] [Batch 403/637] [D loss: 0.173443] [G loss: 0.531080]\n",
      "[Epoch 25/200] [Batch 404/637] [D loss: 0.174295] [G loss: 0.460739]\n",
      "[Epoch 25/200] [Batch 405/637] [D loss: 0.166788] [G loss: 0.453929]\n",
      "[Epoch 25/200] [Batch 406/637] [D loss: 0.177562] [G loss: 0.449193]\n",
      "[Epoch 25/200] [Batch 407/637] [D loss: 0.170682] [G loss: 0.544027]\n",
      "[Epoch 25/200] [Batch 408/637] [D loss: 0.159994] [G loss: 0.479544]\n",
      "[Epoch 25/200] [Batch 409/637] [D loss: 0.155203] [G loss: 0.482068]\n",
      "[Epoch 25/200] [Batch 410/637] [D loss: 0.139546] [G loss: 0.529250]\n",
      "[Epoch 25/200] [Batch 411/637] [D loss: 0.158758] [G loss: 0.467174]\n",
      "[Epoch 25/200] [Batch 412/637] [D loss: 0.174175] [G loss: 0.427107]\n",
      "[Epoch 25/200] [Batch 413/637] [D loss: 0.146998] [G loss: 0.571028]\n",
      "[Epoch 25/200] [Batch 414/637] [D loss: 0.168257] [G loss: 0.513637]\n",
      "[Epoch 25/200] [Batch 415/637] [D loss: 0.149489] [G loss: 0.536441]\n",
      "[Epoch 25/200] [Batch 416/637] [D loss: 0.151006] [G loss: 0.514117]\n",
      "[Epoch 25/200] [Batch 417/637] [D loss: 0.150265] [G loss: 0.457198]\n",
      "[Epoch 25/200] [Batch 418/637] [D loss: 0.151277] [G loss: 0.473417]\n",
      "[Epoch 25/200] [Batch 419/637] [D loss: 0.171808] [G loss: 0.487916]\n",
      "[Epoch 25/200] [Batch 420/637] [D loss: 0.144500] [G loss: 0.480078]\n",
      "[Epoch 25/200] [Batch 421/637] [D loss: 0.163523] [G loss: 0.490645]\n",
      "[Epoch 25/200] [Batch 422/637] [D loss: 0.153361] [G loss: 0.508143]\n",
      "[Epoch 25/200] [Batch 423/637] [D loss: 0.149536] [G loss: 0.515903]\n",
      "[Epoch 25/200] [Batch 424/637] [D loss: 0.201324] [G loss: 0.360450]\n",
      "[Epoch 25/200] [Batch 425/637] [D loss: 0.198255] [G loss: 0.582062]\n",
      "[Epoch 25/200] [Batch 426/637] [D loss: 0.183138] [G loss: 0.539788]\n",
      "[Epoch 25/200] [Batch 427/637] [D loss: 0.163864] [G loss: 0.564508]\n",
      "[Epoch 25/200] [Batch 428/637] [D loss: 0.180477] [G loss: 0.473676]\n",
      "[Epoch 25/200] [Batch 429/637] [D loss: 0.175395] [G loss: 0.504745]\n",
      "[Epoch 25/200] [Batch 430/637] [D loss: 0.167365] [G loss: 0.473549]\n",
      "[Epoch 25/200] [Batch 431/637] [D loss: 0.148526] [G loss: 0.490940]\n",
      "[Epoch 25/200] [Batch 432/637] [D loss: 0.148587] [G loss: 0.507552]\n",
      "[Epoch 25/200] [Batch 433/637] [D loss: 0.154282] [G loss: 0.561509]\n",
      "[Epoch 25/200] [Batch 434/637] [D loss: 0.149036] [G loss: 0.540637]\n",
      "[Epoch 25/200] [Batch 435/637] [D loss: 0.166225] [G loss: 0.518824]\n",
      "[Epoch 25/200] [Batch 436/637] [D loss: 0.158636] [G loss: 0.538193]\n",
      "[Epoch 25/200] [Batch 437/637] [D loss: 0.163038] [G loss: 0.471806]\n",
      "[Epoch 25/200] [Batch 438/637] [D loss: 0.188850] [G loss: 0.442299]\n",
      "[Epoch 25/200] [Batch 439/637] [D loss: 0.163471] [G loss: 0.583911]\n",
      "[Epoch 25/200] [Batch 440/637] [D loss: 0.181139] [G loss: 0.541733]\n",
      "[Epoch 25/200] [Batch 441/637] [D loss: 0.183705] [G loss: 0.437930]\n",
      "[Epoch 25/200] [Batch 442/637] [D loss: 0.175573] [G loss: 0.440214]\n",
      "[Epoch 25/200] [Batch 443/637] [D loss: 0.163825] [G loss: 0.558329]\n",
      "[Epoch 25/200] [Batch 444/637] [D loss: 0.175570] [G loss: 0.544574]\n",
      "[Epoch 25/200] [Batch 445/637] [D loss: 0.171900] [G loss: 0.465520]\n",
      "[Epoch 25/200] [Batch 446/637] [D loss: 0.145816] [G loss: 0.564743]\n",
      "[Epoch 25/200] [Batch 447/637] [D loss: 0.190101] [G loss: 0.434778]\n",
      "[Epoch 25/200] [Batch 448/637] [D loss: 0.158762] [G loss: 0.522181]\n",
      "[Epoch 25/200] [Batch 449/637] [D loss: 0.167300] [G loss: 0.545340]\n",
      "[Epoch 25/200] [Batch 450/637] [D loss: 0.153688] [G loss: 0.532938]\n",
      "[Epoch 25/200] [Batch 451/637] [D loss: 0.206364] [G loss: 0.477370]\n",
      "[Epoch 25/200] [Batch 452/637] [D loss: 0.187652] [G loss: 0.677436]\n",
      "[Epoch 25/200] [Batch 453/637] [D loss: 0.168482] [G loss: 0.580830]\n",
      "[Epoch 25/200] [Batch 454/637] [D loss: 0.152960] [G loss: 0.493054]\n",
      "[Epoch 25/200] [Batch 455/637] [D loss: 0.162095] [G loss: 0.503403]\n",
      "[Epoch 25/200] [Batch 456/637] [D loss: 0.158564] [G loss: 0.464725]\n",
      "[Epoch 25/200] [Batch 457/637] [D loss: 0.156429] [G loss: 0.548874]\n",
      "[Epoch 25/200] [Batch 458/637] [D loss: 0.172055] [G loss: 0.537600]\n",
      "[Epoch 25/200] [Batch 459/637] [D loss: 0.154744] [G loss: 0.519976]\n",
      "[Epoch 25/200] [Batch 460/637] [D loss: 0.169680] [G loss: 0.520639]\n",
      "[Epoch 25/200] [Batch 461/637] [D loss: 0.170817] [G loss: 0.473939]\n",
      "[Epoch 25/200] [Batch 462/637] [D loss: 0.156760] [G loss: 0.459031]\n",
      "[Epoch 25/200] [Batch 463/637] [D loss: 0.146724] [G loss: 0.531142]\n",
      "[Epoch 25/200] [Batch 464/637] [D loss: 0.161785] [G loss: 0.514368]\n",
      "[Epoch 25/200] [Batch 465/637] [D loss: 0.183199] [G loss: 0.498741]\n",
      "[Epoch 25/200] [Batch 466/637] [D loss: 0.173771] [G loss: 0.490555]\n",
      "[Epoch 25/200] [Batch 467/637] [D loss: 0.168130] [G loss: 0.525284]\n",
      "[Epoch 25/200] [Batch 468/637] [D loss: 0.165744] [G loss: 0.589510]\n",
      "[Epoch 25/200] [Batch 469/637] [D loss: 0.166878] [G loss: 0.556484]\n",
      "[Epoch 25/200] [Batch 470/637] [D loss: 0.157320] [G loss: 0.543634]\n",
      "[Epoch 25/200] [Batch 471/637] [D loss: 0.142341] [G loss: 0.510763]\n",
      "[Epoch 25/200] [Batch 472/637] [D loss: 0.180801] [G loss: 0.465582]\n",
      "[Epoch 25/200] [Batch 473/637] [D loss: 0.198545] [G loss: 0.450021]\n",
      "[Epoch 25/200] [Batch 474/637] [D loss: 0.149769] [G loss: 0.518369]\n",
      "[Epoch 25/200] [Batch 475/637] [D loss: 0.157714] [G loss: 0.526555]\n",
      "[Epoch 25/200] [Batch 476/637] [D loss: 0.141239] [G loss: 0.509100]\n",
      "[Epoch 25/200] [Batch 477/637] [D loss: 0.170831] [G loss: 0.479914]\n",
      "[Epoch 25/200] [Batch 478/637] [D loss: 0.170678] [G loss: 0.435318]\n",
      "[Epoch 25/200] [Batch 479/637] [D loss: 0.169872] [G loss: 0.512858]\n",
      "[Epoch 25/200] [Batch 480/637] [D loss: 0.214280] [G loss: 0.520087]\n",
      "[Epoch 25/200] [Batch 481/637] [D loss: 0.165707] [G loss: 0.529341]\n",
      "[Epoch 25/200] [Batch 482/637] [D loss: 0.177764] [G loss: 0.456116]\n",
      "[Epoch 25/200] [Batch 483/637] [D loss: 0.171850] [G loss: 0.514643]\n",
      "[Epoch 25/200] [Batch 484/637] [D loss: 0.175027] [G loss: 0.484848]\n",
      "[Epoch 25/200] [Batch 485/637] [D loss: 0.177940] [G loss: 0.501095]\n",
      "[Epoch 25/200] [Batch 486/637] [D loss: 0.187705] [G loss: 0.432619]\n",
      "[Epoch 25/200] [Batch 487/637] [D loss: 0.166242] [G loss: 0.460589]\n",
      "[Epoch 25/200] [Batch 488/637] [D loss: 0.165723] [G loss: 0.513231]\n",
      "[Epoch 25/200] [Batch 489/637] [D loss: 0.163923] [G loss: 0.487139]\n",
      "[Epoch 25/200] [Batch 490/637] [D loss: 0.150986] [G loss: 0.548694]\n",
      "[Epoch 25/200] [Batch 491/637] [D loss: 0.175833] [G loss: 0.496027]\n",
      "[Epoch 25/200] [Batch 492/637] [D loss: 0.157434] [G loss: 0.452436]\n",
      "[Epoch 25/200] [Batch 493/637] [D loss: 0.184179] [G loss: 0.425058]\n",
      "[Epoch 25/200] [Batch 494/637] [D loss: 0.201379] [G loss: 0.519114]\n",
      "[Epoch 25/200] [Batch 495/637] [D loss: 0.179046] [G loss: 0.578449]\n",
      "[Epoch 25/200] [Batch 496/637] [D loss: 0.182608] [G loss: 0.575726]\n",
      "[Epoch 25/200] [Batch 497/637] [D loss: 0.165283] [G loss: 0.522736]\n",
      "[Epoch 25/200] [Batch 498/637] [D loss: 0.179665] [G loss: 0.446001]\n",
      "[Epoch 25/200] [Batch 499/637] [D loss: 0.156484] [G loss: 0.495119]\n",
      "[Epoch 25/200] [Batch 500/637] [D loss: 0.176032] [G loss: 0.436120]\n",
      "[Epoch 25/200] [Batch 501/637] [D loss: 0.195939] [G loss: 0.497964]\n",
      "[Epoch 25/200] [Batch 502/637] [D loss: 0.161998] [G loss: 0.518442]\n",
      "[Epoch 25/200] [Batch 503/637] [D loss: 0.153465] [G loss: 0.523654]\n",
      "[Epoch 25/200] [Batch 504/637] [D loss: 0.182452] [G loss: 0.474471]\n",
      "[Epoch 25/200] [Batch 505/637] [D loss: 0.162429] [G loss: 0.592094]\n",
      "[Epoch 25/200] [Batch 506/637] [D loss: 0.195502] [G loss: 0.454203]\n",
      "[Epoch 25/200] [Batch 507/637] [D loss: 0.143615] [G loss: 0.490092]\n",
      "[Epoch 25/200] [Batch 508/637] [D loss: 0.179972] [G loss: 0.459493]\n",
      "[Epoch 25/200] [Batch 509/637] [D loss: 0.131997] [G loss: 0.571139]\n",
      "[Epoch 25/200] [Batch 510/637] [D loss: 0.164214] [G loss: 0.495063]\n",
      "[Epoch 25/200] [Batch 511/637] [D loss: 0.150508] [G loss: 0.478683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/200] [Batch 512/637] [D loss: 0.165965] [G loss: 0.436969]\n",
      "[Epoch 25/200] [Batch 513/637] [D loss: 0.144599] [G loss: 0.548209]\n",
      "[Epoch 25/200] [Batch 514/637] [D loss: 0.165975] [G loss: 0.464879]\n",
      "[Epoch 25/200] [Batch 515/637] [D loss: 0.168678] [G loss: 0.512545]\n",
      "[Epoch 25/200] [Batch 516/637] [D loss: 0.154090] [G loss: 0.553918]\n",
      "[Epoch 25/200] [Batch 517/637] [D loss: 0.162205] [G loss: 0.597058]\n",
      "[Epoch 25/200] [Batch 518/637] [D loss: 0.143556] [G loss: 0.494119]\n",
      "[Epoch 25/200] [Batch 519/637] [D loss: 0.248200] [G loss: 0.413203]\n",
      "[Epoch 25/200] [Batch 520/637] [D loss: 0.200232] [G loss: 0.592205]\n",
      "[Epoch 25/200] [Batch 521/637] [D loss: 0.177441] [G loss: 0.518293]\n",
      "[Epoch 25/200] [Batch 522/637] [D loss: 0.194580] [G loss: 0.460297]\n",
      "[Epoch 25/200] [Batch 523/637] [D loss: 0.175778] [G loss: 0.634023]\n",
      "[Epoch 25/200] [Batch 524/637] [D loss: 0.184247] [G loss: 0.572327]\n",
      "[Epoch 25/200] [Batch 525/637] [D loss: 0.172983] [G loss: 0.448870]\n",
      "[Epoch 25/200] [Batch 526/637] [D loss: 0.163929] [G loss: 0.463314]\n",
      "[Epoch 25/200] [Batch 527/637] [D loss: 0.153520] [G loss: 0.459090]\n",
      "[Epoch 25/200] [Batch 528/637] [D loss: 0.160857] [G loss: 0.466579]\n",
      "[Epoch 25/200] [Batch 529/637] [D loss: 0.153380] [G loss: 0.497051]\n",
      "[Epoch 25/200] [Batch 530/637] [D loss: 0.170231] [G loss: 0.487078]\n",
      "[Epoch 25/200] [Batch 531/637] [D loss: 0.175052] [G loss: 0.471643]\n",
      "[Epoch 25/200] [Batch 532/637] [D loss: 0.171466] [G loss: 0.557320]\n",
      "[Epoch 25/200] [Batch 533/637] [D loss: 0.161637] [G loss: 0.483631]\n",
      "[Epoch 25/200] [Batch 534/637] [D loss: 0.159607] [G loss: 0.453645]\n",
      "[Epoch 25/200] [Batch 535/637] [D loss: 0.174092] [G loss: 0.438145]\n",
      "[Epoch 25/200] [Batch 536/637] [D loss: 0.160287] [G loss: 0.478974]\n",
      "[Epoch 25/200] [Batch 537/637] [D loss: 0.163344] [G loss: 0.529905]\n",
      "[Epoch 25/200] [Batch 538/637] [D loss: 0.175555] [G loss: 0.476448]\n",
      "[Epoch 25/200] [Batch 539/637] [D loss: 0.228676] [G loss: 0.417050]\n",
      "[Epoch 25/200] [Batch 540/637] [D loss: 0.163561] [G loss: 0.537417]\n",
      "[Epoch 25/200] [Batch 541/637] [D loss: 0.183872] [G loss: 0.445262]\n",
      "[Epoch 25/200] [Batch 542/637] [D loss: 0.149066] [G loss: 0.506373]\n",
      "[Epoch 25/200] [Batch 543/637] [D loss: 0.166334] [G loss: 0.489182]\n",
      "[Epoch 25/200] [Batch 544/637] [D loss: 0.188842] [G loss: 0.452838]\n",
      "[Epoch 25/200] [Batch 545/637] [D loss: 0.163694] [G loss: 0.474867]\n",
      "[Epoch 25/200] [Batch 546/637] [D loss: 0.174541] [G loss: 0.478824]\n",
      "[Epoch 25/200] [Batch 547/637] [D loss: 0.170810] [G loss: 0.476035]\n",
      "[Epoch 25/200] [Batch 548/637] [D loss: 0.155415] [G loss: 0.460887]\n",
      "[Epoch 25/200] [Batch 549/637] [D loss: 0.182636] [G loss: 0.381234]\n",
      "[Epoch 25/200] [Batch 550/637] [D loss: 0.165690] [G loss: 0.477805]\n",
      "[Epoch 25/200] [Batch 551/637] [D loss: 0.176113] [G loss: 0.497690]\n",
      "[Epoch 25/200] [Batch 552/637] [D loss: 0.193857] [G loss: 0.382262]\n",
      "[Epoch 25/200] [Batch 553/637] [D loss: 0.163346] [G loss: 0.451183]\n",
      "[Epoch 25/200] [Batch 554/637] [D loss: 0.175754] [G loss: 0.501320]\n",
      "[Epoch 25/200] [Batch 555/637] [D loss: 0.185726] [G loss: 0.510827]\n",
      "[Epoch 25/200] [Batch 556/637] [D loss: 0.160770] [G loss: 0.494661]\n",
      "[Epoch 25/200] [Batch 557/637] [D loss: 0.154272] [G loss: 0.472104]\n",
      "[Epoch 25/200] [Batch 558/637] [D loss: 0.163178] [G loss: 0.483777]\n",
      "[Epoch 25/200] [Batch 559/637] [D loss: 0.166472] [G loss: 0.548610]\n",
      "[Epoch 25/200] [Batch 560/637] [D loss: 0.197655] [G loss: 0.449778]\n",
      "[Epoch 25/200] [Batch 561/637] [D loss: 0.185933] [G loss: 0.479036]\n",
      "[Epoch 25/200] [Batch 562/637] [D loss: 0.175623] [G loss: 0.564932]\n",
      "[Epoch 25/200] [Batch 563/637] [D loss: 0.171655] [G loss: 0.555825]\n",
      "[Epoch 25/200] [Batch 564/637] [D loss: 0.174945] [G loss: 0.533786]\n",
      "[Epoch 25/200] [Batch 565/637] [D loss: 0.160432] [G loss: 0.450271]\n",
      "[Epoch 25/200] [Batch 566/637] [D loss: 0.181839] [G loss: 0.466236]\n",
      "[Epoch 25/200] [Batch 567/637] [D loss: 0.142497] [G loss: 0.601995]\n",
      "[Epoch 25/200] [Batch 568/637] [D loss: 0.180731] [G loss: 0.538145]\n",
      "[Epoch 25/200] [Batch 569/637] [D loss: 0.157422] [G loss: 0.589135]\n",
      "[Epoch 25/200] [Batch 570/637] [D loss: 0.175994] [G loss: 0.575426]\n",
      "[Epoch 25/200] [Batch 571/637] [D loss: 0.156748] [G loss: 0.553491]\n",
      "[Epoch 25/200] [Batch 572/637] [D loss: 0.164903] [G loss: 0.518328]\n",
      "[Epoch 25/200] [Batch 573/637] [D loss: 0.157769] [G loss: 0.497074]\n",
      "[Epoch 25/200] [Batch 574/637] [D loss: 0.143258] [G loss: 0.467315]\n",
      "[Epoch 25/200] [Batch 575/637] [D loss: 0.148246] [G loss: 0.505398]\n",
      "[Epoch 25/200] [Batch 576/637] [D loss: 0.172786] [G loss: 0.501056]\n",
      "[Epoch 25/200] [Batch 577/637] [D loss: 0.168509] [G loss: 0.697421]\n",
      "[Epoch 25/200] [Batch 578/637] [D loss: 0.168116] [G loss: 0.570642]\n",
      "[Epoch 25/200] [Batch 579/637] [D loss: 0.169498] [G loss: 0.465682]\n",
      "[Epoch 25/200] [Batch 580/637] [D loss: 0.185209] [G loss: 0.398486]\n",
      "[Epoch 25/200] [Batch 581/637] [D loss: 0.163318] [G loss: 0.482400]\n",
      "[Epoch 25/200] [Batch 582/637] [D loss: 0.156839] [G loss: 0.506261]\n",
      "[Epoch 25/200] [Batch 583/637] [D loss: 0.168088] [G loss: 0.440572]\n",
      "[Epoch 25/200] [Batch 584/637] [D loss: 0.170289] [G loss: 0.488673]\n",
      "[Epoch 25/200] [Batch 585/637] [D loss: 0.158588] [G loss: 0.509866]\n",
      "[Epoch 25/200] [Batch 586/637] [D loss: 0.182893] [G loss: 0.498259]\n",
      "[Epoch 25/200] [Batch 587/637] [D loss: 0.188080] [G loss: 0.490394]\n",
      "[Epoch 25/200] [Batch 588/637] [D loss: 0.166241] [G loss: 0.544936]\n",
      "[Epoch 25/200] [Batch 589/637] [D loss: 0.176316] [G loss: 0.536694]\n",
      "[Epoch 25/200] [Batch 590/637] [D loss: 0.174087] [G loss: 0.495887]\n",
      "[Epoch 25/200] [Batch 591/637] [D loss: 0.181326] [G loss: 0.452876]\n",
      "[Epoch 25/200] [Batch 592/637] [D loss: 0.159230] [G loss: 0.492769]\n",
      "[Epoch 25/200] [Batch 593/637] [D loss: 0.165450] [G loss: 0.509925]\n",
      "[Epoch 25/200] [Batch 594/637] [D loss: 0.173752] [G loss: 0.506423]\n",
      "[Epoch 25/200] [Batch 595/637] [D loss: 0.183847] [G loss: 0.572621]\n",
      "[Epoch 25/200] [Batch 596/637] [D loss: 0.188194] [G loss: 0.439882]\n",
      "[Epoch 25/200] [Batch 597/637] [D loss: 0.196225] [G loss: 0.457070]\n",
      "[Epoch 25/200] [Batch 598/637] [D loss: 0.173336] [G loss: 0.521844]\n",
      "[Epoch 25/200] [Batch 599/637] [D loss: 0.166962] [G loss: 0.512647]\n",
      "[Epoch 25/200] [Batch 600/637] [D loss: 0.166993] [G loss: 0.518797]\n",
      "[Epoch 25/200] [Batch 601/637] [D loss: 0.155489] [G loss: 0.471899]\n",
      "[Epoch 25/200] [Batch 602/637] [D loss: 0.177094] [G loss: 0.528921]\n",
      "[Epoch 25/200] [Batch 603/637] [D loss: 0.165131] [G loss: 0.519715]\n",
      "[Epoch 25/200] [Batch 604/637] [D loss: 0.188252] [G loss: 0.494668]\n",
      "[Epoch 25/200] [Batch 605/637] [D loss: 0.166765] [G loss: 0.629861]\n",
      "[Epoch 25/200] [Batch 606/637] [D loss: 0.181620] [G loss: 0.584259]\n",
      "[Epoch 25/200] [Batch 607/637] [D loss: 0.171663] [G loss: 0.500413]\n",
      "[Epoch 25/200] [Batch 608/637] [D loss: 0.160925] [G loss: 0.534739]\n",
      "[Epoch 25/200] [Batch 609/637] [D loss: 0.173230] [G loss: 0.419225]\n",
      "[Epoch 25/200] [Batch 610/637] [D loss: 0.143030] [G loss: 0.531399]\n",
      "[Epoch 25/200] [Batch 611/637] [D loss: 0.167357] [G loss: 0.503308]\n",
      "[Epoch 25/200] [Batch 612/637] [D loss: 0.163409] [G loss: 0.525825]\n",
      "[Epoch 25/200] [Batch 613/637] [D loss: 0.153420] [G loss: 0.609654]\n",
      "[Epoch 25/200] [Batch 614/637] [D loss: 0.185779] [G loss: 0.481960]\n",
      "[Epoch 25/200] [Batch 615/637] [D loss: 0.191154] [G loss: 0.572653]\n",
      "[Epoch 25/200] [Batch 616/637] [D loss: 0.148876] [G loss: 0.517364]\n",
      "[Epoch 25/200] [Batch 617/637] [D loss: 0.167219] [G loss: 0.427413]\n",
      "[Epoch 25/200] [Batch 618/637] [D loss: 0.158489] [G loss: 0.449926]\n",
      "[Epoch 25/200] [Batch 619/637] [D loss: 0.179871] [G loss: 0.509468]\n",
      "[Epoch 25/200] [Batch 620/637] [D loss: 0.178638] [G loss: 0.442149]\n",
      "[Epoch 25/200] [Batch 621/637] [D loss: 0.177015] [G loss: 0.524322]\n",
      "[Epoch 25/200] [Batch 622/637] [D loss: 0.169144] [G loss: 0.546896]\n",
      "[Epoch 25/200] [Batch 623/637] [D loss: 0.144798] [G loss: 0.544825]\n",
      "[Epoch 25/200] [Batch 624/637] [D loss: 0.138395] [G loss: 0.526128]\n",
      "[Epoch 25/200] [Batch 625/637] [D loss: 0.185534] [G loss: 0.430764]\n",
      "[Epoch 25/200] [Batch 626/637] [D loss: 0.220431] [G loss: 0.416754]\n",
      "[Epoch 25/200] [Batch 627/637] [D loss: 0.250016] [G loss: 0.620358]\n",
      "[Epoch 25/200] [Batch 628/637] [D loss: 0.186413] [G loss: 0.575219]\n",
      "[Epoch 25/200] [Batch 629/637] [D loss: 0.190323] [G loss: 0.501578]\n",
      "[Epoch 25/200] [Batch 630/637] [D loss: 0.176334] [G loss: 0.470861]\n",
      "[Epoch 25/200] [Batch 631/637] [D loss: 0.185703] [G loss: 0.461665]\n",
      "[Epoch 25/200] [Batch 632/637] [D loss: 0.154620] [G loss: 0.446443]\n",
      "[Epoch 25/200] [Batch 633/637] [D loss: 0.169644] [G loss: 0.469552]\n",
      "[Epoch 25/200] [Batch 634/637] [D loss: 0.149370] [G loss: 0.472342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/200] [Batch 635/637] [D loss: 0.172691] [G loss: 0.479200]\n",
      "[Epoch 25/200] [Batch 636/637] [D loss: 0.184244] [G loss: 0.444455]\n",
      "[Epoch 26/200] [Batch 0/637] [D loss: 0.172153] [G loss: 0.527276]\n",
      "[Epoch 26/200] [Batch 1/637] [D loss: 0.171947] [G loss: 0.530350]\n",
      "[Epoch 26/200] [Batch 2/637] [D loss: 0.169764] [G loss: 0.548598]\n",
      "[Epoch 26/200] [Batch 3/637] [D loss: 0.159896] [G loss: 0.441559]\n",
      "[Epoch 26/200] [Batch 4/637] [D loss: 0.153232] [G loss: 0.521146]\n",
      "[Epoch 26/200] [Batch 5/637] [D loss: 0.177016] [G loss: 0.487548]\n",
      "[Epoch 26/200] [Batch 6/637] [D loss: 0.161359] [G loss: 0.560043]\n",
      "[Epoch 26/200] [Batch 7/637] [D loss: 0.172990] [G loss: 0.530229]\n",
      "[Epoch 26/200] [Batch 8/637] [D loss: 0.180954] [G loss: 0.457439]\n",
      "[Epoch 26/200] [Batch 9/637] [D loss: 0.165107] [G loss: 0.492359]\n",
      "[Epoch 26/200] [Batch 10/637] [D loss: 0.163822] [G loss: 0.506965]\n",
      "[Epoch 26/200] [Batch 11/637] [D loss: 0.167477] [G loss: 0.487595]\n",
      "[Epoch 26/200] [Batch 12/637] [D loss: 0.193606] [G loss: 0.554025]\n",
      "[Epoch 26/200] [Batch 13/637] [D loss: 0.182026] [G loss: 0.421136]\n",
      "[Epoch 26/200] [Batch 14/637] [D loss: 0.179483] [G loss: 0.379570]\n",
      "[Epoch 26/200] [Batch 15/637] [D loss: 0.174390] [G loss: 0.520018]\n",
      "[Epoch 26/200] [Batch 16/637] [D loss: 0.177448] [G loss: 0.478004]\n",
      "[Epoch 26/200] [Batch 17/637] [D loss: 0.173026] [G loss: 0.474429]\n",
      "[Epoch 26/200] [Batch 18/637] [D loss: 0.165108] [G loss: 0.597405]\n",
      "[Epoch 26/200] [Batch 19/637] [D loss: 0.165644] [G loss: 0.522071]\n",
      "[Epoch 26/200] [Batch 20/637] [D loss: 0.157094] [G loss: 0.501162]\n",
      "[Epoch 26/200] [Batch 21/637] [D loss: 0.174421] [G loss: 0.499135]\n",
      "[Epoch 26/200] [Batch 22/637] [D loss: 0.206599] [G loss: 0.416150]\n",
      "[Epoch 26/200] [Batch 23/637] [D loss: 0.187143] [G loss: 0.625389]\n",
      "[Epoch 26/200] [Batch 24/637] [D loss: 0.169410] [G loss: 0.530507]\n",
      "[Epoch 26/200] [Batch 25/637] [D loss: 0.171845] [G loss: 0.419012]\n",
      "[Epoch 26/200] [Batch 26/637] [D loss: 0.148750] [G loss: 0.486196]\n",
      "[Epoch 26/200] [Batch 27/637] [D loss: 0.150747] [G loss: 0.508024]\n",
      "[Epoch 26/200] [Batch 28/637] [D loss: 0.159607] [G loss: 0.501801]\n",
      "[Epoch 26/200] [Batch 29/637] [D loss: 0.157352] [G loss: 0.540733]\n",
      "[Epoch 26/200] [Batch 30/637] [D loss: 0.148312] [G loss: 0.499236]\n",
      "[Epoch 26/200] [Batch 31/637] [D loss: 0.153388] [G loss: 0.479308]\n",
      "[Epoch 26/200] [Batch 32/637] [D loss: 0.143096] [G loss: 0.545420]\n",
      "[Epoch 26/200] [Batch 33/637] [D loss: 0.149242] [G loss: 0.570850]\n",
      "[Epoch 26/200] [Batch 34/637] [D loss: 0.189664] [G loss: 0.442157]\n",
      "[Epoch 26/200] [Batch 35/637] [D loss: 0.159043] [G loss: 0.669337]\n",
      "[Epoch 26/200] [Batch 36/637] [D loss: 0.154651] [G loss: 0.580782]\n",
      "[Epoch 26/200] [Batch 37/637] [D loss: 0.175815] [G loss: 0.429815]\n",
      "[Epoch 26/200] [Batch 38/637] [D loss: 0.193306] [G loss: 0.397537]\n",
      "[Epoch 26/200] [Batch 39/637] [D loss: 0.172655] [G loss: 0.535218]\n",
      "[Epoch 26/200] [Batch 40/637] [D loss: 0.175314] [G loss: 0.607539]\n",
      "[Epoch 26/200] [Batch 41/637] [D loss: 0.172996] [G loss: 0.561114]\n",
      "[Epoch 26/200] [Batch 42/637] [D loss: 0.163672] [G loss: 0.481304]\n",
      "[Epoch 26/200] [Batch 43/637] [D loss: 0.150823] [G loss: 0.453753]\n",
      "[Epoch 26/200] [Batch 44/637] [D loss: 0.158197] [G loss: 0.500347]\n",
      "[Epoch 26/200] [Batch 45/637] [D loss: 0.142773] [G loss: 0.510236]\n",
      "[Epoch 26/200] [Batch 46/637] [D loss: 0.155058] [G loss: 0.428550]\n",
      "[Epoch 26/200] [Batch 47/637] [D loss: 0.145495] [G loss: 0.463579]\n",
      "[Epoch 26/200] [Batch 48/637] [D loss: 0.149787] [G loss: 0.539551]\n",
      "[Epoch 26/200] [Batch 49/637] [D loss: 0.167372] [G loss: 0.514329]\n",
      "[Epoch 26/200] [Batch 50/637] [D loss: 0.154139] [G loss: 0.523859]\n",
      "[Epoch 26/200] [Batch 51/637] [D loss: 0.170006] [G loss: 0.486800]\n",
      "[Epoch 26/200] [Batch 52/637] [D loss: 0.151999] [G loss: 0.483801]\n",
      "[Epoch 26/200] [Batch 53/637] [D loss: 0.157760] [G loss: 0.527261]\n",
      "[Epoch 26/200] [Batch 54/637] [D loss: 0.161661] [G loss: 0.578787]\n",
      "[Epoch 26/200] [Batch 55/637] [D loss: 0.163012] [G loss: 0.448491]\n",
      "[Epoch 26/200] [Batch 56/637] [D loss: 0.172637] [G loss: 0.500518]\n",
      "[Epoch 26/200] [Batch 57/637] [D loss: 0.155827] [G loss: 0.569708]\n",
      "[Epoch 26/200] [Batch 58/637] [D loss: 0.152002] [G loss: 0.447229]\n",
      "[Epoch 26/200] [Batch 59/637] [D loss: 0.158257] [G loss: 0.445620]\n",
      "[Epoch 26/200] [Batch 60/637] [D loss: 0.151331] [G loss: 0.488689]\n",
      "[Epoch 26/200] [Batch 61/637] [D loss: 0.180433] [G loss: 0.579557]\n",
      "[Epoch 26/200] [Batch 62/637] [D loss: 0.140078] [G loss: 0.536831]\n",
      "[Epoch 26/200] [Batch 63/637] [D loss: 0.136623] [G loss: 0.492372]\n",
      "[Epoch 26/200] [Batch 64/637] [D loss: 0.147759] [G loss: 0.484261]\n",
      "[Epoch 26/200] [Batch 65/637] [D loss: 0.185148] [G loss: 0.408986]\n",
      "[Epoch 26/200] [Batch 66/637] [D loss: 0.181517] [G loss: 0.576863]\n",
      "[Epoch 26/200] [Batch 67/637] [D loss: 0.146463] [G loss: 0.539514]\n",
      "[Epoch 26/200] [Batch 68/637] [D loss: 0.167738] [G loss: 0.547216]\n",
      "[Epoch 26/200] [Batch 69/637] [D loss: 0.156065] [G loss: 0.496585]\n",
      "[Epoch 26/200] [Batch 70/637] [D loss: 0.175732] [G loss: 0.452296]\n",
      "[Epoch 26/200] [Batch 71/637] [D loss: 0.169757] [G loss: 0.496727]\n",
      "[Epoch 26/200] [Batch 72/637] [D loss: 0.163037] [G loss: 0.512871]\n",
      "[Epoch 26/200] [Batch 73/637] [D loss: 0.178679] [G loss: 0.474783]\n",
      "[Epoch 26/200] [Batch 74/637] [D loss: 0.197233] [G loss: 0.479295]\n",
      "[Epoch 26/200] [Batch 75/637] [D loss: 0.210073] [G loss: 0.408136]\n",
      "[Epoch 26/200] [Batch 76/637] [D loss: 0.162263] [G loss: 0.556399]\n",
      "[Epoch 26/200] [Batch 77/637] [D loss: 0.170712] [G loss: 0.557408]\n",
      "[Epoch 26/200] [Batch 78/637] [D loss: 0.164741] [G loss: 0.464189]\n",
      "[Epoch 26/200] [Batch 79/637] [D loss: 0.146775] [G loss: 0.507662]\n",
      "[Epoch 26/200] [Batch 80/637] [D loss: 0.150966] [G loss: 0.521619]\n",
      "[Epoch 26/200] [Batch 81/637] [D loss: 0.147329] [G loss: 0.569287]\n",
      "[Epoch 26/200] [Batch 82/637] [D loss: 0.140616] [G loss: 0.565654]\n",
      "[Epoch 26/200] [Batch 83/637] [D loss: 0.136688] [G loss: 0.575858]\n",
      "[Epoch 26/200] [Batch 84/637] [D loss: 0.144935] [G loss: 0.512648]\n",
      "[Epoch 26/200] [Batch 85/637] [D loss: 0.134869] [G loss: 0.563904]\n",
      "[Epoch 26/200] [Batch 86/637] [D loss: 0.133475] [G loss: 0.527920]\n",
      "[Epoch 26/200] [Batch 87/637] [D loss: 0.154765] [G loss: 0.554479]\n",
      "[Epoch 26/200] [Batch 88/637] [D loss: 0.137754] [G loss: 0.587111]\n",
      "[Epoch 26/200] [Batch 89/637] [D loss: 0.162219] [G loss: 0.528794]\n",
      "[Epoch 26/200] [Batch 90/637] [D loss: 0.155726] [G loss: 0.531388]\n",
      "[Epoch 26/200] [Batch 91/637] [D loss: 0.135516] [G loss: 0.536014]\n",
      "[Epoch 26/200] [Batch 92/637] [D loss: 0.155883] [G loss: 0.552671]\n",
      "[Epoch 26/200] [Batch 93/637] [D loss: 0.197047] [G loss: 0.480652]\n",
      "[Epoch 26/200] [Batch 94/637] [D loss: 0.167918] [G loss: 0.515910]\n",
      "[Epoch 26/200] [Batch 95/637] [D loss: 0.184982] [G loss: 0.489380]\n",
      "[Epoch 26/200] [Batch 96/637] [D loss: 0.173633] [G loss: 0.546684]\n",
      "[Epoch 26/200] [Batch 97/637] [D loss: 0.168779] [G loss: 0.483989]\n",
      "[Epoch 26/200] [Batch 98/637] [D loss: 0.148415] [G loss: 0.479389]\n",
      "[Epoch 26/200] [Batch 99/637] [D loss: 0.176293] [G loss: 0.422972]\n",
      "[Epoch 26/200] [Batch 100/637] [D loss: 0.158537] [G loss: 0.509476]\n",
      "[Epoch 26/200] [Batch 101/637] [D loss: 0.157737] [G loss: 0.600909]\n",
      "[Epoch 26/200] [Batch 102/637] [D loss: 0.163565] [G loss: 0.559623]\n",
      "[Epoch 26/200] [Batch 103/637] [D loss: 0.169409] [G loss: 0.479794]\n",
      "[Epoch 26/200] [Batch 104/637] [D loss: 0.204273] [G loss: 0.450441]\n",
      "[Epoch 26/200] [Batch 105/637] [D loss: 0.171937] [G loss: 0.515171]\n",
      "[Epoch 26/200] [Batch 106/637] [D loss: 0.186295] [G loss: 0.484499]\n",
      "[Epoch 26/200] [Batch 107/637] [D loss: 0.178082] [G loss: 0.589909]\n",
      "[Epoch 26/200] [Batch 108/637] [D loss: 0.168704] [G loss: 0.503264]\n",
      "[Epoch 26/200] [Batch 109/637] [D loss: 0.171361] [G loss: 0.433283]\n",
      "[Epoch 26/200] [Batch 110/637] [D loss: 0.162080] [G loss: 0.432088]\n",
      "[Epoch 26/200] [Batch 111/637] [D loss: 0.164625] [G loss: 0.449342]\n",
      "[Epoch 26/200] [Batch 112/637] [D loss: 0.155215] [G loss: 0.541805]\n",
      "[Epoch 26/200] [Batch 113/637] [D loss: 0.160209] [G loss: 0.586490]\n",
      "[Epoch 26/200] [Batch 114/637] [D loss: 0.143964] [G loss: 0.522551]\n",
      "[Epoch 26/200] [Batch 115/637] [D loss: 0.149164] [G loss: 0.535170]\n",
      "[Epoch 26/200] [Batch 116/637] [D loss: 0.146993] [G loss: 0.489913]\n",
      "[Epoch 26/200] [Batch 117/637] [D loss: 0.163612] [G loss: 0.476699]\n",
      "[Epoch 26/200] [Batch 118/637] [D loss: 0.178093] [G loss: 0.423094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/200] [Batch 119/637] [D loss: 0.194226] [G loss: 0.507048]\n",
      "[Epoch 26/200] [Batch 120/637] [D loss: 0.187624] [G loss: 0.499826]\n",
      "[Epoch 26/200] [Batch 121/637] [D loss: 0.158297] [G loss: 0.510426]\n",
      "[Epoch 26/200] [Batch 122/637] [D loss: 0.179062] [G loss: 0.427797]\n",
      "[Epoch 26/200] [Batch 123/637] [D loss: 0.157603] [G loss: 0.497418]\n",
      "[Epoch 26/200] [Batch 124/637] [D loss: 0.172194] [G loss: 0.449632]\n",
      "[Epoch 26/200] [Batch 125/637] [D loss: 0.171390] [G loss: 0.457520]\n",
      "[Epoch 26/200] [Batch 126/637] [D loss: 0.189427] [G loss: 0.464626]\n",
      "[Epoch 26/200] [Batch 127/637] [D loss: 0.182779] [G loss: 0.548074]\n",
      "[Epoch 26/200] [Batch 128/637] [D loss: 0.160805] [G loss: 0.541149]\n",
      "[Epoch 26/200] [Batch 129/637] [D loss: 0.204080] [G loss: 0.468311]\n",
      "[Epoch 26/200] [Batch 130/637] [D loss: 0.168524] [G loss: 0.499030]\n",
      "[Epoch 26/200] [Batch 131/637] [D loss: 0.164981] [G loss: 0.513710]\n",
      "[Epoch 26/200] [Batch 132/637] [D loss: 0.174811] [G loss: 0.476949]\n",
      "[Epoch 26/200] [Batch 133/637] [D loss: 0.173430] [G loss: 0.434860]\n",
      "[Epoch 26/200] [Batch 134/637] [D loss: 0.149461] [G loss: 0.527957]\n",
      "[Epoch 26/200] [Batch 135/637] [D loss: 0.153657] [G loss: 0.562710]\n",
      "[Epoch 26/200] [Batch 136/637] [D loss: 0.173425] [G loss: 0.444059]\n",
      "[Epoch 26/200] [Batch 137/637] [D loss: 0.144394] [G loss: 0.548967]\n",
      "[Epoch 26/200] [Batch 138/637] [D loss: 0.138520] [G loss: 0.479384]\n",
      "[Epoch 26/200] [Batch 139/637] [D loss: 0.157186] [G loss: 0.443438]\n",
      "[Epoch 26/200] [Batch 140/637] [D loss: 0.185084] [G loss: 0.512497]\n",
      "[Epoch 26/200] [Batch 141/637] [D loss: 0.164229] [G loss: 0.535741]\n",
      "[Epoch 26/200] [Batch 142/637] [D loss: 0.150457] [G loss: 0.594280]\n",
      "[Epoch 26/200] [Batch 143/637] [D loss: 0.164281] [G loss: 0.490243]\n",
      "[Epoch 26/200] [Batch 144/637] [D loss: 0.158068] [G loss: 0.473313]\n",
      "[Epoch 26/200] [Batch 145/637] [D loss: 0.165536] [G loss: 0.468031]\n",
      "[Epoch 26/200] [Batch 146/637] [D loss: 0.152637] [G loss: 0.509637]\n",
      "[Epoch 26/200] [Batch 147/637] [D loss: 0.167590] [G loss: 0.462849]\n",
      "[Epoch 26/200] [Batch 148/637] [D loss: 0.202267] [G loss: 0.394327]\n",
      "[Epoch 26/200] [Batch 149/637] [D loss: 0.160859] [G loss: 0.594234]\n",
      "[Epoch 26/200] [Batch 150/637] [D loss: 0.185978] [G loss: 0.570206]\n",
      "[Epoch 26/200] [Batch 151/637] [D loss: 0.159524] [G loss: 0.486947]\n",
      "[Epoch 26/200] [Batch 152/637] [D loss: 0.159940] [G loss: 0.495708]\n",
      "[Epoch 26/200] [Batch 153/637] [D loss: 0.162132] [G loss: 0.461853]\n",
      "[Epoch 26/200] [Batch 154/637] [D loss: 0.132932] [G loss: 0.546440]\n",
      "[Epoch 26/200] [Batch 155/637] [D loss: 0.223380] [G loss: 0.465886]\n",
      "[Epoch 26/200] [Batch 156/637] [D loss: 0.178432] [G loss: 0.645026]\n",
      "[Epoch 26/200] [Batch 157/637] [D loss: 0.180770] [G loss: 0.605108]\n",
      "[Epoch 26/200] [Batch 158/637] [D loss: 0.229166] [G loss: 0.417561]\n",
      "[Epoch 26/200] [Batch 159/637] [D loss: 0.164287] [G loss: 0.642458]\n",
      "[Epoch 26/200] [Batch 160/637] [D loss: 0.163666] [G loss: 0.591500]\n",
      "[Epoch 26/200] [Batch 161/637] [D loss: 0.175353] [G loss: 0.484580]\n",
      "[Epoch 26/200] [Batch 162/637] [D loss: 0.177925] [G loss: 0.407245]\n",
      "[Epoch 26/200] [Batch 163/637] [D loss: 0.162392] [G loss: 0.528810]\n",
      "[Epoch 26/200] [Batch 164/637] [D loss: 0.154696] [G loss: 0.493497]\n",
      "[Epoch 26/200] [Batch 165/637] [D loss: 0.154237] [G loss: 0.455477]\n",
      "[Epoch 26/200] [Batch 166/637] [D loss: 0.178619] [G loss: 0.504904]\n",
      "[Epoch 26/200] [Batch 167/637] [D loss: 0.161564] [G loss: 0.473523]\n",
      "[Epoch 26/200] [Batch 168/637] [D loss: 0.178208] [G loss: 0.433051]\n",
      "[Epoch 26/200] [Batch 169/637] [D loss: 0.160196] [G loss: 0.623657]\n",
      "[Epoch 26/200] [Batch 170/637] [D loss: 0.164585] [G loss: 0.578266]\n",
      "[Epoch 26/200] [Batch 171/637] [D loss: 0.155650] [G loss: 0.507431]\n",
      "[Epoch 26/200] [Batch 172/637] [D loss: 0.157506] [G loss: 0.442818]\n",
      "[Epoch 26/200] [Batch 173/637] [D loss: 0.169247] [G loss: 0.499506]\n",
      "[Epoch 26/200] [Batch 174/637] [D loss: 0.156206] [G loss: 0.452719]\n",
      "[Epoch 26/200] [Batch 175/637] [D loss: 0.172517] [G loss: 0.438862]\n",
      "[Epoch 26/200] [Batch 176/637] [D loss: 0.156519] [G loss: 0.525921]\n",
      "[Epoch 26/200] [Batch 177/637] [D loss: 0.155588] [G loss: 0.524931]\n",
      "[Epoch 26/200] [Batch 178/637] [D loss: 0.177474] [G loss: 0.500365]\n",
      "[Epoch 26/200] [Batch 179/637] [D loss: 0.139280] [G loss: 0.506050]\n",
      "[Epoch 26/200] [Batch 180/637] [D loss: 0.156943] [G loss: 0.567027]\n",
      "[Epoch 26/200] [Batch 181/637] [D loss: 0.163261] [G loss: 0.548852]\n",
      "[Epoch 26/200] [Batch 182/637] [D loss: 0.149746] [G loss: 0.572784]\n",
      "[Epoch 26/200] [Batch 183/637] [D loss: 0.154828] [G loss: 0.472063]\n",
      "[Epoch 26/200] [Batch 184/637] [D loss: 0.161044] [G loss: 0.472046]\n",
      "[Epoch 26/200] [Batch 185/637] [D loss: 0.150270] [G loss: 0.550073]\n",
      "[Epoch 26/200] [Batch 186/637] [D loss: 0.178939] [G loss: 0.497858]\n",
      "[Epoch 26/200] [Batch 187/637] [D loss: 0.169113] [G loss: 0.487316]\n",
      "[Epoch 26/200] [Batch 188/637] [D loss: 0.168573] [G loss: 0.561755]\n",
      "[Epoch 26/200] [Batch 189/637] [D loss: 0.161197] [G loss: 0.489690]\n",
      "[Epoch 26/200] [Batch 190/637] [D loss: 0.161963] [G loss: 0.497623]\n",
      "[Epoch 26/200] [Batch 191/637] [D loss: 0.181622] [G loss: 0.404199]\n",
      "[Epoch 26/200] [Batch 192/637] [D loss: 0.187694] [G loss: 0.509941]\n",
      "[Epoch 26/200] [Batch 193/637] [D loss: 0.174989] [G loss: 0.566253]\n",
      "[Epoch 26/200] [Batch 194/637] [D loss: 0.167345] [G loss: 0.526880]\n",
      "[Epoch 26/200] [Batch 195/637] [D loss: 0.199915] [G loss: 0.459412]\n",
      "[Epoch 26/200] [Batch 196/637] [D loss: 0.172125] [G loss: 0.469614]\n",
      "[Epoch 26/200] [Batch 197/637] [D loss: 0.171595] [G loss: 0.465593]\n",
      "[Epoch 26/200] [Batch 198/637] [D loss: 0.163055] [G loss: 0.454390]\n",
      "[Epoch 26/200] [Batch 199/637] [D loss: 0.166539] [G loss: 0.465823]\n",
      "[Epoch 26/200] [Batch 200/637] [D loss: 0.170648] [G loss: 0.564963]\n",
      "[Epoch 26/200] [Batch 201/637] [D loss: 0.146850] [G loss: 0.523609]\n",
      "[Epoch 26/200] [Batch 202/637] [D loss: 0.159257] [G loss: 0.497203]\n",
      "[Epoch 26/200] [Batch 203/637] [D loss: 0.153593] [G loss: 0.480272]\n",
      "[Epoch 26/200] [Batch 204/637] [D loss: 0.152347] [G loss: 0.624312]\n",
      "[Epoch 26/200] [Batch 205/637] [D loss: 0.168765] [G loss: 0.513954]\n",
      "[Epoch 26/200] [Batch 206/637] [D loss: 0.178750] [G loss: 0.473567]\n",
      "[Epoch 26/200] [Batch 207/637] [D loss: 0.188118] [G loss: 0.379190]\n",
      "[Epoch 26/200] [Batch 208/637] [D loss: 0.152275] [G loss: 0.427922]\n",
      "[Epoch 26/200] [Batch 209/637] [D loss: 0.162831] [G loss: 0.585513]\n",
      "[Epoch 26/200] [Batch 210/637] [D loss: 0.163596] [G loss: 0.576481]\n",
      "[Epoch 26/200] [Batch 211/637] [D loss: 0.210815] [G loss: 0.450282]\n",
      "[Epoch 26/200] [Batch 212/637] [D loss: 0.173219] [G loss: 0.447786]\n",
      "[Epoch 26/200] [Batch 213/637] [D loss: 0.161930] [G loss: 0.521352]\n",
      "[Epoch 26/200] [Batch 214/637] [D loss: 0.163503] [G loss: 0.588312]\n",
      "[Epoch 26/200] [Batch 215/637] [D loss: 0.157238] [G loss: 0.586185]\n",
      "[Epoch 26/200] [Batch 216/637] [D loss: 0.146937] [G loss: 0.491524]\n",
      "[Epoch 26/200] [Batch 217/637] [D loss: 0.187725] [G loss: 0.407408]\n",
      "[Epoch 26/200] [Batch 218/637] [D loss: 0.164565] [G loss: 0.483698]\n",
      "[Epoch 26/200] [Batch 219/637] [D loss: 0.167661] [G loss: 0.495486]\n",
      "[Epoch 26/200] [Batch 220/637] [D loss: 0.168287] [G loss: 0.510877]\n",
      "[Epoch 26/200] [Batch 221/637] [D loss: 0.171690] [G loss: 0.468401]\n",
      "[Epoch 26/200] [Batch 222/637] [D loss: 0.181175] [G loss: 0.492053]\n",
      "[Epoch 26/200] [Batch 223/637] [D loss: 0.165495] [G loss: 0.546743]\n",
      "[Epoch 26/200] [Batch 224/637] [D loss: 0.195632] [G loss: 0.483895]\n",
      "[Epoch 26/200] [Batch 225/637] [D loss: 0.147423] [G loss: 0.522685]\n",
      "[Epoch 26/200] [Batch 226/637] [D loss: 0.184923] [G loss: 0.420828]\n",
      "[Epoch 26/200] [Batch 227/637] [D loss: 0.182435] [G loss: 0.498783]\n",
      "[Epoch 26/200] [Batch 228/637] [D loss: 0.228292] [G loss: 0.594990]\n",
      "[Epoch 26/200] [Batch 229/637] [D loss: 0.168824] [G loss: 0.551733]\n",
      "[Epoch 26/200] [Batch 230/637] [D loss: 0.177089] [G loss: 0.463173]\n",
      "[Epoch 26/200] [Batch 231/637] [D loss: 0.184129] [G loss: 0.425657]\n",
      "[Epoch 26/200] [Batch 232/637] [D loss: 0.174465] [G loss: 0.530106]\n",
      "[Epoch 26/200] [Batch 233/637] [D loss: 0.157670] [G loss: 0.631910]\n",
      "[Epoch 26/200] [Batch 234/637] [D loss: 0.161182] [G loss: 0.530131]\n",
      "[Epoch 26/200] [Batch 235/637] [D loss: 0.163097] [G loss: 0.532015]\n",
      "[Epoch 26/200] [Batch 236/637] [D loss: 0.179230] [G loss: 0.465856]\n",
      "[Epoch 26/200] [Batch 237/637] [D loss: 0.155836] [G loss: 0.536699]\n",
      "[Epoch 26/200] [Batch 238/637] [D loss: 0.161829] [G loss: 0.472318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/200] [Batch 239/637] [D loss: 0.164588] [G loss: 0.435314]\n",
      "[Epoch 26/200] [Batch 240/637] [D loss: 0.188474] [G loss: 0.503903]\n",
      "[Epoch 26/200] [Batch 241/637] [D loss: 0.167850] [G loss: 0.470251]\n",
      "[Epoch 26/200] [Batch 242/637] [D loss: 0.154727] [G loss: 0.530796]\n",
      "[Epoch 26/200] [Batch 243/637] [D loss: 0.168746] [G loss: 0.483713]\n",
      "[Epoch 26/200] [Batch 244/637] [D loss: 0.185350] [G loss: 0.425485]\n",
      "[Epoch 26/200] [Batch 245/637] [D loss: 0.182890] [G loss: 0.462893]\n",
      "[Epoch 26/200] [Batch 246/637] [D loss: 0.159880] [G loss: 0.501483]\n",
      "[Epoch 26/200] [Batch 247/637] [D loss: 0.181338] [G loss: 0.510528]\n",
      "[Epoch 26/200] [Batch 248/637] [D loss: 0.189367] [G loss: 0.482420]\n",
      "[Epoch 26/200] [Batch 249/637] [D loss: 0.155318] [G loss: 0.517496]\n",
      "[Epoch 26/200] [Batch 250/637] [D loss: 0.179067] [G loss: 0.490665]\n",
      "[Epoch 26/200] [Batch 251/637] [D loss: 0.181346] [G loss: 0.460649]\n",
      "[Epoch 26/200] [Batch 252/637] [D loss: 0.143506] [G loss: 0.524935]\n",
      "[Epoch 26/200] [Batch 253/637] [D loss: 0.162953] [G loss: 0.462635]\n",
      "[Epoch 26/200] [Batch 254/637] [D loss: 0.168213] [G loss: 0.476192]\n",
      "[Epoch 26/200] [Batch 255/637] [D loss: 0.157277] [G loss: 0.468933]\n",
      "[Epoch 26/200] [Batch 256/637] [D loss: 0.174907] [G loss: 0.472584]\n",
      "[Epoch 26/200] [Batch 257/637] [D loss: 0.158820] [G loss: 0.472208]\n",
      "[Epoch 26/200] [Batch 258/637] [D loss: 0.152965] [G loss: 0.578327]\n",
      "[Epoch 26/200] [Batch 259/637] [D loss: 0.171056] [G loss: 0.454486]\n",
      "[Epoch 26/200] [Batch 260/637] [D loss: 0.149485] [G loss: 0.497829]\n",
      "[Epoch 26/200] [Batch 261/637] [D loss: 0.154884] [G loss: 0.464275]\n",
      "[Epoch 26/200] [Batch 262/637] [D loss: 0.158586] [G loss: 0.490074]\n",
      "[Epoch 26/200] [Batch 263/637] [D loss: 0.153217] [G loss: 0.628134]\n",
      "[Epoch 26/200] [Batch 264/637] [D loss: 0.200175] [G loss: 0.476914]\n",
      "[Epoch 26/200] [Batch 265/637] [D loss: 0.192920] [G loss: 0.446986]\n",
      "[Epoch 26/200] [Batch 266/637] [D loss: 0.185251] [G loss: 0.469592]\n",
      "[Epoch 26/200] [Batch 267/637] [D loss: 0.170482] [G loss: 0.469218]\n",
      "[Epoch 26/200] [Batch 268/637] [D loss: 0.187260] [G loss: 0.453529]\n",
      "[Epoch 26/200] [Batch 269/637] [D loss: 0.163970] [G loss: 0.455378]\n",
      "[Epoch 26/200] [Batch 270/637] [D loss: 0.177739] [G loss: 0.452278]\n",
      "[Epoch 26/200] [Batch 271/637] [D loss: 0.177673] [G loss: 0.488273]\n",
      "[Epoch 26/200] [Batch 272/637] [D loss: 0.168343] [G loss: 0.506275]\n",
      "[Epoch 26/200] [Batch 273/637] [D loss: 0.185204] [G loss: 0.441932]\n",
      "[Epoch 26/200] [Batch 274/637] [D loss: 0.165055] [G loss: 0.538559]\n",
      "[Epoch 26/200] [Batch 275/637] [D loss: 0.194360] [G loss: 0.541966]\n",
      "[Epoch 26/200] [Batch 276/637] [D loss: 0.174869] [G loss: 0.427095]\n",
      "[Epoch 26/200] [Batch 277/637] [D loss: 0.191388] [G loss: 0.413140]\n",
      "[Epoch 26/200] [Batch 278/637] [D loss: 0.167052] [G loss: 0.450422]\n",
      "[Epoch 26/200] [Batch 279/637] [D loss: 0.176428] [G loss: 0.453979]\n",
      "[Epoch 26/200] [Batch 280/637] [D loss: 0.156721] [G loss: 0.519422]\n",
      "[Epoch 26/200] [Batch 281/637] [D loss: 0.167351] [G loss: 0.502052]\n",
      "[Epoch 26/200] [Batch 282/637] [D loss: 0.158585] [G loss: 0.522852]\n",
      "[Epoch 26/200] [Batch 283/637] [D loss: 0.149218] [G loss: 0.500008]\n",
      "[Epoch 26/200] [Batch 284/637] [D loss: 0.182802] [G loss: 0.434528]\n",
      "[Epoch 26/200] [Batch 285/637] [D loss: 0.177815] [G loss: 0.440902]\n",
      "[Epoch 26/200] [Batch 286/637] [D loss: 0.161793] [G loss: 0.509031]\n",
      "[Epoch 26/200] [Batch 287/637] [D loss: 0.166231] [G loss: 0.604168]\n",
      "[Epoch 26/200] [Batch 288/637] [D loss: 0.165361] [G loss: 0.525367]\n",
      "[Epoch 26/200] [Batch 289/637] [D loss: 0.175125] [G loss: 0.502623]\n",
      "[Epoch 26/200] [Batch 290/637] [D loss: 0.161511] [G loss: 0.506209]\n",
      "[Epoch 26/200] [Batch 291/637] [D loss: 0.153755] [G loss: 0.470380]\n",
      "[Epoch 26/200] [Batch 292/637] [D loss: 0.189093] [G loss: 0.464114]\n",
      "[Epoch 26/200] [Batch 293/637] [D loss: 0.177921] [G loss: 0.439117]\n",
      "[Epoch 26/200] [Batch 294/637] [D loss: 0.215861] [G loss: 0.410128]\n",
      "[Epoch 26/200] [Batch 295/637] [D loss: 0.181043] [G loss: 0.602598]\n",
      "[Epoch 26/200] [Batch 296/637] [D loss: 0.171809] [G loss: 0.521392]\n",
      "[Epoch 26/200] [Batch 297/637] [D loss: 0.167427] [G loss: 0.467479]\n",
      "[Epoch 26/200] [Batch 298/637] [D loss: 0.159652] [G loss: 0.431113]\n",
      "[Epoch 26/200] [Batch 299/637] [D loss: 0.160862] [G loss: 0.437649]\n",
      "[Epoch 26/200] [Batch 300/637] [D loss: 0.157054] [G loss: 0.462582]\n",
      "[Epoch 26/200] [Batch 301/637] [D loss: 0.186195] [G loss: 0.423621]\n",
      "[Epoch 26/200] [Batch 302/637] [D loss: 0.165856] [G loss: 0.464998]\n",
      "[Epoch 26/200] [Batch 303/637] [D loss: 0.156425] [G loss: 0.464090]\n",
      "[Epoch 26/200] [Batch 304/637] [D loss: 0.164638] [G loss: 0.555214]\n",
      "[Epoch 26/200] [Batch 305/637] [D loss: 0.163274] [G loss: 0.491777]\n",
      "[Epoch 26/200] [Batch 306/637] [D loss: 0.183041] [G loss: 0.435174]\n",
      "[Epoch 26/200] [Batch 307/637] [D loss: 0.188378] [G loss: 0.481655]\n",
      "[Epoch 26/200] [Batch 308/637] [D loss: 0.182708] [G loss: 0.515283]\n",
      "[Epoch 26/200] [Batch 309/637] [D loss: 0.165525] [G loss: 0.436097]\n",
      "[Epoch 26/200] [Batch 310/637] [D loss: 0.201886] [G loss: 0.415605]\n",
      "[Epoch 26/200] [Batch 311/637] [D loss: 0.170595] [G loss: 0.467993]\n",
      "[Epoch 26/200] [Batch 312/637] [D loss: 0.204352] [G loss: 0.519836]\n",
      "[Epoch 26/200] [Batch 313/637] [D loss: 0.195664] [G loss: 0.525935]\n",
      "[Epoch 26/200] [Batch 314/637] [D loss: 0.188887] [G loss: 0.499910]\n",
      "[Epoch 26/200] [Batch 315/637] [D loss: 0.167705] [G loss: 0.471637]\n",
      "[Epoch 26/200] [Batch 316/637] [D loss: 0.169604] [G loss: 0.416225]\n",
      "[Epoch 26/200] [Batch 317/637] [D loss: 0.156616] [G loss: 0.522596]\n",
      "[Epoch 26/200] [Batch 318/637] [D loss: 0.149327] [G loss: 0.545061]\n",
      "[Epoch 26/200] [Batch 319/637] [D loss: 0.175399] [G loss: 0.502538]\n",
      "[Epoch 26/200] [Batch 320/637] [D loss: 0.180022] [G loss: 0.442339]\n",
      "[Epoch 26/200] [Batch 321/637] [D loss: 0.170812] [G loss: 0.450298]\n",
      "[Epoch 26/200] [Batch 322/637] [D loss: 0.154086] [G loss: 0.570927]\n",
      "[Epoch 26/200] [Batch 323/637] [D loss: 0.161047] [G loss: 0.564248]\n",
      "[Epoch 26/200] [Batch 324/637] [D loss: 0.162438] [G loss: 0.544156]\n",
      "[Epoch 26/200] [Batch 325/637] [D loss: 0.147100] [G loss: 0.524074]\n",
      "[Epoch 26/200] [Batch 326/637] [D loss: 0.192558] [G loss: 0.500735]\n",
      "[Epoch 26/200] [Batch 327/637] [D loss: 0.240183] [G loss: 0.467397]\n",
      "[Epoch 26/200] [Batch 328/637] [D loss: 0.205401] [G loss: 0.444624]\n",
      "[Epoch 26/200] [Batch 329/637] [D loss: 0.184557] [G loss: 0.528580]\n",
      "[Epoch 26/200] [Batch 330/637] [D loss: 0.190237] [G loss: 0.455483]\n",
      "[Epoch 26/200] [Batch 331/637] [D loss: 0.172982] [G loss: 0.464573]\n",
      "[Epoch 26/200] [Batch 332/637] [D loss: 0.165433] [G loss: 0.466818]\n",
      "[Epoch 26/200] [Batch 333/637] [D loss: 0.170029] [G loss: 0.472452]\n",
      "[Epoch 26/200] [Batch 334/637] [D loss: 0.178047] [G loss: 0.499126]\n",
      "[Epoch 26/200] [Batch 335/637] [D loss: 0.161050] [G loss: 0.562846]\n",
      "[Epoch 26/200] [Batch 336/637] [D loss: 0.183565] [G loss: 0.491520]\n",
      "[Epoch 26/200] [Batch 337/637] [D loss: 0.152420] [G loss: 0.546890]\n",
      "[Epoch 26/200] [Batch 338/637] [D loss: 0.152914] [G loss: 0.512848]\n",
      "[Epoch 26/200] [Batch 339/637] [D loss: 0.166678] [G loss: 0.461978]\n",
      "[Epoch 26/200] [Batch 340/637] [D loss: 0.171247] [G loss: 0.504826]\n",
      "[Epoch 26/200] [Batch 341/637] [D loss: 0.184802] [G loss: 0.500357]\n",
      "[Epoch 26/200] [Batch 342/637] [D loss: 0.162583] [G loss: 0.496689]\n",
      "[Epoch 26/200] [Batch 343/637] [D loss: 0.164944] [G loss: 0.459469]\n",
      "[Epoch 26/200] [Batch 344/637] [D loss: 0.168831] [G loss: 0.475439]\n",
      "[Epoch 26/200] [Batch 345/637] [D loss: 0.184593] [G loss: 0.539786]\n",
      "[Epoch 26/200] [Batch 346/637] [D loss: 0.150436] [G loss: 0.518358]\n",
      "[Epoch 26/200] [Batch 347/637] [D loss: 0.176857] [G loss: 0.545223]\n",
      "[Epoch 26/200] [Batch 348/637] [D loss: 0.174445] [G loss: 0.560163]\n",
      "[Epoch 26/200] [Batch 349/637] [D loss: 0.162146] [G loss: 0.475353]\n",
      "[Epoch 26/200] [Batch 350/637] [D loss: 0.158903] [G loss: 0.493818]\n",
      "[Epoch 26/200] [Batch 351/637] [D loss: 0.170312] [G loss: 0.418144]\n",
      "[Epoch 26/200] [Batch 352/637] [D loss: 0.154960] [G loss: 0.507196]\n",
      "[Epoch 26/200] [Batch 353/637] [D loss: 0.167017] [G loss: 0.599406]\n",
      "[Epoch 26/200] [Batch 354/637] [D loss: 0.173632] [G loss: 0.565786]\n",
      "[Epoch 26/200] [Batch 355/637] [D loss: 0.175809] [G loss: 0.462010]\n",
      "[Epoch 26/200] [Batch 356/637] [D loss: 0.206969] [G loss: 0.414429]\n",
      "[Epoch 26/200] [Batch 357/637] [D loss: 0.215654] [G loss: 0.581944]\n",
      "[Epoch 26/200] [Batch 358/637] [D loss: 0.167020] [G loss: 0.603455]\n",
      "[Epoch 26/200] [Batch 359/637] [D loss: 0.177711] [G loss: 0.467348]\n",
      "[Epoch 26/200] [Batch 360/637] [D loss: 0.163573] [G loss: 0.435950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/200] [Batch 361/637] [D loss: 0.154753] [G loss: 0.461013]\n",
      "[Epoch 26/200] [Batch 362/637] [D loss: 0.162647] [G loss: 0.472169]\n",
      "[Epoch 26/200] [Batch 363/637] [D loss: 0.186484] [G loss: 0.469626]\n",
      "[Epoch 26/200] [Batch 364/637] [D loss: 0.174403] [G loss: 0.551084]\n",
      "[Epoch 26/200] [Batch 365/637] [D loss: 0.183913] [G loss: 0.459171]\n",
      "[Epoch 26/200] [Batch 366/637] [D loss: 0.167460] [G loss: 0.564552]\n",
      "[Epoch 26/200] [Batch 367/637] [D loss: 0.173035] [G loss: 0.424492]\n",
      "[Epoch 26/200] [Batch 368/637] [D loss: 0.155102] [G loss: 0.562789]\n",
      "[Epoch 26/200] [Batch 369/637] [D loss: 0.152864] [G loss: 0.592265]\n",
      "[Epoch 26/200] [Batch 370/637] [D loss: 0.162208] [G loss: 0.509007]\n",
      "[Epoch 26/200] [Batch 371/637] [D loss: 0.150510] [G loss: 0.531868]\n",
      "[Epoch 26/200] [Batch 372/637] [D loss: 0.174697] [G loss: 0.512434]\n",
      "[Epoch 26/200] [Batch 373/637] [D loss: 0.153084] [G loss: 0.564559]\n",
      "[Epoch 26/200] [Batch 374/637] [D loss: 0.156598] [G loss: 0.477104]\n",
      "[Epoch 26/200] [Batch 375/637] [D loss: 0.169225] [G loss: 0.475201]\n",
      "[Epoch 26/200] [Batch 376/637] [D loss: 0.214005] [G loss: 0.387573]\n",
      "[Epoch 26/200] [Batch 377/637] [D loss: 0.170908] [G loss: 0.515945]\n",
      "[Epoch 26/200] [Batch 378/637] [D loss: 0.178117] [G loss: 0.526143]\n",
      "[Epoch 26/200] [Batch 379/637] [D loss: 0.177060] [G loss: 0.534641]\n",
      "[Epoch 26/200] [Batch 380/637] [D loss: 0.160345] [G loss: 0.537385]\n",
      "[Epoch 26/200] [Batch 381/637] [D loss: 0.161418] [G loss: 0.581483]\n",
      "[Epoch 26/200] [Batch 382/637] [D loss: 0.186632] [G loss: 0.537038]\n",
      "[Epoch 26/200] [Batch 383/637] [D loss: 0.216556] [G loss: 0.451992]\n",
      "[Epoch 26/200] [Batch 384/637] [D loss: 0.162452] [G loss: 0.487076]\n",
      "[Epoch 26/200] [Batch 385/637] [D loss: 0.177357] [G loss: 0.496819]\n",
      "[Epoch 26/200] [Batch 386/637] [D loss: 0.194370] [G loss: 0.403755]\n",
      "[Epoch 26/200] [Batch 387/637] [D loss: 0.173373] [G loss: 0.489780]\n",
      "[Epoch 26/200] [Batch 388/637] [D loss: 0.163759] [G loss: 0.486884]\n",
      "[Epoch 26/200] [Batch 389/637] [D loss: 0.174376] [G loss: 0.496501]\n",
      "[Epoch 26/200] [Batch 390/637] [D loss: 0.162015] [G loss: 0.564584]\n",
      "[Epoch 26/200] [Batch 391/637] [D loss: 0.161543] [G loss: 0.539521]\n",
      "[Epoch 26/200] [Batch 392/637] [D loss: 0.184112] [G loss: 0.448574]\n",
      "[Epoch 26/200] [Batch 393/637] [D loss: 0.182897] [G loss: 0.485376]\n",
      "[Epoch 26/200] [Batch 394/637] [D loss: 0.213058] [G loss: 0.406605]\n",
      "[Epoch 26/200] [Batch 395/637] [D loss: 0.169043] [G loss: 0.560285]\n",
      "[Epoch 26/200] [Batch 396/637] [D loss: 0.187587] [G loss: 0.565003]\n",
      "[Epoch 26/200] [Batch 397/637] [D loss: 0.188955] [G loss: 0.454741]\n",
      "[Epoch 26/200] [Batch 398/637] [D loss: 0.168290] [G loss: 0.407214]\n",
      "[Epoch 26/200] [Batch 399/637] [D loss: 0.169613] [G loss: 0.435790]\n",
      "[Epoch 26/200] [Batch 400/637] [D loss: 0.187403] [G loss: 0.478753]\n",
      "[Epoch 26/200] [Batch 401/637] [D loss: 0.185420] [G loss: 0.545476]\n",
      "[Epoch 26/200] [Batch 402/637] [D loss: 0.168212] [G loss: 0.540232]\n",
      "[Epoch 26/200] [Batch 403/637] [D loss: 0.169500] [G loss: 0.512937]\n",
      "[Epoch 26/200] [Batch 404/637] [D loss: 0.150274] [G loss: 0.493864]\n",
      "[Epoch 26/200] [Batch 405/637] [D loss: 0.179545] [G loss: 0.431799]\n",
      "[Epoch 26/200] [Batch 406/637] [D loss: 0.212324] [G loss: 0.404379]\n",
      "[Epoch 26/200] [Batch 407/637] [D loss: 0.174432] [G loss: 0.544780]\n",
      "[Epoch 26/200] [Batch 408/637] [D loss: 0.212428] [G loss: 0.507920]\n",
      "[Epoch 26/200] [Batch 409/637] [D loss: 0.179277] [G loss: 0.481848]\n",
      "[Epoch 26/200] [Batch 410/637] [D loss: 0.195244] [G loss: 0.442889]\n",
      "[Epoch 26/200] [Batch 411/637] [D loss: 0.163813] [G loss: 0.492010]\n",
      "[Epoch 26/200] [Batch 412/637] [D loss: 0.165936] [G loss: 0.492342]\n",
      "[Epoch 26/200] [Batch 413/637] [D loss: 0.181133] [G loss: 0.487354]\n",
      "[Epoch 26/200] [Batch 414/637] [D loss: 0.138126] [G loss: 0.560371]\n",
      "[Epoch 26/200] [Batch 415/637] [D loss: 0.155557] [G loss: 0.500702]\n",
      "[Epoch 26/200] [Batch 416/637] [D loss: 0.149270] [G loss: 0.517441]\n",
      "[Epoch 26/200] [Batch 417/637] [D loss: 0.178375] [G loss: 0.449024]\n",
      "[Epoch 26/200] [Batch 418/637] [D loss: 0.151967] [G loss: 0.556879]\n",
      "[Epoch 26/200] [Batch 419/637] [D loss: 0.164528] [G loss: 0.590713]\n",
      "[Epoch 26/200] [Batch 420/637] [D loss: 0.169526] [G loss: 0.539995]\n",
      "[Epoch 26/200] [Batch 421/637] [D loss: 0.163301] [G loss: 0.474180]\n",
      "[Epoch 26/200] [Batch 422/637] [D loss: 0.170259] [G loss: 0.449148]\n",
      "[Epoch 26/200] [Batch 423/637] [D loss: 0.155679] [G loss: 0.566153]\n",
      "[Epoch 26/200] [Batch 424/637] [D loss: 0.181673] [G loss: 0.546739]\n",
      "[Epoch 26/200] [Batch 425/637] [D loss: 0.158648] [G loss: 0.566099]\n",
      "[Epoch 26/200] [Batch 426/637] [D loss: 0.162922] [G loss: 0.468182]\n",
      "[Epoch 26/200] [Batch 427/637] [D loss: 0.167197] [G loss: 0.450836]\n",
      "[Epoch 26/200] [Batch 428/637] [D loss: 0.179928] [G loss: 0.362743]\n",
      "[Epoch 26/200] [Batch 429/637] [D loss: 0.176097] [G loss: 0.417423]\n",
      "[Epoch 26/200] [Batch 430/637] [D loss: 0.166596] [G loss: 0.547519]\n",
      "[Epoch 26/200] [Batch 431/637] [D loss: 0.192486] [G loss: 0.493059]\n",
      "[Epoch 26/200] [Batch 432/637] [D loss: 0.180389] [G loss: 0.626680]\n",
      "[Epoch 26/200] [Batch 433/637] [D loss: 0.174309] [G loss: 0.544573]\n",
      "[Epoch 26/200] [Batch 434/637] [D loss: 0.179867] [G loss: 0.486499]\n",
      "[Epoch 26/200] [Batch 435/637] [D loss: 0.169903] [G loss: 0.475355]\n",
      "[Epoch 26/200] [Batch 436/637] [D loss: 0.146122] [G loss: 0.488044]\n",
      "[Epoch 26/200] [Batch 437/637] [D loss: 0.190385] [G loss: 0.427353]\n",
      "[Epoch 26/200] [Batch 438/637] [D loss: 0.181183] [G loss: 0.430069]\n",
      "[Epoch 26/200] [Batch 439/637] [D loss: 0.168987] [G loss: 0.455630]\n",
      "[Epoch 26/200] [Batch 440/637] [D loss: 0.168699] [G loss: 0.530911]\n",
      "[Epoch 26/200] [Batch 441/637] [D loss: 0.177723] [G loss: 0.523035]\n",
      "[Epoch 26/200] [Batch 442/637] [D loss: 0.159134] [G loss: 0.514491]\n",
      "[Epoch 26/200] [Batch 443/637] [D loss: 0.161694] [G loss: 0.510778]\n",
      "[Epoch 26/200] [Batch 444/637] [D loss: 0.157896] [G loss: 0.430433]\n",
      "[Epoch 26/200] [Batch 445/637] [D loss: 0.183803] [G loss: 0.553928]\n",
      "[Epoch 26/200] [Batch 446/637] [D loss: 0.167693] [G loss: 0.539205]\n",
      "[Epoch 26/200] [Batch 447/637] [D loss: 0.164056] [G loss: 0.445440]\n",
      "[Epoch 26/200] [Batch 448/637] [D loss: 0.171324] [G loss: 0.489289]\n",
      "[Epoch 26/200] [Batch 449/637] [D loss: 0.199321] [G loss: 0.453722]\n",
      "[Epoch 26/200] [Batch 450/637] [D loss: 0.162661] [G loss: 0.521464]\n",
      "[Epoch 26/200] [Batch 451/637] [D loss: 0.187017] [G loss: 0.437245]\n",
      "[Epoch 26/200] [Batch 452/637] [D loss: 0.167100] [G loss: 0.479876]\n",
      "[Epoch 26/200] [Batch 453/637] [D loss: 0.165605] [G loss: 0.535781]\n",
      "[Epoch 26/200] [Batch 454/637] [D loss: 0.169765] [G loss: 0.496246]\n",
      "[Epoch 26/200] [Batch 455/637] [D loss: 0.162982] [G loss: 0.520723]\n",
      "[Epoch 26/200] [Batch 456/637] [D loss: 0.162484] [G loss: 0.537139]\n",
      "[Epoch 26/200] [Batch 457/637] [D loss: 0.155277] [G loss: 0.501269]\n",
      "[Epoch 26/200] [Batch 458/637] [D loss: 0.154105] [G loss: 0.487015]\n",
      "[Epoch 26/200] [Batch 459/637] [D loss: 0.161126] [G loss: 0.494871]\n",
      "[Epoch 26/200] [Batch 460/637] [D loss: 0.170048] [G loss: 0.495636]\n",
      "[Epoch 26/200] [Batch 461/637] [D loss: 0.172991] [G loss: 0.477807]\n",
      "[Epoch 26/200] [Batch 462/637] [D loss: 0.144527] [G loss: 0.527819]\n",
      "[Epoch 26/200] [Batch 463/637] [D loss: 0.130309] [G loss: 0.550188]\n",
      "[Epoch 26/200] [Batch 464/637] [D loss: 0.149527] [G loss: 0.513779]\n",
      "[Epoch 26/200] [Batch 465/637] [D loss: 0.166019] [G loss: 0.404574]\n",
      "[Epoch 26/200] [Batch 466/637] [D loss: 0.185618] [G loss: 0.460005]\n",
      "[Epoch 26/200] [Batch 467/637] [D loss: 0.184960] [G loss: 0.588101]\n",
      "[Epoch 26/200] [Batch 468/637] [D loss: 0.173278] [G loss: 0.537822]\n",
      "[Epoch 26/200] [Batch 469/637] [D loss: 0.163770] [G loss: 0.485890]\n",
      "[Epoch 26/200] [Batch 470/637] [D loss: 0.194636] [G loss: 0.405129]\n",
      "[Epoch 26/200] [Batch 471/637] [D loss: 0.170626] [G loss: 0.477963]\n",
      "[Epoch 26/200] [Batch 472/637] [D loss: 0.166543] [G loss: 0.484300]\n",
      "[Epoch 26/200] [Batch 473/637] [D loss: 0.172600] [G loss: 0.479339]\n",
      "[Epoch 26/200] [Batch 474/637] [D loss: 0.193746] [G loss: 0.447095]\n",
      "[Epoch 26/200] [Batch 475/637] [D loss: 0.170830] [G loss: 0.503926]\n",
      "[Epoch 26/200] [Batch 476/637] [D loss: 0.181316] [G loss: 0.493886]\n",
      "[Epoch 26/200] [Batch 477/637] [D loss: 0.187132] [G loss: 0.530935]\n",
      "[Epoch 26/200] [Batch 478/637] [D loss: 0.185206] [G loss: 0.539752]\n",
      "[Epoch 26/200] [Batch 479/637] [D loss: 0.213560] [G loss: 0.479798]\n",
      "[Epoch 26/200] [Batch 480/637] [D loss: 0.182195] [G loss: 0.464218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/200] [Batch 481/637] [D loss: 0.200435] [G loss: 0.512233]\n",
      "[Epoch 26/200] [Batch 482/637] [D loss: 0.184518] [G loss: 0.550857]\n",
      "[Epoch 26/200] [Batch 483/637] [D loss: 0.170875] [G loss: 0.523747]\n",
      "[Epoch 26/200] [Batch 484/637] [D loss: 0.172914] [G loss: 0.415648]\n",
      "[Epoch 26/200] [Batch 485/637] [D loss: 0.170733] [G loss: 0.432326]\n",
      "[Epoch 26/200] [Batch 486/637] [D loss: 0.175474] [G loss: 0.485435]\n",
      "[Epoch 26/200] [Batch 487/637] [D loss: 0.141018] [G loss: 0.567692]\n",
      "[Epoch 26/200] [Batch 488/637] [D loss: 0.171007] [G loss: 0.503515]\n",
      "[Epoch 26/200] [Batch 489/637] [D loss: 0.195830] [G loss: 0.511266]\n",
      "[Epoch 26/200] [Batch 490/637] [D loss: 0.183211] [G loss: 0.610793]\n",
      "[Epoch 26/200] [Batch 491/637] [D loss: 0.187936] [G loss: 0.535090]\n",
      "[Epoch 26/200] [Batch 492/637] [D loss: 0.152712] [G loss: 0.519869]\n",
      "[Epoch 26/200] [Batch 493/637] [D loss: 0.169901] [G loss: 0.516766]\n",
      "[Epoch 26/200] [Batch 494/637] [D loss: 0.176678] [G loss: 0.478329]\n",
      "[Epoch 26/200] [Batch 495/637] [D loss: 0.182093] [G loss: 0.462400]\n",
      "[Epoch 26/200] [Batch 496/637] [D loss: 0.170431] [G loss: 0.496608]\n",
      "[Epoch 26/200] [Batch 497/637] [D loss: 0.186383] [G loss: 0.476744]\n",
      "[Epoch 26/200] [Batch 498/637] [D loss: 0.181834] [G loss: 0.408034]\n",
      "[Epoch 26/200] [Batch 499/637] [D loss: 0.181670] [G loss: 0.458326]\n",
      "[Epoch 26/200] [Batch 500/637] [D loss: 0.165424] [G loss: 0.488551]\n",
      "[Epoch 26/200] [Batch 501/637] [D loss: 0.173775] [G loss: 0.539490]\n",
      "[Epoch 26/200] [Batch 502/637] [D loss: 0.163878] [G loss: 0.489925]\n",
      "[Epoch 26/200] [Batch 503/637] [D loss: 0.148499] [G loss: 0.575177]\n",
      "[Epoch 26/200] [Batch 504/637] [D loss: 0.200232] [G loss: 0.462963]\n",
      "[Epoch 26/200] [Batch 505/637] [D loss: 0.166597] [G loss: 0.512447]\n",
      "[Epoch 26/200] [Batch 506/637] [D loss: 0.150377] [G loss: 0.504817]\n",
      "[Epoch 26/200] [Batch 507/637] [D loss: 0.164556] [G loss: 0.455720]\n",
      "[Epoch 26/200] [Batch 508/637] [D loss: 0.187991] [G loss: 0.506448]\n",
      "[Epoch 26/200] [Batch 509/637] [D loss: 0.175712] [G loss: 0.514223]\n",
      "[Epoch 26/200] [Batch 510/637] [D loss: 0.161596] [G loss: 0.541599]\n",
      "[Epoch 26/200] [Batch 511/637] [D loss: 0.161279] [G loss: 0.509999]\n",
      "[Epoch 26/200] [Batch 512/637] [D loss: 0.191750] [G loss: 0.438348]\n",
      "[Epoch 26/200] [Batch 513/637] [D loss: 0.175861] [G loss: 0.476813]\n",
      "[Epoch 26/200] [Batch 514/637] [D loss: 0.147917] [G loss: 0.548173]\n",
      "[Epoch 26/200] [Batch 515/637] [D loss: 0.148745] [G loss: 0.493535]\n",
      "[Epoch 26/200] [Batch 516/637] [D loss: 0.179829] [G loss: 0.426105]\n",
      "[Epoch 26/200] [Batch 517/637] [D loss: 0.167570] [G loss: 0.547449]\n",
      "[Epoch 26/200] [Batch 518/637] [D loss: 0.154356] [G loss: 0.532283]\n",
      "[Epoch 26/200] [Batch 519/637] [D loss: 0.178870] [G loss: 0.447179]\n",
      "[Epoch 26/200] [Batch 520/637] [D loss: 0.155549] [G loss: 0.525853]\n",
      "[Epoch 26/200] [Batch 521/637] [D loss: 0.162817] [G loss: 0.467745]\n",
      "[Epoch 26/200] [Batch 522/637] [D loss: 0.173369] [G loss: 0.562605]\n",
      "[Epoch 26/200] [Batch 523/637] [D loss: 0.171905] [G loss: 0.449134]\n",
      "[Epoch 26/200] [Batch 524/637] [D loss: 0.150259] [G loss: 0.511643]\n",
      "[Epoch 26/200] [Batch 525/637] [D loss: 0.171713] [G loss: 0.505601]\n",
      "[Epoch 26/200] [Batch 526/637] [D loss: 0.204494] [G loss: 0.494156]\n",
      "[Epoch 26/200] [Batch 527/637] [D loss: 0.171890] [G loss: 0.521617]\n",
      "[Epoch 26/200] [Batch 528/637] [D loss: 0.177066] [G loss: 0.489557]\n",
      "[Epoch 26/200] [Batch 529/637] [D loss: 0.144841] [G loss: 0.536262]\n",
      "[Epoch 26/200] [Batch 530/637] [D loss: 0.169974] [G loss: 0.454142]\n",
      "[Epoch 26/200] [Batch 531/637] [D loss: 0.188546] [G loss: 0.459337]\n",
      "[Epoch 26/200] [Batch 532/637] [D loss: 0.156361] [G loss: 0.518223]\n",
      "[Epoch 26/200] [Batch 533/637] [D loss: 0.173147] [G loss: 0.645130]\n",
      "[Epoch 26/200] [Batch 534/637] [D loss: 0.152315] [G loss: 0.528608]\n",
      "[Epoch 26/200] [Batch 535/637] [D loss: 0.138274] [G loss: 0.482932]\n",
      "[Epoch 26/200] [Batch 536/637] [D loss: 0.170310] [G loss: 0.540203]\n",
      "[Epoch 26/200] [Batch 537/637] [D loss: 0.178821] [G loss: 0.483676]\n",
      "[Epoch 26/200] [Batch 538/637] [D loss: 0.140376] [G loss: 0.547681]\n",
      "[Epoch 26/200] [Batch 539/637] [D loss: 0.174637] [G loss: 0.439972]\n",
      "[Epoch 26/200] [Batch 540/637] [D loss: 0.164863] [G loss: 0.495040]\n",
      "[Epoch 26/200] [Batch 541/637] [D loss: 0.178344] [G loss: 0.484112]\n",
      "[Epoch 26/200] [Batch 542/637] [D loss: 0.183751] [G loss: 0.423614]\n",
      "[Epoch 26/200] [Batch 543/637] [D loss: 0.175668] [G loss: 0.448730]\n",
      "[Epoch 26/200] [Batch 544/637] [D loss: 0.151900] [G loss: 0.480138]\n",
      "[Epoch 26/200] [Batch 545/637] [D loss: 0.177833] [G loss: 0.402862]\n",
      "[Epoch 26/200] [Batch 546/637] [D loss: 0.198477] [G loss: 0.427780]\n",
      "[Epoch 26/200] [Batch 547/637] [D loss: 0.171196] [G loss: 0.574801]\n",
      "[Epoch 26/200] [Batch 548/637] [D loss: 0.167510] [G loss: 0.476610]\n",
      "[Epoch 26/200] [Batch 549/637] [D loss: 0.165264] [G loss: 0.445774]\n",
      "[Epoch 26/200] [Batch 550/637] [D loss: 0.147677] [G loss: 0.502620]\n",
      "[Epoch 26/200] [Batch 551/637] [D loss: 0.179328] [G loss: 0.495972]\n",
      "[Epoch 26/200] [Batch 552/637] [D loss: 0.175462] [G loss: 0.510999]\n",
      "[Epoch 26/200] [Batch 553/637] [D loss: 0.168719] [G loss: 0.464522]\n",
      "[Epoch 26/200] [Batch 554/637] [D loss: 0.155558] [G loss: 0.473098]\n",
      "[Epoch 26/200] [Batch 555/637] [D loss: 0.161511] [G loss: 0.500041]\n",
      "[Epoch 26/200] [Batch 556/637] [D loss: 0.158003] [G loss: 0.493368]\n",
      "[Epoch 26/200] [Batch 557/637] [D loss: 0.183670] [G loss: 0.451179]\n",
      "[Epoch 26/200] [Batch 558/637] [D loss: 0.177617] [G loss: 0.546074]\n",
      "[Epoch 26/200] [Batch 559/637] [D loss: 0.193995] [G loss: 0.488351]\n",
      "[Epoch 26/200] [Batch 560/637] [D loss: 0.162947] [G loss: 0.472676]\n",
      "[Epoch 26/200] [Batch 561/637] [D loss: 0.165745] [G loss: 0.571283]\n",
      "[Epoch 26/200] [Batch 562/637] [D loss: 0.177668] [G loss: 0.460599]\n",
      "[Epoch 26/200] [Batch 563/637] [D loss: 0.152922] [G loss: 0.513424]\n",
      "[Epoch 26/200] [Batch 564/637] [D loss: 0.171401] [G loss: 0.507300]\n",
      "[Epoch 26/200] [Batch 565/637] [D loss: 0.161601] [G loss: 0.464055]\n",
      "[Epoch 26/200] [Batch 566/637] [D loss: 0.169547] [G loss: 0.486915]\n",
      "[Epoch 26/200] [Batch 567/637] [D loss: 0.176684] [G loss: 0.534969]\n",
      "[Epoch 26/200] [Batch 568/637] [D loss: 0.171837] [G loss: 0.481745]\n",
      "[Epoch 26/200] [Batch 569/637] [D loss: 0.162239] [G loss: 0.607760]\n",
      "[Epoch 26/200] [Batch 570/637] [D loss: 0.200094] [G loss: 0.440252]\n",
      "[Epoch 26/200] [Batch 571/637] [D loss: 0.183489] [G loss: 0.503068]\n",
      "[Epoch 26/200] [Batch 572/637] [D loss: 0.164474] [G loss: 0.486502]\n",
      "[Epoch 26/200] [Batch 573/637] [D loss: 0.163023] [G loss: 0.463628]\n",
      "[Epoch 26/200] [Batch 574/637] [D loss: 0.148883] [G loss: 0.473113]\n",
      "[Epoch 26/200] [Batch 575/637] [D loss: 0.155903] [G loss: 0.446520]\n",
      "[Epoch 26/200] [Batch 576/637] [D loss: 0.166391] [G loss: 0.463417]\n",
      "[Epoch 26/200] [Batch 577/637] [D loss: 0.172154] [G loss: 0.434210]\n",
      "[Epoch 26/200] [Batch 578/637] [D loss: 0.158206] [G loss: 0.585791]\n",
      "[Epoch 26/200] [Batch 579/637] [D loss: 0.155170] [G loss: 0.545611]\n",
      "[Epoch 26/200] [Batch 580/637] [D loss: 0.161087] [G loss: 0.503314]\n",
      "[Epoch 26/200] [Batch 581/637] [D loss: 0.228289] [G loss: 0.377356]\n",
      "[Epoch 26/200] [Batch 582/637] [D loss: 0.201134] [G loss: 0.488638]\n",
      "[Epoch 26/200] [Batch 583/637] [D loss: 0.200108] [G loss: 0.525884]\n",
      "[Epoch 26/200] [Batch 584/637] [D loss: 0.165279] [G loss: 0.536733]\n",
      "[Epoch 26/200] [Batch 585/637] [D loss: 0.185648] [G loss: 0.478297]\n",
      "[Epoch 26/200] [Batch 586/637] [D loss: 0.183944] [G loss: 0.442062]\n",
      "[Epoch 26/200] [Batch 587/637] [D loss: 0.174612] [G loss: 0.483638]\n",
      "[Epoch 26/200] [Batch 588/637] [D loss: 0.152216] [G loss: 0.524948]\n",
      "[Epoch 26/200] [Batch 589/637] [D loss: 0.168931] [G loss: 0.451285]\n",
      "[Epoch 26/200] [Batch 590/637] [D loss: 0.150180] [G loss: 0.496154]\n",
      "[Epoch 26/200] [Batch 591/637] [D loss: 0.145744] [G loss: 0.558598]\n",
      "[Epoch 26/200] [Batch 592/637] [D loss: 0.143988] [G loss: 0.585686]\n",
      "[Epoch 26/200] [Batch 593/637] [D loss: 0.147951] [G loss: 0.490620]\n",
      "[Epoch 26/200] [Batch 594/637] [D loss: 0.160292] [G loss: 0.496913]\n",
      "[Epoch 26/200] [Batch 595/637] [D loss: 0.168792] [G loss: 0.513831]\n",
      "[Epoch 26/200] [Batch 596/637] [D loss: 0.165058] [G loss: 0.521052]\n",
      "[Epoch 26/200] [Batch 597/637] [D loss: 0.147303] [G loss: 0.524178]\n",
      "[Epoch 26/200] [Batch 598/637] [D loss: 0.162258] [G loss: 0.566535]\n",
      "[Epoch 26/200] [Batch 599/637] [D loss: 0.162758] [G loss: 0.498454]\n",
      "[Epoch 26/200] [Batch 600/637] [D loss: 0.177031] [G loss: 0.495605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/200] [Batch 601/637] [D loss: 0.182562] [G loss: 0.521938]\n",
      "[Epoch 26/200] [Batch 602/637] [D loss: 0.166420] [G loss: 0.464931]\n",
      "[Epoch 26/200] [Batch 603/637] [D loss: 0.173780] [G loss: 0.479570]\n",
      "[Epoch 26/200] [Batch 604/637] [D loss: 0.180247] [G loss: 0.462511]\n",
      "[Epoch 26/200] [Batch 605/637] [D loss: 0.163355] [G loss: 0.517259]\n",
      "[Epoch 26/200] [Batch 606/637] [D loss: 0.191891] [G loss: 0.488982]\n",
      "[Epoch 26/200] [Batch 607/637] [D loss: 0.173759] [G loss: 0.439644]\n",
      "[Epoch 26/200] [Batch 608/637] [D loss: 0.163519] [G loss: 0.478583]\n",
      "[Epoch 26/200] [Batch 609/637] [D loss: 0.175836] [G loss: 0.465491]\n",
      "[Epoch 26/200] [Batch 610/637] [D loss: 0.183178] [G loss: 0.518933]\n",
      "[Epoch 26/200] [Batch 611/637] [D loss: 0.160711] [G loss: 0.506817]\n",
      "[Epoch 26/200] [Batch 612/637] [D loss: 0.147210] [G loss: 0.504827]\n",
      "[Epoch 26/200] [Batch 613/637] [D loss: 0.165093] [G loss: 0.519730]\n",
      "[Epoch 26/200] [Batch 614/637] [D loss: 0.185318] [G loss: 0.426348]\n",
      "[Epoch 26/200] [Batch 615/637] [D loss: 0.159915] [G loss: 0.452909]\n",
      "[Epoch 26/200] [Batch 616/637] [D loss: 0.135203] [G loss: 0.527984]\n",
      "[Epoch 26/200] [Batch 617/637] [D loss: 0.163885] [G loss: 0.522291]\n",
      "[Epoch 26/200] [Batch 618/637] [D loss: 0.156832] [G loss: 0.489284]\n",
      "[Epoch 26/200] [Batch 619/637] [D loss: 0.156524] [G loss: 0.463913]\n",
      "[Epoch 26/200] [Batch 620/637] [D loss: 0.165737] [G loss: 0.526477]\n",
      "[Epoch 26/200] [Batch 621/637] [D loss: 0.165874] [G loss: 0.465304]\n",
      "[Epoch 26/200] [Batch 622/637] [D loss: 0.159103] [G loss: 0.512026]\n",
      "[Epoch 26/200] [Batch 623/637] [D loss: 0.164490] [G loss: 0.527694]\n",
      "[Epoch 26/200] [Batch 624/637] [D loss: 0.178906] [G loss: 0.452204]\n",
      "[Epoch 26/200] [Batch 625/637] [D loss: 0.171815] [G loss: 0.476943]\n",
      "[Epoch 26/200] [Batch 626/637] [D loss: 0.181662] [G loss: 0.466467]\n",
      "[Epoch 26/200] [Batch 627/637] [D loss: 0.222779] [G loss: 0.514358]\n",
      "[Epoch 26/200] [Batch 628/637] [D loss: 0.172726] [G loss: 0.503194]\n",
      "[Epoch 26/200] [Batch 629/637] [D loss: 0.162719] [G loss: 0.460488]\n",
      "[Epoch 26/200] [Batch 630/637] [D loss: 0.167879] [G loss: 0.442061]\n",
      "[Epoch 26/200] [Batch 631/637] [D loss: 0.155651] [G loss: 0.448681]\n",
      "[Epoch 26/200] [Batch 632/637] [D loss: 0.149856] [G loss: 0.438814]\n",
      "[Epoch 26/200] [Batch 633/637] [D loss: 0.143777] [G loss: 0.491067]\n",
      "[Epoch 26/200] [Batch 634/637] [D loss: 0.159656] [G loss: 0.496324]\n",
      "[Epoch 26/200] [Batch 635/637] [D loss: 0.154512] [G loss: 0.478661]\n",
      "[Epoch 26/200] [Batch 636/637] [D loss: 0.123845] [G loss: 0.575891]\n",
      "[Epoch 27/200] [Batch 0/637] [D loss: 0.168832] [G loss: 0.511127]\n",
      "[Epoch 27/200] [Batch 1/637] [D loss: 0.161215] [G loss: 0.471823]\n",
      "[Epoch 27/200] [Batch 2/637] [D loss: 0.189394] [G loss: 0.382804]\n",
      "[Epoch 27/200] [Batch 3/637] [D loss: 0.179200] [G loss: 0.554336]\n",
      "[Epoch 27/200] [Batch 4/637] [D loss: 0.176172] [G loss: 0.459946]\n",
      "[Epoch 27/200] [Batch 5/637] [D loss: 0.177575] [G loss: 0.427813]\n",
      "[Epoch 27/200] [Batch 6/637] [D loss: 0.181288] [G loss: 0.453858]\n",
      "[Epoch 27/200] [Batch 7/637] [D loss: 0.175651] [G loss: 0.473347]\n",
      "[Epoch 27/200] [Batch 8/637] [D loss: 0.172902] [G loss: 0.479750]\n",
      "[Epoch 27/200] [Batch 9/637] [D loss: 0.172878] [G loss: 0.454684]\n",
      "[Epoch 27/200] [Batch 10/637] [D loss: 0.161407] [G loss: 0.471432]\n",
      "[Epoch 27/200] [Batch 11/637] [D loss: 0.180996] [G loss: 0.503436]\n",
      "[Epoch 27/200] [Batch 12/637] [D loss: 0.167219] [G loss: 0.462266]\n",
      "[Epoch 27/200] [Batch 13/637] [D loss: 0.169769] [G loss: 0.508681]\n",
      "[Epoch 27/200] [Batch 14/637] [D loss: 0.169979] [G loss: 0.475929]\n",
      "[Epoch 27/200] [Batch 15/637] [D loss: 0.172205] [G loss: 0.538432]\n",
      "[Epoch 27/200] [Batch 16/637] [D loss: 0.155465] [G loss: 0.508990]\n",
      "[Epoch 27/200] [Batch 17/637] [D loss: 0.201196] [G loss: 0.415411]\n",
      "[Epoch 27/200] [Batch 18/637] [D loss: 0.199347] [G loss: 0.621790]\n",
      "[Epoch 27/200] [Batch 19/637] [D loss: 0.177605] [G loss: 0.529914]\n",
      "[Epoch 27/200] [Batch 20/637] [D loss: 0.153106] [G loss: 0.506453]\n",
      "[Epoch 27/200] [Batch 21/637] [D loss: 0.192350] [G loss: 0.482080]\n",
      "[Epoch 27/200] [Batch 22/637] [D loss: 0.174149] [G loss: 0.470330]\n",
      "[Epoch 27/200] [Batch 23/637] [D loss: 0.152608] [G loss: 0.510233]\n",
      "[Epoch 27/200] [Batch 24/637] [D loss: 0.184407] [G loss: 0.470146]\n",
      "[Epoch 27/200] [Batch 25/637] [D loss: 0.143933] [G loss: 0.481283]\n",
      "[Epoch 27/200] [Batch 26/637] [D loss: 0.162971] [G loss: 0.435190]\n",
      "[Epoch 27/200] [Batch 27/637] [D loss: 0.167266] [G loss: 0.486855]\n",
      "[Epoch 27/200] [Batch 28/637] [D loss: 0.154597] [G loss: 0.554046]\n",
      "[Epoch 27/200] [Batch 29/637] [D loss: 0.170184] [G loss: 0.503115]\n",
      "[Epoch 27/200] [Batch 30/637] [D loss: 0.196372] [G loss: 0.425824]\n",
      "[Epoch 27/200] [Batch 31/637] [D loss: 0.175774] [G loss: 0.513838]\n",
      "[Epoch 27/200] [Batch 32/637] [D loss: 0.163744] [G loss: 0.504636]\n",
      "[Epoch 27/200] [Batch 33/637] [D loss: 0.165855] [G loss: 0.496747]\n",
      "[Epoch 27/200] [Batch 34/637] [D loss: 0.172683] [G loss: 0.463426]\n",
      "[Epoch 27/200] [Batch 35/637] [D loss: 0.179918] [G loss: 0.484023]\n",
      "[Epoch 27/200] [Batch 36/637] [D loss: 0.174300] [G loss: 0.543640]\n",
      "[Epoch 27/200] [Batch 37/637] [D loss: 0.192075] [G loss: 0.485617]\n",
      "[Epoch 27/200] [Batch 38/637] [D loss: 0.175701] [G loss: 0.437380]\n",
      "[Epoch 27/200] [Batch 39/637] [D loss: 0.173787] [G loss: 0.507200]\n",
      "[Epoch 27/200] [Batch 40/637] [D loss: 0.177027] [G loss: 0.466683]\n",
      "[Epoch 27/200] [Batch 41/637] [D loss: 0.148947] [G loss: 0.449502]\n",
      "[Epoch 27/200] [Batch 42/637] [D loss: 0.161299] [G loss: 0.465189]\n",
      "[Epoch 27/200] [Batch 43/637] [D loss: 0.169866] [G loss: 0.422475]\n",
      "[Epoch 27/200] [Batch 44/637] [D loss: 0.175012] [G loss: 0.495250]\n",
      "[Epoch 27/200] [Batch 45/637] [D loss: 0.172505] [G loss: 0.528067]\n",
      "[Epoch 27/200] [Batch 46/637] [D loss: 0.161100] [G loss: 0.549298]\n",
      "[Epoch 27/200] [Batch 47/637] [D loss: 0.194276] [G loss: 0.384070]\n",
      "[Epoch 27/200] [Batch 48/637] [D loss: 0.185302] [G loss: 0.506495]\n",
      "[Epoch 27/200] [Batch 49/637] [D loss: 0.162369] [G loss: 0.567993]\n",
      "[Epoch 27/200] [Batch 50/637] [D loss: 0.158326] [G loss: 0.543597]\n",
      "[Epoch 27/200] [Batch 51/637] [D loss: 0.143843] [G loss: 0.499782]\n",
      "[Epoch 27/200] [Batch 52/637] [D loss: 0.172807] [G loss: 0.466831]\n",
      "[Epoch 27/200] [Batch 53/637] [D loss: 0.161553] [G loss: 0.492269]\n",
      "[Epoch 27/200] [Batch 54/637] [D loss: 0.123744] [G loss: 0.520465]\n",
      "[Epoch 27/200] [Batch 55/637] [D loss: 0.151680] [G loss: 0.552436]\n",
      "[Epoch 27/200] [Batch 56/637] [D loss: 0.187778] [G loss: 0.510169]\n",
      "[Epoch 27/200] [Batch 57/637] [D loss: 0.163685] [G loss: 0.566912]\n",
      "[Epoch 27/200] [Batch 58/637] [D loss: 0.151353] [G loss: 0.562342]\n",
      "[Epoch 27/200] [Batch 59/637] [D loss: 0.123191] [G loss: 0.621530]\n",
      "[Epoch 27/200] [Batch 60/637] [D loss: 0.162483] [G loss: 0.508238]\n",
      "[Epoch 27/200] [Batch 61/637] [D loss: 0.158795] [G loss: 0.513456]\n",
      "[Epoch 27/200] [Batch 62/637] [D loss: 0.171857] [G loss: 0.542802]\n",
      "[Epoch 27/200] [Batch 63/637] [D loss: 0.178170] [G loss: 0.503240]\n",
      "[Epoch 27/200] [Batch 64/637] [D loss: 0.169308] [G loss: 0.444454]\n",
      "[Epoch 27/200] [Batch 65/637] [D loss: 0.186380] [G loss: 0.542260]\n",
      "[Epoch 27/200] [Batch 66/637] [D loss: 0.189118] [G loss: 0.475948]\n",
      "[Epoch 27/200] [Batch 67/637] [D loss: 0.164922] [G loss: 0.545352]\n",
      "[Epoch 27/200] [Batch 68/637] [D loss: 0.187027] [G loss: 0.480491]\n",
      "[Epoch 27/200] [Batch 69/637] [D loss: 0.166475] [G loss: 0.500981]\n",
      "[Epoch 27/200] [Batch 70/637] [D loss: 0.181901] [G loss: 0.483345]\n",
      "[Epoch 27/200] [Batch 71/637] [D loss: 0.175546] [G loss: 0.466550]\n",
      "[Epoch 27/200] [Batch 72/637] [D loss: 0.168745] [G loss: 0.482356]\n",
      "[Epoch 27/200] [Batch 73/637] [D loss: 0.157010] [G loss: 0.514425]\n",
      "[Epoch 27/200] [Batch 74/637] [D loss: 0.179451] [G loss: 0.448440]\n",
      "[Epoch 27/200] [Batch 75/637] [D loss: 0.161561] [G loss: 0.512324]\n",
      "[Epoch 27/200] [Batch 76/637] [D loss: 0.145311] [G loss: 0.531491]\n",
      "[Epoch 27/200] [Batch 77/637] [D loss: 0.187298] [G loss: 0.507425]\n",
      "[Epoch 27/200] [Batch 78/637] [D loss: 0.157274] [G loss: 0.498408]\n",
      "[Epoch 27/200] [Batch 79/637] [D loss: 0.166671] [G loss: 0.598474]\n",
      "[Epoch 27/200] [Batch 80/637] [D loss: 0.198700] [G loss: 0.565103]\n",
      "[Epoch 27/200] [Batch 81/637] [D loss: 0.176423] [G loss: 0.609902]\n",
      "[Epoch 27/200] [Batch 82/637] [D loss: 0.196826] [G loss: 0.577979]\n",
      "[Epoch 27/200] [Batch 83/637] [D loss: 0.185161] [G loss: 0.475382]\n",
      "[Epoch 27/200] [Batch 84/637] [D loss: 0.188187] [G loss: 0.409462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/200] [Batch 85/637] [D loss: 0.190381] [G loss: 0.471167]\n",
      "[Epoch 27/200] [Batch 86/637] [D loss: 0.177982] [G loss: 0.585588]\n",
      "[Epoch 27/200] [Batch 87/637] [D loss: 0.176179] [G loss: 0.508506]\n",
      "[Epoch 27/200] [Batch 88/637] [D loss: 0.172745] [G loss: 0.455047]\n",
      "[Epoch 27/200] [Batch 89/637] [D loss: 0.155868] [G loss: 0.482063]\n",
      "[Epoch 27/200] [Batch 90/637] [D loss: 0.161727] [G loss: 0.467325]\n",
      "[Epoch 27/200] [Batch 91/637] [D loss: 0.131551] [G loss: 0.511620]\n",
      "[Epoch 27/200] [Batch 92/637] [D loss: 0.164523] [G loss: 0.481733]\n",
      "[Epoch 27/200] [Batch 93/637] [D loss: 0.144233] [G loss: 0.559823]\n",
      "[Epoch 27/200] [Batch 94/637] [D loss: 0.168410] [G loss: 0.585578]\n",
      "[Epoch 27/200] [Batch 95/637] [D loss: 0.191213] [G loss: 0.418353]\n",
      "[Epoch 27/200] [Batch 96/637] [D loss: 0.167313] [G loss: 0.539949]\n",
      "[Epoch 27/200] [Batch 97/637] [D loss: 0.206877] [G loss: 0.503022]\n",
      "[Epoch 27/200] [Batch 98/637] [D loss: 0.172468] [G loss: 0.534994]\n",
      "[Epoch 27/200] [Batch 99/637] [D loss: 0.169470] [G loss: 0.461052]\n",
      "[Epoch 27/200] [Batch 100/637] [D loss: 0.212981] [G loss: 0.352504]\n",
      "[Epoch 27/200] [Batch 101/637] [D loss: 0.172176] [G loss: 0.485759]\n",
      "[Epoch 27/200] [Batch 102/637] [D loss: 0.163508] [G loss: 0.456935]\n",
      "[Epoch 27/200] [Batch 103/637] [D loss: 0.153316] [G loss: 0.449743]\n",
      "[Epoch 27/200] [Batch 104/637] [D loss: 0.144986] [G loss: 0.451128]\n",
      "[Epoch 27/200] [Batch 105/637] [D loss: 0.166395] [G loss: 0.492160]\n",
      "[Epoch 27/200] [Batch 106/637] [D loss: 0.146042] [G loss: 0.542794]\n",
      "[Epoch 27/200] [Batch 107/637] [D loss: 0.149618] [G loss: 0.526807]\n",
      "[Epoch 27/200] [Batch 108/637] [D loss: 0.150910] [G loss: 0.532402]\n",
      "[Epoch 27/200] [Batch 109/637] [D loss: 0.148745] [G loss: 0.417268]\n",
      "[Epoch 27/200] [Batch 110/637] [D loss: 0.167078] [G loss: 0.452814]\n",
      "[Epoch 27/200] [Batch 111/637] [D loss: 0.188760] [G loss: 0.486772]\n",
      "[Epoch 27/200] [Batch 112/637] [D loss: 0.162456] [G loss: 0.572736]\n",
      "[Epoch 27/200] [Batch 113/637] [D loss: 0.201802] [G loss: 0.550184]\n",
      "[Epoch 27/200] [Batch 114/637] [D loss: 0.167194] [G loss: 0.467997]\n",
      "[Epoch 27/200] [Batch 115/637] [D loss: 0.159249] [G loss: 0.499651]\n",
      "[Epoch 27/200] [Batch 116/637] [D loss: 0.202195] [G loss: 0.419814]\n",
      "[Epoch 27/200] [Batch 117/637] [D loss: 0.178048] [G loss: 0.464269]\n",
      "[Epoch 27/200] [Batch 118/637] [D loss: 0.214168] [G loss: 0.456363]\n",
      "[Epoch 27/200] [Batch 119/637] [D loss: 0.170436] [G loss: 0.481632]\n",
      "[Epoch 27/200] [Batch 120/637] [D loss: 0.181911] [G loss: 0.435498]\n",
      "[Epoch 27/200] [Batch 121/637] [D loss: 0.171774] [G loss: 0.486060]\n",
      "[Epoch 27/200] [Batch 122/637] [D loss: 0.142910] [G loss: 0.488273]\n",
      "[Epoch 27/200] [Batch 123/637] [D loss: 0.152853] [G loss: 0.443154]\n",
      "[Epoch 27/200] [Batch 124/637] [D loss: 0.157211] [G loss: 0.510598]\n",
      "[Epoch 27/200] [Batch 125/637] [D loss: 0.150198] [G loss: 0.536089]\n",
      "[Epoch 27/200] [Batch 126/637] [D loss: 0.165886] [G loss: 0.508242]\n",
      "[Epoch 27/200] [Batch 127/637] [D loss: 0.156981] [G loss: 0.516395]\n",
      "[Epoch 27/200] [Batch 128/637] [D loss: 0.164603] [G loss: 0.459879]\n",
      "[Epoch 27/200] [Batch 129/637] [D loss: 0.190521] [G loss: 0.509722]\n",
      "[Epoch 27/200] [Batch 130/637] [D loss: 0.160773] [G loss: 0.493974]\n",
      "[Epoch 27/200] [Batch 131/637] [D loss: 0.154570] [G loss: 0.469495]\n",
      "[Epoch 27/200] [Batch 132/637] [D loss: 0.185484] [G loss: 0.425266]\n",
      "[Epoch 27/200] [Batch 133/637] [D loss: 0.171537] [G loss: 0.466714]\n",
      "[Epoch 27/200] [Batch 134/637] [D loss: 0.148608] [G loss: 0.570747]\n",
      "[Epoch 27/200] [Batch 135/637] [D loss: 0.162556] [G loss: 0.540197]\n",
      "[Epoch 27/200] [Batch 136/637] [D loss: 0.189452] [G loss: 0.469330]\n",
      "[Epoch 27/200] [Batch 137/637] [D loss: 0.169182] [G loss: 0.616220]\n",
      "[Epoch 27/200] [Batch 138/637] [D loss: 0.171808] [G loss: 0.507697]\n",
      "[Epoch 27/200] [Batch 139/637] [D loss: 0.178404] [G loss: 0.494947]\n",
      "[Epoch 27/200] [Batch 140/637] [D loss: 0.162121] [G loss: 0.441118]\n",
      "[Epoch 27/200] [Batch 141/637] [D loss: 0.180465] [G loss: 0.462522]\n",
      "[Epoch 27/200] [Batch 142/637] [D loss: 0.163539] [G loss: 0.555679]\n",
      "[Epoch 27/200] [Batch 143/637] [D loss: 0.173795] [G loss: 0.526604]\n",
      "[Epoch 27/200] [Batch 144/637] [D loss: 0.182406] [G loss: 0.481052]\n",
      "[Epoch 27/200] [Batch 145/637] [D loss: 0.182834] [G loss: 0.452450]\n",
      "[Epoch 27/200] [Batch 146/637] [D loss: 0.178811] [G loss: 0.472372]\n",
      "[Epoch 27/200] [Batch 147/637] [D loss: 0.198595] [G loss: 0.440764]\n",
      "[Epoch 27/200] [Batch 148/637] [D loss: 0.186295] [G loss: 0.487306]\n",
      "[Epoch 27/200] [Batch 149/637] [D loss: 0.194125] [G loss: 0.486073]\n",
      "[Epoch 27/200] [Batch 150/637] [D loss: 0.164386] [G loss: 0.423208]\n",
      "[Epoch 27/200] [Batch 151/637] [D loss: 0.166694] [G loss: 0.446799]\n",
      "[Epoch 27/200] [Batch 152/637] [D loss: 0.181044] [G loss: 0.515855]\n",
      "[Epoch 27/200] [Batch 153/637] [D loss: 0.174906] [G loss: 0.460768]\n",
      "[Epoch 27/200] [Batch 154/637] [D loss: 0.150695] [G loss: 0.504109]\n",
      "[Epoch 27/200] [Batch 155/637] [D loss: 0.198440] [G loss: 0.457797]\n",
      "[Epoch 27/200] [Batch 156/637] [D loss: 0.157870] [G loss: 0.505576]\n",
      "[Epoch 27/200] [Batch 157/637] [D loss: 0.148666] [G loss: 0.496417]\n",
      "[Epoch 27/200] [Batch 158/637] [D loss: 0.155650] [G loss: 0.481958]\n",
      "[Epoch 27/200] [Batch 159/637] [D loss: 0.176625] [G loss: 0.458550]\n",
      "[Epoch 27/200] [Batch 160/637] [D loss: 0.150394] [G loss: 0.490092]\n",
      "[Epoch 27/200] [Batch 161/637] [D loss: 0.169589] [G loss: 0.440777]\n",
      "[Epoch 27/200] [Batch 162/637] [D loss: 0.166051] [G loss: 0.475547]\n",
      "[Epoch 27/200] [Batch 163/637] [D loss: 0.169765] [G loss: 0.496695]\n",
      "[Epoch 27/200] [Batch 164/637] [D loss: 0.169071] [G loss: 0.489783]\n",
      "[Epoch 27/200] [Batch 165/637] [D loss: 0.168539] [G loss: 0.472803]\n",
      "[Epoch 27/200] [Batch 166/637] [D loss: 0.191228] [G loss: 0.467904]\n",
      "[Epoch 27/200] [Batch 167/637] [D loss: 0.167415] [G loss: 0.481114]\n",
      "[Epoch 27/200] [Batch 168/637] [D loss: 0.187045] [G loss: 0.480359]\n",
      "[Epoch 27/200] [Batch 169/637] [D loss: 0.232783] [G loss: 0.482102]\n",
      "[Epoch 27/200] [Batch 170/637] [D loss: 0.172911] [G loss: 0.533520]\n",
      "[Epoch 27/200] [Batch 171/637] [D loss: 0.188562] [G loss: 0.468474]\n",
      "[Epoch 27/200] [Batch 172/637] [D loss: 0.171761] [G loss: 0.428703]\n",
      "[Epoch 27/200] [Batch 173/637] [D loss: 0.180774] [G loss: 0.436693]\n",
      "[Epoch 27/200] [Batch 174/637] [D loss: 0.191635] [G loss: 0.496433]\n",
      "[Epoch 27/200] [Batch 175/637] [D loss: 0.164111] [G loss: 0.515676]\n",
      "[Epoch 27/200] [Batch 176/637] [D loss: 0.202918] [G loss: 0.455758]\n",
      "[Epoch 27/200] [Batch 177/637] [D loss: 0.187612] [G loss: 0.506012]\n",
      "[Epoch 27/200] [Batch 178/637] [D loss: 0.186863] [G loss: 0.497220]\n",
      "[Epoch 27/200] [Batch 179/637] [D loss: 0.179945] [G loss: 0.536934]\n",
      "[Epoch 27/200] [Batch 180/637] [D loss: 0.163110] [G loss: 0.498431]\n",
      "[Epoch 27/200] [Batch 181/637] [D loss: 0.176599] [G loss: 0.415759]\n",
      "[Epoch 27/200] [Batch 182/637] [D loss: 0.194500] [G loss: 0.423670]\n",
      "[Epoch 27/200] [Batch 183/637] [D loss: 0.154102] [G loss: 0.625922]\n",
      "[Epoch 27/200] [Batch 184/637] [D loss: 0.169783] [G loss: 0.545307]\n",
      "[Epoch 27/200] [Batch 185/637] [D loss: 0.176092] [G loss: 0.495284]\n",
      "[Epoch 27/200] [Batch 186/637] [D loss: 0.164155] [G loss: 0.435552]\n",
      "[Epoch 27/200] [Batch 187/637] [D loss: 0.165533] [G loss: 0.471301]\n",
      "[Epoch 27/200] [Batch 188/637] [D loss: 0.165929] [G loss: 0.489450]\n",
      "[Epoch 27/200] [Batch 189/637] [D loss: 0.189677] [G loss: 0.481058]\n",
      "[Epoch 27/200] [Batch 190/637] [D loss: 0.180178] [G loss: 0.523182]\n",
      "[Epoch 27/200] [Batch 191/637] [D loss: 0.200699] [G loss: 0.471214]\n",
      "[Epoch 27/200] [Batch 192/637] [D loss: 0.180512] [G loss: 0.503245]\n",
      "[Epoch 27/200] [Batch 193/637] [D loss: 0.198114] [G loss: 0.417403]\n",
      "[Epoch 27/200] [Batch 194/637] [D loss: 0.154469] [G loss: 0.527393]\n",
      "[Epoch 27/200] [Batch 195/637] [D loss: 0.202232] [G loss: 0.469108]\n",
      "[Epoch 27/200] [Batch 196/637] [D loss: 0.194196] [G loss: 0.491353]\n",
      "[Epoch 27/200] [Batch 197/637] [D loss: 0.176910] [G loss: 0.449222]\n",
      "[Epoch 27/200] [Batch 198/637] [D loss: 0.188583] [G loss: 0.419506]\n",
      "[Epoch 27/200] [Batch 199/637] [D loss: 0.159173] [G loss: 0.508678]\n",
      "[Epoch 27/200] [Batch 200/637] [D loss: 0.193539] [G loss: 0.484418]\n",
      "[Epoch 27/200] [Batch 201/637] [D loss: 0.189309] [G loss: 0.505163]\n",
      "[Epoch 27/200] [Batch 202/637] [D loss: 0.179040] [G loss: 0.473036]\n",
      "[Epoch 27/200] [Batch 203/637] [D loss: 0.185309] [G loss: 0.441215]\n",
      "[Epoch 27/200] [Batch 204/637] [D loss: 0.186645] [G loss: 0.425182]\n",
      "[Epoch 27/200] [Batch 205/637] [D loss: 0.171603] [G loss: 0.510861]\n",
      "[Epoch 27/200] [Batch 206/637] [D loss: 0.177697] [G loss: 0.489537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/200] [Batch 207/637] [D loss: 0.157865] [G loss: 0.510190]\n",
      "[Epoch 27/200] [Batch 208/637] [D loss: 0.165937] [G loss: 0.524083]\n",
      "[Epoch 27/200] [Batch 209/637] [D loss: 0.174102] [G loss: 0.478573]\n",
      "[Epoch 27/200] [Batch 210/637] [D loss: 0.171584] [G loss: 0.462321]\n",
      "[Epoch 27/200] [Batch 211/637] [D loss: 0.185037] [G loss: 0.469240]\n",
      "[Epoch 27/200] [Batch 212/637] [D loss: 0.172968] [G loss: 0.465463]\n",
      "[Epoch 27/200] [Batch 213/637] [D loss: 0.153454] [G loss: 0.542647]\n",
      "[Epoch 27/200] [Batch 214/637] [D loss: 0.162564] [G loss: 0.487162]\n",
      "[Epoch 27/200] [Batch 215/637] [D loss: 0.168553] [G loss: 0.457964]\n",
      "[Epoch 27/200] [Batch 216/637] [D loss: 0.203721] [G loss: 0.423974]\n",
      "[Epoch 27/200] [Batch 217/637] [D loss: 0.186412] [G loss: 0.452919]\n",
      "[Epoch 27/200] [Batch 218/637] [D loss: 0.165086] [G loss: 0.478824]\n",
      "[Epoch 27/200] [Batch 219/637] [D loss: 0.181444] [G loss: 0.436376]\n",
      "[Epoch 27/200] [Batch 220/637] [D loss: 0.166294] [G loss: 0.435591]\n",
      "[Epoch 27/200] [Batch 221/637] [D loss: 0.173109] [G loss: 0.449659]\n",
      "[Epoch 27/200] [Batch 222/637] [D loss: 0.151423] [G loss: 0.471516]\n",
      "[Epoch 27/200] [Batch 223/637] [D loss: 0.164619] [G loss: 0.424321]\n",
      "[Epoch 27/200] [Batch 224/637] [D loss: 0.157665] [G loss: 0.421113]\n",
      "[Epoch 27/200] [Batch 225/637] [D loss: 0.178589] [G loss: 0.445947]\n",
      "[Epoch 27/200] [Batch 226/637] [D loss: 0.159460] [G loss: 0.481096]\n",
      "[Epoch 27/200] [Batch 227/637] [D loss: 0.146163] [G loss: 0.535686]\n",
      "[Epoch 27/200] [Batch 228/637] [D loss: 0.152010] [G loss: 0.482506]\n",
      "[Epoch 27/200] [Batch 229/637] [D loss: 0.151136] [G loss: 0.478832]\n",
      "[Epoch 27/200] [Batch 230/637] [D loss: 0.173479] [G loss: 0.498273]\n",
      "[Epoch 27/200] [Batch 231/637] [D loss: 0.153832] [G loss: 0.534493]\n",
      "[Epoch 27/200] [Batch 232/637] [D loss: 0.144223] [G loss: 0.503150]\n",
      "[Epoch 27/200] [Batch 233/637] [D loss: 0.169265] [G loss: 0.446170]\n",
      "[Epoch 27/200] [Batch 234/637] [D loss: 0.178759] [G loss: 0.420175]\n",
      "[Epoch 27/200] [Batch 235/637] [D loss: 0.172421] [G loss: 0.478607]\n",
      "[Epoch 27/200] [Batch 236/637] [D loss: 0.230899] [G loss: 0.459957]\n",
      "[Epoch 27/200] [Batch 237/637] [D loss: 0.158762] [G loss: 0.553010]\n",
      "[Epoch 27/200] [Batch 238/637] [D loss: 0.218310] [G loss: 0.441982]\n",
      "[Epoch 27/200] [Batch 239/637] [D loss: 0.182970] [G loss: 0.523614]\n",
      "[Epoch 27/200] [Batch 240/637] [D loss: 0.196512] [G loss: 0.470783]\n",
      "[Epoch 27/200] [Batch 241/637] [D loss: 0.169891] [G loss: 0.536995]\n",
      "[Epoch 27/200] [Batch 242/637] [D loss: 0.164721] [G loss: 0.575966]\n",
      "[Epoch 27/200] [Batch 243/637] [D loss: 0.156041] [G loss: 0.510483]\n",
      "[Epoch 27/200] [Batch 244/637] [D loss: 0.155507] [G loss: 0.476065]\n",
      "[Epoch 27/200] [Batch 245/637] [D loss: 0.160766] [G loss: 0.458267]\n",
      "[Epoch 27/200] [Batch 246/637] [D loss: 0.156570] [G loss: 0.556846]\n",
      "[Epoch 27/200] [Batch 247/637] [D loss: 0.178206] [G loss: 0.435408]\n",
      "[Epoch 27/200] [Batch 248/637] [D loss: 0.153554] [G loss: 0.615210]\n",
      "[Epoch 27/200] [Batch 249/637] [D loss: 0.180431] [G loss: 0.477668]\n",
      "[Epoch 27/200] [Batch 250/637] [D loss: 0.205441] [G loss: 0.468669]\n",
      "[Epoch 27/200] [Batch 251/637] [D loss: 0.169030] [G loss: 0.594214]\n",
      "[Epoch 27/200] [Batch 252/637] [D loss: 0.189924] [G loss: 0.522119]\n",
      "[Epoch 27/200] [Batch 253/637] [D loss: 0.162681] [G loss: 0.443683]\n",
      "[Epoch 27/200] [Batch 254/637] [D loss: 0.170540] [G loss: 0.444153]\n",
      "[Epoch 27/200] [Batch 255/637] [D loss: 0.165375] [G loss: 0.482437]\n",
      "[Epoch 27/200] [Batch 256/637] [D loss: 0.147704] [G loss: 0.537949]\n",
      "[Epoch 27/200] [Batch 257/637] [D loss: 0.149419] [G loss: 0.509612]\n",
      "[Epoch 27/200] [Batch 258/637] [D loss: 0.183254] [G loss: 0.482405]\n",
      "[Epoch 27/200] [Batch 259/637] [D loss: 0.159856] [G loss: 0.527209]\n",
      "[Epoch 27/200] [Batch 260/637] [D loss: 0.184524] [G loss: 0.569991]\n",
      "[Epoch 27/200] [Batch 261/637] [D loss: 0.165387] [G loss: 0.554886]\n",
      "[Epoch 27/200] [Batch 262/637] [D loss: 0.197596] [G loss: 0.499313]\n",
      "[Epoch 27/200] [Batch 263/637] [D loss: 0.156386] [G loss: 0.576133]\n",
      "[Epoch 27/200] [Batch 264/637] [D loss: 0.206968] [G loss: 0.479043]\n",
      "[Epoch 27/200] [Batch 265/637] [D loss: 0.171458] [G loss: 0.564087]\n",
      "[Epoch 27/200] [Batch 266/637] [D loss: 0.191712] [G loss: 0.541373]\n",
      "[Epoch 27/200] [Batch 267/637] [D loss: 0.167415] [G loss: 0.492076]\n",
      "[Epoch 27/200] [Batch 268/637] [D loss: 0.200734] [G loss: 0.351811]\n",
      "[Epoch 27/200] [Batch 269/637] [D loss: 0.192230] [G loss: 0.488742]\n",
      "[Epoch 27/200] [Batch 270/637] [D loss: 0.187073] [G loss: 0.508138]\n",
      "[Epoch 27/200] [Batch 271/637] [D loss: 0.209127] [G loss: 0.412145]\n",
      "[Epoch 27/200] [Batch 272/637] [D loss: 0.179419] [G loss: 0.511238]\n",
      "[Epoch 27/200] [Batch 273/637] [D loss: 0.183645] [G loss: 0.447467]\n",
      "[Epoch 27/200] [Batch 274/637] [D loss: 0.162738] [G loss: 0.483206]\n",
      "[Epoch 27/200] [Batch 275/637] [D loss: 0.172245] [G loss: 0.471706]\n",
      "[Epoch 27/200] [Batch 276/637] [D loss: 0.178956] [G loss: 0.450990]\n",
      "[Epoch 27/200] [Batch 277/637] [D loss: 0.190796] [G loss: 0.483298]\n",
      "[Epoch 27/200] [Batch 278/637] [D loss: 0.157547] [G loss: 0.486130]\n",
      "[Epoch 27/200] [Batch 279/637] [D loss: 0.166503] [G loss: 0.453862]\n",
      "[Epoch 27/200] [Batch 280/637] [D loss: 0.159088] [G loss: 0.494134]\n",
      "[Epoch 27/200] [Batch 281/637] [D loss: 0.170932] [G loss: 0.473651]\n",
      "[Epoch 27/200] [Batch 282/637] [D loss: 0.142521] [G loss: 0.552925]\n",
      "[Epoch 27/200] [Batch 283/637] [D loss: 0.168436] [G loss: 0.453345]\n",
      "[Epoch 27/200] [Batch 284/637] [D loss: 0.263443] [G loss: 0.429888]\n",
      "[Epoch 27/200] [Batch 285/637] [D loss: 0.178872] [G loss: 0.613066]\n",
      "[Epoch 27/200] [Batch 286/637] [D loss: 0.183268] [G loss: 0.622651]\n",
      "[Epoch 27/200] [Batch 287/637] [D loss: 0.186239] [G loss: 0.434754]\n",
      "[Epoch 27/200] [Batch 288/637] [D loss: 0.172618] [G loss: 0.428889]\n",
      "[Epoch 27/200] [Batch 289/637] [D loss: 0.154812] [G loss: 0.549855]\n",
      "[Epoch 27/200] [Batch 290/637] [D loss: 0.166806] [G loss: 0.484328]\n",
      "[Epoch 27/200] [Batch 291/637] [D loss: 0.168715] [G loss: 0.482542]\n",
      "[Epoch 27/200] [Batch 292/637] [D loss: 0.169549] [G loss: 0.510779]\n",
      "[Epoch 27/200] [Batch 293/637] [D loss: 0.173521] [G loss: 0.498467]\n",
      "[Epoch 27/200] [Batch 294/637] [D loss: 0.168770] [G loss: 0.482110]\n",
      "[Epoch 27/200] [Batch 295/637] [D loss: 0.165278] [G loss: 0.446291]\n",
      "[Epoch 27/200] [Batch 296/637] [D loss: 0.186574] [G loss: 0.454569]\n",
      "[Epoch 27/200] [Batch 297/637] [D loss: 0.185221] [G loss: 0.459640]\n",
      "[Epoch 27/200] [Batch 298/637] [D loss: 0.184187] [G loss: 0.474172]\n",
      "[Epoch 27/200] [Batch 299/637] [D loss: 0.164616] [G loss: 0.452299]\n",
      "[Epoch 27/200] [Batch 300/637] [D loss: 0.180186] [G loss: 0.478406]\n",
      "[Epoch 27/200] [Batch 301/637] [D loss: 0.182510] [G loss: 0.454992]\n",
      "[Epoch 27/200] [Batch 302/637] [D loss: 0.190149] [G loss: 0.508728]\n",
      "[Epoch 27/200] [Batch 303/637] [D loss: 0.174532] [G loss: 0.572915]\n",
      "[Epoch 27/200] [Batch 304/637] [D loss: 0.177960] [G loss: 0.517128]\n",
      "[Epoch 27/200] [Batch 305/637] [D loss: 0.174842] [G loss: 0.429268]\n",
      "[Epoch 27/200] [Batch 306/637] [D loss: 0.166118] [G loss: 0.528265]\n",
      "[Epoch 27/200] [Batch 307/637] [D loss: 0.189429] [G loss: 0.518931]\n",
      "[Epoch 27/200] [Batch 308/637] [D loss: 0.151733] [G loss: 0.498399]\n",
      "[Epoch 27/200] [Batch 309/637] [D loss: 0.168465] [G loss: 0.466225]\n",
      "[Epoch 27/200] [Batch 310/637] [D loss: 0.149514] [G loss: 0.475786]\n",
      "[Epoch 27/200] [Batch 311/637] [D loss: 0.171900] [G loss: 0.440405]\n",
      "[Epoch 27/200] [Batch 312/637] [D loss: 0.148126] [G loss: 0.482500]\n",
      "[Epoch 27/200] [Batch 313/637] [D loss: 0.181004] [G loss: 0.542713]\n",
      "[Epoch 27/200] [Batch 314/637] [D loss: 0.168112] [G loss: 0.496002]\n",
      "[Epoch 27/200] [Batch 315/637] [D loss: 0.160224] [G loss: 0.531545]\n",
      "[Epoch 27/200] [Batch 316/637] [D loss: 0.169020] [G loss: 0.474188]\n",
      "[Epoch 27/200] [Batch 317/637] [D loss: 0.204925] [G loss: 0.427883]\n",
      "[Epoch 27/200] [Batch 318/637] [D loss: 0.165555] [G loss: 0.545064]\n",
      "[Epoch 27/200] [Batch 319/637] [D loss: 0.161352] [G loss: 0.500445]\n",
      "[Epoch 27/200] [Batch 320/637] [D loss: 0.166744] [G loss: 0.486755]\n",
      "[Epoch 27/200] [Batch 321/637] [D loss: 0.156737] [G loss: 0.444154]\n",
      "[Epoch 27/200] [Batch 322/637] [D loss: 0.162100] [G loss: 0.572014]\n",
      "[Epoch 27/200] [Batch 323/637] [D loss: 0.159842] [G loss: 0.527573]\n",
      "[Epoch 27/200] [Batch 324/637] [D loss: 0.141114] [G loss: 0.517579]\n",
      "[Epoch 27/200] [Batch 325/637] [D loss: 0.188829] [G loss: 0.527428]\n",
      "[Epoch 27/200] [Batch 326/637] [D loss: 0.165878] [G loss: 0.480700]\n",
      "[Epoch 27/200] [Batch 327/637] [D loss: 0.164160] [G loss: 0.495837]\n",
      "[Epoch 27/200] [Batch 328/637] [D loss: 0.179986] [G loss: 0.471796]\n",
      "[Epoch 27/200] [Batch 329/637] [D loss: 0.169580] [G loss: 0.428363]\n",
      "[Epoch 27/200] [Batch 330/637] [D loss: 0.173804] [G loss: 0.469737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/200] [Batch 331/637] [D loss: 0.165876] [G loss: 0.454957]\n",
      "[Epoch 27/200] [Batch 332/637] [D loss: 0.183993] [G loss: 0.441039]\n",
      "[Epoch 27/200] [Batch 333/637] [D loss: 0.169831] [G loss: 0.501249]\n",
      "[Epoch 27/200] [Batch 334/637] [D loss: 0.172333] [G loss: 0.525988]\n",
      "[Epoch 27/200] [Batch 335/637] [D loss: 0.210661] [G loss: 0.504008]\n",
      "[Epoch 27/200] [Batch 336/637] [D loss: 0.163372] [G loss: 0.464759]\n",
      "[Epoch 27/200] [Batch 337/637] [D loss: 0.194609] [G loss: 0.464731]\n",
      "[Epoch 27/200] [Batch 338/637] [D loss: 0.161960] [G loss: 0.506893]\n",
      "[Epoch 27/200] [Batch 339/637] [D loss: 0.181979] [G loss: 0.477823]\n",
      "[Epoch 27/200] [Batch 340/637] [D loss: 0.156136] [G loss: 0.504556]\n",
      "[Epoch 27/200] [Batch 341/637] [D loss: 0.171065] [G loss: 0.476768]\n",
      "[Epoch 27/200] [Batch 342/637] [D loss: 0.181461] [G loss: 0.471794]\n",
      "[Epoch 27/200] [Batch 343/637] [D loss: 0.162530] [G loss: 0.518164]\n",
      "[Epoch 27/200] [Batch 344/637] [D loss: 0.199143] [G loss: 0.509219]\n",
      "[Epoch 27/200] [Batch 345/637] [D loss: 0.158531] [G loss: 0.518809]\n",
      "[Epoch 27/200] [Batch 346/637] [D loss: 0.170233] [G loss: 0.519488]\n",
      "[Epoch 27/200] [Batch 347/637] [D loss: 0.168103] [G loss: 0.505856]\n",
      "[Epoch 27/200] [Batch 348/637] [D loss: 0.174679] [G loss: 0.502809]\n",
      "[Epoch 27/200] [Batch 349/637] [D loss: 0.144060] [G loss: 0.496392]\n",
      "[Epoch 27/200] [Batch 350/637] [D loss: 0.190619] [G loss: 0.450194]\n",
      "[Epoch 27/200] [Batch 351/637] [D loss: 0.172328] [G loss: 0.541136]\n",
      "[Epoch 27/200] [Batch 352/637] [D loss: 0.196127] [G loss: 0.520319]\n",
      "[Epoch 27/200] [Batch 353/637] [D loss: 0.180059] [G loss: 0.452736]\n",
      "[Epoch 27/200] [Batch 354/637] [D loss: 0.190742] [G loss: 0.462335]\n",
      "[Epoch 27/200] [Batch 355/637] [D loss: 0.192568] [G loss: 0.489069]\n",
      "[Epoch 27/200] [Batch 356/637] [D loss: 0.161792] [G loss: 0.450579]\n",
      "[Epoch 27/200] [Batch 357/637] [D loss: 0.178106] [G loss: 0.448263]\n",
      "[Epoch 27/200] [Batch 358/637] [D loss: 0.152220] [G loss: 0.477924]\n",
      "[Epoch 27/200] [Batch 359/637] [D loss: 0.178329] [G loss: 0.426454]\n",
      "[Epoch 27/200] [Batch 360/637] [D loss: 0.178479] [G loss: 0.472815]\n",
      "[Epoch 27/200] [Batch 361/637] [D loss: 0.166989] [G loss: 0.442788]\n",
      "[Epoch 27/200] [Batch 362/637] [D loss: 0.149220] [G loss: 0.486982]\n",
      "[Epoch 27/200] [Batch 363/637] [D loss: 0.193302] [G loss: 0.433170]\n",
      "[Epoch 27/200] [Batch 364/637] [D loss: 0.173592] [G loss: 0.552830]\n",
      "[Epoch 27/200] [Batch 365/637] [D loss: 0.174212] [G loss: 0.561644]\n",
      "[Epoch 27/200] [Batch 366/637] [D loss: 0.182828] [G loss: 0.437856]\n",
      "[Epoch 27/200] [Batch 367/637] [D loss: 0.165150] [G loss: 0.424298]\n",
      "[Epoch 27/200] [Batch 368/637] [D loss: 0.163467] [G loss: 0.430612]\n",
      "[Epoch 27/200] [Batch 369/637] [D loss: 0.166685] [G loss: 0.536972]\n",
      "[Epoch 27/200] [Batch 370/637] [D loss: 0.171039] [G loss: 0.519529]\n",
      "[Epoch 27/200] [Batch 371/637] [D loss: 0.161720] [G loss: 0.446521]\n",
      "[Epoch 27/200] [Batch 372/637] [D loss: 0.144688] [G loss: 0.476225]\n",
      "[Epoch 27/200] [Batch 373/637] [D loss: 0.158775] [G loss: 0.530375]\n",
      "[Epoch 27/200] [Batch 374/637] [D loss: 0.161768] [G loss: 0.557732]\n",
      "[Epoch 27/200] [Batch 375/637] [D loss: 0.160296] [G loss: 0.500381]\n",
      "[Epoch 27/200] [Batch 376/637] [D loss: 0.178316] [G loss: 0.455103]\n",
      "[Epoch 27/200] [Batch 377/637] [D loss: 0.167693] [G loss: 0.596673]\n",
      "[Epoch 27/200] [Batch 378/637] [D loss: 0.214412] [G loss: 0.415109]\n",
      "[Epoch 27/200] [Batch 379/637] [D loss: 0.171621] [G loss: 0.606295]\n",
      "[Epoch 27/200] [Batch 380/637] [D loss: 0.167623] [G loss: 0.593247]\n",
      "[Epoch 27/200] [Batch 381/637] [D loss: 0.177760] [G loss: 0.487813]\n",
      "[Epoch 27/200] [Batch 382/637] [D loss: 0.156135] [G loss: 0.465400]\n",
      "[Epoch 27/200] [Batch 383/637] [D loss: 0.152548] [G loss: 0.450442]\n",
      "[Epoch 27/200] [Batch 384/637] [D loss: 0.172593] [G loss: 0.480469]\n",
      "[Epoch 27/200] [Batch 385/637] [D loss: 0.151306] [G loss: 0.515177]\n",
      "[Epoch 27/200] [Batch 386/637] [D loss: 0.154549] [G loss: 0.554269]\n",
      "[Epoch 27/200] [Batch 387/637] [D loss: 0.151011] [G loss: 0.532144]\n",
      "[Epoch 27/200] [Batch 388/637] [D loss: 0.170927] [G loss: 0.526018]\n",
      "[Epoch 27/200] [Batch 389/637] [D loss: 0.131566] [G loss: 0.528483]\n",
      "[Epoch 27/200] [Batch 390/637] [D loss: 0.172121] [G loss: 0.529320]\n",
      "[Epoch 27/200] [Batch 391/637] [D loss: 0.152505] [G loss: 0.578630]\n",
      "[Epoch 27/200] [Batch 392/637] [D loss: 0.179925] [G loss: 0.492474]\n",
      "[Epoch 27/200] [Batch 393/637] [D loss: 0.156346] [G loss: 0.540401]\n",
      "[Epoch 27/200] [Batch 394/637] [D loss: 0.175457] [G loss: 0.425456]\n",
      "[Epoch 27/200] [Batch 395/637] [D loss: 0.165031] [G loss: 0.452592]\n",
      "[Epoch 27/200] [Batch 396/637] [D loss: 0.184432] [G loss: 0.538917]\n",
      "[Epoch 27/200] [Batch 397/637] [D loss: 0.168018] [G loss: 0.568522]\n",
      "[Epoch 27/200] [Batch 398/637] [D loss: 0.203330] [G loss: 0.489872]\n",
      "[Epoch 27/200] [Batch 399/637] [D loss: 0.187894] [G loss: 0.373182]\n",
      "[Epoch 27/200] [Batch 400/637] [D loss: 0.188520] [G loss: 0.381565]\n",
      "[Epoch 27/200] [Batch 401/637] [D loss: 0.168357] [G loss: 0.475670]\n",
      "[Epoch 27/200] [Batch 402/637] [D loss: 0.183727] [G loss: 0.471000]\n",
      "[Epoch 27/200] [Batch 403/637] [D loss: 0.190600] [G loss: 0.445141]\n",
      "[Epoch 27/200] [Batch 404/637] [D loss: 0.181147] [G loss: 0.520122]\n",
      "[Epoch 27/200] [Batch 405/637] [D loss: 0.170058] [G loss: 0.508874]\n",
      "[Epoch 27/200] [Batch 406/637] [D loss: 0.195665] [G loss: 0.400389]\n",
      "[Epoch 27/200] [Batch 407/637] [D loss: 0.180795] [G loss: 0.509319]\n",
      "[Epoch 27/200] [Batch 408/637] [D loss: 0.174551] [G loss: 0.539440]\n",
      "[Epoch 27/200] [Batch 409/637] [D loss: 0.181279] [G loss: 0.444815]\n",
      "[Epoch 27/200] [Batch 410/637] [D loss: 0.193051] [G loss: 0.419381]\n",
      "[Epoch 27/200] [Batch 411/637] [D loss: 0.256761] [G loss: 0.410455]\n",
      "[Epoch 27/200] [Batch 412/637] [D loss: 0.204470] [G loss: 0.517419]\n",
      "[Epoch 27/200] [Batch 413/637] [D loss: 0.177881] [G loss: 0.517235]\n",
      "[Epoch 27/200] [Batch 414/637] [D loss: 0.165537] [G loss: 0.466059]\n",
      "[Epoch 27/200] [Batch 415/637] [D loss: 0.169830] [G loss: 0.476123]\n",
      "[Epoch 27/200] [Batch 416/637] [D loss: 0.177351] [G loss: 0.447189]\n",
      "[Epoch 27/200] [Batch 417/637] [D loss: 0.164398] [G loss: 0.474122]\n",
      "[Epoch 27/200] [Batch 418/637] [D loss: 0.164200] [G loss: 0.496268]\n",
      "[Epoch 27/200] [Batch 419/637] [D loss: 0.163294] [G loss: 0.510817]\n",
      "[Epoch 27/200] [Batch 420/637] [D loss: 0.183590] [G loss: 0.514299]\n",
      "[Epoch 27/200] [Batch 421/637] [D loss: 0.173673] [G loss: 0.530631]\n",
      "[Epoch 27/200] [Batch 422/637] [D loss: 0.147553] [G loss: 0.533634]\n",
      "[Epoch 27/200] [Batch 423/637] [D loss: 0.174749] [G loss: 0.446062]\n",
      "[Epoch 27/200] [Batch 424/637] [D loss: 0.168186] [G loss: 0.514918]\n",
      "[Epoch 27/200] [Batch 425/637] [D loss: 0.213124] [G loss: 0.522128]\n",
      "[Epoch 27/200] [Batch 426/637] [D loss: 0.150181] [G loss: 0.495436]\n",
      "[Epoch 27/200] [Batch 427/637] [D loss: 0.232006] [G loss: 0.462498]\n",
      "[Epoch 27/200] [Batch 428/637] [D loss: 0.186020] [G loss: 0.571513]\n",
      "[Epoch 27/200] [Batch 429/637] [D loss: 0.200625] [G loss: 0.581232]\n",
      "[Epoch 27/200] [Batch 430/637] [D loss: 0.175015] [G loss: 0.462879]\n",
      "[Epoch 27/200] [Batch 431/637] [D loss: 0.204809] [G loss: 0.334065]\n",
      "[Epoch 27/200] [Batch 432/637] [D loss: 0.214216] [G loss: 0.511914]\n",
      "[Epoch 27/200] [Batch 433/637] [D loss: 0.160983] [G loss: 0.557379]\n",
      "[Epoch 27/200] [Batch 434/637] [D loss: 0.193769] [G loss: 0.515730]\n",
      "[Epoch 27/200] [Batch 435/637] [D loss: 0.158783] [G loss: 0.460958]\n",
      "[Epoch 27/200] [Batch 436/637] [D loss: 0.146996] [G loss: 0.519088]\n",
      "[Epoch 27/200] [Batch 437/637] [D loss: 0.156959] [G loss: 0.478422]\n",
      "[Epoch 27/200] [Batch 438/637] [D loss: 0.144403] [G loss: 0.500372]\n",
      "[Epoch 27/200] [Batch 439/637] [D loss: 0.159475] [G loss: 0.589099]\n",
      "[Epoch 27/200] [Batch 440/637] [D loss: 0.158947] [G loss: 0.576509]\n",
      "[Epoch 27/200] [Batch 441/637] [D loss: 0.189599] [G loss: 0.436573]\n",
      "[Epoch 27/200] [Batch 442/637] [D loss: 0.154317] [G loss: 0.527509]\n",
      "[Epoch 27/200] [Batch 443/637] [D loss: 0.162502] [G loss: 0.496734]\n",
      "[Epoch 27/200] [Batch 444/637] [D loss: 0.152380] [G loss: 0.531695]\n",
      "[Epoch 27/200] [Batch 445/637] [D loss: 0.137052] [G loss: 0.562594]\n",
      "[Epoch 27/200] [Batch 446/637] [D loss: 0.180505] [G loss: 0.524419]\n",
      "[Epoch 27/200] [Batch 447/637] [D loss: 0.185332] [G loss: 0.605897]\n",
      "[Epoch 27/200] [Batch 448/637] [D loss: 0.177618] [G loss: 0.548301]\n",
      "[Epoch 27/200] [Batch 449/637] [D loss: 0.165956] [G loss: 0.542374]\n",
      "[Epoch 27/200] [Batch 450/637] [D loss: 0.165018] [G loss: 0.477365]\n",
      "[Epoch 27/200] [Batch 451/637] [D loss: 0.197605] [G loss: 0.430920]\n",
      "[Epoch 27/200] [Batch 452/637] [D loss: 0.173867] [G loss: 0.512817]\n",
      "[Epoch 27/200] [Batch 453/637] [D loss: 0.177039] [G loss: 0.456823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/200] [Batch 454/637] [D loss: 0.186732] [G loss: 0.456003]\n",
      "[Epoch 27/200] [Batch 455/637] [D loss: 0.180586] [G loss: 0.484350]\n",
      "[Epoch 27/200] [Batch 456/637] [D loss: 0.167401] [G loss: 0.471513]\n",
      "[Epoch 27/200] [Batch 457/637] [D loss: 0.160531] [G loss: 0.520087]\n",
      "[Epoch 27/200] [Batch 458/637] [D loss: 0.165179] [G loss: 0.458853]\n",
      "[Epoch 27/200] [Batch 459/637] [D loss: 0.185696] [G loss: 0.433897]\n",
      "[Epoch 27/200] [Batch 460/637] [D loss: 0.179245] [G loss: 0.506106]\n",
      "[Epoch 27/200] [Batch 461/637] [D loss: 0.190062] [G loss: 0.445969]\n",
      "[Epoch 27/200] [Batch 462/637] [D loss: 0.193472] [G loss: 0.516940]\n",
      "[Epoch 27/200] [Batch 463/637] [D loss: 0.164217] [G loss: 0.493844]\n",
      "[Epoch 27/200] [Batch 464/637] [D loss: 0.149092] [G loss: 0.494502]\n",
      "[Epoch 27/200] [Batch 465/637] [D loss: 0.167252] [G loss: 0.461930]\n",
      "[Epoch 27/200] [Batch 466/637] [D loss: 0.168940] [G loss: 0.408598]\n",
      "[Epoch 27/200] [Batch 467/637] [D loss: 0.148865] [G loss: 0.515815]\n",
      "[Epoch 27/200] [Batch 468/637] [D loss: 0.182566] [G loss: 0.493659]\n",
      "[Epoch 27/200] [Batch 469/637] [D loss: 0.203797] [G loss: 0.426133]\n",
      "[Epoch 27/200] [Batch 470/637] [D loss: 0.167077] [G loss: 0.542696]\n",
      "[Epoch 27/200] [Batch 471/637] [D loss: 0.188103] [G loss: 0.498813]\n",
      "[Epoch 27/200] [Batch 472/637] [D loss: 0.201290] [G loss: 0.450958]\n",
      "[Epoch 27/200] [Batch 473/637] [D loss: 0.172877] [G loss: 0.583410]\n",
      "[Epoch 27/200] [Batch 474/637] [D loss: 0.175529] [G loss: 0.523180]\n",
      "[Epoch 27/200] [Batch 475/637] [D loss: 0.164562] [G loss: 0.472357]\n",
      "[Epoch 27/200] [Batch 476/637] [D loss: 0.169207] [G loss: 0.433159]\n",
      "[Epoch 27/200] [Batch 477/637] [D loss: 0.181289] [G loss: 0.436611]\n",
      "[Epoch 27/200] [Batch 478/637] [D loss: 0.155410] [G loss: 0.449351]\n",
      "[Epoch 27/200] [Batch 479/637] [D loss: 0.177235] [G loss: 0.486800]\n",
      "[Epoch 27/200] [Batch 480/637] [D loss: 0.169962] [G loss: 0.504276]\n",
      "[Epoch 27/200] [Batch 481/637] [D loss: 0.180941] [G loss: 0.499163]\n",
      "[Epoch 27/200] [Batch 482/637] [D loss: 0.158691] [G loss: 0.624920]\n",
      "[Epoch 27/200] [Batch 483/637] [D loss: 0.171339] [G loss: 0.508512]\n",
      "[Epoch 27/200] [Batch 484/637] [D loss: 0.177119] [G loss: 0.412730]\n",
      "[Epoch 27/200] [Batch 485/637] [D loss: 0.161867] [G loss: 0.476931]\n",
      "[Epoch 27/200] [Batch 486/637] [D loss: 0.172505] [G loss: 0.473650]\n",
      "[Epoch 27/200] [Batch 487/637] [D loss: 0.138891] [G loss: 0.553084]\n",
      "[Epoch 27/200] [Batch 488/637] [D loss: 0.182970] [G loss: 0.529150]\n",
      "[Epoch 27/200] [Batch 489/637] [D loss: 0.168073] [G loss: 0.608927]\n",
      "[Epoch 27/200] [Batch 490/637] [D loss: 0.158476] [G loss: 0.562549]\n",
      "[Epoch 27/200] [Batch 491/637] [D loss: 0.192990] [G loss: 0.423625]\n",
      "[Epoch 27/200] [Batch 492/637] [D loss: 0.154439] [G loss: 0.500398]\n",
      "[Epoch 27/200] [Batch 493/637] [D loss: 0.169941] [G loss: 0.464656]\n",
      "[Epoch 27/200] [Batch 494/637] [D loss: 0.173987] [G loss: 0.456301]\n",
      "[Epoch 27/200] [Batch 495/637] [D loss: 0.165471] [G loss: 0.501348]\n",
      "[Epoch 27/200] [Batch 496/637] [D loss: 0.192905] [G loss: 0.457907]\n",
      "[Epoch 27/200] [Batch 497/637] [D loss: 0.144834] [G loss: 0.574524]\n",
      "[Epoch 27/200] [Batch 498/637] [D loss: 0.166633] [G loss: 0.537454]\n",
      "[Epoch 27/200] [Batch 499/637] [D loss: 0.157362] [G loss: 0.461926]\n",
      "[Epoch 27/200] [Batch 500/637] [D loss: 0.170389] [G loss: 0.521219]\n",
      "[Epoch 27/200] [Batch 501/637] [D loss: 0.173393] [G loss: 0.470584]\n",
      "[Epoch 27/200] [Batch 502/637] [D loss: 0.172639] [G loss: 0.519941]\n",
      "[Epoch 27/200] [Batch 503/637] [D loss: 0.164358] [G loss: 0.536806]\n",
      "[Epoch 27/200] [Batch 504/637] [D loss: 0.174427] [G loss: 0.521893]\n",
      "[Epoch 27/200] [Batch 505/637] [D loss: 0.167537] [G loss: 0.488992]\n",
      "[Epoch 27/200] [Batch 506/637] [D loss: 0.165788] [G loss: 0.437386]\n",
      "[Epoch 27/200] [Batch 507/637] [D loss: 0.158922] [G loss: 0.465978]\n",
      "[Epoch 27/200] [Batch 508/637] [D loss: 0.170040] [G loss: 0.557518]\n",
      "[Epoch 27/200] [Batch 509/637] [D loss: 0.155166] [G loss: 0.506204]\n",
      "[Epoch 27/200] [Batch 510/637] [D loss: 0.183560] [G loss: 0.409615]\n",
      "[Epoch 27/200] [Batch 511/637] [D loss: 0.153187] [G loss: 0.601252]\n",
      "[Epoch 27/200] [Batch 512/637] [D loss: 0.178886] [G loss: 0.498881]\n",
      "[Epoch 27/200] [Batch 513/637] [D loss: 0.168812] [G loss: 0.499246]\n",
      "[Epoch 27/200] [Batch 514/637] [D loss: 0.167998] [G loss: 0.472682]\n",
      "[Epoch 27/200] [Batch 515/637] [D loss: 0.154889] [G loss: 0.513686]\n",
      "[Epoch 27/200] [Batch 516/637] [D loss: 0.183563] [G loss: 0.481549]\n",
      "[Epoch 27/200] [Batch 517/637] [D loss: 0.174341] [G loss: 0.506372]\n",
      "[Epoch 27/200] [Batch 518/637] [D loss: 0.160356] [G loss: 0.433102]\n",
      "[Epoch 27/200] [Batch 519/637] [D loss: 0.169086] [G loss: 0.434759]\n",
      "[Epoch 27/200] [Batch 520/637] [D loss: 0.183458] [G loss: 0.487453]\n",
      "[Epoch 27/200] [Batch 521/637] [D loss: 0.177964] [G loss: 0.413359]\n",
      "[Epoch 27/200] [Batch 522/637] [D loss: 0.142015] [G loss: 0.516777]\n",
      "[Epoch 27/200] [Batch 523/637] [D loss: 0.158746] [G loss: 0.524754]\n",
      "[Epoch 27/200] [Batch 524/637] [D loss: 0.170003] [G loss: 0.546196]\n",
      "[Epoch 27/200] [Batch 525/637] [D loss: 0.147142] [G loss: 0.596477]\n",
      "[Epoch 27/200] [Batch 526/637] [D loss: 0.160380] [G loss: 0.465314]\n",
      "[Epoch 27/200] [Batch 527/637] [D loss: 0.153041] [G loss: 0.464108]\n",
      "[Epoch 27/200] [Batch 528/637] [D loss: 0.176717] [G loss: 0.433774]\n",
      "[Epoch 27/200] [Batch 529/637] [D loss: 0.167939] [G loss: 0.624828]\n",
      "[Epoch 27/200] [Batch 530/637] [D loss: 0.164060] [G loss: 0.668347]\n",
      "[Epoch 27/200] [Batch 531/637] [D loss: 0.179121] [G loss: 0.521755]\n",
      "[Epoch 27/200] [Batch 532/637] [D loss: 0.166209] [G loss: 0.459058]\n",
      "[Epoch 27/200] [Batch 533/637] [D loss: 0.173055] [G loss: 0.442977]\n",
      "[Epoch 27/200] [Batch 534/637] [D loss: 0.174293] [G loss: 0.457189]\n",
      "[Epoch 27/200] [Batch 535/637] [D loss: 0.152620] [G loss: 0.455186]\n",
      "[Epoch 27/200] [Batch 536/637] [D loss: 0.200615] [G loss: 0.470838]\n",
      "[Epoch 27/200] [Batch 537/637] [D loss: 0.183219] [G loss: 0.525784]\n",
      "[Epoch 27/200] [Batch 538/637] [D loss: 0.144019] [G loss: 0.546975]\n",
      "[Epoch 27/200] [Batch 539/637] [D loss: 0.144166] [G loss: 0.461063]\n",
      "[Epoch 27/200] [Batch 540/637] [D loss: 0.180846] [G loss: 0.444763]\n",
      "[Epoch 27/200] [Batch 541/637] [D loss: 0.148074] [G loss: 0.569802]\n",
      "[Epoch 27/200] [Batch 542/637] [D loss: 0.161613] [G loss: 0.573211]\n",
      "[Epoch 27/200] [Batch 543/637] [D loss: 0.171899] [G loss: 0.478223]\n",
      "[Epoch 27/200] [Batch 544/637] [D loss: 0.172433] [G loss: 0.435848]\n",
      "[Epoch 27/200] [Batch 545/637] [D loss: 0.182559] [G loss: 0.487485]\n",
      "[Epoch 27/200] [Batch 546/637] [D loss: 0.200547] [G loss: 0.448021]\n",
      "[Epoch 27/200] [Batch 547/637] [D loss: 0.170215] [G loss: 0.574225]\n",
      "[Epoch 27/200] [Batch 548/637] [D loss: 0.171934] [G loss: 0.516398]\n",
      "[Epoch 27/200] [Batch 549/637] [D loss: 0.184020] [G loss: 0.504445]\n",
      "[Epoch 27/200] [Batch 550/637] [D loss: 0.166683] [G loss: 0.508272]\n",
      "[Epoch 27/200] [Batch 551/637] [D loss: 0.187878] [G loss: 0.543605]\n",
      "[Epoch 27/200] [Batch 552/637] [D loss: 0.160632] [G loss: 0.575514]\n",
      "[Epoch 27/200] [Batch 553/637] [D loss: 0.165328] [G loss: 0.563139]\n",
      "[Epoch 27/200] [Batch 554/637] [D loss: 0.155517] [G loss: 0.510960]\n",
      "[Epoch 27/200] [Batch 555/637] [D loss: 0.180052] [G loss: 0.440679]\n",
      "[Epoch 27/200] [Batch 556/637] [D loss: 0.154964] [G loss: 0.517696]\n",
      "[Epoch 27/200] [Batch 557/637] [D loss: 0.163648] [G loss: 0.549898]\n",
      "[Epoch 27/200] [Batch 558/637] [D loss: 0.185993] [G loss: 0.506447]\n",
      "[Epoch 27/200] [Batch 559/637] [D loss: 0.138419] [G loss: 0.513345]\n",
      "[Epoch 27/200] [Batch 560/637] [D loss: 0.198358] [G loss: 0.471890]\n",
      "[Epoch 27/200] [Batch 561/637] [D loss: 0.176950] [G loss: 0.486095]\n",
      "[Epoch 27/200] [Batch 562/637] [D loss: 0.166250] [G loss: 0.575625]\n",
      "[Epoch 27/200] [Batch 563/637] [D loss: 0.183632] [G loss: 0.488061]\n",
      "[Epoch 27/200] [Batch 564/637] [D loss: 0.164178] [G loss: 0.478138]\n",
      "[Epoch 27/200] [Batch 565/637] [D loss: 0.166659] [G loss: 0.444353]\n",
      "[Epoch 27/200] [Batch 566/637] [D loss: 0.152835] [G loss: 0.500850]\n",
      "[Epoch 27/200] [Batch 567/637] [D loss: 0.169585] [G loss: 0.485000]\n",
      "[Epoch 27/200] [Batch 568/637] [D loss: 0.164650] [G loss: 0.420417]\n",
      "[Epoch 27/200] [Batch 569/637] [D loss: 0.171766] [G loss: 0.467733]\n",
      "[Epoch 27/200] [Batch 570/637] [D loss: 0.177952] [G loss: 0.467230]\n",
      "[Epoch 27/200] [Batch 571/637] [D loss: 0.181817] [G loss: 0.467642]\n",
      "[Epoch 27/200] [Batch 572/637] [D loss: 0.182488] [G loss: 0.548694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/200] [Batch 573/637] [D loss: 0.177709] [G loss: 0.482488]\n",
      "[Epoch 27/200] [Batch 574/637] [D loss: 0.224721] [G loss: 0.380319]\n",
      "[Epoch 27/200] [Batch 575/637] [D loss: 0.171168] [G loss: 0.554680]\n",
      "[Epoch 27/200] [Batch 576/637] [D loss: 0.170821] [G loss: 0.602360]\n",
      "[Epoch 27/200] [Batch 577/637] [D loss: 0.175928] [G loss: 0.517709]\n",
      "[Epoch 27/200] [Batch 578/637] [D loss: 0.162584] [G loss: 0.523871]\n",
      "[Epoch 27/200] [Batch 579/637] [D loss: 0.188847] [G loss: 0.458510]\n",
      "[Epoch 27/200] [Batch 580/637] [D loss: 0.158957] [G loss: 0.587971]\n",
      "[Epoch 27/200] [Batch 581/637] [D loss: 0.167051] [G loss: 0.565650]\n",
      "[Epoch 27/200] [Batch 582/637] [D loss: 0.158485] [G loss: 0.497373]\n",
      "[Epoch 27/200] [Batch 583/637] [D loss: 0.139471] [G loss: 0.501255]\n",
      "[Epoch 27/200] [Batch 584/637] [D loss: 0.158292] [G loss: 0.466765]\n",
      "[Epoch 27/200] [Batch 585/637] [D loss: 0.185107] [G loss: 0.494162]\n",
      "[Epoch 27/200] [Batch 586/637] [D loss: 0.147889] [G loss: 0.574780]\n",
      "[Epoch 27/200] [Batch 587/637] [D loss: 0.137723] [G loss: 0.549555]\n",
      "[Epoch 27/200] [Batch 588/637] [D loss: 0.174828] [G loss: 0.487064]\n",
      "[Epoch 27/200] [Batch 589/637] [D loss: 0.197519] [G loss: 0.476456]\n",
      "[Epoch 27/200] [Batch 590/637] [D loss: 0.170087] [G loss: 0.538927]\n",
      "[Epoch 27/200] [Batch 591/637] [D loss: 0.161306] [G loss: 0.501571]\n",
      "[Epoch 27/200] [Batch 592/637] [D loss: 0.171600] [G loss: 0.447788]\n",
      "[Epoch 27/200] [Batch 593/637] [D loss: 0.156821] [G loss: 0.424644]\n",
      "[Epoch 27/200] [Batch 594/637] [D loss: 0.166643] [G loss: 0.505099]\n",
      "[Epoch 27/200] [Batch 595/637] [D loss: 0.162112] [G loss: 0.485262]\n",
      "[Epoch 27/200] [Batch 596/637] [D loss: 0.161963] [G loss: 0.456507]\n",
      "[Epoch 27/200] [Batch 597/637] [D loss: 0.191092] [G loss: 0.416146]\n",
      "[Epoch 27/200] [Batch 598/637] [D loss: 0.161786] [G loss: 0.577216]\n",
      "[Epoch 27/200] [Batch 599/637] [D loss: 0.173129] [G loss: 0.626748]\n",
      "[Epoch 27/200] [Batch 600/637] [D loss: 0.171348] [G loss: 0.505951]\n",
      "[Epoch 27/200] [Batch 601/637] [D loss: 0.155842] [G loss: 0.451899]\n",
      "[Epoch 27/200] [Batch 602/637] [D loss: 0.166053] [G loss: 0.422395]\n",
      "[Epoch 27/200] [Batch 603/637] [D loss: 0.214925] [G loss: 0.475611]\n",
      "[Epoch 27/200] [Batch 604/637] [D loss: 0.170303] [G loss: 0.461463]\n",
      "[Epoch 27/200] [Batch 605/637] [D loss: 0.188459] [G loss: 0.497480]\n",
      "[Epoch 27/200] [Batch 606/637] [D loss: 0.197449] [G loss: 0.523540]\n",
      "[Epoch 27/200] [Batch 607/637] [D loss: 0.170893] [G loss: 0.507960]\n",
      "[Epoch 27/200] [Batch 608/637] [D loss: 0.174065] [G loss: 0.552884]\n",
      "[Epoch 27/200] [Batch 609/637] [D loss: 0.174346] [G loss: 0.477452]\n",
      "[Epoch 27/200] [Batch 610/637] [D loss: 0.152693] [G loss: 0.511939]\n",
      "[Epoch 27/200] [Batch 611/637] [D loss: 0.181659] [G loss: 0.467311]\n",
      "[Epoch 27/200] [Batch 612/637] [D loss: 0.158233] [G loss: 0.531685]\n",
      "[Epoch 27/200] [Batch 613/637] [D loss: 0.166480] [G loss: 0.632710]\n",
      "[Epoch 27/200] [Batch 614/637] [D loss: 0.151713] [G loss: 0.536318]\n",
      "[Epoch 27/200] [Batch 615/637] [D loss: 0.188887] [G loss: 0.416044]\n",
      "[Epoch 27/200] [Batch 616/637] [D loss: 0.163432] [G loss: 0.587128]\n",
      "[Epoch 27/200] [Batch 617/637] [D loss: 0.163429] [G loss: 0.493927]\n",
      "[Epoch 27/200] [Batch 618/637] [D loss: 0.168585] [G loss: 0.529049]\n",
      "[Epoch 27/200] [Batch 619/637] [D loss: 0.199460] [G loss: 0.551851]\n",
      "[Epoch 27/200] [Batch 620/637] [D loss: 0.178386] [G loss: 0.499850]\n",
      "[Epoch 27/200] [Batch 621/637] [D loss: 0.149720] [G loss: 0.525850]\n",
      "[Epoch 27/200] [Batch 622/637] [D loss: 0.188751] [G loss: 0.459599]\n",
      "[Epoch 27/200] [Batch 623/637] [D loss: 0.166617] [G loss: 0.496631]\n",
      "[Epoch 27/200] [Batch 624/637] [D loss: 0.183376] [G loss: 0.514947]\n",
      "[Epoch 27/200] [Batch 625/637] [D loss: 0.165379] [G loss: 0.488979]\n",
      "[Epoch 27/200] [Batch 626/637] [D loss: 0.162836] [G loss: 0.497430]\n",
      "[Epoch 27/200] [Batch 627/637] [D loss: 0.177886] [G loss: 0.490784]\n",
      "[Epoch 27/200] [Batch 628/637] [D loss: 0.165425] [G loss: 0.534655]\n",
      "[Epoch 27/200] [Batch 629/637] [D loss: 0.183633] [G loss: 0.503064]\n",
      "[Epoch 27/200] [Batch 630/637] [D loss: 0.175245] [G loss: 0.541181]\n",
      "[Epoch 27/200] [Batch 631/637] [D loss: 0.184845] [G loss: 0.464081]\n",
      "[Epoch 27/200] [Batch 632/637] [D loss: 0.183164] [G loss: 0.479414]\n",
      "[Epoch 27/200] [Batch 633/637] [D loss: 0.167920] [G loss: 0.532402]\n",
      "[Epoch 27/200] [Batch 634/637] [D loss: 0.161344] [G loss: 0.457809]\n",
      "[Epoch 27/200] [Batch 635/637] [D loss: 0.152077] [G loss: 0.482851]\n",
      "[Epoch 27/200] [Batch 636/637] [D loss: 0.188057] [G loss: 0.403448]\n",
      "[Epoch 28/200] [Batch 0/637] [D loss: 0.214947] [G loss: 0.663036]\n",
      "[Epoch 28/200] [Batch 1/637] [D loss: 0.203811] [G loss: 0.559168]\n",
      "[Epoch 28/200] [Batch 2/637] [D loss: 0.204356] [G loss: 0.489982]\n",
      "[Epoch 28/200] [Batch 3/637] [D loss: 0.204570] [G loss: 0.420214]\n",
      "[Epoch 28/200] [Batch 4/637] [D loss: 0.166211] [G loss: 0.527226]\n",
      "[Epoch 28/200] [Batch 5/637] [D loss: 0.169817] [G loss: 0.493387]\n",
      "[Epoch 28/200] [Batch 6/637] [D loss: 0.156719] [G loss: 0.485907]\n",
      "[Epoch 28/200] [Batch 7/637] [D loss: 0.153634] [G loss: 0.487881]\n",
      "[Epoch 28/200] [Batch 8/637] [D loss: 0.182786] [G loss: 0.382633]\n",
      "[Epoch 28/200] [Batch 9/637] [D loss: 0.148704] [G loss: 0.456708]\n",
      "[Epoch 28/200] [Batch 10/637] [D loss: 0.180384] [G loss: 0.480401]\n",
      "[Epoch 28/200] [Batch 11/637] [D loss: 0.163888] [G loss: 0.555564]\n",
      "[Epoch 28/200] [Batch 12/637] [D loss: 0.207823] [G loss: 0.540435]\n",
      "[Epoch 28/200] [Batch 13/637] [D loss: 0.190200] [G loss: 0.443511]\n",
      "[Epoch 28/200] [Batch 14/637] [D loss: 0.179729] [G loss: 0.394433]\n",
      "[Epoch 28/200] [Batch 15/637] [D loss: 0.195702] [G loss: 0.346298]\n",
      "[Epoch 28/200] [Batch 16/637] [D loss: 0.192654] [G loss: 0.463119]\n",
      "[Epoch 28/200] [Batch 17/637] [D loss: 0.152983] [G loss: 0.516232]\n",
      "[Epoch 28/200] [Batch 18/637] [D loss: 0.142785] [G loss: 0.484272]\n",
      "[Epoch 28/200] [Batch 19/637] [D loss: 0.161487] [G loss: 0.417410]\n",
      "[Epoch 28/200] [Batch 20/637] [D loss: 0.166978] [G loss: 0.463529]\n",
      "[Epoch 28/200] [Batch 21/637] [D loss: 0.165502] [G loss: 0.549805]\n",
      "[Epoch 28/200] [Batch 22/637] [D loss: 0.186671] [G loss: 0.405052]\n",
      "[Epoch 28/200] [Batch 23/637] [D loss: 0.184595] [G loss: 0.491908]\n",
      "[Epoch 28/200] [Batch 24/637] [D loss: 0.194865] [G loss: 0.487637]\n",
      "[Epoch 28/200] [Batch 25/637] [D loss: 0.162052] [G loss: 0.520251]\n",
      "[Epoch 28/200] [Batch 26/637] [D loss: 0.200447] [G loss: 0.463750]\n",
      "[Epoch 28/200] [Batch 27/637] [D loss: 0.188749] [G loss: 0.429152]\n",
      "[Epoch 28/200] [Batch 28/637] [D loss: 0.170644] [G loss: 0.466993]\n",
      "[Epoch 28/200] [Batch 29/637] [D loss: 0.186926] [G loss: 0.477667]\n",
      "[Epoch 28/200] [Batch 30/637] [D loss: 0.176293] [G loss: 0.370474]\n",
      "[Epoch 28/200] [Batch 31/637] [D loss: 0.180800] [G loss: 0.423921]\n",
      "[Epoch 28/200] [Batch 32/637] [D loss: 0.209771] [G loss: 0.468981]\n",
      "[Epoch 28/200] [Batch 33/637] [D loss: 0.194190] [G loss: 0.463310]\n",
      "[Epoch 28/200] [Batch 34/637] [D loss: 0.165122] [G loss: 0.485184]\n",
      "[Epoch 28/200] [Batch 35/637] [D loss: 0.145430] [G loss: 0.544197]\n",
      "[Epoch 28/200] [Batch 36/637] [D loss: 0.185441] [G loss: 0.483947]\n",
      "[Epoch 28/200] [Batch 37/637] [D loss: 0.179968] [G loss: 0.538345]\n",
      "[Epoch 28/200] [Batch 38/637] [D loss: 0.181182] [G loss: 0.424769]\n",
      "[Epoch 28/200] [Batch 39/637] [D loss: 0.162999] [G loss: 0.442481]\n",
      "[Epoch 28/200] [Batch 40/637] [D loss: 0.201154] [G loss: 0.499948]\n",
      "[Epoch 28/200] [Batch 41/637] [D loss: 0.179676] [G loss: 0.454382]\n",
      "[Epoch 28/200] [Batch 42/637] [D loss: 0.171189] [G loss: 0.504020]\n",
      "[Epoch 28/200] [Batch 43/637] [D loss: 0.200051] [G loss: 0.434391]\n",
      "[Epoch 28/200] [Batch 44/637] [D loss: 0.204240] [G loss: 0.478564]\n",
      "[Epoch 28/200] [Batch 45/637] [D loss: 0.176860] [G loss: 0.486131]\n",
      "[Epoch 28/200] [Batch 46/637] [D loss: 0.179752] [G loss: 0.426508]\n",
      "[Epoch 28/200] [Batch 47/637] [D loss: 0.172700] [G loss: 0.464653]\n",
      "[Epoch 28/200] [Batch 48/637] [D loss: 0.167648] [G loss: 0.464161]\n",
      "[Epoch 28/200] [Batch 49/637] [D loss: 0.159306] [G loss: 0.530805]\n",
      "[Epoch 28/200] [Batch 50/637] [D loss: 0.169060] [G loss: 0.481800]\n",
      "[Epoch 28/200] [Batch 51/637] [D loss: 0.189996] [G loss: 0.474079]\n",
      "[Epoch 28/200] [Batch 52/637] [D loss: 0.170307] [G loss: 0.458773]\n",
      "[Epoch 28/200] [Batch 53/637] [D loss: 0.161504] [G loss: 0.435306]\n",
      "[Epoch 28/200] [Batch 54/637] [D loss: 0.146254] [G loss: 0.438985]\n",
      "[Epoch 28/200] [Batch 55/637] [D loss: 0.165444] [G loss: 0.458669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/200] [Batch 56/637] [D loss: 0.171443] [G loss: 0.467543]\n",
      "[Epoch 28/200] [Batch 57/637] [D loss: 0.191287] [G loss: 0.455603]\n",
      "[Epoch 28/200] [Batch 58/637] [D loss: 0.162758] [G loss: 0.500353]\n",
      "[Epoch 28/200] [Batch 59/637] [D loss: 0.183154] [G loss: 0.507852]\n",
      "[Epoch 28/200] [Batch 60/637] [D loss: 0.183347] [G loss: 0.498782]\n",
      "[Epoch 28/200] [Batch 61/637] [D loss: 0.170560] [G loss: 0.477210]\n",
      "[Epoch 28/200] [Batch 62/637] [D loss: 0.188986] [G loss: 0.422090]\n",
      "[Epoch 28/200] [Batch 63/637] [D loss: 0.182678] [G loss: 0.476710]\n",
      "[Epoch 28/200] [Batch 64/637] [D loss: 0.149665] [G loss: 0.530748]\n",
      "[Epoch 28/200] [Batch 65/637] [D loss: 0.179610] [G loss: 0.467462]\n",
      "[Epoch 28/200] [Batch 66/637] [D loss: 0.170330] [G loss: 0.508908]\n",
      "[Epoch 28/200] [Batch 67/637] [D loss: 0.197107] [G loss: 0.435722]\n",
      "[Epoch 28/200] [Batch 68/637] [D loss: 0.169702] [G loss: 0.439261]\n",
      "[Epoch 28/200] [Batch 69/637] [D loss: 0.176504] [G loss: 0.517630]\n",
      "[Epoch 28/200] [Batch 70/637] [D loss: 0.158163] [G loss: 0.480980]\n",
      "[Epoch 28/200] [Batch 71/637] [D loss: 0.186895] [G loss: 0.505339]\n",
      "[Epoch 28/200] [Batch 72/637] [D loss: 0.172766] [G loss: 0.482741]\n",
      "[Epoch 28/200] [Batch 73/637] [D loss: 0.205771] [G loss: 0.526739]\n",
      "[Epoch 28/200] [Batch 74/637] [D loss: 0.150096] [G loss: 0.489550]\n",
      "[Epoch 28/200] [Batch 75/637] [D loss: 0.173148] [G loss: 0.416050]\n",
      "[Epoch 28/200] [Batch 76/637] [D loss: 0.183085] [G loss: 0.398965]\n",
      "[Epoch 28/200] [Batch 77/637] [D loss: 0.157788] [G loss: 0.481051]\n",
      "[Epoch 28/200] [Batch 78/637] [D loss: 0.196984] [G loss: 0.545002]\n",
      "[Epoch 28/200] [Batch 79/637] [D loss: 0.158148] [G loss: 0.543550]\n",
      "[Epoch 28/200] [Batch 80/637] [D loss: 0.154714] [G loss: 0.470064]\n",
      "[Epoch 28/200] [Batch 81/637] [D loss: 0.164420] [G loss: 0.470592]\n",
      "[Epoch 28/200] [Batch 82/637] [D loss: 0.191384] [G loss: 0.450156]\n",
      "[Epoch 28/200] [Batch 83/637] [D loss: 0.189904] [G loss: 0.575705]\n",
      "[Epoch 28/200] [Batch 84/637] [D loss: 0.152134] [G loss: 0.620923]\n",
      "[Epoch 28/200] [Batch 85/637] [D loss: 0.161665] [G loss: 0.465317]\n",
      "[Epoch 28/200] [Batch 86/637] [D loss: 0.169152] [G loss: 0.511765]\n",
      "[Epoch 28/200] [Batch 87/637] [D loss: 0.210705] [G loss: 0.454715]\n",
      "[Epoch 28/200] [Batch 88/637] [D loss: 0.174296] [G loss: 0.549221]\n",
      "[Epoch 28/200] [Batch 89/637] [D loss: 0.173471] [G loss: 0.547169]\n",
      "[Epoch 28/200] [Batch 90/637] [D loss: 0.177538] [G loss: 0.519567]\n",
      "[Epoch 28/200] [Batch 91/637] [D loss: 0.175597] [G loss: 0.457420]\n",
      "[Epoch 28/200] [Batch 92/637] [D loss: 0.190636] [G loss: 0.410732]\n",
      "[Epoch 28/200] [Batch 93/637] [D loss: 0.212034] [G loss: 0.500742]\n",
      "[Epoch 28/200] [Batch 94/637] [D loss: 0.163749] [G loss: 0.497263]\n",
      "[Epoch 28/200] [Batch 95/637] [D loss: 0.168474] [G loss: 0.470196]\n",
      "[Epoch 28/200] [Batch 96/637] [D loss: 0.146024] [G loss: 0.530107]\n",
      "[Epoch 28/200] [Batch 97/637] [D loss: 0.170590] [G loss: 0.542306]\n",
      "[Epoch 28/200] [Batch 98/637] [D loss: 0.197254] [G loss: 0.460632]\n",
      "[Epoch 28/200] [Batch 99/637] [D loss: 0.175592] [G loss: 0.530691]\n",
      "[Epoch 28/200] [Batch 100/637] [D loss: 0.179539] [G loss: 0.481584]\n",
      "[Epoch 28/200] [Batch 101/637] [D loss: 0.177795] [G loss: 0.573888]\n",
      "[Epoch 28/200] [Batch 102/637] [D loss: 0.168172] [G loss: 0.516917]\n",
      "[Epoch 28/200] [Batch 103/637] [D loss: 0.171232] [G loss: 0.438105]\n",
      "[Epoch 28/200] [Batch 104/637] [D loss: 0.179323] [G loss: 0.475153]\n",
      "[Epoch 28/200] [Batch 105/637] [D loss: 0.162261] [G loss: 0.543902]\n",
      "[Epoch 28/200] [Batch 106/637] [D loss: 0.150631] [G loss: 0.535112]\n",
      "[Epoch 28/200] [Batch 107/637] [D loss: 0.195131] [G loss: 0.630034]\n",
      "[Epoch 28/200] [Batch 108/637] [D loss: 0.164538] [G loss: 0.512295]\n",
      "[Epoch 28/200] [Batch 109/637] [D loss: 0.231244] [G loss: 0.428787]\n",
      "[Epoch 28/200] [Batch 110/637] [D loss: 0.183562] [G loss: 0.522879]\n",
      "[Epoch 28/200] [Batch 111/637] [D loss: 0.223315] [G loss: 0.481744]\n",
      "[Epoch 28/200] [Batch 112/637] [D loss: 0.181820] [G loss: 0.461256]\n",
      "[Epoch 28/200] [Batch 113/637] [D loss: 0.177548] [G loss: 0.415027]\n",
      "[Epoch 28/200] [Batch 114/637] [D loss: 0.159266] [G loss: 0.507517]\n",
      "[Epoch 28/200] [Batch 115/637] [D loss: 0.158313] [G loss: 0.516538]\n",
      "[Epoch 28/200] [Batch 116/637] [D loss: 0.152011] [G loss: 0.482271]\n",
      "[Epoch 28/200] [Batch 117/637] [D loss: 0.161897] [G loss: 0.496854]\n",
      "[Epoch 28/200] [Batch 118/637] [D loss: 0.150458] [G loss: 0.510602]\n",
      "[Epoch 28/200] [Batch 119/637] [D loss: 0.168997] [G loss: 0.509066]\n",
      "[Epoch 28/200] [Batch 120/637] [D loss: 0.194179] [G loss: 0.476097]\n",
      "[Epoch 28/200] [Batch 121/637] [D loss: 0.186501] [G loss: 0.536314]\n",
      "[Epoch 28/200] [Batch 122/637] [D loss: 0.156701] [G loss: 0.464674]\n",
      "[Epoch 28/200] [Batch 123/637] [D loss: 0.179081] [G loss: 0.510693]\n",
      "[Epoch 28/200] [Batch 124/637] [D loss: 0.190973] [G loss: 0.412804]\n",
      "[Epoch 28/200] [Batch 125/637] [D loss: 0.175970] [G loss: 0.464802]\n",
      "[Epoch 28/200] [Batch 126/637] [D loss: 0.163523] [G loss: 0.515489]\n",
      "[Epoch 28/200] [Batch 127/637] [D loss: 0.170675] [G loss: 0.510554]\n",
      "[Epoch 28/200] [Batch 128/637] [D loss: 0.166842] [G loss: 0.466096]\n",
      "[Epoch 28/200] [Batch 129/637] [D loss: 0.179709] [G loss: 0.504852]\n",
      "[Epoch 28/200] [Batch 130/637] [D loss: 0.179229] [G loss: 0.466187]\n",
      "[Epoch 28/200] [Batch 131/637] [D loss: 0.175275] [G loss: 0.457917]\n",
      "[Epoch 28/200] [Batch 132/637] [D loss: 0.183407] [G loss: 0.595313]\n",
      "[Epoch 28/200] [Batch 133/637] [D loss: 0.238061] [G loss: 0.447602]\n",
      "[Epoch 28/200] [Batch 134/637] [D loss: 0.194691] [G loss: 0.449406]\n",
      "[Epoch 28/200] [Batch 135/637] [D loss: 0.185692] [G loss: 0.432250]\n",
      "[Epoch 28/200] [Batch 136/637] [D loss: 0.158092] [G loss: 0.480572]\n",
      "[Epoch 28/200] [Batch 137/637] [D loss: 0.184639] [G loss: 0.472688]\n",
      "[Epoch 28/200] [Batch 138/637] [D loss: 0.159644] [G loss: 0.487973]\n",
      "[Epoch 28/200] [Batch 139/637] [D loss: 0.174498] [G loss: 0.489427]\n",
      "[Epoch 28/200] [Batch 140/637] [D loss: 0.144131] [G loss: 0.492411]\n",
      "[Epoch 28/200] [Batch 141/637] [D loss: 0.172384] [G loss: 0.451874]\n",
      "[Epoch 28/200] [Batch 142/637] [D loss: 0.168775] [G loss: 0.479658]\n",
      "[Epoch 28/200] [Batch 143/637] [D loss: 0.156098] [G loss: 0.514967]\n",
      "[Epoch 28/200] [Batch 144/637] [D loss: 0.149929] [G loss: 0.590482]\n",
      "[Epoch 28/200] [Batch 145/637] [D loss: 0.177878] [G loss: 0.530433]\n",
      "[Epoch 28/200] [Batch 146/637] [D loss: 0.161684] [G loss: 0.535395]\n",
      "[Epoch 28/200] [Batch 147/637] [D loss: 0.179726] [G loss: 0.463069]\n",
      "[Epoch 28/200] [Batch 148/637] [D loss: 0.188687] [G loss: 0.428137]\n",
      "[Epoch 28/200] [Batch 149/637] [D loss: 0.164127] [G loss: 0.458536]\n",
      "[Epoch 28/200] [Batch 150/637] [D loss: 0.173411] [G loss: 0.497691]\n",
      "[Epoch 28/200] [Batch 151/637] [D loss: 0.158888] [G loss: 0.486164]\n",
      "[Epoch 28/200] [Batch 152/637] [D loss: 0.163995] [G loss: 0.481171]\n",
      "[Epoch 28/200] [Batch 153/637] [D loss: 0.175504] [G loss: 0.424064]\n",
      "[Epoch 28/200] [Batch 154/637] [D loss: 0.170000] [G loss: 0.498385]\n",
      "[Epoch 28/200] [Batch 155/637] [D loss: 0.188491] [G loss: 0.458782]\n",
      "[Epoch 28/200] [Batch 156/637] [D loss: 0.173194] [G loss: 0.539293]\n",
      "[Epoch 28/200] [Batch 157/637] [D loss: 0.189838] [G loss: 0.424592]\n",
      "[Epoch 28/200] [Batch 158/637] [D loss: 0.196654] [G loss: 0.386524]\n",
      "[Epoch 28/200] [Batch 159/637] [D loss: 0.177246] [G loss: 0.492911]\n",
      "[Epoch 28/200] [Batch 160/637] [D loss: 0.168568] [G loss: 0.460403]\n",
      "[Epoch 28/200] [Batch 161/637] [D loss: 0.172944] [G loss: 0.451695]\n",
      "[Epoch 28/200] [Batch 162/637] [D loss: 0.176664] [G loss: 0.433532]\n",
      "[Epoch 28/200] [Batch 163/637] [D loss: 0.167295] [G loss: 0.479499]\n",
      "[Epoch 28/200] [Batch 164/637] [D loss: 0.182756] [G loss: 0.399035]\n",
      "[Epoch 28/200] [Batch 165/637] [D loss: 0.164597] [G loss: 0.384039]\n",
      "[Epoch 28/200] [Batch 166/637] [D loss: 0.177859] [G loss: 0.430881]\n",
      "[Epoch 28/200] [Batch 167/637] [D loss: 0.172828] [G loss: 0.450246]\n",
      "[Epoch 28/200] [Batch 168/637] [D loss: 0.156528] [G loss: 0.502809]\n",
      "[Epoch 28/200] [Batch 169/637] [D loss: 0.195286] [G loss: 0.509206]\n",
      "[Epoch 28/200] [Batch 170/637] [D loss: 0.180990] [G loss: 0.478740]\n",
      "[Epoch 28/200] [Batch 171/637] [D loss: 0.185266] [G loss: 0.515824]\n",
      "[Epoch 28/200] [Batch 172/637] [D loss: 0.177621] [G loss: 0.532555]\n",
      "[Epoch 28/200] [Batch 173/637] [D loss: 0.177553] [G loss: 0.476772]\n",
      "[Epoch 28/200] [Batch 174/637] [D loss: 0.148896] [G loss: 0.497342]\n",
      "[Epoch 28/200] [Batch 175/637] [D loss: 0.162201] [G loss: 0.456841]\n",
      "[Epoch 28/200] [Batch 176/637] [D loss: 0.156292] [G loss: 0.486996]\n",
      "[Epoch 28/200] [Batch 177/637] [D loss: 0.153121] [G loss: 0.510804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/200] [Batch 178/637] [D loss: 0.151607] [G loss: 0.513796]\n",
      "[Epoch 28/200] [Batch 179/637] [D loss: 0.163872] [G loss: 0.517392]\n",
      "[Epoch 28/200] [Batch 180/637] [D loss: 0.148514] [G loss: 0.472809]\n",
      "[Epoch 28/200] [Batch 181/637] [D loss: 0.150571] [G loss: 0.495144]\n",
      "[Epoch 28/200] [Batch 182/637] [D loss: 0.186229] [G loss: 0.526874]\n",
      "[Epoch 28/200] [Batch 183/637] [D loss: 0.199150] [G loss: 0.489589]\n",
      "[Epoch 28/200] [Batch 184/637] [D loss: 0.140520] [G loss: 0.571271]\n",
      "[Epoch 28/200] [Batch 185/637] [D loss: 0.179462] [G loss: 0.530711]\n",
      "[Epoch 28/200] [Batch 186/637] [D loss: 0.178018] [G loss: 0.511820]\n",
      "[Epoch 28/200] [Batch 187/637] [D loss: 0.163793] [G loss: 0.478171]\n",
      "[Epoch 28/200] [Batch 188/637] [D loss: 0.166935] [G loss: 0.464381]\n",
      "[Epoch 28/200] [Batch 189/637] [D loss: 0.156983] [G loss: 0.531626]\n",
      "[Epoch 28/200] [Batch 190/637] [D loss: 0.176607] [G loss: 0.497072]\n",
      "[Epoch 28/200] [Batch 191/637] [D loss: 0.158451] [G loss: 0.474684]\n",
      "[Epoch 28/200] [Batch 192/637] [D loss: 0.186185] [G loss: 0.473195]\n",
      "[Epoch 28/200] [Batch 193/637] [D loss: 0.168582] [G loss: 0.541541]\n",
      "[Epoch 28/200] [Batch 194/637] [D loss: 0.245041] [G loss: 0.539048]\n",
      "[Epoch 28/200] [Batch 195/637] [D loss: 0.221426] [G loss: 0.498973]\n",
      "[Epoch 28/200] [Batch 196/637] [D loss: 0.177522] [G loss: 0.529927]\n",
      "[Epoch 28/200] [Batch 197/637] [D loss: 0.183181] [G loss: 0.480747]\n",
      "[Epoch 28/200] [Batch 198/637] [D loss: 0.177220] [G loss: 0.492590]\n",
      "[Epoch 28/200] [Batch 199/637] [D loss: 0.191721] [G loss: 0.414713]\n",
      "[Epoch 28/200] [Batch 200/637] [D loss: 0.157219] [G loss: 0.504924]\n",
      "[Epoch 28/200] [Batch 201/637] [D loss: 0.248661] [G loss: 0.428334]\n",
      "[Epoch 28/200] [Batch 202/637] [D loss: 0.173243] [G loss: 0.542162]\n",
      "[Epoch 28/200] [Batch 203/637] [D loss: 0.181565] [G loss: 0.575621]\n",
      "[Epoch 28/200] [Batch 204/637] [D loss: 0.172236] [G loss: 0.539387]\n",
      "[Epoch 28/200] [Batch 205/637] [D loss: 0.193235] [G loss: 0.381237]\n",
      "[Epoch 28/200] [Batch 206/637] [D loss: 0.204412] [G loss: 0.456229]\n",
      "[Epoch 28/200] [Batch 207/637] [D loss: 0.175023] [G loss: 0.474458]\n",
      "[Epoch 28/200] [Batch 208/637] [D loss: 0.174341] [G loss: 0.500138]\n",
      "[Epoch 28/200] [Batch 209/637] [D loss: 0.174826] [G loss: 0.458413]\n",
      "[Epoch 28/200] [Batch 210/637] [D loss: 0.148296] [G loss: 0.500768]\n",
      "[Epoch 28/200] [Batch 211/637] [D loss: 0.148963] [G loss: 0.460433]\n",
      "[Epoch 28/200] [Batch 212/637] [D loss: 0.202547] [G loss: 0.435919]\n",
      "[Epoch 28/200] [Batch 213/637] [D loss: 0.174758] [G loss: 0.568330]\n",
      "[Epoch 28/200] [Batch 214/637] [D loss: 0.183817] [G loss: 0.482878]\n",
      "[Epoch 28/200] [Batch 215/637] [D loss: 0.173262] [G loss: 0.501157]\n",
      "[Epoch 28/200] [Batch 216/637] [D loss: 0.155472] [G loss: 0.441411]\n",
      "[Epoch 28/200] [Batch 217/637] [D loss: 0.185173] [G loss: 0.383503]\n",
      "[Epoch 28/200] [Batch 218/637] [D loss: 0.148818] [G loss: 0.523685]\n",
      "[Epoch 28/200] [Batch 219/637] [D loss: 0.183810] [G loss: 0.491020]\n",
      "[Epoch 28/200] [Batch 220/637] [D loss: 0.182158] [G loss: 0.438255]\n",
      "[Epoch 28/200] [Batch 221/637] [D loss: 0.201337] [G loss: 0.467171]\n",
      "[Epoch 28/200] [Batch 222/637] [D loss: 0.160122] [G loss: 0.512984]\n",
      "[Epoch 28/200] [Batch 223/637] [D loss: 0.176780] [G loss: 0.514285]\n",
      "[Epoch 28/200] [Batch 224/637] [D loss: 0.173360] [G loss: 0.546954]\n",
      "[Epoch 28/200] [Batch 225/637] [D loss: 0.175132] [G loss: 0.431068]\n",
      "[Epoch 28/200] [Batch 226/637] [D loss: 0.180865] [G loss: 0.409763]\n",
      "[Epoch 28/200] [Batch 227/637] [D loss: 0.154418] [G loss: 0.493940]\n",
      "[Epoch 28/200] [Batch 228/637] [D loss: 0.155917] [G loss: 0.515344]\n",
      "[Epoch 28/200] [Batch 229/637] [D loss: 0.169970] [G loss: 0.549331]\n",
      "[Epoch 28/200] [Batch 230/637] [D loss: 0.185336] [G loss: 0.597288]\n",
      "[Epoch 28/200] [Batch 231/637] [D loss: 0.157546] [G loss: 0.489299]\n",
      "[Epoch 28/200] [Batch 232/637] [D loss: 0.184790] [G loss: 0.472325]\n",
      "[Epoch 28/200] [Batch 233/637] [D loss: 0.161112] [G loss: 0.474621]\n",
      "[Epoch 28/200] [Batch 234/637] [D loss: 0.182968] [G loss: 0.456458]\n",
      "[Epoch 28/200] [Batch 235/637] [D loss: 0.178819] [G loss: 0.618152]\n",
      "[Epoch 28/200] [Batch 236/637] [D loss: 0.186627] [G loss: 0.520620]\n",
      "[Epoch 28/200] [Batch 237/637] [D loss: 0.163681] [G loss: 0.454522]\n",
      "[Epoch 28/200] [Batch 238/637] [D loss: 0.167983] [G loss: 0.500117]\n",
      "[Epoch 28/200] [Batch 239/637] [D loss: 0.185529] [G loss: 0.477911]\n",
      "[Epoch 28/200] [Batch 240/637] [D loss: 0.185470] [G loss: 0.516019]\n",
      "[Epoch 28/200] [Batch 241/637] [D loss: 0.165852] [G loss: 0.529465]\n",
      "[Epoch 28/200] [Batch 242/637] [D loss: 0.199739] [G loss: 0.457825]\n",
      "[Epoch 28/200] [Batch 243/637] [D loss: 0.184998] [G loss: 0.585916]\n",
      "[Epoch 28/200] [Batch 244/637] [D loss: 0.214968] [G loss: 0.491624]\n",
      "[Epoch 28/200] [Batch 245/637] [D loss: 0.189913] [G loss: 0.473508]\n",
      "[Epoch 28/200] [Batch 246/637] [D loss: 0.174202] [G loss: 0.457975]\n",
      "[Epoch 28/200] [Batch 247/637] [D loss: 0.166933] [G loss: 0.478095]\n",
      "[Epoch 28/200] [Batch 248/637] [D loss: 0.187321] [G loss: 0.482620]\n",
      "[Epoch 28/200] [Batch 249/637] [D loss: 0.164091] [G loss: 0.497360]\n",
      "[Epoch 28/200] [Batch 250/637] [D loss: 0.178274] [G loss: 0.465812]\n",
      "[Epoch 28/200] [Batch 251/637] [D loss: 0.164688] [G loss: 0.532305]\n",
      "[Epoch 28/200] [Batch 252/637] [D loss: 0.186486] [G loss: 0.418795]\n",
      "[Epoch 28/200] [Batch 253/637] [D loss: 0.156654] [G loss: 0.536301]\n",
      "[Epoch 28/200] [Batch 254/637] [D loss: 0.179007] [G loss: 0.449728]\n",
      "[Epoch 28/200] [Batch 255/637] [D loss: 0.192248] [G loss: 0.517554]\n",
      "[Epoch 28/200] [Batch 256/637] [D loss: 0.225975] [G loss: 0.550640]\n",
      "[Epoch 28/200] [Batch 257/637] [D loss: 0.158912] [G loss: 0.528897]\n",
      "[Epoch 28/200] [Batch 258/637] [D loss: 0.195627] [G loss: 0.409869]\n",
      "[Epoch 28/200] [Batch 259/637] [D loss: 0.170135] [G loss: 0.469862]\n",
      "[Epoch 28/200] [Batch 260/637] [D loss: 0.168771] [G loss: 0.489118]\n",
      "[Epoch 28/200] [Batch 261/637] [D loss: 0.200634] [G loss: 0.456481]\n",
      "[Epoch 28/200] [Batch 262/637] [D loss: 0.163264] [G loss: 0.470001]\n",
      "[Epoch 28/200] [Batch 263/637] [D loss: 0.182187] [G loss: 0.458554]\n",
      "[Epoch 28/200] [Batch 264/637] [D loss: 0.179172] [G loss: 0.453091]\n",
      "[Epoch 28/200] [Batch 265/637] [D loss: 0.163082] [G loss: 0.486619]\n",
      "[Epoch 28/200] [Batch 266/637] [D loss: 0.145207] [G loss: 0.516040]\n",
      "[Epoch 28/200] [Batch 267/637] [D loss: 0.180559] [G loss: 0.483210]\n",
      "[Epoch 28/200] [Batch 268/637] [D loss: 0.168203] [G loss: 0.455436]\n",
      "[Epoch 28/200] [Batch 269/637] [D loss: 0.159717] [G loss: 0.462377]\n",
      "[Epoch 28/200] [Batch 270/637] [D loss: 0.183531] [G loss: 0.473014]\n",
      "[Epoch 28/200] [Batch 271/637] [D loss: 0.169344] [G loss: 0.487431]\n",
      "[Epoch 28/200] [Batch 272/637] [D loss: 0.173884] [G loss: 0.463954]\n",
      "[Epoch 28/200] [Batch 273/637] [D loss: 0.187887] [G loss: 0.441626]\n",
      "[Epoch 28/200] [Batch 274/637] [D loss: 0.190487] [G loss: 0.456723]\n",
      "[Epoch 28/200] [Batch 275/637] [D loss: 0.175732] [G loss: 0.492906]\n",
      "[Epoch 28/200] [Batch 276/637] [D loss: 0.184790] [G loss: 0.456732]\n",
      "[Epoch 28/200] [Batch 277/637] [D loss: 0.165798] [G loss: 0.457704]\n",
      "[Epoch 28/200] [Batch 278/637] [D loss: 0.205873] [G loss: 0.428480]\n",
      "[Epoch 28/200] [Batch 279/637] [D loss: 0.159453] [G loss: 0.487343]\n",
      "[Epoch 28/200] [Batch 280/637] [D loss: 0.192774] [G loss: 0.428493]\n",
      "[Epoch 28/200] [Batch 281/637] [D loss: 0.189499] [G loss: 0.461128]\n",
      "[Epoch 28/200] [Batch 282/637] [D loss: 0.181398] [G loss: 0.459996]\n",
      "[Epoch 28/200] [Batch 283/637] [D loss: 0.193964] [G loss: 0.370406]\n",
      "[Epoch 28/200] [Batch 284/637] [D loss: 0.190538] [G loss: 0.498079]\n",
      "[Epoch 28/200] [Batch 285/637] [D loss: 0.159683] [G loss: 0.550895]\n",
      "[Epoch 28/200] [Batch 286/637] [D loss: 0.202578] [G loss: 0.534304]\n",
      "[Epoch 28/200] [Batch 287/637] [D loss: 0.152192] [G loss: 0.506696]\n",
      "[Epoch 28/200] [Batch 288/637] [D loss: 0.168402] [G loss: 0.454215]\n",
      "[Epoch 28/200] [Batch 289/637] [D loss: 0.199374] [G loss: 0.434706]\n",
      "[Epoch 28/200] [Batch 290/637] [D loss: 0.180777] [G loss: 0.478702]\n",
      "[Epoch 28/200] [Batch 291/637] [D loss: 0.169645] [G loss: 0.486200]\n",
      "[Epoch 28/200] [Batch 292/637] [D loss: 0.178950] [G loss: 0.441712]\n",
      "[Epoch 28/200] [Batch 293/637] [D loss: 0.172901] [G loss: 0.458201]\n",
      "[Epoch 28/200] [Batch 294/637] [D loss: 0.193496] [G loss: 0.481956]\n",
      "[Epoch 28/200] [Batch 295/637] [D loss: 0.179309] [G loss: 0.464777]\n",
      "[Epoch 28/200] [Batch 296/637] [D loss: 0.199541] [G loss: 0.434044]\n",
      "[Epoch 28/200] [Batch 297/637] [D loss: 0.158800] [G loss: 0.457961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/200] [Batch 298/637] [D loss: 0.210163] [G loss: 0.419751]\n",
      "[Epoch 28/200] [Batch 299/637] [D loss: 0.174716] [G loss: 0.513616]\n",
      "[Epoch 28/200] [Batch 300/637] [D loss: 0.176618] [G loss: 0.424122]\n",
      "[Epoch 28/200] [Batch 301/637] [D loss: 0.151362] [G loss: 0.479760]\n",
      "[Epoch 28/200] [Batch 302/637] [D loss: 0.172356] [G loss: 0.519989]\n",
      "[Epoch 28/200] [Batch 303/637] [D loss: 0.177313] [G loss: 0.516620]\n",
      "[Epoch 28/200] [Batch 304/637] [D loss: 0.187958] [G loss: 0.438833]\n",
      "[Epoch 28/200] [Batch 305/637] [D loss: 0.182688] [G loss: 0.438683]\n",
      "[Epoch 28/200] [Batch 306/637] [D loss: 0.186426] [G loss: 0.446856]\n",
      "[Epoch 28/200] [Batch 307/637] [D loss: 0.155580] [G loss: 0.504645]\n",
      "[Epoch 28/200] [Batch 308/637] [D loss: 0.238279] [G loss: 0.384516]\n",
      "[Epoch 28/200] [Batch 309/637] [D loss: 0.297785] [G loss: 0.432325]\n",
      "[Epoch 28/200] [Batch 310/637] [D loss: 0.199085] [G loss: 0.513673]\n",
      "[Epoch 28/200] [Batch 311/637] [D loss: 0.192035] [G loss: 0.490237]\n",
      "[Epoch 28/200] [Batch 312/637] [D loss: 0.182623] [G loss: 0.440373]\n",
      "[Epoch 28/200] [Batch 313/637] [D loss: 0.187555] [G loss: 0.438050]\n",
      "[Epoch 28/200] [Batch 314/637] [D loss: 0.193049] [G loss: 0.482576]\n",
      "[Epoch 28/200] [Batch 315/637] [D loss: 0.188445] [G loss: 0.464386]\n",
      "[Epoch 28/200] [Batch 316/637] [D loss: 0.187254] [G loss: 0.403985]\n",
      "[Epoch 28/200] [Batch 317/637] [D loss: 0.177897] [G loss: 0.479471]\n",
      "[Epoch 28/200] [Batch 318/637] [D loss: 0.206187] [G loss: 0.439669]\n",
      "[Epoch 28/200] [Batch 319/637] [D loss: 0.196144] [G loss: 0.594166]\n",
      "[Epoch 28/200] [Batch 320/637] [D loss: 0.167836] [G loss: 0.501517]\n",
      "[Epoch 28/200] [Batch 321/637] [D loss: 0.169492] [G loss: 0.443447]\n",
      "[Epoch 28/200] [Batch 322/637] [D loss: 0.212093] [G loss: 0.388747]\n",
      "[Epoch 28/200] [Batch 323/637] [D loss: 0.173505] [G loss: 0.476198]\n",
      "[Epoch 28/200] [Batch 324/637] [D loss: 0.163535] [G loss: 0.495939]\n",
      "[Epoch 28/200] [Batch 325/637] [D loss: 0.176967] [G loss: 0.424459]\n",
      "[Epoch 28/200] [Batch 326/637] [D loss: 0.161214] [G loss: 0.494884]\n",
      "[Epoch 28/200] [Batch 327/637] [D loss: 0.167729] [G loss: 0.499814]\n",
      "[Epoch 28/200] [Batch 328/637] [D loss: 0.200120] [G loss: 0.529265]\n",
      "[Epoch 28/200] [Batch 329/637] [D loss: 0.173668] [G loss: 0.497336]\n",
      "[Epoch 28/200] [Batch 330/637] [D loss: 0.171936] [G loss: 0.520247]\n",
      "[Epoch 28/200] [Batch 331/637] [D loss: 0.192344] [G loss: 0.516387]\n",
      "[Epoch 28/200] [Batch 332/637] [D loss: 0.147287] [G loss: 0.513693]\n",
      "[Epoch 28/200] [Batch 333/637] [D loss: 0.155056] [G loss: 0.507663]\n",
      "[Epoch 28/200] [Batch 334/637] [D loss: 0.174377] [G loss: 0.501325]\n",
      "[Epoch 28/200] [Batch 335/637] [D loss: 0.151450] [G loss: 0.461312]\n",
      "[Epoch 28/200] [Batch 336/637] [D loss: 0.201117] [G loss: 0.439815]\n",
      "[Epoch 28/200] [Batch 337/637] [D loss: 0.176654] [G loss: 0.539278]\n",
      "[Epoch 28/200] [Batch 338/637] [D loss: 0.162993] [G loss: 0.511382]\n",
      "[Epoch 28/200] [Batch 339/637] [D loss: 0.191969] [G loss: 0.478914]\n",
      "[Epoch 28/200] [Batch 340/637] [D loss: 0.175021] [G loss: 0.433966]\n",
      "[Epoch 28/200] [Batch 341/637] [D loss: 0.198025] [G loss: 0.498755]\n",
      "[Epoch 28/200] [Batch 342/637] [D loss: 0.168551] [G loss: 0.514462]\n",
      "[Epoch 28/200] [Batch 343/637] [D loss: 0.157580] [G loss: 0.479739]\n",
      "[Epoch 28/200] [Batch 344/637] [D loss: 0.143978] [G loss: 0.542388]\n",
      "[Epoch 28/200] [Batch 345/637] [D loss: 0.165375] [G loss: 0.527475]\n",
      "[Epoch 28/200] [Batch 346/637] [D loss: 0.147115] [G loss: 0.505696]\n",
      "[Epoch 28/200] [Batch 347/637] [D loss: 0.171000] [G loss: 0.452558]\n",
      "[Epoch 28/200] [Batch 348/637] [D loss: 0.155325] [G loss: 0.479404]\n",
      "[Epoch 28/200] [Batch 349/637] [D loss: 0.169334] [G loss: 0.468242]\n",
      "[Epoch 28/200] [Batch 350/637] [D loss: 0.169745] [G loss: 0.485663]\n",
      "[Epoch 28/200] [Batch 351/637] [D loss: 0.172629] [G loss: 0.499377]\n",
      "[Epoch 28/200] [Batch 352/637] [D loss: 0.172103] [G loss: 0.487631]\n",
      "[Epoch 28/200] [Batch 353/637] [D loss: 0.169271] [G loss: 0.480376]\n",
      "[Epoch 28/200] [Batch 354/637] [D loss: 0.186201] [G loss: 0.473633]\n",
      "[Epoch 28/200] [Batch 355/637] [D loss: 0.186148] [G loss: 0.481562]\n",
      "[Epoch 28/200] [Batch 356/637] [D loss: 0.162413] [G loss: 0.520953]\n",
      "[Epoch 28/200] [Batch 357/637] [D loss: 0.174823] [G loss: 0.457513]\n",
      "[Epoch 28/200] [Batch 358/637] [D loss: 0.169241] [G loss: 0.482123]\n",
      "[Epoch 28/200] [Batch 359/637] [D loss: 0.177444] [G loss: 0.456707]\n",
      "[Epoch 28/200] [Batch 360/637] [D loss: 0.161902] [G loss: 0.473451]\n",
      "[Epoch 28/200] [Batch 361/637] [D loss: 0.167785] [G loss: 0.503521]\n",
      "[Epoch 28/200] [Batch 362/637] [D loss: 0.183915] [G loss: 0.455123]\n",
      "[Epoch 28/200] [Batch 363/637] [D loss: 0.186668] [G loss: 0.466150]\n",
      "[Epoch 28/200] [Batch 364/637] [D loss: 0.182865] [G loss: 0.498623]\n",
      "[Epoch 28/200] [Batch 365/637] [D loss: 0.196088] [G loss: 0.475651]\n",
      "[Epoch 28/200] [Batch 366/637] [D loss: 0.177420] [G loss: 0.447918]\n",
      "[Epoch 28/200] [Batch 367/637] [D loss: 0.194634] [G loss: 0.395109]\n",
      "[Epoch 28/200] [Batch 368/637] [D loss: 0.176330] [G loss: 0.407578]\n",
      "[Epoch 28/200] [Batch 369/637] [D loss: 0.179072] [G loss: 0.411816]\n",
      "[Epoch 28/200] [Batch 370/637] [D loss: 0.176090] [G loss: 0.418160]\n",
      "[Epoch 28/200] [Batch 371/637] [D loss: 0.194493] [G loss: 0.492636]\n",
      "[Epoch 28/200] [Batch 372/637] [D loss: 0.165555] [G loss: 0.485775]\n",
      "[Epoch 28/200] [Batch 373/637] [D loss: 0.167444] [G loss: 0.493122]\n",
      "[Epoch 28/200] [Batch 374/637] [D loss: 0.157521] [G loss: 0.442977]\n",
      "[Epoch 28/200] [Batch 375/637] [D loss: 0.181981] [G loss: 0.444944]\n",
      "[Epoch 28/200] [Batch 376/637] [D loss: 0.186486] [G loss: 0.592767]\n",
      "[Epoch 28/200] [Batch 377/637] [D loss: 0.155310] [G loss: 0.538735]\n",
      "[Epoch 28/200] [Batch 378/637] [D loss: 0.167025] [G loss: 0.468510]\n",
      "[Epoch 28/200] [Batch 379/637] [D loss: 0.184353] [G loss: 0.407194]\n",
      "[Epoch 28/200] [Batch 380/637] [D loss: 0.185575] [G loss: 0.523947]\n",
      "[Epoch 28/200] [Batch 381/637] [D loss: 0.166684] [G loss: 0.545342]\n",
      "[Epoch 28/200] [Batch 382/637] [D loss: 0.169493] [G loss: 0.458793]\n",
      "[Epoch 28/200] [Batch 383/637] [D loss: 0.175408] [G loss: 0.454773]\n",
      "[Epoch 28/200] [Batch 384/637] [D loss: 0.192642] [G loss: 0.418931]\n",
      "[Epoch 28/200] [Batch 385/637] [D loss: 0.171601] [G loss: 0.445608]\n",
      "[Epoch 28/200] [Batch 386/637] [D loss: 0.171472] [G loss: 0.472153]\n",
      "[Epoch 28/200] [Batch 387/637] [D loss: 0.174475] [G loss: 0.430841]\n",
      "[Epoch 28/200] [Batch 388/637] [D loss: 0.170353] [G loss: 0.444350]\n",
      "[Epoch 28/200] [Batch 389/637] [D loss: 0.154968] [G loss: 0.490418]\n",
      "[Epoch 28/200] [Batch 390/637] [D loss: 0.173801] [G loss: 0.508678]\n",
      "[Epoch 28/200] [Batch 391/637] [D loss: 0.189034] [G loss: 0.487304]\n",
      "[Epoch 28/200] [Batch 392/637] [D loss: 0.190987] [G loss: 0.436709]\n",
      "[Epoch 28/200] [Batch 393/637] [D loss: 0.242522] [G loss: 0.440344]\n",
      "[Epoch 28/200] [Batch 394/637] [D loss: 0.175317] [G loss: 0.542108]\n",
      "[Epoch 28/200] [Batch 395/637] [D loss: 0.166191] [G loss: 0.483808]\n",
      "[Epoch 28/200] [Batch 396/637] [D loss: 0.174751] [G loss: 0.418756]\n",
      "[Epoch 28/200] [Batch 397/637] [D loss: 0.174637] [G loss: 0.417341]\n",
      "[Epoch 28/200] [Batch 398/637] [D loss: 0.172553] [G loss: 0.474478]\n",
      "[Epoch 28/200] [Batch 399/637] [D loss: 0.145707] [G loss: 0.548090]\n",
      "[Epoch 28/200] [Batch 400/637] [D loss: 0.167897] [G loss: 0.551178]\n",
      "[Epoch 28/200] [Batch 401/637] [D loss: 0.171703] [G loss: 0.491682]\n",
      "[Epoch 28/200] [Batch 402/637] [D loss: 0.185900] [G loss: 0.438319]\n",
      "[Epoch 28/200] [Batch 403/637] [D loss: 0.166163] [G loss: 0.486668]\n",
      "[Epoch 28/200] [Batch 404/637] [D loss: 0.160715] [G loss: 0.459782]\n",
      "[Epoch 28/200] [Batch 405/637] [D loss: 0.193498] [G loss: 0.425030]\n",
      "[Epoch 28/200] [Batch 406/637] [D loss: 0.169167] [G loss: 0.505221]\n",
      "[Epoch 28/200] [Batch 407/637] [D loss: 0.170178] [G loss: 0.492606]\n",
      "[Epoch 28/200] [Batch 408/637] [D loss: 0.164031] [G loss: 0.522442]\n",
      "[Epoch 28/200] [Batch 409/637] [D loss: 0.164721] [G loss: 0.489385]\n",
      "[Epoch 28/200] [Batch 410/637] [D loss: 0.184396] [G loss: 0.461309]\n",
      "[Epoch 28/200] [Batch 411/637] [D loss: 0.158192] [G loss: 0.474426]\n",
      "[Epoch 28/200] [Batch 412/637] [D loss: 0.196048] [G loss: 0.519162]\n",
      "[Epoch 28/200] [Batch 413/637] [D loss: 0.198085] [G loss: 0.478387]\n",
      "[Epoch 28/200] [Batch 414/637] [D loss: 0.186976] [G loss: 0.511915]\n",
      "[Epoch 28/200] [Batch 415/637] [D loss: 0.169492] [G loss: 0.535599]\n",
      "[Epoch 28/200] [Batch 416/637] [D loss: 0.184843] [G loss: 0.406717]\n",
      "[Epoch 28/200] [Batch 417/637] [D loss: 0.171388] [G loss: 0.492088]\n",
      "[Epoch 28/200] [Batch 418/637] [D loss: 0.172931] [G loss: 0.471315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/200] [Batch 419/637] [D loss: 0.261223] [G loss: 0.371476]\n",
      "[Epoch 28/200] [Batch 420/637] [D loss: 0.218160] [G loss: 0.604838]\n",
      "[Epoch 28/200] [Batch 421/637] [D loss: 0.215330] [G loss: 0.505547]\n",
      "[Epoch 28/200] [Batch 422/637] [D loss: 0.177205] [G loss: 0.477660]\n",
      "[Epoch 28/200] [Batch 423/637] [D loss: 0.197905] [G loss: 0.389316]\n",
      "[Epoch 28/200] [Batch 424/637] [D loss: 0.173969] [G loss: 0.430965]\n",
      "[Epoch 28/200] [Batch 425/637] [D loss: 0.177391] [G loss: 0.467841]\n",
      "[Epoch 28/200] [Batch 426/637] [D loss: 0.165233] [G loss: 0.460455]\n",
      "[Epoch 28/200] [Batch 427/637] [D loss: 0.179359] [G loss: 0.451135]\n",
      "[Epoch 28/200] [Batch 428/637] [D loss: 0.202873] [G loss: 0.440122]\n",
      "[Epoch 28/200] [Batch 429/637] [D loss: 0.189272] [G loss: 0.445008]\n",
      "[Epoch 28/200] [Batch 430/637] [D loss: 0.167816] [G loss: 0.520594]\n",
      "[Epoch 28/200] [Batch 431/637] [D loss: 0.172225] [G loss: 0.426679]\n",
      "[Epoch 28/200] [Batch 432/637] [D loss: 0.156748] [G loss: 0.434649]\n",
      "[Epoch 28/200] [Batch 433/637] [D loss: 0.203781] [G loss: 0.401896]\n",
      "[Epoch 28/200] [Batch 434/637] [D loss: 0.198022] [G loss: 0.465462]\n",
      "[Epoch 28/200] [Batch 435/637] [D loss: 0.177314] [G loss: 0.487368]\n",
      "[Epoch 28/200] [Batch 436/637] [D loss: 0.174164] [G loss: 0.463606]\n",
      "[Epoch 28/200] [Batch 437/637] [D loss: 0.171365] [G loss: 0.462301]\n",
      "[Epoch 28/200] [Batch 438/637] [D loss: 0.172198] [G loss: 0.480896]\n",
      "[Epoch 28/200] [Batch 439/637] [D loss: 0.192333] [G loss: 0.458490]\n",
      "[Epoch 28/200] [Batch 440/637] [D loss: 0.174470] [G loss: 0.535540]\n",
      "[Epoch 28/200] [Batch 441/637] [D loss: 0.145296] [G loss: 0.508903]\n",
      "[Epoch 28/200] [Batch 442/637] [D loss: 0.166076] [G loss: 0.428464]\n",
      "[Epoch 28/200] [Batch 443/637] [D loss: 0.152637] [G loss: 0.516526]\n",
      "[Epoch 28/200] [Batch 444/637] [D loss: 0.198180] [G loss: 0.470773]\n",
      "[Epoch 28/200] [Batch 445/637] [D loss: 0.159727] [G loss: 0.480788]\n",
      "[Epoch 28/200] [Batch 446/637] [D loss: 0.182940] [G loss: 0.522268]\n",
      "[Epoch 28/200] [Batch 447/637] [D loss: 0.161081] [G loss: 0.478997]\n",
      "[Epoch 28/200] [Batch 448/637] [D loss: 0.176054] [G loss: 0.417145]\n",
      "[Epoch 28/200] [Batch 449/637] [D loss: 0.185570] [G loss: 0.516119]\n",
      "[Epoch 28/200] [Batch 450/637] [D loss: 0.154343] [G loss: 0.473453]\n",
      "[Epoch 28/200] [Batch 451/637] [D loss: 0.176223] [G loss: 0.485093]\n",
      "[Epoch 28/200] [Batch 452/637] [D loss: 0.150898] [G loss: 0.540507]\n",
      "[Epoch 28/200] [Batch 453/637] [D loss: 0.166521] [G loss: 0.571761]\n",
      "[Epoch 28/200] [Batch 454/637] [D loss: 0.142017] [G loss: 0.471790]\n",
      "[Epoch 28/200] [Batch 455/637] [D loss: 0.254613] [G loss: 0.388429]\n",
      "[Epoch 28/200] [Batch 456/637] [D loss: 0.217614] [G loss: 0.510041]\n",
      "[Epoch 28/200] [Batch 457/637] [D loss: 0.167944] [G loss: 0.554904]\n",
      "[Epoch 28/200] [Batch 458/637] [D loss: 0.180088] [G loss: 0.459219]\n",
      "[Epoch 28/200] [Batch 459/637] [D loss: 0.183097] [G loss: 0.442991]\n",
      "[Epoch 28/200] [Batch 460/637] [D loss: 0.189173] [G loss: 0.458163]\n",
      "[Epoch 28/200] [Batch 461/637] [D loss: 0.188645] [G loss: 0.466449]\n",
      "[Epoch 28/200] [Batch 462/637] [D loss: 0.182694] [G loss: 0.535372]\n",
      "[Epoch 28/200] [Batch 463/637] [D loss: 0.201755] [G loss: 0.555227]\n",
      "[Epoch 28/200] [Batch 464/637] [D loss: 0.183749] [G loss: 0.511504]\n",
      "[Epoch 28/200] [Batch 465/637] [D loss: 0.204440] [G loss: 0.472712]\n",
      "[Epoch 28/200] [Batch 466/637] [D loss: 0.187232] [G loss: 0.452475]\n",
      "[Epoch 28/200] [Batch 467/637] [D loss: 0.177347] [G loss: 0.505758]\n",
      "[Epoch 28/200] [Batch 468/637] [D loss: 0.191374] [G loss: 0.431687]\n",
      "[Epoch 28/200] [Batch 469/637] [D loss: 0.186164] [G loss: 0.467278]\n",
      "[Epoch 28/200] [Batch 470/637] [D loss: 0.180382] [G loss: 0.469519]\n",
      "[Epoch 28/200] [Batch 471/637] [D loss: 0.187146] [G loss: 0.445417]\n",
      "[Epoch 28/200] [Batch 472/637] [D loss: 0.188026] [G loss: 0.482730]\n",
      "[Epoch 28/200] [Batch 473/637] [D loss: 0.172427] [G loss: 0.474545]\n",
      "[Epoch 28/200] [Batch 474/637] [D loss: 0.175952] [G loss: 0.489420]\n",
      "[Epoch 28/200] [Batch 475/637] [D loss: 0.180663] [G loss: 0.453599]\n",
      "[Epoch 28/200] [Batch 476/637] [D loss: 0.161283] [G loss: 0.472432]\n",
      "[Epoch 28/200] [Batch 477/637] [D loss: 0.179145] [G loss: 0.451378]\n",
      "[Epoch 28/200] [Batch 478/637] [D loss: 0.176945] [G loss: 0.446999]\n",
      "[Epoch 28/200] [Batch 479/637] [D loss: 0.222423] [G loss: 0.465708]\n",
      "[Epoch 28/200] [Batch 480/637] [D loss: 0.181470] [G loss: 0.488052]\n",
      "[Epoch 28/200] [Batch 481/637] [D loss: 0.177876] [G loss: 0.471007]\n",
      "[Epoch 28/200] [Batch 482/637] [D loss: 0.172653] [G loss: 0.430642]\n",
      "[Epoch 28/200] [Batch 483/637] [D loss: 0.174966] [G loss: 0.414023]\n",
      "[Epoch 28/200] [Batch 484/637] [D loss: 0.164063] [G loss: 0.414865]\n",
      "[Epoch 28/200] [Batch 485/637] [D loss: 0.160563] [G loss: 0.436891]\n",
      "[Epoch 28/200] [Batch 486/637] [D loss: 0.182554] [G loss: 0.458159]\n",
      "[Epoch 28/200] [Batch 487/637] [D loss: 0.222122] [G loss: 0.495141]\n",
      "[Epoch 28/200] [Batch 488/637] [D loss: 0.217426] [G loss: 0.485455]\n",
      "[Epoch 28/200] [Batch 489/637] [D loss: 0.195826] [G loss: 0.592576]\n",
      "[Epoch 28/200] [Batch 490/637] [D loss: 0.159833] [G loss: 0.515016]\n",
      "[Epoch 28/200] [Batch 491/637] [D loss: 0.160154] [G loss: 0.412541]\n",
      "[Epoch 28/200] [Batch 492/637] [D loss: 0.151558] [G loss: 0.430367]\n",
      "[Epoch 28/200] [Batch 493/637] [D loss: 0.148930] [G loss: 0.454428]\n",
      "[Epoch 28/200] [Batch 494/637] [D loss: 0.165154] [G loss: 0.440876]\n",
      "[Epoch 28/200] [Batch 495/637] [D loss: 0.158709] [G loss: 0.530737]\n",
      "[Epoch 28/200] [Batch 496/637] [D loss: 0.176510] [G loss: 0.556264]\n",
      "[Epoch 28/200] [Batch 497/637] [D loss: 0.181392] [G loss: 0.470156]\n",
      "[Epoch 28/200] [Batch 498/637] [D loss: 0.178493] [G loss: 0.468440]\n",
      "[Epoch 28/200] [Batch 499/637] [D loss: 0.186512] [G loss: 0.497068]\n",
      "[Epoch 28/200] [Batch 500/637] [D loss: 0.193345] [G loss: 0.473817]\n",
      "[Epoch 28/200] [Batch 501/637] [D loss: 0.172272] [G loss: 0.461600]\n",
      "[Epoch 28/200] [Batch 502/637] [D loss: 0.167751] [G loss: 0.522916]\n",
      "[Epoch 28/200] [Batch 503/637] [D loss: 0.175281] [G loss: 0.457441]\n",
      "[Epoch 28/200] [Batch 504/637] [D loss: 0.178705] [G loss: 0.476242]\n",
      "[Epoch 28/200] [Batch 505/637] [D loss: 0.184922] [G loss: 0.484185]\n",
      "[Epoch 28/200] [Batch 506/637] [D loss: 0.182964] [G loss: 0.441074]\n",
      "[Epoch 28/200] [Batch 507/637] [D loss: 0.188647] [G loss: 0.412102]\n",
      "[Epoch 28/200] [Batch 508/637] [D loss: 0.177325] [G loss: 0.502288]\n",
      "[Epoch 28/200] [Batch 509/637] [D loss: 0.180784] [G loss: 0.558554]\n",
      "[Epoch 28/200] [Batch 510/637] [D loss: 0.220377] [G loss: 0.421835]\n",
      "[Epoch 28/200] [Batch 511/637] [D loss: 0.265091] [G loss: 0.456513]\n",
      "[Epoch 28/200] [Batch 512/637] [D loss: 0.177311] [G loss: 0.502571]\n",
      "[Epoch 28/200] [Batch 513/637] [D loss: 0.187437] [G loss: 0.455333]\n",
      "[Epoch 28/200] [Batch 514/637] [D loss: 0.179464] [G loss: 0.448511]\n",
      "[Epoch 28/200] [Batch 515/637] [D loss: 0.162051] [G loss: 0.437450]\n",
      "[Epoch 28/200] [Batch 516/637] [D loss: 0.155568] [G loss: 0.513257]\n",
      "[Epoch 28/200] [Batch 517/637] [D loss: 0.210287] [G loss: 0.425371]\n",
      "[Epoch 28/200] [Batch 518/637] [D loss: 0.196849] [G loss: 0.609023]\n",
      "[Epoch 28/200] [Batch 519/637] [D loss: 0.166042] [G loss: 0.589259]\n",
      "[Epoch 28/200] [Batch 520/637] [D loss: 0.179079] [G loss: 0.423633]\n",
      "[Epoch 28/200] [Batch 521/637] [D loss: 0.158160] [G loss: 0.458966]\n",
      "[Epoch 28/200] [Batch 522/637] [D loss: 0.163721] [G loss: 0.420933]\n",
      "[Epoch 28/200] [Batch 523/637] [D loss: 0.183221] [G loss: 0.440317]\n",
      "[Epoch 28/200] [Batch 524/637] [D loss: 0.170493] [G loss: 0.716645]\n",
      "[Epoch 28/200] [Batch 525/637] [D loss: 0.203868] [G loss: 0.547411]\n",
      "[Epoch 28/200] [Batch 526/637] [D loss: 0.187680] [G loss: 0.494868]\n",
      "[Epoch 28/200] [Batch 527/637] [D loss: 0.204678] [G loss: 0.465381]\n",
      "[Epoch 28/200] [Batch 528/637] [D loss: 0.165556] [G loss: 0.528229]\n",
      "[Epoch 28/200] [Batch 529/637] [D loss: 0.187517] [G loss: 0.428124]\n",
      "[Epoch 28/200] [Batch 530/637] [D loss: 0.174334] [G loss: 0.493723]\n",
      "[Epoch 28/200] [Batch 531/637] [D loss: 0.167026] [G loss: 0.490713]\n",
      "[Epoch 28/200] [Batch 532/637] [D loss: 0.155123] [G loss: 0.487912]\n",
      "[Epoch 28/200] [Batch 533/637] [D loss: 0.171963] [G loss: 0.490089]\n",
      "[Epoch 28/200] [Batch 534/637] [D loss: 0.170545] [G loss: 0.454635]\n",
      "[Epoch 28/200] [Batch 535/637] [D loss: 0.207495] [G loss: 0.490427]\n",
      "[Epoch 28/200] [Batch 536/637] [D loss: 0.159736] [G loss: 0.554157]\n",
      "[Epoch 28/200] [Batch 537/637] [D loss: 0.193078] [G loss: 0.472113]\n",
      "[Epoch 28/200] [Batch 538/637] [D loss: 0.152073] [G loss: 0.431372]\n",
      "[Epoch 28/200] [Batch 539/637] [D loss: 0.154166] [G loss: 0.438555]\n",
      "[Epoch 28/200] [Batch 540/637] [D loss: 0.161239] [G loss: 0.413075]\n",
      "[Epoch 28/200] [Batch 541/637] [D loss: 0.183770] [G loss: 0.450624]\n",
      "[Epoch 28/200] [Batch 542/637] [D loss: 0.189238] [G loss: 0.472077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/200] [Batch 543/637] [D loss: 0.171020] [G loss: 0.545149]\n",
      "[Epoch 28/200] [Batch 544/637] [D loss: 0.167365] [G loss: 0.571062]\n",
      "[Epoch 28/200] [Batch 545/637] [D loss: 0.164497] [G loss: 0.573171]\n",
      "[Epoch 28/200] [Batch 546/637] [D loss: 0.166445] [G loss: 0.410655]\n",
      "[Epoch 28/200] [Batch 547/637] [D loss: 0.156391] [G loss: 0.453471]\n",
      "[Epoch 28/200] [Batch 548/637] [D loss: 0.154943] [G loss: 0.488428]\n",
      "[Epoch 28/200] [Batch 549/637] [D loss: 0.168582] [G loss: 0.507607]\n",
      "[Epoch 28/200] [Batch 550/637] [D loss: 0.174141] [G loss: 0.474718]\n",
      "[Epoch 28/200] [Batch 551/637] [D loss: 0.170750] [G loss: 0.484628]\n",
      "[Epoch 28/200] [Batch 552/637] [D loss: 0.174284] [G loss: 0.434075]\n",
      "[Epoch 28/200] [Batch 553/637] [D loss: 0.132690] [G loss: 0.561739]\n",
      "[Epoch 28/200] [Batch 554/637] [D loss: 0.152244] [G loss: 0.610035]\n",
      "[Epoch 28/200] [Batch 555/637] [D loss: 0.169873] [G loss: 0.503644]\n",
      "[Epoch 28/200] [Batch 556/637] [D loss: 0.144048] [G loss: 0.480987]\n",
      "[Epoch 28/200] [Batch 557/637] [D loss: 0.173278] [G loss: 0.423971]\n",
      "[Epoch 28/200] [Batch 558/637] [D loss: 0.169416] [G loss: 0.533878]\n",
      "[Epoch 28/200] [Batch 559/637] [D loss: 0.152089] [G loss: 0.609093]\n",
      "[Epoch 28/200] [Batch 560/637] [D loss: 0.178313] [G loss: 0.463371]\n",
      "[Epoch 28/200] [Batch 561/637] [D loss: 0.208036] [G loss: 0.376603]\n",
      "[Epoch 28/200] [Batch 562/637] [D loss: 0.197785] [G loss: 0.486046]\n",
      "[Epoch 28/200] [Batch 563/637] [D loss: 0.187118] [G loss: 0.502165]\n",
      "[Epoch 28/200] [Batch 564/637] [D loss: 0.179681] [G loss: 0.490567]\n",
      "[Epoch 28/200] [Batch 565/637] [D loss: 0.161565] [G loss: 0.507452]\n",
      "[Epoch 28/200] [Batch 566/637] [D loss: 0.207869] [G loss: 0.432792]\n",
      "[Epoch 28/200] [Batch 567/637] [D loss: 0.174880] [G loss: 0.451668]\n",
      "[Epoch 28/200] [Batch 568/637] [D loss: 0.215444] [G loss: 0.426042]\n",
      "[Epoch 28/200] [Batch 569/637] [D loss: 0.183791] [G loss: 0.476414]\n",
      "[Epoch 28/200] [Batch 570/637] [D loss: 0.162732] [G loss: 0.502218]\n",
      "[Epoch 28/200] [Batch 571/637] [D loss: 0.181626] [G loss: 0.448535]\n",
      "[Epoch 28/200] [Batch 572/637] [D loss: 0.188298] [G loss: 0.447508]\n",
      "[Epoch 28/200] [Batch 573/637] [D loss: 0.182892] [G loss: 0.471767]\n",
      "[Epoch 28/200] [Batch 574/637] [D loss: 0.183812] [G loss: 0.438307]\n",
      "[Epoch 28/200] [Batch 575/637] [D loss: 0.162884] [G loss: 0.442385]\n",
      "[Epoch 28/200] [Batch 576/637] [D loss: 0.149090] [G loss: 0.501440]\n",
      "[Epoch 28/200] [Batch 577/637] [D loss: 0.141762] [G loss: 0.489781]\n",
      "[Epoch 28/200] [Batch 578/637] [D loss: 0.174677] [G loss: 0.483285]\n",
      "[Epoch 28/200] [Batch 579/637] [D loss: 0.183639] [G loss: 0.466585]\n",
      "[Epoch 28/200] [Batch 580/637] [D loss: 0.172696] [G loss: 0.537142]\n",
      "[Epoch 28/200] [Batch 581/637] [D loss: 0.175496] [G loss: 0.457419]\n",
      "[Epoch 28/200] [Batch 582/637] [D loss: 0.165756] [G loss: 0.434439]\n",
      "[Epoch 28/200] [Batch 583/637] [D loss: 0.160159] [G loss: 0.557713]\n",
      "[Epoch 28/200] [Batch 584/637] [D loss: 0.177587] [G loss: 0.491393]\n",
      "[Epoch 28/200] [Batch 585/637] [D loss: 0.179586] [G loss: 0.455434]\n",
      "[Epoch 28/200] [Batch 586/637] [D loss: 0.184324] [G loss: 0.525137]\n",
      "[Epoch 28/200] [Batch 587/637] [D loss: 0.164161] [G loss: 0.494150]\n",
      "[Epoch 28/200] [Batch 588/637] [D loss: 0.200811] [G loss: 0.417434]\n",
      "[Epoch 28/200] [Batch 589/637] [D loss: 0.147591] [G loss: 0.600321]\n",
      "[Epoch 28/200] [Batch 590/637] [D loss: 0.154096] [G loss: 0.564094]\n",
      "[Epoch 28/200] [Batch 591/637] [D loss: 0.143347] [G loss: 0.503921]\n",
      "[Epoch 28/200] [Batch 592/637] [D loss: 0.249562] [G loss: 0.447801]\n",
      "[Epoch 28/200] [Batch 593/637] [D loss: 0.179308] [G loss: 0.555828]\n",
      "[Epoch 28/200] [Batch 594/637] [D loss: 0.168888] [G loss: 0.474125]\n",
      "[Epoch 28/200] [Batch 595/637] [D loss: 0.163103] [G loss: 0.488362]\n",
      "[Epoch 28/200] [Batch 596/637] [D loss: 0.130888] [G loss: 0.506439]\n",
      "[Epoch 28/200] [Batch 597/637] [D loss: 0.147742] [G loss: 0.483496]\n",
      "[Epoch 28/200] [Batch 598/637] [D loss: 0.166656] [G loss: 0.473889]\n",
      "[Epoch 28/200] [Batch 599/637] [D loss: 0.186413] [G loss: 0.539218]\n",
      "[Epoch 28/200] [Batch 600/637] [D loss: 0.145218] [G loss: 0.507853]\n",
      "[Epoch 28/200] [Batch 601/637] [D loss: 0.156295] [G loss: 0.554151]\n",
      "[Epoch 28/200] [Batch 602/637] [D loss: 0.149204] [G loss: 0.528602]\n",
      "[Epoch 28/200] [Batch 603/637] [D loss: 0.159601] [G loss: 0.535749]\n",
      "[Epoch 28/200] [Batch 604/637] [D loss: 0.191569] [G loss: 0.519386]\n",
      "[Epoch 28/200] [Batch 605/637] [D loss: 0.202286] [G loss: 0.478071]\n",
      "[Epoch 28/200] [Batch 606/637] [D loss: 0.170127] [G loss: 0.581775]\n",
      "[Epoch 28/200] [Batch 607/637] [D loss: 0.178750] [G loss: 0.553059]\n",
      "[Epoch 28/200] [Batch 608/637] [D loss: 0.183263] [G loss: 0.475094]\n",
      "[Epoch 28/200] [Batch 609/637] [D loss: 0.176468] [G loss: 0.428064]\n",
      "[Epoch 28/200] [Batch 610/637] [D loss: 0.193675] [G loss: 0.413124]\n",
      "[Epoch 28/200] [Batch 611/637] [D loss: 0.186352] [G loss: 0.426777]\n",
      "[Epoch 28/200] [Batch 612/637] [D loss: 0.166286] [G loss: 0.501457]\n",
      "[Epoch 28/200] [Batch 613/637] [D loss: 0.207957] [G loss: 0.577595]\n",
      "[Epoch 28/200] [Batch 614/637] [D loss: 0.191228] [G loss: 0.510577]\n",
      "[Epoch 28/200] [Batch 615/637] [D loss: 0.182575] [G loss: 0.467969]\n",
      "[Epoch 28/200] [Batch 616/637] [D loss: 0.168566] [G loss: 0.449919]\n",
      "[Epoch 28/200] [Batch 617/637] [D loss: 0.201721] [G loss: 0.397063]\n",
      "[Epoch 28/200] [Batch 618/637] [D loss: 0.201740] [G loss: 0.414473]\n",
      "[Epoch 28/200] [Batch 619/637] [D loss: 0.190714] [G loss: 0.446630]\n",
      "[Epoch 28/200] [Batch 620/637] [D loss: 0.183818] [G loss: 0.482437]\n",
      "[Epoch 28/200] [Batch 621/637] [D loss: 0.180441] [G loss: 0.461221]\n",
      "[Epoch 28/200] [Batch 622/637] [D loss: 0.163354] [G loss: 0.457895]\n",
      "[Epoch 28/200] [Batch 623/637] [D loss: 0.200823] [G loss: 0.425638]\n",
      "[Epoch 28/200] [Batch 624/637] [D loss: 0.163168] [G loss: 0.458296]\n",
      "[Epoch 28/200] [Batch 625/637] [D loss: 0.170914] [G loss: 0.480206]\n",
      "[Epoch 28/200] [Batch 626/637] [D loss: 0.150619] [G loss: 0.511994]\n",
      "[Epoch 28/200] [Batch 627/637] [D loss: 0.160870] [G loss: 0.506281]\n",
      "[Epoch 28/200] [Batch 628/637] [D loss: 0.154405] [G loss: 0.481191]\n",
      "[Epoch 28/200] [Batch 629/637] [D loss: 0.157664] [G loss: 0.550342]\n",
      "[Epoch 28/200] [Batch 630/637] [D loss: 0.181509] [G loss: 0.476074]\n",
      "[Epoch 28/200] [Batch 631/637] [D loss: 0.178502] [G loss: 0.540527]\n",
      "[Epoch 28/200] [Batch 632/637] [D loss: 0.193536] [G loss: 0.572652]\n",
      "[Epoch 28/200] [Batch 633/637] [D loss: 0.178647] [G loss: 0.531520]\n",
      "[Epoch 28/200] [Batch 634/637] [D loss: 0.238475] [G loss: 0.467817]\n",
      "[Epoch 28/200] [Batch 635/637] [D loss: 0.178786] [G loss: 0.480254]\n",
      "[Epoch 28/200] [Batch 636/637] [D loss: 0.133358] [G loss: 0.536421]\n",
      "[Epoch 29/200] [Batch 0/637] [D loss: 0.182252] [G loss: 0.464240]\n",
      "[Epoch 29/200] [Batch 1/637] [D loss: 0.167761] [G loss: 0.463326]\n",
      "[Epoch 29/200] [Batch 2/637] [D loss: 0.163153] [G loss: 0.530806]\n",
      "[Epoch 29/200] [Batch 3/637] [D loss: 0.176980] [G loss: 0.464336]\n",
      "[Epoch 29/200] [Batch 4/637] [D loss: 0.157793] [G loss: 0.579191]\n",
      "[Epoch 29/200] [Batch 5/637] [D loss: 0.179435] [G loss: 0.485628]\n",
      "[Epoch 29/200] [Batch 6/637] [D loss: 0.184842] [G loss: 0.477903]\n",
      "[Epoch 29/200] [Batch 7/637] [D loss: 0.172585] [G loss: 0.437629]\n",
      "[Epoch 29/200] [Batch 8/637] [D loss: 0.154642] [G loss: 0.506911]\n",
      "[Epoch 29/200] [Batch 9/637] [D loss: 0.164793] [G loss: 0.466607]\n",
      "[Epoch 29/200] [Batch 10/637] [D loss: 0.156658] [G loss: 0.491304]\n",
      "[Epoch 29/200] [Batch 11/637] [D loss: 0.187342] [G loss: 0.493716]\n",
      "[Epoch 29/200] [Batch 12/637] [D loss: 0.147735] [G loss: 0.563262]\n",
      "[Epoch 29/200] [Batch 13/637] [D loss: 0.189199] [G loss: 0.501380]\n",
      "[Epoch 29/200] [Batch 14/637] [D loss: 0.195769] [G loss: 0.668800]\n",
      "[Epoch 29/200] [Batch 15/637] [D loss: 0.166999] [G loss: 0.524698]\n",
      "[Epoch 29/200] [Batch 16/637] [D loss: 0.141462] [G loss: 0.521360]\n",
      "[Epoch 29/200] [Batch 17/637] [D loss: 0.172572] [G loss: 0.415729]\n",
      "[Epoch 29/200] [Batch 18/637] [D loss: 0.180346] [G loss: 0.467449]\n",
      "[Epoch 29/200] [Batch 19/637] [D loss: 0.168394] [G loss: 0.468299]\n",
      "[Epoch 29/200] [Batch 20/637] [D loss: 0.164307] [G loss: 0.520043]\n",
      "[Epoch 29/200] [Batch 21/637] [D loss: 0.195509] [G loss: 0.398739]\n",
      "[Epoch 29/200] [Batch 22/637] [D loss: 0.179749] [G loss: 0.503045]\n",
      "[Epoch 29/200] [Batch 23/637] [D loss: 0.203626] [G loss: 0.583034]\n",
      "[Epoch 29/200] [Batch 24/637] [D loss: 0.164030] [G loss: 0.456935]\n",
      "[Epoch 29/200] [Batch 25/637] [D loss: 0.159845] [G loss: 0.519393]\n",
      "[Epoch 29/200] [Batch 26/637] [D loss: 0.194463] [G loss: 0.458814]\n",
      "[Epoch 29/200] [Batch 27/637] [D loss: 0.169144] [G loss: 0.486674]\n",
      "[Epoch 29/200] [Batch 28/637] [D loss: 0.166860] [G loss: 0.492668]\n",
      "[Epoch 29/200] [Batch 29/637] [D loss: 0.192933] [G loss: 0.400334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/200] [Batch 30/637] [D loss: 0.176183] [G loss: 0.400291]\n",
      "[Epoch 29/200] [Batch 31/637] [D loss: 0.169443] [G loss: 0.466213]\n",
      "[Epoch 29/200] [Batch 32/637] [D loss: 0.174966] [G loss: 0.468959]\n",
      "[Epoch 29/200] [Batch 33/637] [D loss: 0.170833] [G loss: 0.453657]\n",
      "[Epoch 29/200] [Batch 34/637] [D loss: 0.170124] [G loss: 0.462797]\n",
      "[Epoch 29/200] [Batch 35/637] [D loss: 0.173657] [G loss: 0.516304]\n",
      "[Epoch 29/200] [Batch 36/637] [D loss: 0.158145] [G loss: 0.488553]\n",
      "[Epoch 29/200] [Batch 37/637] [D loss: 0.162488] [G loss: 0.477594]\n",
      "[Epoch 29/200] [Batch 38/637] [D loss: 0.181477] [G loss: 0.433402]\n",
      "[Epoch 29/200] [Batch 39/637] [D loss: 0.164686] [G loss: 0.510388]\n",
      "[Epoch 29/200] [Batch 40/637] [D loss: 0.209573] [G loss: 0.549777]\n",
      "[Epoch 29/200] [Batch 41/637] [D loss: 0.193473] [G loss: 0.485410]\n",
      "[Epoch 29/200] [Batch 42/637] [D loss: 0.179516] [G loss: 0.465566]\n",
      "[Epoch 29/200] [Batch 43/637] [D loss: 0.158901] [G loss: 0.411956]\n",
      "[Epoch 29/200] [Batch 44/637] [D loss: 0.158349] [G loss: 0.428055]\n",
      "[Epoch 29/200] [Batch 45/637] [D loss: 0.156348] [G loss: 0.484877]\n",
      "[Epoch 29/200] [Batch 46/637] [D loss: 0.189295] [G loss: 0.421955]\n",
      "[Epoch 29/200] [Batch 47/637] [D loss: 0.158884] [G loss: 0.496169]\n",
      "[Epoch 29/200] [Batch 48/637] [D loss: 0.175345] [G loss: 0.482399]\n",
      "[Epoch 29/200] [Batch 49/637] [D loss: 0.187636] [G loss: 0.426775]\n",
      "[Epoch 29/200] [Batch 50/637] [D loss: 0.164071] [G loss: 0.434083]\n",
      "[Epoch 29/200] [Batch 51/637] [D loss: 0.161086] [G loss: 0.465263]\n",
      "[Epoch 29/200] [Batch 52/637] [D loss: 0.163891] [G loss: 0.465687]\n",
      "[Epoch 29/200] [Batch 53/637] [D loss: 0.184887] [G loss: 0.459318]\n",
      "[Epoch 29/200] [Batch 54/637] [D loss: 0.188449] [G loss: 0.416645]\n",
      "[Epoch 29/200] [Batch 55/637] [D loss: 0.175971] [G loss: 0.497559]\n",
      "[Epoch 29/200] [Batch 56/637] [D loss: 0.148415] [G loss: 0.458266]\n",
      "[Epoch 29/200] [Batch 57/637] [D loss: 0.194350] [G loss: 0.402289]\n",
      "[Epoch 29/200] [Batch 58/637] [D loss: 0.161247] [G loss: 0.469773]\n",
      "[Epoch 29/200] [Batch 59/637] [D loss: 0.162246] [G loss: 0.529606]\n",
      "[Epoch 29/200] [Batch 60/637] [D loss: 0.181837] [G loss: 0.433671]\n",
      "[Epoch 29/200] [Batch 61/637] [D loss: 0.177644] [G loss: 0.496024]\n",
      "[Epoch 29/200] [Batch 62/637] [D loss: 0.146424] [G loss: 0.473894]\n",
      "[Epoch 29/200] [Batch 63/637] [D loss: 0.190590] [G loss: 0.418553]\n",
      "[Epoch 29/200] [Batch 64/637] [D loss: 0.154650] [G loss: 0.524274]\n",
      "[Epoch 29/200] [Batch 65/637] [D loss: 0.166031] [G loss: 0.486057]\n",
      "[Epoch 29/200] [Batch 66/637] [D loss: 0.186536] [G loss: 0.445321]\n",
      "[Epoch 29/200] [Batch 67/637] [D loss: 0.183991] [G loss: 0.402145]\n",
      "[Epoch 29/200] [Batch 68/637] [D loss: 0.162559] [G loss: 0.523803]\n",
      "[Epoch 29/200] [Batch 69/637] [D loss: 0.169683] [G loss: 0.526632]\n",
      "[Epoch 29/200] [Batch 70/637] [D loss: 0.166620] [G loss: 0.510501]\n",
      "[Epoch 29/200] [Batch 71/637] [D loss: 0.170488] [G loss: 0.469115]\n",
      "[Epoch 29/200] [Batch 72/637] [D loss: 0.163321] [G loss: 0.493439]\n",
      "[Epoch 29/200] [Batch 73/637] [D loss: 0.212266] [G loss: 0.481245]\n",
      "[Epoch 29/200] [Batch 74/637] [D loss: 0.176920] [G loss: 0.580262]\n",
      "[Epoch 29/200] [Batch 75/637] [D loss: 0.205025] [G loss: 0.532201]\n",
      "[Epoch 29/200] [Batch 76/637] [D loss: 0.164221] [G loss: 0.469849]\n",
      "[Epoch 29/200] [Batch 77/637] [D loss: 0.152762] [G loss: 0.474684]\n",
      "[Epoch 29/200] [Batch 78/637] [D loss: 0.163634] [G loss: 0.423234]\n",
      "[Epoch 29/200] [Batch 79/637] [D loss: 0.143940] [G loss: 0.504435]\n",
      "[Epoch 29/200] [Batch 80/637] [D loss: 0.173857] [G loss: 0.396063]\n",
      "[Epoch 29/200] [Batch 81/637] [D loss: 0.183011] [G loss: 0.529863]\n",
      "[Epoch 29/200] [Batch 82/637] [D loss: 0.180627] [G loss: 0.581077]\n",
      "[Epoch 29/200] [Batch 83/637] [D loss: 0.154572] [G loss: 0.585633]\n",
      "[Epoch 29/200] [Batch 84/637] [D loss: 0.191433] [G loss: 0.495097]\n",
      "[Epoch 29/200] [Batch 85/637] [D loss: 0.174051] [G loss: 0.535201]\n",
      "[Epoch 29/200] [Batch 86/637] [D loss: 0.165838] [G loss: 0.480507]\n",
      "[Epoch 29/200] [Batch 87/637] [D loss: 0.193104] [G loss: 0.472524]\n",
      "[Epoch 29/200] [Batch 88/637] [D loss: 0.190357] [G loss: 0.430395]\n",
      "[Epoch 29/200] [Batch 89/637] [D loss: 0.164130] [G loss: 0.448987]\n",
      "[Epoch 29/200] [Batch 90/637] [D loss: 0.193896] [G loss: 0.477241]\n",
      "[Epoch 29/200] [Batch 91/637] [D loss: 0.176922] [G loss: 0.506635]\n",
      "[Epoch 29/200] [Batch 92/637] [D loss: 0.174163] [G loss: 0.558654]\n",
      "[Epoch 29/200] [Batch 93/637] [D loss: 0.172624] [G loss: 0.482752]\n",
      "[Epoch 29/200] [Batch 94/637] [D loss: 0.210218] [G loss: 0.386369]\n",
      "[Epoch 29/200] [Batch 95/637] [D loss: 0.179999] [G loss: 0.439548]\n",
      "[Epoch 29/200] [Batch 96/637] [D loss: 0.203100] [G loss: 0.481569]\n",
      "[Epoch 29/200] [Batch 97/637] [D loss: 0.173551] [G loss: 0.493301]\n",
      "[Epoch 29/200] [Batch 98/637] [D loss: 0.171246] [G loss: 0.503508]\n",
      "[Epoch 29/200] [Batch 99/637] [D loss: 0.192715] [G loss: 0.437358]\n",
      "[Epoch 29/200] [Batch 100/637] [D loss: 0.190206] [G loss: 0.449463]\n",
      "[Epoch 29/200] [Batch 101/637] [D loss: 0.182639] [G loss: 0.430015]\n",
      "[Epoch 29/200] [Batch 102/637] [D loss: 0.161709] [G loss: 0.428839]\n",
      "[Epoch 29/200] [Batch 103/637] [D loss: 0.164402] [G loss: 0.510731]\n",
      "[Epoch 29/200] [Batch 104/637] [D loss: 0.193271] [G loss: 0.422002]\n",
      "[Epoch 29/200] [Batch 105/637] [D loss: 0.168462] [G loss: 0.474656]\n",
      "[Epoch 29/200] [Batch 106/637] [D loss: 0.176294] [G loss: 0.545895]\n",
      "[Epoch 29/200] [Batch 107/637] [D loss: 0.197219] [G loss: 0.493987]\n",
      "[Epoch 29/200] [Batch 108/637] [D loss: 0.173016] [G loss: 0.437626]\n",
      "[Epoch 29/200] [Batch 109/637] [D loss: 0.186344] [G loss: 0.448137]\n",
      "[Epoch 29/200] [Batch 110/637] [D loss: 0.168439] [G loss: 0.498733]\n",
      "[Epoch 29/200] [Batch 111/637] [D loss: 0.154125] [G loss: 0.487424]\n",
      "[Epoch 29/200] [Batch 112/637] [D loss: 0.171764] [G loss: 0.437078]\n",
      "[Epoch 29/200] [Batch 113/637] [D loss: 0.171999] [G loss: 0.507381]\n",
      "[Epoch 29/200] [Batch 114/637] [D loss: 0.197378] [G loss: 0.505542]\n",
      "[Epoch 29/200] [Batch 115/637] [D loss: 0.202463] [G loss: 0.442382]\n",
      "[Epoch 29/200] [Batch 116/637] [D loss: 0.154338] [G loss: 0.528291]\n",
      "[Epoch 29/200] [Batch 117/637] [D loss: 0.195379] [G loss: 0.438291]\n",
      "[Epoch 29/200] [Batch 118/637] [D loss: 0.190167] [G loss: 0.484839]\n",
      "[Epoch 29/200] [Batch 119/637] [D loss: 0.183164] [G loss: 0.527454]\n",
      "[Epoch 29/200] [Batch 120/637] [D loss: 0.178147] [G loss: 0.475323]\n",
      "[Epoch 29/200] [Batch 121/637] [D loss: 0.175869] [G loss: 0.484328]\n",
      "[Epoch 29/200] [Batch 122/637] [D loss: 0.172989] [G loss: 0.453669]\n",
      "[Epoch 29/200] [Batch 123/637] [D loss: 0.190647] [G loss: 0.438787]\n",
      "[Epoch 29/200] [Batch 124/637] [D loss: 0.183651] [G loss: 0.512264]\n",
      "[Epoch 29/200] [Batch 125/637] [D loss: 0.192317] [G loss: 0.466270]\n",
      "[Epoch 29/200] [Batch 126/637] [D loss: 0.171234] [G loss: 0.434167]\n",
      "[Epoch 29/200] [Batch 127/637] [D loss: 0.163449] [G loss: 0.499526]\n",
      "[Epoch 29/200] [Batch 128/637] [D loss: 0.169160] [G loss: 0.471433]\n",
      "[Epoch 29/200] [Batch 129/637] [D loss: 0.183750] [G loss: 0.456943]\n",
      "[Epoch 29/200] [Batch 130/637] [D loss: 0.165420] [G loss: 0.530668]\n",
      "[Epoch 29/200] [Batch 131/637] [D loss: 0.156174] [G loss: 0.546993]\n",
      "[Epoch 29/200] [Batch 132/637] [D loss: 0.208680] [G loss: 0.447516]\n",
      "[Epoch 29/200] [Batch 133/637] [D loss: 0.175875] [G loss: 0.463953]\n",
      "[Epoch 29/200] [Batch 134/637] [D loss: 0.168508] [G loss: 0.509452]\n",
      "[Epoch 29/200] [Batch 135/637] [D loss: 0.183693] [G loss: 0.488487]\n",
      "[Epoch 29/200] [Batch 136/637] [D loss: 0.175993] [G loss: 0.504842]\n",
      "[Epoch 29/200] [Batch 137/637] [D loss: 0.174974] [G loss: 0.500062]\n",
      "[Epoch 29/200] [Batch 138/637] [D loss: 0.166492] [G loss: 0.490838]\n",
      "[Epoch 29/200] [Batch 139/637] [D loss: 0.168427] [G loss: 0.487919]\n",
      "[Epoch 29/200] [Batch 140/637] [D loss: 0.191591] [G loss: 0.487240]\n",
      "[Epoch 29/200] [Batch 141/637] [D loss: 0.174404] [G loss: 0.509702]\n",
      "[Epoch 29/200] [Batch 142/637] [D loss: 0.167883] [G loss: 0.486609]\n",
      "[Epoch 29/200] [Batch 143/637] [D loss: 0.161803] [G loss: 0.490301]\n",
      "[Epoch 29/200] [Batch 144/637] [D loss: 0.171261] [G loss: 0.452624]\n",
      "[Epoch 29/200] [Batch 145/637] [D loss: 0.156023] [G loss: 0.521755]\n",
      "[Epoch 29/200] [Batch 146/637] [D loss: 0.195614] [G loss: 0.487150]\n",
      "[Epoch 29/200] [Batch 147/637] [D loss: 0.157854] [G loss: 0.514013]\n",
      "[Epoch 29/200] [Batch 148/637] [D loss: 0.217255] [G loss: 0.471135]\n",
      "[Epoch 29/200] [Batch 149/637] [D loss: 0.168608] [G loss: 0.562700]\n",
      "[Epoch 29/200] [Batch 150/637] [D loss: 0.176059] [G loss: 0.460589]\n",
      "[Epoch 29/200] [Batch 151/637] [D loss: 0.171792] [G loss: 0.392796]\n",
      "[Epoch 29/200] [Batch 152/637] [D loss: 0.155356] [G loss: 0.469672]\n",
      "[Epoch 29/200] [Batch 153/637] [D loss: 0.144630] [G loss: 0.523688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/200] [Batch 154/637] [D loss: 0.177119] [G loss: 0.465424]\n",
      "[Epoch 29/200] [Batch 155/637] [D loss: 0.168463] [G loss: 0.515854]\n",
      "[Epoch 29/200] [Batch 156/637] [D loss: 0.148562] [G loss: 0.520783]\n",
      "[Epoch 29/200] [Batch 157/637] [D loss: 0.174801] [G loss: 0.444051]\n",
      "[Epoch 29/200] [Batch 158/637] [D loss: 0.156951] [G loss: 0.487861]\n",
      "[Epoch 29/200] [Batch 159/637] [D loss: 0.177669] [G loss: 0.472012]\n",
      "[Epoch 29/200] [Batch 160/637] [D loss: 0.173709] [G loss: 0.519848]\n",
      "[Epoch 29/200] [Batch 161/637] [D loss: 0.171711] [G loss: 0.495825]\n",
      "[Epoch 29/200] [Batch 162/637] [D loss: 0.166062] [G loss: 0.461091]\n",
      "[Epoch 29/200] [Batch 163/637] [D loss: 0.190368] [G loss: 0.543440]\n",
      "[Epoch 29/200] [Batch 164/637] [D loss: 0.211815] [G loss: 0.484515]\n",
      "[Epoch 29/200] [Batch 165/637] [D loss: 0.183617] [G loss: 0.574278]\n",
      "[Epoch 29/200] [Batch 166/637] [D loss: 0.171654] [G loss: 0.544232]\n",
      "[Epoch 29/200] [Batch 167/637] [D loss: 0.181852] [G loss: 0.378752]\n",
      "[Epoch 29/200] [Batch 168/637] [D loss: 0.203462] [G loss: 0.366797]\n",
      "[Epoch 29/200] [Batch 169/637] [D loss: 0.154524] [G loss: 0.520106]\n",
      "[Epoch 29/200] [Batch 170/637] [D loss: 0.183820] [G loss: 0.435057]\n",
      "[Epoch 29/200] [Batch 171/637] [D loss: 0.166191] [G loss: 0.501379]\n",
      "[Epoch 29/200] [Batch 172/637] [D loss: 0.164989] [G loss: 0.507467]\n",
      "[Epoch 29/200] [Batch 173/637] [D loss: 0.180688] [G loss: 0.551097]\n",
      "[Epoch 29/200] [Batch 174/637] [D loss: 0.152939] [G loss: 0.476700]\n",
      "[Epoch 29/200] [Batch 175/637] [D loss: 0.164481] [G loss: 0.474932]\n",
      "[Epoch 29/200] [Batch 176/637] [D loss: 0.180975] [G loss: 0.545675]\n",
      "[Epoch 29/200] [Batch 177/637] [D loss: 0.167791] [G loss: 0.501700]\n",
      "[Epoch 29/200] [Batch 178/637] [D loss: 0.173933] [G loss: 0.486919]\n",
      "[Epoch 29/200] [Batch 179/637] [D loss: 0.157311] [G loss: 0.465243]\n",
      "[Epoch 29/200] [Batch 180/637] [D loss: 0.166080] [G loss: 0.527875]\n",
      "[Epoch 29/200] [Batch 181/637] [D loss: 0.173539] [G loss: 0.508211]\n",
      "[Epoch 29/200] [Batch 182/637] [D loss: 0.180639] [G loss: 0.511852]\n",
      "[Epoch 29/200] [Batch 183/637] [D loss: 0.166077] [G loss: 0.494251]\n",
      "[Epoch 29/200] [Batch 184/637] [D loss: 0.151446] [G loss: 0.567886]\n",
      "[Epoch 29/200] [Batch 185/637] [D loss: 0.155729] [G loss: 0.534943]\n",
      "[Epoch 29/200] [Batch 186/637] [D loss: 0.156430] [G loss: 0.493804]\n",
      "[Epoch 29/200] [Batch 187/637] [D loss: 0.155401] [G loss: 0.555694]\n",
      "[Epoch 29/200] [Batch 188/637] [D loss: 0.145449] [G loss: 0.500865]\n",
      "[Epoch 29/200] [Batch 189/637] [D loss: 0.197281] [G loss: 0.395602]\n",
      "[Epoch 29/200] [Batch 190/637] [D loss: 0.168928] [G loss: 0.542823]\n",
      "[Epoch 29/200] [Batch 191/637] [D loss: 0.165760] [G loss: 0.517596]\n",
      "[Epoch 29/200] [Batch 192/637] [D loss: 0.171059] [G loss: 0.503163]\n",
      "[Epoch 29/200] [Batch 193/637] [D loss: 0.172019] [G loss: 0.495942]\n",
      "[Epoch 29/200] [Batch 194/637] [D loss: 0.159657] [G loss: 0.497240]\n",
      "[Epoch 29/200] [Batch 195/637] [D loss: 0.119275] [G loss: 0.589276]\n",
      "[Epoch 29/200] [Batch 196/637] [D loss: 0.169502] [G loss: 0.509248]\n",
      "[Epoch 29/200] [Batch 197/637] [D loss: 0.140513] [G loss: 0.583715]\n",
      "[Epoch 29/200] [Batch 198/637] [D loss: 0.168107] [G loss: 0.483476]\n",
      "[Epoch 29/200] [Batch 199/637] [D loss: 0.169127] [G loss: 0.479643]\n",
      "[Epoch 29/200] [Batch 200/637] [D loss: 0.174731] [G loss: 0.483747]\n",
      "[Epoch 29/200] [Batch 201/637] [D loss: 0.192464] [G loss: 0.458228]\n",
      "[Epoch 29/200] [Batch 202/637] [D loss: 0.175293] [G loss: 0.423188]\n",
      "[Epoch 29/200] [Batch 203/637] [D loss: 0.169226] [G loss: 0.449149]\n",
      "[Epoch 29/200] [Batch 204/637] [D loss: 0.159256] [G loss: 0.513091]\n",
      "[Epoch 29/200] [Batch 205/637] [D loss: 0.179696] [G loss: 0.522580]\n",
      "[Epoch 29/200] [Batch 206/637] [D loss: 0.179799] [G loss: 0.457960]\n",
      "[Epoch 29/200] [Batch 207/637] [D loss: 0.183683] [G loss: 0.445750]\n",
      "[Epoch 29/200] [Batch 208/637] [D loss: 0.186693] [G loss: 0.436178]\n",
      "[Epoch 29/200] [Batch 209/637] [D loss: 0.176731] [G loss: 0.551121]\n",
      "[Epoch 29/200] [Batch 210/637] [D loss: 0.196732] [G loss: 0.526680]\n",
      "[Epoch 29/200] [Batch 211/637] [D loss: 0.169144] [G loss: 0.468433]\n",
      "[Epoch 29/200] [Batch 212/637] [D loss: 0.150769] [G loss: 0.458304]\n",
      "[Epoch 29/200] [Batch 213/637] [D loss: 0.181312] [G loss: 0.402826]\n",
      "[Epoch 29/200] [Batch 214/637] [D loss: 0.170720] [G loss: 0.463070]\n",
      "[Epoch 29/200] [Batch 215/637] [D loss: 0.176812] [G loss: 0.471631]\n",
      "[Epoch 29/200] [Batch 216/637] [D loss: 0.129909] [G loss: 0.555109]\n",
      "[Epoch 29/200] [Batch 217/637] [D loss: 0.169602] [G loss: 0.506989]\n",
      "[Epoch 29/200] [Batch 218/637] [D loss: 0.180638] [G loss: 0.494485]\n",
      "[Epoch 29/200] [Batch 219/637] [D loss: 0.162568] [G loss: 0.517798]\n",
      "[Epoch 29/200] [Batch 220/637] [D loss: 0.180124] [G loss: 0.538229]\n",
      "[Epoch 29/200] [Batch 221/637] [D loss: 0.148977] [G loss: 0.614830]\n",
      "[Epoch 29/200] [Batch 222/637] [D loss: 0.177418] [G loss: 0.497601]\n",
      "[Epoch 29/200] [Batch 223/637] [D loss: 0.163922] [G loss: 0.433236]\n",
      "[Epoch 29/200] [Batch 224/637] [D loss: 0.183482] [G loss: 0.432672]\n",
      "[Epoch 29/200] [Batch 225/637] [D loss: 0.197117] [G loss: 0.507698]\n",
      "[Epoch 29/200] [Batch 226/637] [D loss: 0.182922] [G loss: 0.561102]\n",
      "[Epoch 29/200] [Batch 227/637] [D loss: 0.192418] [G loss: 0.526665]\n",
      "[Epoch 29/200] [Batch 228/637] [D loss: 0.178916] [G loss: 0.429635]\n",
      "[Epoch 29/200] [Batch 229/637] [D loss: 0.165644] [G loss: 0.449431]\n",
      "[Epoch 29/200] [Batch 230/637] [D loss: 0.145366] [G loss: 0.528344]\n",
      "[Epoch 29/200] [Batch 231/637] [D loss: 0.191385] [G loss: 0.507834]\n",
      "[Epoch 29/200] [Batch 232/637] [D loss: 0.158470] [G loss: 0.534317]\n",
      "[Epoch 29/200] [Batch 233/637] [D loss: 0.159624] [G loss: 0.522391]\n",
      "[Epoch 29/200] [Batch 234/637] [D loss: 0.188364] [G loss: 0.398659]\n",
      "[Epoch 29/200] [Batch 235/637] [D loss: 0.231928] [G loss: 0.387302]\n",
      "[Epoch 29/200] [Batch 236/637] [D loss: 0.177244] [G loss: 0.567454]\n",
      "[Epoch 29/200] [Batch 237/637] [D loss: 0.196475] [G loss: 0.524113]\n",
      "[Epoch 29/200] [Batch 238/637] [D loss: 0.187951] [G loss: 0.423023]\n",
      "[Epoch 29/200] [Batch 239/637] [D loss: 0.188133] [G loss: 0.476633]\n",
      "[Epoch 29/200] [Batch 240/637] [D loss: 0.222683] [G loss: 0.649200]\n",
      "[Epoch 29/200] [Batch 241/637] [D loss: 0.176926] [G loss: 0.557193]\n",
      "[Epoch 29/200] [Batch 242/637] [D loss: 0.194355] [G loss: 0.467797]\n",
      "[Epoch 29/200] [Batch 243/637] [D loss: 0.174442] [G loss: 0.494118]\n",
      "[Epoch 29/200] [Batch 244/637] [D loss: 0.177861] [G loss: 0.467653]\n",
      "[Epoch 29/200] [Batch 245/637] [D loss: 0.169185] [G loss: 0.456586]\n",
      "[Epoch 29/200] [Batch 246/637] [D loss: 0.185321] [G loss: 0.465100]\n",
      "[Epoch 29/200] [Batch 247/637] [D loss: 0.194578] [G loss: 0.572157]\n",
      "[Epoch 29/200] [Batch 248/637] [D loss: 0.165441] [G loss: 0.509286]\n",
      "[Epoch 29/200] [Batch 249/637] [D loss: 0.153184] [G loss: 0.494073]\n",
      "[Epoch 29/200] [Batch 250/637] [D loss: 0.152233] [G loss: 0.508099]\n",
      "[Epoch 29/200] [Batch 251/637] [D loss: 0.158627] [G loss: 0.483822]\n",
      "[Epoch 29/200] [Batch 252/637] [D loss: 0.157447] [G loss: 0.443463]\n",
      "[Epoch 29/200] [Batch 253/637] [D loss: 0.164390] [G loss: 0.507104]\n",
      "[Epoch 29/200] [Batch 254/637] [D loss: 0.164186] [G loss: 0.518411]\n",
      "[Epoch 29/200] [Batch 255/637] [D loss: 0.135192] [G loss: 0.522673]\n",
      "[Epoch 29/200] [Batch 256/637] [D loss: 0.183194] [G loss: 0.447547]\n",
      "[Epoch 29/200] [Batch 257/637] [D loss: 0.153936] [G loss: 0.471582]\n",
      "[Epoch 29/200] [Batch 258/637] [D loss: 0.155696] [G loss: 0.577528]\n",
      "[Epoch 29/200] [Batch 259/637] [D loss: 0.176307] [G loss: 0.427582]\n",
      "[Epoch 29/200] [Batch 260/637] [D loss: 0.176936] [G loss: 0.470921]\n",
      "[Epoch 29/200] [Batch 261/637] [D loss: 0.166020] [G loss: 0.521376]\n",
      "[Epoch 29/200] [Batch 262/637] [D loss: 0.151092] [G loss: 0.488838]\n",
      "[Epoch 29/200] [Batch 263/637] [D loss: 0.137999] [G loss: 0.526556]\n",
      "[Epoch 29/200] [Batch 264/637] [D loss: 0.177283] [G loss: 0.468143]\n",
      "[Epoch 29/200] [Batch 265/637] [D loss: 0.142334] [G loss: 0.565631]\n",
      "[Epoch 29/200] [Batch 266/637] [D loss: 0.150010] [G loss: 0.584925]\n",
      "[Epoch 29/200] [Batch 267/637] [D loss: 0.167727] [G loss: 0.477605]\n",
      "[Epoch 29/200] [Batch 268/637] [D loss: 0.169649] [G loss: 0.453511]\n",
      "[Epoch 29/200] [Batch 269/637] [D loss: 0.149901] [G loss: 0.502743]\n",
      "[Epoch 29/200] [Batch 270/637] [D loss: 0.209787] [G loss: 0.444913]\n",
      "[Epoch 29/200] [Batch 271/637] [D loss: 0.151056] [G loss: 0.503902]\n",
      "[Epoch 29/200] [Batch 272/637] [D loss: 0.162469] [G loss: 0.525585]\n",
      "[Epoch 29/200] [Batch 273/637] [D loss: 0.176919] [G loss: 0.501028]\n",
      "[Epoch 29/200] [Batch 274/637] [D loss: 0.187861] [G loss: 0.490561]\n",
      "[Epoch 29/200] [Batch 275/637] [D loss: 0.161696] [G loss: 0.509063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/200] [Batch 276/637] [D loss: 0.179029] [G loss: 0.438521]\n",
      "[Epoch 29/200] [Batch 277/637] [D loss: 0.159581] [G loss: 0.467225]\n",
      "[Epoch 29/200] [Batch 278/637] [D loss: 0.186785] [G loss: 0.517862]\n",
      "[Epoch 29/200] [Batch 279/637] [D loss: 0.142453] [G loss: 0.560011]\n",
      "[Epoch 29/200] [Batch 280/637] [D loss: 0.213765] [G loss: 0.453707]\n",
      "[Epoch 29/200] [Batch 281/637] [D loss: 0.175040] [G loss: 0.497464]\n",
      "[Epoch 29/200] [Batch 282/637] [D loss: 0.157000] [G loss: 0.546852]\n",
      "[Epoch 29/200] [Batch 283/637] [D loss: 0.182647] [G loss: 0.430952]\n",
      "[Epoch 29/200] [Batch 284/637] [D loss: 0.210209] [G loss: 0.338753]\n",
      "[Epoch 29/200] [Batch 285/637] [D loss: 0.187032] [G loss: 0.463392]\n",
      "[Epoch 29/200] [Batch 286/637] [D loss: 0.186888] [G loss: 0.530929]\n",
      "[Epoch 29/200] [Batch 287/637] [D loss: 0.176009] [G loss: 0.526477]\n",
      "[Epoch 29/200] [Batch 288/637] [D loss: 0.165458] [G loss: 0.462592]\n",
      "[Epoch 29/200] [Batch 289/637] [D loss: 0.167700] [G loss: 0.404487]\n",
      "[Epoch 29/200] [Batch 290/637] [D loss: 0.178617] [G loss: 0.462593]\n",
      "[Epoch 29/200] [Batch 291/637] [D loss: 0.174684] [G loss: 0.645480]\n",
      "[Epoch 29/200] [Batch 292/637] [D loss: 0.159277] [G loss: 0.544004]\n",
      "[Epoch 29/200] [Batch 293/637] [D loss: 0.150625] [G loss: 0.490791]\n",
      "[Epoch 29/200] [Batch 294/637] [D loss: 0.194214] [G loss: 0.395660]\n",
      "[Epoch 29/200] [Batch 295/637] [D loss: 0.155538] [G loss: 0.476421]\n",
      "[Epoch 29/200] [Batch 296/637] [D loss: 0.168993] [G loss: 0.545476]\n",
      "[Epoch 29/200] [Batch 297/637] [D loss: 0.144266] [G loss: 0.569852]\n",
      "[Epoch 29/200] [Batch 298/637] [D loss: 0.172412] [G loss: 0.516296]\n",
      "[Epoch 29/200] [Batch 299/637] [D loss: 0.163626] [G loss: 0.485595]\n",
      "[Epoch 29/200] [Batch 300/637] [D loss: 0.162887] [G loss: 0.530676]\n",
      "[Epoch 29/200] [Batch 301/637] [D loss: 0.177596] [G loss: 0.443488]\n",
      "[Epoch 29/200] [Batch 302/637] [D loss: 0.175144] [G loss: 0.492713]\n",
      "[Epoch 29/200] [Batch 303/637] [D loss: 0.165675] [G loss: 0.538393]\n",
      "[Epoch 29/200] [Batch 304/637] [D loss: 0.153698] [G loss: 0.558861]\n",
      "[Epoch 29/200] [Batch 305/637] [D loss: 0.200608] [G loss: 0.509919]\n",
      "[Epoch 29/200] [Batch 306/637] [D loss: 0.174717] [G loss: 0.526507]\n",
      "[Epoch 29/200] [Batch 307/637] [D loss: 0.196118] [G loss: 0.584344]\n",
      "[Epoch 29/200] [Batch 308/637] [D loss: 0.151852] [G loss: 0.538036]\n",
      "[Epoch 29/200] [Batch 309/637] [D loss: 0.159359] [G loss: 0.516381]\n",
      "[Epoch 29/200] [Batch 310/637] [D loss: 0.165808] [G loss: 0.497769]\n",
      "[Epoch 29/200] [Batch 311/637] [D loss: 0.172915] [G loss: 0.497144]\n",
      "[Epoch 29/200] [Batch 312/637] [D loss: 0.180298] [G loss: 0.468609]\n",
      "[Epoch 29/200] [Batch 313/637] [D loss: 0.174281] [G loss: 0.502999]\n",
      "[Epoch 29/200] [Batch 314/637] [D loss: 0.178439] [G loss: 0.458281]\n",
      "[Epoch 29/200] [Batch 315/637] [D loss: 0.181596] [G loss: 0.431207]\n",
      "[Epoch 29/200] [Batch 316/637] [D loss: 0.165755] [G loss: 0.483589]\n",
      "[Epoch 29/200] [Batch 317/637] [D loss: 0.177508] [G loss: 0.469080]\n",
      "[Epoch 29/200] [Batch 318/637] [D loss: 0.174405] [G loss: 0.425919]\n",
      "[Epoch 29/200] [Batch 319/637] [D loss: 0.180185] [G loss: 0.397183]\n",
      "[Epoch 29/200] [Batch 320/637] [D loss: 0.187663] [G loss: 0.450232]\n",
      "[Epoch 29/200] [Batch 321/637] [D loss: 0.199564] [G loss: 0.463054]\n",
      "[Epoch 29/200] [Batch 322/637] [D loss: 0.225741] [G loss: 0.393801]\n",
      "[Epoch 29/200] [Batch 323/637] [D loss: 0.178424] [G loss: 0.561134]\n",
      "[Epoch 29/200] [Batch 324/637] [D loss: 0.172930] [G loss: 0.515112]\n",
      "[Epoch 29/200] [Batch 325/637] [D loss: 0.175465] [G loss: 0.441765]\n",
      "[Epoch 29/200] [Batch 326/637] [D loss: 0.199190] [G loss: 0.403035]\n",
      "[Epoch 29/200] [Batch 327/637] [D loss: 0.180252] [G loss: 0.447863]\n",
      "[Epoch 29/200] [Batch 328/637] [D loss: 0.187835] [G loss: 0.419251]\n",
      "[Epoch 29/200] [Batch 329/637] [D loss: 0.187371] [G loss: 0.481873]\n",
      "[Epoch 29/200] [Batch 330/637] [D loss: 0.179455] [G loss: 0.500183]\n",
      "[Epoch 29/200] [Batch 331/637] [D loss: 0.173157] [G loss: 0.493551]\n",
      "[Epoch 29/200] [Batch 332/637] [D loss: 0.178392] [G loss: 0.406482]\n",
      "[Epoch 29/200] [Batch 333/637] [D loss: 0.172732] [G loss: 0.406321]\n",
      "[Epoch 29/200] [Batch 334/637] [D loss: 0.151095] [G loss: 0.568120]\n",
      "[Epoch 29/200] [Batch 335/637] [D loss: 0.179779] [G loss: 0.500073]\n",
      "[Epoch 29/200] [Batch 336/637] [D loss: 0.177671] [G loss: 0.464754]\n",
      "[Epoch 29/200] [Batch 337/637] [D loss: 0.167138] [G loss: 0.409291]\n",
      "[Epoch 29/200] [Batch 338/637] [D loss: 0.142825] [G loss: 0.488793]\n",
      "[Epoch 29/200] [Batch 339/637] [D loss: 0.162866] [G loss: 0.493741]\n",
      "[Epoch 29/200] [Batch 340/637] [D loss: 0.164095] [G loss: 0.551173]\n",
      "[Epoch 29/200] [Batch 341/637] [D loss: 0.175001] [G loss: 0.483403]\n",
      "[Epoch 29/200] [Batch 342/637] [D loss: 0.164470] [G loss: 0.405031]\n",
      "[Epoch 29/200] [Batch 343/637] [D loss: 0.177066] [G loss: 0.448277]\n",
      "[Epoch 29/200] [Batch 344/637] [D loss: 0.154818] [G loss: 0.492733]\n",
      "[Epoch 29/200] [Batch 345/637] [D loss: 0.183858] [G loss: 0.432143]\n",
      "[Epoch 29/200] [Batch 346/637] [D loss: 0.167695] [G loss: 0.585182]\n",
      "[Epoch 29/200] [Batch 347/637] [D loss: 0.135156] [G loss: 0.544632]\n",
      "[Epoch 29/200] [Batch 348/637] [D loss: 0.174274] [G loss: 0.455922]\n",
      "[Epoch 29/200] [Batch 349/637] [D loss: 0.164517] [G loss: 0.410771]\n",
      "[Epoch 29/200] [Batch 350/637] [D loss: 0.199408] [G loss: 0.509461]\n",
      "[Epoch 29/200] [Batch 351/637] [D loss: 0.163626] [G loss: 0.531595]\n",
      "[Epoch 29/200] [Batch 352/637] [D loss: 0.187398] [G loss: 0.455057]\n",
      "[Epoch 29/200] [Batch 353/637] [D loss: 0.165057] [G loss: 0.424679]\n",
      "[Epoch 29/200] [Batch 354/637] [D loss: 0.185442] [G loss: 0.437614]\n",
      "[Epoch 29/200] [Batch 355/637] [D loss: 0.175223] [G loss: 0.529610]\n",
      "[Epoch 29/200] [Batch 356/637] [D loss: 0.173086] [G loss: 0.528776]\n",
      "[Epoch 29/200] [Batch 357/637] [D loss: 0.148633] [G loss: 0.463655]\n",
      "[Epoch 29/200] [Batch 358/637] [D loss: 0.198795] [G loss: 0.410862]\n",
      "[Epoch 29/200] [Batch 359/637] [D loss: 0.213432] [G loss: 0.495619]\n",
      "[Epoch 29/200] [Batch 360/637] [D loss: 0.146773] [G loss: 0.469895]\n",
      "[Epoch 29/200] [Batch 361/637] [D loss: 0.179892] [G loss: 0.401459]\n",
      "[Epoch 29/200] [Batch 362/637] [D loss: 0.170678] [G loss: 0.520749]\n",
      "[Epoch 29/200] [Batch 363/637] [D loss: 0.173033] [G loss: 0.597089]\n",
      "[Epoch 29/200] [Batch 364/637] [D loss: 0.143180] [G loss: 0.517380]\n",
      "[Epoch 29/200] [Batch 365/637] [D loss: 0.162649] [G loss: 0.411213]\n",
      "[Epoch 29/200] [Batch 366/637] [D loss: 0.171408] [G loss: 0.479775]\n",
      "[Epoch 29/200] [Batch 367/637] [D loss: 0.166983] [G loss: 0.448320]\n",
      "[Epoch 29/200] [Batch 368/637] [D loss: 0.168825] [G loss: 0.529540]\n",
      "[Epoch 29/200] [Batch 369/637] [D loss: 0.141403] [G loss: 0.536623]\n",
      "[Epoch 29/200] [Batch 370/637] [D loss: 0.152866] [G loss: 0.509966]\n",
      "[Epoch 29/200] [Batch 371/637] [D loss: 0.159394] [G loss: 0.556148]\n",
      "[Epoch 29/200] [Batch 372/637] [D loss: 0.167365] [G loss: 0.592023]\n",
      "[Epoch 29/200] [Batch 373/637] [D loss: 0.180650] [G loss: 0.461426]\n",
      "[Epoch 29/200] [Batch 374/637] [D loss: 0.167507] [G loss: 0.469568]\n",
      "[Epoch 29/200] [Batch 375/637] [D loss: 0.159607] [G loss: 0.491560]\n",
      "[Epoch 29/200] [Batch 376/637] [D loss: 0.154954] [G loss: 0.533138]\n",
      "[Epoch 29/200] [Batch 377/637] [D loss: 0.148344] [G loss: 0.473977]\n",
      "[Epoch 29/200] [Batch 378/637] [D loss: 0.163301] [G loss: 0.524078]\n",
      "[Epoch 29/200] [Batch 379/637] [D loss: 0.219892] [G loss: 0.412741]\n",
      "[Epoch 29/200] [Batch 380/637] [D loss: 0.163814] [G loss: 0.590035]\n",
      "[Epoch 29/200] [Batch 381/637] [D loss: 0.190376] [G loss: 0.487547]\n",
      "[Epoch 29/200] [Batch 382/637] [D loss: 0.199774] [G loss: 0.503176]\n",
      "[Epoch 29/200] [Batch 383/637] [D loss: 0.192233] [G loss: 0.424010]\n",
      "[Epoch 29/200] [Batch 384/637] [D loss: 0.188616] [G loss: 0.425825]\n",
      "[Epoch 29/200] [Batch 385/637] [D loss: 0.170294] [G loss: 0.528634]\n",
      "[Epoch 29/200] [Batch 386/637] [D loss: 0.170147] [G loss: 0.504273]\n",
      "[Epoch 29/200] [Batch 387/637] [D loss: 0.178741] [G loss: 0.487479]\n",
      "[Epoch 29/200] [Batch 388/637] [D loss: 0.178809] [G loss: 0.423838]\n",
      "[Epoch 29/200] [Batch 389/637] [D loss: 0.161892] [G loss: 0.435956]\n",
      "[Epoch 29/200] [Batch 390/637] [D loss: 0.182966] [G loss: 0.484069]\n",
      "[Epoch 29/200] [Batch 391/637] [D loss: 0.184777] [G loss: 0.476316]\n",
      "[Epoch 29/200] [Batch 392/637] [D loss: 0.180554] [G loss: 0.517436]\n",
      "[Epoch 29/200] [Batch 393/637] [D loss: 0.159692] [G loss: 0.499755]\n",
      "[Epoch 29/200] [Batch 394/637] [D loss: 0.154799] [G loss: 0.524971]\n",
      "[Epoch 29/200] [Batch 395/637] [D loss: 0.176938] [G loss: 0.488704]\n",
      "[Epoch 29/200] [Batch 396/637] [D loss: 0.169598] [G loss: 0.496241]\n",
      "[Epoch 29/200] [Batch 397/637] [D loss: 0.167870] [G loss: 0.473555]\n",
      "[Epoch 29/200] [Batch 398/637] [D loss: 0.158925] [G loss: 0.491017]\n",
      "[Epoch 29/200] [Batch 399/637] [D loss: 0.168012] [G loss: 0.510855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/200] [Batch 400/637] [D loss: 0.158504] [G loss: 0.464687]\n",
      "[Epoch 29/200] [Batch 401/637] [D loss: 0.146164] [G loss: 0.459668]\n",
      "[Epoch 29/200] [Batch 402/637] [D loss: 0.179336] [G loss: 0.447253]\n",
      "[Epoch 29/200] [Batch 403/637] [D loss: 0.192775] [G loss: 0.475786]\n",
      "[Epoch 29/200] [Batch 404/637] [D loss: 0.172116] [G loss: 0.596113]\n",
      "[Epoch 29/200] [Batch 405/637] [D loss: 0.179689] [G loss: 0.456081]\n",
      "[Epoch 29/200] [Batch 406/637] [D loss: 0.188957] [G loss: 0.460642]\n",
      "[Epoch 29/200] [Batch 407/637] [D loss: 0.178221] [G loss: 0.453922]\n",
      "[Epoch 29/200] [Batch 408/637] [D loss: 0.170684] [G loss: 0.476939]\n",
      "[Epoch 29/200] [Batch 409/637] [D loss: 0.203208] [G loss: 0.460247]\n",
      "[Epoch 29/200] [Batch 410/637] [D loss: 0.194877] [G loss: 0.475074]\n",
      "[Epoch 29/200] [Batch 411/637] [D loss: 0.198966] [G loss: 0.489065]\n",
      "[Epoch 29/200] [Batch 412/637] [D loss: 0.188877] [G loss: 0.465264]\n",
      "[Epoch 29/200] [Batch 413/637] [D loss: 0.149000] [G loss: 0.468122]\n",
      "[Epoch 29/200] [Batch 414/637] [D loss: 0.218471] [G loss: 0.389965]\n",
      "[Epoch 29/200] [Batch 415/637] [D loss: 0.170313] [G loss: 0.484630]\n",
      "[Epoch 29/200] [Batch 416/637] [D loss: 0.168340] [G loss: 0.586645]\n",
      "[Epoch 29/200] [Batch 417/637] [D loss: 0.166007] [G loss: 0.471908]\n",
      "[Epoch 29/200] [Batch 418/637] [D loss: 0.163357] [G loss: 0.453776]\n",
      "[Epoch 29/200] [Batch 419/637] [D loss: 0.165892] [G loss: 0.467088]\n",
      "[Epoch 29/200] [Batch 420/637] [D loss: 0.152615] [G loss: 0.463571]\n",
      "[Epoch 29/200] [Batch 421/637] [D loss: 0.161664] [G loss: 0.505081]\n",
      "[Epoch 29/200] [Batch 422/637] [D loss: 0.171554] [G loss: 0.465786]\n",
      "[Epoch 29/200] [Batch 423/637] [D loss: 0.192053] [G loss: 0.422033]\n",
      "[Epoch 29/200] [Batch 424/637] [D loss: 0.161332] [G loss: 0.578529]\n",
      "[Epoch 29/200] [Batch 425/637] [D loss: 0.159677] [G loss: 0.548069]\n",
      "[Epoch 29/200] [Batch 426/637] [D loss: 0.160108] [G loss: 0.490328]\n",
      "[Epoch 29/200] [Batch 427/637] [D loss: 0.222967] [G loss: 0.459656]\n",
      "[Epoch 29/200] [Batch 428/637] [D loss: 0.192233] [G loss: 0.460738]\n",
      "[Epoch 29/200] [Batch 429/637] [D loss: 0.169083] [G loss: 0.530159]\n",
      "[Epoch 29/200] [Batch 430/637] [D loss: 0.186042] [G loss: 0.502381]\n",
      "[Epoch 29/200] [Batch 431/637] [D loss: 0.154028] [G loss: 0.551201]\n",
      "[Epoch 29/200] [Batch 432/637] [D loss: 0.161955] [G loss: 0.535894]\n",
      "[Epoch 29/200] [Batch 433/637] [D loss: 0.149684] [G loss: 0.471345]\n",
      "[Epoch 29/200] [Batch 434/637] [D loss: 0.158399] [G loss: 0.441506]\n",
      "[Epoch 29/200] [Batch 435/637] [D loss: 0.183075] [G loss: 0.429751]\n",
      "[Epoch 29/200] [Batch 436/637] [D loss: 0.184211] [G loss: 0.470133]\n",
      "[Epoch 29/200] [Batch 437/637] [D loss: 0.194365] [G loss: 0.509587]\n",
      "[Epoch 29/200] [Batch 438/637] [D loss: 0.177588] [G loss: 0.477768]\n",
      "[Epoch 29/200] [Batch 439/637] [D loss: 0.170196] [G loss: 0.476922]\n",
      "[Epoch 29/200] [Batch 440/637] [D loss: 0.182187] [G loss: 0.488240]\n",
      "[Epoch 29/200] [Batch 441/637] [D loss: 0.151236] [G loss: 0.477196]\n",
      "[Epoch 29/200] [Batch 442/637] [D loss: 0.152666] [G loss: 0.487049]\n",
      "[Epoch 29/200] [Batch 443/637] [D loss: 0.129733] [G loss: 0.556892]\n",
      "[Epoch 29/200] [Batch 444/637] [D loss: 0.139763] [G loss: 0.478322]\n",
      "[Epoch 29/200] [Batch 445/637] [D loss: 0.152426] [G loss: 0.484011]\n",
      "[Epoch 29/200] [Batch 446/637] [D loss: 0.162322] [G loss: 0.502887]\n",
      "[Epoch 29/200] [Batch 447/637] [D loss: 0.173519] [G loss: 0.570681]\n",
      "[Epoch 29/200] [Batch 448/637] [D loss: 0.178652] [G loss: 0.538376]\n",
      "[Epoch 29/200] [Batch 449/637] [D loss: 0.188779] [G loss: 0.425264]\n",
      "[Epoch 29/200] [Batch 450/637] [D loss: 0.170872] [G loss: 0.514706]\n",
      "[Epoch 29/200] [Batch 451/637] [D loss: 0.184514] [G loss: 0.478241]\n",
      "[Epoch 29/200] [Batch 452/637] [D loss: 0.178752] [G loss: 0.449161]\n",
      "[Epoch 29/200] [Batch 453/637] [D loss: 0.173771] [G loss: 0.494214]\n",
      "[Epoch 29/200] [Batch 454/637] [D loss: 0.182675] [G loss: 0.558015]\n",
      "[Epoch 29/200] [Batch 455/637] [D loss: 0.167857] [G loss: 0.479058]\n",
      "[Epoch 29/200] [Batch 456/637] [D loss: 0.165001] [G loss: 0.488413]\n",
      "[Epoch 29/200] [Batch 457/637] [D loss: 0.184707] [G loss: 0.473788]\n",
      "[Epoch 29/200] [Batch 458/637] [D loss: 0.179903] [G loss: 0.464556]\n",
      "[Epoch 29/200] [Batch 459/637] [D loss: 0.196165] [G loss: 0.441810]\n",
      "[Epoch 29/200] [Batch 460/637] [D loss: 0.181299] [G loss: 0.526509]\n",
      "[Epoch 29/200] [Batch 461/637] [D loss: 0.178771] [G loss: 0.510292]\n",
      "[Epoch 29/200] [Batch 462/637] [D loss: 0.194765] [G loss: 0.505811]\n",
      "[Epoch 29/200] [Batch 463/637] [D loss: 0.183135] [G loss: 0.471579]\n",
      "[Epoch 29/200] [Batch 464/637] [D loss: 0.164896] [G loss: 0.462629]\n",
      "[Epoch 29/200] [Batch 465/637] [D loss: 0.198209] [G loss: 0.421822]\n",
      "[Epoch 29/200] [Batch 466/637] [D loss: 0.168140] [G loss: 0.499265]\n",
      "[Epoch 29/200] [Batch 467/637] [D loss: 0.191648] [G loss: 0.471101]\n",
      "[Epoch 29/200] [Batch 468/637] [D loss: 0.177022] [G loss: 0.478324]\n",
      "[Epoch 29/200] [Batch 469/637] [D loss: 0.149423] [G loss: 0.438474]\n",
      "[Epoch 29/200] [Batch 470/637] [D loss: 0.179113] [G loss: 0.498973]\n",
      "[Epoch 29/200] [Batch 471/637] [D loss: 0.187634] [G loss: 0.425760]\n",
      "[Epoch 29/200] [Batch 472/637] [D loss: 0.157547] [G loss: 0.517504]\n",
      "[Epoch 29/200] [Batch 473/637] [D loss: 0.167440] [G loss: 0.498918]\n",
      "[Epoch 29/200] [Batch 474/637] [D loss: 0.158680] [G loss: 0.477600]\n",
      "[Epoch 29/200] [Batch 475/637] [D loss: 0.172437] [G loss: 0.535177]\n",
      "[Epoch 29/200] [Batch 476/637] [D loss: 0.216229] [G loss: 0.508883]\n",
      "[Epoch 29/200] [Batch 477/637] [D loss: 0.190055] [G loss: 0.448248]\n",
      "[Epoch 29/200] [Batch 478/637] [D loss: 0.206177] [G loss: 0.529999]\n",
      "[Epoch 29/200] [Batch 479/637] [D loss: 0.178633] [G loss: 0.512890]\n",
      "[Epoch 29/200] [Batch 480/637] [D loss: 0.167499] [G loss: 0.521706]\n",
      "[Epoch 29/200] [Batch 481/637] [D loss: 0.159413] [G loss: 0.449015]\n",
      "[Epoch 29/200] [Batch 482/637] [D loss: 0.159284] [G loss: 0.442161]\n",
      "[Epoch 29/200] [Batch 483/637] [D loss: 0.135819] [G loss: 0.582560]\n",
      "[Epoch 29/200] [Batch 484/637] [D loss: 0.164882] [G loss: 0.577009]\n",
      "[Epoch 29/200] [Batch 485/637] [D loss: 0.177335] [G loss: 0.450848]\n",
      "[Epoch 29/200] [Batch 486/637] [D loss: 0.161389] [G loss: 0.459018]\n",
      "[Epoch 29/200] [Batch 487/637] [D loss: 0.161344] [G loss: 0.510599]\n",
      "[Epoch 29/200] [Batch 488/637] [D loss: 0.169592] [G loss: 0.555005]\n",
      "[Epoch 29/200] [Batch 489/637] [D loss: 0.179811] [G loss: 0.473457]\n",
      "[Epoch 29/200] [Batch 490/637] [D loss: 0.151390] [G loss: 0.577776]\n",
      "[Epoch 29/200] [Batch 491/637] [D loss: 0.163352] [G loss: 0.521867]\n",
      "[Epoch 29/200] [Batch 492/637] [D loss: 0.179277] [G loss: 0.499617]\n",
      "[Epoch 29/200] [Batch 493/637] [D loss: 0.169564] [G loss: 0.509929]\n",
      "[Epoch 29/200] [Batch 494/637] [D loss: 0.145468] [G loss: 0.530756]\n",
      "[Epoch 29/200] [Batch 495/637] [D loss: 0.181639] [G loss: 0.484122]\n",
      "[Epoch 29/200] [Batch 496/637] [D loss: 0.170913] [G loss: 0.513198]\n",
      "[Epoch 29/200] [Batch 497/637] [D loss: 0.160117] [G loss: 0.523067]\n",
      "[Epoch 29/200] [Batch 498/637] [D loss: 0.208540] [G loss: 0.447945]\n",
      "[Epoch 29/200] [Batch 499/637] [D loss: 0.198218] [G loss: 0.448056]\n",
      "[Epoch 29/200] [Batch 500/637] [D loss: 0.186282] [G loss: 0.428605]\n",
      "[Epoch 29/200] [Batch 501/637] [D loss: 0.183646] [G loss: 0.455042]\n",
      "[Epoch 29/200] [Batch 502/637] [D loss: 0.189239] [G loss: 0.475075]\n",
      "[Epoch 29/200] [Batch 503/637] [D loss: 0.190438] [G loss: 0.459255]\n",
      "[Epoch 29/200] [Batch 504/637] [D loss: 0.176503] [G loss: 0.525844]\n",
      "[Epoch 29/200] [Batch 505/637] [D loss: 0.211366] [G loss: 0.544175]\n",
      "[Epoch 29/200] [Batch 506/637] [D loss: 0.156730] [G loss: 0.484113]\n",
      "[Epoch 29/200] [Batch 507/637] [D loss: 0.142942] [G loss: 0.482949]\n",
      "[Epoch 29/200] [Batch 508/637] [D loss: 0.181937] [G loss: 0.469578]\n",
      "[Epoch 29/200] [Batch 509/637] [D loss: 0.185144] [G loss: 0.492655]\n",
      "[Epoch 29/200] [Batch 510/637] [D loss: 0.149142] [G loss: 0.585110]\n",
      "[Epoch 29/200] [Batch 511/637] [D loss: 0.191893] [G loss: 0.520261]\n",
      "[Epoch 29/200] [Batch 512/637] [D loss: 0.169984] [G loss: 0.469684]\n",
      "[Epoch 29/200] [Batch 513/637] [D loss: 0.152866] [G loss: 0.472710]\n",
      "[Epoch 29/200] [Batch 514/637] [D loss: 0.162584] [G loss: 0.523161]\n",
      "[Epoch 29/200] [Batch 515/637] [D loss: 0.159178] [G loss: 0.455218]\n",
      "[Epoch 29/200] [Batch 516/637] [D loss: 0.177652] [G loss: 0.539732]\n",
      "[Epoch 29/200] [Batch 517/637] [D loss: 0.207530] [G loss: 0.469302]\n",
      "[Epoch 29/200] [Batch 518/637] [D loss: 0.170002] [G loss: 0.494119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/200] [Batch 519/637] [D loss: 0.232985] [G loss: 0.418875]\n",
      "[Epoch 29/200] [Batch 520/637] [D loss: 0.184031] [G loss: 0.418510]\n",
      "[Epoch 29/200] [Batch 521/637] [D loss: 0.195388] [G loss: 0.548177]\n",
      "[Epoch 29/200] [Batch 522/637] [D loss: 0.144857] [G loss: 0.534584]\n",
      "[Epoch 29/200] [Batch 523/637] [D loss: 0.185895] [G loss: 0.446484]\n",
      "[Epoch 29/200] [Batch 524/637] [D loss: 0.172087] [G loss: 0.385473]\n",
      "[Epoch 29/200] [Batch 525/637] [D loss: 0.182033] [G loss: 0.390165]\n",
      "[Epoch 29/200] [Batch 526/637] [D loss: 0.180873] [G loss: 0.427765]\n",
      "[Epoch 29/200] [Batch 527/637] [D loss: 0.185477] [G loss: 0.468365]\n",
      "[Epoch 29/200] [Batch 528/637] [D loss: 0.202185] [G loss: 0.459895]\n",
      "[Epoch 29/200] [Batch 529/637] [D loss: 0.182154] [G loss: 0.489792]\n",
      "[Epoch 29/200] [Batch 530/637] [D loss: 0.169068] [G loss: 0.479137]\n",
      "[Epoch 29/200] [Batch 531/637] [D loss: 0.181354] [G loss: 0.443721]\n",
      "[Epoch 29/200] [Batch 532/637] [D loss: 0.160842] [G loss: 0.435840]\n",
      "[Epoch 29/200] [Batch 533/637] [D loss: 0.142709] [G loss: 0.498722]\n",
      "[Epoch 29/200] [Batch 534/637] [D loss: 0.148357] [G loss: 0.486891]\n",
      "[Epoch 29/200] [Batch 535/637] [D loss: 0.178390] [G loss: 0.383342]\n",
      "[Epoch 29/200] [Batch 536/637] [D loss: 0.193113] [G loss: 0.415593]\n",
      "[Epoch 29/200] [Batch 537/637] [D loss: 0.181684] [G loss: 0.630093]\n",
      "[Epoch 29/200] [Batch 538/637] [D loss: 0.172355] [G loss: 0.565942]\n",
      "[Epoch 29/200] [Batch 539/637] [D loss: 0.208184] [G loss: 0.423098]\n",
      "[Epoch 29/200] [Batch 540/637] [D loss: 0.171177] [G loss: 0.548821]\n",
      "[Epoch 29/200] [Batch 541/637] [D loss: 0.176046] [G loss: 0.458724]\n",
      "[Epoch 29/200] [Batch 542/637] [D loss: 0.189564] [G loss: 0.432403]\n",
      "[Epoch 29/200] [Batch 543/637] [D loss: 0.194039] [G loss: 0.415300]\n",
      "[Epoch 29/200] [Batch 544/637] [D loss: 0.183641] [G loss: 0.525133]\n",
      "[Epoch 29/200] [Batch 545/637] [D loss: 0.173320] [G loss: 0.488848]\n",
      "[Epoch 29/200] [Batch 546/637] [D loss: 0.171124] [G loss: 0.559330]\n",
      "[Epoch 29/200] [Batch 547/637] [D loss: 0.162085] [G loss: 0.507123]\n",
      "[Epoch 29/200] [Batch 548/637] [D loss: 0.188814] [G loss: 0.533116]\n",
      "[Epoch 29/200] [Batch 549/637] [D loss: 0.166879] [G loss: 0.585606]\n",
      "[Epoch 29/200] [Batch 550/637] [D loss: 0.165701] [G loss: 0.513057]\n",
      "[Epoch 29/200] [Batch 551/637] [D loss: 0.173635] [G loss: 0.435452]\n",
      "[Epoch 29/200] [Batch 552/637] [D loss: 0.203891] [G loss: 0.400524]\n",
      "[Epoch 29/200] [Batch 553/637] [D loss: 0.164896] [G loss: 0.561505]\n",
      "[Epoch 29/200] [Batch 554/637] [D loss: 0.202129] [G loss: 0.557270]\n",
      "[Epoch 29/200] [Batch 555/637] [D loss: 0.176741] [G loss: 0.560809]\n",
      "[Epoch 29/200] [Batch 556/637] [D loss: 0.192542] [G loss: 0.488929]\n",
      "[Epoch 29/200] [Batch 557/637] [D loss: 0.162673] [G loss: 0.460249]\n",
      "[Epoch 29/200] [Batch 558/637] [D loss: 0.176346] [G loss: 0.465301]\n",
      "[Epoch 29/200] [Batch 559/637] [D loss: 0.168786] [G loss: 0.495759]\n",
      "[Epoch 29/200] [Batch 560/637] [D loss: 0.173122] [G loss: 0.471341]\n",
      "[Epoch 29/200] [Batch 561/637] [D loss: 0.159340] [G loss: 0.469068]\n",
      "[Epoch 29/200] [Batch 562/637] [D loss: 0.185377] [G loss: 0.477281]\n",
      "[Epoch 29/200] [Batch 563/637] [D loss: 0.156589] [G loss: 0.478800]\n",
      "[Epoch 29/200] [Batch 564/637] [D loss: 0.155060] [G loss: 0.499968]\n",
      "[Epoch 29/200] [Batch 565/637] [D loss: 0.156747] [G loss: 0.484064]\n",
      "[Epoch 29/200] [Batch 566/637] [D loss: 0.188215] [G loss: 0.502038]\n",
      "[Epoch 29/200] [Batch 567/637] [D loss: 0.168205] [G loss: 0.508974]\n",
      "[Epoch 29/200] [Batch 568/637] [D loss: 0.161188] [G loss: 0.479606]\n",
      "[Epoch 29/200] [Batch 569/637] [D loss: 0.172779] [G loss: 0.452048]\n",
      "[Epoch 29/200] [Batch 570/637] [D loss: 0.162621] [G loss: 0.490750]\n",
      "[Epoch 29/200] [Batch 571/637] [D loss: 0.168647] [G loss: 0.461026]\n",
      "[Epoch 29/200] [Batch 572/637] [D loss: 0.171068] [G loss: 0.509955]\n",
      "[Epoch 29/200] [Batch 573/637] [D loss: 0.143321] [G loss: 0.547505]\n",
      "[Epoch 29/200] [Batch 574/637] [D loss: 0.162263] [G loss: 0.518894]\n",
      "[Epoch 29/200] [Batch 575/637] [D loss: 0.190573] [G loss: 0.458185]\n",
      "[Epoch 29/200] [Batch 576/637] [D loss: 0.194177] [G loss: 0.597100]\n",
      "[Epoch 29/200] [Batch 577/637] [D loss: 0.188712] [G loss: 0.520186]\n",
      "[Epoch 29/200] [Batch 578/637] [D loss: 0.171798] [G loss: 0.512267]\n",
      "[Epoch 29/200] [Batch 579/637] [D loss: 0.170072] [G loss: 0.506396]\n",
      "[Epoch 29/200] [Batch 580/637] [D loss: 0.180222] [G loss: 0.467548]\n",
      "[Epoch 29/200] [Batch 581/637] [D loss: 0.155914] [G loss: 0.458029]\n",
      "[Epoch 29/200] [Batch 582/637] [D loss: 0.153474] [G loss: 0.477220]\n",
      "[Epoch 29/200] [Batch 583/637] [D loss: 0.207708] [G loss: 0.413931]\n",
      "[Epoch 29/200] [Batch 584/637] [D loss: 0.180440] [G loss: 0.546542]\n",
      "[Epoch 29/200] [Batch 585/637] [D loss: 0.180409] [G loss: 0.528432]\n",
      "[Epoch 29/200] [Batch 586/637] [D loss: 0.156682] [G loss: 0.522655]\n",
      "[Epoch 29/200] [Batch 587/637] [D loss: 0.163852] [G loss: 0.469439]\n",
      "[Epoch 29/200] [Batch 588/637] [D loss: 0.196343] [G loss: 0.424806]\n",
      "[Epoch 29/200] [Batch 589/637] [D loss: 0.167174] [G loss: 0.462344]\n",
      "[Epoch 29/200] [Batch 590/637] [D loss: 0.158666] [G loss: 0.490202]\n",
      "[Epoch 29/200] [Batch 591/637] [D loss: 0.178921] [G loss: 0.444884]\n",
      "[Epoch 29/200] [Batch 592/637] [D loss: 0.175307] [G loss: 0.459146]\n",
      "[Epoch 29/200] [Batch 593/637] [D loss: 0.162091] [G loss: 0.554458]\n",
      "[Epoch 29/200] [Batch 594/637] [D loss: 0.166022] [G loss: 0.485918]\n",
      "[Epoch 29/200] [Batch 595/637] [D loss: 0.182398] [G loss: 0.486458]\n",
      "[Epoch 29/200] [Batch 596/637] [D loss: 0.155943] [G loss: 0.448206]\n",
      "[Epoch 29/200] [Batch 597/637] [D loss: 0.174132] [G loss: 0.448906]\n",
      "[Epoch 29/200] [Batch 598/637] [D loss: 0.169488] [G loss: 0.551118]\n",
      "[Epoch 29/200] [Batch 599/637] [D loss: 0.165059] [G loss: 0.546725]\n",
      "[Epoch 29/200] [Batch 600/637] [D loss: 0.176860] [G loss: 0.471200]\n",
      "[Epoch 29/200] [Batch 601/637] [D loss: 0.180980] [G loss: 0.469034]\n",
      "[Epoch 29/200] [Batch 602/637] [D loss: 0.172377] [G loss: 0.484254]\n",
      "[Epoch 29/200] [Batch 603/637] [D loss: 0.166770] [G loss: 0.528640]\n",
      "[Epoch 29/200] [Batch 604/637] [D loss: 0.155505] [G loss: 0.489684]\n",
      "[Epoch 29/200] [Batch 605/637] [D loss: 0.140485] [G loss: 0.529929]\n",
      "[Epoch 29/200] [Batch 606/637] [D loss: 0.179023] [G loss: 0.472064]\n",
      "[Epoch 29/200] [Batch 607/637] [D loss: 0.176696] [G loss: 0.520636]\n",
      "[Epoch 29/200] [Batch 608/637] [D loss: 0.160884] [G loss: 0.491738]\n",
      "[Epoch 29/200] [Batch 609/637] [D loss: 0.177912] [G loss: 0.450295]\n",
      "[Epoch 29/200] [Batch 610/637] [D loss: 0.188169] [G loss: 0.522550]\n",
      "[Epoch 29/200] [Batch 611/637] [D loss: 0.155701] [G loss: 0.495262]\n",
      "[Epoch 29/200] [Batch 612/637] [D loss: 0.174962] [G loss: 0.503011]\n",
      "[Epoch 29/200] [Batch 613/637] [D loss: 0.180635] [G loss: 0.531705]\n",
      "[Epoch 29/200] [Batch 614/637] [D loss: 0.168929] [G loss: 0.533865]\n",
      "[Epoch 29/200] [Batch 615/637] [D loss: 0.153857] [G loss: 0.484403]\n",
      "[Epoch 29/200] [Batch 616/637] [D loss: 0.173270] [G loss: 0.425011]\n",
      "[Epoch 29/200] [Batch 617/637] [D loss: 0.169176] [G loss: 0.459247]\n",
      "[Epoch 29/200] [Batch 618/637] [D loss: 0.178936] [G loss: 0.478610]\n",
      "[Epoch 29/200] [Batch 619/637] [D loss: 0.165618] [G loss: 0.486087]\n",
      "[Epoch 29/200] [Batch 620/637] [D loss: 0.153272] [G loss: 0.536306]\n",
      "[Epoch 29/200] [Batch 621/637] [D loss: 0.153962] [G loss: 0.500675]\n",
      "[Epoch 29/200] [Batch 622/637] [D loss: 0.133241] [G loss: 0.512100]\n",
      "[Epoch 29/200] [Batch 623/637] [D loss: 0.140468] [G loss: 0.599913]\n",
      "[Epoch 29/200] [Batch 624/637] [D loss: 0.165156] [G loss: 0.532766]\n",
      "[Epoch 29/200] [Batch 625/637] [D loss: 0.152363] [G loss: 0.517499]\n",
      "[Epoch 29/200] [Batch 626/637] [D loss: 0.146446] [G loss: 0.492388]\n",
      "[Epoch 29/200] [Batch 627/637] [D loss: 0.185130] [G loss: 0.464168]\n",
      "[Epoch 29/200] [Batch 628/637] [D loss: 0.196548] [G loss: 0.448658]\n",
      "[Epoch 29/200] [Batch 629/637] [D loss: 0.183866] [G loss: 0.547038]\n",
      "[Epoch 29/200] [Batch 630/637] [D loss: 0.147558] [G loss: 0.618439]\n",
      "[Epoch 29/200] [Batch 631/637] [D loss: 0.178851] [G loss: 0.479554]\n",
      "[Epoch 29/200] [Batch 632/637] [D loss: 0.175552] [G loss: 0.503005]\n",
      "[Epoch 29/200] [Batch 633/637] [D loss: 0.175909] [G loss: 0.527265]\n",
      "[Epoch 29/200] [Batch 634/637] [D loss: 0.164564] [G loss: 0.534863]\n",
      "[Epoch 29/200] [Batch 635/637] [D loss: 0.210348] [G loss: 0.422601]\n",
      "[Epoch 29/200] [Batch 636/637] [D loss: 0.208912] [G loss: 0.581729]\n",
      "[Epoch 30/200] [Batch 0/637] [D loss: 0.161289] [G loss: 0.613912]\n",
      "[Epoch 30/200] [Batch 1/637] [D loss: 0.166179] [G loss: 0.514600]\n",
      "[Epoch 30/200] [Batch 2/637] [D loss: 0.161070] [G loss: 0.541228]\n",
      "[Epoch 30/200] [Batch 3/637] [D loss: 0.192822] [G loss: 0.409866]\n",
      "[Epoch 30/200] [Batch 4/637] [D loss: 0.170141] [G loss: 0.455977]\n",
      "[Epoch 30/200] [Batch 5/637] [D loss: 0.167971] [G loss: 0.492837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 6/637] [D loss: 0.148879] [G loss: 0.559195]\n",
      "[Epoch 30/200] [Batch 7/637] [D loss: 0.238410] [G loss: 0.444932]\n",
      "[Epoch 30/200] [Batch 8/637] [D loss: 0.230087] [G loss: 0.494765]\n",
      "[Epoch 30/200] [Batch 9/637] [D loss: 0.182766] [G loss: 0.562227]\n",
      "[Epoch 30/200] [Batch 10/637] [D loss: 0.198762] [G loss: 0.488629]\n",
      "[Epoch 30/200] [Batch 11/637] [D loss: 0.178275] [G loss: 0.462734]\n",
      "[Epoch 30/200] [Batch 12/637] [D loss: 0.192137] [G loss: 0.531925]\n",
      "[Epoch 30/200] [Batch 13/637] [D loss: 0.188079] [G loss: 0.452549]\n",
      "[Epoch 30/200] [Batch 14/637] [D loss: 0.201933] [G loss: 0.398692]\n",
      "[Epoch 30/200] [Batch 15/637] [D loss: 0.170770] [G loss: 0.518327]\n",
      "[Epoch 30/200] [Batch 16/637] [D loss: 0.182129] [G loss: 0.442482]\n",
      "[Epoch 30/200] [Batch 17/637] [D loss: 0.187205] [G loss: 0.430563]\n",
      "[Epoch 30/200] [Batch 18/637] [D loss: 0.178107] [G loss: 0.434602]\n",
      "[Epoch 30/200] [Batch 19/637] [D loss: 0.220766] [G loss: 0.449146]\n",
      "[Epoch 30/200] [Batch 20/637] [D loss: 0.204322] [G loss: 0.608403]\n",
      "[Epoch 30/200] [Batch 21/637] [D loss: 0.198914] [G loss: 0.575217]\n",
      "[Epoch 30/200] [Batch 22/637] [D loss: 0.170861] [G loss: 0.463426]\n",
      "[Epoch 30/200] [Batch 23/637] [D loss: 0.179358] [G loss: 0.355139]\n",
      "[Epoch 30/200] [Batch 24/637] [D loss: 0.166827] [G loss: 0.400436]\n",
      "[Epoch 30/200] [Batch 25/637] [D loss: 0.169944] [G loss: 0.486655]\n",
      "[Epoch 30/200] [Batch 26/637] [D loss: 0.177443] [G loss: 0.467161]\n",
      "[Epoch 30/200] [Batch 27/637] [D loss: 0.166872] [G loss: 0.518697]\n",
      "[Epoch 30/200] [Batch 28/637] [D loss: 0.164882] [G loss: 0.526994]\n",
      "[Epoch 30/200] [Batch 29/637] [D loss: 0.181619] [G loss: 0.486203]\n",
      "[Epoch 30/200] [Batch 30/637] [D loss: 0.172631] [G loss: 0.469305]\n",
      "[Epoch 30/200] [Batch 31/637] [D loss: 0.163847] [G loss: 0.476122]\n",
      "[Epoch 30/200] [Batch 32/637] [D loss: 0.186721] [G loss: 0.441953]\n",
      "[Epoch 30/200] [Batch 33/637] [D loss: 0.178811] [G loss: 0.444101]\n",
      "[Epoch 30/200] [Batch 34/637] [D loss: 0.168455] [G loss: 0.492938]\n",
      "[Epoch 30/200] [Batch 35/637] [D loss: 0.185661] [G loss: 0.461142]\n",
      "[Epoch 30/200] [Batch 36/637] [D loss: 0.183714] [G loss: 0.523643]\n",
      "[Epoch 30/200] [Batch 37/637] [D loss: 0.184307] [G loss: 0.496841]\n",
      "[Epoch 30/200] [Batch 38/637] [D loss: 0.166224] [G loss: 0.481391]\n",
      "[Epoch 30/200] [Batch 39/637] [D loss: 0.212195] [G loss: 0.455003]\n",
      "[Epoch 30/200] [Batch 40/637] [D loss: 0.170688] [G loss: 0.546403]\n",
      "[Epoch 30/200] [Batch 41/637] [D loss: 0.181649] [G loss: 0.473371]\n",
      "[Epoch 30/200] [Batch 42/637] [D loss: 0.179926] [G loss: 0.547331]\n",
      "[Epoch 30/200] [Batch 43/637] [D loss: 0.174417] [G loss: 0.452983]\n",
      "[Epoch 30/200] [Batch 44/637] [D loss: 0.153948] [G loss: 0.487910]\n",
      "[Epoch 30/200] [Batch 45/637] [D loss: 0.167207] [G loss: 0.488618]\n",
      "[Epoch 30/200] [Batch 46/637] [D loss: 0.176153] [G loss: 0.413376]\n",
      "[Epoch 30/200] [Batch 47/637] [D loss: 0.169793] [G loss: 0.475801]\n",
      "[Epoch 30/200] [Batch 48/637] [D loss: 0.172167] [G loss: 0.522786]\n",
      "[Epoch 30/200] [Batch 49/637] [D loss: 0.178946] [G loss: 0.508966]\n",
      "[Epoch 30/200] [Batch 50/637] [D loss: 0.150688] [G loss: 0.541751]\n",
      "[Epoch 30/200] [Batch 51/637] [D loss: 0.178398] [G loss: 0.469403]\n",
      "[Epoch 30/200] [Batch 52/637] [D loss: 0.153430] [G loss: 0.573591]\n",
      "[Epoch 30/200] [Batch 53/637] [D loss: 0.165433] [G loss: 0.543966]\n",
      "[Epoch 30/200] [Batch 54/637] [D loss: 0.171796] [G loss: 0.607070]\n",
      "[Epoch 30/200] [Batch 55/637] [D loss: 0.154845] [G loss: 0.557078]\n",
      "[Epoch 30/200] [Batch 56/637] [D loss: 0.174320] [G loss: 0.464903]\n",
      "[Epoch 30/200] [Batch 57/637] [D loss: 0.191952] [G loss: 0.453083]\n",
      "[Epoch 30/200] [Batch 58/637] [D loss: 0.197955] [G loss: 0.520650]\n",
      "[Epoch 30/200] [Batch 59/637] [D loss: 0.164937] [G loss: 0.521020]\n",
      "[Epoch 30/200] [Batch 60/637] [D loss: 0.168449] [G loss: 0.477651]\n",
      "[Epoch 30/200] [Batch 61/637] [D loss: 0.175210] [G loss: 0.491561]\n",
      "[Epoch 30/200] [Batch 62/637] [D loss: 0.182294] [G loss: 0.471268]\n",
      "[Epoch 30/200] [Batch 63/637] [D loss: 0.176477] [G loss: 0.502061]\n",
      "[Epoch 30/200] [Batch 64/637] [D loss: 0.242054] [G loss: 0.478706]\n",
      "[Epoch 30/200] [Batch 65/637] [D loss: 0.188632] [G loss: 0.520393]\n",
      "[Epoch 30/200] [Batch 66/637] [D loss: 0.208945] [G loss: 0.467967]\n",
      "[Epoch 30/200] [Batch 67/637] [D loss: 0.158486] [G loss: 0.488412]\n",
      "[Epoch 30/200] [Batch 68/637] [D loss: 0.147007] [G loss: 0.453680]\n",
      "[Epoch 30/200] [Batch 69/637] [D loss: 0.177800] [G loss: 0.444179]\n",
      "[Epoch 30/200] [Batch 70/637] [D loss: 0.158679] [G loss: 0.510529]\n",
      "[Epoch 30/200] [Batch 71/637] [D loss: 0.186509] [G loss: 0.509067]\n",
      "[Epoch 30/200] [Batch 72/637] [D loss: 0.168001] [G loss: 0.475666]\n",
      "[Epoch 30/200] [Batch 73/637] [D loss: 0.204317] [G loss: 0.410796]\n",
      "[Epoch 30/200] [Batch 74/637] [D loss: 0.178003] [G loss: 0.496149]\n",
      "[Epoch 30/200] [Batch 75/637] [D loss: 0.175798] [G loss: 0.466171]\n",
      "[Epoch 30/200] [Batch 76/637] [D loss: 0.176203] [G loss: 0.427303]\n",
      "[Epoch 30/200] [Batch 77/637] [D loss: 0.163838] [G loss: 0.427745]\n",
      "[Epoch 30/200] [Batch 78/637] [D loss: 0.194100] [G loss: 0.464986]\n",
      "[Epoch 30/200] [Batch 79/637] [D loss: 0.167592] [G loss: 0.580012]\n",
      "[Epoch 30/200] [Batch 80/637] [D loss: 0.183993] [G loss: 0.448385]\n",
      "[Epoch 30/200] [Batch 81/637] [D loss: 0.161826] [G loss: 0.448201]\n",
      "[Epoch 30/200] [Batch 82/637] [D loss: 0.180567] [G loss: 0.445021]\n",
      "[Epoch 30/200] [Batch 83/637] [D loss: 0.154132] [G loss: 0.538779]\n",
      "[Epoch 30/200] [Batch 84/637] [D loss: 0.164723] [G loss: 0.498617]\n",
      "[Epoch 30/200] [Batch 85/637] [D loss: 0.154277] [G loss: 0.525574]\n",
      "[Epoch 30/200] [Batch 86/637] [D loss: 0.184096] [G loss: 0.417286]\n",
      "[Epoch 30/200] [Batch 87/637] [D loss: 0.178281] [G loss: 0.552309]\n",
      "[Epoch 30/200] [Batch 88/637] [D loss: 0.157966] [G loss: 0.564149]\n",
      "[Epoch 30/200] [Batch 89/637] [D loss: 0.197431] [G loss: 0.445677]\n",
      "[Epoch 30/200] [Batch 90/637] [D loss: 0.177343] [G loss: 0.516753]\n",
      "[Epoch 30/200] [Batch 91/637] [D loss: 0.210466] [G loss: 0.378700]\n",
      "[Epoch 30/200] [Batch 92/637] [D loss: 0.177532] [G loss: 0.432343]\n",
      "[Epoch 30/200] [Batch 93/637] [D loss: 0.199917] [G loss: 0.488623]\n",
      "[Epoch 30/200] [Batch 94/637] [D loss: 0.190185] [G loss: 0.420529]\n",
      "[Epoch 30/200] [Batch 95/637] [D loss: 0.203495] [G loss: 0.410867]\n",
      "[Epoch 30/200] [Batch 96/637] [D loss: 0.228998] [G loss: 0.484453]\n",
      "[Epoch 30/200] [Batch 97/637] [D loss: 0.171578] [G loss: 0.626376]\n",
      "[Epoch 30/200] [Batch 98/637] [D loss: 0.166567] [G loss: 0.482785]\n",
      "[Epoch 30/200] [Batch 99/637] [D loss: 0.164216] [G loss: 0.479283]\n",
      "[Epoch 30/200] [Batch 100/637] [D loss: 0.139855] [G loss: 0.467638]\n",
      "[Epoch 30/200] [Batch 101/637] [D loss: 0.168771] [G loss: 0.529324]\n",
      "[Epoch 30/200] [Batch 102/637] [D loss: 0.139073] [G loss: 0.534760]\n",
      "[Epoch 30/200] [Batch 103/637] [D loss: 0.175481] [G loss: 0.542653]\n",
      "[Epoch 30/200] [Batch 104/637] [D loss: 0.176150] [G loss: 0.520007]\n",
      "[Epoch 30/200] [Batch 105/637] [D loss: 0.174252] [G loss: 0.544398]\n",
      "[Epoch 30/200] [Batch 106/637] [D loss: 0.182443] [G loss: 0.510735]\n",
      "[Epoch 30/200] [Batch 107/637] [D loss: 0.177464] [G loss: 0.425542]\n",
      "[Epoch 30/200] [Batch 108/637] [D loss: 0.166321] [G loss: 0.545504]\n",
      "[Epoch 30/200] [Batch 109/637] [D loss: 0.186912] [G loss: 0.480843]\n",
      "[Epoch 30/200] [Batch 110/637] [D loss: 0.161758] [G loss: 0.593143]\n",
      "[Epoch 30/200] [Batch 111/637] [D loss: 0.200837] [G loss: 0.488057]\n",
      "[Epoch 30/200] [Batch 112/637] [D loss: 0.188142] [G loss: 0.505524]\n",
      "[Epoch 30/200] [Batch 113/637] [D loss: 0.178176] [G loss: 0.500796]\n",
      "[Epoch 30/200] [Batch 114/637] [D loss: 0.155507] [G loss: 0.540367]\n",
      "[Epoch 30/200] [Batch 115/637] [D loss: 0.185789] [G loss: 0.512141]\n",
      "[Epoch 30/200] [Batch 116/637] [D loss: 0.215017] [G loss: 0.480182]\n",
      "[Epoch 30/200] [Batch 117/637] [D loss: 0.185183] [G loss: 0.502724]\n",
      "[Epoch 30/200] [Batch 118/637] [D loss: 0.156852] [G loss: 0.506675]\n",
      "[Epoch 30/200] [Batch 119/637] [D loss: 0.166463] [G loss: 0.428462]\n",
      "[Epoch 30/200] [Batch 120/637] [D loss: 0.191918] [G loss: 0.452652]\n",
      "[Epoch 30/200] [Batch 121/637] [D loss: 0.179791] [G loss: 0.461223]\n",
      "[Epoch 30/200] [Batch 122/637] [D loss: 0.176138] [G loss: 0.552786]\n",
      "[Epoch 30/200] [Batch 123/637] [D loss: 0.170251] [G loss: 0.578157]\n",
      "[Epoch 30/200] [Batch 124/637] [D loss: 0.161197] [G loss: 0.465060]\n",
      "[Epoch 30/200] [Batch 125/637] [D loss: 0.171844] [G loss: 0.444844]\n",
      "[Epoch 30/200] [Batch 126/637] [D loss: 0.134889] [G loss: 0.551952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 127/637] [D loss: 0.175860] [G loss: 0.493537]\n",
      "[Epoch 30/200] [Batch 128/637] [D loss: 0.168798] [G loss: 0.532759]\n",
      "[Epoch 30/200] [Batch 129/637] [D loss: 0.169498] [G loss: 0.612644]\n",
      "[Epoch 30/200] [Batch 130/637] [D loss: 0.165837] [G loss: 0.556041]\n",
      "[Epoch 30/200] [Batch 131/637] [D loss: 0.155313] [G loss: 0.520751]\n",
      "[Epoch 30/200] [Batch 132/637] [D loss: 0.171301] [G loss: 0.542647]\n",
      "[Epoch 30/200] [Batch 133/637] [D loss: 0.185643] [G loss: 0.436391]\n",
      "[Epoch 30/200] [Batch 134/637] [D loss: 0.181332] [G loss: 0.455891]\n",
      "[Epoch 30/200] [Batch 135/637] [D loss: 0.166502] [G loss: 0.454933]\n",
      "[Epoch 30/200] [Batch 136/637] [D loss: 0.154114] [G loss: 0.529845]\n",
      "[Epoch 30/200] [Batch 137/637] [D loss: 0.191590] [G loss: 0.425803]\n",
      "[Epoch 30/200] [Batch 138/637] [D loss: 0.163641] [G loss: 0.492849]\n",
      "[Epoch 30/200] [Batch 139/637] [D loss: 0.170994] [G loss: 0.508073]\n",
      "[Epoch 30/200] [Batch 140/637] [D loss: 0.160789] [G loss: 0.494466]\n",
      "[Epoch 30/200] [Batch 141/637] [D loss: 0.186634] [G loss: 0.466898]\n",
      "[Epoch 30/200] [Batch 142/637] [D loss: 0.187863] [G loss: 0.440600]\n",
      "[Epoch 30/200] [Batch 143/637] [D loss: 0.161191] [G loss: 0.523594]\n",
      "[Epoch 30/200] [Batch 144/637] [D loss: 0.158005] [G loss: 0.452449]\n",
      "[Epoch 30/200] [Batch 145/637] [D loss: 0.262503] [G loss: 0.388161]\n",
      "[Epoch 30/200] [Batch 146/637] [D loss: 0.215202] [G loss: 0.502521]\n",
      "[Epoch 30/200] [Batch 147/637] [D loss: 0.210643] [G loss: 0.530546]\n",
      "[Epoch 30/200] [Batch 148/637] [D loss: 0.176005] [G loss: 0.447326]\n",
      "[Epoch 30/200] [Batch 149/637] [D loss: 0.207543] [G loss: 0.374290]\n",
      "[Epoch 30/200] [Batch 150/637] [D loss: 0.188966] [G loss: 0.442484]\n",
      "[Epoch 30/200] [Batch 151/637] [D loss: 0.205151] [G loss: 0.592448]\n",
      "[Epoch 30/200] [Batch 152/637] [D loss: 0.169244] [G loss: 0.561404]\n",
      "[Epoch 30/200] [Batch 153/637] [D loss: 0.181291] [G loss: 0.486941]\n",
      "[Epoch 30/200] [Batch 154/637] [D loss: 0.181872] [G loss: 0.368889]\n",
      "[Epoch 30/200] [Batch 155/637] [D loss: 0.167673] [G loss: 0.433551]\n",
      "[Epoch 30/200] [Batch 156/637] [D loss: 0.143570] [G loss: 0.515884]\n",
      "[Epoch 30/200] [Batch 157/637] [D loss: 0.162310] [G loss: 0.481633]\n",
      "[Epoch 30/200] [Batch 158/637] [D loss: 0.168356] [G loss: 0.487507]\n",
      "[Epoch 30/200] [Batch 159/637] [D loss: 0.144472] [G loss: 0.515226]\n",
      "[Epoch 30/200] [Batch 160/637] [D loss: 0.176421] [G loss: 0.485341]\n",
      "[Epoch 30/200] [Batch 161/637] [D loss: 0.152410] [G loss: 0.578624]\n",
      "[Epoch 30/200] [Batch 162/637] [D loss: 0.183019] [G loss: 0.519216]\n",
      "[Epoch 30/200] [Batch 163/637] [D loss: 0.165656] [G loss: 0.466257]\n",
      "[Epoch 30/200] [Batch 164/637] [D loss: 0.163251] [G loss: 0.486848]\n",
      "[Epoch 30/200] [Batch 165/637] [D loss: 0.176596] [G loss: 0.453438]\n",
      "[Epoch 30/200] [Batch 166/637] [D loss: 0.174701] [G loss: 0.488042]\n",
      "[Epoch 30/200] [Batch 167/637] [D loss: 0.162576] [G loss: 0.516971]\n",
      "[Epoch 30/200] [Batch 168/637] [D loss: 0.182900] [G loss: 0.430817]\n",
      "[Epoch 30/200] [Batch 169/637] [D loss: 0.178329] [G loss: 0.506081]\n",
      "[Epoch 30/200] [Batch 170/637] [D loss: 0.176962] [G loss: 0.561708]\n",
      "[Epoch 30/200] [Batch 171/637] [D loss: 0.194427] [G loss: 0.464981]\n",
      "[Epoch 30/200] [Batch 172/637] [D loss: 0.181725] [G loss: 0.458479]\n",
      "[Epoch 30/200] [Batch 173/637] [D loss: 0.171089] [G loss: 0.434900]\n",
      "[Epoch 30/200] [Batch 174/637] [D loss: 0.186693] [G loss: 0.483941]\n",
      "[Epoch 30/200] [Batch 175/637] [D loss: 0.153048] [G loss: 0.542783]\n",
      "[Epoch 30/200] [Batch 176/637] [D loss: 0.181174] [G loss: 0.481371]\n",
      "[Epoch 30/200] [Batch 177/637] [D loss: 0.178663] [G loss: 0.464029]\n",
      "[Epoch 30/200] [Batch 178/637] [D loss: 0.167248] [G loss: 0.538506]\n",
      "[Epoch 30/200] [Batch 179/637] [D loss: 0.166485] [G loss: 0.483592]\n",
      "[Epoch 30/200] [Batch 180/637] [D loss: 0.156486] [G loss: 0.528541]\n",
      "[Epoch 30/200] [Batch 181/637] [D loss: 0.167866] [G loss: 0.478896]\n",
      "[Epoch 30/200] [Batch 182/637] [D loss: 0.166508] [G loss: 0.507997]\n",
      "[Epoch 30/200] [Batch 183/637] [D loss: 0.173782] [G loss: 0.474884]\n",
      "[Epoch 30/200] [Batch 184/637] [D loss: 0.171496] [G loss: 0.498529]\n",
      "[Epoch 30/200] [Batch 185/637] [D loss: 0.186315] [G loss: 0.537599]\n",
      "[Epoch 30/200] [Batch 186/637] [D loss: 0.153197] [G loss: 0.592451]\n",
      "[Epoch 30/200] [Batch 187/637] [D loss: 0.177298] [G loss: 0.435062]\n",
      "[Epoch 30/200] [Batch 188/637] [D loss: 0.164180] [G loss: 0.420885]\n",
      "[Epoch 30/200] [Batch 189/637] [D loss: 0.169820] [G loss: 0.451112]\n",
      "[Epoch 30/200] [Batch 190/637] [D loss: 0.169913] [G loss: 0.517362]\n",
      "[Epoch 30/200] [Batch 191/637] [D loss: 0.158318] [G loss: 0.469543]\n",
      "[Epoch 30/200] [Batch 192/637] [D loss: 0.155874] [G loss: 0.479890]\n",
      "[Epoch 30/200] [Batch 193/637] [D loss: 0.166784] [G loss: 0.438507]\n",
      "[Epoch 30/200] [Batch 194/637] [D loss: 0.192785] [G loss: 0.513626]\n",
      "[Epoch 30/200] [Batch 195/637] [D loss: 0.168860] [G loss: 0.534469]\n",
      "[Epoch 30/200] [Batch 196/637] [D loss: 0.184033] [G loss: 0.469767]\n",
      "[Epoch 30/200] [Batch 197/637] [D loss: 0.191524] [G loss: 0.484119]\n",
      "[Epoch 30/200] [Batch 198/637] [D loss: 0.177544] [G loss: 0.427264]\n",
      "[Epoch 30/200] [Batch 199/637] [D loss: 0.168278] [G loss: 0.451349]\n",
      "[Epoch 30/200] [Batch 200/637] [D loss: 0.172989] [G loss: 0.458072]\n",
      "[Epoch 30/200] [Batch 201/637] [D loss: 0.196384] [G loss: 0.477837]\n",
      "[Epoch 30/200] [Batch 202/637] [D loss: 0.156906] [G loss: 0.454594]\n",
      "[Epoch 30/200] [Batch 203/637] [D loss: 0.148055] [G loss: 0.511636]\n",
      "[Epoch 30/200] [Batch 204/637] [D loss: 0.197902] [G loss: 0.460425]\n",
      "[Epoch 30/200] [Batch 205/637] [D loss: 0.186515] [G loss: 0.435857]\n",
      "[Epoch 30/200] [Batch 206/637] [D loss: 0.189640] [G loss: 0.422394]\n",
      "[Epoch 30/200] [Batch 207/637] [D loss: 0.157766] [G loss: 0.494038]\n",
      "[Epoch 30/200] [Batch 208/637] [D loss: 0.169560] [G loss: 0.465388]\n",
      "[Epoch 30/200] [Batch 209/637] [D loss: 0.168332] [G loss: 0.458303]\n",
      "[Epoch 30/200] [Batch 210/637] [D loss: 0.155831] [G loss: 0.502322]\n",
      "[Epoch 30/200] [Batch 211/637] [D loss: 0.157013] [G loss: 0.499874]\n",
      "[Epoch 30/200] [Batch 212/637] [D loss: 0.191377] [G loss: 0.391613]\n",
      "[Epoch 30/200] [Batch 213/637] [D loss: 0.162207] [G loss: 0.470099]\n",
      "[Epoch 30/200] [Batch 214/637] [D loss: 0.148095] [G loss: 0.537642]\n",
      "[Epoch 30/200] [Batch 215/637] [D loss: 0.166083] [G loss: 0.498981]\n",
      "[Epoch 30/200] [Batch 216/637] [D loss: 0.160456] [G loss: 0.443403]\n",
      "[Epoch 30/200] [Batch 217/637] [D loss: 0.162392] [G loss: 0.513266]\n",
      "[Epoch 30/200] [Batch 218/637] [D loss: 0.183239] [G loss: 0.505744]\n",
      "[Epoch 30/200] [Batch 219/637] [D loss: 0.160713] [G loss: 0.574317]\n",
      "[Epoch 30/200] [Batch 220/637] [D loss: 0.194626] [G loss: 0.446833]\n",
      "[Epoch 30/200] [Batch 221/637] [D loss: 0.199707] [G loss: 0.420875]\n",
      "[Epoch 30/200] [Batch 222/637] [D loss: 0.187804] [G loss: 0.431276]\n",
      "[Epoch 30/200] [Batch 223/637] [D loss: 0.177095] [G loss: 0.498114]\n",
      "[Epoch 30/200] [Batch 224/637] [D loss: 0.176960] [G loss: 0.491239]\n",
      "[Epoch 30/200] [Batch 225/637] [D loss: 0.166701] [G loss: 0.408510]\n",
      "[Epoch 30/200] [Batch 226/637] [D loss: 0.149352] [G loss: 0.501373]\n",
      "[Epoch 30/200] [Batch 227/637] [D loss: 0.171855] [G loss: 0.490462]\n",
      "[Epoch 30/200] [Batch 228/637] [D loss: 0.154891] [G loss: 0.488410]\n",
      "[Epoch 30/200] [Batch 229/637] [D loss: 0.187201] [G loss: 0.465565]\n",
      "[Epoch 30/200] [Batch 230/637] [D loss: 0.159896] [G loss: 0.477106]\n",
      "[Epoch 30/200] [Batch 231/637] [D loss: 0.169650] [G loss: 0.468198]\n",
      "[Epoch 30/200] [Batch 232/637] [D loss: 0.184285] [G loss: 0.518895]\n",
      "[Epoch 30/200] [Batch 233/637] [D loss: 0.160061] [G loss: 0.446284]\n",
      "[Epoch 30/200] [Batch 234/637] [D loss: 0.184052] [G loss: 0.535930]\n",
      "[Epoch 30/200] [Batch 235/637] [D loss: 0.179693] [G loss: 0.592764]\n",
      "[Epoch 30/200] [Batch 236/637] [D loss: 0.176174] [G loss: 0.462984]\n",
      "[Epoch 30/200] [Batch 237/637] [D loss: 0.169973] [G loss: 0.449358]\n",
      "[Epoch 30/200] [Batch 238/637] [D loss: 0.178333] [G loss: 0.427350]\n",
      "[Epoch 30/200] [Batch 239/637] [D loss: 0.169943] [G loss: 0.452466]\n",
      "[Epoch 30/200] [Batch 240/637] [D loss: 0.162283] [G loss: 0.531241]\n",
      "[Epoch 30/200] [Batch 241/637] [D loss: 0.179865] [G loss: 0.487881]\n",
      "[Epoch 30/200] [Batch 242/637] [D loss: 0.170805] [G loss: 0.504838]\n",
      "[Epoch 30/200] [Batch 243/637] [D loss: 0.164882] [G loss: 0.520030]\n",
      "[Epoch 30/200] [Batch 244/637] [D loss: 0.161633] [G loss: 0.490562]\n",
      "[Epoch 30/200] [Batch 245/637] [D loss: 0.196290] [G loss: 0.455934]\n",
      "[Epoch 30/200] [Batch 246/637] [D loss: 0.188399] [G loss: 0.530979]\n",
      "[Epoch 30/200] [Batch 247/637] [D loss: 0.163123] [G loss: 0.514359]\n",
      "[Epoch 30/200] [Batch 248/637] [D loss: 0.158277] [G loss: 0.563792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 249/637] [D loss: 0.173857] [G loss: 0.522784]\n",
      "[Epoch 30/200] [Batch 250/637] [D loss: 0.161214] [G loss: 0.439328]\n",
      "[Epoch 30/200] [Batch 251/637] [D loss: 0.147869] [G loss: 0.482426]\n",
      "[Epoch 30/200] [Batch 252/637] [D loss: 0.159350] [G loss: 0.579621]\n",
      "[Epoch 30/200] [Batch 253/637] [D loss: 0.157504] [G loss: 0.622904]\n",
      "[Epoch 30/200] [Batch 254/637] [D loss: 0.181699] [G loss: 0.501733]\n",
      "[Epoch 30/200] [Batch 255/637] [D loss: 0.200614] [G loss: 0.447725]\n",
      "[Epoch 30/200] [Batch 256/637] [D loss: 0.181147] [G loss: 0.495526]\n",
      "[Epoch 30/200] [Batch 257/637] [D loss: 0.174903] [G loss: 0.484442]\n",
      "[Epoch 30/200] [Batch 258/637] [D loss: 0.178353] [G loss: 0.506291]\n",
      "[Epoch 30/200] [Batch 259/637] [D loss: 0.156120] [G loss: 0.578967]\n",
      "[Epoch 30/200] [Batch 260/637] [D loss: 0.164323] [G loss: 0.479124]\n",
      "[Epoch 30/200] [Batch 261/637] [D loss: 0.181285] [G loss: 0.470329]\n",
      "[Epoch 30/200] [Batch 262/637] [D loss: 0.180800] [G loss: 0.505441]\n",
      "[Epoch 30/200] [Batch 263/637] [D loss: 0.172666] [G loss: 0.476590]\n",
      "[Epoch 30/200] [Batch 264/637] [D loss: 0.144769] [G loss: 0.517125]\n",
      "[Epoch 30/200] [Batch 265/637] [D loss: 0.177118] [G loss: 0.555459]\n",
      "[Epoch 30/200] [Batch 266/637] [D loss: 0.183093] [G loss: 0.515314]\n",
      "[Epoch 30/200] [Batch 267/637] [D loss: 0.179454] [G loss: 0.451042]\n",
      "[Epoch 30/200] [Batch 268/637] [D loss: 0.188463] [G loss: 0.439975]\n",
      "[Epoch 30/200] [Batch 269/637] [D loss: 0.180769] [G loss: 0.455898]\n",
      "[Epoch 30/200] [Batch 270/637] [D loss: 0.149126] [G loss: 0.486275]\n",
      "[Epoch 30/200] [Batch 271/637] [D loss: 0.171386] [G loss: 0.497213]\n",
      "[Epoch 30/200] [Batch 272/637] [D loss: 0.179047] [G loss: 0.511457]\n",
      "[Epoch 30/200] [Batch 273/637] [D loss: 0.163350] [G loss: 0.482472]\n",
      "[Epoch 30/200] [Batch 274/637] [D loss: 0.154756] [G loss: 0.484736]\n",
      "[Epoch 30/200] [Batch 275/637] [D loss: 0.174465] [G loss: 0.458794]\n",
      "[Epoch 30/200] [Batch 276/637] [D loss: 0.189926] [G loss: 0.496124]\n",
      "[Epoch 30/200] [Batch 277/637] [D loss: 0.178321] [G loss: 0.447860]\n",
      "[Epoch 30/200] [Batch 278/637] [D loss: 0.170042] [G loss: 0.514306]\n",
      "[Epoch 30/200] [Batch 279/637] [D loss: 0.174406] [G loss: 0.482694]\n",
      "[Epoch 30/200] [Batch 280/637] [D loss: 0.197396] [G loss: 0.499454]\n",
      "[Epoch 30/200] [Batch 281/637] [D loss: 0.176623] [G loss: 0.531129]\n",
      "[Epoch 30/200] [Batch 282/637] [D loss: 0.167577] [G loss: 0.494750]\n",
      "[Epoch 30/200] [Batch 283/637] [D loss: 0.230245] [G loss: 0.471439]\n",
      "[Epoch 30/200] [Batch 284/637] [D loss: 0.162687] [G loss: 0.622308]\n",
      "[Epoch 30/200] [Batch 285/637] [D loss: 0.194404] [G loss: 0.527201]\n",
      "[Epoch 30/200] [Batch 286/637] [D loss: 0.168278] [G loss: 0.473524]\n",
      "[Epoch 30/200] [Batch 287/637] [D loss: 0.143027] [G loss: 0.489616]\n",
      "[Epoch 30/200] [Batch 288/637] [D loss: 0.169390] [G loss: 0.493611]\n",
      "[Epoch 30/200] [Batch 289/637] [D loss: 0.159715] [G loss: 0.509889]\n",
      "[Epoch 30/200] [Batch 290/637] [D loss: 0.155723] [G loss: 0.477369]\n",
      "[Epoch 30/200] [Batch 291/637] [D loss: 0.149998] [G loss: 0.517659]\n",
      "[Epoch 30/200] [Batch 292/637] [D loss: 0.182337] [G loss: 0.551505]\n",
      "[Epoch 30/200] [Batch 293/637] [D loss: 0.164522] [G loss: 0.539235]\n",
      "[Epoch 30/200] [Batch 294/637] [D loss: 0.162509] [G loss: 0.505121]\n",
      "[Epoch 30/200] [Batch 295/637] [D loss: 0.158381] [G loss: 0.488334]\n",
      "[Epoch 30/200] [Batch 296/637] [D loss: 0.177654] [G loss: 0.520271]\n",
      "[Epoch 30/200] [Batch 297/637] [D loss: 0.194248] [G loss: 0.480313]\n",
      "[Epoch 30/200] [Batch 298/637] [D loss: 0.172447] [G loss: 0.464738]\n",
      "[Epoch 30/200] [Batch 299/637] [D loss: 0.166130] [G loss: 0.477488]\n",
      "[Epoch 30/200] [Batch 300/637] [D loss: 0.167840] [G loss: 0.501639]\n",
      "[Epoch 30/200] [Batch 301/637] [D loss: 0.165920] [G loss: 0.511735]\n",
      "[Epoch 30/200] [Batch 302/637] [D loss: 0.166092] [G loss: 0.529750]\n",
      "[Epoch 30/200] [Batch 303/637] [D loss: 0.202827] [G loss: 0.436633]\n",
      "[Epoch 30/200] [Batch 304/637] [D loss: 0.211954] [G loss: 0.450650]\n",
      "[Epoch 30/200] [Batch 305/637] [D loss: 0.149456] [G loss: 0.536933]\n",
      "[Epoch 30/200] [Batch 306/637] [D loss: 0.173604] [G loss: 0.489173]\n",
      "[Epoch 30/200] [Batch 307/637] [D loss: 0.186506] [G loss: 0.577153]\n",
      "[Epoch 30/200] [Batch 308/637] [D loss: 0.198799] [G loss: 0.463913]\n",
      "[Epoch 30/200] [Batch 309/637] [D loss: 0.186310] [G loss: 0.503759]\n",
      "[Epoch 30/200] [Batch 310/637] [D loss: 0.196966] [G loss: 0.446765]\n",
      "[Epoch 30/200] [Batch 311/637] [D loss: 0.179912] [G loss: 0.454024]\n",
      "[Epoch 30/200] [Batch 312/637] [D loss: 0.186639] [G loss: 0.481028]\n",
      "[Epoch 30/200] [Batch 313/637] [D loss: 0.173600] [G loss: 0.429102]\n",
      "[Epoch 30/200] [Batch 314/637] [D loss: 0.210008] [G loss: 0.425357]\n",
      "[Epoch 30/200] [Batch 315/637] [D loss: 0.172033] [G loss: 0.493990]\n",
      "[Epoch 30/200] [Batch 316/637] [D loss: 0.189954] [G loss: 0.461251]\n",
      "[Epoch 30/200] [Batch 317/637] [D loss: 0.177605] [G loss: 0.459232]\n",
      "[Epoch 30/200] [Batch 318/637] [D loss: 0.176176] [G loss: 0.451420]\n",
      "[Epoch 30/200] [Batch 319/637] [D loss: 0.177045] [G loss: 0.479936]\n",
      "[Epoch 30/200] [Batch 320/637] [D loss: 0.172182] [G loss: 0.467981]\n",
      "[Epoch 30/200] [Batch 321/637] [D loss: 0.179199] [G loss: 0.541066]\n",
      "[Epoch 30/200] [Batch 322/637] [D loss: 0.157058] [G loss: 0.441907]\n",
      "[Epoch 30/200] [Batch 323/637] [D loss: 0.179623] [G loss: 0.444529]\n",
      "[Epoch 30/200] [Batch 324/637] [D loss: 0.133487] [G loss: 0.509113]\n",
      "[Epoch 30/200] [Batch 325/637] [D loss: 0.158214] [G loss: 0.537503]\n",
      "[Epoch 30/200] [Batch 326/637] [D loss: 0.160180] [G loss: 0.516316]\n",
      "[Epoch 30/200] [Batch 327/637] [D loss: 0.157733] [G loss: 0.551089]\n",
      "[Epoch 30/200] [Batch 328/637] [D loss: 0.150435] [G loss: 0.556871]\n",
      "[Epoch 30/200] [Batch 329/637] [D loss: 0.176619] [G loss: 0.459030]\n",
      "[Epoch 30/200] [Batch 330/637] [D loss: 0.177090] [G loss: 0.512835]\n",
      "[Epoch 30/200] [Batch 331/637] [D loss: 0.157730] [G loss: 0.516498]\n",
      "[Epoch 30/200] [Batch 332/637] [D loss: 0.149760] [G loss: 0.504800]\n",
      "[Epoch 30/200] [Batch 333/637] [D loss: 0.169908] [G loss: 0.482638]\n",
      "[Epoch 30/200] [Batch 334/637] [D loss: 0.193019] [G loss: 0.485447]\n",
      "[Epoch 30/200] [Batch 335/637] [D loss: 0.179989] [G loss: 0.484191]\n",
      "[Epoch 30/200] [Batch 336/637] [D loss: 0.160882] [G loss: 0.518138]\n",
      "[Epoch 30/200] [Batch 337/637] [D loss: 0.176789] [G loss: 0.606097]\n",
      "[Epoch 30/200] [Batch 338/637] [D loss: 0.159816] [G loss: 0.538095]\n",
      "[Epoch 30/200] [Batch 339/637] [D loss: 0.168193] [G loss: 0.457304]\n",
      "[Epoch 30/200] [Batch 340/637] [D loss: 0.184916] [G loss: 0.510608]\n",
      "[Epoch 30/200] [Batch 341/637] [D loss: 0.178942] [G loss: 0.469306]\n",
      "[Epoch 30/200] [Batch 342/637] [D loss: 0.184911] [G loss: 0.496841]\n",
      "[Epoch 30/200] [Batch 343/637] [D loss: 0.157756] [G loss: 0.562680]\n",
      "[Epoch 30/200] [Batch 344/637] [D loss: 0.157362] [G loss: 0.510878]\n",
      "[Epoch 30/200] [Batch 345/637] [D loss: 0.159714] [G loss: 0.527210]\n",
      "[Epoch 30/200] [Batch 346/637] [D loss: 0.200691] [G loss: 0.454783]\n",
      "[Epoch 30/200] [Batch 347/637] [D loss: 0.170035] [G loss: 0.540366]\n",
      "[Epoch 30/200] [Batch 348/637] [D loss: 0.169072] [G loss: 0.521282]\n",
      "[Epoch 30/200] [Batch 349/637] [D loss: 0.164956] [G loss: 0.459418]\n",
      "[Epoch 30/200] [Batch 350/637] [D loss: 0.162299] [G loss: 0.526402]\n",
      "[Epoch 30/200] [Batch 351/637] [D loss: 0.146558] [G loss: 0.553371]\n",
      "[Epoch 30/200] [Batch 352/637] [D loss: 0.187377] [G loss: 0.457007]\n",
      "[Epoch 30/200] [Batch 353/637] [D loss: 0.167634] [G loss: 0.463300]\n",
      "[Epoch 30/200] [Batch 354/637] [D loss: 0.211676] [G loss: 0.440230]\n",
      "[Epoch 30/200] [Batch 355/637] [D loss: 0.186481] [G loss: 0.463064]\n",
      "[Epoch 30/200] [Batch 356/637] [D loss: 0.168610] [G loss: 0.517284]\n",
      "[Epoch 30/200] [Batch 357/637] [D loss: 0.166374] [G loss: 0.457985]\n",
      "[Epoch 30/200] [Batch 358/637] [D loss: 0.166811] [G loss: 0.484785]\n",
      "[Epoch 30/200] [Batch 359/637] [D loss: 0.178425] [G loss: 0.451146]\n",
      "[Epoch 30/200] [Batch 360/637] [D loss: 0.181865] [G loss: 0.463733]\n",
      "[Epoch 30/200] [Batch 361/637] [D loss: 0.185672] [G loss: 0.483797]\n",
      "[Epoch 30/200] [Batch 362/637] [D loss: 0.170776] [G loss: 0.487515]\n",
      "[Epoch 30/200] [Batch 363/637] [D loss: 0.152981] [G loss: 0.479741]\n",
      "[Epoch 30/200] [Batch 364/637] [D loss: 0.162737] [G loss: 0.443046]\n",
      "[Epoch 30/200] [Batch 365/637] [D loss: 0.160985] [G loss: 0.564168]\n",
      "[Epoch 30/200] [Batch 366/637] [D loss: 0.160004] [G loss: 0.556718]\n",
      "[Epoch 30/200] [Batch 367/637] [D loss: 0.171562] [G loss: 0.487399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 368/637] [D loss: 0.189374] [G loss: 0.494046]\n",
      "[Epoch 30/200] [Batch 369/637] [D loss: 0.166428] [G loss: 0.558701]\n",
      "[Epoch 30/200] [Batch 370/637] [D loss: 0.153173] [G loss: 0.578775]\n",
      "[Epoch 30/200] [Batch 371/637] [D loss: 0.192498] [G loss: 0.503626]\n",
      "[Epoch 30/200] [Batch 372/637] [D loss: 0.169724] [G loss: 0.488483]\n",
      "[Epoch 30/200] [Batch 373/637] [D loss: 0.185931] [G loss: 0.509534]\n",
      "[Epoch 30/200] [Batch 374/637] [D loss: 0.184271] [G loss: 0.519993]\n",
      "[Epoch 30/200] [Batch 375/637] [D loss: 0.168887] [G loss: 0.559774]\n",
      "[Epoch 30/200] [Batch 376/637] [D loss: 0.152751] [G loss: 0.537990]\n",
      "[Epoch 30/200] [Batch 377/637] [D loss: 0.133673] [G loss: 0.518554]\n",
      "[Epoch 30/200] [Batch 378/637] [D loss: 0.159769] [G loss: 0.455350]\n",
      "[Epoch 30/200] [Batch 379/637] [D loss: 0.153141] [G loss: 0.548536]\n",
      "[Epoch 30/200] [Batch 380/637] [D loss: 0.173747] [G loss: 0.461638]\n",
      "[Epoch 30/200] [Batch 381/637] [D loss: 0.186460] [G loss: 0.452444]\n",
      "[Epoch 30/200] [Batch 382/637] [D loss: 0.167111] [G loss: 0.479741]\n",
      "[Epoch 30/200] [Batch 383/637] [D loss: 0.141099] [G loss: 0.546692]\n",
      "[Epoch 30/200] [Batch 384/637] [D loss: 0.133165] [G loss: 0.490280]\n",
      "[Epoch 30/200] [Batch 385/637] [D loss: 0.151282] [G loss: 0.446405]\n",
      "[Epoch 30/200] [Batch 386/637] [D loss: 0.157689] [G loss: 0.472408]\n",
      "[Epoch 30/200] [Batch 387/637] [D loss: 0.183789] [G loss: 0.568427]\n",
      "[Epoch 30/200] [Batch 388/637] [D loss: 0.166981] [G loss: 0.518997]\n",
      "[Epoch 30/200] [Batch 389/637] [D loss: 0.184229] [G loss: 0.466131]\n",
      "[Epoch 30/200] [Batch 390/637] [D loss: 0.170986] [G loss: 0.440869]\n",
      "[Epoch 30/200] [Batch 391/637] [D loss: 0.171545] [G loss: 0.501477]\n",
      "[Epoch 30/200] [Batch 392/637] [D loss: 0.156951] [G loss: 0.533383]\n",
      "[Epoch 30/200] [Batch 393/637] [D loss: 0.168409] [G loss: 0.487581]\n",
      "[Epoch 30/200] [Batch 394/637] [D loss: 0.186250] [G loss: 0.466618]\n",
      "[Epoch 30/200] [Batch 395/637] [D loss: 0.168905] [G loss: 0.487071]\n",
      "[Epoch 30/200] [Batch 396/637] [D loss: 0.146894] [G loss: 0.568380]\n",
      "[Epoch 30/200] [Batch 397/637] [D loss: 0.154194] [G loss: 0.541873]\n",
      "[Epoch 30/200] [Batch 398/637] [D loss: 0.150094] [G loss: 0.527665]\n",
      "[Epoch 30/200] [Batch 399/637] [D loss: 0.154850] [G loss: 0.539505]\n",
      "[Epoch 30/200] [Batch 400/637] [D loss: 0.167167] [G loss: 0.548869]\n",
      "[Epoch 30/200] [Batch 401/637] [D loss: 0.152661] [G loss: 0.554610]\n",
      "[Epoch 30/200] [Batch 402/637] [D loss: 0.170455] [G loss: 0.480191]\n",
      "[Epoch 30/200] [Batch 403/637] [D loss: 0.183288] [G loss: 0.463698]\n",
      "[Epoch 30/200] [Batch 404/637] [D loss: 0.166968] [G loss: 0.505040]\n",
      "[Epoch 30/200] [Batch 405/637] [D loss: 0.168367] [G loss: 0.491209]\n",
      "[Epoch 30/200] [Batch 406/637] [D loss: 0.155329] [G loss: 0.471652]\n",
      "[Epoch 30/200] [Batch 407/637] [D loss: 0.157703] [G loss: 0.487086]\n",
      "[Epoch 30/200] [Batch 408/637] [D loss: 0.159639] [G loss: 0.464657]\n",
      "[Epoch 30/200] [Batch 409/637] [D loss: 0.172378] [G loss: 0.466344]\n",
      "[Epoch 30/200] [Batch 410/637] [D loss: 0.211506] [G loss: 0.503912]\n",
      "[Epoch 30/200] [Batch 411/637] [D loss: 0.163236] [G loss: 0.710814]\n",
      "[Epoch 30/200] [Batch 412/637] [D loss: 0.182662] [G loss: 0.565212]\n",
      "[Epoch 30/200] [Batch 413/637] [D loss: 0.145925] [G loss: 0.580291]\n",
      "[Epoch 30/200] [Batch 414/637] [D loss: 0.185863] [G loss: 0.427034]\n",
      "[Epoch 30/200] [Batch 415/637] [D loss: 0.154520] [G loss: 0.496088]\n",
      "[Epoch 30/200] [Batch 416/637] [D loss: 0.150442] [G loss: 0.499001]\n",
      "[Epoch 30/200] [Batch 417/637] [D loss: 0.159869] [G loss: 0.517314]\n",
      "[Epoch 30/200] [Batch 418/637] [D loss: 0.137440] [G loss: 0.616367]\n",
      "[Epoch 30/200] [Batch 419/637] [D loss: 0.158387] [G loss: 0.471848]\n",
      "[Epoch 30/200] [Batch 420/637] [D loss: 0.169346] [G loss: 0.532384]\n",
      "[Epoch 30/200] [Batch 421/637] [D loss: 0.186316] [G loss: 0.494947]\n",
      "[Epoch 30/200] [Batch 422/637] [D loss: 0.158016] [G loss: 0.497258]\n",
      "[Epoch 30/200] [Batch 423/637] [D loss: 0.144582] [G loss: 0.530959]\n",
      "[Epoch 30/200] [Batch 424/637] [D loss: 0.184493] [G loss: 0.446041]\n",
      "[Epoch 30/200] [Batch 425/637] [D loss: 0.158873] [G loss: 0.528931]\n",
      "[Epoch 30/200] [Batch 426/637] [D loss: 0.169675] [G loss: 0.464777]\n",
      "[Epoch 30/200] [Batch 427/637] [D loss: 0.186951] [G loss: 0.492925]\n",
      "[Epoch 30/200] [Batch 428/637] [D loss: 0.189595] [G loss: 0.454748]\n",
      "[Epoch 30/200] [Batch 429/637] [D loss: 0.141984] [G loss: 0.496141]\n",
      "[Epoch 30/200] [Batch 430/637] [D loss: 0.160875] [G loss: 0.522258]\n",
      "[Epoch 30/200] [Batch 431/637] [D loss: 0.175277] [G loss: 0.490794]\n",
      "[Epoch 30/200] [Batch 432/637] [D loss: 0.173484] [G loss: 0.540205]\n",
      "[Epoch 30/200] [Batch 433/637] [D loss: 0.147336] [G loss: 0.541303]\n",
      "[Epoch 30/200] [Batch 434/637] [D loss: 0.186656] [G loss: 0.392708]\n",
      "[Epoch 30/200] [Batch 435/637] [D loss: 0.164463] [G loss: 0.499419]\n",
      "[Epoch 30/200] [Batch 436/637] [D loss: 0.166499] [G loss: 0.477077]\n",
      "[Epoch 30/200] [Batch 437/637] [D loss: 0.173170] [G loss: 0.507282]\n",
      "[Epoch 30/200] [Batch 438/637] [D loss: 0.154014] [G loss: 0.526845]\n",
      "[Epoch 30/200] [Batch 439/637] [D loss: 0.161708] [G loss: 0.462375]\n",
      "[Epoch 30/200] [Batch 440/637] [D loss: 0.172431] [G loss: 0.461017]\n",
      "[Epoch 30/200] [Batch 441/637] [D loss: 0.165693] [G loss: 0.458834]\n",
      "[Epoch 30/200] [Batch 442/637] [D loss: 0.145917] [G loss: 0.568137]\n",
      "[Epoch 30/200] [Batch 443/637] [D loss: 0.163221] [G loss: 0.541141]\n",
      "[Epoch 30/200] [Batch 444/637] [D loss: 0.164043] [G loss: 0.508697]\n",
      "[Epoch 30/200] [Batch 445/637] [D loss: 0.189959] [G loss: 0.495268]\n",
      "[Epoch 30/200] [Batch 446/637] [D loss: 0.155388] [G loss: 0.520789]\n",
      "[Epoch 30/200] [Batch 447/637] [D loss: 0.145720] [G loss: 0.503153]\n",
      "[Epoch 30/200] [Batch 448/637] [D loss: 0.163928] [G loss: 0.528875]\n",
      "[Epoch 30/200] [Batch 449/637] [D loss: 0.156923] [G loss: 0.541759]\n",
      "[Epoch 30/200] [Batch 450/637] [D loss: 0.162018] [G loss: 0.608193]\n",
      "[Epoch 30/200] [Batch 451/637] [D loss: 0.196347] [G loss: 0.456622]\n",
      "[Epoch 30/200] [Batch 452/637] [D loss: 0.195384] [G loss: 0.504670]\n",
      "[Epoch 30/200] [Batch 453/637] [D loss: 0.158525] [G loss: 0.523022]\n",
      "[Epoch 30/200] [Batch 454/637] [D loss: 0.150546] [G loss: 0.555108]\n",
      "[Epoch 30/200] [Batch 455/637] [D loss: 0.168821] [G loss: 0.508394]\n",
      "[Epoch 30/200] [Batch 456/637] [D loss: 0.200384] [G loss: 0.411509]\n",
      "[Epoch 30/200] [Batch 457/637] [D loss: 0.220557] [G loss: 0.430342]\n",
      "[Epoch 30/200] [Batch 458/637] [D loss: 0.156905] [G loss: 0.552438]\n",
      "[Epoch 30/200] [Batch 459/637] [D loss: 0.156913] [G loss: 0.474602]\n",
      "[Epoch 30/200] [Batch 460/637] [D loss: 0.174203] [G loss: 0.510886]\n",
      "[Epoch 30/200] [Batch 461/637] [D loss: 0.149293] [G loss: 0.529583]\n",
      "[Epoch 30/200] [Batch 462/637] [D loss: 0.157364] [G loss: 0.527203]\n",
      "[Epoch 30/200] [Batch 463/637] [D loss: 0.161647] [G loss: 0.518784]\n",
      "[Epoch 30/200] [Batch 464/637] [D loss: 0.152912] [G loss: 0.511792]\n",
      "[Epoch 30/200] [Batch 465/637] [D loss: 0.179157] [G loss: 0.474978]\n",
      "[Epoch 30/200] [Batch 466/637] [D loss: 0.163870] [G loss: 0.538742]\n",
      "[Epoch 30/200] [Batch 467/637] [D loss: 0.169500] [G loss: 0.530349]\n",
      "[Epoch 30/200] [Batch 468/637] [D loss: 0.160640] [G loss: 0.439503]\n",
      "[Epoch 30/200] [Batch 469/637] [D loss: 0.183333] [G loss: 0.433357]\n",
      "[Epoch 30/200] [Batch 470/637] [D loss: 0.136507] [G loss: 0.547168]\n",
      "[Epoch 30/200] [Batch 471/637] [D loss: 0.195114] [G loss: 0.539925]\n",
      "[Epoch 30/200] [Batch 472/637] [D loss: 0.153572] [G loss: 0.468583]\n",
      "[Epoch 30/200] [Batch 473/637] [D loss: 0.176572] [G loss: 0.480180]\n",
      "[Epoch 30/200] [Batch 474/637] [D loss: 0.156736] [G loss: 0.547695]\n",
      "[Epoch 30/200] [Batch 475/637] [D loss: 0.172365] [G loss: 0.498601]\n",
      "[Epoch 30/200] [Batch 476/637] [D loss: 0.142975] [G loss: 0.507691]\n",
      "[Epoch 30/200] [Batch 477/637] [D loss: 0.175071] [G loss: 0.455586]\n",
      "[Epoch 30/200] [Batch 478/637] [D loss: 0.180548] [G loss: 0.465596]\n",
      "[Epoch 30/200] [Batch 479/637] [D loss: 0.164704] [G loss: 0.508139]\n",
      "[Epoch 30/200] [Batch 480/637] [D loss: 0.174971] [G loss: 0.447976]\n",
      "[Epoch 30/200] [Batch 481/637] [D loss: 0.159772] [G loss: 0.417829]\n",
      "[Epoch 30/200] [Batch 482/637] [D loss: 0.177507] [G loss: 0.431594]\n",
      "[Epoch 30/200] [Batch 483/637] [D loss: 0.152867] [G loss: 0.518899]\n",
      "[Epoch 30/200] [Batch 484/637] [D loss: 0.181051] [G loss: 0.476872]\n",
      "[Epoch 30/200] [Batch 485/637] [D loss: 0.163933] [G loss: 0.406079]\n",
      "[Epoch 30/200] [Batch 486/637] [D loss: 0.172962] [G loss: 0.431652]\n",
      "[Epoch 30/200] [Batch 487/637] [D loss: 0.190853] [G loss: 0.497037]\n",
      "[Epoch 30/200] [Batch 488/637] [D loss: 0.170935] [G loss: 0.483465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 489/637] [D loss: 0.177644] [G loss: 0.473175]\n",
      "[Epoch 30/200] [Batch 490/637] [D loss: 0.173108] [G loss: 0.464427]\n",
      "[Epoch 30/200] [Batch 491/637] [D loss: 0.178743] [G loss: 0.508252]\n",
      "[Epoch 30/200] [Batch 492/637] [D loss: 0.169675] [G loss: 0.434353]\n",
      "[Epoch 30/200] [Batch 493/637] [D loss: 0.172989] [G loss: 0.455306]\n",
      "[Epoch 30/200] [Batch 494/637] [D loss: 0.173693] [G loss: 0.488652]\n",
      "[Epoch 30/200] [Batch 495/637] [D loss: 0.162172] [G loss: 0.486944]\n",
      "[Epoch 30/200] [Batch 496/637] [D loss: 0.160367] [G loss: 0.475277]\n",
      "[Epoch 30/200] [Batch 497/637] [D loss: 0.146081] [G loss: 0.441026]\n",
      "[Epoch 30/200] [Batch 498/637] [D loss: 0.132089] [G loss: 0.456746]\n",
      "[Epoch 30/200] [Batch 499/637] [D loss: 0.145536] [G loss: 0.496512]\n",
      "[Epoch 30/200] [Batch 500/637] [D loss: 0.143751] [G loss: 0.531440]\n",
      "[Epoch 30/200] [Batch 501/637] [D loss: 0.153618] [G loss: 0.442528]\n",
      "[Epoch 30/200] [Batch 502/637] [D loss: 0.151605] [G loss: 0.603588]\n",
      "[Epoch 30/200] [Batch 503/637] [D loss: 0.159582] [G loss: 0.489101]\n",
      "[Epoch 30/200] [Batch 504/637] [D loss: 0.159687] [G loss: 0.536344]\n",
      "[Epoch 30/200] [Batch 505/637] [D loss: 0.153117] [G loss: 0.515550]\n",
      "[Epoch 30/200] [Batch 506/637] [D loss: 0.202930] [G loss: 0.447275]\n",
      "[Epoch 30/200] [Batch 507/637] [D loss: 0.165549] [G loss: 0.499415]\n",
      "[Epoch 30/200] [Batch 508/637] [D loss: 0.146435] [G loss: 0.547279]\n",
      "[Epoch 30/200] [Batch 509/637] [D loss: 0.152493] [G loss: 0.532994]\n",
      "[Epoch 30/200] [Batch 510/637] [D loss: 0.144704] [G loss: 0.599156]\n",
      "[Epoch 30/200] [Batch 511/637] [D loss: 0.150171] [G loss: 0.516709]\n",
      "[Epoch 30/200] [Batch 512/637] [D loss: 0.165457] [G loss: 0.468840]\n",
      "[Epoch 30/200] [Batch 513/637] [D loss: 0.170270] [G loss: 0.417717]\n",
      "[Epoch 30/200] [Batch 514/637] [D loss: 0.154473] [G loss: 0.575947]\n",
      "[Epoch 30/200] [Batch 515/637] [D loss: 0.141172] [G loss: 0.574008]\n",
      "[Epoch 30/200] [Batch 516/637] [D loss: 0.169585] [G loss: 0.499128]\n",
      "[Epoch 30/200] [Batch 517/637] [D loss: 0.165880] [G loss: 0.531802]\n",
      "[Epoch 30/200] [Batch 518/637] [D loss: 0.156856] [G loss: 0.500798]\n",
      "[Epoch 30/200] [Batch 519/637] [D loss: 0.162300] [G loss: 0.479043]\n",
      "[Epoch 30/200] [Batch 520/637] [D loss: 0.163205] [G loss: 0.455003]\n",
      "[Epoch 30/200] [Batch 521/637] [D loss: 0.135467] [G loss: 0.597320]\n",
      "[Epoch 30/200] [Batch 522/637] [D loss: 0.173348] [G loss: 0.511546]\n",
      "[Epoch 30/200] [Batch 523/637] [D loss: 0.155800] [G loss: 0.534576]\n",
      "[Epoch 30/200] [Batch 524/637] [D loss: 0.157667] [G loss: 0.557206]\n",
      "[Epoch 30/200] [Batch 525/637] [D loss: 0.155392] [G loss: 0.561279]\n",
      "[Epoch 30/200] [Batch 526/637] [D loss: 0.160941] [G loss: 0.474015]\n",
      "[Epoch 30/200] [Batch 527/637] [D loss: 0.169622] [G loss: 0.498573]\n",
      "[Epoch 30/200] [Batch 528/637] [D loss: 0.161026] [G loss: 0.498870]\n",
      "[Epoch 30/200] [Batch 529/637] [D loss: 0.170671] [G loss: 0.513753]\n",
      "[Epoch 30/200] [Batch 530/637] [D loss: 0.160323] [G loss: 0.594949]\n",
      "[Epoch 30/200] [Batch 531/637] [D loss: 0.175094] [G loss: 0.493557]\n",
      "[Epoch 30/200] [Batch 532/637] [D loss: 0.199677] [G loss: 0.474492]\n",
      "[Epoch 30/200] [Batch 533/637] [D loss: 0.163956] [G loss: 0.498027]\n",
      "[Epoch 30/200] [Batch 534/637] [D loss: 0.165654] [G loss: 0.476343]\n",
      "[Epoch 30/200] [Batch 535/637] [D loss: 0.163400] [G loss: 0.410687]\n",
      "[Epoch 30/200] [Batch 536/637] [D loss: 0.172040] [G loss: 0.428799]\n",
      "[Epoch 30/200] [Batch 537/637] [D loss: 0.175297] [G loss: 0.426791]\n",
      "[Epoch 30/200] [Batch 538/637] [D loss: 0.181406] [G loss: 0.466462]\n",
      "[Epoch 30/200] [Batch 539/637] [D loss: 0.157267] [G loss: 0.493462]\n",
      "[Epoch 30/200] [Batch 540/637] [D loss: 0.160667] [G loss: 0.529476]\n",
      "[Epoch 30/200] [Batch 541/637] [D loss: 0.158445] [G loss: 0.503675]\n",
      "[Epoch 30/200] [Batch 542/637] [D loss: 0.182172] [G loss: 0.469657]\n",
      "[Epoch 30/200] [Batch 543/637] [D loss: 0.168190] [G loss: 0.505969]\n",
      "[Epoch 30/200] [Batch 544/637] [D loss: 0.134523] [G loss: 0.563884]\n",
      "[Epoch 30/200] [Batch 545/637] [D loss: 0.154237] [G loss: 0.498225]\n",
      "[Epoch 30/200] [Batch 546/637] [D loss: 0.161503] [G loss: 0.493094]\n",
      "[Epoch 30/200] [Batch 547/637] [D loss: 0.163597] [G loss: 0.534479]\n",
      "[Epoch 30/200] [Batch 548/637] [D loss: 0.172842] [G loss: 0.504318]\n",
      "[Epoch 30/200] [Batch 549/637] [D loss: 0.176308] [G loss: 0.441277]\n",
      "[Epoch 30/200] [Batch 550/637] [D loss: 0.194499] [G loss: 0.473813]\n",
      "[Epoch 30/200] [Batch 551/637] [D loss: 0.183848] [G loss: 0.503213]\n",
      "[Epoch 30/200] [Batch 552/637] [D loss: 0.174359] [G loss: 0.413355]\n",
      "[Epoch 30/200] [Batch 553/637] [D loss: 0.178276] [G loss: 0.467816]\n",
      "[Epoch 30/200] [Batch 554/637] [D loss: 0.197836] [G loss: 0.409644]\n",
      "[Epoch 30/200] [Batch 555/637] [D loss: 0.154059] [G loss: 0.518193]\n",
      "[Epoch 30/200] [Batch 556/637] [D loss: 0.156896] [G loss: 0.505364]\n",
      "[Epoch 30/200] [Batch 557/637] [D loss: 0.180651] [G loss: 0.443575]\n",
      "[Epoch 30/200] [Batch 558/637] [D loss: 0.174713] [G loss: 0.462113]\n",
      "[Epoch 30/200] [Batch 559/637] [D loss: 0.171589] [G loss: 0.461502]\n",
      "[Epoch 30/200] [Batch 560/637] [D loss: 0.160103] [G loss: 0.500460]\n",
      "[Epoch 30/200] [Batch 561/637] [D loss: 0.164884] [G loss: 0.489267]\n",
      "[Epoch 30/200] [Batch 562/637] [D loss: 0.164321] [G loss: 0.420898]\n",
      "[Epoch 30/200] [Batch 563/637] [D loss: 0.165904] [G loss: 0.491359]\n",
      "[Epoch 30/200] [Batch 564/637] [D loss: 0.186371] [G loss: 0.456455]\n",
      "[Epoch 30/200] [Batch 565/637] [D loss: 0.224677] [G loss: 0.536047]\n",
      "[Epoch 30/200] [Batch 566/637] [D loss: 0.149167] [G loss: 0.560814]\n",
      "[Epoch 30/200] [Batch 567/637] [D loss: 0.198292] [G loss: 0.419545]\n",
      "[Epoch 30/200] [Batch 568/637] [D loss: 0.178351] [G loss: 0.572456]\n",
      "[Epoch 30/200] [Batch 569/637] [D loss: 0.157423] [G loss: 0.561395]\n",
      "[Epoch 30/200] [Batch 570/637] [D loss: 0.159942] [G loss: 0.441012]\n",
      "[Epoch 30/200] [Batch 571/637] [D loss: 0.159103] [G loss: 0.454997]\n",
      "[Epoch 30/200] [Batch 572/637] [D loss: 0.156332] [G loss: 0.474702]\n",
      "[Epoch 30/200] [Batch 573/637] [D loss: 0.173329] [G loss: 0.499464]\n",
      "[Epoch 30/200] [Batch 574/637] [D loss: 0.146401] [G loss: 0.644453]\n",
      "[Epoch 30/200] [Batch 575/637] [D loss: 0.200786] [G loss: 0.549240]\n",
      "[Epoch 30/200] [Batch 576/637] [D loss: 0.164141] [G loss: 0.515431]\n",
      "[Epoch 30/200] [Batch 577/637] [D loss: 0.167264] [G loss: 0.543929]\n",
      "[Epoch 30/200] [Batch 578/637] [D loss: 0.178751] [G loss: 0.387863]\n",
      "[Epoch 30/200] [Batch 579/637] [D loss: 0.152920] [G loss: 0.478579]\n",
      "[Epoch 30/200] [Batch 580/637] [D loss: 0.166646] [G loss: 0.460012]\n",
      "[Epoch 30/200] [Batch 581/637] [D loss: 0.212609] [G loss: 0.507134]\n",
      "[Epoch 30/200] [Batch 582/637] [D loss: 0.177985] [G loss: 0.543809]\n",
      "[Epoch 30/200] [Batch 583/637] [D loss: 0.183183] [G loss: 0.496615]\n",
      "[Epoch 30/200] [Batch 584/637] [D loss: 0.186459] [G loss: 0.560470]\n",
      "[Epoch 30/200] [Batch 585/637] [D loss: 0.145659] [G loss: 0.524730]\n",
      "[Epoch 30/200] [Batch 586/637] [D loss: 0.154220] [G loss: 0.481570]\n",
      "[Epoch 30/200] [Batch 587/637] [D loss: 0.173453] [G loss: 0.434379]\n",
      "[Epoch 30/200] [Batch 588/637] [D loss: 0.173710] [G loss: 0.476359]\n",
      "[Epoch 30/200] [Batch 589/637] [D loss: 0.160873] [G loss: 0.461479]\n",
      "[Epoch 30/200] [Batch 590/637] [D loss: 0.172870] [G loss: 0.499149]\n",
      "[Epoch 30/200] [Batch 591/637] [D loss: 0.155130] [G loss: 0.515528]\n",
      "[Epoch 30/200] [Batch 592/637] [D loss: 0.125175] [G loss: 0.512117]\n",
      "[Epoch 30/200] [Batch 593/637] [D loss: 0.141892] [G loss: 0.509485]\n",
      "[Epoch 30/200] [Batch 594/637] [D loss: 0.144767] [G loss: 0.540430]\n",
      "[Epoch 30/200] [Batch 595/637] [D loss: 0.150154] [G loss: 0.513003]\n",
      "[Epoch 30/200] [Batch 596/637] [D loss: 0.148101] [G loss: 0.545652]\n",
      "[Epoch 30/200] [Batch 597/637] [D loss: 0.162232] [G loss: 0.556860]\n",
      "[Epoch 30/200] [Batch 598/637] [D loss: 0.162214] [G loss: 0.483821]\n",
      "[Epoch 30/200] [Batch 599/637] [D loss: 0.159938] [G loss: 0.505931]\n",
      "[Epoch 30/200] [Batch 600/637] [D loss: 0.151767] [G loss: 0.514513]\n",
      "[Epoch 30/200] [Batch 601/637] [D loss: 0.168001] [G loss: 0.492394]\n",
      "[Epoch 30/200] [Batch 602/637] [D loss: 0.177797] [G loss: 0.491900]\n",
      "[Epoch 30/200] [Batch 603/637] [D loss: 0.189636] [G loss: 0.498080]\n",
      "[Epoch 30/200] [Batch 604/637] [D loss: 0.165944] [G loss: 0.483653]\n",
      "[Epoch 30/200] [Batch 605/637] [D loss: 0.187124] [G loss: 0.420291]\n",
      "[Epoch 30/200] [Batch 606/637] [D loss: 0.172231] [G loss: 0.453624]\n",
      "[Epoch 30/200] [Batch 607/637] [D loss: 0.159480] [G loss: 0.458986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 608/637] [D loss: 0.161736] [G loss: 0.464916]\n",
      "[Epoch 30/200] [Batch 609/637] [D loss: 0.175705] [G loss: 0.452239]\n",
      "[Epoch 30/200] [Batch 610/637] [D loss: 0.158338] [G loss: 0.534554]\n",
      "[Epoch 30/200] [Batch 611/637] [D loss: 0.140006] [G loss: 0.488127]\n",
      "[Epoch 30/200] [Batch 612/637] [D loss: 0.152972] [G loss: 0.474342]\n",
      "[Epoch 30/200] [Batch 613/637] [D loss: 0.159939] [G loss: 0.524132]\n",
      "[Epoch 30/200] [Batch 614/637] [D loss: 0.166234] [G loss: 0.495704]\n",
      "[Epoch 30/200] [Batch 615/637] [D loss: 0.150457] [G loss: 0.487133]\n",
      "[Epoch 30/200] [Batch 616/637] [D loss: 0.178985] [G loss: 0.452431]\n",
      "[Epoch 30/200] [Batch 617/637] [D loss: 0.170990] [G loss: 0.423865]\n",
      "[Epoch 30/200] [Batch 618/637] [D loss: 0.161039] [G loss: 0.491491]\n",
      "[Epoch 30/200] [Batch 619/637] [D loss: 0.178888] [G loss: 0.466648]\n",
      "[Epoch 30/200] [Batch 620/637] [D loss: 0.178151] [G loss: 0.437412]\n",
      "[Epoch 30/200] [Batch 621/637] [D loss: 0.147396] [G loss: 0.512972]\n",
      "[Epoch 30/200] [Batch 622/637] [D loss: 0.181656] [G loss: 0.555251]\n",
      "[Epoch 30/200] [Batch 623/637] [D loss: 0.184751] [G loss: 0.509860]\n",
      "[Epoch 30/200] [Batch 624/637] [D loss: 0.195809] [G loss: 0.456557]\n",
      "[Epoch 30/200] [Batch 625/637] [D loss: 0.179725] [G loss: 0.377515]\n",
      "[Epoch 30/200] [Batch 626/637] [D loss: 0.176846] [G loss: 0.496007]\n",
      "[Epoch 30/200] [Batch 627/637] [D loss: 0.164095] [G loss: 0.497881]\n",
      "[Epoch 30/200] [Batch 628/637] [D loss: 0.157113] [G loss: 0.541233]\n",
      "[Epoch 30/200] [Batch 629/637] [D loss: 0.187484] [G loss: 0.556062]\n",
      "[Epoch 30/200] [Batch 630/637] [D loss: 0.170923] [G loss: 0.479545]\n",
      "[Epoch 30/200] [Batch 631/637] [D loss: 0.166774] [G loss: 0.507663]\n",
      "[Epoch 30/200] [Batch 632/637] [D loss: 0.196369] [G loss: 0.482804]\n",
      "[Epoch 30/200] [Batch 633/637] [D loss: 0.171123] [G loss: 0.490036]\n",
      "[Epoch 30/200] [Batch 634/637] [D loss: 0.154985] [G loss: 0.480657]\n",
      "[Epoch 30/200] [Batch 635/637] [D loss: 0.171320] [G loss: 0.496554]\n",
      "[Epoch 30/200] [Batch 636/637] [D loss: 0.218853] [G loss: 0.333090]\n",
      "[Epoch 31/200] [Batch 0/637] [D loss: 0.169103] [G loss: 0.553723]\n",
      "[Epoch 31/200] [Batch 1/637] [D loss: 0.172733] [G loss: 0.501269]\n",
      "[Epoch 31/200] [Batch 2/637] [D loss: 0.181389] [G loss: 0.475461]\n",
      "[Epoch 31/200] [Batch 3/637] [D loss: 0.193738] [G loss: 0.487471]\n",
      "[Epoch 31/200] [Batch 4/637] [D loss: 0.164149] [G loss: 0.462248]\n",
      "[Epoch 31/200] [Batch 5/637] [D loss: 0.161143] [G loss: 0.465793]\n",
      "[Epoch 31/200] [Batch 6/637] [D loss: 0.161099] [G loss: 0.487977]\n",
      "[Epoch 31/200] [Batch 7/637] [D loss: 0.165751] [G loss: 0.506546]\n",
      "[Epoch 31/200] [Batch 8/637] [D loss: 0.160289] [G loss: 0.570913]\n",
      "[Epoch 31/200] [Batch 9/637] [D loss: 0.174353] [G loss: 0.440807]\n",
      "[Epoch 31/200] [Batch 10/637] [D loss: 0.162091] [G loss: 0.541229]\n",
      "[Epoch 31/200] [Batch 11/637] [D loss: 0.150538] [G loss: 0.536768]\n",
      "[Epoch 31/200] [Batch 12/637] [D loss: 0.174297] [G loss: 0.518018]\n",
      "[Epoch 31/200] [Batch 13/637] [D loss: 0.167614] [G loss: 0.550315]\n",
      "[Epoch 31/200] [Batch 14/637] [D loss: 0.167907] [G loss: 0.467362]\n",
      "[Epoch 31/200] [Batch 15/637] [D loss: 0.182211] [G loss: 0.487724]\n",
      "[Epoch 31/200] [Batch 16/637] [D loss: 0.159015] [G loss: 0.534655]\n",
      "[Epoch 31/200] [Batch 17/637] [D loss: 0.174154] [G loss: 0.519440]\n",
      "[Epoch 31/200] [Batch 18/637] [D loss: 0.179075] [G loss: 0.497792]\n",
      "[Epoch 31/200] [Batch 19/637] [D loss: 0.200915] [G loss: 0.478577]\n",
      "[Epoch 31/200] [Batch 20/637] [D loss: 0.173852] [G loss: 0.460046]\n",
      "[Epoch 31/200] [Batch 21/637] [D loss: 0.154137] [G loss: 0.548388]\n",
      "[Epoch 31/200] [Batch 22/637] [D loss: 0.164910] [G loss: 0.464436]\n",
      "[Epoch 31/200] [Batch 23/637] [D loss: 0.163885] [G loss: 0.496155]\n",
      "[Epoch 31/200] [Batch 24/637] [D loss: 0.174603] [G loss: 0.509366]\n",
      "[Epoch 31/200] [Batch 25/637] [D loss: 0.177273] [G loss: 0.483205]\n",
      "[Epoch 31/200] [Batch 26/637] [D loss: 0.179368] [G loss: 0.474957]\n",
      "[Epoch 31/200] [Batch 27/637] [D loss: 0.186776] [G loss: 0.515331]\n",
      "[Epoch 31/200] [Batch 28/637] [D loss: 0.176229] [G loss: 0.533964]\n",
      "[Epoch 31/200] [Batch 29/637] [D loss: 0.166276] [G loss: 0.518298]\n",
      "[Epoch 31/200] [Batch 30/637] [D loss: 0.166884] [G loss: 0.488597]\n",
      "[Epoch 31/200] [Batch 31/637] [D loss: 0.160723] [G loss: 0.493248]\n",
      "[Epoch 31/200] [Batch 32/637] [D loss: 0.162875] [G loss: 0.501169]\n",
      "[Epoch 31/200] [Batch 33/637] [D loss: 0.136212] [G loss: 0.509696]\n",
      "[Epoch 31/200] [Batch 34/637] [D loss: 0.151758] [G loss: 0.575343]\n",
      "[Epoch 31/200] [Batch 35/637] [D loss: 0.156926] [G loss: 0.500299]\n",
      "[Epoch 31/200] [Batch 36/637] [D loss: 0.188687] [G loss: 0.570257]\n",
      "[Epoch 31/200] [Batch 37/637] [D loss: 0.176067] [G loss: 0.512398]\n",
      "[Epoch 31/200] [Batch 38/637] [D loss: 0.174586] [G loss: 0.567071]\n",
      "[Epoch 31/200] [Batch 39/637] [D loss: 0.181505] [G loss: 0.493813]\n",
      "[Epoch 31/200] [Batch 40/637] [D loss: 0.171995] [G loss: 0.520802]\n",
      "[Epoch 31/200] [Batch 41/637] [D loss: 0.157615] [G loss: 0.512493]\n",
      "[Epoch 31/200] [Batch 42/637] [D loss: 0.205973] [G loss: 0.376114]\n",
      "[Epoch 31/200] [Batch 43/637] [D loss: 0.164769] [G loss: 0.489797]\n",
      "[Epoch 31/200] [Batch 44/637] [D loss: 0.159657] [G loss: 0.524792]\n",
      "[Epoch 31/200] [Batch 45/637] [D loss: 0.162161] [G loss: 0.455435]\n",
      "[Epoch 31/200] [Batch 46/637] [D loss: 0.155416] [G loss: 0.450652]\n",
      "[Epoch 31/200] [Batch 47/637] [D loss: 0.165002] [G loss: 0.517539]\n",
      "[Epoch 31/200] [Batch 48/637] [D loss: 0.153437] [G loss: 0.578316]\n",
      "[Epoch 31/200] [Batch 49/637] [D loss: 0.191675] [G loss: 0.551018]\n",
      "[Epoch 31/200] [Batch 50/637] [D loss: 0.151692] [G loss: 0.566972]\n",
      "[Epoch 31/200] [Batch 51/637] [D loss: 0.163089] [G loss: 0.537145]\n",
      "[Epoch 31/200] [Batch 52/637] [D loss: 0.181470] [G loss: 0.538046]\n",
      "[Epoch 31/200] [Batch 53/637] [D loss: 0.160586] [G loss: 0.465392]\n",
      "[Epoch 31/200] [Batch 54/637] [D loss: 0.206504] [G loss: 0.420451]\n",
      "[Epoch 31/200] [Batch 55/637] [D loss: 0.162413] [G loss: 0.600530]\n",
      "[Epoch 31/200] [Batch 56/637] [D loss: 0.185695] [G loss: 0.469593]\n",
      "[Epoch 31/200] [Batch 57/637] [D loss: 0.165296] [G loss: 0.447920]\n",
      "[Epoch 31/200] [Batch 58/637] [D loss: 0.154258] [G loss: 0.470402]\n",
      "[Epoch 31/200] [Batch 59/637] [D loss: 0.179604] [G loss: 0.452845]\n",
      "[Epoch 31/200] [Batch 60/637] [D loss: 0.175459] [G loss: 0.534918]\n",
      "[Epoch 31/200] [Batch 61/637] [D loss: 0.159142] [G loss: 0.566422]\n",
      "[Epoch 31/200] [Batch 62/637] [D loss: 0.169532] [G loss: 0.478178]\n",
      "[Epoch 31/200] [Batch 63/637] [D loss: 0.158325] [G loss: 0.531155]\n",
      "[Epoch 31/200] [Batch 64/637] [D loss: 0.157274] [G loss: 0.518085]\n",
      "[Epoch 31/200] [Batch 65/637] [D loss: 0.159015] [G loss: 0.583523]\n",
      "[Epoch 31/200] [Batch 66/637] [D loss: 0.193139] [G loss: 0.458391]\n",
      "[Epoch 31/200] [Batch 67/637] [D loss: 0.174806] [G loss: 0.548877]\n",
      "[Epoch 31/200] [Batch 68/637] [D loss: 0.175617] [G loss: 0.475861]\n",
      "[Epoch 31/200] [Batch 69/637] [D loss: 0.173204] [G loss: 0.453939]\n",
      "[Epoch 31/200] [Batch 70/637] [D loss: 0.162762] [G loss: 0.502073]\n",
      "[Epoch 31/200] [Batch 71/637] [D loss: 0.196598] [G loss: 0.421268]\n",
      "[Epoch 31/200] [Batch 72/637] [D loss: 0.187415] [G loss: 0.443087]\n",
      "[Epoch 31/200] [Batch 73/637] [D loss: 0.174113] [G loss: 0.533348]\n",
      "[Epoch 31/200] [Batch 74/637] [D loss: 0.175557] [G loss: 0.507768]\n",
      "[Epoch 31/200] [Batch 75/637] [D loss: 0.189728] [G loss: 0.447651]\n",
      "[Epoch 31/200] [Batch 76/637] [D loss: 0.178104] [G loss: 0.515860]\n",
      "[Epoch 31/200] [Batch 77/637] [D loss: 0.185885] [G loss: 0.439816]\n",
      "[Epoch 31/200] [Batch 78/637] [D loss: 0.165633] [G loss: 0.530117]\n",
      "[Epoch 31/200] [Batch 79/637] [D loss: 0.166987] [G loss: 0.480439]\n",
      "[Epoch 31/200] [Batch 80/637] [D loss: 0.178435] [G loss: 0.430798]\n",
      "[Epoch 31/200] [Batch 81/637] [D loss: 0.172594] [G loss: 0.502923]\n",
      "[Epoch 31/200] [Batch 82/637] [D loss: 0.171728] [G loss: 0.456843]\n",
      "[Epoch 31/200] [Batch 83/637] [D loss: 0.197150] [G loss: 0.447306]\n",
      "[Epoch 31/200] [Batch 84/637] [D loss: 0.176557] [G loss: 0.497821]\n",
      "[Epoch 31/200] [Batch 85/637] [D loss: 0.184971] [G loss: 0.508516]\n",
      "[Epoch 31/200] [Batch 86/637] [D loss: 0.191977] [G loss: 0.411747]\n",
      "[Epoch 31/200] [Batch 87/637] [D loss: 0.176544] [G loss: 0.458744]\n",
      "[Epoch 31/200] [Batch 88/637] [D loss: 0.169191] [G loss: 0.473775]\n",
      "[Epoch 31/200] [Batch 89/637] [D loss: 0.173596] [G loss: 0.479032]\n",
      "[Epoch 31/200] [Batch 90/637] [D loss: 0.194664] [G loss: 0.466487]\n",
      "[Epoch 31/200] [Batch 91/637] [D loss: 0.195516] [G loss: 0.461738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/200] [Batch 92/637] [D loss: 0.184579] [G loss: 0.520168]\n",
      "[Epoch 31/200] [Batch 93/637] [D loss: 0.174729] [G loss: 0.488906]\n",
      "[Epoch 31/200] [Batch 94/637] [D loss: 0.194089] [G loss: 0.441507]\n",
      "[Epoch 31/200] [Batch 95/637] [D loss: 0.157159] [G loss: 0.465930]\n",
      "[Epoch 31/200] [Batch 96/637] [D loss: 0.182138] [G loss: 0.474875]\n",
      "[Epoch 31/200] [Batch 97/637] [D loss: 0.189667] [G loss: 0.435455]\n",
      "[Epoch 31/200] [Batch 98/637] [D loss: 0.159871] [G loss: 0.482650]\n",
      "[Epoch 31/200] [Batch 99/637] [D loss: 0.161253] [G loss: 0.504325]\n",
      "[Epoch 31/200] [Batch 100/637] [D loss: 0.166872] [G loss: 0.496745]\n",
      "[Epoch 31/200] [Batch 101/637] [D loss: 0.173375] [G loss: 0.469787]\n",
      "[Epoch 31/200] [Batch 102/637] [D loss: 0.150829] [G loss: 0.523902]\n",
      "[Epoch 31/200] [Batch 103/637] [D loss: 0.161629] [G loss: 0.495586]\n",
      "[Epoch 31/200] [Batch 104/637] [D loss: 0.182374] [G loss: 0.531375]\n",
      "[Epoch 31/200] [Batch 105/637] [D loss: 0.156927] [G loss: 0.558085]\n",
      "[Epoch 31/200] [Batch 106/637] [D loss: 0.194791] [G loss: 0.460405]\n",
      "[Epoch 31/200] [Batch 107/637] [D loss: 0.169610] [G loss: 0.544852]\n",
      "[Epoch 31/200] [Batch 108/637] [D loss: 0.189833] [G loss: 0.475340]\n",
      "[Epoch 31/200] [Batch 109/637] [D loss: 0.192248] [G loss: 0.441622]\n",
      "[Epoch 31/200] [Batch 110/637] [D loss: 0.162242] [G loss: 0.494701]\n",
      "[Epoch 31/200] [Batch 111/637] [D loss: 0.177992] [G loss: 0.419447]\n",
      "[Epoch 31/200] [Batch 112/637] [D loss: 0.176229] [G loss: 0.484935]\n",
      "[Epoch 31/200] [Batch 113/637] [D loss: 0.159907] [G loss: 0.466154]\n",
      "[Epoch 31/200] [Batch 114/637] [D loss: 0.200355] [G loss: 0.445976]\n",
      "[Epoch 31/200] [Batch 115/637] [D loss: 0.158039] [G loss: 0.485247]\n",
      "[Epoch 31/200] [Batch 116/637] [D loss: 0.212401] [G loss: 0.469442]\n",
      "[Epoch 31/200] [Batch 117/637] [D loss: 0.167841] [G loss: 0.559937]\n",
      "[Epoch 31/200] [Batch 118/637] [D loss: 0.193373] [G loss: 0.479722]\n",
      "[Epoch 31/200] [Batch 119/637] [D loss: 0.155888] [G loss: 0.477711]\n",
      "[Epoch 31/200] [Batch 120/637] [D loss: 0.181260] [G loss: 0.465834]\n",
      "[Epoch 31/200] [Batch 121/637] [D loss: 0.187368] [G loss: 0.447542]\n",
      "[Epoch 31/200] [Batch 122/637] [D loss: 0.187504] [G loss: 0.428879]\n",
      "[Epoch 31/200] [Batch 123/637] [D loss: 0.164850] [G loss: 0.464148]\n",
      "[Epoch 31/200] [Batch 124/637] [D loss: 0.172642] [G loss: 0.509357]\n",
      "[Epoch 31/200] [Batch 125/637] [D loss: 0.167034] [G loss: 0.553552]\n",
      "[Epoch 31/200] [Batch 126/637] [D loss: 0.170190] [G loss: 0.466452]\n",
      "[Epoch 31/200] [Batch 127/637] [D loss: 0.175044] [G loss: 0.444555]\n",
      "[Epoch 31/200] [Batch 128/637] [D loss: 0.180231] [G loss: 0.443605]\n",
      "[Epoch 31/200] [Batch 129/637] [D loss: 0.168981] [G loss: 0.467916]\n",
      "[Epoch 31/200] [Batch 130/637] [D loss: 0.153198] [G loss: 0.490671]\n",
      "[Epoch 31/200] [Batch 131/637] [D loss: 0.171526] [G loss: 0.494885]\n",
      "[Epoch 31/200] [Batch 132/637] [D loss: 0.194368] [G loss: 0.507785]\n",
      "[Epoch 31/200] [Batch 133/637] [D loss: 0.176065] [G loss: 0.583864]\n",
      "[Epoch 31/200] [Batch 134/637] [D loss: 0.170725] [G loss: 0.534850]\n",
      "[Epoch 31/200] [Batch 135/637] [D loss: 0.158939] [G loss: 0.473912]\n",
      "[Epoch 31/200] [Batch 136/637] [D loss: 0.185040] [G loss: 0.405480]\n",
      "[Epoch 31/200] [Batch 137/637] [D loss: 0.168083] [G loss: 0.461780]\n",
      "[Epoch 31/200] [Batch 138/637] [D loss: 0.190084] [G loss: 0.519255]\n",
      "[Epoch 31/200] [Batch 139/637] [D loss: 0.205582] [G loss: 0.396878]\n",
      "[Epoch 31/200] [Batch 140/637] [D loss: 0.170370] [G loss: 0.486491]\n",
      "[Epoch 31/200] [Batch 141/637] [D loss: 0.190544] [G loss: 0.456230]\n",
      "[Epoch 31/200] [Batch 142/637] [D loss: 0.180900] [G loss: 0.434104]\n",
      "[Epoch 31/200] [Batch 143/637] [D loss: 0.174297] [G loss: 0.459656]\n",
      "[Epoch 31/200] [Batch 144/637] [D loss: 0.161252] [G loss: 0.454005]\n",
      "[Epoch 31/200] [Batch 145/637] [D loss: 0.170525] [G loss: 0.460004]\n",
      "[Epoch 31/200] [Batch 146/637] [D loss: 0.172098] [G loss: 0.456875]\n",
      "[Epoch 31/200] [Batch 147/637] [D loss: 0.164593] [G loss: 0.486594]\n",
      "[Epoch 31/200] [Batch 148/637] [D loss: 0.178835] [G loss: 0.484703]\n",
      "[Epoch 31/200] [Batch 149/637] [D loss: 0.175003] [G loss: 0.447779]\n",
      "[Epoch 31/200] [Batch 150/637] [D loss: 0.176516] [G loss: 0.518665]\n",
      "[Epoch 31/200] [Batch 151/637] [D loss: 0.172866] [G loss: 0.580499]\n",
      "[Epoch 31/200] [Batch 152/637] [D loss: 0.175998] [G loss: 0.499368]\n",
      "[Epoch 31/200] [Batch 153/637] [D loss: 0.218790] [G loss: 0.361558]\n",
      "[Epoch 31/200] [Batch 154/637] [D loss: 0.171534] [G loss: 0.433499]\n",
      "[Epoch 31/200] [Batch 155/637] [D loss: 0.173774] [G loss: 0.450928]\n",
      "[Epoch 31/200] [Batch 156/637] [D loss: 0.158448] [G loss: 0.500130]\n",
      "[Epoch 31/200] [Batch 157/637] [D loss: 0.165297] [G loss: 0.473358]\n",
      "[Epoch 31/200] [Batch 158/637] [D loss: 0.158884] [G loss: 0.479046]\n",
      "[Epoch 31/200] [Batch 159/637] [D loss: 0.190418] [G loss: 0.422771]\n",
      "[Epoch 31/200] [Batch 160/637] [D loss: 0.185442] [G loss: 0.483729]\n",
      "[Epoch 31/200] [Batch 161/637] [D loss: 0.187774] [G loss: 0.446592]\n",
      "[Epoch 31/200] [Batch 162/637] [D loss: 0.156718] [G loss: 0.527590]\n",
      "[Epoch 31/200] [Batch 163/637] [D loss: 0.157163] [G loss: 0.539317]\n",
      "[Epoch 31/200] [Batch 164/637] [D loss: 0.179040] [G loss: 0.449693]\n",
      "[Epoch 31/200] [Batch 165/637] [D loss: 0.157032] [G loss: 0.532386]\n",
      "[Epoch 31/200] [Batch 166/637] [D loss: 0.148174] [G loss: 0.503159]\n",
      "[Epoch 31/200] [Batch 167/637] [D loss: 0.185733] [G loss: 0.393153]\n",
      "[Epoch 31/200] [Batch 168/637] [D loss: 0.185453] [G loss: 0.494132]\n",
      "[Epoch 31/200] [Batch 169/637] [D loss: 0.196513] [G loss: 0.493467]\n",
      "[Epoch 31/200] [Batch 170/637] [D loss: 0.173086] [G loss: 0.510147]\n",
      "[Epoch 31/200] [Batch 171/637] [D loss: 0.189258] [G loss: 0.402998]\n",
      "[Epoch 31/200] [Batch 172/637] [D loss: 0.210205] [G loss: 0.440690]\n",
      "[Epoch 31/200] [Batch 173/637] [D loss: 0.175329] [G loss: 0.499865]\n",
      "[Epoch 31/200] [Batch 174/637] [D loss: 0.152009] [G loss: 0.534872]\n",
      "[Epoch 31/200] [Batch 175/637] [D loss: 0.162565] [G loss: 0.468839]\n",
      "[Epoch 31/200] [Batch 176/637] [D loss: 0.166859] [G loss: 0.485628]\n",
      "[Epoch 31/200] [Batch 177/637] [D loss: 0.162796] [G loss: 0.490558]\n",
      "[Epoch 31/200] [Batch 178/637] [D loss: 0.168832] [G loss: 0.429497]\n",
      "[Epoch 31/200] [Batch 179/637] [D loss: 0.154927] [G loss: 0.487144]\n",
      "[Epoch 31/200] [Batch 180/637] [D loss: 0.167297] [G loss: 0.474463]\n",
      "[Epoch 31/200] [Batch 181/637] [D loss: 0.152888] [G loss: 0.504673]\n",
      "[Epoch 31/200] [Batch 182/637] [D loss: 0.165676] [G loss: 0.529419]\n",
      "[Epoch 31/200] [Batch 183/637] [D loss: 0.169990] [G loss: 0.513050]\n",
      "[Epoch 31/200] [Batch 184/637] [D loss: 0.172436] [G loss: 0.475899]\n",
      "[Epoch 31/200] [Batch 185/637] [D loss: 0.158401] [G loss: 0.472491]\n",
      "[Epoch 31/200] [Batch 186/637] [D loss: 0.166093] [G loss: 0.581235]\n",
      "[Epoch 31/200] [Batch 187/637] [D loss: 0.177307] [G loss: 0.489477]\n",
      "[Epoch 31/200] [Batch 188/637] [D loss: 0.208194] [G loss: 0.512162]\n",
      "[Epoch 31/200] [Batch 189/637] [D loss: 0.183880] [G loss: 0.519331]\n",
      "[Epoch 31/200] [Batch 190/637] [D loss: 0.190590] [G loss: 0.477125]\n",
      "[Epoch 31/200] [Batch 191/637] [D loss: 0.171160] [G loss: 0.446476]\n",
      "[Epoch 31/200] [Batch 192/637] [D loss: 0.170071] [G loss: 0.469328]\n",
      "[Epoch 31/200] [Batch 193/637] [D loss: 0.207425] [G loss: 0.440924]\n",
      "[Epoch 31/200] [Batch 194/637] [D loss: 0.166423] [G loss: 0.488212]\n",
      "[Epoch 31/200] [Batch 195/637] [D loss: 0.194435] [G loss: 0.459204]\n",
      "[Epoch 31/200] [Batch 196/637] [D loss: 0.166172] [G loss: 0.512503]\n",
      "[Epoch 31/200] [Batch 197/637] [D loss: 0.170425] [G loss: 0.532320]\n",
      "[Epoch 31/200] [Batch 198/637] [D loss: 0.221053] [G loss: 0.466481]\n",
      "[Epoch 31/200] [Batch 199/637] [D loss: 0.212776] [G loss: 0.402914]\n",
      "[Epoch 31/200] [Batch 200/637] [D loss: 0.162202] [G loss: 0.478294]\n",
      "[Epoch 31/200] [Batch 201/637] [D loss: 0.200354] [G loss: 0.460723]\n",
      "[Epoch 31/200] [Batch 202/637] [D loss: 0.180192] [G loss: 0.507167]\n",
      "[Epoch 31/200] [Batch 203/637] [D loss: 0.168013] [G loss: 0.447680]\n",
      "[Epoch 31/200] [Batch 204/637] [D loss: 0.181103] [G loss: 0.432168]\n",
      "[Epoch 31/200] [Batch 205/637] [D loss: 0.182689] [G loss: 0.410166]\n",
      "[Epoch 31/200] [Batch 206/637] [D loss: 0.193511] [G loss: 0.456719]\n",
      "[Epoch 31/200] [Batch 207/637] [D loss: 0.172455] [G loss: 0.480800]\n",
      "[Epoch 31/200] [Batch 208/637] [D loss: 0.166264] [G loss: 0.503880]\n",
      "[Epoch 31/200] [Batch 209/637] [D loss: 0.201961] [G loss: 0.443880]\n",
      "[Epoch 31/200] [Batch 210/637] [D loss: 0.205156] [G loss: 0.454978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/200] [Batch 211/637] [D loss: 0.186583] [G loss: 0.481917]\n",
      "[Epoch 31/200] [Batch 212/637] [D loss: 0.158920] [G loss: 0.499781]\n",
      "[Epoch 31/200] [Batch 213/637] [D loss: 0.165792] [G loss: 0.484617]\n",
      "[Epoch 31/200] [Batch 214/637] [D loss: 0.192935] [G loss: 0.467016]\n",
      "[Epoch 31/200] [Batch 215/637] [D loss: 0.174780] [G loss: 0.432844]\n",
      "[Epoch 31/200] [Batch 216/637] [D loss: 0.164528] [G loss: 0.518364]\n",
      "[Epoch 31/200] [Batch 217/637] [D loss: 0.159851] [G loss: 0.492554]\n",
      "[Epoch 31/200] [Batch 218/637] [D loss: 0.164790] [G loss: 0.531775]\n",
      "[Epoch 31/200] [Batch 219/637] [D loss: 0.132106] [G loss: 0.548014]\n",
      "[Epoch 31/200] [Batch 220/637] [D loss: 0.190999] [G loss: 0.386366]\n",
      "[Epoch 31/200] [Batch 221/637] [D loss: 0.190934] [G loss: 0.511557]\n",
      "[Epoch 31/200] [Batch 222/637] [D loss: 0.176851] [G loss: 0.509237]\n",
      "[Epoch 31/200] [Batch 223/637] [D loss: 0.171639] [G loss: 0.530251]\n",
      "[Epoch 31/200] [Batch 224/637] [D loss: 0.160123] [G loss: 0.495375]\n",
      "[Epoch 31/200] [Batch 225/637] [D loss: 0.171041] [G loss: 0.453810]\n",
      "[Epoch 31/200] [Batch 226/637] [D loss: 0.177162] [G loss: 0.446338]\n",
      "[Epoch 31/200] [Batch 227/637] [D loss: 0.189371] [G loss: 0.409388]\n",
      "[Epoch 31/200] [Batch 228/637] [D loss: 0.173830] [G loss: 0.508105]\n",
      "[Epoch 31/200] [Batch 229/637] [D loss: 0.175932] [G loss: 0.509091]\n",
      "[Epoch 31/200] [Batch 230/637] [D loss: 0.176315] [G loss: 0.447409]\n",
      "[Epoch 31/200] [Batch 231/637] [D loss: 0.169032] [G loss: 0.436404]\n",
      "[Epoch 31/200] [Batch 232/637] [D loss: 0.176523] [G loss: 0.446969]\n",
      "[Epoch 31/200] [Batch 233/637] [D loss: 0.187658] [G loss: 0.467001]\n",
      "[Epoch 31/200] [Batch 234/637] [D loss: 0.149824] [G loss: 0.457240]\n",
      "[Epoch 31/200] [Batch 235/637] [D loss: 0.161122] [G loss: 0.480923]\n",
      "[Epoch 31/200] [Batch 236/637] [D loss: 0.172136] [G loss: 0.448899]\n",
      "[Epoch 31/200] [Batch 237/637] [D loss: 0.168287] [G loss: 0.495085]\n",
      "[Epoch 31/200] [Batch 238/637] [D loss: 0.160539] [G loss: 0.515401]\n",
      "[Epoch 31/200] [Batch 239/637] [D loss: 0.172174] [G loss: 0.461065]\n",
      "[Epoch 31/200] [Batch 240/637] [D loss: 0.188272] [G loss: 0.425492]\n",
      "[Epoch 31/200] [Batch 241/637] [D loss: 0.206080] [G loss: 0.542913]\n",
      "[Epoch 31/200] [Batch 242/637] [D loss: 0.163227] [G loss: 0.524607]\n",
      "[Epoch 31/200] [Batch 243/637] [D loss: 0.194671] [G loss: 0.501027]\n",
      "[Epoch 31/200] [Batch 244/637] [D loss: 0.173004] [G loss: 0.458109]\n",
      "[Epoch 31/200] [Batch 245/637] [D loss: 0.175429] [G loss: 0.473079]\n",
      "[Epoch 31/200] [Batch 246/637] [D loss: 0.171847] [G loss: 0.482940]\n",
      "[Epoch 31/200] [Batch 247/637] [D loss: 0.165144] [G loss: 0.456810]\n",
      "[Epoch 31/200] [Batch 248/637] [D loss: 0.185387] [G loss: 0.471077]\n",
      "[Epoch 31/200] [Batch 249/637] [D loss: 0.161093] [G loss: 0.437391]\n",
      "[Epoch 31/200] [Batch 250/637] [D loss: 0.169660] [G loss: 0.493627]\n",
      "[Epoch 31/200] [Batch 251/637] [D loss: 0.203794] [G loss: 0.452209]\n",
      "[Epoch 31/200] [Batch 252/637] [D loss: 0.195553] [G loss: 0.438509]\n",
      "[Epoch 31/200] [Batch 253/637] [D loss: 0.176579] [G loss: 0.496379]\n",
      "[Epoch 31/200] [Batch 254/637] [D loss: 0.185350] [G loss: 0.524788]\n",
      "[Epoch 31/200] [Batch 255/637] [D loss: 0.174313] [G loss: 0.489230]\n",
      "[Epoch 31/200] [Batch 256/637] [D loss: 0.178014] [G loss: 0.437340]\n",
      "[Epoch 31/200] [Batch 257/637] [D loss: 0.174652] [G loss: 0.498998]\n",
      "[Epoch 31/200] [Batch 258/637] [D loss: 0.186489] [G loss: 0.488153]\n",
      "[Epoch 31/200] [Batch 259/637] [D loss: 0.161404] [G loss: 0.458247]\n",
      "[Epoch 31/200] [Batch 260/637] [D loss: 0.141752] [G loss: 0.562328]\n",
      "[Epoch 31/200] [Batch 261/637] [D loss: 0.172627] [G loss: 0.458051]\n",
      "[Epoch 31/200] [Batch 262/637] [D loss: 0.173924] [G loss: 0.509070]\n",
      "[Epoch 31/200] [Batch 263/637] [D loss: 0.186810] [G loss: 0.469703]\n",
      "[Epoch 31/200] [Batch 264/637] [D loss: 0.167235] [G loss: 0.526054]\n",
      "[Epoch 31/200] [Batch 265/637] [D loss: 0.156113] [G loss: 0.454390]\n",
      "[Epoch 31/200] [Batch 266/637] [D loss: 0.177558] [G loss: 0.486980]\n",
      "[Epoch 31/200] [Batch 267/637] [D loss: 0.167625] [G loss: 0.525978]\n",
      "[Epoch 31/200] [Batch 268/637] [D loss: 0.172532] [G loss: 0.502436]\n",
      "[Epoch 31/200] [Batch 269/637] [D loss: 0.180450] [G loss: 0.437690]\n",
      "[Epoch 31/200] [Batch 270/637] [D loss: 0.166097] [G loss: 0.512680]\n",
      "[Epoch 31/200] [Batch 271/637] [D loss: 0.194405] [G loss: 0.472629]\n",
      "[Epoch 31/200] [Batch 272/637] [D loss: 0.176901] [G loss: 0.542107]\n",
      "[Epoch 31/200] [Batch 273/637] [D loss: 0.170400] [G loss: 0.444064]\n",
      "[Epoch 31/200] [Batch 274/637] [D loss: 0.173576] [G loss: 0.481054]\n",
      "[Epoch 31/200] [Batch 275/637] [D loss: 0.173601] [G loss: 0.464276]\n",
      "[Epoch 31/200] [Batch 276/637] [D loss: 0.198214] [G loss: 0.504680]\n",
      "[Epoch 31/200] [Batch 277/637] [D loss: 0.151744] [G loss: 0.543119]\n",
      "[Epoch 31/200] [Batch 278/637] [D loss: 0.260589] [G loss: 0.464525]\n",
      "[Epoch 31/200] [Batch 279/637] [D loss: 0.180808] [G loss: 0.570985]\n",
      "[Epoch 31/200] [Batch 280/637] [D loss: 0.175609] [G loss: 0.570179]\n",
      "[Epoch 31/200] [Batch 281/637] [D loss: 0.182668] [G loss: 0.483620]\n",
      "[Epoch 31/200] [Batch 282/637] [D loss: 0.155558] [G loss: 0.487380]\n",
      "[Epoch 31/200] [Batch 283/637] [D loss: 0.170223] [G loss: 0.498457]\n",
      "[Epoch 31/200] [Batch 284/637] [D loss: 0.194210] [G loss: 0.427227]\n",
      "[Epoch 31/200] [Batch 285/637] [D loss: 0.150935] [G loss: 0.505121]\n",
      "[Epoch 31/200] [Batch 286/637] [D loss: 0.176158] [G loss: 0.470495]\n",
      "[Epoch 31/200] [Batch 287/637] [D loss: 0.142918] [G loss: 0.501322]\n",
      "[Epoch 31/200] [Batch 288/637] [D loss: 0.182191] [G loss: 0.430032]\n",
      "[Epoch 31/200] [Batch 289/637] [D loss: 0.166013] [G loss: 0.541149]\n",
      "[Epoch 31/200] [Batch 290/637] [D loss: 0.182244] [G loss: 0.598901]\n",
      "[Epoch 31/200] [Batch 291/637] [D loss: 0.170000] [G loss: 0.505201]\n",
      "[Epoch 31/200] [Batch 292/637] [D loss: 0.165686] [G loss: 0.440443]\n",
      "[Epoch 31/200] [Batch 293/637] [D loss: 0.185896] [G loss: 0.423633]\n",
      "[Epoch 31/200] [Batch 294/637] [D loss: 0.160666] [G loss: 0.473833]\n",
      "[Epoch 31/200] [Batch 295/637] [D loss: 0.161707] [G loss: 0.471539]\n",
      "[Epoch 31/200] [Batch 296/637] [D loss: 0.166773] [G loss: 0.494932]\n",
      "[Epoch 31/200] [Batch 297/637] [D loss: 0.195233] [G loss: 0.443926]\n",
      "[Epoch 31/200] [Batch 298/637] [D loss: 0.187169] [G loss: 0.473807]\n",
      "[Epoch 31/200] [Batch 299/637] [D loss: 0.195557] [G loss: 0.433224]\n",
      "[Epoch 31/200] [Batch 300/637] [D loss: 0.164932] [G loss: 0.505278]\n",
      "[Epoch 31/200] [Batch 301/637] [D loss: 0.187775] [G loss: 0.457398]\n",
      "[Epoch 31/200] [Batch 302/637] [D loss: 0.187497] [G loss: 0.411459]\n",
      "[Epoch 31/200] [Batch 303/637] [D loss: 0.169647] [G loss: 0.455511]\n",
      "[Epoch 31/200] [Batch 304/637] [D loss: 0.183777] [G loss: 0.454259]\n",
      "[Epoch 31/200] [Batch 305/637] [D loss: 0.152516] [G loss: 0.575348]\n",
      "[Epoch 31/200] [Batch 306/637] [D loss: 0.185329] [G loss: 0.388028]\n",
      "[Epoch 31/200] [Batch 307/637] [D loss: 0.172701] [G loss: 0.506386]\n",
      "[Epoch 31/200] [Batch 308/637] [D loss: 0.161301] [G loss: 0.525122]\n",
      "[Epoch 31/200] [Batch 309/637] [D loss: 0.159341] [G loss: 0.529361]\n",
      "[Epoch 31/200] [Batch 310/637] [D loss: 0.153975] [G loss: 0.588365]\n",
      "[Epoch 31/200] [Batch 311/637] [D loss: 0.209531] [G loss: 0.417225]\n",
      "[Epoch 31/200] [Batch 312/637] [D loss: 0.163306] [G loss: 0.522389]\n",
      "[Epoch 31/200] [Batch 313/637] [D loss: 0.190203] [G loss: 0.467256]\n",
      "[Epoch 31/200] [Batch 314/637] [D loss: 0.168154] [G loss: 0.499011]\n",
      "[Epoch 31/200] [Batch 315/637] [D loss: 0.186625] [G loss: 0.411009]\n",
      "[Epoch 31/200] [Batch 316/637] [D loss: 0.158550] [G loss: 0.442103]\n",
      "[Epoch 31/200] [Batch 317/637] [D loss: 0.202868] [G loss: 0.447748]\n",
      "[Epoch 31/200] [Batch 318/637] [D loss: 0.175654] [G loss: 0.481281]\n",
      "[Epoch 31/200] [Batch 319/637] [D loss: 0.176795] [G loss: 0.494707]\n",
      "[Epoch 31/200] [Batch 320/637] [D loss: 0.163409] [G loss: 0.515611]\n",
      "[Epoch 31/200] [Batch 321/637] [D loss: 0.160310] [G loss: 0.465796]\n",
      "[Epoch 31/200] [Batch 322/637] [D loss: 0.171985] [G loss: 0.457019]\n",
      "[Epoch 31/200] [Batch 323/637] [D loss: 0.146971] [G loss: 0.478695]\n",
      "[Epoch 31/200] [Batch 324/637] [D loss: 0.153639] [G loss: 0.496155]\n",
      "[Epoch 31/200] [Batch 325/637] [D loss: 0.194357] [G loss: 0.493451]\n",
      "[Epoch 31/200] [Batch 326/637] [D loss: 0.163087] [G loss: 0.510829]\n",
      "[Epoch 31/200] [Batch 327/637] [D loss: 0.183488] [G loss: 0.453373]\n",
      "[Epoch 31/200] [Batch 328/637] [D loss: 0.188722] [G loss: 0.494387]\n",
      "[Epoch 31/200] [Batch 329/637] [D loss: 0.162080] [G loss: 0.452256]\n",
      "[Epoch 31/200] [Batch 330/637] [D loss: 0.178745] [G loss: 0.470468]\n",
      "[Epoch 31/200] [Batch 331/637] [D loss: 0.153741] [G loss: 0.573488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/200] [Batch 332/637] [D loss: 0.164475] [G loss: 0.509135]\n",
      "[Epoch 31/200] [Batch 333/637] [D loss: 0.181801] [G loss: 0.487659]\n",
      "[Epoch 31/200] [Batch 334/637] [D loss: 0.250378] [G loss: 0.483015]\n",
      "[Epoch 31/200] [Batch 335/637] [D loss: 0.190870] [G loss: 0.479134]\n",
      "[Epoch 31/200] [Batch 336/637] [D loss: 0.185742] [G loss: 0.444931]\n",
      "[Epoch 31/200] [Batch 337/637] [D loss: 0.199587] [G loss: 0.399097]\n",
      "[Epoch 31/200] [Batch 338/637] [D loss: 0.168320] [G loss: 0.460795]\n",
      "[Epoch 31/200] [Batch 339/637] [D loss: 0.179210] [G loss: 0.443192]\n",
      "[Epoch 31/200] [Batch 340/637] [D loss: 0.174450] [G loss: 0.485951]\n",
      "[Epoch 31/200] [Batch 341/637] [D loss: 0.163652] [G loss: 0.569805]\n",
      "[Epoch 31/200] [Batch 342/637] [D loss: 0.179596] [G loss: 0.496803]\n",
      "[Epoch 31/200] [Batch 343/637] [D loss: 0.168339] [G loss: 0.504977]\n",
      "[Epoch 31/200] [Batch 344/637] [D loss: 0.177027] [G loss: 0.492680]\n",
      "[Epoch 31/200] [Batch 345/637] [D loss: 0.158882] [G loss: 0.476837]\n",
      "[Epoch 31/200] [Batch 346/637] [D loss: 0.172692] [G loss: 0.417492]\n",
      "[Epoch 31/200] [Batch 347/637] [D loss: 0.179852] [G loss: 0.444447]\n",
      "[Epoch 31/200] [Batch 348/637] [D loss: 0.174766] [G loss: 0.452350]\n",
      "[Epoch 31/200] [Batch 349/637] [D loss: 0.174173] [G loss: 0.514490]\n",
      "[Epoch 31/200] [Batch 350/637] [D loss: 0.194258] [G loss: 0.448553]\n",
      "[Epoch 31/200] [Batch 351/637] [D loss: 0.165049] [G loss: 0.455381]\n",
      "[Epoch 31/200] [Batch 352/637] [D loss: 0.169580] [G loss: 0.536955]\n",
      "[Epoch 31/200] [Batch 353/637] [D loss: 0.156342] [G loss: 0.581638]\n",
      "[Epoch 31/200] [Batch 354/637] [D loss: 0.212028] [G loss: 0.448310]\n",
      "[Epoch 31/200] [Batch 355/637] [D loss: 0.162799] [G loss: 0.477879]\n",
      "[Epoch 31/200] [Batch 356/637] [D loss: 0.156225] [G loss: 0.484776]\n",
      "[Epoch 31/200] [Batch 357/637] [D loss: 0.182178] [G loss: 0.411240]\n",
      "[Epoch 31/200] [Batch 358/637] [D loss: 0.169678] [G loss: 0.512303]\n",
      "[Epoch 31/200] [Batch 359/637] [D loss: 0.146339] [G loss: 0.514478]\n",
      "[Epoch 31/200] [Batch 360/637] [D loss: 0.173996] [G loss: 0.454203]\n",
      "[Epoch 31/200] [Batch 361/637] [D loss: 0.184562] [G loss: 0.447438]\n",
      "[Epoch 31/200] [Batch 362/637] [D loss: 0.181629] [G loss: 0.504529]\n",
      "[Epoch 31/200] [Batch 363/637] [D loss: 0.177016] [G loss: 0.441599]\n",
      "[Epoch 31/200] [Batch 364/637] [D loss: 0.178027] [G loss: 0.455335]\n",
      "[Epoch 31/200] [Batch 365/637] [D loss: 0.155627] [G loss: 0.507089]\n",
      "[Epoch 31/200] [Batch 366/637] [D loss: 0.159799] [G loss: 0.489692]\n",
      "[Epoch 31/200] [Batch 367/637] [D loss: 0.173470] [G loss: 0.511078]\n",
      "[Epoch 31/200] [Batch 368/637] [D loss: 0.151252] [G loss: 0.485215]\n",
      "[Epoch 31/200] [Batch 369/637] [D loss: 0.151752] [G loss: 0.473413]\n",
      "[Epoch 31/200] [Batch 370/637] [D loss: 0.157703] [G loss: 0.476967]\n",
      "[Epoch 31/200] [Batch 371/637] [D loss: 0.167549] [G loss: 0.495640]\n",
      "[Epoch 31/200] [Batch 372/637] [D loss: 0.157411] [G loss: 0.504225]\n",
      "[Epoch 31/200] [Batch 373/637] [D loss: 0.148516] [G loss: 0.487603]\n",
      "[Epoch 31/200] [Batch 374/637] [D loss: 0.144681] [G loss: 0.522234]\n",
      "[Epoch 31/200] [Batch 375/637] [D loss: 0.188228] [G loss: 0.520249]\n",
      "[Epoch 31/200] [Batch 376/637] [D loss: 0.143552] [G loss: 0.510173]\n",
      "[Epoch 31/200] [Batch 377/637] [D loss: 0.156372] [G loss: 0.510713]\n",
      "[Epoch 31/200] [Batch 378/637] [D loss: 0.150838] [G loss: 0.481611]\n",
      "[Epoch 31/200] [Batch 379/637] [D loss: 0.150335] [G loss: 0.504716]\n",
      "[Epoch 31/200] [Batch 380/637] [D loss: 0.168715] [G loss: 0.489921]\n",
      "[Epoch 31/200] [Batch 381/637] [D loss: 0.138407] [G loss: 0.555667]\n",
      "[Epoch 31/200] [Batch 382/637] [D loss: 0.162906] [G loss: 0.521876]\n",
      "[Epoch 31/200] [Batch 383/637] [D loss: 0.173526] [G loss: 0.449045]\n",
      "[Epoch 31/200] [Batch 384/637] [D loss: 0.167516] [G loss: 0.597208]\n",
      "[Epoch 31/200] [Batch 385/637] [D loss: 0.196469] [G loss: 0.611616]\n",
      "[Epoch 31/200] [Batch 386/637] [D loss: 0.210808] [G loss: 0.491492]\n",
      "[Epoch 31/200] [Batch 387/637] [D loss: 0.159541] [G loss: 0.568738]\n",
      "[Epoch 31/200] [Batch 388/637] [D loss: 0.185162] [G loss: 0.420797]\n",
      "[Epoch 31/200] [Batch 389/637] [D loss: 0.186496] [G loss: 0.455409]\n",
      "[Epoch 31/200] [Batch 390/637] [D loss: 0.164385] [G loss: 0.523942]\n",
      "[Epoch 31/200] [Batch 391/637] [D loss: 0.159931] [G loss: 0.489413]\n",
      "[Epoch 31/200] [Batch 392/637] [D loss: 0.173034] [G loss: 0.558209]\n",
      "[Epoch 31/200] [Batch 393/637] [D loss: 0.171443] [G loss: 0.471614]\n",
      "[Epoch 31/200] [Batch 394/637] [D loss: 0.164856] [G loss: 0.537139]\n",
      "[Epoch 31/200] [Batch 395/637] [D loss: 0.160882] [G loss: 0.524856]\n",
      "[Epoch 31/200] [Batch 396/637] [D loss: 0.173461] [G loss: 0.455422]\n",
      "[Epoch 31/200] [Batch 397/637] [D loss: 0.178276] [G loss: 0.434246]\n",
      "[Epoch 31/200] [Batch 398/637] [D loss: 0.178258] [G loss: 0.431477]\n",
      "[Epoch 31/200] [Batch 399/637] [D loss: 0.158896] [G loss: 0.487312]\n",
      "[Epoch 31/200] [Batch 400/637] [D loss: 0.147042] [G loss: 0.482447]\n",
      "[Epoch 31/200] [Batch 401/637] [D loss: 0.164322] [G loss: 0.450517]\n",
      "[Epoch 31/200] [Batch 402/637] [D loss: 0.171265] [G loss: 0.458408]\n",
      "[Epoch 31/200] [Batch 403/637] [D loss: 0.174524] [G loss: 0.520879]\n",
      "[Epoch 31/200] [Batch 404/637] [D loss: 0.161310] [G loss: 0.515719]\n",
      "[Epoch 31/200] [Batch 405/637] [D loss: 0.173210] [G loss: 0.506899]\n",
      "[Epoch 31/200] [Batch 406/637] [D loss: 0.197535] [G loss: 0.468490]\n",
      "[Epoch 31/200] [Batch 407/637] [D loss: 0.169040] [G loss: 0.507810]\n",
      "[Epoch 31/200] [Batch 408/637] [D loss: 0.159617] [G loss: 0.561037]\n",
      "[Epoch 31/200] [Batch 409/637] [D loss: 0.167633] [G loss: 0.524047]\n",
      "[Epoch 31/200] [Batch 410/637] [D loss: 0.168653] [G loss: 0.516822]\n",
      "[Epoch 31/200] [Batch 411/637] [D loss: 0.186169] [G loss: 0.547088]\n",
      "[Epoch 31/200] [Batch 412/637] [D loss: 0.171699] [G loss: 0.447221]\n",
      "[Epoch 31/200] [Batch 413/637] [D loss: 0.158091] [G loss: 0.500555]\n",
      "[Epoch 31/200] [Batch 414/637] [D loss: 0.170031] [G loss: 0.485957]\n",
      "[Epoch 31/200] [Batch 415/637] [D loss: 0.173000] [G loss: 0.470011]\n",
      "[Epoch 31/200] [Batch 416/637] [D loss: 0.189395] [G loss: 0.407035]\n",
      "[Epoch 31/200] [Batch 417/637] [D loss: 0.174713] [G loss: 0.456473]\n",
      "[Epoch 31/200] [Batch 418/637] [D loss: 0.173486] [G loss: 0.533976]\n",
      "[Epoch 31/200] [Batch 419/637] [D loss: 0.173939] [G loss: 0.439924]\n",
      "[Epoch 31/200] [Batch 420/637] [D loss: 0.160805] [G loss: 0.490936]\n",
      "[Epoch 31/200] [Batch 421/637] [D loss: 0.161684] [G loss: 0.559887]\n",
      "[Epoch 31/200] [Batch 422/637] [D loss: 0.195686] [G loss: 0.448610]\n",
      "[Epoch 31/200] [Batch 423/637] [D loss: 0.168040] [G loss: 0.535631]\n",
      "[Epoch 31/200] [Batch 424/637] [D loss: 0.201262] [G loss: 0.515987]\n",
      "[Epoch 31/200] [Batch 425/637] [D loss: 0.181351] [G loss: 0.477009]\n",
      "[Epoch 31/200] [Batch 426/637] [D loss: 0.182280] [G loss: 0.461487]\n",
      "[Epoch 31/200] [Batch 427/637] [D loss: 0.169595] [G loss: 0.476077]\n",
      "[Epoch 31/200] [Batch 428/637] [D loss: 0.169315] [G loss: 0.512310]\n",
      "[Epoch 31/200] [Batch 429/637] [D loss: 0.165155] [G loss: 0.481436]\n",
      "[Epoch 31/200] [Batch 430/637] [D loss: 0.172337] [G loss: 0.516504]\n",
      "[Epoch 31/200] [Batch 431/637] [D loss: 0.170351] [G loss: 0.451277]\n",
      "[Epoch 31/200] [Batch 432/637] [D loss: 0.161485] [G loss: 0.476827]\n",
      "[Epoch 31/200] [Batch 433/637] [D loss: 0.169576] [G loss: 0.475116]\n",
      "[Epoch 31/200] [Batch 434/637] [D loss: 0.170781] [G loss: 0.495256]\n",
      "[Epoch 31/200] [Batch 435/637] [D loss: 0.174419] [G loss: 0.429544]\n",
      "[Epoch 31/200] [Batch 436/637] [D loss: 0.198488] [G loss: 0.441676]\n",
      "[Epoch 31/200] [Batch 437/637] [D loss: 0.177087] [G loss: 0.464753]\n",
      "[Epoch 31/200] [Batch 438/637] [D loss: 0.156350] [G loss: 0.585497]\n",
      "[Epoch 31/200] [Batch 439/637] [D loss: 0.192844] [G loss: 0.459310]\n",
      "[Epoch 31/200] [Batch 440/637] [D loss: 0.165111] [G loss: 0.513603]\n",
      "[Epoch 31/200] [Batch 441/637] [D loss: 0.180145] [G loss: 0.450196]\n",
      "[Epoch 31/200] [Batch 442/637] [D loss: 0.165728] [G loss: 0.432092]\n",
      "[Epoch 31/200] [Batch 443/637] [D loss: 0.168499] [G loss: 0.501824]\n",
      "[Epoch 31/200] [Batch 444/637] [D loss: 0.198056] [G loss: 0.453400]\n",
      "[Epoch 31/200] [Batch 445/637] [D loss: 0.172888] [G loss: 0.577046]\n",
      "[Epoch 31/200] [Batch 446/637] [D loss: 0.197336] [G loss: 0.491108]\n",
      "[Epoch 31/200] [Batch 447/637] [D loss: 0.182196] [G loss: 0.478401]\n",
      "[Epoch 31/200] [Batch 448/637] [D loss: 0.161186] [G loss: 0.497195]\n",
      "[Epoch 31/200] [Batch 449/637] [D loss: 0.159050] [G loss: 0.478288]\n",
      "[Epoch 31/200] [Batch 450/637] [D loss: 0.155259] [G loss: 0.534225]\n",
      "[Epoch 31/200] [Batch 451/637] [D loss: 0.149833] [G loss: 0.485990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/200] [Batch 452/637] [D loss: 0.187661] [G loss: 0.457358]\n",
      "[Epoch 31/200] [Batch 453/637] [D loss: 0.157562] [G loss: 0.638441]\n",
      "[Epoch 31/200] [Batch 454/637] [D loss: 0.188571] [G loss: 0.499826]\n",
      "[Epoch 31/200] [Batch 455/637] [D loss: 0.163329] [G loss: 0.461656]\n",
      "[Epoch 31/200] [Batch 456/637] [D loss: 0.153704] [G loss: 0.438569]\n",
      "[Epoch 31/200] [Batch 457/637] [D loss: 0.172011] [G loss: 0.467222]\n",
      "[Epoch 31/200] [Batch 458/637] [D loss: 0.179169] [G loss: 0.497262]\n",
      "[Epoch 31/200] [Batch 459/637] [D loss: 0.180930] [G loss: 0.466771]\n",
      "[Epoch 31/200] [Batch 460/637] [D loss: 0.165179] [G loss: 0.520949]\n",
      "[Epoch 31/200] [Batch 461/637] [D loss: 0.172827] [G loss: 0.488119]\n",
      "[Epoch 31/200] [Batch 462/637] [D loss: 0.176194] [G loss: 0.526625]\n",
      "[Epoch 31/200] [Batch 463/637] [D loss: 0.176911] [G loss: 0.505271]\n",
      "[Epoch 31/200] [Batch 464/637] [D loss: 0.184383] [G loss: 0.470290]\n",
      "[Epoch 31/200] [Batch 465/637] [D loss: 0.198469] [G loss: 0.484792]\n",
      "[Epoch 31/200] [Batch 466/637] [D loss: 0.173061] [G loss: 0.473128]\n",
      "[Epoch 31/200] [Batch 467/637] [D loss: 0.169992] [G loss: 0.558705]\n",
      "[Epoch 31/200] [Batch 468/637] [D loss: 0.151970] [G loss: 0.570295]\n",
      "[Epoch 31/200] [Batch 469/637] [D loss: 0.192907] [G loss: 0.400865]\n",
      "[Epoch 31/200] [Batch 470/637] [D loss: 0.172037] [G loss: 0.473511]\n",
      "[Epoch 31/200] [Batch 471/637] [D loss: 0.159656] [G loss: 0.545097]\n",
      "[Epoch 31/200] [Batch 472/637] [D loss: 0.160528] [G loss: 0.535527]\n",
      "[Epoch 31/200] [Batch 473/637] [D loss: 0.172253] [G loss: 0.463180]\n",
      "[Epoch 31/200] [Batch 474/637] [D loss: 0.149453] [G loss: 0.590988]\n",
      "[Epoch 31/200] [Batch 475/637] [D loss: 0.172810] [G loss: 0.467215]\n",
      "[Epoch 31/200] [Batch 476/637] [D loss: 0.159506] [G loss: 0.451247]\n",
      "[Epoch 31/200] [Batch 477/637] [D loss: 0.183162] [G loss: 0.454988]\n",
      "[Epoch 31/200] [Batch 478/637] [D loss: 0.196901] [G loss: 0.619496]\n",
      "[Epoch 31/200] [Batch 479/637] [D loss: 0.177744] [G loss: 0.419502]\n",
      "[Epoch 31/200] [Batch 480/637] [D loss: 0.160032] [G loss: 0.476389]\n",
      "[Epoch 31/200] [Batch 481/637] [D loss: 0.177025] [G loss: 0.467681]\n",
      "[Epoch 31/200] [Batch 482/637] [D loss: 0.178280] [G loss: 0.471405]\n",
      "[Epoch 31/200] [Batch 483/637] [D loss: 0.174465] [G loss: 0.456357]\n",
      "[Epoch 31/200] [Batch 484/637] [D loss: 0.155447] [G loss: 0.506126]\n",
      "[Epoch 31/200] [Batch 485/637] [D loss: 0.161588] [G loss: 0.500043]\n",
      "[Epoch 31/200] [Batch 486/637] [D loss: 0.156501] [G loss: 0.447381]\n",
      "[Epoch 31/200] [Batch 487/637] [D loss: 0.166177] [G loss: 0.440894]\n",
      "[Epoch 31/200] [Batch 488/637] [D loss: 0.172735] [G loss: 0.464889]\n",
      "[Epoch 31/200] [Batch 489/637] [D loss: 0.177965] [G loss: 0.404991]\n",
      "[Epoch 31/200] [Batch 490/637] [D loss: 0.211465] [G loss: 0.412954]\n",
      "[Epoch 31/200] [Batch 491/637] [D loss: 0.215298] [G loss: 0.415083]\n",
      "[Epoch 31/200] [Batch 492/637] [D loss: 0.211228] [G loss: 0.605485]\n",
      "[Epoch 31/200] [Batch 493/637] [D loss: 0.210639] [G loss: 0.514102]\n",
      "[Epoch 31/200] [Batch 494/637] [D loss: 0.178209] [G loss: 0.413360]\n",
      "[Epoch 31/200] [Batch 495/637] [D loss: 0.175720] [G loss: 0.356297]\n",
      "[Epoch 31/200] [Batch 496/637] [D loss: 0.205664] [G loss: 0.368256]\n",
      "[Epoch 31/200] [Batch 497/637] [D loss: 0.192868] [G loss: 0.456199]\n",
      "[Epoch 31/200] [Batch 498/637] [D loss: 0.176422] [G loss: 0.485077]\n",
      "[Epoch 31/200] [Batch 499/637] [D loss: 0.197586] [G loss: 0.416712]\n",
      "[Epoch 31/200] [Batch 500/637] [D loss: 0.178262] [G loss: 0.489626]\n",
      "[Epoch 31/200] [Batch 501/637] [D loss: 0.166767] [G loss: 0.426027]\n",
      "[Epoch 31/200] [Batch 502/637] [D loss: 0.180095] [G loss: 0.580538]\n",
      "[Epoch 31/200] [Batch 503/637] [D loss: 0.193274] [G loss: 0.467518]\n",
      "[Epoch 31/200] [Batch 504/637] [D loss: 0.175695] [G loss: 0.445008]\n",
      "[Epoch 31/200] [Batch 505/637] [D loss: 0.185183] [G loss: 0.372015]\n",
      "[Epoch 31/200] [Batch 506/637] [D loss: 0.189559] [G loss: 0.406836]\n",
      "[Epoch 31/200] [Batch 507/637] [D loss: 0.194119] [G loss: 0.546555]\n",
      "[Epoch 31/200] [Batch 508/637] [D loss: 0.193490] [G loss: 0.522244]\n",
      "[Epoch 31/200] [Batch 509/637] [D loss: 0.160207] [G loss: 0.488599]\n",
      "[Epoch 31/200] [Batch 510/637] [D loss: 0.173285] [G loss: 0.427363]\n",
      "[Epoch 31/200] [Batch 511/637] [D loss: 0.173875] [G loss: 0.470316]\n",
      "[Epoch 31/200] [Batch 512/637] [D loss: 0.168488] [G loss: 0.469418]\n",
      "[Epoch 31/200] [Batch 513/637] [D loss: 0.182153] [G loss: 0.464922]\n",
      "[Epoch 31/200] [Batch 514/637] [D loss: 0.145822] [G loss: 0.496592]\n",
      "[Epoch 31/200] [Batch 515/637] [D loss: 0.157051] [G loss: 0.478968]\n",
      "[Epoch 31/200] [Batch 516/637] [D loss: 0.161274] [G loss: 0.452749]\n",
      "[Epoch 31/200] [Batch 517/637] [D loss: 0.167021] [G loss: 0.481344]\n",
      "[Epoch 31/200] [Batch 518/637] [D loss: 0.182164] [G loss: 0.519381]\n",
      "[Epoch 31/200] [Batch 519/637] [D loss: 0.190201] [G loss: 0.470201]\n",
      "[Epoch 31/200] [Batch 520/637] [D loss: 0.197485] [G loss: 0.394670]\n",
      "[Epoch 31/200] [Batch 521/637] [D loss: 0.163639] [G loss: 0.528535]\n",
      "[Epoch 31/200] [Batch 522/637] [D loss: 0.191960] [G loss: 0.479402]\n",
      "[Epoch 31/200] [Batch 523/637] [D loss: 0.196934] [G loss: 0.468776]\n",
      "[Epoch 31/200] [Batch 524/637] [D loss: 0.186972] [G loss: 0.474712]\n",
      "[Epoch 31/200] [Batch 525/637] [D loss: 0.178181] [G loss: 0.449746]\n",
      "[Epoch 31/200] [Batch 526/637] [D loss: 0.174998] [G loss: 0.516246]\n",
      "[Epoch 31/200] [Batch 527/637] [D loss: 0.163545] [G loss: 0.568601]\n",
      "[Epoch 31/200] [Batch 528/637] [D loss: 0.181834] [G loss: 0.390636]\n",
      "[Epoch 31/200] [Batch 529/637] [D loss: 0.154530] [G loss: 0.507026]\n",
      "[Epoch 31/200] [Batch 530/637] [D loss: 0.176879] [G loss: 0.520584]\n",
      "[Epoch 31/200] [Batch 531/637] [D loss: 0.196265] [G loss: 0.506273]\n",
      "[Epoch 31/200] [Batch 532/637] [D loss: 0.164442] [G loss: 0.527741]\n",
      "[Epoch 31/200] [Batch 533/637] [D loss: 0.153961] [G loss: 0.584656]\n",
      "[Epoch 31/200] [Batch 534/637] [D loss: 0.184031] [G loss: 0.568966]\n",
      "[Epoch 31/200] [Batch 535/637] [D loss: 0.188006] [G loss: 0.443510]\n",
      "[Epoch 31/200] [Batch 536/637] [D loss: 0.193672] [G loss: 0.456703]\n",
      "[Epoch 31/200] [Batch 537/637] [D loss: 0.176945] [G loss: 0.476641]\n",
      "[Epoch 31/200] [Batch 538/637] [D loss: 0.189826] [G loss: 0.448875]\n",
      "[Epoch 31/200] [Batch 539/637] [D loss: 0.157263] [G loss: 0.568311]\n",
      "[Epoch 31/200] [Batch 540/637] [D loss: 0.176744] [G loss: 0.524196]\n",
      "[Epoch 31/200] [Batch 541/637] [D loss: 0.164839] [G loss: 0.461573]\n",
      "[Epoch 31/200] [Batch 542/637] [D loss: 0.211260] [G loss: 0.415664]\n",
      "[Epoch 31/200] [Batch 543/637] [D loss: 0.184264] [G loss: 0.391349]\n",
      "[Epoch 31/200] [Batch 544/637] [D loss: 0.198797] [G loss: 0.448424]\n",
      "[Epoch 31/200] [Batch 545/637] [D loss: 0.188821] [G loss: 0.625608]\n",
      "[Epoch 31/200] [Batch 546/637] [D loss: 0.169816] [G loss: 0.545290]\n",
      "[Epoch 31/200] [Batch 547/637] [D loss: 0.176142] [G loss: 0.402664]\n",
      "[Epoch 31/200] [Batch 548/637] [D loss: 0.174545] [G loss: 0.445747]\n",
      "[Epoch 31/200] [Batch 549/637] [D loss: 0.173304] [G loss: 0.427980]\n",
      "[Epoch 31/200] [Batch 550/637] [D loss: 0.159155] [G loss: 0.544813]\n",
      "[Epoch 31/200] [Batch 551/637] [D loss: 0.180718] [G loss: 0.474746]\n",
      "[Epoch 31/200] [Batch 552/637] [D loss: 0.170027] [G loss: 0.490092]\n",
      "[Epoch 31/200] [Batch 553/637] [D loss: 0.184743] [G loss: 0.491546]\n",
      "[Epoch 31/200] [Batch 554/637] [D loss: 0.199758] [G loss: 0.414128]\n",
      "[Epoch 31/200] [Batch 555/637] [D loss: 0.165967] [G loss: 0.495016]\n",
      "[Epoch 31/200] [Batch 556/637] [D loss: 0.186847] [G loss: 0.453010]\n",
      "[Epoch 31/200] [Batch 557/637] [D loss: 0.170579] [G loss: 0.490464]\n",
      "[Epoch 31/200] [Batch 558/637] [D loss: 0.167058] [G loss: 0.443326]\n",
      "[Epoch 31/200] [Batch 559/637] [D loss: 0.181674] [G loss: 0.452210]\n",
      "[Epoch 31/200] [Batch 560/637] [D loss: 0.171925] [G loss: 0.529721]\n",
      "[Epoch 31/200] [Batch 561/637] [D loss: 0.161098] [G loss: 0.522145]\n",
      "[Epoch 31/200] [Batch 562/637] [D loss: 0.166807] [G loss: 0.444577]\n",
      "[Epoch 31/200] [Batch 563/637] [D loss: 0.155510] [G loss: 0.499389]\n",
      "[Epoch 31/200] [Batch 564/637] [D loss: 0.150130] [G loss: 0.549299]\n",
      "[Epoch 31/200] [Batch 565/637] [D loss: 0.155233] [G loss: 0.598194]\n",
      "[Epoch 31/200] [Batch 566/637] [D loss: 0.178602] [G loss: 0.490089]\n",
      "[Epoch 31/200] [Batch 567/637] [D loss: 0.162211] [G loss: 0.427097]\n",
      "[Epoch 31/200] [Batch 568/637] [D loss: 0.179770] [G loss: 0.518233]\n",
      "[Epoch 31/200] [Batch 569/637] [D loss: 0.175670] [G loss: 0.555094]\n",
      "[Epoch 31/200] [Batch 570/637] [D loss: 0.165479] [G loss: 0.442819]\n",
      "[Epoch 31/200] [Batch 571/637] [D loss: 0.172341] [G loss: 0.437830]\n",
      "[Epoch 31/200] [Batch 572/637] [D loss: 0.161404] [G loss: 0.468388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/200] [Batch 573/637] [D loss: 0.183202] [G loss: 0.452095]\n",
      "[Epoch 31/200] [Batch 574/637] [D loss: 0.169279] [G loss: 0.485736]\n",
      "[Epoch 31/200] [Batch 575/637] [D loss: 0.190273] [G loss: 0.376360]\n",
      "[Epoch 31/200] [Batch 576/637] [D loss: 0.161778] [G loss: 0.446577]\n",
      "[Epoch 31/200] [Batch 577/637] [D loss: 0.157579] [G loss: 0.465949]\n",
      "[Epoch 31/200] [Batch 578/637] [D loss: 0.176649] [G loss: 0.470734]\n",
      "[Epoch 31/200] [Batch 579/637] [D loss: 0.176649] [G loss: 0.477416]\n",
      "[Epoch 31/200] [Batch 580/637] [D loss: 0.159522] [G loss: 0.467835]\n",
      "[Epoch 31/200] [Batch 581/637] [D loss: 0.178482] [G loss: 0.501428]\n",
      "[Epoch 31/200] [Batch 582/637] [D loss: 0.161445] [G loss: 0.486503]\n",
      "[Epoch 31/200] [Batch 583/637] [D loss: 0.173491] [G loss: 0.447510]\n",
      "[Epoch 31/200] [Batch 584/637] [D loss: 0.184990] [G loss: 0.433620]\n",
      "[Epoch 31/200] [Batch 585/637] [D loss: 0.176090] [G loss: 0.473653]\n",
      "[Epoch 31/200] [Batch 586/637] [D loss: 0.176815] [G loss: 0.546550]\n",
      "[Epoch 31/200] [Batch 587/637] [D loss: 0.167292] [G loss: 0.520762]\n",
      "[Epoch 31/200] [Batch 588/637] [D loss: 0.175890] [G loss: 0.436272]\n",
      "[Epoch 31/200] [Batch 589/637] [D loss: 0.178118] [G loss: 0.510690]\n",
      "[Epoch 31/200] [Batch 590/637] [D loss: 0.180276] [G loss: 0.560064]\n",
      "[Epoch 31/200] [Batch 591/637] [D loss: 0.181193] [G loss: 0.453657]\n",
      "[Epoch 31/200] [Batch 592/637] [D loss: 0.163792] [G loss: 0.425358]\n",
      "[Epoch 31/200] [Batch 593/637] [D loss: 0.187866] [G loss: 0.522907]\n",
      "[Epoch 31/200] [Batch 594/637] [D loss: 0.179276] [G loss: 0.506916]\n",
      "[Epoch 31/200] [Batch 595/637] [D loss: 0.166441] [G loss: 0.485570]\n",
      "[Epoch 31/200] [Batch 596/637] [D loss: 0.157786] [G loss: 0.544579]\n",
      "[Epoch 31/200] [Batch 597/637] [D loss: 0.176012] [G loss: 0.507643]\n",
      "[Epoch 31/200] [Batch 598/637] [D loss: 0.161432] [G loss: 0.455717]\n",
      "[Epoch 31/200] [Batch 599/637] [D loss: 0.150690] [G loss: 0.560754]\n",
      "[Epoch 31/200] [Batch 600/637] [D loss: 0.170473] [G loss: 0.546551]\n",
      "[Epoch 31/200] [Batch 601/637] [D loss: 0.172363] [G loss: 0.463723]\n",
      "[Epoch 31/200] [Batch 602/637] [D loss: 0.188118] [G loss: 0.400244]\n",
      "[Epoch 31/200] [Batch 603/637] [D loss: 0.157185] [G loss: 0.447673]\n",
      "[Epoch 31/200] [Batch 604/637] [D loss: 0.193032] [G loss: 0.484430]\n",
      "[Epoch 31/200] [Batch 605/637] [D loss: 0.159180] [G loss: 0.540359]\n",
      "[Epoch 31/200] [Batch 606/637] [D loss: 0.165041] [G loss: 0.439739]\n",
      "[Epoch 31/200] [Batch 607/637] [D loss: 0.191431] [G loss: 0.454592]\n",
      "[Epoch 31/200] [Batch 608/637] [D loss: 0.207028] [G loss: 0.383906]\n",
      "[Epoch 31/200] [Batch 609/637] [D loss: 0.189117] [G loss: 0.558769]\n",
      "[Epoch 31/200] [Batch 610/637] [D loss: 0.176905] [G loss: 0.535472]\n",
      "[Epoch 31/200] [Batch 611/637] [D loss: 0.169247] [G loss: 0.522354]\n",
      "[Epoch 31/200] [Batch 612/637] [D loss: 0.174451] [G loss: 0.439034]\n",
      "[Epoch 31/200] [Batch 613/637] [D loss: 0.162354] [G loss: 0.464964]\n",
      "[Epoch 31/200] [Batch 614/637] [D loss: 0.165601] [G loss: 0.505103]\n",
      "[Epoch 31/200] [Batch 615/637] [D loss: 0.149009] [G loss: 0.586955]\n",
      "[Epoch 31/200] [Batch 616/637] [D loss: 0.232752] [G loss: 0.441038]\n",
      "[Epoch 31/200] [Batch 617/637] [D loss: 0.191946] [G loss: 0.438518]\n",
      "[Epoch 31/200] [Batch 618/637] [D loss: 0.170243] [G loss: 0.500176]\n",
      "[Epoch 31/200] [Batch 619/637] [D loss: 0.186883] [G loss: 0.463475]\n",
      "[Epoch 31/200] [Batch 620/637] [D loss: 0.175445] [G loss: 0.519657]\n",
      "[Epoch 31/200] [Batch 621/637] [D loss: 0.166571] [G loss: 0.451035]\n",
      "[Epoch 31/200] [Batch 622/637] [D loss: 0.154727] [G loss: 0.488435]\n",
      "[Epoch 31/200] [Batch 623/637] [D loss: 0.167799] [G loss: 0.481406]\n",
      "[Epoch 31/200] [Batch 624/637] [D loss: 0.154952] [G loss: 0.562866]\n",
      "[Epoch 31/200] [Batch 625/637] [D loss: 0.174471] [G loss: 0.517646]\n",
      "[Epoch 31/200] [Batch 626/637] [D loss: 0.170611] [G loss: 0.499851]\n",
      "[Epoch 31/200] [Batch 627/637] [D loss: 0.155460] [G loss: 0.473636]\n",
      "[Epoch 31/200] [Batch 628/637] [D loss: 0.243366] [G loss: 0.485402]\n",
      "[Epoch 31/200] [Batch 629/637] [D loss: 0.154849] [G loss: 0.506643]\n",
      "[Epoch 31/200] [Batch 630/637] [D loss: 0.157450] [G loss: 0.485014]\n",
      "[Epoch 31/200] [Batch 631/637] [D loss: 0.193446] [G loss: 0.452585]\n",
      "[Epoch 31/200] [Batch 632/637] [D loss: 0.188810] [G loss: 0.498590]\n",
      "[Epoch 31/200] [Batch 633/637] [D loss: 0.171625] [G loss: 0.554816]\n",
      "[Epoch 31/200] [Batch 634/637] [D loss: 0.165926] [G loss: 0.483821]\n",
      "[Epoch 31/200] [Batch 635/637] [D loss: 0.175031] [G loss: 0.434588]\n",
      "[Epoch 31/200] [Batch 636/637] [D loss: 0.168976] [G loss: 0.494067]\n",
      "[Epoch 32/200] [Batch 0/637] [D loss: 0.160285] [G loss: 0.444253]\n",
      "[Epoch 32/200] [Batch 1/637] [D loss: 0.175514] [G loss: 0.456624]\n",
      "[Epoch 32/200] [Batch 2/637] [D loss: 0.170500] [G loss: 0.460204]\n",
      "[Epoch 32/200] [Batch 3/637] [D loss: 0.169433] [G loss: 0.461974]\n",
      "[Epoch 32/200] [Batch 4/637] [D loss: 0.173401] [G loss: 0.539942]\n",
      "[Epoch 32/200] [Batch 5/637] [D loss: 0.158122] [G loss: 0.577619]\n",
      "[Epoch 32/200] [Batch 6/637] [D loss: 0.171167] [G loss: 0.478115]\n",
      "[Epoch 32/200] [Batch 7/637] [D loss: 0.185572] [G loss: 0.355859]\n",
      "[Epoch 32/200] [Batch 8/637] [D loss: 0.172728] [G loss: 0.514743]\n",
      "[Epoch 32/200] [Batch 9/637] [D loss: 0.175379] [G loss: 0.552373]\n",
      "[Epoch 32/200] [Batch 10/637] [D loss: 0.179060] [G loss: 0.542093]\n",
      "[Epoch 32/200] [Batch 11/637] [D loss: 0.169689] [G loss: 0.508679]\n",
      "[Epoch 32/200] [Batch 12/637] [D loss: 0.220907] [G loss: 0.345079]\n",
      "[Epoch 32/200] [Batch 13/637] [D loss: 0.191941] [G loss: 0.453188]\n",
      "[Epoch 32/200] [Batch 14/637] [D loss: 0.179009] [G loss: 0.509737]\n",
      "[Epoch 32/200] [Batch 15/637] [D loss: 0.165161] [G loss: 0.468566]\n",
      "[Epoch 32/200] [Batch 16/637] [D loss: 0.168900] [G loss: 0.475737]\n",
      "[Epoch 32/200] [Batch 17/637] [D loss: 0.156141] [G loss: 0.440379]\n",
      "[Epoch 32/200] [Batch 18/637] [D loss: 0.193602] [G loss: 0.416147]\n",
      "[Epoch 32/200] [Batch 19/637] [D loss: 0.168192] [G loss: 0.539721]\n",
      "[Epoch 32/200] [Batch 20/637] [D loss: 0.187204] [G loss: 0.520296]\n",
      "[Epoch 32/200] [Batch 21/637] [D loss: 0.162368] [G loss: 0.493855]\n",
      "[Epoch 32/200] [Batch 22/637] [D loss: 0.192550] [G loss: 0.456493]\n",
      "[Epoch 32/200] [Batch 23/637] [D loss: 0.178521] [G loss: 0.405973]\n",
      "[Epoch 32/200] [Batch 24/637] [D loss: 0.181427] [G loss: 0.469485]\n",
      "[Epoch 32/200] [Batch 25/637] [D loss: 0.185941] [G loss: 0.436366]\n",
      "[Epoch 32/200] [Batch 26/637] [D loss: 0.167936] [G loss: 0.503764]\n",
      "[Epoch 32/200] [Batch 27/637] [D loss: 0.165893] [G loss: 0.548138]\n",
      "[Epoch 32/200] [Batch 28/637] [D loss: 0.171027] [G loss: 0.456143]\n",
      "[Epoch 32/200] [Batch 29/637] [D loss: 0.148411] [G loss: 0.519412]\n",
      "[Epoch 32/200] [Batch 30/637] [D loss: 0.186211] [G loss: 0.470077]\n",
      "[Epoch 32/200] [Batch 31/637] [D loss: 0.162096] [G loss: 0.463218]\n",
      "[Epoch 32/200] [Batch 32/637] [D loss: 0.196188] [G loss: 0.448644]\n",
      "[Epoch 32/200] [Batch 33/637] [D loss: 0.189932] [G loss: 0.461666]\n",
      "[Epoch 32/200] [Batch 34/637] [D loss: 0.165391] [G loss: 0.490346]\n",
      "[Epoch 32/200] [Batch 35/637] [D loss: 0.182476] [G loss: 0.461607]\n",
      "[Epoch 32/200] [Batch 36/637] [D loss: 0.214880] [G loss: 0.395158]\n",
      "[Epoch 32/200] [Batch 37/637] [D loss: 0.190187] [G loss: 0.457803]\n",
      "[Epoch 32/200] [Batch 38/637] [D loss: 0.216482] [G loss: 0.456849]\n",
      "[Epoch 32/200] [Batch 39/637] [D loss: 0.180785] [G loss: 0.513119]\n",
      "[Epoch 32/200] [Batch 40/637] [D loss: 0.173487] [G loss: 0.456896]\n",
      "[Epoch 32/200] [Batch 41/637] [D loss: 0.184919] [G loss: 0.408022]\n",
      "[Epoch 32/200] [Batch 42/637] [D loss: 0.152213] [G loss: 0.444382]\n",
      "[Epoch 32/200] [Batch 43/637] [D loss: 0.151490] [G loss: 0.488326]\n",
      "[Epoch 32/200] [Batch 44/637] [D loss: 0.167931] [G loss: 0.453744]\n",
      "[Epoch 32/200] [Batch 45/637] [D loss: 0.176526] [G loss: 0.470643]\n",
      "[Epoch 32/200] [Batch 46/637] [D loss: 0.165895] [G loss: 0.465717]\n",
      "[Epoch 32/200] [Batch 47/637] [D loss: 0.189747] [G loss: 0.504748]\n",
      "[Epoch 32/200] [Batch 48/637] [D loss: 0.158922] [G loss: 0.516728]\n",
      "[Epoch 32/200] [Batch 49/637] [D loss: 0.181818] [G loss: 0.436384]\n",
      "[Epoch 32/200] [Batch 50/637] [D loss: 0.182306] [G loss: 0.453184]\n",
      "[Epoch 32/200] [Batch 51/637] [D loss: 0.181689] [G loss: 0.451966]\n",
      "[Epoch 32/200] [Batch 52/637] [D loss: 0.161583] [G loss: 0.543576]\n",
      "[Epoch 32/200] [Batch 53/637] [D loss: 0.214038] [G loss: 0.444771]\n",
      "[Epoch 32/200] [Batch 54/637] [D loss: 0.137485] [G loss: 0.625689]\n",
      "[Epoch 32/200] [Batch 55/637] [D loss: 0.184191] [G loss: 0.586598]\n",
      "[Epoch 32/200] [Batch 56/637] [D loss: 0.173787] [G loss: 0.554288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/200] [Batch 57/637] [D loss: 0.166265] [G loss: 0.414163]\n",
      "[Epoch 32/200] [Batch 58/637] [D loss: 0.163003] [G loss: 0.480808]\n",
      "[Epoch 32/200] [Batch 59/637] [D loss: 0.160818] [G loss: 0.465408]\n",
      "[Epoch 32/200] [Batch 60/637] [D loss: 0.183800] [G loss: 0.548633]\n",
      "[Epoch 32/200] [Batch 61/637] [D loss: 0.182411] [G loss: 0.438608]\n",
      "[Epoch 32/200] [Batch 62/637] [D loss: 0.146840] [G loss: 0.506541]\n",
      "[Epoch 32/200] [Batch 63/637] [D loss: 0.177399] [G loss: 0.470106]\n",
      "[Epoch 32/200] [Batch 64/637] [D loss: 0.149656] [G loss: 0.586805]\n",
      "[Epoch 32/200] [Batch 65/637] [D loss: 0.184499] [G loss: 0.508288]\n",
      "[Epoch 32/200] [Batch 66/637] [D loss: 0.152931] [G loss: 0.497034]\n",
      "[Epoch 32/200] [Batch 67/637] [D loss: 0.187036] [G loss: 0.444902]\n",
      "[Epoch 32/200] [Batch 68/637] [D loss: 0.180584] [G loss: 0.558072]\n",
      "[Epoch 32/200] [Batch 69/637] [D loss: 0.163799] [G loss: 0.566215]\n",
      "[Epoch 32/200] [Batch 70/637] [D loss: 0.175088] [G loss: 0.500090]\n",
      "[Epoch 32/200] [Batch 71/637] [D loss: 0.176469] [G loss: 0.457365]\n",
      "[Epoch 32/200] [Batch 72/637] [D loss: 0.180921] [G loss: 0.428175]\n",
      "[Epoch 32/200] [Batch 73/637] [D loss: 0.178836] [G loss: 0.504945]\n",
      "[Epoch 32/200] [Batch 74/637] [D loss: 0.173669] [G loss: 0.554393]\n",
      "[Epoch 32/200] [Batch 75/637] [D loss: 0.142392] [G loss: 0.541035]\n",
      "[Epoch 32/200] [Batch 76/637] [D loss: 0.144766] [G loss: 0.503895]\n",
      "[Epoch 32/200] [Batch 77/637] [D loss: 0.176142] [G loss: 0.496123]\n",
      "[Epoch 32/200] [Batch 78/637] [D loss: 0.173882] [G loss: 0.472109]\n",
      "[Epoch 32/200] [Batch 79/637] [D loss: 0.160902] [G loss: 0.556892]\n",
      "[Epoch 32/200] [Batch 80/637] [D loss: 0.160432] [G loss: 0.513831]\n",
      "[Epoch 32/200] [Batch 81/637] [D loss: 0.159788] [G loss: 0.540134]\n",
      "[Epoch 32/200] [Batch 82/637] [D loss: 0.192131] [G loss: 0.515392]\n",
      "[Epoch 32/200] [Batch 83/637] [D loss: 0.186018] [G loss: 0.508409]\n",
      "[Epoch 32/200] [Batch 84/637] [D loss: 0.155424] [G loss: 0.545146]\n",
      "[Epoch 32/200] [Batch 85/637] [D loss: 0.174047] [G loss: 0.484067]\n",
      "[Epoch 32/200] [Batch 86/637] [D loss: 0.166149] [G loss: 0.488150]\n",
      "[Epoch 32/200] [Batch 87/637] [D loss: 0.163467] [G loss: 0.511393]\n",
      "[Epoch 32/200] [Batch 88/637] [D loss: 0.178601] [G loss: 0.478145]\n",
      "[Epoch 32/200] [Batch 89/637] [D loss: 0.215613] [G loss: 0.432236]\n",
      "[Epoch 32/200] [Batch 90/637] [D loss: 0.185738] [G loss: 0.513462]\n",
      "[Epoch 32/200] [Batch 91/637] [D loss: 0.184226] [G loss: 0.473928]\n",
      "[Epoch 32/200] [Batch 92/637] [D loss: 0.177542] [G loss: 0.458663]\n",
      "[Epoch 32/200] [Batch 93/637] [D loss: 0.174375] [G loss: 0.524318]\n",
      "[Epoch 32/200] [Batch 94/637] [D loss: 0.159518] [G loss: 0.467823]\n",
      "[Epoch 32/200] [Batch 95/637] [D loss: 0.160348] [G loss: 0.472834]\n",
      "[Epoch 32/200] [Batch 96/637] [D loss: 0.147977] [G loss: 0.528507]\n",
      "[Epoch 32/200] [Batch 97/637] [D loss: 0.202471] [G loss: 0.501229]\n",
      "[Epoch 32/200] [Batch 98/637] [D loss: 0.151157] [G loss: 0.472160]\n",
      "[Epoch 32/200] [Batch 99/637] [D loss: 0.194474] [G loss: 0.493375]\n",
      "[Epoch 32/200] [Batch 100/637] [D loss: 0.168686] [G loss: 0.588511]\n",
      "[Epoch 32/200] [Batch 101/637] [D loss: 0.165643] [G loss: 0.536215]\n",
      "[Epoch 32/200] [Batch 102/637] [D loss: 0.159900] [G loss: 0.471231]\n",
      "[Epoch 32/200] [Batch 103/637] [D loss: 0.195227] [G loss: 0.440956]\n",
      "[Epoch 32/200] [Batch 104/637] [D loss: 0.159554] [G loss: 0.488372]\n",
      "[Epoch 32/200] [Batch 105/637] [D loss: 0.192390] [G loss: 0.392248]\n",
      "[Epoch 32/200] [Batch 106/637] [D loss: 0.147033] [G loss: 0.579102]\n",
      "[Epoch 32/200] [Batch 107/637] [D loss: 0.180678] [G loss: 0.548157]\n",
      "[Epoch 32/200] [Batch 108/637] [D loss: 0.171712] [G loss: 0.435568]\n",
      "[Epoch 32/200] [Batch 109/637] [D loss: 0.173760] [G loss: 0.417735]\n",
      "[Epoch 32/200] [Batch 110/637] [D loss: 0.159153] [G loss: 0.491156]\n",
      "[Epoch 32/200] [Batch 111/637] [D loss: 0.165937] [G loss: 0.532799]\n",
      "[Epoch 32/200] [Batch 112/637] [D loss: 0.176855] [G loss: 0.410860]\n",
      "[Epoch 32/200] [Batch 113/637] [D loss: 0.150939] [G loss: 0.540927]\n",
      "[Epoch 32/200] [Batch 114/637] [D loss: 0.152116] [G loss: 0.490855]\n",
      "[Epoch 32/200] [Batch 115/637] [D loss: 0.170508] [G loss: 0.479091]\n",
      "[Epoch 32/200] [Batch 116/637] [D loss: 0.179280] [G loss: 0.443106]\n",
      "[Epoch 32/200] [Batch 117/637] [D loss: 0.139796] [G loss: 0.555405]\n",
      "[Epoch 32/200] [Batch 118/637] [D loss: 0.166342] [G loss: 0.448812]\n",
      "[Epoch 32/200] [Batch 119/637] [D loss: 0.190699] [G loss: 0.474911]\n",
      "[Epoch 32/200] [Batch 120/637] [D loss: 0.179803] [G loss: 0.499635]\n",
      "[Epoch 32/200] [Batch 121/637] [D loss: 0.184559] [G loss: 0.493481]\n",
      "[Epoch 32/200] [Batch 122/637] [D loss: 0.173878] [G loss: 0.460252]\n",
      "[Epoch 32/200] [Batch 123/637] [D loss: 0.189767] [G loss: 0.453008]\n",
      "[Epoch 32/200] [Batch 124/637] [D loss: 0.188951] [G loss: 0.483924]\n",
      "[Epoch 32/200] [Batch 125/637] [D loss: 0.165883] [G loss: 0.502910]\n",
      "[Epoch 32/200] [Batch 126/637] [D loss: 0.174910] [G loss: 0.481848]\n",
      "[Epoch 32/200] [Batch 127/637] [D loss: 0.172827] [G loss: 0.505499]\n",
      "[Epoch 32/200] [Batch 128/637] [D loss: 0.177088] [G loss: 0.469627]\n",
      "[Epoch 32/200] [Batch 129/637] [D loss: 0.194868] [G loss: 0.414829]\n",
      "[Epoch 32/200] [Batch 130/637] [D loss: 0.168697] [G loss: 0.513020]\n",
      "[Epoch 32/200] [Batch 131/637] [D loss: 0.199725] [G loss: 0.449725]\n",
      "[Epoch 32/200] [Batch 132/637] [D loss: 0.163785] [G loss: 0.533717]\n",
      "[Epoch 32/200] [Batch 133/637] [D loss: 0.183878] [G loss: 0.542424]\n",
      "[Epoch 32/200] [Batch 134/637] [D loss: 0.196867] [G loss: 0.443528]\n",
      "[Epoch 32/200] [Batch 135/637] [D loss: 0.178029] [G loss: 0.554245]\n",
      "[Epoch 32/200] [Batch 136/637] [D loss: 0.177639] [G loss: 0.536285]\n",
      "[Epoch 32/200] [Batch 137/637] [D loss: 0.186351] [G loss: 0.508466]\n",
      "[Epoch 32/200] [Batch 138/637] [D loss: 0.173542] [G loss: 0.449779]\n",
      "[Epoch 32/200] [Batch 139/637] [D loss: 0.167056] [G loss: 0.402696]\n",
      "[Epoch 32/200] [Batch 140/637] [D loss: 0.156279] [G loss: 0.475784]\n",
      "[Epoch 32/200] [Batch 141/637] [D loss: 0.182460] [G loss: 0.513518]\n",
      "[Epoch 32/200] [Batch 142/637] [D loss: 0.171382] [G loss: 0.471505]\n",
      "[Epoch 32/200] [Batch 143/637] [D loss: 0.177748] [G loss: 0.485243]\n",
      "[Epoch 32/200] [Batch 144/637] [D loss: 0.189775] [G loss: 0.515375]\n",
      "[Epoch 32/200] [Batch 145/637] [D loss: 0.183703] [G loss: 0.462350]\n",
      "[Epoch 32/200] [Batch 146/637] [D loss: 0.194506] [G loss: 0.544037]\n",
      "[Epoch 32/200] [Batch 147/637] [D loss: 0.177821] [G loss: 0.505318]\n",
      "[Epoch 32/200] [Batch 148/637] [D loss: 0.181079] [G loss: 0.445114]\n",
      "[Epoch 32/200] [Batch 149/637] [D loss: 0.165274] [G loss: 0.533035]\n",
      "[Epoch 32/200] [Batch 150/637] [D loss: 0.152160] [G loss: 0.496678]\n",
      "[Epoch 32/200] [Batch 151/637] [D loss: 0.212540] [G loss: 0.478042]\n",
      "[Epoch 32/200] [Batch 152/637] [D loss: 0.207873] [G loss: 0.450525]\n",
      "[Epoch 32/200] [Batch 153/637] [D loss: 0.172793] [G loss: 0.507272]\n",
      "[Epoch 32/200] [Batch 154/637] [D loss: 0.189435] [G loss: 0.550688]\n",
      "[Epoch 32/200] [Batch 155/637] [D loss: 0.167578] [G loss: 0.498531]\n",
      "[Epoch 32/200] [Batch 156/637] [D loss: 0.157039] [G loss: 0.413065]\n",
      "[Epoch 32/200] [Batch 157/637] [D loss: 0.175360] [G loss: 0.444262]\n",
      "[Epoch 32/200] [Batch 158/637] [D loss: 0.176310] [G loss: 0.463769]\n",
      "[Epoch 32/200] [Batch 159/637] [D loss: 0.166015] [G loss: 0.472916]\n",
      "[Epoch 32/200] [Batch 160/637] [D loss: 0.177499] [G loss: 0.522661]\n",
      "[Epoch 32/200] [Batch 161/637] [D loss: 0.156155] [G loss: 0.490074]\n",
      "[Epoch 32/200] [Batch 162/637] [D loss: 0.163392] [G loss: 0.467522]\n",
      "[Epoch 32/200] [Batch 163/637] [D loss: 0.167958] [G loss: 0.485937]\n",
      "[Epoch 32/200] [Batch 164/637] [D loss: 0.171058] [G loss: 0.484951]\n",
      "[Epoch 32/200] [Batch 165/637] [D loss: 0.172306] [G loss: 0.450693]\n",
      "[Epoch 32/200] [Batch 166/637] [D loss: 0.148010] [G loss: 0.512663]\n",
      "[Epoch 32/200] [Batch 167/637] [D loss: 0.186145] [G loss: 0.487287]\n",
      "[Epoch 32/200] [Batch 168/637] [D loss: 0.208588] [G loss: 0.433490]\n",
      "[Epoch 32/200] [Batch 169/637] [D loss: 0.156649] [G loss: 0.518216]\n",
      "[Epoch 32/200] [Batch 170/637] [D loss: 0.183276] [G loss: 0.502779]\n",
      "[Epoch 32/200] [Batch 171/637] [D loss: 0.175432] [G loss: 0.475635]\n",
      "[Epoch 32/200] [Batch 172/637] [D loss: 0.160603] [G loss: 0.499089]\n",
      "[Epoch 32/200] [Batch 173/637] [D loss: 0.170537] [G loss: 0.463519]\n",
      "[Epoch 32/200] [Batch 174/637] [D loss: 0.161195] [G loss: 0.446994]\n",
      "[Epoch 32/200] [Batch 175/637] [D loss: 0.179389] [G loss: 0.457630]\n",
      "[Epoch 32/200] [Batch 176/637] [D loss: 0.175941] [G loss: 0.490057]\n",
      "[Epoch 32/200] [Batch 177/637] [D loss: 0.162187] [G loss: 0.504103]\n",
      "[Epoch 32/200] [Batch 178/637] [D loss: 0.158870] [G loss: 0.535690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/200] [Batch 179/637] [D loss: 0.169810] [G loss: 0.476731]\n",
      "[Epoch 32/200] [Batch 180/637] [D loss: 0.176911] [G loss: 0.492520]\n",
      "[Epoch 32/200] [Batch 181/637] [D loss: 0.186835] [G loss: 0.465217]\n",
      "[Epoch 32/200] [Batch 182/637] [D loss: 0.171511] [G loss: 0.495042]\n",
      "[Epoch 32/200] [Batch 183/637] [D loss: 0.155782] [G loss: 0.505769]\n",
      "[Epoch 32/200] [Batch 184/637] [D loss: 0.192246] [G loss: 0.584194]\n",
      "[Epoch 32/200] [Batch 185/637] [D loss: 0.178873] [G loss: 0.480660]\n",
      "[Epoch 32/200] [Batch 186/637] [D loss: 0.176146] [G loss: 0.459665]\n",
      "[Epoch 32/200] [Batch 187/637] [D loss: 0.160518] [G loss: 0.500893]\n",
      "[Epoch 32/200] [Batch 188/637] [D loss: 0.176615] [G loss: 0.495160]\n",
      "[Epoch 32/200] [Batch 189/637] [D loss: 0.161509] [G loss: 0.500327]\n",
      "[Epoch 32/200] [Batch 190/637] [D loss: 0.183555] [G loss: 0.421133]\n",
      "[Epoch 32/200] [Batch 191/637] [D loss: 0.131180] [G loss: 0.562501]\n",
      "[Epoch 32/200] [Batch 192/637] [D loss: 0.153280] [G loss: 0.558459]\n",
      "[Epoch 32/200] [Batch 193/637] [D loss: 0.179311] [G loss: 0.429378]\n",
      "[Epoch 32/200] [Batch 194/637] [D loss: 0.180406] [G loss: 0.511845]\n",
      "[Epoch 32/200] [Batch 195/637] [D loss: 0.210234] [G loss: 0.525587]\n",
      "[Epoch 32/200] [Batch 196/637] [D loss: 0.224872] [G loss: 0.409984]\n",
      "[Epoch 32/200] [Batch 197/637] [D loss: 0.155055] [G loss: 0.516902]\n",
      "[Epoch 32/200] [Batch 198/637] [D loss: 0.165245] [G loss: 0.539017]\n",
      "[Epoch 32/200] [Batch 199/637] [D loss: 0.176066] [G loss: 0.420170]\n",
      "[Epoch 32/200] [Batch 200/637] [D loss: 0.184873] [G loss: 0.430649]\n",
      "[Epoch 32/200] [Batch 201/637] [D loss: 0.168008] [G loss: 0.516870]\n",
      "[Epoch 32/200] [Batch 202/637] [D loss: 0.198825] [G loss: 0.466114]\n",
      "[Epoch 32/200] [Batch 203/637] [D loss: 0.178090] [G loss: 0.474127]\n",
      "[Epoch 32/200] [Batch 204/637] [D loss: 0.151934] [G loss: 0.541888]\n",
      "[Epoch 32/200] [Batch 205/637] [D loss: 0.184728] [G loss: 0.487884]\n",
      "[Epoch 32/200] [Batch 206/637] [D loss: 0.206210] [G loss: 0.458311]\n",
      "[Epoch 32/200] [Batch 207/637] [D loss: 0.189806] [G loss: 0.458028]\n",
      "[Epoch 32/200] [Batch 208/637] [D loss: 0.173251] [G loss: 0.526088]\n",
      "[Epoch 32/200] [Batch 209/637] [D loss: 0.195904] [G loss: 0.505158]\n",
      "[Epoch 32/200] [Batch 210/637] [D loss: 0.167065] [G loss: 0.448918]\n",
      "[Epoch 32/200] [Batch 211/637] [D loss: 0.155731] [G loss: 0.475318]\n",
      "[Epoch 32/200] [Batch 212/637] [D loss: 0.187584] [G loss: 0.433533]\n",
      "[Epoch 32/200] [Batch 213/637] [D loss: 0.199032] [G loss: 0.496459]\n",
      "[Epoch 32/200] [Batch 214/637] [D loss: 0.168344] [G loss: 0.472302]\n",
      "[Epoch 32/200] [Batch 215/637] [D loss: 0.155765] [G loss: 0.457747]\n",
      "[Epoch 32/200] [Batch 216/637] [D loss: 0.177645] [G loss: 0.421154]\n",
      "[Epoch 32/200] [Batch 217/637] [D loss: 0.174718] [G loss: 0.470042]\n",
      "[Epoch 32/200] [Batch 218/637] [D loss: 0.145141] [G loss: 0.543227]\n",
      "[Epoch 32/200] [Batch 219/637] [D loss: 0.175243] [G loss: 0.503897]\n",
      "[Epoch 32/200] [Batch 220/637] [D loss: 0.173434] [G loss: 0.526041]\n",
      "[Epoch 32/200] [Batch 221/637] [D loss: 0.162588] [G loss: 0.496753]\n",
      "[Epoch 32/200] [Batch 222/637] [D loss: 0.151449] [G loss: 0.468515]\n",
      "[Epoch 32/200] [Batch 223/637] [D loss: 0.143606] [G loss: 0.495618]\n",
      "[Epoch 32/200] [Batch 224/637] [D loss: 0.154221] [G loss: 0.534728]\n",
      "[Epoch 32/200] [Batch 225/637] [D loss: 0.213603] [G loss: 0.499325]\n",
      "[Epoch 32/200] [Batch 226/637] [D loss: 0.188831] [G loss: 0.467857]\n",
      "[Epoch 32/200] [Batch 227/637] [D loss: 0.180740] [G loss: 0.478977]\n",
      "[Epoch 32/200] [Batch 228/637] [D loss: 0.173208] [G loss: 0.503520]\n",
      "[Epoch 32/200] [Batch 229/637] [D loss: 0.156995] [G loss: 0.510734]\n",
      "[Epoch 32/200] [Batch 230/637] [D loss: 0.177065] [G loss: 0.450693]\n",
      "[Epoch 32/200] [Batch 231/637] [D loss: 0.162424] [G loss: 0.492406]\n",
      "[Epoch 32/200] [Batch 232/637] [D loss: 0.156604] [G loss: 0.506023]\n",
      "[Epoch 32/200] [Batch 233/637] [D loss: 0.188457] [G loss: 0.384931]\n",
      "[Epoch 32/200] [Batch 234/637] [D loss: 0.174203] [G loss: 0.418292]\n",
      "[Epoch 32/200] [Batch 235/637] [D loss: 0.130540] [G loss: 0.537905]\n",
      "[Epoch 32/200] [Batch 236/637] [D loss: 0.162055] [G loss: 0.455215]\n",
      "[Epoch 32/200] [Batch 237/637] [D loss: 0.172129] [G loss: 0.557884]\n",
      "[Epoch 32/200] [Batch 238/637] [D loss: 0.173253] [G loss: 0.460865]\n",
      "[Epoch 32/200] [Batch 239/637] [D loss: 0.163098] [G loss: 0.523786]\n",
      "[Epoch 32/200] [Batch 240/637] [D loss: 0.167090] [G loss: 0.513213]\n",
      "[Epoch 32/200] [Batch 241/637] [D loss: 0.184811] [G loss: 0.503210]\n",
      "[Epoch 32/200] [Batch 242/637] [D loss: 0.161210] [G loss: 0.464083]\n",
      "[Epoch 32/200] [Batch 243/637] [D loss: 0.166179] [G loss: 0.494154]\n",
      "[Epoch 32/200] [Batch 244/637] [D loss: 0.144300] [G loss: 0.446573]\n",
      "[Epoch 32/200] [Batch 245/637] [D loss: 0.195565] [G loss: 0.432763]\n",
      "[Epoch 32/200] [Batch 246/637] [D loss: 0.177959] [G loss: 0.551913]\n",
      "[Epoch 32/200] [Batch 247/637] [D loss: 0.146856] [G loss: 0.524292]\n",
      "[Epoch 32/200] [Batch 248/637] [D loss: 0.152691] [G loss: 0.490046]\n",
      "[Epoch 32/200] [Batch 249/637] [D loss: 0.166058] [G loss: 0.488284]\n",
      "[Epoch 32/200] [Batch 250/637] [D loss: 0.194051] [G loss: 0.422878]\n",
      "[Epoch 32/200] [Batch 251/637] [D loss: 0.167860] [G loss: 0.519171]\n",
      "[Epoch 32/200] [Batch 252/637] [D loss: 0.176762] [G loss: 0.478789]\n",
      "[Epoch 32/200] [Batch 253/637] [D loss: 0.167084] [G loss: 0.550843]\n",
      "[Epoch 32/200] [Batch 254/637] [D loss: 0.171753] [G loss: 0.506646]\n",
      "[Epoch 32/200] [Batch 255/637] [D loss: 0.178023] [G loss: 0.440759]\n",
      "[Epoch 32/200] [Batch 256/637] [D loss: 0.172616] [G loss: 0.554249]\n",
      "[Epoch 32/200] [Batch 257/637] [D loss: 0.208567] [G loss: 0.374958]\n",
      "[Epoch 32/200] [Batch 258/637] [D loss: 0.172120] [G loss: 0.460011]\n",
      "[Epoch 32/200] [Batch 259/637] [D loss: 0.150247] [G loss: 0.501906]\n",
      "[Epoch 32/200] [Batch 260/637] [D loss: 0.183052] [G loss: 0.456906]\n",
      "[Epoch 32/200] [Batch 261/637] [D loss: 0.155422] [G loss: 0.484557]\n",
      "[Epoch 32/200] [Batch 262/637] [D loss: 0.155625] [G loss: 0.549882]\n",
      "[Epoch 32/200] [Batch 263/637] [D loss: 0.157952] [G loss: 0.502859]\n",
      "[Epoch 32/200] [Batch 264/637] [D loss: 0.170637] [G loss: 0.445690]\n",
      "[Epoch 32/200] [Batch 265/637] [D loss: 0.151020] [G loss: 0.504203]\n",
      "[Epoch 32/200] [Batch 266/637] [D loss: 0.156268] [G loss: 0.585522]\n",
      "[Epoch 32/200] [Batch 267/637] [D loss: 0.184857] [G loss: 0.574343]\n",
      "[Epoch 32/200] [Batch 268/637] [D loss: 0.155301] [G loss: 0.556112]\n",
      "[Epoch 32/200] [Batch 269/637] [D loss: 0.179528] [G loss: 0.478413]\n",
      "[Epoch 32/200] [Batch 270/637] [D loss: 0.175505] [G loss: 0.454772]\n",
      "[Epoch 32/200] [Batch 271/637] [D loss: 0.164430] [G loss: 0.440925]\n",
      "[Epoch 32/200] [Batch 272/637] [D loss: 0.163862] [G loss: 0.467504]\n",
      "[Epoch 32/200] [Batch 273/637] [D loss: 0.163353] [G loss: 0.462333]\n",
      "[Epoch 32/200] [Batch 274/637] [D loss: 0.180955] [G loss: 0.495105]\n",
      "[Epoch 32/200] [Batch 275/637] [D loss: 0.180383] [G loss: 0.494666]\n",
      "[Epoch 32/200] [Batch 276/637] [D loss: 0.176462] [G loss: 0.462864]\n",
      "[Epoch 32/200] [Batch 277/637] [D loss: 0.177134] [G loss: 0.470268]\n",
      "[Epoch 32/200] [Batch 278/637] [D loss: 0.144068] [G loss: 0.533235]\n",
      "[Epoch 32/200] [Batch 279/637] [D loss: 0.164248] [G loss: 0.494594]\n",
      "[Epoch 32/200] [Batch 280/637] [D loss: 0.200851] [G loss: 0.456091]\n",
      "[Epoch 32/200] [Batch 281/637] [D loss: 0.161612] [G loss: 0.480463]\n",
      "[Epoch 32/200] [Batch 282/637] [D loss: 0.174631] [G loss: 0.445458]\n",
      "[Epoch 32/200] [Batch 283/637] [D loss: 0.170052] [G loss: 0.443263]\n",
      "[Epoch 32/200] [Batch 284/637] [D loss: 0.168119] [G loss: 0.507136]\n",
      "[Epoch 32/200] [Batch 285/637] [D loss: 0.189608] [G loss: 0.457420]\n",
      "[Epoch 32/200] [Batch 286/637] [D loss: 0.160250] [G loss: 0.498673]\n",
      "[Epoch 32/200] [Batch 287/637] [D loss: 0.147735] [G loss: 0.555258]\n",
      "[Epoch 32/200] [Batch 288/637] [D loss: 0.168281] [G loss: 0.452512]\n",
      "[Epoch 32/200] [Batch 289/637] [D loss: 0.193555] [G loss: 0.488602]\n",
      "[Epoch 32/200] [Batch 290/637] [D loss: 0.153575] [G loss: 0.578274]\n",
      "[Epoch 32/200] [Batch 291/637] [D loss: 0.178047] [G loss: 0.447724]\n",
      "[Epoch 32/200] [Batch 292/637] [D loss: 0.161732] [G loss: 0.507587]\n",
      "[Epoch 32/200] [Batch 293/637] [D loss: 0.157191] [G loss: 0.579006]\n",
      "[Epoch 32/200] [Batch 294/637] [D loss: 0.169645] [G loss: 0.532847]\n",
      "[Epoch 32/200] [Batch 295/637] [D loss: 0.171806] [G loss: 0.481781]\n",
      "[Epoch 32/200] [Batch 296/637] [D loss: 0.199483] [G loss: 0.526863]\n",
      "[Epoch 32/200] [Batch 297/637] [D loss: 0.157917] [G loss: 0.582908]\n",
      "[Epoch 32/200] [Batch 298/637] [D loss: 0.160605] [G loss: 0.486587]\n",
      "[Epoch 32/200] [Batch 299/637] [D loss: 0.167322] [G loss: 0.452093]\n",
      "[Epoch 32/200] [Batch 300/637] [D loss: 0.173677] [G loss: 0.481463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/200] [Batch 301/637] [D loss: 0.172091] [G loss: 0.490064]\n",
      "[Epoch 32/200] [Batch 302/637] [D loss: 0.186474] [G loss: 0.531690]\n",
      "[Epoch 32/200] [Batch 303/637] [D loss: 0.177188] [G loss: 0.497897]\n",
      "[Epoch 32/200] [Batch 304/637] [D loss: 0.176264] [G loss: 0.417984]\n",
      "[Epoch 32/200] [Batch 305/637] [D loss: 0.178100] [G loss: 0.459594]\n",
      "[Epoch 32/200] [Batch 306/637] [D loss: 0.190614] [G loss: 0.445780]\n",
      "[Epoch 32/200] [Batch 307/637] [D loss: 0.175573] [G loss: 0.499921]\n",
      "[Epoch 32/200] [Batch 308/637] [D loss: 0.179108] [G loss: 0.436505]\n",
      "[Epoch 32/200] [Batch 309/637] [D loss: 0.166590] [G loss: 0.513660]\n",
      "[Epoch 32/200] [Batch 310/637] [D loss: 0.163711] [G loss: 0.474762]\n",
      "[Epoch 32/200] [Batch 311/637] [D loss: 0.198828] [G loss: 0.417417]\n",
      "[Epoch 32/200] [Batch 312/637] [D loss: 0.147644] [G loss: 0.554367]\n",
      "[Epoch 32/200] [Batch 313/637] [D loss: 0.160341] [G loss: 0.513178]\n",
      "[Epoch 32/200] [Batch 314/637] [D loss: 0.171489] [G loss: 0.554517]\n",
      "[Epoch 32/200] [Batch 315/637] [D loss: 0.157160] [G loss: 0.530105]\n",
      "[Epoch 32/200] [Batch 316/637] [D loss: 0.162138] [G loss: 0.534008]\n",
      "[Epoch 32/200] [Batch 317/637] [D loss: 0.182879] [G loss: 0.450657]\n",
      "[Epoch 32/200] [Batch 318/637] [D loss: 0.159274] [G loss: 0.431705]\n",
      "[Epoch 32/200] [Batch 319/637] [D loss: 0.147996] [G loss: 0.549798]\n",
      "[Epoch 32/200] [Batch 320/637] [D loss: 0.178702] [G loss: 0.479747]\n",
      "[Epoch 32/200] [Batch 321/637] [D loss: 0.188923] [G loss: 0.459201]\n",
      "[Epoch 32/200] [Batch 322/637] [D loss: 0.172927] [G loss: 0.469285]\n",
      "[Epoch 32/200] [Batch 323/637] [D loss: 0.155454] [G loss: 0.533019]\n",
      "[Epoch 32/200] [Batch 324/637] [D loss: 0.159214] [G loss: 0.500310]\n",
      "[Epoch 32/200] [Batch 325/637] [D loss: 0.188774] [G loss: 0.500118]\n",
      "[Epoch 32/200] [Batch 326/637] [D loss: 0.177151] [G loss: 0.505267]\n",
      "[Epoch 32/200] [Batch 327/637] [D loss: 0.185089] [G loss: 0.511381]\n",
      "[Epoch 32/200] [Batch 328/637] [D loss: 0.174833] [G loss: 0.527485]\n",
      "[Epoch 32/200] [Batch 329/637] [D loss: 0.192369] [G loss: 0.425594]\n",
      "[Epoch 32/200] [Batch 330/637] [D loss: 0.181352] [G loss: 0.468593]\n",
      "[Epoch 32/200] [Batch 331/637] [D loss: 0.188664] [G loss: 0.466600]\n",
      "[Epoch 32/200] [Batch 332/637] [D loss: 0.149792] [G loss: 0.509616]\n",
      "[Epoch 32/200] [Batch 333/637] [D loss: 0.141473] [G loss: 0.504548]\n",
      "[Epoch 32/200] [Batch 334/637] [D loss: 0.189774] [G loss: 0.479768]\n",
      "[Epoch 32/200] [Batch 335/637] [D loss: 0.167062] [G loss: 0.545657]\n",
      "[Epoch 32/200] [Batch 336/637] [D loss: 0.163342] [G loss: 0.579324]\n",
      "[Epoch 32/200] [Batch 337/637] [D loss: 0.159275] [G loss: 0.486457]\n",
      "[Epoch 32/200] [Batch 338/637] [D loss: 0.159065] [G loss: 0.477296]\n",
      "[Epoch 32/200] [Batch 339/637] [D loss: 0.179392] [G loss: 0.421101]\n",
      "[Epoch 32/200] [Batch 340/637] [D loss: 0.158146] [G loss: 0.510905]\n",
      "[Epoch 32/200] [Batch 341/637] [D loss: 0.197776] [G loss: 0.419377]\n",
      "[Epoch 32/200] [Batch 342/637] [D loss: 0.196061] [G loss: 0.494747]\n",
      "[Epoch 32/200] [Batch 343/637] [D loss: 0.185560] [G loss: 0.516580]\n",
      "[Epoch 32/200] [Batch 344/637] [D loss: 0.179895] [G loss: 0.581938]\n",
      "[Epoch 32/200] [Batch 345/637] [D loss: 0.182392] [G loss: 0.546010]\n",
      "[Epoch 32/200] [Batch 346/637] [D loss: 0.176795] [G loss: 0.439161]\n",
      "[Epoch 32/200] [Batch 347/637] [D loss: 0.156932] [G loss: 0.446090]\n",
      "[Epoch 32/200] [Batch 348/637] [D loss: 0.147863] [G loss: 0.486894]\n",
      "[Epoch 32/200] [Batch 349/637] [D loss: 0.182462] [G loss: 0.459839]\n",
      "[Epoch 32/200] [Batch 350/637] [D loss: 0.159083] [G loss: 0.464058]\n",
      "[Epoch 32/200] [Batch 351/637] [D loss: 0.211539] [G loss: 0.520274]\n",
      "[Epoch 32/200] [Batch 352/637] [D loss: 0.177559] [G loss: 0.508045]\n",
      "[Epoch 32/200] [Batch 353/637] [D loss: 0.175786] [G loss: 0.477175]\n",
      "[Epoch 32/200] [Batch 354/637] [D loss: 0.172867] [G loss: 0.487133]\n",
      "[Epoch 32/200] [Batch 355/637] [D loss: 0.171779] [G loss: 0.480062]\n",
      "[Epoch 32/200] [Batch 356/637] [D loss: 0.184995] [G loss: 0.444476]\n",
      "[Epoch 32/200] [Batch 357/637] [D loss: 0.190967] [G loss: 0.440217]\n",
      "[Epoch 32/200] [Batch 358/637] [D loss: 0.177434] [G loss: 0.490950]\n",
      "[Epoch 32/200] [Batch 359/637] [D loss: 0.180200] [G loss: 0.484173]\n",
      "[Epoch 32/200] [Batch 360/637] [D loss: 0.181472] [G loss: 0.497817]\n",
      "[Epoch 32/200] [Batch 361/637] [D loss: 0.170699] [G loss: 0.492595]\n",
      "[Epoch 32/200] [Batch 362/637] [D loss: 0.160127] [G loss: 0.521528]\n",
      "[Epoch 32/200] [Batch 363/637] [D loss: 0.182821] [G loss: 0.526654]\n",
      "[Epoch 32/200] [Batch 364/637] [D loss: 0.185939] [G loss: 0.453502]\n",
      "[Epoch 32/200] [Batch 365/637] [D loss: 0.189010] [G loss: 0.403797]\n",
      "[Epoch 32/200] [Batch 366/637] [D loss: 0.163782] [G loss: 0.470811]\n",
      "[Epoch 32/200] [Batch 367/637] [D loss: 0.189012] [G loss: 0.527739]\n",
      "[Epoch 32/200] [Batch 368/637] [D loss: 0.165432] [G loss: 0.447912]\n",
      "[Epoch 32/200] [Batch 369/637] [D loss: 0.163939] [G loss: 0.511685]\n",
      "[Epoch 32/200] [Batch 370/637] [D loss: 0.177091] [G loss: 0.506363]\n",
      "[Epoch 32/200] [Batch 371/637] [D loss: 0.184595] [G loss: 0.420152]\n",
      "[Epoch 32/200] [Batch 372/637] [D loss: 0.180627] [G loss: 0.448118]\n",
      "[Epoch 32/200] [Batch 373/637] [D loss: 0.178607] [G loss: 0.479065]\n",
      "[Epoch 32/200] [Batch 374/637] [D loss: 0.181743] [G loss: 0.463685]\n",
      "[Epoch 32/200] [Batch 375/637] [D loss: 0.163552] [G loss: 0.528731]\n",
      "[Epoch 32/200] [Batch 376/637] [D loss: 0.188354] [G loss: 0.487821]\n",
      "[Epoch 32/200] [Batch 377/637] [D loss: 0.174902] [G loss: 0.478424]\n",
      "[Epoch 32/200] [Batch 378/637] [D loss: 0.216752] [G loss: 0.374787]\n",
      "[Epoch 32/200] [Batch 379/637] [D loss: 0.184047] [G loss: 0.517993]\n",
      "[Epoch 32/200] [Batch 380/637] [D loss: 0.161826] [G loss: 0.523295]\n",
      "[Epoch 32/200] [Batch 381/637] [D loss: 0.145775] [G loss: 0.458406]\n",
      "[Epoch 32/200] [Batch 382/637] [D loss: 0.179118] [G loss: 0.405199]\n",
      "[Epoch 32/200] [Batch 383/637] [D loss: 0.190306] [G loss: 0.461077]\n",
      "[Epoch 32/200] [Batch 384/637] [D loss: 0.159203] [G loss: 0.489776]\n",
      "[Epoch 32/200] [Batch 385/637] [D loss: 0.162221] [G loss: 0.511450]\n",
      "[Epoch 32/200] [Batch 386/637] [D loss: 0.167786] [G loss: 0.570440]\n",
      "[Epoch 32/200] [Batch 387/637] [D loss: 0.174582] [G loss: 0.442470]\n",
      "[Epoch 32/200] [Batch 388/637] [D loss: 0.153341] [G loss: 0.486402]\n",
      "[Epoch 32/200] [Batch 389/637] [D loss: 0.179874] [G loss: 0.376074]\n",
      "[Epoch 32/200] [Batch 390/637] [D loss: 0.184490] [G loss: 0.570005]\n",
      "[Epoch 32/200] [Batch 391/637] [D loss: 0.185200] [G loss: 0.516366]\n",
      "[Epoch 32/200] [Batch 392/637] [D loss: 0.169017] [G loss: 0.559414]\n",
      "[Epoch 32/200] [Batch 393/637] [D loss: 0.193673] [G loss: 0.481118]\n",
      "[Epoch 32/200] [Batch 394/637] [D loss: 0.169696] [G loss: 0.401845]\n",
      "[Epoch 32/200] [Batch 395/637] [D loss: 0.189192] [G loss: 0.416268]\n",
      "[Epoch 32/200] [Batch 396/637] [D loss: 0.171949] [G loss: 0.468549]\n",
      "[Epoch 32/200] [Batch 397/637] [D loss: 0.170902] [G loss: 0.512860]\n",
      "[Epoch 32/200] [Batch 398/637] [D loss: 0.161342] [G loss: 0.583772]\n",
      "[Epoch 32/200] [Batch 399/637] [D loss: 0.190139] [G loss: 0.460471]\n",
      "[Epoch 32/200] [Batch 400/637] [D loss: 0.144071] [G loss: 0.498451]\n",
      "[Epoch 32/200] [Batch 401/637] [D loss: 0.193934] [G loss: 0.409633]\n",
      "[Epoch 32/200] [Batch 402/637] [D loss: 0.192858] [G loss: 0.390376]\n",
      "[Epoch 32/200] [Batch 403/637] [D loss: 0.160870] [G loss: 0.522079]\n",
      "[Epoch 32/200] [Batch 404/637] [D loss: 0.191331] [G loss: 0.510486]\n",
      "[Epoch 32/200] [Batch 405/637] [D loss: 0.172499] [G loss: 0.478269]\n",
      "[Epoch 32/200] [Batch 406/637] [D loss: 0.188534] [G loss: 0.472185]\n",
      "[Epoch 32/200] [Batch 407/637] [D loss: 0.164268] [G loss: 0.441285]\n",
      "[Epoch 32/200] [Batch 408/637] [D loss: 0.170655] [G loss: 0.467543]\n",
      "[Epoch 32/200] [Batch 409/637] [D loss: 0.180504] [G loss: 0.464570]\n",
      "[Epoch 32/200] [Batch 410/637] [D loss: 0.177691] [G loss: 0.517858]\n",
      "[Epoch 32/200] [Batch 411/637] [D loss: 0.172320] [G loss: 0.471296]\n",
      "[Epoch 32/200] [Batch 412/637] [D loss: 0.168163] [G loss: 0.524371]\n",
      "[Epoch 32/200] [Batch 413/637] [D loss: 0.178185] [G loss: 0.438521]\n",
      "[Epoch 32/200] [Batch 414/637] [D loss: 0.174140] [G loss: 0.415345]\n",
      "[Epoch 32/200] [Batch 415/637] [D loss: 0.178337] [G loss: 0.504917]\n",
      "[Epoch 32/200] [Batch 416/637] [D loss: 0.175276] [G loss: 0.452725]\n",
      "[Epoch 32/200] [Batch 417/637] [D loss: 0.194376] [G loss: 0.441984]\n",
      "[Epoch 32/200] [Batch 418/637] [D loss: 0.174178] [G loss: 0.475920]\n",
      "[Epoch 32/200] [Batch 419/637] [D loss: 0.191788] [G loss: 0.486919]\n",
      "[Epoch 32/200] [Batch 420/637] [D loss: 0.159080] [G loss: 0.445819]\n",
      "[Epoch 32/200] [Batch 421/637] [D loss: 0.184798] [G loss: 0.453728]\n",
      "[Epoch 32/200] [Batch 422/637] [D loss: 0.184975] [G loss: 0.452811]\n",
      "[Epoch 32/200] [Batch 423/637] [D loss: 0.194648] [G loss: 0.458015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/200] [Batch 424/637] [D loss: 0.159783] [G loss: 0.488877]\n",
      "[Epoch 32/200] [Batch 425/637] [D loss: 0.187407] [G loss: 0.443688]\n",
      "[Epoch 32/200] [Batch 426/637] [D loss: 0.163736] [G loss: 0.522555]\n",
      "[Epoch 32/200] [Batch 427/637] [D loss: 0.195598] [G loss: 0.390505]\n",
      "[Epoch 32/200] [Batch 428/637] [D loss: 0.151361] [G loss: 0.512540]\n",
      "[Epoch 32/200] [Batch 429/637] [D loss: 0.168163] [G loss: 0.577804]\n",
      "[Epoch 32/200] [Batch 430/637] [D loss: 0.159209] [G loss: 0.502279]\n",
      "[Epoch 32/200] [Batch 431/637] [D loss: 0.161539] [G loss: 0.470936]\n",
      "[Epoch 32/200] [Batch 432/637] [D loss: 0.153782] [G loss: 0.499081]\n",
      "[Epoch 32/200] [Batch 433/637] [D loss: 0.150125] [G loss: 0.560894]\n",
      "[Epoch 32/200] [Batch 434/637] [D loss: 0.197967] [G loss: 0.487535]\n",
      "[Epoch 32/200] [Batch 435/637] [D loss: 0.172336] [G loss: 0.536349]\n",
      "[Epoch 32/200] [Batch 436/637] [D loss: 0.163014] [G loss: 0.527945]\n",
      "[Epoch 32/200] [Batch 437/637] [D loss: 0.159180] [G loss: 0.485648]\n",
      "[Epoch 32/200] [Batch 438/637] [D loss: 0.173891] [G loss: 0.409865]\n",
      "[Epoch 32/200] [Batch 439/637] [D loss: 0.180059] [G loss: 0.483717]\n",
      "[Epoch 32/200] [Batch 440/637] [D loss: 0.183624] [G loss: 0.515032]\n",
      "[Epoch 32/200] [Batch 441/637] [D loss: 0.165966] [G loss: 0.498990]\n",
      "[Epoch 32/200] [Batch 442/637] [D loss: 0.194008] [G loss: 0.492492]\n",
      "[Epoch 32/200] [Batch 443/637] [D loss: 0.159471] [G loss: 0.487460]\n",
      "[Epoch 32/200] [Batch 444/637] [D loss: 0.160197] [G loss: 0.565441]\n",
      "[Epoch 32/200] [Batch 445/637] [D loss: 0.183099] [G loss: 0.482904]\n",
      "[Epoch 32/200] [Batch 446/637] [D loss: 0.190252] [G loss: 0.401274]\n",
      "[Epoch 32/200] [Batch 447/637] [D loss: 0.182350] [G loss: 0.527540]\n",
      "[Epoch 32/200] [Batch 448/637] [D loss: 0.152193] [G loss: 0.545230]\n",
      "[Epoch 32/200] [Batch 449/637] [D loss: 0.170070] [G loss: 0.493263]\n",
      "[Epoch 32/200] [Batch 450/637] [D loss: 0.156537] [G loss: 0.479349]\n",
      "[Epoch 32/200] [Batch 451/637] [D loss: 0.171477] [G loss: 0.435495]\n",
      "[Epoch 32/200] [Batch 452/637] [D loss: 0.157033] [G loss: 0.476721]\n",
      "[Epoch 32/200] [Batch 453/637] [D loss: 0.155591] [G loss: 0.503256]\n",
      "[Epoch 32/200] [Batch 454/637] [D loss: 0.169413] [G loss: 0.541359]\n",
      "[Epoch 32/200] [Batch 455/637] [D loss: 0.173856] [G loss: 0.495603]\n",
      "[Epoch 32/200] [Batch 456/637] [D loss: 0.162314] [G loss: 0.446959]\n",
      "[Epoch 32/200] [Batch 457/637] [D loss: 0.159239] [G loss: 0.509826]\n",
      "[Epoch 32/200] [Batch 458/637] [D loss: 0.167181] [G loss: 0.467236]\n",
      "[Epoch 32/200] [Batch 459/637] [D loss: 0.164671] [G loss: 0.529761]\n",
      "[Epoch 32/200] [Batch 460/637] [D loss: 0.152671] [G loss: 0.463286]\n",
      "[Epoch 32/200] [Batch 461/637] [D loss: 0.173910] [G loss: 0.499719]\n",
      "[Epoch 32/200] [Batch 462/637] [D loss: 0.176985] [G loss: 0.539075]\n",
      "[Epoch 32/200] [Batch 463/637] [D loss: 0.163616] [G loss: 0.519222]\n",
      "[Epoch 32/200] [Batch 464/637] [D loss: 0.157570] [G loss: 0.513786]\n",
      "[Epoch 32/200] [Batch 465/637] [D loss: 0.176284] [G loss: 0.472036]\n",
      "[Epoch 32/200] [Batch 466/637] [D loss: 0.180713] [G loss: 0.390708]\n",
      "[Epoch 32/200] [Batch 467/637] [D loss: 0.165021] [G loss: 0.532137]\n",
      "[Epoch 32/200] [Batch 468/637] [D loss: 0.186351] [G loss: 0.518451]\n",
      "[Epoch 32/200] [Batch 469/637] [D loss: 0.166255] [G loss: 0.501616]\n",
      "[Epoch 32/200] [Batch 470/637] [D loss: 0.195452] [G loss: 0.494583]\n",
      "[Epoch 32/200] [Batch 471/637] [D loss: 0.154467] [G loss: 0.515673]\n",
      "[Epoch 32/200] [Batch 472/637] [D loss: 0.200326] [G loss: 0.428162]\n",
      "[Epoch 32/200] [Batch 473/637] [D loss: 0.179907] [G loss: 0.548004]\n",
      "[Epoch 32/200] [Batch 474/637] [D loss: 0.178008] [G loss: 0.554528]\n",
      "[Epoch 32/200] [Batch 475/637] [D loss: 0.160826] [G loss: 0.514669]\n",
      "[Epoch 32/200] [Batch 476/637] [D loss: 0.144738] [G loss: 0.539182]\n",
      "[Epoch 32/200] [Batch 477/637] [D loss: 0.187523] [G loss: 0.452406]\n",
      "[Epoch 32/200] [Batch 478/637] [D loss: 0.166060] [G loss: 0.513901]\n",
      "[Epoch 32/200] [Batch 479/637] [D loss: 0.187262] [G loss: 0.545831]\n",
      "[Epoch 32/200] [Batch 480/637] [D loss: 0.152899] [G loss: 0.486819]\n",
      "[Epoch 32/200] [Batch 481/637] [D loss: 0.148067] [G loss: 0.538238]\n",
      "[Epoch 32/200] [Batch 482/637] [D loss: 0.190271] [G loss: 0.514301]\n",
      "[Epoch 32/200] [Batch 483/637] [D loss: 0.141912] [G loss: 0.517136]\n",
      "[Epoch 32/200] [Batch 484/637] [D loss: 0.148239] [G loss: 0.487168]\n",
      "[Epoch 32/200] [Batch 485/637] [D loss: 0.151088] [G loss: 0.535207]\n",
      "[Epoch 32/200] [Batch 486/637] [D loss: 0.182499] [G loss: 0.522176]\n",
      "[Epoch 32/200] [Batch 487/637] [D loss: 0.182649] [G loss: 0.536828]\n",
      "[Epoch 32/200] [Batch 488/637] [D loss: 0.157477] [G loss: 0.520181]\n",
      "[Epoch 32/200] [Batch 489/637] [D loss: 0.173194] [G loss: 0.516907]\n",
      "[Epoch 32/200] [Batch 490/637] [D loss: 0.173621] [G loss: 0.470328]\n",
      "[Epoch 32/200] [Batch 491/637] [D loss: 0.163164] [G loss: 0.486678]\n",
      "[Epoch 32/200] [Batch 492/637] [D loss: 0.185059] [G loss: 0.595801]\n",
      "[Epoch 32/200] [Batch 493/637] [D loss: 0.182446] [G loss: 0.543595]\n",
      "[Epoch 32/200] [Batch 494/637] [D loss: 0.169689] [G loss: 0.503191]\n",
      "[Epoch 32/200] [Batch 495/637] [D loss: 0.181649] [G loss: 0.422342]\n",
      "[Epoch 32/200] [Batch 496/637] [D loss: 0.152267] [G loss: 0.459938]\n",
      "[Epoch 32/200] [Batch 497/637] [D loss: 0.183741] [G loss: 0.536128]\n",
      "[Epoch 32/200] [Batch 498/637] [D loss: 0.166784] [G loss: 0.487884]\n",
      "[Epoch 32/200] [Batch 499/637] [D loss: 0.167360] [G loss: 0.469943]\n",
      "[Epoch 32/200] [Batch 500/637] [D loss: 0.149447] [G loss: 0.470320]\n",
      "[Epoch 32/200] [Batch 501/637] [D loss: 0.162849] [G loss: 0.460136]\n",
      "[Epoch 32/200] [Batch 502/637] [D loss: 0.155611] [G loss: 0.485491]\n",
      "[Epoch 32/200] [Batch 503/637] [D loss: 0.179152] [G loss: 0.442030]\n",
      "[Epoch 32/200] [Batch 504/637] [D loss: 0.189131] [G loss: 0.529327]\n",
      "[Epoch 32/200] [Batch 505/637] [D loss: 0.154530] [G loss: 0.522657]\n",
      "[Epoch 32/200] [Batch 506/637] [D loss: 0.166313] [G loss: 0.460391]\n",
      "[Epoch 32/200] [Batch 507/637] [D loss: 0.161674] [G loss: 0.475486]\n",
      "[Epoch 32/200] [Batch 508/637] [D loss: 0.181070] [G loss: 0.445494]\n",
      "[Epoch 32/200] [Batch 509/637] [D loss: 0.188041] [G loss: 0.415288]\n",
      "[Epoch 32/200] [Batch 510/637] [D loss: 0.166351] [G loss: 0.512789]\n",
      "[Epoch 32/200] [Batch 511/637] [D loss: 0.158102] [G loss: 0.635112]\n",
      "[Epoch 32/200] [Batch 512/637] [D loss: 0.163700] [G loss: 0.476058]\n",
      "[Epoch 32/200] [Batch 513/637] [D loss: 0.124681] [G loss: 0.549307]\n",
      "[Epoch 32/200] [Batch 514/637] [D loss: 0.272986] [G loss: 0.475864]\n",
      "[Epoch 32/200] [Batch 515/637] [D loss: 0.338400] [G loss: 0.446715]\n",
      "[Epoch 32/200] [Batch 516/637] [D loss: 0.232549] [G loss: 0.426587]\n",
      "[Epoch 32/200] [Batch 517/637] [D loss: 0.284680] [G loss: 0.222401]\n",
      "[Epoch 32/200] [Batch 518/637] [D loss: 0.265740] [G loss: 0.661291]\n",
      "[Epoch 32/200] [Batch 519/637] [D loss: 0.254991] [G loss: 0.616446]\n",
      "[Epoch 32/200] [Batch 520/637] [D loss: 0.190265] [G loss: 0.471840]\n",
      "[Epoch 32/200] [Batch 521/637] [D loss: 0.229404] [G loss: 0.337860]\n",
      "[Epoch 32/200] [Batch 522/637] [D loss: 0.205028] [G loss: 0.494615]\n",
      "[Epoch 32/200] [Batch 523/637] [D loss: 0.178916] [G loss: 0.564792]\n",
      "[Epoch 32/200] [Batch 524/637] [D loss: 0.179948] [G loss: 0.439783]\n",
      "[Epoch 32/200] [Batch 525/637] [D loss: 0.175499] [G loss: 0.455728]\n",
      "[Epoch 32/200] [Batch 526/637] [D loss: 0.173174] [G loss: 0.476619]\n",
      "[Epoch 32/200] [Batch 527/637] [D loss: 0.186662] [G loss: 0.543475]\n",
      "[Epoch 32/200] [Batch 528/637] [D loss: 0.175861] [G loss: 0.512730]\n",
      "[Epoch 32/200] [Batch 529/637] [D loss: 0.167681] [G loss: 0.498824]\n",
      "[Epoch 32/200] [Batch 530/637] [D loss: 0.175274] [G loss: 0.441781]\n",
      "[Epoch 32/200] [Batch 531/637] [D loss: 0.154405] [G loss: 0.511557]\n",
      "[Epoch 32/200] [Batch 532/637] [D loss: 0.166301] [G loss: 0.492898]\n",
      "[Epoch 32/200] [Batch 533/637] [D loss: 0.188039] [G loss: 0.444131]\n",
      "[Epoch 32/200] [Batch 534/637] [D loss: 0.211862] [G loss: 0.451262]\n",
      "[Epoch 32/200] [Batch 535/637] [D loss: 0.191062] [G loss: 0.498424]\n",
      "[Epoch 32/200] [Batch 536/637] [D loss: 0.212097] [G loss: 0.487455]\n",
      "[Epoch 32/200] [Batch 537/637] [D loss: 0.173944] [G loss: 0.399888]\n",
      "[Epoch 32/200] [Batch 538/637] [D loss: 0.198217] [G loss: 0.456059]\n",
      "[Epoch 32/200] [Batch 539/637] [D loss: 0.186452] [G loss: 0.453436]\n",
      "[Epoch 32/200] [Batch 540/637] [D loss: 0.186064] [G loss: 0.419113]\n",
      "[Epoch 32/200] [Batch 541/637] [D loss: 0.188722] [G loss: 0.425761]\n",
      "[Epoch 32/200] [Batch 542/637] [D loss: 0.167841] [G loss: 0.527543]\n",
      "[Epoch 32/200] [Batch 543/637] [D loss: 0.191663] [G loss: 0.484595]\n",
      "[Epoch 32/200] [Batch 544/637] [D loss: 0.200605] [G loss: 0.439467]\n",
      "[Epoch 32/200] [Batch 545/637] [D loss: 0.183425] [G loss: 0.414452]\n",
      "[Epoch 32/200] [Batch 546/637] [D loss: 0.183325] [G loss: 0.408496]\n",
      "[Epoch 32/200] [Batch 547/637] [D loss: 0.188868] [G loss: 0.469923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/200] [Batch 548/637] [D loss: 0.166478] [G loss: 0.496609]\n",
      "[Epoch 32/200] [Batch 549/637] [D loss: 0.184199] [G loss: 0.473603]\n",
      "[Epoch 32/200] [Batch 550/637] [D loss: 0.177486] [G loss: 0.453020]\n",
      "[Epoch 32/200] [Batch 551/637] [D loss: 0.187620] [G loss: 0.409704]\n",
      "[Epoch 32/200] [Batch 552/637] [D loss: 0.170227] [G loss: 0.421467]\n",
      "[Epoch 32/200] [Batch 553/637] [D loss: 0.177884] [G loss: 0.413184]\n",
      "[Epoch 32/200] [Batch 554/637] [D loss: 0.174636] [G loss: 0.469996]\n",
      "[Epoch 32/200] [Batch 555/637] [D loss: 0.198379] [G loss: 0.455738]\n",
      "[Epoch 32/200] [Batch 556/637] [D loss: 0.127929] [G loss: 0.617296]\n",
      "[Epoch 32/200] [Batch 557/637] [D loss: 0.177371] [G loss: 0.455416]\n",
      "[Epoch 32/200] [Batch 558/637] [D loss: 0.148934] [G loss: 0.577993]\n",
      "[Epoch 32/200] [Batch 559/637] [D loss: 0.170176] [G loss: 0.534481]\n",
      "[Epoch 32/200] [Batch 560/637] [D loss: 0.178700] [G loss: 0.462026]\n",
      "[Epoch 32/200] [Batch 561/637] [D loss: 0.205900] [G loss: 0.436171]\n",
      "[Epoch 32/200] [Batch 562/637] [D loss: 0.179032] [G loss: 0.464967]\n",
      "[Epoch 32/200] [Batch 563/637] [D loss: 0.152064] [G loss: 0.497532]\n",
      "[Epoch 32/200] [Batch 564/637] [D loss: 0.168575] [G loss: 0.465277]\n",
      "[Epoch 32/200] [Batch 565/637] [D loss: 0.172922] [G loss: 0.500257]\n",
      "[Epoch 32/200] [Batch 566/637] [D loss: 0.171595] [G loss: 0.480685]\n",
      "[Epoch 32/200] [Batch 567/637] [D loss: 0.168307] [G loss: 0.511585]\n",
      "[Epoch 32/200] [Batch 568/637] [D loss: 0.145725] [G loss: 0.526365]\n",
      "[Epoch 32/200] [Batch 569/637] [D loss: 0.182777] [G loss: 0.531109]\n",
      "[Epoch 32/200] [Batch 570/637] [D loss: 0.168601] [G loss: 0.451685]\n",
      "[Epoch 32/200] [Batch 571/637] [D loss: 0.172227] [G loss: 0.448977]\n",
      "[Epoch 32/200] [Batch 572/637] [D loss: 0.171567] [G loss: 0.478006]\n",
      "[Epoch 32/200] [Batch 573/637] [D loss: 0.150061] [G loss: 0.506219]\n",
      "[Epoch 32/200] [Batch 574/637] [D loss: 0.180542] [G loss: 0.488908]\n",
      "[Epoch 32/200] [Batch 575/637] [D loss: 0.161154] [G loss: 0.471648]\n",
      "[Epoch 32/200] [Batch 576/637] [D loss: 0.158095] [G loss: 0.523875]\n",
      "[Epoch 32/200] [Batch 577/637] [D loss: 0.164171] [G loss: 0.532536]\n",
      "[Epoch 32/200] [Batch 578/637] [D loss: 0.167623] [G loss: 0.448437]\n",
      "[Epoch 32/200] [Batch 579/637] [D loss: 0.180104] [G loss: 0.515763]\n",
      "[Epoch 32/200] [Batch 580/637] [D loss: 0.183928] [G loss: 0.444491]\n",
      "[Epoch 32/200] [Batch 581/637] [D loss: 0.178706] [G loss: 0.521298]\n",
      "[Epoch 32/200] [Batch 582/637] [D loss: 0.166801] [G loss: 0.517643]\n",
      "[Epoch 32/200] [Batch 583/637] [D loss: 0.166086] [G loss: 0.418653]\n",
      "[Epoch 32/200] [Batch 584/637] [D loss: 0.167095] [G loss: 0.461079]\n",
      "[Epoch 32/200] [Batch 585/637] [D loss: 0.174901] [G loss: 0.473782]\n",
      "[Epoch 32/200] [Batch 586/637] [D loss: 0.237837] [G loss: 0.478896]\n",
      "[Epoch 32/200] [Batch 587/637] [D loss: 0.207972] [G loss: 0.472469]\n",
      "[Epoch 32/200] [Batch 588/637] [D loss: 0.190741] [G loss: 0.574651]\n",
      "[Epoch 32/200] [Batch 589/637] [D loss: 0.186599] [G loss: 0.510664]\n",
      "[Epoch 32/200] [Batch 590/637] [D loss: 0.179999] [G loss: 0.400323]\n",
      "[Epoch 32/200] [Batch 591/637] [D loss: 0.169226] [G loss: 0.374802]\n",
      "[Epoch 32/200] [Batch 592/637] [D loss: 0.171058] [G loss: 0.401758]\n",
      "[Epoch 32/200] [Batch 593/637] [D loss: 0.198071] [G loss: 0.440419]\n",
      "[Epoch 32/200] [Batch 594/637] [D loss: 0.156144] [G loss: 0.568666]\n",
      "[Epoch 32/200] [Batch 595/637] [D loss: 0.179786] [G loss: 0.483895]\n",
      "[Epoch 32/200] [Batch 596/637] [D loss: 0.187151] [G loss: 0.479503]\n",
      "[Epoch 32/200] [Batch 597/637] [D loss: 0.176510] [G loss: 0.488651]\n",
      "[Epoch 32/200] [Batch 598/637] [D loss: 0.183422] [G loss: 0.503578]\n",
      "[Epoch 32/200] [Batch 599/637] [D loss: 0.184959] [G loss: 0.472218]\n",
      "[Epoch 32/200] [Batch 600/637] [D loss: 0.180317] [G loss: 0.423611]\n",
      "[Epoch 32/200] [Batch 601/637] [D loss: 0.164171] [G loss: 0.452233]\n",
      "[Epoch 32/200] [Batch 602/637] [D loss: 0.185154] [G loss: 0.423714]\n",
      "[Epoch 32/200] [Batch 603/637] [D loss: 0.188077] [G loss: 0.466083]\n",
      "[Epoch 32/200] [Batch 604/637] [D loss: 0.185715] [G loss: 0.450345]\n",
      "[Epoch 32/200] [Batch 605/637] [D loss: 0.156083] [G loss: 0.479782]\n",
      "[Epoch 32/200] [Batch 606/637] [D loss: 0.164386] [G loss: 0.508997]\n",
      "[Epoch 32/200] [Batch 607/637] [D loss: 0.190726] [G loss: 0.429858]\n",
      "[Epoch 32/200] [Batch 608/637] [D loss: 0.172552] [G loss: 0.466544]\n",
      "[Epoch 32/200] [Batch 609/637] [D loss: 0.201455] [G loss: 0.427954]\n",
      "[Epoch 32/200] [Batch 610/637] [D loss: 0.165233] [G loss: 0.566881]\n",
      "[Epoch 32/200] [Batch 611/637] [D loss: 0.166871] [G loss: 0.525085]\n",
      "[Epoch 32/200] [Batch 612/637] [D loss: 0.185450] [G loss: 0.453554]\n",
      "[Epoch 32/200] [Batch 613/637] [D loss: 0.159588] [G loss: 0.509152]\n",
      "[Epoch 32/200] [Batch 614/637] [D loss: 0.175599] [G loss: 0.463087]\n",
      "[Epoch 32/200] [Batch 615/637] [D loss: 0.164873] [G loss: 0.502639]\n",
      "[Epoch 32/200] [Batch 616/637] [D loss: 0.175640] [G loss: 0.576977]\n",
      "[Epoch 32/200] [Batch 617/637] [D loss: 0.188476] [G loss: 0.470004]\n",
      "[Epoch 32/200] [Batch 618/637] [D loss: 0.153114] [G loss: 0.550550]\n",
      "[Epoch 32/200] [Batch 619/637] [D loss: 0.221188] [G loss: 0.472617]\n",
      "[Epoch 32/200] [Batch 620/637] [D loss: 0.162703] [G loss: 0.527226]\n",
      "[Epoch 32/200] [Batch 621/637] [D loss: 0.178538] [G loss: 0.557493]\n",
      "[Epoch 32/200] [Batch 622/637] [D loss: 0.183564] [G loss: 0.454530]\n",
      "[Epoch 32/200] [Batch 623/637] [D loss: 0.175613] [G loss: 0.424874]\n",
      "[Epoch 32/200] [Batch 624/637] [D loss: 0.160568] [G loss: 0.431845]\n",
      "[Epoch 32/200] [Batch 625/637] [D loss: 0.167163] [G loss: 0.535362]\n",
      "[Epoch 32/200] [Batch 626/637] [D loss: 0.154163] [G loss: 0.541502]\n",
      "[Epoch 32/200] [Batch 627/637] [D loss: 0.171179] [G loss: 0.462348]\n",
      "[Epoch 32/200] [Batch 628/637] [D loss: 0.168749] [G loss: 0.465265]\n",
      "[Epoch 32/200] [Batch 629/637] [D loss: 0.176228] [G loss: 0.524217]\n",
      "[Epoch 32/200] [Batch 630/637] [D loss: 0.181856] [G loss: 0.519419]\n",
      "[Epoch 32/200] [Batch 631/637] [D loss: 0.176190] [G loss: 0.528065]\n",
      "[Epoch 32/200] [Batch 632/637] [D loss: 0.164589] [G loss: 0.499676]\n",
      "[Epoch 32/200] [Batch 633/637] [D loss: 0.163266] [G loss: 0.469496]\n",
      "[Epoch 32/200] [Batch 634/637] [D loss: 0.193301] [G loss: 0.418206]\n",
      "[Epoch 32/200] [Batch 635/637] [D loss: 0.215410] [G loss: 0.460868]\n",
      "[Epoch 32/200] [Batch 636/637] [D loss: 0.181797] [G loss: 0.573983]\n",
      "[Epoch 33/200] [Batch 0/637] [D loss: 0.184708] [G loss: 0.524520]\n",
      "[Epoch 33/200] [Batch 1/637] [D loss: 0.152484] [G loss: 0.550237]\n",
      "[Epoch 33/200] [Batch 2/637] [D loss: 0.168537] [G loss: 0.480910]\n",
      "[Epoch 33/200] [Batch 3/637] [D loss: 0.160349] [G loss: 0.449374]\n",
      "[Epoch 33/200] [Batch 4/637] [D loss: 0.167528] [G loss: 0.492424]\n",
      "[Epoch 33/200] [Batch 5/637] [D loss: 0.141940] [G loss: 0.499047]\n",
      "[Epoch 33/200] [Batch 6/637] [D loss: 0.177814] [G loss: 0.490730]\n",
      "[Epoch 33/200] [Batch 7/637] [D loss: 0.174899] [G loss: 0.568966]\n",
      "[Epoch 33/200] [Batch 8/637] [D loss: 0.189738] [G loss: 0.486382]\n",
      "[Epoch 33/200] [Batch 9/637] [D loss: 0.158706] [G loss: 0.463388]\n",
      "[Epoch 33/200] [Batch 10/637] [D loss: 0.228066] [G loss: 0.443004]\n",
      "[Epoch 33/200] [Batch 11/637] [D loss: 0.192224] [G loss: 0.422169]\n",
      "[Epoch 33/200] [Batch 12/637] [D loss: 0.179504] [G loss: 0.508966]\n",
      "[Epoch 33/200] [Batch 13/637] [D loss: 0.149328] [G loss: 0.500572]\n",
      "[Epoch 33/200] [Batch 14/637] [D loss: 0.185867] [G loss: 0.449745]\n",
      "[Epoch 33/200] [Batch 15/637] [D loss: 0.163835] [G loss: 0.496801]\n",
      "[Epoch 33/200] [Batch 16/637] [D loss: 0.168760] [G loss: 0.512776]\n",
      "[Epoch 33/200] [Batch 17/637] [D loss: 0.138682] [G loss: 0.516772]\n",
      "[Epoch 33/200] [Batch 18/637] [D loss: 0.213468] [G loss: 0.412779]\n",
      "[Epoch 33/200] [Batch 19/637] [D loss: 0.180849] [G loss: 0.495541]\n",
      "[Epoch 33/200] [Batch 20/637] [D loss: 0.172102] [G loss: 0.525398]\n",
      "[Epoch 33/200] [Batch 21/637] [D loss: 0.155164] [G loss: 0.457752]\n",
      "[Epoch 33/200] [Batch 22/637] [D loss: 0.167543] [G loss: 0.499197]\n",
      "[Epoch 33/200] [Batch 23/637] [D loss: 0.169883] [G loss: 0.442928]\n",
      "[Epoch 33/200] [Batch 24/637] [D loss: 0.160897] [G loss: 0.444991]\n",
      "[Epoch 33/200] [Batch 25/637] [D loss: 0.165973] [G loss: 0.484003]\n",
      "[Epoch 33/200] [Batch 26/637] [D loss: 0.187918] [G loss: 0.439203]\n",
      "[Epoch 33/200] [Batch 27/637] [D loss: 0.166092] [G loss: 0.528004]\n",
      "[Epoch 33/200] [Batch 28/637] [D loss: 0.164185] [G loss: 0.513383]\n",
      "[Epoch 33/200] [Batch 29/637] [D loss: 0.172957] [G loss: 0.470355]\n",
      "[Epoch 33/200] [Batch 30/637] [D loss: 0.159004] [G loss: 0.472621]\n",
      "[Epoch 33/200] [Batch 31/637] [D loss: 0.172339] [G loss: 0.470484]\n",
      "[Epoch 33/200] [Batch 32/637] [D loss: 0.178511] [G loss: 0.496128]\n",
      "[Epoch 33/200] [Batch 33/637] [D loss: 0.180007] [G loss: 0.401874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/200] [Batch 34/637] [D loss: 0.169603] [G loss: 0.560926]\n",
      "[Epoch 33/200] [Batch 35/637] [D loss: 0.200258] [G loss: 0.522537]\n",
      "[Epoch 33/200] [Batch 36/637] [D loss: 0.152737] [G loss: 0.573793]\n",
      "[Epoch 33/200] [Batch 37/637] [D loss: 0.172178] [G loss: 0.455614]\n",
      "[Epoch 33/200] [Batch 38/637] [D loss: 0.168286] [G loss: 0.450508]\n",
      "[Epoch 33/200] [Batch 39/637] [D loss: 0.176478] [G loss: 0.437260]\n",
      "[Epoch 33/200] [Batch 40/637] [D loss: 0.162554] [G loss: 0.491556]\n",
      "[Epoch 33/200] [Batch 41/637] [D loss: 0.161567] [G loss: 0.485845]\n",
      "[Epoch 33/200] [Batch 42/637] [D loss: 0.157275] [G loss: 0.490641]\n",
      "[Epoch 33/200] [Batch 43/637] [D loss: 0.175804] [G loss: 0.458922]\n",
      "[Epoch 33/200] [Batch 44/637] [D loss: 0.163505] [G loss: 0.460223]\n",
      "[Epoch 33/200] [Batch 45/637] [D loss: 0.169618] [G loss: 0.454993]\n",
      "[Epoch 33/200] [Batch 46/637] [D loss: 0.165869] [G loss: 0.467821]\n",
      "[Epoch 33/200] [Batch 47/637] [D loss: 0.195818] [G loss: 0.422328]\n",
      "[Epoch 33/200] [Batch 48/637] [D loss: 0.158418] [G loss: 0.587246]\n",
      "[Epoch 33/200] [Batch 49/637] [D loss: 0.174830] [G loss: 0.481476]\n",
      "[Epoch 33/200] [Batch 50/637] [D loss: 0.186603] [G loss: 0.503510]\n",
      "[Epoch 33/200] [Batch 51/637] [D loss: 0.162256] [G loss: 0.482712]\n",
      "[Epoch 33/200] [Batch 52/637] [D loss: 0.170888] [G loss: 0.470752]\n",
      "[Epoch 33/200] [Batch 53/637] [D loss: 0.152246] [G loss: 0.474334]\n",
      "[Epoch 33/200] [Batch 54/637] [D loss: 0.182383] [G loss: 0.482549]\n",
      "[Epoch 33/200] [Batch 55/637] [D loss: 0.152259] [G loss: 0.502520]\n",
      "[Epoch 33/200] [Batch 56/637] [D loss: 0.166039] [G loss: 0.489042]\n",
      "[Epoch 33/200] [Batch 57/637] [D loss: 0.171537] [G loss: 0.490203]\n",
      "[Epoch 33/200] [Batch 58/637] [D loss: 0.167134] [G loss: 0.463593]\n",
      "[Epoch 33/200] [Batch 59/637] [D loss: 0.179933] [G loss: 0.507652]\n",
      "[Epoch 33/200] [Batch 60/637] [D loss: 0.153928] [G loss: 0.556301]\n",
      "[Epoch 33/200] [Batch 61/637] [D loss: 0.171860] [G loss: 0.407591]\n",
      "[Epoch 33/200] [Batch 62/637] [D loss: 0.197687] [G loss: 0.389577]\n",
      "[Epoch 33/200] [Batch 63/637] [D loss: 0.181117] [G loss: 0.520748]\n",
      "[Epoch 33/200] [Batch 64/637] [D loss: 0.191713] [G loss: 0.495372]\n",
      "[Epoch 33/200] [Batch 65/637] [D loss: 0.151850] [G loss: 0.523709]\n",
      "[Epoch 33/200] [Batch 66/637] [D loss: 0.202686] [G loss: 0.442241]\n",
      "[Epoch 33/200] [Batch 67/637] [D loss: 0.172539] [G loss: 0.457242]\n",
      "[Epoch 33/200] [Batch 68/637] [D loss: 0.151244] [G loss: 0.485019]\n",
      "[Epoch 33/200] [Batch 69/637] [D loss: 0.177044] [G loss: 0.473826]\n",
      "[Epoch 33/200] [Batch 70/637] [D loss: 0.162915] [G loss: 0.506976]\n",
      "[Epoch 33/200] [Batch 71/637] [D loss: 0.159507] [G loss: 0.533704]\n",
      "[Epoch 33/200] [Batch 72/637] [D loss: 0.167611] [G loss: 0.511432]\n",
      "[Epoch 33/200] [Batch 73/637] [D loss: 0.190338] [G loss: 0.444593]\n",
      "[Epoch 33/200] [Batch 74/637] [D loss: 0.158398] [G loss: 0.462462]\n",
      "[Epoch 33/200] [Batch 75/637] [D loss: 0.183124] [G loss: 0.420288]\n",
      "[Epoch 33/200] [Batch 76/637] [D loss: 0.159760] [G loss: 0.503612]\n",
      "[Epoch 33/200] [Batch 77/637] [D loss: 0.167541] [G loss: 0.555972]\n",
      "[Epoch 33/200] [Batch 78/637] [D loss: 0.180615] [G loss: 0.503553]\n",
      "[Epoch 33/200] [Batch 79/637] [D loss: 0.142095] [G loss: 0.542598]\n",
      "[Epoch 33/200] [Batch 80/637] [D loss: 0.149518] [G loss: 0.562164]\n",
      "[Epoch 33/200] [Batch 81/637] [D loss: 0.167455] [G loss: 0.463581]\n",
      "[Epoch 33/200] [Batch 82/637] [D loss: 0.169332] [G loss: 0.451218]\n",
      "[Epoch 33/200] [Batch 83/637] [D loss: 0.175057] [G loss: 0.426444]\n",
      "[Epoch 33/200] [Batch 84/637] [D loss: 0.187361] [G loss: 0.469915]\n",
      "[Epoch 33/200] [Batch 85/637] [D loss: 0.179302] [G loss: 0.514070]\n",
      "[Epoch 33/200] [Batch 86/637] [D loss: 0.167074] [G loss: 0.486295]\n",
      "[Epoch 33/200] [Batch 87/637] [D loss: 0.178382] [G loss: 0.517741]\n",
      "[Epoch 33/200] [Batch 88/637] [D loss: 0.165563] [G loss: 0.456617]\n",
      "[Epoch 33/200] [Batch 89/637] [D loss: 0.178104] [G loss: 0.477420]\n",
      "[Epoch 33/200] [Batch 90/637] [D loss: 0.167895] [G loss: 0.492790]\n",
      "[Epoch 33/200] [Batch 91/637] [D loss: 0.150516] [G loss: 0.517891]\n",
      "[Epoch 33/200] [Batch 92/637] [D loss: 0.186413] [G loss: 0.449439]\n",
      "[Epoch 33/200] [Batch 93/637] [D loss: 0.162459] [G loss: 0.495995]\n",
      "[Epoch 33/200] [Batch 94/637] [D loss: 0.172310] [G loss: 0.547467]\n",
      "[Epoch 33/200] [Batch 95/637] [D loss: 0.166988] [G loss: 0.511987]\n",
      "[Epoch 33/200] [Batch 96/637] [D loss: 0.150281] [G loss: 0.508386]\n",
      "[Epoch 33/200] [Batch 97/637] [D loss: 0.170680] [G loss: 0.441039]\n",
      "[Epoch 33/200] [Batch 98/637] [D loss: 0.150335] [G loss: 0.492022]\n",
      "[Epoch 33/200] [Batch 99/637] [D loss: 0.169535] [G loss: 0.495220]\n",
      "[Epoch 33/200] [Batch 100/637] [D loss: 0.161327] [G loss: 0.520723]\n",
      "[Epoch 33/200] [Batch 101/637] [D loss: 0.154623] [G loss: 0.510868]\n",
      "[Epoch 33/200] [Batch 102/637] [D loss: 0.151844] [G loss: 0.496424]\n",
      "[Epoch 33/200] [Batch 103/637] [D loss: 0.183955] [G loss: 0.453951]\n",
      "[Epoch 33/200] [Batch 104/637] [D loss: 0.182997] [G loss: 0.531162]\n",
      "[Epoch 33/200] [Batch 105/637] [D loss: 0.162407] [G loss: 0.540649]\n",
      "[Epoch 33/200] [Batch 106/637] [D loss: 0.166775] [G loss: 0.515134]\n",
      "[Epoch 33/200] [Batch 107/637] [D loss: 0.151517] [G loss: 0.539606]\n",
      "[Epoch 33/200] [Batch 108/637] [D loss: 0.187481] [G loss: 0.420174]\n",
      "[Epoch 33/200] [Batch 109/637] [D loss: 0.198351] [G loss: 0.478566]\n",
      "[Epoch 33/200] [Batch 110/637] [D loss: 0.182549] [G loss: 0.467221]\n",
      "[Epoch 33/200] [Batch 111/637] [D loss: 0.165960] [G loss: 0.490099]\n",
      "[Epoch 33/200] [Batch 112/637] [D loss: 0.177860] [G loss: 0.476587]\n",
      "[Epoch 33/200] [Batch 113/637] [D loss: 0.183306] [G loss: 0.475281]\n",
      "[Epoch 33/200] [Batch 114/637] [D loss: 0.160441] [G loss: 0.503084]\n",
      "[Epoch 33/200] [Batch 115/637] [D loss: 0.182992] [G loss: 0.415383]\n",
      "[Epoch 33/200] [Batch 116/637] [D loss: 0.148559] [G loss: 0.547525]\n",
      "[Epoch 33/200] [Batch 117/637] [D loss: 0.177700] [G loss: 0.493641]\n",
      "[Epoch 33/200] [Batch 118/637] [D loss: 0.161887] [G loss: 0.564436]\n",
      "[Epoch 33/200] [Batch 119/637] [D loss: 0.188991] [G loss: 0.538949]\n",
      "[Epoch 33/200] [Batch 120/637] [D loss: 0.153624] [G loss: 0.511059]\n",
      "[Epoch 33/200] [Batch 121/637] [D loss: 0.209254] [G loss: 0.422438]\n",
      "[Epoch 33/200] [Batch 122/637] [D loss: 0.203216] [G loss: 0.439706]\n",
      "[Epoch 33/200] [Batch 123/637] [D loss: 0.188049] [G loss: 0.464113]\n",
      "[Epoch 33/200] [Batch 124/637] [D loss: 0.179610] [G loss: 0.483616]\n",
      "[Epoch 33/200] [Batch 125/637] [D loss: 0.175255] [G loss: 0.464118]\n",
      "[Epoch 33/200] [Batch 126/637] [D loss: 0.160234] [G loss: 0.491378]\n",
      "[Epoch 33/200] [Batch 127/637] [D loss: 0.185950] [G loss: 0.435112]\n",
      "[Epoch 33/200] [Batch 128/637] [D loss: 0.171554] [G loss: 0.460740]\n",
      "[Epoch 33/200] [Batch 129/637] [D loss: 0.153788] [G loss: 0.470117]\n",
      "[Epoch 33/200] [Batch 130/637] [D loss: 0.151955] [G loss: 0.489741]\n",
      "[Epoch 33/200] [Batch 131/637] [D loss: 0.142977] [G loss: 0.522251]\n",
      "[Epoch 33/200] [Batch 132/637] [D loss: 0.191750] [G loss: 0.448379]\n",
      "[Epoch 33/200] [Batch 133/637] [D loss: 0.162177] [G loss: 0.544216]\n",
      "[Epoch 33/200] [Batch 134/637] [D loss: 0.173137] [G loss: 0.582850]\n",
      "[Epoch 33/200] [Batch 135/637] [D loss: 0.159623] [G loss: 0.530835]\n",
      "[Epoch 33/200] [Batch 136/637] [D loss: 0.176371] [G loss: 0.443955]\n",
      "[Epoch 33/200] [Batch 137/637] [D loss: 0.156511] [G loss: 0.479458]\n",
      "[Epoch 33/200] [Batch 138/637] [D loss: 0.152875] [G loss: 0.448997]\n",
      "[Epoch 33/200] [Batch 139/637] [D loss: 0.145640] [G loss: 0.524358]\n",
      "[Epoch 33/200] [Batch 140/637] [D loss: 0.164176] [G loss: 0.523638]\n",
      "[Epoch 33/200] [Batch 141/637] [D loss: 0.136881] [G loss: 0.547786]\n",
      "[Epoch 33/200] [Batch 142/637] [D loss: 0.174592] [G loss: 0.455444]\n",
      "[Epoch 33/200] [Batch 143/637] [D loss: 0.166654] [G loss: 0.532262]\n",
      "[Epoch 33/200] [Batch 144/637] [D loss: 0.185288] [G loss: 0.472153]\n",
      "[Epoch 33/200] [Batch 145/637] [D loss: 0.162643] [G loss: 0.523167]\n",
      "[Epoch 33/200] [Batch 146/637] [D loss: 0.170157] [G loss: 0.491792]\n",
      "[Epoch 33/200] [Batch 147/637] [D loss: 0.173107] [G loss: 0.479572]\n",
      "[Epoch 33/200] [Batch 148/637] [D loss: 0.174650] [G loss: 0.491110]\n",
      "[Epoch 33/200] [Batch 149/637] [D loss: 0.163957] [G loss: 0.514289]\n",
      "[Epoch 33/200] [Batch 150/637] [D loss: 0.183503] [G loss: 0.445981]\n",
      "[Epoch 33/200] [Batch 151/637] [D loss: 0.162484] [G loss: 0.453882]\n",
      "[Epoch 33/200] [Batch 152/637] [D loss: 0.173621] [G loss: 0.501332]\n",
      "[Epoch 33/200] [Batch 153/637] [D loss: 0.147560] [G loss: 0.502370]\n",
      "[Epoch 33/200] [Batch 154/637] [D loss: 0.174240] [G loss: 0.470817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/200] [Batch 155/637] [D loss: 0.171197] [G loss: 0.503743]\n",
      "[Epoch 33/200] [Batch 156/637] [D loss: 0.163742] [G loss: 0.521588]\n",
      "[Epoch 33/200] [Batch 157/637] [D loss: 0.173767] [G loss: 0.424433]\n",
      "[Epoch 33/200] [Batch 158/637] [D loss: 0.153313] [G loss: 0.477099]\n",
      "[Epoch 33/200] [Batch 159/637] [D loss: 0.137498] [G loss: 0.558064]\n",
      "[Epoch 33/200] [Batch 160/637] [D loss: 0.144856] [G loss: 0.535218]\n",
      "[Epoch 33/200] [Batch 161/637] [D loss: 0.161590] [G loss: 0.496671]\n",
      "[Epoch 33/200] [Batch 162/637] [D loss: 0.159024] [G loss: 0.501390]\n",
      "[Epoch 33/200] [Batch 163/637] [D loss: 0.140778] [G loss: 0.597399]\n",
      "[Epoch 33/200] [Batch 164/637] [D loss: 0.157412] [G loss: 0.466381]\n",
      "[Epoch 33/200] [Batch 165/637] [D loss: 0.175613] [G loss: 0.480442]\n",
      "[Epoch 33/200] [Batch 166/637] [D loss: 0.167300] [G loss: 0.545751]\n",
      "[Epoch 33/200] [Batch 167/637] [D loss: 0.196814] [G loss: 0.509078]\n",
      "[Epoch 33/200] [Batch 168/637] [D loss: 0.147056] [G loss: 0.616507]\n",
      "[Epoch 33/200] [Batch 169/637] [D loss: 0.193811] [G loss: 0.530546]\n",
      "[Epoch 33/200] [Batch 170/637] [D loss: 0.148787] [G loss: 0.514103]\n",
      "[Epoch 33/200] [Batch 171/637] [D loss: 0.193139] [G loss: 0.472952]\n",
      "[Epoch 33/200] [Batch 172/637] [D loss: 0.169469] [G loss: 0.452400]\n",
      "[Epoch 33/200] [Batch 173/637] [D loss: 0.172347] [G loss: 0.490989]\n",
      "[Epoch 33/200] [Batch 174/637] [D loss: 0.178043] [G loss: 0.491663]\n",
      "[Epoch 33/200] [Batch 175/637] [D loss: 0.158780] [G loss: 0.518963]\n",
      "[Epoch 33/200] [Batch 176/637] [D loss: 0.174431] [G loss: 0.491155]\n",
      "[Epoch 33/200] [Batch 177/637] [D loss: 0.163235] [G loss: 0.548811]\n",
      "[Epoch 33/200] [Batch 178/637] [D loss: 0.158198] [G loss: 0.544082]\n",
      "[Epoch 33/200] [Batch 179/637] [D loss: 0.163437] [G loss: 0.445927]\n",
      "[Epoch 33/200] [Batch 180/637] [D loss: 0.160086] [G loss: 0.479838]\n",
      "[Epoch 33/200] [Batch 181/637] [D loss: 0.149998] [G loss: 0.491140]\n",
      "[Epoch 33/200] [Batch 182/637] [D loss: 0.193501] [G loss: 0.465615]\n",
      "[Epoch 33/200] [Batch 183/637] [D loss: 0.187891] [G loss: 0.572386]\n",
      "[Epoch 33/200] [Batch 184/637] [D loss: 0.177223] [G loss: 0.556888]\n",
      "[Epoch 33/200] [Batch 185/637] [D loss: 0.148318] [G loss: 0.531320]\n",
      "[Epoch 33/200] [Batch 186/637] [D loss: 0.193727] [G loss: 0.459845]\n",
      "[Epoch 33/200] [Batch 187/637] [D loss: 0.170959] [G loss: 0.484358]\n",
      "[Epoch 33/200] [Batch 188/637] [D loss: 0.163628] [G loss: 0.520432]\n",
      "[Epoch 33/200] [Batch 189/637] [D loss: 0.176075] [G loss: 0.427224]\n",
      "[Epoch 33/200] [Batch 190/637] [D loss: 0.173241] [G loss: 0.463163]\n",
      "[Epoch 33/200] [Batch 191/637] [D loss: 0.162887] [G loss: 0.439179]\n",
      "[Epoch 33/200] [Batch 192/637] [D loss: 0.155004] [G loss: 0.442296]\n",
      "[Epoch 33/200] [Batch 193/637] [D loss: 0.162140] [G loss: 0.498249]\n",
      "[Epoch 33/200] [Batch 194/637] [D loss: 0.158092] [G loss: 0.544764]\n",
      "[Epoch 33/200] [Batch 195/637] [D loss: 0.151628] [G loss: 0.526217]\n",
      "[Epoch 33/200] [Batch 196/637] [D loss: 0.163705] [G loss: 0.464003]\n",
      "[Epoch 33/200] [Batch 197/637] [D loss: 0.162546] [G loss: 0.493957]\n",
      "[Epoch 33/200] [Batch 198/637] [D loss: 0.165663] [G loss: 0.487969]\n",
      "[Epoch 33/200] [Batch 199/637] [D loss: 0.172406] [G loss: 0.476409]\n",
      "[Epoch 33/200] [Batch 200/637] [D loss: 0.150951] [G loss: 0.508157]\n",
      "[Epoch 33/200] [Batch 201/637] [D loss: 0.170765] [G loss: 0.470400]\n",
      "[Epoch 33/200] [Batch 202/637] [D loss: 0.174351] [G loss: 0.469862]\n",
      "[Epoch 33/200] [Batch 203/637] [D loss: 0.170995] [G loss: 0.469743]\n",
      "[Epoch 33/200] [Batch 204/637] [D loss: 0.171146] [G loss: 0.435907]\n",
      "[Epoch 33/200] [Batch 205/637] [D loss: 0.174457] [G loss: 0.461827]\n",
      "[Epoch 33/200] [Batch 206/637] [D loss: 0.178582] [G loss: 0.498084]\n",
      "[Epoch 33/200] [Batch 207/637] [D loss: 0.148016] [G loss: 0.503551]\n",
      "[Epoch 33/200] [Batch 208/637] [D loss: 0.177839] [G loss: 0.499637]\n",
      "[Epoch 33/200] [Batch 209/637] [D loss: 0.152821] [G loss: 0.486111]\n",
      "[Epoch 33/200] [Batch 210/637] [D loss: 0.178395] [G loss: 0.445358]\n",
      "[Epoch 33/200] [Batch 211/637] [D loss: 0.157419] [G loss: 0.524830]\n",
      "[Epoch 33/200] [Batch 212/637] [D loss: 0.158781] [G loss: 0.541683]\n",
      "[Epoch 33/200] [Batch 213/637] [D loss: 0.159480] [G loss: 0.503242]\n",
      "[Epoch 33/200] [Batch 214/637] [D loss: 0.161328] [G loss: 0.471210]\n",
      "[Epoch 33/200] [Batch 215/637] [D loss: 0.180657] [G loss: 0.470377]\n",
      "[Epoch 33/200] [Batch 216/637] [D loss: 0.171761] [G loss: 0.467655]\n",
      "[Epoch 33/200] [Batch 217/637] [D loss: 0.178968] [G loss: 0.492963]\n",
      "[Epoch 33/200] [Batch 218/637] [D loss: 0.167997] [G loss: 0.483030]\n",
      "[Epoch 33/200] [Batch 219/637] [D loss: 0.161237] [G loss: 0.534819]\n",
      "[Epoch 33/200] [Batch 220/637] [D loss: 0.164078] [G loss: 0.583240]\n",
      "[Epoch 33/200] [Batch 221/637] [D loss: 0.188191] [G loss: 0.504034]\n",
      "[Epoch 33/200] [Batch 222/637] [D loss: 0.151831] [G loss: 0.520750]\n",
      "[Epoch 33/200] [Batch 223/637] [D loss: 0.166291] [G loss: 0.483458]\n",
      "[Epoch 33/200] [Batch 224/637] [D loss: 0.168393] [G loss: 0.461034]\n",
      "[Epoch 33/200] [Batch 225/637] [D loss: 0.176672] [G loss: 0.503866]\n",
      "[Epoch 33/200] [Batch 226/637] [D loss: 0.150593] [G loss: 0.506116]\n",
      "[Epoch 33/200] [Batch 227/637] [D loss: 0.164913] [G loss: 0.514725]\n",
      "[Epoch 33/200] [Batch 228/637] [D loss: 0.170457] [G loss: 0.495709]\n",
      "[Epoch 33/200] [Batch 229/637] [D loss: 0.149592] [G loss: 0.478426]\n",
      "[Epoch 33/200] [Batch 230/637] [D loss: 0.173358] [G loss: 0.457789]\n",
      "[Epoch 33/200] [Batch 231/637] [D loss: 0.227063] [G loss: 0.421173]\n",
      "[Epoch 33/200] [Batch 232/637] [D loss: 0.207821] [G loss: 0.539234]\n",
      "[Epoch 33/200] [Batch 233/637] [D loss: 0.179432] [G loss: 0.550171]\n",
      "[Epoch 33/200] [Batch 234/637] [D loss: 0.191869] [G loss: 0.485266]\n",
      "[Epoch 33/200] [Batch 235/637] [D loss: 0.166288] [G loss: 0.458254]\n",
      "[Epoch 33/200] [Batch 236/637] [D loss: 0.159829] [G loss: 0.486237]\n",
      "[Epoch 33/200] [Batch 237/637] [D loss: 0.181842] [G loss: 0.435384]\n",
      "[Epoch 33/200] [Batch 238/637] [D loss: 0.178251] [G loss: 0.496492]\n",
      "[Epoch 33/200] [Batch 239/637] [D loss: 0.196466] [G loss: 0.536343]\n",
      "[Epoch 33/200] [Batch 240/637] [D loss: 0.170036] [G loss: 0.487047]\n",
      "[Epoch 33/200] [Batch 241/637] [D loss: 0.176973] [G loss: 0.497929]\n",
      "[Epoch 33/200] [Batch 242/637] [D loss: 0.169726] [G loss: 0.507600]\n",
      "[Epoch 33/200] [Batch 243/637] [D loss: 0.187954] [G loss: 0.455453]\n",
      "[Epoch 33/200] [Batch 244/637] [D loss: 0.214745] [G loss: 0.390665]\n",
      "[Epoch 33/200] [Batch 245/637] [D loss: 0.166536] [G loss: 0.584984]\n",
      "[Epoch 33/200] [Batch 246/637] [D loss: 0.161919] [G loss: 0.580411]\n",
      "[Epoch 33/200] [Batch 247/637] [D loss: 0.152015] [G loss: 0.575754]\n",
      "[Epoch 33/200] [Batch 248/637] [D loss: 0.179404] [G loss: 0.470909]\n",
      "[Epoch 33/200] [Batch 249/637] [D loss: 0.167748] [G loss: 0.444269]\n",
      "[Epoch 33/200] [Batch 250/637] [D loss: 0.137976] [G loss: 0.475308]\n",
      "[Epoch 33/200] [Batch 251/637] [D loss: 0.182652] [G loss: 0.482340]\n",
      "[Epoch 33/200] [Batch 252/637] [D loss: 0.160466] [G loss: 0.536630]\n",
      "[Epoch 33/200] [Batch 253/637] [D loss: 0.163007] [G loss: 0.533993]\n",
      "[Epoch 33/200] [Batch 254/637] [D loss: 0.186934] [G loss: 0.405100]\n",
      "[Epoch 33/200] [Batch 255/637] [D loss: 0.166824] [G loss: 0.442537]\n",
      "[Epoch 33/200] [Batch 256/637] [D loss: 0.175325] [G loss: 0.529359]\n",
      "[Epoch 33/200] [Batch 257/637] [D loss: 0.165035] [G loss: 0.477462]\n",
      "[Epoch 33/200] [Batch 258/637] [D loss: 0.202937] [G loss: 0.480059]\n",
      "[Epoch 33/200] [Batch 259/637] [D loss: 0.164069] [G loss: 0.538792]\n",
      "[Epoch 33/200] [Batch 260/637] [D loss: 0.164731] [G loss: 0.525545]\n",
      "[Epoch 33/200] [Batch 261/637] [D loss: 0.189066] [G loss: 0.441916]\n",
      "[Epoch 33/200] [Batch 262/637] [D loss: 0.164304] [G loss: 0.495620]\n",
      "[Epoch 33/200] [Batch 263/637] [D loss: 0.185665] [G loss: 0.463055]\n",
      "[Epoch 33/200] [Batch 264/637] [D loss: 0.166742] [G loss: 0.499139]\n",
      "[Epoch 33/200] [Batch 265/637] [D loss: 0.164320] [G loss: 0.460918]\n",
      "[Epoch 33/200] [Batch 266/637] [D loss: 0.196739] [G loss: 0.447141]\n",
      "[Epoch 33/200] [Batch 267/637] [D loss: 0.172814] [G loss: 0.540480]\n",
      "[Epoch 33/200] [Batch 268/637] [D loss: 0.172000] [G loss: 0.606760]\n",
      "[Epoch 33/200] [Batch 269/637] [D loss: 0.204490] [G loss: 0.440991]\n",
      "[Epoch 33/200] [Batch 270/637] [D loss: 0.171135] [G loss: 0.584476]\n",
      "[Epoch 33/200] [Batch 271/637] [D loss: 0.221229] [G loss: 0.456900]\n",
      "[Epoch 33/200] [Batch 272/637] [D loss: 0.168599] [G loss: 0.498455]\n",
      "[Epoch 33/200] [Batch 273/637] [D loss: 0.169094] [G loss: 0.464035]\n",
      "[Epoch 33/200] [Batch 274/637] [D loss: 0.166693] [G loss: 0.475946]\n",
      "[Epoch 33/200] [Batch 275/637] [D loss: 0.172437] [G loss: 0.499938]\n",
      "[Epoch 33/200] [Batch 276/637] [D loss: 0.163235] [G loss: 0.501116]\n",
      "[Epoch 33/200] [Batch 277/637] [D loss: 0.171916] [G loss: 0.563211]\n",
      "[Epoch 33/200] [Batch 278/637] [D loss: 0.159518] [G loss: 0.477820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/200] [Batch 279/637] [D loss: 0.184094] [G loss: 0.491371]\n",
      "[Epoch 33/200] [Batch 280/637] [D loss: 0.155492] [G loss: 0.493097]\n",
      "[Epoch 33/200] [Batch 281/637] [D loss: 0.187508] [G loss: 0.416209]\n",
      "[Epoch 33/200] [Batch 282/637] [D loss: 0.161195] [G loss: 0.556353]\n",
      "[Epoch 33/200] [Batch 283/637] [D loss: 0.164116] [G loss: 0.545740]\n",
      "[Epoch 33/200] [Batch 284/637] [D loss: 0.194192] [G loss: 0.507768]\n",
      "[Epoch 33/200] [Batch 285/637] [D loss: 0.165489] [G loss: 0.449903]\n",
      "[Epoch 33/200] [Batch 286/637] [D loss: 0.192542] [G loss: 0.418397]\n",
      "[Epoch 33/200] [Batch 287/637] [D loss: 0.183283] [G loss: 0.444905]\n",
      "[Epoch 33/200] [Batch 288/637] [D loss: 0.170483] [G loss: 0.518470]\n",
      "[Epoch 33/200] [Batch 289/637] [D loss: 0.219071] [G loss: 0.409137]\n",
      "[Epoch 33/200] [Batch 290/637] [D loss: 0.149147] [G loss: 0.500270]\n",
      "[Epoch 33/200] [Batch 291/637] [D loss: 0.189135] [G loss: 0.426141]\n",
      "[Epoch 33/200] [Batch 292/637] [D loss: 0.168475] [G loss: 0.478233]\n",
      "[Epoch 33/200] [Batch 293/637] [D loss: 0.176716] [G loss: 0.504471]\n",
      "[Epoch 33/200] [Batch 294/637] [D loss: 0.189678] [G loss: 0.412310]\n",
      "[Epoch 33/200] [Batch 295/637] [D loss: 0.190875] [G loss: 0.441479]\n",
      "[Epoch 33/200] [Batch 296/637] [D loss: 0.179169] [G loss: 0.547728]\n",
      "[Epoch 33/200] [Batch 297/637] [D loss: 0.168620] [G loss: 0.478975]\n",
      "[Epoch 33/200] [Batch 298/637] [D loss: 0.182906] [G loss: 0.462961]\n",
      "[Epoch 33/200] [Batch 299/637] [D loss: 0.167977] [G loss: 0.472318]\n",
      "[Epoch 33/200] [Batch 300/637] [D loss: 0.175232] [G loss: 0.466244]\n",
      "[Epoch 33/200] [Batch 301/637] [D loss: 0.151352] [G loss: 0.535116]\n",
      "[Epoch 33/200] [Batch 302/637] [D loss: 0.152706] [G loss: 0.507260]\n",
      "[Epoch 33/200] [Batch 303/637] [D loss: 0.160043] [G loss: 0.469656]\n",
      "[Epoch 33/200] [Batch 304/637] [D loss: 0.152455] [G loss: 0.508675]\n",
      "[Epoch 33/200] [Batch 305/637] [D loss: 0.178394] [G loss: 0.480713]\n",
      "[Epoch 33/200] [Batch 306/637] [D loss: 0.178809] [G loss: 0.499249]\n",
      "[Epoch 33/200] [Batch 307/637] [D loss: 0.163126] [G loss: 0.536878]\n",
      "[Epoch 33/200] [Batch 308/637] [D loss: 0.162195] [G loss: 0.572004]\n",
      "[Epoch 33/200] [Batch 309/637] [D loss: 0.193644] [G loss: 0.465898]\n",
      "[Epoch 33/200] [Batch 310/637] [D loss: 0.185280] [G loss: 0.426084]\n",
      "[Epoch 33/200] [Batch 311/637] [D loss: 0.194751] [G loss: 0.449137]\n",
      "[Epoch 33/200] [Batch 312/637] [D loss: 0.194091] [G loss: 0.435114]\n",
      "[Epoch 33/200] [Batch 313/637] [D loss: 0.172236] [G loss: 0.531900]\n",
      "[Epoch 33/200] [Batch 314/637] [D loss: 0.170683] [G loss: 0.454670]\n",
      "[Epoch 33/200] [Batch 315/637] [D loss: 0.219956] [G loss: 0.350033]\n",
      "[Epoch 33/200] [Batch 316/637] [D loss: 0.167753] [G loss: 0.499482]\n",
      "[Epoch 33/200] [Batch 317/637] [D loss: 0.158174] [G loss: 0.559760]\n",
      "[Epoch 33/200] [Batch 318/637] [D loss: 0.165339] [G loss: 0.490463]\n",
      "[Epoch 33/200] [Batch 319/637] [D loss: 0.163095] [G loss: 0.410276]\n",
      "[Epoch 33/200] [Batch 320/637] [D loss: 0.183657] [G loss: 0.420748]\n",
      "[Epoch 33/200] [Batch 321/637] [D loss: 0.168263] [G loss: 0.586941]\n",
      "[Epoch 33/200] [Batch 322/637] [D loss: 0.144004] [G loss: 0.567614]\n",
      "[Epoch 33/200] [Batch 323/637] [D loss: 0.172136] [G loss: 0.501673]\n",
      "[Epoch 33/200] [Batch 324/637] [D loss: 0.180022] [G loss: 0.527026]\n",
      "[Epoch 33/200] [Batch 325/637] [D loss: 0.157883] [G loss: 0.544757]\n",
      "[Epoch 33/200] [Batch 326/637] [D loss: 0.194941] [G loss: 0.497150]\n",
      "[Epoch 33/200] [Batch 327/637] [D loss: 0.162741] [G loss: 0.476701]\n",
      "[Epoch 33/200] [Batch 328/637] [D loss: 0.180604] [G loss: 0.451796]\n",
      "[Epoch 33/200] [Batch 329/637] [D loss: 0.175605] [G loss: 0.445919]\n",
      "[Epoch 33/200] [Batch 330/637] [D loss: 0.162789] [G loss: 0.463483]\n",
      "[Epoch 33/200] [Batch 331/637] [D loss: 0.201852] [G loss: 0.528412]\n",
      "[Epoch 33/200] [Batch 332/637] [D loss: 0.157883] [G loss: 0.543770]\n",
      "[Epoch 33/200] [Batch 333/637] [D loss: 0.149702] [G loss: 0.450128]\n",
      "[Epoch 33/200] [Batch 334/637] [D loss: 0.183272] [G loss: 0.444802]\n",
      "[Epoch 33/200] [Batch 335/637] [D loss: 0.159419] [G loss: 0.514848]\n",
      "[Epoch 33/200] [Batch 336/637] [D loss: 0.169804] [G loss: 0.583812]\n",
      "[Epoch 33/200] [Batch 337/637] [D loss: 0.166650] [G loss: 0.518625]\n",
      "[Epoch 33/200] [Batch 338/637] [D loss: 0.168122] [G loss: 0.471035]\n",
      "[Epoch 33/200] [Batch 339/637] [D loss: 0.185619] [G loss: 0.438999]\n",
      "[Epoch 33/200] [Batch 340/637] [D loss: 0.182691] [G loss: 0.505241]\n",
      "[Epoch 33/200] [Batch 341/637] [D loss: 0.170602] [G loss: 0.503523]\n",
      "[Epoch 33/200] [Batch 342/637] [D loss: 0.161801] [G loss: 0.484827]\n",
      "[Epoch 33/200] [Batch 343/637] [D loss: 0.181118] [G loss: 0.490048]\n",
      "[Epoch 33/200] [Batch 344/637] [D loss: 0.181627] [G loss: 0.502163]\n",
      "[Epoch 33/200] [Batch 345/637] [D loss: 0.162681] [G loss: 0.474412]\n",
      "[Epoch 33/200] [Batch 346/637] [D loss: 0.162379] [G loss: 0.451010]\n",
      "[Epoch 33/200] [Batch 347/637] [D loss: 0.177447] [G loss: 0.443862]\n",
      "[Epoch 33/200] [Batch 348/637] [D loss: 0.167174] [G loss: 0.486374]\n",
      "[Epoch 33/200] [Batch 349/637] [D loss: 0.152946] [G loss: 0.528258]\n",
      "[Epoch 33/200] [Batch 350/637] [D loss: 0.166657] [G loss: 0.474541]\n",
      "[Epoch 33/200] [Batch 351/637] [D loss: 0.165230] [G loss: 0.554680]\n",
      "[Epoch 33/200] [Batch 352/637] [D loss: 0.163007] [G loss: 0.487449]\n",
      "[Epoch 33/200] [Batch 353/637] [D loss: 0.171513] [G loss: 0.477173]\n",
      "[Epoch 33/200] [Batch 354/637] [D loss: 0.163753] [G loss: 0.484446]\n",
      "[Epoch 33/200] [Batch 355/637] [D loss: 0.198712] [G loss: 0.455263]\n",
      "[Epoch 33/200] [Batch 356/637] [D loss: 0.168496] [G loss: 0.433710]\n",
      "[Epoch 33/200] [Batch 357/637] [D loss: 0.158592] [G loss: 0.449860]\n",
      "[Epoch 33/200] [Batch 358/637] [D loss: 0.162564] [G loss: 0.472152]\n",
      "[Epoch 33/200] [Batch 359/637] [D loss: 0.181819] [G loss: 0.411529]\n",
      "[Epoch 33/200] [Batch 360/637] [D loss: 0.171263] [G loss: 0.446249]\n",
      "[Epoch 33/200] [Batch 361/637] [D loss: 0.173053] [G loss: 0.472199]\n",
      "[Epoch 33/200] [Batch 362/637] [D loss: 0.158653] [G loss: 0.483813]\n",
      "[Epoch 33/200] [Batch 363/637] [D loss: 0.162591] [G loss: 0.500922]\n",
      "[Epoch 33/200] [Batch 364/637] [D loss: 0.150198] [G loss: 0.536788]\n",
      "[Epoch 33/200] [Batch 365/637] [D loss: 0.151928] [G loss: 0.517557]\n",
      "[Epoch 33/200] [Batch 366/637] [D loss: 0.167151] [G loss: 0.457900]\n",
      "[Epoch 33/200] [Batch 367/637] [D loss: 0.151143] [G loss: 0.489738]\n",
      "[Epoch 33/200] [Batch 368/637] [D loss: 0.178088] [G loss: 0.481571]\n",
      "[Epoch 33/200] [Batch 369/637] [D loss: 0.167027] [G loss: 0.536409]\n",
      "[Epoch 33/200] [Batch 370/637] [D loss: 0.183237] [G loss: 0.446520]\n",
      "[Epoch 33/200] [Batch 371/637] [D loss: 0.176781] [G loss: 0.441975]\n",
      "[Epoch 33/200] [Batch 372/637] [D loss: 0.190738] [G loss: 0.444691]\n",
      "[Epoch 33/200] [Batch 373/637] [D loss: 0.225392] [G loss: 0.483335]\n",
      "[Epoch 33/200] [Batch 374/637] [D loss: 0.183560] [G loss: 0.553789]\n",
      "[Epoch 33/200] [Batch 375/637] [D loss: 0.187854] [G loss: 0.526040]\n",
      "[Epoch 33/200] [Batch 376/637] [D loss: 0.190614] [G loss: 0.400987]\n",
      "[Epoch 33/200] [Batch 377/637] [D loss: 0.179508] [G loss: 0.414538]\n",
      "[Epoch 33/200] [Batch 378/637] [D loss: 0.171536] [G loss: 0.485611]\n",
      "[Epoch 33/200] [Batch 379/637] [D loss: 0.164553] [G loss: 0.487514]\n",
      "[Epoch 33/200] [Batch 380/637] [D loss: 0.156724] [G loss: 0.518554]\n",
      "[Epoch 33/200] [Batch 381/637] [D loss: 0.163108] [G loss: 0.525035]\n",
      "[Epoch 33/200] [Batch 382/637] [D loss: 0.194049] [G loss: 0.517197]\n",
      "[Epoch 33/200] [Batch 383/637] [D loss: 0.163389] [G loss: 0.471464]\n",
      "[Epoch 33/200] [Batch 384/637] [D loss: 0.167857] [G loss: 0.523562]\n",
      "[Epoch 33/200] [Batch 385/637] [D loss: 0.182202] [G loss: 0.484807]\n",
      "[Epoch 33/200] [Batch 386/637] [D loss: 0.165674] [G loss: 0.492797]\n",
      "[Epoch 33/200] [Batch 387/637] [D loss: 0.166874] [G loss: 0.507704]\n",
      "[Epoch 33/200] [Batch 388/637] [D loss: 0.184998] [G loss: 0.523142]\n",
      "[Epoch 33/200] [Batch 389/637] [D loss: 0.193119] [G loss: 0.472476]\n",
      "[Epoch 33/200] [Batch 390/637] [D loss: 0.193111] [G loss: 0.437268]\n",
      "[Epoch 33/200] [Batch 391/637] [D loss: 0.200960] [G loss: 0.429813]\n",
      "[Epoch 33/200] [Batch 392/637] [D loss: 0.186751] [G loss: 0.541452]\n",
      "[Epoch 33/200] [Batch 393/637] [D loss: 0.171893] [G loss: 0.531743]\n",
      "[Epoch 33/200] [Batch 394/637] [D loss: 0.161146] [G loss: 0.473774]\n",
      "[Epoch 33/200] [Batch 395/637] [D loss: 0.168519] [G loss: 0.460022]\n",
      "[Epoch 33/200] [Batch 396/637] [D loss: 0.177025] [G loss: 0.449261]\n",
      "[Epoch 33/200] [Batch 397/637] [D loss: 0.186945] [G loss: 0.423745]\n",
      "[Epoch 33/200] [Batch 398/637] [D loss: 0.160736] [G loss: 0.520645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/200] [Batch 399/637] [D loss: 0.184064] [G loss: 0.477253]\n",
      "[Epoch 33/200] [Batch 400/637] [D loss: 0.160380] [G loss: 0.506983]\n",
      "[Epoch 33/200] [Batch 401/637] [D loss: 0.166999] [G loss: 0.537190]\n",
      "[Epoch 33/200] [Batch 402/637] [D loss: 0.160104] [G loss: 0.532731]\n",
      "[Epoch 33/200] [Batch 403/637] [D loss: 0.161116] [G loss: 0.459315]\n",
      "[Epoch 33/200] [Batch 404/637] [D loss: 0.169860] [G loss: 0.447935]\n",
      "[Epoch 33/200] [Batch 405/637] [D loss: 0.163214] [G loss: 0.574482]\n",
      "[Epoch 33/200] [Batch 406/637] [D loss: 0.161868] [G loss: 0.605442]\n",
      "[Epoch 33/200] [Batch 407/637] [D loss: 0.156087] [G loss: 0.503823]\n",
      "[Epoch 33/200] [Batch 408/637] [D loss: 0.153764] [G loss: 0.517147]\n",
      "[Epoch 33/200] [Batch 409/637] [D loss: 0.183843] [G loss: 0.432888]\n",
      "[Epoch 33/200] [Batch 410/637] [D loss: 0.224049] [G loss: 0.534040]\n",
      "[Epoch 33/200] [Batch 411/637] [D loss: 0.187133] [G loss: 0.548625]\n",
      "[Epoch 33/200] [Batch 412/637] [D loss: 0.184785] [G loss: 0.536012]\n",
      "[Epoch 33/200] [Batch 413/637] [D loss: 0.185035] [G loss: 0.462962]\n",
      "[Epoch 33/200] [Batch 414/637] [D loss: 0.158456] [G loss: 0.484574]\n",
      "[Epoch 33/200] [Batch 415/637] [D loss: 0.159023] [G loss: 0.476558]\n",
      "[Epoch 33/200] [Batch 416/637] [D loss: 0.163087] [G loss: 0.476471]\n",
      "[Epoch 33/200] [Batch 417/637] [D loss: 0.174866] [G loss: 0.540503]\n",
      "[Epoch 33/200] [Batch 418/637] [D loss: 0.180194] [G loss: 0.548492]\n",
      "[Epoch 33/200] [Batch 419/637] [D loss: 0.181694] [G loss: 0.497949]\n",
      "[Epoch 33/200] [Batch 420/637] [D loss: 0.156916] [G loss: 0.479801]\n",
      "[Epoch 33/200] [Batch 421/637] [D loss: 0.180190] [G loss: 0.480606]\n",
      "[Epoch 33/200] [Batch 422/637] [D loss: 0.170678] [G loss: 0.472422]\n",
      "[Epoch 33/200] [Batch 423/637] [D loss: 0.150548] [G loss: 0.443291]\n",
      "[Epoch 33/200] [Batch 424/637] [D loss: 0.139325] [G loss: 0.547026]\n",
      "[Epoch 33/200] [Batch 425/637] [D loss: 0.173965] [G loss: 0.553895]\n",
      "[Epoch 33/200] [Batch 426/637] [D loss: 0.156250] [G loss: 0.551680]\n",
      "[Epoch 33/200] [Batch 427/637] [D loss: 0.185484] [G loss: 0.494439]\n",
      "[Epoch 33/200] [Batch 428/637] [D loss: 0.193795] [G loss: 0.452354]\n",
      "[Epoch 33/200] [Batch 429/637] [D loss: 0.175301] [G loss: 0.467714]\n",
      "[Epoch 33/200] [Batch 430/637] [D loss: 0.175926] [G loss: 0.483025]\n",
      "[Epoch 33/200] [Batch 431/637] [D loss: 0.162668] [G loss: 0.439851]\n",
      "[Epoch 33/200] [Batch 432/637] [D loss: 0.175813] [G loss: 0.457347]\n",
      "[Epoch 33/200] [Batch 433/637] [D loss: 0.176075] [G loss: 0.436032]\n",
      "[Epoch 33/200] [Batch 434/637] [D loss: 0.164071] [G loss: 0.458609]\n",
      "[Epoch 33/200] [Batch 435/637] [D loss: 0.204018] [G loss: 0.412034]\n",
      "[Epoch 33/200] [Batch 436/637] [D loss: 0.171352] [G loss: 0.489270]\n",
      "[Epoch 33/200] [Batch 437/637] [D loss: 0.161981] [G loss: 0.474152]\n",
      "[Epoch 33/200] [Batch 438/637] [D loss: 0.178798] [G loss: 0.433000]\n",
      "[Epoch 33/200] [Batch 439/637] [D loss: 0.164785] [G loss: 0.459502]\n",
      "[Epoch 33/200] [Batch 440/637] [D loss: 0.164442] [G loss: 0.473484]\n",
      "[Epoch 33/200] [Batch 441/637] [D loss: 0.149503] [G loss: 0.482034]\n",
      "[Epoch 33/200] [Batch 442/637] [D loss: 0.171366] [G loss: 0.467228]\n",
      "[Epoch 33/200] [Batch 443/637] [D loss: 0.215296] [G loss: 0.446478]\n",
      "[Epoch 33/200] [Batch 444/637] [D loss: 0.176980] [G loss: 0.469706]\n",
      "[Epoch 33/200] [Batch 445/637] [D loss: 0.185350] [G loss: 0.440836]\n",
      "[Epoch 33/200] [Batch 446/637] [D loss: 0.175747] [G loss: 0.420038]\n",
      "[Epoch 33/200] [Batch 447/637] [D loss: 0.184397] [G loss: 0.397556]\n",
      "[Epoch 33/200] [Batch 448/637] [D loss: 0.176338] [G loss: 0.429650]\n",
      "[Epoch 33/200] [Batch 449/637] [D loss: 0.191038] [G loss: 0.432622]\n",
      "[Epoch 33/200] [Batch 450/637] [D loss: 0.198922] [G loss: 0.450112]\n",
      "[Epoch 33/200] [Batch 451/637] [D loss: 0.172372] [G loss: 0.533594]\n",
      "[Epoch 33/200] [Batch 452/637] [D loss: 0.194075] [G loss: 0.422182]\n",
      "[Epoch 33/200] [Batch 453/637] [D loss: 0.193021] [G loss: 0.397916]\n",
      "[Epoch 33/200] [Batch 454/637] [D loss: 0.194176] [G loss: 0.451385]\n",
      "[Epoch 33/200] [Batch 455/637] [D loss: 0.159679] [G loss: 0.556565]\n",
      "[Epoch 33/200] [Batch 456/637] [D loss: 0.160259] [G loss: 0.517520]\n",
      "[Epoch 33/200] [Batch 457/637] [D loss: 0.169857] [G loss: 0.443852]\n",
      "[Epoch 33/200] [Batch 458/637] [D loss: 0.176219] [G loss: 0.487600]\n",
      "[Epoch 33/200] [Batch 459/637] [D loss: 0.150051] [G loss: 0.422378]\n",
      "[Epoch 33/200] [Batch 460/637] [D loss: 0.147709] [G loss: 0.496016]\n",
      "[Epoch 33/200] [Batch 461/637] [D loss: 0.167917] [G loss: 0.514096]\n",
      "[Epoch 33/200] [Batch 462/637] [D loss: 0.171361] [G loss: 0.562636]\n",
      "[Epoch 33/200] [Batch 463/637] [D loss: 0.153071] [G loss: 0.603377]\n",
      "[Epoch 33/200] [Batch 464/637] [D loss: 0.184296] [G loss: 0.534549]\n",
      "[Epoch 33/200] [Batch 465/637] [D loss: 0.184261] [G loss: 0.454645]\n",
      "[Epoch 33/200] [Batch 466/637] [D loss: 0.184669] [G loss: 0.534582]\n",
      "[Epoch 33/200] [Batch 467/637] [D loss: 0.157170] [G loss: 0.537098]\n",
      "[Epoch 33/200] [Batch 468/637] [D loss: 0.171893] [G loss: 0.524403]\n",
      "[Epoch 33/200] [Batch 469/637] [D loss: 0.164637] [G loss: 0.475466]\n",
      "[Epoch 33/200] [Batch 470/637] [D loss: 0.160392] [G loss: 0.537031]\n",
      "[Epoch 33/200] [Batch 471/637] [D loss: 0.161315] [G loss: 0.505757]\n",
      "[Epoch 33/200] [Batch 472/637] [D loss: 0.170811] [G loss: 0.493640]\n",
      "[Epoch 33/200] [Batch 473/637] [D loss: 0.181140] [G loss: 0.476383]\n",
      "[Epoch 33/200] [Batch 474/637] [D loss: 0.162982] [G loss: 0.468323]\n",
      "[Epoch 33/200] [Batch 475/637] [D loss: 0.197044] [G loss: 0.439609]\n",
      "[Epoch 33/200] [Batch 476/637] [D loss: 0.174631] [G loss: 0.458491]\n",
      "[Epoch 33/200] [Batch 477/637] [D loss: 0.166796] [G loss: 0.509287]\n",
      "[Epoch 33/200] [Batch 478/637] [D loss: 0.157406] [G loss: 0.502478]\n",
      "[Epoch 33/200] [Batch 479/637] [D loss: 0.146925] [G loss: 0.559806]\n",
      "[Epoch 33/200] [Batch 480/637] [D loss: 0.152224] [G loss: 0.558497]\n",
      "[Epoch 33/200] [Batch 481/637] [D loss: 0.148509] [G loss: 0.500299]\n",
      "[Epoch 33/200] [Batch 482/637] [D loss: 0.148326] [G loss: 0.493597]\n",
      "[Epoch 33/200] [Batch 483/637] [D loss: 0.156914] [G loss: 0.521389]\n",
      "[Epoch 33/200] [Batch 484/637] [D loss: 0.178773] [G loss: 0.554476]\n",
      "[Epoch 33/200] [Batch 485/637] [D loss: 0.177861] [G loss: 0.442634]\n",
      "[Epoch 33/200] [Batch 486/637] [D loss: 0.185089] [G loss: 0.450377]\n",
      "[Epoch 33/200] [Batch 487/637] [D loss: 0.191442] [G loss: 0.501996]\n",
      "[Epoch 33/200] [Batch 488/637] [D loss: 0.179008] [G loss: 0.522750]\n",
      "[Epoch 33/200] [Batch 489/637] [D loss: 0.167445] [G loss: 0.525554]\n",
      "[Epoch 33/200] [Batch 490/637] [D loss: 0.166130] [G loss: 0.466652]\n",
      "[Epoch 33/200] [Batch 491/637] [D loss: 0.177036] [G loss: 0.460921]\n",
      "[Epoch 33/200] [Batch 492/637] [D loss: 0.165120] [G loss: 0.482034]\n",
      "[Epoch 33/200] [Batch 493/637] [D loss: 0.135201] [G loss: 0.524057]\n",
      "[Epoch 33/200] [Batch 494/637] [D loss: 0.173771] [G loss: 0.497310]\n",
      "[Epoch 33/200] [Batch 495/637] [D loss: 0.174242] [G loss: 0.462022]\n",
      "[Epoch 33/200] [Batch 496/637] [D loss: 0.163415] [G loss: 0.497994]\n",
      "[Epoch 33/200] [Batch 497/637] [D loss: 0.181275] [G loss: 0.519881]\n",
      "[Epoch 33/200] [Batch 498/637] [D loss: 0.160575] [G loss: 0.505840]\n",
      "[Epoch 33/200] [Batch 499/637] [D loss: 0.172464] [G loss: 0.406169]\n",
      "[Epoch 33/200] [Batch 500/637] [D loss: 0.155738] [G loss: 0.484434]\n",
      "[Epoch 33/200] [Batch 501/637] [D loss: 0.159575] [G loss: 0.482371]\n",
      "[Epoch 33/200] [Batch 502/637] [D loss: 0.158964] [G loss: 0.506605]\n",
      "[Epoch 33/200] [Batch 503/637] [D loss: 0.156142] [G loss: 0.521650]\n",
      "[Epoch 33/200] [Batch 504/637] [D loss: 0.165926] [G loss: 0.454858]\n",
      "[Epoch 33/200] [Batch 505/637] [D loss: 0.176456] [G loss: 0.528593]\n",
      "[Epoch 33/200] [Batch 506/637] [D loss: 0.147177] [G loss: 0.538150]\n",
      "[Epoch 33/200] [Batch 507/637] [D loss: 0.146385] [G loss: 0.539357]\n",
      "[Epoch 33/200] [Batch 508/637] [D loss: 0.188842] [G loss: 0.512718]\n",
      "[Epoch 33/200] [Batch 509/637] [D loss: 0.166965] [G loss: 0.511190]\n",
      "[Epoch 33/200] [Batch 510/637] [D loss: 0.199505] [G loss: 0.465192]\n",
      "[Epoch 33/200] [Batch 511/637] [D loss: 0.184313] [G loss: 0.509945]\n",
      "[Epoch 33/200] [Batch 512/637] [D loss: 0.156748] [G loss: 0.488192]\n",
      "[Epoch 33/200] [Batch 513/637] [D loss: 0.194445] [G loss: 0.466722]\n",
      "[Epoch 33/200] [Batch 514/637] [D loss: 0.197313] [G loss: 0.489316]\n",
      "[Epoch 33/200] [Batch 515/637] [D loss: 0.158971] [G loss: 0.534600]\n",
      "[Epoch 33/200] [Batch 516/637] [D loss: 0.164382] [G loss: 0.493967]\n",
      "[Epoch 33/200] [Batch 517/637] [D loss: 0.165598] [G loss: 0.477042]\n",
      "[Epoch 33/200] [Batch 518/637] [D loss: 0.165679] [G loss: 0.435123]\n",
      "[Epoch 33/200] [Batch 519/637] [D loss: 0.167074] [G loss: 0.483746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/200] [Batch 520/637] [D loss: 0.155689] [G loss: 0.524268]\n",
      "[Epoch 33/200] [Batch 521/637] [D loss: 0.187831] [G loss: 0.437118]\n",
      "[Epoch 33/200] [Batch 522/637] [D loss: 0.151046] [G loss: 0.590733]\n",
      "[Epoch 33/200] [Batch 523/637] [D loss: 0.159883] [G loss: 0.534631]\n",
      "[Epoch 33/200] [Batch 524/637] [D loss: 0.206723] [G loss: 0.426867]\n",
      "[Epoch 33/200] [Batch 525/637] [D loss: 0.182904] [G loss: 0.425034]\n",
      "[Epoch 33/200] [Batch 526/637] [D loss: 0.173649] [G loss: 0.475160]\n",
      "[Epoch 33/200] [Batch 527/637] [D loss: 0.183757] [G loss: 0.439539]\n",
      "[Epoch 33/200] [Batch 528/637] [D loss: 0.167935] [G loss: 0.502947]\n",
      "[Epoch 33/200] [Batch 529/637] [D loss: 0.161513] [G loss: 0.499662]\n",
      "[Epoch 33/200] [Batch 530/637] [D loss: 0.163566] [G loss: 0.477690]\n",
      "[Epoch 33/200] [Batch 531/637] [D loss: 0.169971] [G loss: 0.479004]\n",
      "[Epoch 33/200] [Batch 532/637] [D loss: 0.156836] [G loss: 0.556693]\n",
      "[Epoch 33/200] [Batch 533/637] [D loss: 0.187590] [G loss: 0.471089]\n",
      "[Epoch 33/200] [Batch 534/637] [D loss: 0.181533] [G loss: 0.597582]\n",
      "[Epoch 33/200] [Batch 535/637] [D loss: 0.186015] [G loss: 0.480152]\n",
      "[Epoch 33/200] [Batch 536/637] [D loss: 0.175155] [G loss: 0.507027]\n",
      "[Epoch 33/200] [Batch 537/637] [D loss: 0.182024] [G loss: 0.491258]\n",
      "[Epoch 33/200] [Batch 538/637] [D loss: 0.158011] [G loss: 0.483311]\n",
      "[Epoch 33/200] [Batch 539/637] [D loss: 0.161084] [G loss: 0.478438]\n",
      "[Epoch 33/200] [Batch 540/637] [D loss: 0.164223] [G loss: 0.502482]\n",
      "[Epoch 33/200] [Batch 541/637] [D loss: 0.154970] [G loss: 0.493004]\n",
      "[Epoch 33/200] [Batch 542/637] [D loss: 0.173389] [G loss: 0.532324]\n",
      "[Epoch 33/200] [Batch 543/637] [D loss: 0.178930] [G loss: 0.590439]\n",
      "[Epoch 33/200] [Batch 544/637] [D loss: 0.154604] [G loss: 0.503397]\n",
      "[Epoch 33/200] [Batch 545/637] [D loss: 0.185706] [G loss: 0.455398]\n",
      "[Epoch 33/200] [Batch 546/637] [D loss: 0.174474] [G loss: 0.453600]\n",
      "[Epoch 33/200] [Batch 547/637] [D loss: 0.139749] [G loss: 0.523003]\n",
      "[Epoch 33/200] [Batch 548/637] [D loss: 0.187413] [G loss: 0.442392]\n",
      "[Epoch 33/200] [Batch 549/637] [D loss: 0.159065] [G loss: 0.517342]\n",
      "[Epoch 33/200] [Batch 550/637] [D loss: 0.156376] [G loss: 0.506038]\n",
      "[Epoch 33/200] [Batch 551/637] [D loss: 0.179868] [G loss: 0.466407]\n",
      "[Epoch 33/200] [Batch 552/637] [D loss: 0.151244] [G loss: 0.488850]\n",
      "[Epoch 33/200] [Batch 553/637] [D loss: 0.176308] [G loss: 0.524240]\n",
      "[Epoch 33/200] [Batch 554/637] [D loss: 0.168421] [G loss: 0.537218]\n",
      "[Epoch 33/200] [Batch 555/637] [D loss: 0.177863] [G loss: 0.488603]\n",
      "[Epoch 33/200] [Batch 556/637] [D loss: 0.180066] [G loss: 0.471984]\n",
      "[Epoch 33/200] [Batch 557/637] [D loss: 0.159224] [G loss: 0.446172]\n",
      "[Epoch 33/200] [Batch 558/637] [D loss: 0.142429] [G loss: 0.494271]\n",
      "[Epoch 33/200] [Batch 559/637] [D loss: 0.175119] [G loss: 0.449565]\n",
      "[Epoch 33/200] [Batch 560/637] [D loss: 0.174043] [G loss: 0.497684]\n",
      "[Epoch 33/200] [Batch 561/637] [D loss: 0.171362] [G loss: 0.482480]\n",
      "[Epoch 33/200] [Batch 562/637] [D loss: 0.159179] [G loss: 0.553834]\n",
      "[Epoch 33/200] [Batch 563/637] [D loss: 0.150692] [G loss: 0.511475]\n",
      "[Epoch 33/200] [Batch 564/637] [D loss: 0.164211] [G loss: 0.523257]\n",
      "[Epoch 33/200] [Batch 565/637] [D loss: 0.166995] [G loss: 0.468415]\n",
      "[Epoch 33/200] [Batch 566/637] [D loss: 0.160058] [G loss: 0.495232]\n",
      "[Epoch 33/200] [Batch 567/637] [D loss: 0.171219] [G loss: 0.555556]\n",
      "[Epoch 33/200] [Batch 568/637] [D loss: 0.157527] [G loss: 0.550433]\n",
      "[Epoch 33/200] [Batch 569/637] [D loss: 0.179646] [G loss: 0.513143]\n",
      "[Epoch 33/200] [Batch 570/637] [D loss: 0.163833] [G loss: 0.476995]\n",
      "[Epoch 33/200] [Batch 571/637] [D loss: 0.168714] [G loss: 0.517583]\n",
      "[Epoch 33/200] [Batch 572/637] [D loss: 0.160297] [G loss: 0.474548]\n",
      "[Epoch 33/200] [Batch 573/637] [D loss: 0.168112] [G loss: 0.462822]\n",
      "[Epoch 33/200] [Batch 574/637] [D loss: 0.152784] [G loss: 0.516703]\n",
      "[Epoch 33/200] [Batch 575/637] [D loss: 0.168983] [G loss: 0.501645]\n",
      "[Epoch 33/200] [Batch 576/637] [D loss: 0.178860] [G loss: 0.495897]\n",
      "[Epoch 33/200] [Batch 577/637] [D loss: 0.160948] [G loss: 0.492008]\n",
      "[Epoch 33/200] [Batch 578/637] [D loss: 0.173221] [G loss: 0.499704]\n",
      "[Epoch 33/200] [Batch 579/637] [D loss: 0.181642] [G loss: 0.471325]\n",
      "[Epoch 33/200] [Batch 580/637] [D loss: 0.172940] [G loss: 0.508908]\n",
      "[Epoch 33/200] [Batch 581/637] [D loss: 0.169246] [G loss: 0.467778]\n",
      "[Epoch 33/200] [Batch 582/637] [D loss: 0.190085] [G loss: 0.389041]\n",
      "[Epoch 33/200] [Batch 583/637] [D loss: 0.162483] [G loss: 0.453888]\n",
      "[Epoch 33/200] [Batch 584/637] [D loss: 0.168486] [G loss: 0.436446]\n",
      "[Epoch 33/200] [Batch 585/637] [D loss: 0.174146] [G loss: 0.507732]\n",
      "[Epoch 33/200] [Batch 586/637] [D loss: 0.173859] [G loss: 0.553286]\n",
      "[Epoch 33/200] [Batch 587/637] [D loss: 0.164566] [G loss: 0.542727]\n",
      "[Epoch 33/200] [Batch 588/637] [D loss: 0.148555] [G loss: 0.556207]\n",
      "[Epoch 33/200] [Batch 589/637] [D loss: 0.158445] [G loss: 0.514162]\n",
      "[Epoch 33/200] [Batch 590/637] [D loss: 0.165694] [G loss: 0.422398]\n",
      "[Epoch 33/200] [Batch 591/637] [D loss: 0.167812] [G loss: 0.468376]\n",
      "[Epoch 33/200] [Batch 592/637] [D loss: 0.160020] [G loss: 0.537488]\n",
      "[Epoch 33/200] [Batch 593/637] [D loss: 0.184011] [G loss: 0.443146]\n",
      "[Epoch 33/200] [Batch 594/637] [D loss: 0.162497] [G loss: 0.440288]\n",
      "[Epoch 33/200] [Batch 595/637] [D loss: 0.169021] [G loss: 0.535474]\n",
      "[Epoch 33/200] [Batch 596/637] [D loss: 0.173551] [G loss: 0.503258]\n",
      "[Epoch 33/200] [Batch 597/637] [D loss: 0.187939] [G loss: 0.421393]\n",
      "[Epoch 33/200] [Batch 598/637] [D loss: 0.169421] [G loss: 0.469339]\n",
      "[Epoch 33/200] [Batch 599/637] [D loss: 0.165029] [G loss: 0.453255]\n",
      "[Epoch 33/200] [Batch 600/637] [D loss: 0.178615] [G loss: 0.464057]\n",
      "[Epoch 33/200] [Batch 601/637] [D loss: 0.185934] [G loss: 0.566219]\n",
      "[Epoch 33/200] [Batch 602/637] [D loss: 0.186234] [G loss: 0.478454]\n",
      "[Epoch 33/200] [Batch 603/637] [D loss: 0.169341] [G loss: 0.488681]\n",
      "[Epoch 33/200] [Batch 604/637] [D loss: 0.174861] [G loss: 0.447946]\n",
      "[Epoch 33/200] [Batch 605/637] [D loss: 0.175688] [G loss: 0.409734]\n",
      "[Epoch 33/200] [Batch 606/637] [D loss: 0.194438] [G loss: 0.388161]\n",
      "[Epoch 33/200] [Batch 607/637] [D loss: 0.193131] [G loss: 0.396160]\n",
      "[Epoch 33/200] [Batch 608/637] [D loss: 0.188472] [G loss: 0.534034]\n",
      "[Epoch 33/200] [Batch 609/637] [D loss: 0.170679] [G loss: 0.548333]\n",
      "[Epoch 33/200] [Batch 610/637] [D loss: 0.189785] [G loss: 0.566598]\n",
      "[Epoch 33/200] [Batch 611/637] [D loss: 0.159588] [G loss: 0.505653]\n",
      "[Epoch 33/200] [Batch 612/637] [D loss: 0.196353] [G loss: 0.454977]\n",
      "[Epoch 33/200] [Batch 613/637] [D loss: 0.178073] [G loss: 0.420636]\n",
      "[Epoch 33/200] [Batch 614/637] [D loss: 0.165902] [G loss: 0.503326]\n",
      "[Epoch 33/200] [Batch 615/637] [D loss: 0.185059] [G loss: 0.465628]\n",
      "[Epoch 33/200] [Batch 616/637] [D loss: 0.165253] [G loss: 0.491467]\n",
      "[Epoch 33/200] [Batch 617/637] [D loss: 0.154596] [G loss: 0.527053]\n",
      "[Epoch 33/200] [Batch 618/637] [D loss: 0.172524] [G loss: 0.518607]\n",
      "[Epoch 33/200] [Batch 619/637] [D loss: 0.145880] [G loss: 0.485103]\n",
      "[Epoch 33/200] [Batch 620/637] [D loss: 0.174636] [G loss: 0.502901]\n",
      "[Epoch 33/200] [Batch 621/637] [D loss: 0.166276] [G loss: 0.468023]\n",
      "[Epoch 33/200] [Batch 622/637] [D loss: 0.156711] [G loss: 0.515905]\n",
      "[Epoch 33/200] [Batch 623/637] [D loss: 0.176704] [G loss: 0.520769]\n",
      "[Epoch 33/200] [Batch 624/637] [D loss: 0.188540] [G loss: 0.486688]\n",
      "[Epoch 33/200] [Batch 625/637] [D loss: 0.193090] [G loss: 0.415990]\n",
      "[Epoch 33/200] [Batch 626/637] [D loss: 0.173535] [G loss: 0.465075]\n",
      "[Epoch 33/200] [Batch 627/637] [D loss: 0.186832] [G loss: 0.471125]\n",
      "[Epoch 33/200] [Batch 628/637] [D loss: 0.189111] [G loss: 0.453207]\n",
      "[Epoch 33/200] [Batch 629/637] [D loss: 0.188622] [G loss: 0.392552]\n",
      "[Epoch 33/200] [Batch 630/637] [D loss: 0.187717] [G loss: 0.469045]\n",
      "[Epoch 33/200] [Batch 631/637] [D loss: 0.193205] [G loss: 0.510587]\n",
      "[Epoch 33/200] [Batch 632/637] [D loss: 0.195018] [G loss: 0.508166]\n",
      "[Epoch 33/200] [Batch 633/637] [D loss: 0.189963] [G loss: 0.412648]\n",
      "[Epoch 33/200] [Batch 634/637] [D loss: 0.180125] [G loss: 0.476690]\n",
      "[Epoch 33/200] [Batch 635/637] [D loss: 0.210476] [G loss: 0.410042]\n",
      "[Epoch 33/200] [Batch 636/637] [D loss: 0.176685] [G loss: 0.416452]\n",
      "[Epoch 34/200] [Batch 0/637] [D loss: 0.169950] [G loss: 0.500686]\n",
      "[Epoch 34/200] [Batch 1/637] [D loss: 0.174089] [G loss: 0.524840]\n",
      "[Epoch 34/200] [Batch 2/637] [D loss: 0.164338] [G loss: 0.534464]\n",
      "[Epoch 34/200] [Batch 3/637] [D loss: 0.192073] [G loss: 0.482120]\n",
      "[Epoch 34/200] [Batch 4/637] [D loss: 0.148059] [G loss: 0.504409]\n",
      "[Epoch 34/200] [Batch 5/637] [D loss: 0.170078] [G loss: 0.451196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 6/637] [D loss: 0.175569] [G loss: 0.378429]\n",
      "[Epoch 34/200] [Batch 7/637] [D loss: 0.155511] [G loss: 0.516517]\n",
      "[Epoch 34/200] [Batch 8/637] [D loss: 0.163154] [G loss: 0.499833]\n",
      "[Epoch 34/200] [Batch 9/637] [D loss: 0.174134] [G loss: 0.505657]\n",
      "[Epoch 34/200] [Batch 10/637] [D loss: 0.178126] [G loss: 0.445736]\n",
      "[Epoch 34/200] [Batch 11/637] [D loss: 0.174320] [G loss: 0.463761]\n",
      "[Epoch 34/200] [Batch 12/637] [D loss: 0.176081] [G loss: 0.496637]\n",
      "[Epoch 34/200] [Batch 13/637] [D loss: 0.161693] [G loss: 0.499150]\n",
      "[Epoch 34/200] [Batch 14/637] [D loss: 0.177293] [G loss: 0.500874]\n",
      "[Epoch 34/200] [Batch 15/637] [D loss: 0.194277] [G loss: 0.475366]\n",
      "[Epoch 34/200] [Batch 16/637] [D loss: 0.194399] [G loss: 0.479119]\n",
      "[Epoch 34/200] [Batch 17/637] [D loss: 0.197000] [G loss: 0.434573]\n",
      "[Epoch 34/200] [Batch 18/637] [D loss: 0.190134] [G loss: 0.539155]\n",
      "[Epoch 34/200] [Batch 19/637] [D loss: 0.172973] [G loss: 0.486881]\n",
      "[Epoch 34/200] [Batch 20/637] [D loss: 0.205642] [G loss: 0.408818]\n",
      "[Epoch 34/200] [Batch 21/637] [D loss: 0.208829] [G loss: 0.416169]\n",
      "[Epoch 34/200] [Batch 22/637] [D loss: 0.185760] [G loss: 0.561490]\n",
      "[Epoch 34/200] [Batch 23/637] [D loss: 0.171887] [G loss: 0.559390]\n",
      "[Epoch 34/200] [Batch 24/637] [D loss: 0.184634] [G loss: 0.384490]\n",
      "[Epoch 34/200] [Batch 25/637] [D loss: 0.194692] [G loss: 0.455073]\n",
      "[Epoch 34/200] [Batch 26/637] [D loss: 0.164650] [G loss: 0.500477]\n",
      "[Epoch 34/200] [Batch 27/637] [D loss: 0.169465] [G loss: 0.510552]\n",
      "[Epoch 34/200] [Batch 28/637] [D loss: 0.173928] [G loss: 0.474952]\n",
      "[Epoch 34/200] [Batch 29/637] [D loss: 0.153093] [G loss: 0.554877]\n",
      "[Epoch 34/200] [Batch 30/637] [D loss: 0.178775] [G loss: 0.395009]\n",
      "[Epoch 34/200] [Batch 31/637] [D loss: 0.165170] [G loss: 0.536512]\n",
      "[Epoch 34/200] [Batch 32/637] [D loss: 0.189534] [G loss: 0.503918]\n",
      "[Epoch 34/200] [Batch 33/637] [D loss: 0.207739] [G loss: 0.542279]\n",
      "[Epoch 34/200] [Batch 34/637] [D loss: 0.172428] [G loss: 0.542179]\n",
      "[Epoch 34/200] [Batch 35/637] [D loss: 0.171465] [G loss: 0.494213]\n",
      "[Epoch 34/200] [Batch 36/637] [D loss: 0.205544] [G loss: 0.446078]\n",
      "[Epoch 34/200] [Batch 37/637] [D loss: 0.179466] [G loss: 0.497060]\n",
      "[Epoch 34/200] [Batch 38/637] [D loss: 0.195891] [G loss: 0.474002]\n",
      "[Epoch 34/200] [Batch 39/637] [D loss: 0.182093] [G loss: 0.471777]\n",
      "[Epoch 34/200] [Batch 40/637] [D loss: 0.166047] [G loss: 0.606598]\n",
      "[Epoch 34/200] [Batch 41/637] [D loss: 0.160095] [G loss: 0.526649]\n",
      "[Epoch 34/200] [Batch 42/637] [D loss: 0.161735] [G loss: 0.488396]\n",
      "[Epoch 34/200] [Batch 43/637] [D loss: 0.170653] [G loss: 0.437232]\n",
      "[Epoch 34/200] [Batch 44/637] [D loss: 0.180080] [G loss: 0.465888]\n",
      "[Epoch 34/200] [Batch 45/637] [D loss: 0.160437] [G loss: 0.553357]\n",
      "[Epoch 34/200] [Batch 46/637] [D loss: 0.173363] [G loss: 0.459284]\n",
      "[Epoch 34/200] [Batch 47/637] [D loss: 0.172829] [G loss: 0.499540]\n",
      "[Epoch 34/200] [Batch 48/637] [D loss: 0.177782] [G loss: 0.467027]\n",
      "[Epoch 34/200] [Batch 49/637] [D loss: 0.160374] [G loss: 0.504024]\n",
      "[Epoch 34/200] [Batch 50/637] [D loss: 0.167407] [G loss: 0.502986]\n",
      "[Epoch 34/200] [Batch 51/637] [D loss: 0.139184] [G loss: 0.578904]\n",
      "[Epoch 34/200] [Batch 52/637] [D loss: 0.168947] [G loss: 0.547008]\n",
      "[Epoch 34/200] [Batch 53/637] [D loss: 0.156434] [G loss: 0.548517]\n",
      "[Epoch 34/200] [Batch 54/637] [D loss: 0.169450] [G loss: 0.528951]\n",
      "[Epoch 34/200] [Batch 55/637] [D loss: 0.160526] [G loss: 0.542725]\n",
      "[Epoch 34/200] [Batch 56/637] [D loss: 0.147735] [G loss: 0.516647]\n",
      "[Epoch 34/200] [Batch 57/637] [D loss: 0.163479] [G loss: 0.477718]\n",
      "[Epoch 34/200] [Batch 58/637] [D loss: 0.187887] [G loss: 0.483793]\n",
      "[Epoch 34/200] [Batch 59/637] [D loss: 0.170430] [G loss: 0.525929]\n",
      "[Epoch 34/200] [Batch 60/637] [D loss: 0.184276] [G loss: 0.473795]\n",
      "[Epoch 34/200] [Batch 61/637] [D loss: 0.169827] [G loss: 0.493928]\n",
      "[Epoch 34/200] [Batch 62/637] [D loss: 0.186882] [G loss: 0.443647]\n",
      "[Epoch 34/200] [Batch 63/637] [D loss: 0.198718] [G loss: 0.476070]\n",
      "[Epoch 34/200] [Batch 64/637] [D loss: 0.163716] [G loss: 0.493962]\n",
      "[Epoch 34/200] [Batch 65/637] [D loss: 0.182749] [G loss: 0.410319]\n",
      "[Epoch 34/200] [Batch 66/637] [D loss: 0.181273] [G loss: 0.410617]\n",
      "[Epoch 34/200] [Batch 67/637] [D loss: 0.181913] [G loss: 0.478576]\n",
      "[Epoch 34/200] [Batch 68/637] [D loss: 0.168973] [G loss: 0.422758]\n",
      "[Epoch 34/200] [Batch 69/637] [D loss: 0.182864] [G loss: 0.422615]\n",
      "[Epoch 34/200] [Batch 70/637] [D loss: 0.156697] [G loss: 0.509749]\n",
      "[Epoch 34/200] [Batch 71/637] [D loss: 0.155391] [G loss: 0.520885]\n",
      "[Epoch 34/200] [Batch 72/637] [D loss: 0.192965] [G loss: 0.478694]\n",
      "[Epoch 34/200] [Batch 73/637] [D loss: 0.178038] [G loss: 0.486782]\n",
      "[Epoch 34/200] [Batch 74/637] [D loss: 0.190472] [G loss: 0.438425]\n",
      "[Epoch 34/200] [Batch 75/637] [D loss: 0.188786] [G loss: 0.414603]\n",
      "[Epoch 34/200] [Batch 76/637] [D loss: 0.156179] [G loss: 0.448148]\n",
      "[Epoch 34/200] [Batch 77/637] [D loss: 0.171869] [G loss: 0.444806]\n",
      "[Epoch 34/200] [Batch 78/637] [D loss: 0.176762] [G loss: 0.457100]\n",
      "[Epoch 34/200] [Batch 79/637] [D loss: 0.188370] [G loss: 0.492205]\n",
      "[Epoch 34/200] [Batch 80/637] [D loss: 0.140431] [G loss: 0.483932]\n",
      "[Epoch 34/200] [Batch 81/637] [D loss: 0.159276] [G loss: 0.468505]\n",
      "[Epoch 34/200] [Batch 82/637] [D loss: 0.159691] [G loss: 0.494944]\n",
      "[Epoch 34/200] [Batch 83/637] [D loss: 0.167133] [G loss: 0.448481]\n",
      "[Epoch 34/200] [Batch 84/637] [D loss: 0.155914] [G loss: 0.515930]\n",
      "[Epoch 34/200] [Batch 85/637] [D loss: 0.169781] [G loss: 0.502036]\n",
      "[Epoch 34/200] [Batch 86/637] [D loss: 0.177549] [G loss: 0.490592]\n",
      "[Epoch 34/200] [Batch 87/637] [D loss: 0.172232] [G loss: 0.489901]\n",
      "[Epoch 34/200] [Batch 88/637] [D loss: 0.153839] [G loss: 0.521585]\n",
      "[Epoch 34/200] [Batch 89/637] [D loss: 0.165377] [G loss: 0.475870]\n",
      "[Epoch 34/200] [Batch 90/637] [D loss: 0.203899] [G loss: 0.389682]\n",
      "[Epoch 34/200] [Batch 91/637] [D loss: 0.162279] [G loss: 0.449579]\n",
      "[Epoch 34/200] [Batch 92/637] [D loss: 0.167715] [G loss: 0.478645]\n",
      "[Epoch 34/200] [Batch 93/637] [D loss: 0.171331] [G loss: 0.462990]\n",
      "[Epoch 34/200] [Batch 94/637] [D loss: 0.159737] [G loss: 0.480721]\n",
      "[Epoch 34/200] [Batch 95/637] [D loss: 0.166911] [G loss: 0.446355]\n",
      "[Epoch 34/200] [Batch 96/637] [D loss: 0.164782] [G loss: 0.435946]\n",
      "[Epoch 34/200] [Batch 97/637] [D loss: 0.173284] [G loss: 0.454270]\n",
      "[Epoch 34/200] [Batch 98/637] [D loss: 0.173426] [G loss: 0.494140]\n",
      "[Epoch 34/200] [Batch 99/637] [D loss: 0.186548] [G loss: 0.521745]\n",
      "[Epoch 34/200] [Batch 100/637] [D loss: 0.179626] [G loss: 0.395805]\n",
      "[Epoch 34/200] [Batch 101/637] [D loss: 0.193459] [G loss: 0.447050]\n",
      "[Epoch 34/200] [Batch 102/637] [D loss: 0.174951] [G loss: 0.540593]\n",
      "[Epoch 34/200] [Batch 103/637] [D loss: 0.189146] [G loss: 0.440519]\n",
      "[Epoch 34/200] [Batch 104/637] [D loss: 0.205446] [G loss: 0.451498]\n",
      "[Epoch 34/200] [Batch 105/637] [D loss: 0.212917] [G loss: 0.428435]\n",
      "[Epoch 34/200] [Batch 106/637] [D loss: 0.191169] [G loss: 0.546896]\n",
      "[Epoch 34/200] [Batch 107/637] [D loss: 0.179988] [G loss: 0.560084]\n",
      "[Epoch 34/200] [Batch 108/637] [D loss: 0.172765] [G loss: 0.503539]\n",
      "[Epoch 34/200] [Batch 109/637] [D loss: 0.171924] [G loss: 0.455800]\n",
      "[Epoch 34/200] [Batch 110/637] [D loss: 0.165223] [G loss: 0.474404]\n",
      "[Epoch 34/200] [Batch 111/637] [D loss: 0.174640] [G loss: 0.504670]\n",
      "[Epoch 34/200] [Batch 112/637] [D loss: 0.182442] [G loss: 0.526279]\n",
      "[Epoch 34/200] [Batch 113/637] [D loss: 0.177745] [G loss: 0.461098]\n",
      "[Epoch 34/200] [Batch 114/637] [D loss: 0.168610] [G loss: 0.442729]\n",
      "[Epoch 34/200] [Batch 115/637] [D loss: 0.176959] [G loss: 0.452674]\n",
      "[Epoch 34/200] [Batch 116/637] [D loss: 0.157709] [G loss: 0.521171]\n",
      "[Epoch 34/200] [Batch 117/637] [D loss: 0.171952] [G loss: 0.496469]\n",
      "[Epoch 34/200] [Batch 118/637] [D loss: 0.168580] [G loss: 0.493005]\n",
      "[Epoch 34/200] [Batch 119/637] [D loss: 0.151451] [G loss: 0.567031]\n",
      "[Epoch 34/200] [Batch 120/637] [D loss: 0.172366] [G loss: 0.509091]\n",
      "[Epoch 34/200] [Batch 121/637] [D loss: 0.152243] [G loss: 0.516640]\n",
      "[Epoch 34/200] [Batch 122/637] [D loss: 0.184750] [G loss: 0.501931]\n",
      "[Epoch 34/200] [Batch 123/637] [D loss: 0.185204] [G loss: 0.520863]\n",
      "[Epoch 34/200] [Batch 124/637] [D loss: 0.193321] [G loss: 0.446923]\n",
      "[Epoch 34/200] [Batch 125/637] [D loss: 0.179845] [G loss: 0.570543]\n",
      "[Epoch 34/200] [Batch 126/637] [D loss: 0.169775] [G loss: 0.544636]\n",
      "[Epoch 34/200] [Batch 127/637] [D loss: 0.179476] [G loss: 0.444632]\n",
      "[Epoch 34/200] [Batch 128/637] [D loss: 0.162543] [G loss: 0.411059]\n",
      "[Epoch 34/200] [Batch 129/637] [D loss: 0.169269] [G loss: 0.473545]\n",
      "[Epoch 34/200] [Batch 130/637] [D loss: 0.172966] [G loss: 0.471190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 131/637] [D loss: 0.161955] [G loss: 0.510518]\n",
      "[Epoch 34/200] [Batch 132/637] [D loss: 0.157703] [G loss: 0.599476]\n",
      "[Epoch 34/200] [Batch 133/637] [D loss: 0.210168] [G loss: 0.425212]\n",
      "[Epoch 34/200] [Batch 134/637] [D loss: 0.175363] [G loss: 0.499170]\n",
      "[Epoch 34/200] [Batch 135/637] [D loss: 0.210905] [G loss: 0.424895]\n",
      "[Epoch 34/200] [Batch 136/637] [D loss: 0.205418] [G loss: 0.486174]\n",
      "[Epoch 34/200] [Batch 137/637] [D loss: 0.205093] [G loss: 0.427876]\n",
      "[Epoch 34/200] [Batch 138/637] [D loss: 0.160677] [G loss: 0.555797]\n",
      "[Epoch 34/200] [Batch 139/637] [D loss: 0.149973] [G loss: 0.484439]\n",
      "[Epoch 34/200] [Batch 140/637] [D loss: 0.162257] [G loss: 0.462049]\n",
      "[Epoch 34/200] [Batch 141/637] [D loss: 0.190046] [G loss: 0.405878]\n",
      "[Epoch 34/200] [Batch 142/637] [D loss: 0.165010] [G loss: 0.490012]\n",
      "[Epoch 34/200] [Batch 143/637] [D loss: 0.156181] [G loss: 0.581114]\n",
      "[Epoch 34/200] [Batch 144/637] [D loss: 0.158806] [G loss: 0.578360]\n",
      "[Epoch 34/200] [Batch 145/637] [D loss: 0.128373] [G loss: 0.471641]\n",
      "[Epoch 34/200] [Batch 146/637] [D loss: 0.179686] [G loss: 0.389398]\n",
      "[Epoch 34/200] [Batch 147/637] [D loss: 0.158420] [G loss: 0.461308]\n",
      "[Epoch 34/200] [Batch 148/637] [D loss: 0.177929] [G loss: 0.522247]\n",
      "[Epoch 34/200] [Batch 149/637] [D loss: 0.160436] [G loss: 0.582372]\n",
      "[Epoch 34/200] [Batch 150/637] [D loss: 0.189395] [G loss: 0.440005]\n",
      "[Epoch 34/200] [Batch 151/637] [D loss: 0.162792] [G loss: 0.496657]\n",
      "[Epoch 34/200] [Batch 152/637] [D loss: 0.148885] [G loss: 0.509009]\n",
      "[Epoch 34/200] [Batch 153/637] [D loss: 0.147550] [G loss: 0.515020]\n",
      "[Epoch 34/200] [Batch 154/637] [D loss: 0.165326] [G loss: 0.431228]\n",
      "[Epoch 34/200] [Batch 155/637] [D loss: 0.154413] [G loss: 0.465595]\n",
      "[Epoch 34/200] [Batch 156/637] [D loss: 0.165150] [G loss: 0.519678]\n",
      "[Epoch 34/200] [Batch 157/637] [D loss: 0.159341] [G loss: 0.525517]\n",
      "[Epoch 34/200] [Batch 158/637] [D loss: 0.191917] [G loss: 0.441149]\n",
      "[Epoch 34/200] [Batch 159/637] [D loss: 0.161045] [G loss: 0.489664]\n",
      "[Epoch 34/200] [Batch 160/637] [D loss: 0.194341] [G loss: 0.429361]\n",
      "[Epoch 34/200] [Batch 161/637] [D loss: 0.181185] [G loss: 0.470202]\n",
      "[Epoch 34/200] [Batch 162/637] [D loss: 0.192283] [G loss: 0.483850]\n",
      "[Epoch 34/200] [Batch 163/637] [D loss: 0.159239] [G loss: 0.437295]\n",
      "[Epoch 34/200] [Batch 164/637] [D loss: 0.180307] [G loss: 0.405790]\n",
      "[Epoch 34/200] [Batch 165/637] [D loss: 0.164767] [G loss: 0.415624]\n",
      "[Epoch 34/200] [Batch 166/637] [D loss: 0.190250] [G loss: 0.370252]\n",
      "[Epoch 34/200] [Batch 167/637] [D loss: 0.151986] [G loss: 0.506059]\n",
      "[Epoch 34/200] [Batch 168/637] [D loss: 0.181076] [G loss: 0.526903]\n",
      "[Epoch 34/200] [Batch 169/637] [D loss: 0.172032] [G loss: 0.577503]\n",
      "[Epoch 34/200] [Batch 170/637] [D loss: 0.161570] [G loss: 0.472894]\n",
      "[Epoch 34/200] [Batch 171/637] [D loss: 0.196242] [G loss: 0.402889]\n",
      "[Epoch 34/200] [Batch 172/637] [D loss: 0.157764] [G loss: 0.545975]\n",
      "[Epoch 34/200] [Batch 173/637] [D loss: 0.184469] [G loss: 0.491564]\n",
      "[Epoch 34/200] [Batch 174/637] [D loss: 0.172926] [G loss: 0.580016]\n",
      "[Epoch 34/200] [Batch 175/637] [D loss: 0.179969] [G loss: 0.458498]\n",
      "[Epoch 34/200] [Batch 176/637] [D loss: 0.143842] [G loss: 0.495822]\n",
      "[Epoch 34/200] [Batch 177/637] [D loss: 0.163355] [G loss: 0.494630]\n",
      "[Epoch 34/200] [Batch 178/637] [D loss: 0.154132] [G loss: 0.523259]\n",
      "[Epoch 34/200] [Batch 179/637] [D loss: 0.205135] [G loss: 0.516014]\n",
      "[Epoch 34/200] [Batch 180/637] [D loss: 0.187506] [G loss: 0.542131]\n",
      "[Epoch 34/200] [Batch 181/637] [D loss: 0.165810] [G loss: 0.512806]\n",
      "[Epoch 34/200] [Batch 182/637] [D loss: 0.147178] [G loss: 0.523183]\n",
      "[Epoch 34/200] [Batch 183/637] [D loss: 0.198531] [G loss: 0.455174]\n",
      "[Epoch 34/200] [Batch 184/637] [D loss: 0.162503] [G loss: 0.488980]\n",
      "[Epoch 34/200] [Batch 185/637] [D loss: 0.168535] [G loss: 0.499650]\n",
      "[Epoch 34/200] [Batch 186/637] [D loss: 0.166015] [G loss: 0.538927]\n",
      "[Epoch 34/200] [Batch 187/637] [D loss: 0.173772] [G loss: 0.562399]\n",
      "[Epoch 34/200] [Batch 188/637] [D loss: 0.208674] [G loss: 0.487080]\n",
      "[Epoch 34/200] [Batch 189/637] [D loss: 0.183325] [G loss: 0.521062]\n",
      "[Epoch 34/200] [Batch 190/637] [D loss: 0.165633] [G loss: 0.551498]\n",
      "[Epoch 34/200] [Batch 191/637] [D loss: 0.229132] [G loss: 0.416080]\n",
      "[Epoch 34/200] [Batch 192/637] [D loss: 0.169317] [G loss: 0.593307]\n",
      "[Epoch 34/200] [Batch 193/637] [D loss: 0.210998] [G loss: 0.561785]\n",
      "[Epoch 34/200] [Batch 194/637] [D loss: 0.163913] [G loss: 0.484755]\n",
      "[Epoch 34/200] [Batch 195/637] [D loss: 0.155362] [G loss: 0.393785]\n",
      "[Epoch 34/200] [Batch 196/637] [D loss: 0.177262] [G loss: 0.463597]\n",
      "[Epoch 34/200] [Batch 197/637] [D loss: 0.176171] [G loss: 0.488539]\n",
      "[Epoch 34/200] [Batch 198/637] [D loss: 0.169106] [G loss: 0.478733]\n",
      "[Epoch 34/200] [Batch 199/637] [D loss: 0.162334] [G loss: 0.536492]\n",
      "[Epoch 34/200] [Batch 200/637] [D loss: 0.170103] [G loss: 0.485881]\n",
      "[Epoch 34/200] [Batch 201/637] [D loss: 0.180444] [G loss: 0.411960]\n",
      "[Epoch 34/200] [Batch 202/637] [D loss: 0.162173] [G loss: 0.506472]\n",
      "[Epoch 34/200] [Batch 203/637] [D loss: 0.167412] [G loss: 0.486287]\n",
      "[Epoch 34/200] [Batch 204/637] [D loss: 0.152363] [G loss: 0.538851]\n",
      "[Epoch 34/200] [Batch 205/637] [D loss: 0.158152] [G loss: 0.471980]\n",
      "[Epoch 34/200] [Batch 206/637] [D loss: 0.170604] [G loss: 0.502175]\n",
      "[Epoch 34/200] [Batch 207/637] [D loss: 0.162755] [G loss: 0.499264]\n",
      "[Epoch 34/200] [Batch 208/637] [D loss: 0.165736] [G loss: 0.534630]\n",
      "[Epoch 34/200] [Batch 209/637] [D loss: 0.143145] [G loss: 0.603621]\n",
      "[Epoch 34/200] [Batch 210/637] [D loss: 0.166778] [G loss: 0.487361]\n",
      "[Epoch 34/200] [Batch 211/637] [D loss: 0.150720] [G loss: 0.551126]\n",
      "[Epoch 34/200] [Batch 212/637] [D loss: 0.183040] [G loss: 0.562206]\n",
      "[Epoch 34/200] [Batch 213/637] [D loss: 0.181130] [G loss: 0.547496]\n",
      "[Epoch 34/200] [Batch 214/637] [D loss: 0.174991] [G loss: 0.483075]\n",
      "[Epoch 34/200] [Batch 215/637] [D loss: 0.154104] [G loss: 0.528414]\n",
      "[Epoch 34/200] [Batch 216/637] [D loss: 0.152406] [G loss: 0.455898]\n",
      "[Epoch 34/200] [Batch 217/637] [D loss: 0.156150] [G loss: 0.492632]\n",
      "[Epoch 34/200] [Batch 218/637] [D loss: 0.208161] [G loss: 0.469658]\n",
      "[Epoch 34/200] [Batch 219/637] [D loss: 0.166101] [G loss: 0.490992]\n",
      "[Epoch 34/200] [Batch 220/637] [D loss: 0.164203] [G loss: 0.501707]\n",
      "[Epoch 34/200] [Batch 221/637] [D loss: 0.190640] [G loss: 0.519182]\n",
      "[Epoch 34/200] [Batch 222/637] [D loss: 0.192673] [G loss: 0.527800]\n",
      "[Epoch 34/200] [Batch 223/637] [D loss: 0.172452] [G loss: 0.423065]\n",
      "[Epoch 34/200] [Batch 224/637] [D loss: 0.173153] [G loss: 0.492758]\n",
      "[Epoch 34/200] [Batch 225/637] [D loss: 0.176797] [G loss: 0.529840]\n",
      "[Epoch 34/200] [Batch 226/637] [D loss: 0.171109] [G loss: 0.443792]\n",
      "[Epoch 34/200] [Batch 227/637] [D loss: 0.171923] [G loss: 0.482897]\n",
      "[Epoch 34/200] [Batch 228/637] [D loss: 0.181698] [G loss: 0.501865]\n",
      "[Epoch 34/200] [Batch 229/637] [D loss: 0.185606] [G loss: 0.419693]\n",
      "[Epoch 34/200] [Batch 230/637] [D loss: 0.207338] [G loss: 0.586790]\n",
      "[Epoch 34/200] [Batch 231/637] [D loss: 0.189972] [G loss: 0.466762]\n",
      "[Epoch 34/200] [Batch 232/637] [D loss: 0.189555] [G loss: 0.412175]\n",
      "[Epoch 34/200] [Batch 233/637] [D loss: 0.181021] [G loss: 0.452746]\n",
      "[Epoch 34/200] [Batch 234/637] [D loss: 0.173274] [G loss: 0.475178]\n",
      "[Epoch 34/200] [Batch 235/637] [D loss: 0.162238] [G loss: 0.487272]\n",
      "[Epoch 34/200] [Batch 236/637] [D loss: 0.176138] [G loss: 0.549822]\n",
      "[Epoch 34/200] [Batch 237/637] [D loss: 0.179477] [G loss: 0.432086]\n",
      "[Epoch 34/200] [Batch 238/637] [D loss: 0.165592] [G loss: 0.451910]\n",
      "[Epoch 34/200] [Batch 239/637] [D loss: 0.189219] [G loss: 0.418073]\n",
      "[Epoch 34/200] [Batch 240/637] [D loss: 0.156690] [G loss: 0.433205]\n",
      "[Epoch 34/200] [Batch 241/637] [D loss: 0.168688] [G loss: 0.451329]\n",
      "[Epoch 34/200] [Batch 242/637] [D loss: 0.171030] [G loss: 0.471920]\n",
      "[Epoch 34/200] [Batch 243/637] [D loss: 0.183957] [G loss: 0.437113]\n",
      "[Epoch 34/200] [Batch 244/637] [D loss: 0.164536] [G loss: 0.456257]\n",
      "[Epoch 34/200] [Batch 245/637] [D loss: 0.166437] [G loss: 0.436186]\n",
      "[Epoch 34/200] [Batch 246/637] [D loss: 0.150945] [G loss: 0.558469]\n",
      "[Epoch 34/200] [Batch 247/637] [D loss: 0.153649] [G loss: 0.551932]\n",
      "[Epoch 34/200] [Batch 248/637] [D loss: 0.160687] [G loss: 0.529248]\n",
      "[Epoch 34/200] [Batch 249/637] [D loss: 0.168703] [G loss: 0.478787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 250/637] [D loss: 0.168376] [G loss: 0.480680]\n",
      "[Epoch 34/200] [Batch 251/637] [D loss: 0.157543] [G loss: 0.563200]\n",
      "[Epoch 34/200] [Batch 252/637] [D loss: 0.162492] [G loss: 0.580175]\n",
      "[Epoch 34/200] [Batch 253/637] [D loss: 0.183126] [G loss: 0.466946]\n",
      "[Epoch 34/200] [Batch 254/637] [D loss: 0.174592] [G loss: 0.563321]\n",
      "[Epoch 34/200] [Batch 255/637] [D loss: 0.179610] [G loss: 0.545611]\n",
      "[Epoch 34/200] [Batch 256/637] [D loss: 0.157443] [G loss: 0.577799]\n",
      "[Epoch 34/200] [Batch 257/637] [D loss: 0.177976] [G loss: 0.450514]\n",
      "[Epoch 34/200] [Batch 258/637] [D loss: 0.163357] [G loss: 0.575431]\n",
      "[Epoch 34/200] [Batch 259/637] [D loss: 0.174511] [G loss: 0.514153]\n",
      "[Epoch 34/200] [Batch 260/637] [D loss: 0.174331] [G loss: 0.433020]\n",
      "[Epoch 34/200] [Batch 261/637] [D loss: 0.200223] [G loss: 0.484436]\n",
      "[Epoch 34/200] [Batch 262/637] [D loss: 0.166784] [G loss: 0.466462]\n",
      "[Epoch 34/200] [Batch 263/637] [D loss: 0.178376] [G loss: 0.457990]\n",
      "[Epoch 34/200] [Batch 264/637] [D loss: 0.165259] [G loss: 0.492984]\n",
      "[Epoch 34/200] [Batch 265/637] [D loss: 0.186019] [G loss: 0.436027]\n",
      "[Epoch 34/200] [Batch 266/637] [D loss: 0.178950] [G loss: 0.526941]\n",
      "[Epoch 34/200] [Batch 267/637] [D loss: 0.178524] [G loss: 0.561829]\n",
      "[Epoch 34/200] [Batch 268/637] [D loss: 0.161836] [G loss: 0.518822]\n",
      "[Epoch 34/200] [Batch 269/637] [D loss: 0.183942] [G loss: 0.440492]\n",
      "[Epoch 34/200] [Batch 270/637] [D loss: 0.146133] [G loss: 0.496947]\n",
      "[Epoch 34/200] [Batch 271/637] [D loss: 0.205162] [G loss: 0.463950]\n",
      "[Epoch 34/200] [Batch 272/637] [D loss: 0.173055] [G loss: 0.443384]\n",
      "[Epoch 34/200] [Batch 273/637] [D loss: 0.166816] [G loss: 0.560774]\n",
      "[Epoch 34/200] [Batch 274/637] [D loss: 0.179702] [G loss: 0.511826]\n",
      "[Epoch 34/200] [Batch 275/637] [D loss: 0.175329] [G loss: 0.514345]\n",
      "[Epoch 34/200] [Batch 276/637] [D loss: 0.204759] [G loss: 0.404326]\n",
      "[Epoch 34/200] [Batch 277/637] [D loss: 0.199008] [G loss: 0.451981]\n",
      "[Epoch 34/200] [Batch 278/637] [D loss: 0.183470] [G loss: 0.472261]\n",
      "[Epoch 34/200] [Batch 279/637] [D loss: 0.175518] [G loss: 0.470088]\n",
      "[Epoch 34/200] [Batch 280/637] [D loss: 0.157866] [G loss: 0.436216]\n",
      "[Epoch 34/200] [Batch 281/637] [D loss: 0.156934] [G loss: 0.492384]\n",
      "[Epoch 34/200] [Batch 282/637] [D loss: 0.214018] [G loss: 0.411492]\n",
      "[Epoch 34/200] [Batch 283/637] [D loss: 0.161794] [G loss: 0.500543]\n",
      "[Epoch 34/200] [Batch 284/637] [D loss: 0.162636] [G loss: 0.514464]\n",
      "[Epoch 34/200] [Batch 285/637] [D loss: 0.150964] [G loss: 0.464492]\n",
      "[Epoch 34/200] [Batch 286/637] [D loss: 0.180466] [G loss: 0.426480]\n",
      "[Epoch 34/200] [Batch 287/637] [D loss: 0.166863] [G loss: 0.579499]\n",
      "[Epoch 34/200] [Batch 288/637] [D loss: 0.172455] [G loss: 0.501937]\n",
      "[Epoch 34/200] [Batch 289/637] [D loss: 0.164943] [G loss: 0.482681]\n",
      "[Epoch 34/200] [Batch 290/637] [D loss: 0.168114] [G loss: 0.495975]\n",
      "[Epoch 34/200] [Batch 291/637] [D loss: 0.174399] [G loss: 0.423595]\n",
      "[Epoch 34/200] [Batch 292/637] [D loss: 0.178996] [G loss: 0.510116]\n",
      "[Epoch 34/200] [Batch 293/637] [D loss: 0.165051] [G loss: 0.551044]\n",
      "[Epoch 34/200] [Batch 294/637] [D loss: 0.153828] [G loss: 0.504104]\n",
      "[Epoch 34/200] [Batch 295/637] [D loss: 0.211505] [G loss: 0.418148]\n",
      "[Epoch 34/200] [Batch 296/637] [D loss: 0.148932] [G loss: 0.490668]\n",
      "[Epoch 34/200] [Batch 297/637] [D loss: 0.167460] [G loss: 0.431274]\n",
      "[Epoch 34/200] [Batch 298/637] [D loss: 0.190666] [G loss: 0.479265]\n",
      "[Epoch 34/200] [Batch 299/637] [D loss: 0.179447] [G loss: 0.520140]\n",
      "[Epoch 34/200] [Batch 300/637] [D loss: 0.148445] [G loss: 0.471723]\n",
      "[Epoch 34/200] [Batch 301/637] [D loss: 0.154817] [G loss: 0.490940]\n",
      "[Epoch 34/200] [Batch 302/637] [D loss: 0.184436] [G loss: 0.495436]\n",
      "[Epoch 34/200] [Batch 303/637] [D loss: 0.170639] [G loss: 0.475063]\n",
      "[Epoch 34/200] [Batch 304/637] [D loss: 0.147182] [G loss: 0.541271]\n",
      "[Epoch 34/200] [Batch 305/637] [D loss: 0.181814] [G loss: 0.546814]\n",
      "[Epoch 34/200] [Batch 306/637] [D loss: 0.155998] [G loss: 0.487505]\n",
      "[Epoch 34/200] [Batch 307/637] [D loss: 0.163022] [G loss: 0.483983]\n",
      "[Epoch 34/200] [Batch 308/637] [D loss: 0.157568] [G loss: 0.477871]\n",
      "[Epoch 34/200] [Batch 309/637] [D loss: 0.160759] [G loss: 0.473120]\n",
      "[Epoch 34/200] [Batch 310/637] [D loss: 0.195213] [G loss: 0.584811]\n",
      "[Epoch 34/200] [Batch 311/637] [D loss: 0.144773] [G loss: 0.606288]\n",
      "[Epoch 34/200] [Batch 312/637] [D loss: 0.162880] [G loss: 0.439306]\n",
      "[Epoch 34/200] [Batch 313/637] [D loss: 0.186454] [G loss: 0.407626]\n",
      "[Epoch 34/200] [Batch 314/637] [D loss: 0.147035] [G loss: 0.528226]\n",
      "[Epoch 34/200] [Batch 315/637] [D loss: 0.172336] [G loss: 0.475668]\n",
      "[Epoch 34/200] [Batch 316/637] [D loss: 0.178028] [G loss: 0.553692]\n",
      "[Epoch 34/200] [Batch 317/637] [D loss: 0.174995] [G loss: 0.449098]\n",
      "[Epoch 34/200] [Batch 318/637] [D loss: 0.175765] [G loss: 0.468719]\n",
      "[Epoch 34/200] [Batch 319/637] [D loss: 0.183163] [G loss: 0.459398]\n",
      "[Epoch 34/200] [Batch 320/637] [D loss: 0.181856] [G loss: 0.544994]\n",
      "[Epoch 34/200] [Batch 321/637] [D loss: 0.196509] [G loss: 0.472791]\n",
      "[Epoch 34/200] [Batch 322/637] [D loss: 0.185671] [G loss: 0.424888]\n",
      "[Epoch 34/200] [Batch 323/637] [D loss: 0.187298] [G loss: 0.430477]\n",
      "[Epoch 34/200] [Batch 324/637] [D loss: 0.170616] [G loss: 0.521035]\n",
      "[Epoch 34/200] [Batch 325/637] [D loss: 0.169303] [G loss: 0.501633]\n",
      "[Epoch 34/200] [Batch 326/637] [D loss: 0.147343] [G loss: 0.550828]\n",
      "[Epoch 34/200] [Batch 327/637] [D loss: 0.166352] [G loss: 0.517035]\n",
      "[Epoch 34/200] [Batch 328/637] [D loss: 0.188999] [G loss: 0.508591]\n",
      "[Epoch 34/200] [Batch 329/637] [D loss: 0.168269] [G loss: 0.486419]\n",
      "[Epoch 34/200] [Batch 330/637] [D loss: 0.165692] [G loss: 0.494262]\n",
      "[Epoch 34/200] [Batch 331/637] [D loss: 0.169129] [G loss: 0.562380]\n",
      "[Epoch 34/200] [Batch 332/637] [D loss: 0.165220] [G loss: 0.575153]\n",
      "[Epoch 34/200] [Batch 333/637] [D loss: 0.151540] [G loss: 0.495390]\n",
      "[Epoch 34/200] [Batch 334/637] [D loss: 0.152586] [G loss: 0.562310]\n",
      "[Epoch 34/200] [Batch 335/637] [D loss: 0.148521] [G loss: 0.575644]\n",
      "[Epoch 34/200] [Batch 336/637] [D loss: 0.169016] [G loss: 0.500344]\n",
      "[Epoch 34/200] [Batch 337/637] [D loss: 0.148172] [G loss: 0.626158]\n",
      "[Epoch 34/200] [Batch 338/637] [D loss: 0.175225] [G loss: 0.577290]\n",
      "[Epoch 34/200] [Batch 339/637] [D loss: 0.164529] [G loss: 0.515280]\n",
      "[Epoch 34/200] [Batch 340/637] [D loss: 0.191497] [G loss: 0.456818]\n",
      "[Epoch 34/200] [Batch 341/637] [D loss: 0.170238] [G loss: 0.453965]\n",
      "[Epoch 34/200] [Batch 342/637] [D loss: 0.175955] [G loss: 0.480908]\n",
      "[Epoch 34/200] [Batch 343/637] [D loss: 0.175941] [G loss: 0.519359]\n",
      "[Epoch 34/200] [Batch 344/637] [D loss: 0.170334] [G loss: 0.489250]\n",
      "[Epoch 34/200] [Batch 345/637] [D loss: 0.176724] [G loss: 0.461279]\n",
      "[Epoch 34/200] [Batch 346/637] [D loss: 0.166267] [G loss: 0.419618]\n",
      "[Epoch 34/200] [Batch 347/637] [D loss: 0.174002] [G loss: 0.495071]\n",
      "[Epoch 34/200] [Batch 348/637] [D loss: 0.177269] [G loss: 0.501783]\n",
      "[Epoch 34/200] [Batch 349/637] [D loss: 0.160679] [G loss: 0.534320]\n",
      "[Epoch 34/200] [Batch 350/637] [D loss: 0.146549] [G loss: 0.560025]\n",
      "[Epoch 34/200] [Batch 351/637] [D loss: 0.164862] [G loss: 0.499991]\n",
      "[Epoch 34/200] [Batch 352/637] [D loss: 0.149487] [G loss: 0.544164]\n",
      "[Epoch 34/200] [Batch 353/637] [D loss: 0.165593] [G loss: 0.523312]\n",
      "[Epoch 34/200] [Batch 354/637] [D loss: 0.179019] [G loss: 0.443396]\n",
      "[Epoch 34/200] [Batch 355/637] [D loss: 0.175468] [G loss: 0.469015]\n",
      "[Epoch 34/200] [Batch 356/637] [D loss: 0.155763] [G loss: 0.558478]\n",
      "[Epoch 34/200] [Batch 357/637] [D loss: 0.159819] [G loss: 0.513449]\n",
      "[Epoch 34/200] [Batch 358/637] [D loss: 0.173519] [G loss: 0.509497]\n",
      "[Epoch 34/200] [Batch 359/637] [D loss: 0.165229] [G loss: 0.481160]\n",
      "[Epoch 34/200] [Batch 360/637] [D loss: 0.189610] [G loss: 0.439727]\n",
      "[Epoch 34/200] [Batch 361/637] [D loss: 0.166046] [G loss: 0.496200]\n",
      "[Epoch 34/200] [Batch 362/637] [D loss: 0.171242] [G loss: 0.502051]\n",
      "[Epoch 34/200] [Batch 363/637] [D loss: 0.185692] [G loss: 0.489375]\n",
      "[Epoch 34/200] [Batch 364/637] [D loss: 0.190639] [G loss: 0.537336]\n",
      "[Epoch 34/200] [Batch 365/637] [D loss: 0.158885] [G loss: 0.572788]\n",
      "[Epoch 34/200] [Batch 366/637] [D loss: 0.147018] [G loss: 0.480033]\n",
      "[Epoch 34/200] [Batch 367/637] [D loss: 0.167440] [G loss: 0.429886]\n",
      "[Epoch 34/200] [Batch 368/637] [D loss: 0.159821] [G loss: 0.533699]\n",
      "[Epoch 34/200] [Batch 369/637] [D loss: 0.174103] [G loss: 0.496382]\n",
      "[Epoch 34/200] [Batch 370/637] [D loss: 0.168325] [G loss: 0.539900]\n",
      "[Epoch 34/200] [Batch 371/637] [D loss: 0.142394] [G loss: 0.554047]\n",
      "[Epoch 34/200] [Batch 372/637] [D loss: 0.194850] [G loss: 0.408877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 373/637] [D loss: 0.167801] [G loss: 0.528524]\n",
      "[Epoch 34/200] [Batch 374/637] [D loss: 0.166156] [G loss: 0.540335]\n",
      "[Epoch 34/200] [Batch 375/637] [D loss: 0.186038] [G loss: 0.463490]\n",
      "[Epoch 34/200] [Batch 376/637] [D loss: 0.169920] [G loss: 0.478124]\n",
      "[Epoch 34/200] [Batch 377/637] [D loss: 0.169851] [G loss: 0.433175]\n",
      "[Epoch 34/200] [Batch 378/637] [D loss: 0.206043] [G loss: 0.419571]\n",
      "[Epoch 34/200] [Batch 379/637] [D loss: 0.195980] [G loss: 0.489154]\n",
      "[Epoch 34/200] [Batch 380/637] [D loss: 0.206476] [G loss: 0.549677]\n",
      "[Epoch 34/200] [Batch 381/637] [D loss: 0.164836] [G loss: 0.602887]\n",
      "[Epoch 34/200] [Batch 382/637] [D loss: 0.189196] [G loss: 0.435605]\n",
      "[Epoch 34/200] [Batch 383/637] [D loss: 0.156891] [G loss: 0.497988]\n",
      "[Epoch 34/200] [Batch 384/637] [D loss: 0.183573] [G loss: 0.467281]\n",
      "[Epoch 34/200] [Batch 385/637] [D loss: 0.184571] [G loss: 0.456436]\n",
      "[Epoch 34/200] [Batch 386/637] [D loss: 0.175625] [G loss: 0.423055]\n",
      "[Epoch 34/200] [Batch 387/637] [D loss: 0.169591] [G loss: 0.471974]\n",
      "[Epoch 34/200] [Batch 388/637] [D loss: 0.153682] [G loss: 0.533134]\n",
      "[Epoch 34/200] [Batch 389/637] [D loss: 0.163278] [G loss: 0.536373]\n",
      "[Epoch 34/200] [Batch 390/637] [D loss: 0.175633] [G loss: 0.502869]\n",
      "[Epoch 34/200] [Batch 391/637] [D loss: 0.150964] [G loss: 0.537820]\n",
      "[Epoch 34/200] [Batch 392/637] [D loss: 0.153459] [G loss: 0.504277]\n",
      "[Epoch 34/200] [Batch 393/637] [D loss: 0.174253] [G loss: 0.415052]\n",
      "[Epoch 34/200] [Batch 394/637] [D loss: 0.165904] [G loss: 0.496877]\n",
      "[Epoch 34/200] [Batch 395/637] [D loss: 0.159991] [G loss: 0.488982]\n",
      "[Epoch 34/200] [Batch 396/637] [D loss: 0.180285] [G loss: 0.508686]\n",
      "[Epoch 34/200] [Batch 397/637] [D loss: 0.172880] [G loss: 0.443499]\n",
      "[Epoch 34/200] [Batch 398/637] [D loss: 0.186219] [G loss: 0.434197]\n",
      "[Epoch 34/200] [Batch 399/637] [D loss: 0.160987] [G loss: 0.527086]\n",
      "[Epoch 34/200] [Batch 400/637] [D loss: 0.174490] [G loss: 0.532638]\n",
      "[Epoch 34/200] [Batch 401/637] [D loss: 0.212036] [G loss: 0.575695]\n",
      "[Epoch 34/200] [Batch 402/637] [D loss: 0.152066] [G loss: 0.507716]\n",
      "[Epoch 34/200] [Batch 403/637] [D loss: 0.214437] [G loss: 0.430234]\n",
      "[Epoch 34/200] [Batch 404/637] [D loss: 0.151735] [G loss: 0.553223]\n",
      "[Epoch 34/200] [Batch 405/637] [D loss: 0.211401] [G loss: 0.513806]\n",
      "[Epoch 34/200] [Batch 406/637] [D loss: 0.172501] [G loss: 0.515570]\n",
      "[Epoch 34/200] [Batch 407/637] [D loss: 0.168258] [G loss: 0.446447]\n",
      "[Epoch 34/200] [Batch 408/637] [D loss: 0.179067] [G loss: 0.438305]\n",
      "[Epoch 34/200] [Batch 409/637] [D loss: 0.171583] [G loss: 0.458472]\n",
      "[Epoch 34/200] [Batch 410/637] [D loss: 0.152913] [G loss: 0.491750]\n",
      "[Epoch 34/200] [Batch 411/637] [D loss: 0.158555] [G loss: 0.475655]\n",
      "[Epoch 34/200] [Batch 412/637] [D loss: 0.163319] [G loss: 0.450743]\n",
      "[Epoch 34/200] [Batch 413/637] [D loss: 0.194498] [G loss: 0.436887]\n",
      "[Epoch 34/200] [Batch 414/637] [D loss: 0.157505] [G loss: 0.496600]\n",
      "[Epoch 34/200] [Batch 415/637] [D loss: 0.185313] [G loss: 0.494054]\n",
      "[Epoch 34/200] [Batch 416/637] [D loss: 0.162992] [G loss: 0.541377]\n",
      "[Epoch 34/200] [Batch 417/637] [D loss: 0.164850] [G loss: 0.509984]\n",
      "[Epoch 34/200] [Batch 418/637] [D loss: 0.165769] [G loss: 0.502789]\n",
      "[Epoch 34/200] [Batch 419/637] [D loss: 0.172213] [G loss: 0.447175]\n",
      "[Epoch 34/200] [Batch 420/637] [D loss: 0.220942] [G loss: 0.472047]\n",
      "[Epoch 34/200] [Batch 421/637] [D loss: 0.163544] [G loss: 0.531056]\n",
      "[Epoch 34/200] [Batch 422/637] [D loss: 0.208247] [G loss: 0.424841]\n",
      "[Epoch 34/200] [Batch 423/637] [D loss: 0.171375] [G loss: 0.543894]\n",
      "[Epoch 34/200] [Batch 424/637] [D loss: 0.174518] [G loss: 0.509913]\n",
      "[Epoch 34/200] [Batch 425/637] [D loss: 0.171881] [G loss: 0.524488]\n",
      "[Epoch 34/200] [Batch 426/637] [D loss: 0.184866] [G loss: 0.411184]\n",
      "[Epoch 34/200] [Batch 427/637] [D loss: 0.174732] [G loss: 0.469236]\n",
      "[Epoch 34/200] [Batch 428/637] [D loss: 0.169388] [G loss: 0.511214]\n",
      "[Epoch 34/200] [Batch 429/637] [D loss: 0.186361] [G loss: 0.435007]\n",
      "[Epoch 34/200] [Batch 430/637] [D loss: 0.156687] [G loss: 0.545797]\n",
      "[Epoch 34/200] [Batch 431/637] [D loss: 0.168473] [G loss: 0.481115]\n",
      "[Epoch 34/200] [Batch 432/637] [D loss: 0.146143] [G loss: 0.497682]\n",
      "[Epoch 34/200] [Batch 433/637] [D loss: 0.163812] [G loss: 0.487903]\n",
      "[Epoch 34/200] [Batch 434/637] [D loss: 0.180677] [G loss: 0.567125]\n",
      "[Epoch 34/200] [Batch 435/637] [D loss: 0.160457] [G loss: 0.500546]\n",
      "[Epoch 34/200] [Batch 436/637] [D loss: 0.163062] [G loss: 0.512748]\n",
      "[Epoch 34/200] [Batch 437/637] [D loss: 0.233712] [G loss: 0.445013]\n",
      "[Epoch 34/200] [Batch 438/637] [D loss: 0.155940] [G loss: 0.610451]\n",
      "[Epoch 34/200] [Batch 439/637] [D loss: 0.204493] [G loss: 0.519883]\n",
      "[Epoch 34/200] [Batch 440/637] [D loss: 0.154394] [G loss: 0.544975]\n",
      "[Epoch 34/200] [Batch 441/637] [D loss: 0.178775] [G loss: 0.416821]\n",
      "[Epoch 34/200] [Batch 442/637] [D loss: 0.178926] [G loss: 0.450233]\n",
      "[Epoch 34/200] [Batch 443/637] [D loss: 0.161179] [G loss: 0.521153]\n",
      "[Epoch 34/200] [Batch 444/637] [D loss: 0.186562] [G loss: 0.441916]\n",
      "[Epoch 34/200] [Batch 445/637] [D loss: 0.183176] [G loss: 0.443964]\n",
      "[Epoch 34/200] [Batch 446/637] [D loss: 0.173130] [G loss: 0.487934]\n",
      "[Epoch 34/200] [Batch 447/637] [D loss: 0.161452] [G loss: 0.514992]\n",
      "[Epoch 34/200] [Batch 448/637] [D loss: 0.178609] [G loss: 0.482179]\n",
      "[Epoch 34/200] [Batch 449/637] [D loss: 0.187445] [G loss: 0.533684]\n",
      "[Epoch 34/200] [Batch 450/637] [D loss: 0.149285] [G loss: 0.516747]\n",
      "[Epoch 34/200] [Batch 451/637] [D loss: 0.169337] [G loss: 0.526968]\n",
      "[Epoch 34/200] [Batch 452/637] [D loss: 0.164661] [G loss: 0.458096]\n",
      "[Epoch 34/200] [Batch 453/637] [D loss: 0.163091] [G loss: 0.438595]\n",
      "[Epoch 34/200] [Batch 454/637] [D loss: 0.174954] [G loss: 0.498401]\n",
      "[Epoch 34/200] [Batch 455/637] [D loss: 0.167601] [G loss: 0.502159]\n",
      "[Epoch 34/200] [Batch 456/637] [D loss: 0.156487] [G loss: 0.538800]\n",
      "[Epoch 34/200] [Batch 457/637] [D loss: 0.156474] [G loss: 0.532059]\n",
      "[Epoch 34/200] [Batch 458/637] [D loss: 0.173372] [G loss: 0.508472]\n",
      "[Epoch 34/200] [Batch 459/637] [D loss: 0.192290] [G loss: 0.410824]\n",
      "[Epoch 34/200] [Batch 460/637] [D loss: 0.156777] [G loss: 0.533185]\n",
      "[Epoch 34/200] [Batch 461/637] [D loss: 0.183669] [G loss: 0.497942]\n",
      "[Epoch 34/200] [Batch 462/637] [D loss: 0.148188] [G loss: 0.525452]\n",
      "[Epoch 34/200] [Batch 463/637] [D loss: 0.185308] [G loss: 0.520584]\n",
      "[Epoch 34/200] [Batch 464/637] [D loss: 0.167901] [G loss: 0.523928]\n",
      "[Epoch 34/200] [Batch 465/637] [D loss: 0.166837] [G loss: 0.479950]\n",
      "[Epoch 34/200] [Batch 466/637] [D loss: 0.168332] [G loss: 0.470782]\n",
      "[Epoch 34/200] [Batch 467/637] [D loss: 0.165829] [G loss: 0.464795]\n",
      "[Epoch 34/200] [Batch 468/637] [D loss: 0.174132] [G loss: 0.516929]\n",
      "[Epoch 34/200] [Batch 469/637] [D loss: 0.182274] [G loss: 0.426464]\n",
      "[Epoch 34/200] [Batch 470/637] [D loss: 0.175228] [G loss: 0.479613]\n",
      "[Epoch 34/200] [Batch 471/637] [D loss: 0.157671] [G loss: 0.497952]\n",
      "[Epoch 34/200] [Batch 472/637] [D loss: 0.173596] [G loss: 0.453974]\n",
      "[Epoch 34/200] [Batch 473/637] [D loss: 0.169596] [G loss: 0.490282]\n",
      "[Epoch 34/200] [Batch 474/637] [D loss: 0.171237] [G loss: 0.557454]\n",
      "[Epoch 34/200] [Batch 475/637] [D loss: 0.167718] [G loss: 0.496676]\n",
      "[Epoch 34/200] [Batch 476/637] [D loss: 0.176303] [G loss: 0.463176]\n",
      "[Epoch 34/200] [Batch 477/637] [D loss: 0.170225] [G loss: 0.459080]\n",
      "[Epoch 34/200] [Batch 478/637] [D loss: 0.167542] [G loss: 0.528093]\n",
      "[Epoch 34/200] [Batch 479/637] [D loss: 0.189395] [G loss: 0.438641]\n",
      "[Epoch 34/200] [Batch 480/637] [D loss: 0.181758] [G loss: 0.526500]\n",
      "[Epoch 34/200] [Batch 481/637] [D loss: 0.164490] [G loss: 0.474220]\n",
      "[Epoch 34/200] [Batch 482/637] [D loss: 0.143151] [G loss: 0.530507]\n",
      "[Epoch 34/200] [Batch 483/637] [D loss: 0.165849] [G loss: 0.435742]\n",
      "[Epoch 34/200] [Batch 484/637] [D loss: 0.155971] [G loss: 0.487242]\n",
      "[Epoch 34/200] [Batch 485/637] [D loss: 0.177747] [G loss: 0.491427]\n",
      "[Epoch 34/200] [Batch 486/637] [D loss: 0.156912] [G loss: 0.543496]\n",
      "[Epoch 34/200] [Batch 487/637] [D loss: 0.170424] [G loss: 0.512673]\n",
      "[Epoch 34/200] [Batch 488/637] [D loss: 0.175653] [G loss: 0.491186]\n",
      "[Epoch 34/200] [Batch 489/637] [D loss: 0.156949] [G loss: 0.495972]\n",
      "[Epoch 34/200] [Batch 490/637] [D loss: 0.185394] [G loss: 0.442588]\n",
      "[Epoch 34/200] [Batch 491/637] [D loss: 0.166688] [G loss: 0.479282]\n",
      "[Epoch 34/200] [Batch 492/637] [D loss: 0.157640] [G loss: 0.503560]\n",
      "[Epoch 34/200] [Batch 493/637] [D loss: 0.176913] [G loss: 0.478880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 494/637] [D loss: 0.181876] [G loss: 0.472192]\n",
      "[Epoch 34/200] [Batch 495/637] [D loss: 0.152117] [G loss: 0.457334]\n",
      "[Epoch 34/200] [Batch 496/637] [D loss: 0.166303] [G loss: 0.499392]\n",
      "[Epoch 34/200] [Batch 497/637] [D loss: 0.158330] [G loss: 0.558115]\n",
      "[Epoch 34/200] [Batch 498/637] [D loss: 0.168865] [G loss: 0.487064]\n",
      "[Epoch 34/200] [Batch 499/637] [D loss: 0.182018] [G loss: 0.429016]\n",
      "[Epoch 34/200] [Batch 500/637] [D loss: 0.178564] [G loss: 0.488900]\n",
      "[Epoch 34/200] [Batch 501/637] [D loss: 0.182568] [G loss: 0.481136]\n",
      "[Epoch 34/200] [Batch 502/637] [D loss: 0.170944] [G loss: 0.556649]\n",
      "[Epoch 34/200] [Batch 503/637] [D loss: 0.137592] [G loss: 0.613564]\n",
      "[Epoch 34/200] [Batch 504/637] [D loss: 0.171070] [G loss: 0.496820]\n",
      "[Epoch 34/200] [Batch 505/637] [D loss: 0.202965] [G loss: 0.418120]\n",
      "[Epoch 34/200] [Batch 506/637] [D loss: 0.194587] [G loss: 0.515744]\n",
      "[Epoch 34/200] [Batch 507/637] [D loss: 0.186319] [G loss: 0.526225]\n",
      "[Epoch 34/200] [Batch 508/637] [D loss: 0.163573] [G loss: 0.545266]\n",
      "[Epoch 34/200] [Batch 509/637] [D loss: 0.160035] [G loss: 0.502375]\n",
      "[Epoch 34/200] [Batch 510/637] [D loss: 0.176952] [G loss: 0.447595]\n",
      "[Epoch 34/200] [Batch 511/637] [D loss: 0.174544] [G loss: 0.521477]\n",
      "[Epoch 34/200] [Batch 512/637] [D loss: 0.170225] [G loss: 0.398206]\n",
      "[Epoch 34/200] [Batch 513/637] [D loss: 0.181040] [G loss: 0.463518]\n",
      "[Epoch 34/200] [Batch 514/637] [D loss: 0.211134] [G loss: 0.594405]\n",
      "[Epoch 34/200] [Batch 515/637] [D loss: 0.163592] [G loss: 0.539953]\n",
      "[Epoch 34/200] [Batch 516/637] [D loss: 0.145235] [G loss: 0.493531]\n",
      "[Epoch 34/200] [Batch 517/637] [D loss: 0.160177] [G loss: 0.403703]\n",
      "[Epoch 34/200] [Batch 518/637] [D loss: 0.165458] [G loss: 0.477890]\n",
      "[Epoch 34/200] [Batch 519/637] [D loss: 0.166607] [G loss: 0.574310]\n",
      "[Epoch 34/200] [Batch 520/637] [D loss: 0.163301] [G loss: 0.491874]\n",
      "[Epoch 34/200] [Batch 521/637] [D loss: 0.158650] [G loss: 0.505480]\n",
      "[Epoch 34/200] [Batch 522/637] [D loss: 0.198251] [G loss: 0.471081]\n",
      "[Epoch 34/200] [Batch 523/637] [D loss: 0.184923] [G loss: 0.458679]\n",
      "[Epoch 34/200] [Batch 524/637] [D loss: 0.157932] [G loss: 0.499696]\n",
      "[Epoch 34/200] [Batch 525/637] [D loss: 0.186601] [G loss: 0.548962]\n",
      "[Epoch 34/200] [Batch 526/637] [D loss: 0.173674] [G loss: 0.532703]\n",
      "[Epoch 34/200] [Batch 527/637] [D loss: 0.157746] [G loss: 0.480571]\n",
      "[Epoch 34/200] [Batch 528/637] [D loss: 0.162047] [G loss: 0.481466]\n",
      "[Epoch 34/200] [Batch 529/637] [D loss: 0.169301] [G loss: 0.490855]\n",
      "[Epoch 34/200] [Batch 530/637] [D loss: 0.167168] [G loss: 0.482165]\n",
      "[Epoch 34/200] [Batch 531/637] [D loss: 0.154225] [G loss: 0.501393]\n",
      "[Epoch 34/200] [Batch 532/637] [D loss: 0.136633] [G loss: 0.541687]\n",
      "[Epoch 34/200] [Batch 533/637] [D loss: 0.160668] [G loss: 0.468309]\n",
      "[Epoch 34/200] [Batch 534/637] [D loss: 0.244535] [G loss: 0.457155]\n",
      "[Epoch 34/200] [Batch 535/637] [D loss: 0.202189] [G loss: 0.537450]\n",
      "[Epoch 34/200] [Batch 536/637] [D loss: 0.168707] [G loss: 0.513890]\n",
      "[Epoch 34/200] [Batch 537/637] [D loss: 0.175455] [G loss: 0.517827]\n",
      "[Epoch 34/200] [Batch 538/637] [D loss: 0.185893] [G loss: 0.484805]\n",
      "[Epoch 34/200] [Batch 539/637] [D loss: 0.196799] [G loss: 0.425467]\n",
      "[Epoch 34/200] [Batch 540/637] [D loss: 0.161776] [G loss: 0.460320]\n",
      "[Epoch 34/200] [Batch 541/637] [D loss: 0.168202] [G loss: 0.462431]\n",
      "[Epoch 34/200] [Batch 542/637] [D loss: 0.181963] [G loss: 0.534506]\n",
      "[Epoch 34/200] [Batch 543/637] [D loss: 0.170252] [G loss: 0.506509]\n",
      "[Epoch 34/200] [Batch 544/637] [D loss: 0.167559] [G loss: 0.517721]\n",
      "[Epoch 34/200] [Batch 545/637] [D loss: 0.156201] [G loss: 0.495140]\n",
      "[Epoch 34/200] [Batch 546/637] [D loss: 0.175598] [G loss: 0.456385]\n",
      "[Epoch 34/200] [Batch 547/637] [D loss: 0.168610] [G loss: 0.476034]\n",
      "[Epoch 34/200] [Batch 548/637] [D loss: 0.168844] [G loss: 0.495075]\n",
      "[Epoch 34/200] [Batch 549/637] [D loss: 0.165526] [G loss: 0.449578]\n",
      "[Epoch 34/200] [Batch 550/637] [D loss: 0.150742] [G loss: 0.457775]\n",
      "[Epoch 34/200] [Batch 551/637] [D loss: 0.182948] [G loss: 0.490224]\n",
      "[Epoch 34/200] [Batch 552/637] [D loss: 0.147755] [G loss: 0.542990]\n",
      "[Epoch 34/200] [Batch 553/637] [D loss: 0.149017] [G loss: 0.508963]\n",
      "[Epoch 34/200] [Batch 554/637] [D loss: 0.191411] [G loss: 0.442276]\n",
      "[Epoch 34/200] [Batch 555/637] [D loss: 0.158889] [G loss: 0.516896]\n",
      "[Epoch 34/200] [Batch 556/637] [D loss: 0.174728] [G loss: 0.492761]\n",
      "[Epoch 34/200] [Batch 557/637] [D loss: 0.165049] [G loss: 0.493361]\n",
      "[Epoch 34/200] [Batch 558/637] [D loss: 0.169598] [G loss: 0.408901]\n",
      "[Epoch 34/200] [Batch 559/637] [D loss: 0.199912] [G loss: 0.478003]\n",
      "[Epoch 34/200] [Batch 560/637] [D loss: 0.162654] [G loss: 0.600719]\n",
      "[Epoch 34/200] [Batch 561/637] [D loss: 0.184934] [G loss: 0.491947]\n",
      "[Epoch 34/200] [Batch 562/637] [D loss: 0.175746] [G loss: 0.476459]\n",
      "[Epoch 34/200] [Batch 563/637] [D loss: 0.184890] [G loss: 0.461156]\n",
      "[Epoch 34/200] [Batch 564/637] [D loss: 0.174616] [G loss: 0.514196]\n",
      "[Epoch 34/200] [Batch 565/637] [D loss: 0.181332] [G loss: 0.430775]\n",
      "[Epoch 34/200] [Batch 566/637] [D loss: 0.160492] [G loss: 0.495719]\n",
      "[Epoch 34/200] [Batch 567/637] [D loss: 0.169969] [G loss: 0.473477]\n",
      "[Epoch 34/200] [Batch 568/637] [D loss: 0.170235] [G loss: 0.558099]\n",
      "[Epoch 34/200] [Batch 569/637] [D loss: 0.135143] [G loss: 0.624089]\n",
      "[Epoch 34/200] [Batch 570/637] [D loss: 0.222860] [G loss: 0.429480]\n",
      "[Epoch 34/200] [Batch 571/637] [D loss: 0.169442] [G loss: 0.460903]\n",
      "[Epoch 34/200] [Batch 572/637] [D loss: 0.180955] [G loss: 0.510278]\n",
      "[Epoch 34/200] [Batch 573/637] [D loss: 0.153212] [G loss: 0.691664]\n",
      "[Epoch 34/200] [Batch 574/637] [D loss: 0.150074] [G loss: 0.583605]\n",
      "[Epoch 34/200] [Batch 575/637] [D loss: 0.170352] [G loss: 0.485055]\n",
      "[Epoch 34/200] [Batch 576/637] [D loss: 0.151675] [G loss: 0.542726]\n",
      "[Epoch 34/200] [Batch 577/637] [D loss: 0.168760] [G loss: 0.496288]\n",
      "[Epoch 34/200] [Batch 578/637] [D loss: 0.157448] [G loss: 0.661315]\n",
      "[Epoch 34/200] [Batch 579/637] [D loss: 0.201364] [G loss: 0.583938]\n",
      "[Epoch 34/200] [Batch 580/637] [D loss: 0.142381] [G loss: 0.554613]\n",
      "[Epoch 34/200] [Batch 581/637] [D loss: 0.192069] [G loss: 0.433296]\n",
      "[Epoch 34/200] [Batch 582/637] [D loss: 0.159233] [G loss: 0.517316]\n",
      "[Epoch 34/200] [Batch 583/637] [D loss: 0.176489] [G loss: 0.531842]\n",
      "[Epoch 34/200] [Batch 584/637] [D loss: 0.178058] [G loss: 0.468383]\n",
      "[Epoch 34/200] [Batch 585/637] [D loss: 0.175241] [G loss: 0.527693]\n",
      "[Epoch 34/200] [Batch 586/637] [D loss: 0.168214] [G loss: 0.591284]\n",
      "[Epoch 34/200] [Batch 587/637] [D loss: 0.143810] [G loss: 0.606429]\n",
      "[Epoch 34/200] [Batch 588/637] [D loss: 0.172485] [G loss: 0.470077]\n",
      "[Epoch 34/200] [Batch 589/637] [D loss: 0.173719] [G loss: 0.474939]\n",
      "[Epoch 34/200] [Batch 590/637] [D loss: 0.182379] [G loss: 0.480768]\n",
      "[Epoch 34/200] [Batch 591/637] [D loss: 0.163241] [G loss: 0.596115]\n",
      "[Epoch 34/200] [Batch 592/637] [D loss: 0.161369] [G loss: 0.548800]\n",
      "[Epoch 34/200] [Batch 593/637] [D loss: 0.195039] [G loss: 0.439930]\n",
      "[Epoch 34/200] [Batch 594/637] [D loss: 0.172905] [G loss: 0.505563]\n",
      "[Epoch 34/200] [Batch 595/637] [D loss: 0.162528] [G loss: 0.531110]\n",
      "[Epoch 34/200] [Batch 596/637] [D loss: 0.185491] [G loss: 0.512516]\n",
      "[Epoch 34/200] [Batch 597/637] [D loss: 0.181388] [G loss: 0.457104]\n",
      "[Epoch 34/200] [Batch 598/637] [D loss: 0.185104] [G loss: 0.437949]\n",
      "[Epoch 34/200] [Batch 599/637] [D loss: 0.195009] [G loss: 0.476887]\n",
      "[Epoch 34/200] [Batch 600/637] [D loss: 0.180943] [G loss: 0.469539]\n",
      "[Epoch 34/200] [Batch 601/637] [D loss: 0.178464] [G loss: 0.458873]\n",
      "[Epoch 34/200] [Batch 602/637] [D loss: 0.180544] [G loss: 0.447979]\n",
      "[Epoch 34/200] [Batch 603/637] [D loss: 0.178876] [G loss: 0.491699]\n",
      "[Epoch 34/200] [Batch 604/637] [D loss: 0.157340] [G loss: 0.525124]\n",
      "[Epoch 34/200] [Batch 605/637] [D loss: 0.149551] [G loss: 0.486864]\n",
      "[Epoch 34/200] [Batch 606/637] [D loss: 0.167565] [G loss: 0.459601]\n",
      "[Epoch 34/200] [Batch 607/637] [D loss: 0.160448] [G loss: 0.488128]\n",
      "[Epoch 34/200] [Batch 608/637] [D loss: 0.160311] [G loss: 0.453541]\n",
      "[Epoch 34/200] [Batch 609/637] [D loss: 0.165566] [G loss: 0.493970]\n",
      "[Epoch 34/200] [Batch 610/637] [D loss: 0.170796] [G loss: 0.514660]\n",
      "[Epoch 34/200] [Batch 611/637] [D loss: 0.182967] [G loss: 0.470150]\n",
      "[Epoch 34/200] [Batch 612/637] [D loss: 0.164538] [G loss: 0.491634]\n",
      "[Epoch 34/200] [Batch 613/637] [D loss: 0.153777] [G loss: 0.477287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 614/637] [D loss: 0.168896] [G loss: 0.444168]\n",
      "[Epoch 34/200] [Batch 615/637] [D loss: 0.168446] [G loss: 0.455455]\n",
      "[Epoch 34/200] [Batch 616/637] [D loss: 0.151142] [G loss: 0.514096]\n",
      "[Epoch 34/200] [Batch 617/637] [D loss: 0.174149] [G loss: 0.496522]\n",
      "[Epoch 34/200] [Batch 618/637] [D loss: 0.198353] [G loss: 0.446043]\n",
      "[Epoch 34/200] [Batch 619/637] [D loss: 0.168112] [G loss: 0.591886]\n",
      "[Epoch 34/200] [Batch 620/637] [D loss: 0.176023] [G loss: 0.628827]\n",
      "[Epoch 34/200] [Batch 621/637] [D loss: 0.161643] [G loss: 0.459218]\n",
      "[Epoch 34/200] [Batch 622/637] [D loss: 0.182987] [G loss: 0.402139]\n",
      "[Epoch 34/200] [Batch 623/637] [D loss: 0.176600] [G loss: 0.431500]\n",
      "[Epoch 34/200] [Batch 624/637] [D loss: 0.159206] [G loss: 0.538909]\n",
      "[Epoch 34/200] [Batch 625/637] [D loss: 0.170260] [G loss: 0.484100]\n",
      "[Epoch 34/200] [Batch 626/637] [D loss: 0.165620] [G loss: 0.450359]\n",
      "[Epoch 34/200] [Batch 627/637] [D loss: 0.201975] [G loss: 0.393667]\n",
      "[Epoch 34/200] [Batch 628/637] [D loss: 0.163695] [G loss: 0.557856]\n",
      "[Epoch 34/200] [Batch 629/637] [D loss: 0.167548] [G loss: 0.556185]\n",
      "[Epoch 34/200] [Batch 630/637] [D loss: 0.196858] [G loss: 0.487160]\n",
      "[Epoch 34/200] [Batch 631/637] [D loss: 0.157801] [G loss: 0.455896]\n",
      "[Epoch 34/200] [Batch 632/637] [D loss: 0.164646] [G loss: 0.458399]\n",
      "[Epoch 34/200] [Batch 633/637] [D loss: 0.168375] [G loss: 0.439075]\n",
      "[Epoch 34/200] [Batch 634/637] [D loss: 0.183224] [G loss: 0.470714]\n",
      "[Epoch 34/200] [Batch 635/637] [D loss: 0.167385] [G loss: 0.549018]\n",
      "[Epoch 34/200] [Batch 636/637] [D loss: 0.212547] [G loss: 0.544869]\n",
      "[Epoch 35/200] [Batch 0/637] [D loss: 0.279743] [G loss: 0.489431]\n",
      "[Epoch 35/200] [Batch 1/637] [D loss: 0.180811] [G loss: 0.479402]\n",
      "[Epoch 35/200] [Batch 2/637] [D loss: 0.189534] [G loss: 0.439264]\n",
      "[Epoch 35/200] [Batch 3/637] [D loss: 0.207379] [G loss: 0.463667]\n",
      "[Epoch 35/200] [Batch 4/637] [D loss: 0.175520] [G loss: 0.444593]\n",
      "[Epoch 35/200] [Batch 5/637] [D loss: 0.197627] [G loss: 0.477057]\n",
      "[Epoch 35/200] [Batch 6/637] [D loss: 0.186042] [G loss: 0.646492]\n",
      "[Epoch 35/200] [Batch 7/637] [D loss: 0.188418] [G loss: 0.551097]\n",
      "[Epoch 35/200] [Batch 8/637] [D loss: 0.166563] [G loss: 0.508644]\n",
      "[Epoch 35/200] [Batch 9/637] [D loss: 0.209276] [G loss: 0.357386]\n",
      "[Epoch 35/200] [Batch 10/637] [D loss: 0.180156] [G loss: 0.640751]\n",
      "[Epoch 35/200] [Batch 11/637] [D loss: 0.196110] [G loss: 0.676491]\n",
      "[Epoch 35/200] [Batch 12/637] [D loss: 0.181372] [G loss: 0.435874]\n",
      "[Epoch 35/200] [Batch 13/637] [D loss: 0.180466] [G loss: 0.386393]\n",
      "[Epoch 35/200] [Batch 14/637] [D loss: 0.171591] [G loss: 0.452775]\n",
      "[Epoch 35/200] [Batch 15/637] [D loss: 0.163967] [G loss: 0.476785]\n",
      "[Epoch 35/200] [Batch 16/637] [D loss: 0.161791] [G loss: 0.501311]\n",
      "[Epoch 35/200] [Batch 17/637] [D loss: 0.170133] [G loss: 0.506273]\n",
      "[Epoch 35/200] [Batch 18/637] [D loss: 0.151987] [G loss: 0.500414]\n",
      "[Epoch 35/200] [Batch 19/637] [D loss: 0.177375] [G loss: 0.539615]\n",
      "[Epoch 35/200] [Batch 20/637] [D loss: 0.144333] [G loss: 0.602622]\n",
      "[Epoch 35/200] [Batch 21/637] [D loss: 0.186136] [G loss: 0.483073]\n",
      "[Epoch 35/200] [Batch 22/637] [D loss: 0.163836] [G loss: 0.518384]\n",
      "[Epoch 35/200] [Batch 23/637] [D loss: 0.178600] [G loss: 0.489301]\n",
      "[Epoch 35/200] [Batch 24/637] [D loss: 0.173216] [G loss: 0.512712]\n",
      "[Epoch 35/200] [Batch 25/637] [D loss: 0.188344] [G loss: 0.422680]\n",
      "[Epoch 35/200] [Batch 26/637] [D loss: 0.180448] [G loss: 0.437342]\n",
      "[Epoch 35/200] [Batch 27/637] [D loss: 0.192598] [G loss: 0.435125]\n",
      "[Epoch 35/200] [Batch 28/637] [D loss: 0.219498] [G loss: 0.512653]\n",
      "[Epoch 35/200] [Batch 29/637] [D loss: 0.177329] [G loss: 0.467890]\n",
      "[Epoch 35/200] [Batch 30/637] [D loss: 0.187079] [G loss: 0.523444]\n",
      "[Epoch 35/200] [Batch 31/637] [D loss: 0.181216] [G loss: 0.441224]\n",
      "[Epoch 35/200] [Batch 32/637] [D loss: 0.163183] [G loss: 0.480695]\n",
      "[Epoch 35/200] [Batch 33/637] [D loss: 0.172171] [G loss: 0.516599]\n",
      "[Epoch 35/200] [Batch 34/637] [D loss: 0.189197] [G loss: 0.433176]\n",
      "[Epoch 35/200] [Batch 35/637] [D loss: 0.146641] [G loss: 0.500546]\n",
      "[Epoch 35/200] [Batch 36/637] [D loss: 0.175409] [G loss: 0.541491]\n",
      "[Epoch 35/200] [Batch 37/637] [D loss: 0.150662] [G loss: 0.520178]\n",
      "[Epoch 35/200] [Batch 38/637] [D loss: 0.199132] [G loss: 0.481193]\n",
      "[Epoch 35/200] [Batch 39/637] [D loss: 0.188910] [G loss: 0.497718]\n",
      "[Epoch 35/200] [Batch 40/637] [D loss: 0.170845] [G loss: 0.466842]\n",
      "[Epoch 35/200] [Batch 41/637] [D loss: 0.148626] [G loss: 0.499291]\n",
      "[Epoch 35/200] [Batch 42/637] [D loss: 0.168325] [G loss: 0.466429]\n",
      "[Epoch 35/200] [Batch 43/637] [D loss: 0.156324] [G loss: 0.492608]\n",
      "[Epoch 35/200] [Batch 44/637] [D loss: 0.177227] [G loss: 0.489803]\n",
      "[Epoch 35/200] [Batch 45/637] [D loss: 0.164425] [G loss: 0.450807]\n",
      "[Epoch 35/200] [Batch 46/637] [D loss: 0.146748] [G loss: 0.502694]\n",
      "[Epoch 35/200] [Batch 47/637] [D loss: 0.155971] [G loss: 0.509398]\n",
      "[Epoch 35/200] [Batch 48/637] [D loss: 0.151786] [G loss: 0.513594]\n",
      "[Epoch 35/200] [Batch 49/637] [D loss: 0.154370] [G loss: 0.511516]\n",
      "[Epoch 35/200] [Batch 50/637] [D loss: 0.195465] [G loss: 0.463908]\n",
      "[Epoch 35/200] [Batch 51/637] [D loss: 0.170000] [G loss: 0.521909]\n",
      "[Epoch 35/200] [Batch 52/637] [D loss: 0.169947] [G loss: 0.505384]\n",
      "[Epoch 35/200] [Batch 53/637] [D loss: 0.187098] [G loss: 0.443715]\n",
      "[Epoch 35/200] [Batch 54/637] [D loss: 0.174915] [G loss: 0.517014]\n",
      "[Epoch 35/200] [Batch 55/637] [D loss: 0.179544] [G loss: 0.507668]\n",
      "[Epoch 35/200] [Batch 56/637] [D loss: 0.163220] [G loss: 0.507364]\n",
      "[Epoch 35/200] [Batch 57/637] [D loss: 0.222696] [G loss: 0.474767]\n",
      "[Epoch 35/200] [Batch 58/637] [D loss: 0.178966] [G loss: 0.616815]\n",
      "[Epoch 35/200] [Batch 59/637] [D loss: 0.200562] [G loss: 0.490360]\n",
      "[Epoch 35/200] [Batch 60/637] [D loss: 0.166950] [G loss: 0.451555]\n",
      "[Epoch 35/200] [Batch 61/637] [D loss: 0.155999] [G loss: 0.453031]\n",
      "[Epoch 35/200] [Batch 62/637] [D loss: 0.163945] [G loss: 0.458728]\n",
      "[Epoch 35/200] [Batch 63/637] [D loss: 0.145362] [G loss: 0.518821]\n",
      "[Epoch 35/200] [Batch 64/637] [D loss: 0.160879] [G loss: 0.516435]\n",
      "[Epoch 35/200] [Batch 65/637] [D loss: 0.171344] [G loss: 0.461131]\n",
      "[Epoch 35/200] [Batch 66/637] [D loss: 0.151572] [G loss: 0.486783]\n",
      "[Epoch 35/200] [Batch 67/637] [D loss: 0.167945] [G loss: 0.465287]\n",
      "[Epoch 35/200] [Batch 68/637] [D loss: 0.162522] [G loss: 0.561271]\n",
      "[Epoch 35/200] [Batch 69/637] [D loss: 0.142923] [G loss: 0.529873]\n",
      "[Epoch 35/200] [Batch 70/637] [D loss: 0.178206] [G loss: 0.465109]\n",
      "[Epoch 35/200] [Batch 71/637] [D loss: 0.175196] [G loss: 0.520631]\n",
      "[Epoch 35/200] [Batch 72/637] [D loss: 0.172792] [G loss: 0.476241]\n",
      "[Epoch 35/200] [Batch 73/637] [D loss: 0.180661] [G loss: 0.483378]\n",
      "[Epoch 35/200] [Batch 74/637] [D loss: 0.167042] [G loss: 0.454882]\n",
      "[Epoch 35/200] [Batch 75/637] [D loss: 0.175966] [G loss: 0.517517]\n",
      "[Epoch 35/200] [Batch 76/637] [D loss: 0.166409] [G loss: 0.488153]\n",
      "[Epoch 35/200] [Batch 77/637] [D loss: 0.151854] [G loss: 0.510229]\n",
      "[Epoch 35/200] [Batch 78/637] [D loss: 0.221917] [G loss: 0.519819]\n",
      "[Epoch 35/200] [Batch 79/637] [D loss: 0.180518] [G loss: 0.464702]\n",
      "[Epoch 35/200] [Batch 80/637] [D loss: 0.162612] [G loss: 0.440930]\n",
      "[Epoch 35/200] [Batch 81/637] [D loss: 0.159591] [G loss: 0.502043]\n",
      "[Epoch 35/200] [Batch 82/637] [D loss: 0.172821] [G loss: 0.478193]\n",
      "[Epoch 35/200] [Batch 83/637] [D loss: 0.167920] [G loss: 0.472575]\n",
      "[Epoch 35/200] [Batch 84/637] [D loss: 0.157013] [G loss: 0.451849]\n",
      "[Epoch 35/200] [Batch 85/637] [D loss: 0.166336] [G loss: 0.477845]\n",
      "[Epoch 35/200] [Batch 86/637] [D loss: 0.170287] [G loss: 0.466025]\n",
      "[Epoch 35/200] [Batch 87/637] [D loss: 0.140273] [G loss: 0.545891]\n",
      "[Epoch 35/200] [Batch 88/637] [D loss: 0.159087] [G loss: 0.504250]\n",
      "[Epoch 35/200] [Batch 89/637] [D loss: 0.192683] [G loss: 0.490928]\n",
      "[Epoch 35/200] [Batch 90/637] [D loss: 0.153130] [G loss: 0.573916]\n",
      "[Epoch 35/200] [Batch 91/637] [D loss: 0.161795] [G loss: 0.565778]\n",
      "[Epoch 35/200] [Batch 92/637] [D loss: 0.164443] [G loss: 0.470690]\n",
      "[Epoch 35/200] [Batch 93/637] [D loss: 0.163078] [G loss: 0.539059]\n",
      "[Epoch 35/200] [Batch 94/637] [D loss: 0.188632] [G loss: 0.486159]\n",
      "[Epoch 35/200] [Batch 95/637] [D loss: 0.157627] [G loss: 0.637224]\n",
      "[Epoch 35/200] [Batch 96/637] [D loss: 0.157703] [G loss: 0.579265]\n",
      "[Epoch 35/200] [Batch 97/637] [D loss: 0.186080] [G loss: 0.454095]\n",
      "[Epoch 35/200] [Batch 98/637] [D loss: 0.194739] [G loss: 0.480248]\n",
      "[Epoch 35/200] [Batch 99/637] [D loss: 0.203038] [G loss: 0.518502]\n",
      "[Epoch 35/200] [Batch 100/637] [D loss: 0.190087] [G loss: 0.510886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/200] [Batch 101/637] [D loss: 0.153699] [G loss: 0.534521]\n",
      "[Epoch 35/200] [Batch 102/637] [D loss: 0.170614] [G loss: 0.434766]\n",
      "[Epoch 35/200] [Batch 103/637] [D loss: 0.182590] [G loss: 0.455506]\n",
      "[Epoch 35/200] [Batch 104/637] [D loss: 0.165961] [G loss: 0.461350]\n",
      "[Epoch 35/200] [Batch 105/637] [D loss: 0.164204] [G loss: 0.530730]\n",
      "[Epoch 35/200] [Batch 106/637] [D loss: 0.150545] [G loss: 0.514274]\n",
      "[Epoch 35/200] [Batch 107/637] [D loss: 0.163729] [G loss: 0.488816]\n",
      "[Epoch 35/200] [Batch 108/637] [D loss: 0.157744] [G loss: 0.516857]\n",
      "[Epoch 35/200] [Batch 109/637] [D loss: 0.170942] [G loss: 0.488915]\n",
      "[Epoch 35/200] [Batch 110/637] [D loss: 0.149245] [G loss: 0.574964]\n",
      "[Epoch 35/200] [Batch 111/637] [D loss: 0.176967] [G loss: 0.467447]\n",
      "[Epoch 35/200] [Batch 112/637] [D loss: 0.184889] [G loss: 0.436913]\n",
      "[Epoch 35/200] [Batch 113/637] [D loss: 0.166652] [G loss: 0.465092]\n",
      "[Epoch 35/200] [Batch 114/637] [D loss: 0.183925] [G loss: 0.456315]\n",
      "[Epoch 35/200] [Batch 115/637] [D loss: 0.177239] [G loss: 0.466321]\n",
      "[Epoch 35/200] [Batch 116/637] [D loss: 0.164578] [G loss: 0.493001]\n",
      "[Epoch 35/200] [Batch 117/637] [D loss: 0.163931] [G loss: 0.547372]\n",
      "[Epoch 35/200] [Batch 118/637] [D loss: 0.168649] [G loss: 0.518935]\n",
      "[Epoch 35/200] [Batch 119/637] [D loss: 0.192326] [G loss: 0.421429]\n",
      "[Epoch 35/200] [Batch 120/637] [D loss: 0.169406] [G loss: 0.556470]\n",
      "[Epoch 35/200] [Batch 121/637] [D loss: 0.166574] [G loss: 0.519749]\n",
      "[Epoch 35/200] [Batch 122/637] [D loss: 0.167145] [G loss: 0.488073]\n",
      "[Epoch 35/200] [Batch 123/637] [D loss: 0.148723] [G loss: 0.515551]\n",
      "[Epoch 35/200] [Batch 124/637] [D loss: 0.175711] [G loss: 0.552667]\n",
      "[Epoch 35/200] [Batch 125/637] [D loss: 0.162776] [G loss: 0.632856]\n",
      "[Epoch 35/200] [Batch 126/637] [D loss: 0.164522] [G loss: 0.604140]\n",
      "[Epoch 35/200] [Batch 127/637] [D loss: 0.168671] [G loss: 0.519774]\n",
      "[Epoch 35/200] [Batch 128/637] [D loss: 0.193503] [G loss: 0.426195]\n",
      "[Epoch 35/200] [Batch 129/637] [D loss: 0.212790] [G loss: 0.496425]\n",
      "[Epoch 35/200] [Batch 130/637] [D loss: 0.167533] [G loss: 0.528032]\n",
      "[Epoch 35/200] [Batch 131/637] [D loss: 0.151991] [G loss: 0.513709]\n",
      "[Epoch 35/200] [Batch 132/637] [D loss: 0.156344] [G loss: 0.490610]\n",
      "[Epoch 35/200] [Batch 133/637] [D loss: 0.179477] [G loss: 0.491266]\n",
      "[Epoch 35/200] [Batch 134/637] [D loss: 0.174170] [G loss: 0.502116]\n",
      "[Epoch 35/200] [Batch 135/637] [D loss: 0.177540] [G loss: 0.494127]\n",
      "[Epoch 35/200] [Batch 136/637] [D loss: 0.177297] [G loss: 0.512852]\n",
      "[Epoch 35/200] [Batch 137/637] [D loss: 0.164156] [G loss: 0.455535]\n",
      "[Epoch 35/200] [Batch 138/637] [D loss: 0.179026] [G loss: 0.502873]\n",
      "[Epoch 35/200] [Batch 139/637] [D loss: 0.188799] [G loss: 0.420213]\n",
      "[Epoch 35/200] [Batch 140/637] [D loss: 0.170993] [G loss: 0.463549]\n",
      "[Epoch 35/200] [Batch 141/637] [D loss: 0.180405] [G loss: 0.419928]\n",
      "[Epoch 35/200] [Batch 142/637] [D loss: 0.185756] [G loss: 0.432546]\n",
      "[Epoch 35/200] [Batch 143/637] [D loss: 0.168193] [G loss: 0.534454]\n",
      "[Epoch 35/200] [Batch 144/637] [D loss: 0.180590] [G loss: 0.537918]\n",
      "[Epoch 35/200] [Batch 145/637] [D loss: 0.168677] [G loss: 0.512469]\n",
      "[Epoch 35/200] [Batch 146/637] [D loss: 0.156590] [G loss: 0.491065]\n",
      "[Epoch 35/200] [Batch 147/637] [D loss: 0.169784] [G loss: 0.468959]\n",
      "[Epoch 35/200] [Batch 148/637] [D loss: 0.163510] [G loss: 0.514860]\n",
      "[Epoch 35/200] [Batch 149/637] [D loss: 0.182986] [G loss: 0.532215]\n",
      "[Epoch 35/200] [Batch 150/637] [D loss: 0.156671] [G loss: 0.455882]\n",
      "[Epoch 35/200] [Batch 151/637] [D loss: 0.168622] [G loss: 0.448702]\n",
      "[Epoch 35/200] [Batch 152/637] [D loss: 0.181272] [G loss: 0.428234]\n",
      "[Epoch 35/200] [Batch 153/637] [D loss: 0.150187] [G loss: 0.555433]\n",
      "[Epoch 35/200] [Batch 154/637] [D loss: 0.169174] [G loss: 0.543725]\n",
      "[Epoch 35/200] [Batch 155/637] [D loss: 0.177764] [G loss: 0.527418]\n",
      "[Epoch 35/200] [Batch 156/637] [D loss: 0.156399] [G loss: 0.524599]\n",
      "[Epoch 35/200] [Batch 157/637] [D loss: 0.162242] [G loss: 0.482244]\n",
      "[Epoch 35/200] [Batch 158/637] [D loss: 0.154364] [G loss: 0.474718]\n",
      "[Epoch 35/200] [Batch 159/637] [D loss: 0.144882] [G loss: 0.588753]\n",
      "[Epoch 35/200] [Batch 160/637] [D loss: 0.165481] [G loss: 0.529971]\n",
      "[Epoch 35/200] [Batch 161/637] [D loss: 0.175378] [G loss: 0.431911]\n",
      "[Epoch 35/200] [Batch 162/637] [D loss: 0.148464] [G loss: 0.596860]\n",
      "[Epoch 35/200] [Batch 163/637] [D loss: 0.159437] [G loss: 0.542799]\n",
      "[Epoch 35/200] [Batch 164/637] [D loss: 0.160346] [G loss: 0.460610]\n",
      "[Epoch 35/200] [Batch 165/637] [D loss: 0.206284] [G loss: 0.398205]\n",
      "[Epoch 35/200] [Batch 166/637] [D loss: 0.184116] [G loss: 0.503852]\n",
      "[Epoch 35/200] [Batch 167/637] [D loss: 0.177064] [G loss: 0.469038]\n",
      "[Epoch 35/200] [Batch 168/637] [D loss: 0.186857] [G loss: 0.416793]\n",
      "[Epoch 35/200] [Batch 169/637] [D loss: 0.177442] [G loss: 0.459880]\n",
      "[Epoch 35/200] [Batch 170/637] [D loss: 0.192332] [G loss: 0.466315]\n",
      "[Epoch 35/200] [Batch 171/637] [D loss: 0.153395] [G loss: 0.499419]\n",
      "[Epoch 35/200] [Batch 172/637] [D loss: 0.175882] [G loss: 0.453450]\n",
      "[Epoch 35/200] [Batch 173/637] [D loss: 0.161582] [G loss: 0.512949]\n",
      "[Epoch 35/200] [Batch 174/637] [D loss: 0.177346] [G loss: 0.486333]\n",
      "[Epoch 35/200] [Batch 175/637] [D loss: 0.147561] [G loss: 0.514962]\n",
      "[Epoch 35/200] [Batch 176/637] [D loss: 0.207302] [G loss: 0.465247]\n",
      "[Epoch 35/200] [Batch 177/637] [D loss: 0.284652] [G loss: 0.494644]\n",
      "[Epoch 35/200] [Batch 178/637] [D loss: 0.292271] [G loss: 0.391220]\n",
      "[Epoch 35/200] [Batch 179/637] [D loss: 0.234279] [G loss: 0.501926]\n",
      "[Epoch 35/200] [Batch 180/637] [D loss: 0.288763] [G loss: 0.305445]\n",
      "[Epoch 35/200] [Batch 181/637] [D loss: 0.285550] [G loss: 0.754512]\n",
      "[Epoch 35/200] [Batch 182/637] [D loss: 0.235811] [G loss: 0.556814]\n",
      "[Epoch 35/200] [Batch 183/637] [D loss: 0.217663] [G loss: 0.406269]\n",
      "[Epoch 35/200] [Batch 184/637] [D loss: 0.211385] [G loss: 0.449684]\n",
      "[Epoch 35/200] [Batch 185/637] [D loss: 0.212878] [G loss: 0.426646]\n",
      "[Epoch 35/200] [Batch 186/637] [D loss: 0.213618] [G loss: 0.426435]\n",
      "[Epoch 35/200] [Batch 187/637] [D loss: 0.199731] [G loss: 0.489619]\n",
      "[Epoch 35/200] [Batch 188/637] [D loss: 0.191555] [G loss: 0.552163]\n",
      "[Epoch 35/200] [Batch 189/637] [D loss: 0.184251] [G loss: 0.491537]\n",
      "[Epoch 35/200] [Batch 190/637] [D loss: 0.186906] [G loss: 0.402462]\n",
      "[Epoch 35/200] [Batch 191/637] [D loss: 0.181637] [G loss: 0.411355]\n",
      "[Epoch 35/200] [Batch 192/637] [D loss: 0.183317] [G loss: 0.438945]\n",
      "[Epoch 35/200] [Batch 193/637] [D loss: 0.179502] [G loss: 0.575119]\n",
      "[Epoch 35/200] [Batch 194/637] [D loss: 0.176622] [G loss: 0.532300]\n",
      "[Epoch 35/200] [Batch 195/637] [D loss: 0.179207] [G loss: 0.488876]\n",
      "[Epoch 35/200] [Batch 196/637] [D loss: 0.174755] [G loss: 0.475984]\n",
      "[Epoch 35/200] [Batch 197/637] [D loss: 0.193612] [G loss: 0.477095]\n",
      "[Epoch 35/200] [Batch 198/637] [D loss: 0.174951] [G loss: 0.545695]\n",
      "[Epoch 35/200] [Batch 199/637] [D loss: 0.179974] [G loss: 0.546089]\n",
      "[Epoch 35/200] [Batch 200/637] [D loss: 0.166189] [G loss: 0.505630]\n",
      "[Epoch 35/200] [Batch 201/637] [D loss: 0.193453] [G loss: 0.493372]\n",
      "[Epoch 35/200] [Batch 202/637] [D loss: 0.175719] [G loss: 0.471731]\n",
      "[Epoch 35/200] [Batch 203/637] [D loss: 0.176230] [G loss: 0.529152]\n",
      "[Epoch 35/200] [Batch 204/637] [D loss: 0.192729] [G loss: 0.548978]\n",
      "[Epoch 35/200] [Batch 205/637] [D loss: 0.180922] [G loss: 0.562232]\n",
      "[Epoch 35/200] [Batch 206/637] [D loss: 0.182110] [G loss: 0.497492]\n",
      "[Epoch 35/200] [Batch 207/637] [D loss: 0.179178] [G loss: 0.386280]\n",
      "[Epoch 35/200] [Batch 208/637] [D loss: 0.159332] [G loss: 0.442616]\n",
      "[Epoch 35/200] [Batch 209/637] [D loss: 0.172236] [G loss: 0.400406]\n",
      "[Epoch 35/200] [Batch 210/637] [D loss: 0.207074] [G loss: 0.433556]\n",
      "[Epoch 35/200] [Batch 211/637] [D loss: 0.165413] [G loss: 0.575809]\n",
      "[Epoch 35/200] [Batch 212/637] [D loss: 0.198859] [G loss: 0.434014]\n",
      "[Epoch 35/200] [Batch 213/637] [D loss: 0.173232] [G loss: 0.491496]\n",
      "[Epoch 35/200] [Batch 214/637] [D loss: 0.162203] [G loss: 0.461057]\n",
      "[Epoch 35/200] [Batch 215/637] [D loss: 0.207843] [G loss: 0.344352]\n",
      "[Epoch 35/200] [Batch 216/637] [D loss: 0.173746] [G loss: 0.502066]\n",
      "[Epoch 35/200] [Batch 217/637] [D loss: 0.181838] [G loss: 0.549302]\n",
      "[Epoch 35/200] [Batch 218/637] [D loss: 0.167352] [G loss: 0.548061]\n",
      "[Epoch 35/200] [Batch 219/637] [D loss: 0.170272] [G loss: 0.478772]\n",
      "[Epoch 35/200] [Batch 220/637] [D loss: 0.149548] [G loss: 0.516536]\n",
      "[Epoch 35/200] [Batch 221/637] [D loss: 0.170068] [G loss: 0.466987]\n",
      "[Epoch 35/200] [Batch 222/637] [D loss: 0.189800] [G loss: 0.475685]\n",
      "[Epoch 35/200] [Batch 223/637] [D loss: 0.150337] [G loss: 0.568234]\n",
      "[Epoch 35/200] [Batch 224/637] [D loss: 0.165528] [G loss: 0.552605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/200] [Batch 225/637] [D loss: 0.172982] [G loss: 0.512183]\n",
      "[Epoch 35/200] [Batch 226/637] [D loss: 0.151054] [G loss: 0.459710]\n",
      "[Epoch 35/200] [Batch 227/637] [D loss: 0.183494] [G loss: 0.464220]\n",
      "[Epoch 35/200] [Batch 228/637] [D loss: 0.161021] [G loss: 0.478683]\n",
      "[Epoch 35/200] [Batch 229/637] [D loss: 0.180495] [G loss: 0.488501]\n",
      "[Epoch 35/200] [Batch 230/637] [D loss: 0.167554] [G loss: 0.531597]\n",
      "[Epoch 35/200] [Batch 231/637] [D loss: 0.183775] [G loss: 0.502630]\n",
      "[Epoch 35/200] [Batch 232/637] [D loss: 0.171304] [G loss: 0.571710]\n",
      "[Epoch 35/200] [Batch 233/637] [D loss: 0.197197] [G loss: 0.476405]\n",
      "[Epoch 35/200] [Batch 234/637] [D loss: 0.159019] [G loss: 0.496381]\n",
      "[Epoch 35/200] [Batch 235/637] [D loss: 0.164779] [G loss: 0.467289]\n",
      "[Epoch 35/200] [Batch 236/637] [D loss: 0.155244] [G loss: 0.492900]\n",
      "[Epoch 35/200] [Batch 237/637] [D loss: 0.159380] [G loss: 0.533404]\n",
      "[Epoch 35/200] [Batch 238/637] [D loss: 0.164297] [G loss: 0.486566]\n",
      "[Epoch 35/200] [Batch 239/637] [D loss: 0.156787] [G loss: 0.476778]\n",
      "[Epoch 35/200] [Batch 240/637] [D loss: 0.155590] [G loss: 0.477796]\n",
      "[Epoch 35/200] [Batch 241/637] [D loss: 0.175043] [G loss: 0.446818]\n",
      "[Epoch 35/200] [Batch 242/637] [D loss: 0.150764] [G loss: 0.461765]\n",
      "[Epoch 35/200] [Batch 243/637] [D loss: 0.153801] [G loss: 0.518551]\n",
      "[Epoch 35/200] [Batch 244/637] [D loss: 0.158498] [G loss: 0.484339]\n",
      "[Epoch 35/200] [Batch 245/637] [D loss: 0.162292] [G loss: 0.486725]\n",
      "[Epoch 35/200] [Batch 246/637] [D loss: 0.171913] [G loss: 0.488875]\n",
      "[Epoch 35/200] [Batch 247/637] [D loss: 0.162697] [G loss: 0.478028]\n",
      "[Epoch 35/200] [Batch 248/637] [D loss: 0.162326] [G loss: 0.541607]\n",
      "[Epoch 35/200] [Batch 249/637] [D loss: 0.182736] [G loss: 0.429444]\n",
      "[Epoch 35/200] [Batch 250/637] [D loss: 0.167161] [G loss: 0.582326]\n",
      "[Epoch 35/200] [Batch 251/637] [D loss: 0.185228] [G loss: 0.438926]\n",
      "[Epoch 35/200] [Batch 252/637] [D loss: 0.193199] [G loss: 0.426056]\n",
      "[Epoch 35/200] [Batch 253/637] [D loss: 0.159672] [G loss: 0.512798]\n",
      "[Epoch 35/200] [Batch 254/637] [D loss: 0.171102] [G loss: 0.503918]\n",
      "[Epoch 35/200] [Batch 255/637] [D loss: 0.148043] [G loss: 0.488653]\n",
      "[Epoch 35/200] [Batch 256/637] [D loss: 0.163148] [G loss: 0.517368]\n",
      "[Epoch 35/200] [Batch 257/637] [D loss: 0.147173] [G loss: 0.473898]\n",
      "[Epoch 35/200] [Batch 258/637] [D loss: 0.145676] [G loss: 0.525691]\n",
      "[Epoch 35/200] [Batch 259/637] [D loss: 0.149511] [G loss: 0.526719]\n",
      "[Epoch 35/200] [Batch 260/637] [D loss: 0.162440] [G loss: 0.527775]\n",
      "[Epoch 35/200] [Batch 261/637] [D loss: 0.137321] [G loss: 0.527344]\n",
      "[Epoch 35/200] [Batch 262/637] [D loss: 0.216552] [G loss: 0.533761]\n",
      "[Epoch 35/200] [Batch 263/637] [D loss: 0.175729] [G loss: 0.452437]\n",
      "[Epoch 35/200] [Batch 264/637] [D loss: 0.182859] [G loss: 0.469456]\n",
      "[Epoch 35/200] [Batch 265/637] [D loss: 0.153561] [G loss: 0.515912]\n",
      "[Epoch 35/200] [Batch 266/637] [D loss: 0.219729] [G loss: 0.484310]\n",
      "[Epoch 35/200] [Batch 267/637] [D loss: 0.174227] [G loss: 0.478275]\n",
      "[Epoch 35/200] [Batch 268/637] [D loss: 0.149452] [G loss: 0.474345]\n",
      "[Epoch 35/200] [Batch 269/637] [D loss: 0.174933] [G loss: 0.469280]\n",
      "[Epoch 35/200] [Batch 270/637] [D loss: 0.165633] [G loss: 0.519796]\n",
      "[Epoch 35/200] [Batch 271/637] [D loss: 0.169425] [G loss: 0.468751]\n",
      "[Epoch 35/200] [Batch 272/637] [D loss: 0.176482] [G loss: 0.411224]\n",
      "[Epoch 35/200] [Batch 273/637] [D loss: 0.142135] [G loss: 0.595725]\n",
      "[Epoch 35/200] [Batch 274/637] [D loss: 0.172308] [G loss: 0.556618]\n",
      "[Epoch 35/200] [Batch 275/637] [D loss: 0.169894] [G loss: 0.461070]\n",
      "[Epoch 35/200] [Batch 276/637] [D loss: 0.166854] [G loss: 0.440942]\n",
      "[Epoch 35/200] [Batch 277/637] [D loss: 0.168558] [G loss: 0.536895]\n",
      "[Epoch 35/200] [Batch 278/637] [D loss: 0.168352] [G loss: 0.497342]\n",
      "[Epoch 35/200] [Batch 279/637] [D loss: 0.193131] [G loss: 0.473244]\n",
      "[Epoch 35/200] [Batch 280/637] [D loss: 0.157807] [G loss: 0.505479]\n",
      "[Epoch 35/200] [Batch 281/637] [D loss: 0.157909] [G loss: 0.441056]\n",
      "[Epoch 35/200] [Batch 282/637] [D loss: 0.149927] [G loss: 0.510386]\n",
      "[Epoch 35/200] [Batch 283/637] [D loss: 0.163654] [G loss: 0.491974]\n",
      "[Epoch 35/200] [Batch 284/637] [D loss: 0.153262] [G loss: 0.539397]\n",
      "[Epoch 35/200] [Batch 285/637] [D loss: 0.170001] [G loss: 0.489283]\n",
      "[Epoch 35/200] [Batch 286/637] [D loss: 0.167687] [G loss: 0.510480]\n",
      "[Epoch 35/200] [Batch 287/637] [D loss: 0.177454] [G loss: 0.468918]\n",
      "[Epoch 35/200] [Batch 288/637] [D loss: 0.186792] [G loss: 0.406891]\n",
      "[Epoch 35/200] [Batch 289/637] [D loss: 0.160882] [G loss: 0.521179]\n",
      "[Epoch 35/200] [Batch 290/637] [D loss: 0.170211] [G loss: 0.555634]\n",
      "[Epoch 35/200] [Batch 291/637] [D loss: 0.166728] [G loss: 0.504460]\n",
      "[Epoch 35/200] [Batch 292/637] [D loss: 0.171643] [G loss: 0.501883]\n",
      "[Epoch 35/200] [Batch 293/637] [D loss: 0.183803] [G loss: 0.457370]\n",
      "[Epoch 35/200] [Batch 294/637] [D loss: 0.165371] [G loss: 0.458300]\n",
      "[Epoch 35/200] [Batch 295/637] [D loss: 0.164727] [G loss: 0.458507]\n",
      "[Epoch 35/200] [Batch 296/637] [D loss: 0.148356] [G loss: 0.499674]\n",
      "[Epoch 35/200] [Batch 297/637] [D loss: 0.171572] [G loss: 0.467968]\n",
      "[Epoch 35/200] [Batch 298/637] [D loss: 0.146665] [G loss: 0.468478]\n",
      "[Epoch 35/200] [Batch 299/637] [D loss: 0.159264] [G loss: 0.488980]\n",
      "[Epoch 35/200] [Batch 300/637] [D loss: 0.173021] [G loss: 0.476792]\n",
      "[Epoch 35/200] [Batch 301/637] [D loss: 0.163489] [G loss: 0.500508]\n",
      "[Epoch 35/200] [Batch 302/637] [D loss: 0.180917] [G loss: 0.444871]\n",
      "[Epoch 35/200] [Batch 303/637] [D loss: 0.173408] [G loss: 0.450993]\n",
      "[Epoch 35/200] [Batch 304/637] [D loss: 0.175176] [G loss: 0.466407]\n",
      "[Epoch 35/200] [Batch 305/637] [D loss: 0.169757] [G loss: 0.486482]\n",
      "[Epoch 35/200] [Batch 306/637] [D loss: 0.178317] [G loss: 0.495406]\n",
      "[Epoch 35/200] [Batch 307/637] [D loss: 0.155672] [G loss: 0.511774]\n",
      "[Epoch 35/200] [Batch 308/637] [D loss: 0.207980] [G loss: 0.472569]\n",
      "[Epoch 35/200] [Batch 309/637] [D loss: 0.163562] [G loss: 0.437455]\n",
      "[Epoch 35/200] [Batch 310/637] [D loss: 0.164430] [G loss: 0.506079]\n",
      "[Epoch 35/200] [Batch 311/637] [D loss: 0.146604] [G loss: 0.537445]\n",
      "[Epoch 35/200] [Batch 312/637] [D loss: 0.191043] [G loss: 0.452327]\n",
      "[Epoch 35/200] [Batch 313/637] [D loss: 0.173468] [G loss: 0.422777]\n",
      "[Epoch 35/200] [Batch 314/637] [D loss: 0.180700] [G loss: 0.414095]\n",
      "[Epoch 35/200] [Batch 315/637] [D loss: 0.156344] [G loss: 0.607948]\n",
      "[Epoch 35/200] [Batch 316/637] [D loss: 0.178461] [G loss: 0.528764]\n",
      "[Epoch 35/200] [Batch 317/637] [D loss: 0.174495] [G loss: 0.604116]\n",
      "[Epoch 35/200] [Batch 318/637] [D loss: 0.162260] [G loss: 0.467645]\n",
      "[Epoch 35/200] [Batch 319/637] [D loss: 0.173134] [G loss: 0.434346]\n",
      "[Epoch 35/200] [Batch 320/637] [D loss: 0.195820] [G loss: 0.426363]\n",
      "[Epoch 35/200] [Batch 321/637] [D loss: 0.161689] [G loss: 0.545059]\n",
      "[Epoch 35/200] [Batch 322/637] [D loss: 0.152954] [G loss: 0.526313]\n",
      "[Epoch 35/200] [Batch 323/637] [D loss: 0.178422] [G loss: 0.445408]\n",
      "[Epoch 35/200] [Batch 324/637] [D loss: 0.183443] [G loss: 0.458257]\n",
      "[Epoch 35/200] [Batch 325/637] [D loss: 0.184814] [G loss: 0.441503]\n",
      "[Epoch 35/200] [Batch 326/637] [D loss: 0.165617] [G loss: 0.446080]\n",
      "[Epoch 35/200] [Batch 327/637] [D loss: 0.175135] [G loss: 0.447612]\n",
      "[Epoch 35/200] [Batch 328/637] [D loss: 0.167536] [G loss: 0.496217]\n",
      "[Epoch 35/200] [Batch 329/637] [D loss: 0.170872] [G loss: 0.508288]\n",
      "[Epoch 35/200] [Batch 330/637] [D loss: 0.156901] [G loss: 0.478282]\n",
      "[Epoch 35/200] [Batch 331/637] [D loss: 0.155443] [G loss: 0.504695]\n",
      "[Epoch 35/200] [Batch 332/637] [D loss: 0.159461] [G loss: 0.527672]\n",
      "[Epoch 35/200] [Batch 333/637] [D loss: 0.186330] [G loss: 0.496496]\n",
      "[Epoch 35/200] [Batch 334/637] [D loss: 0.167057] [G loss: 0.528276]\n",
      "[Epoch 35/200] [Batch 335/637] [D loss: 0.176643] [G loss: 0.465186]\n",
      "[Epoch 35/200] [Batch 336/637] [D loss: 0.165917] [G loss: 0.529048]\n",
      "[Epoch 35/200] [Batch 337/637] [D loss: 0.200827] [G loss: 0.471947]\n",
      "[Epoch 35/200] [Batch 338/637] [D loss: 0.181016] [G loss: 0.398624]\n",
      "[Epoch 35/200] [Batch 339/637] [D loss: 0.174464] [G loss: 0.492809]\n",
      "[Epoch 35/200] [Batch 340/637] [D loss: 0.185893] [G loss: 0.558114]\n",
      "[Epoch 35/200] [Batch 341/637] [D loss: 0.164856] [G loss: 0.508835]\n",
      "[Epoch 35/200] [Batch 342/637] [D loss: 0.159517] [G loss: 0.497658]\n",
      "[Epoch 35/200] [Batch 343/637] [D loss: 0.164721] [G loss: 0.506806]\n",
      "[Epoch 35/200] [Batch 344/637] [D loss: 0.157771] [G loss: 0.508732]\n",
      "[Epoch 35/200] [Batch 345/637] [D loss: 0.203617] [G loss: 0.459493]\n",
      "[Epoch 35/200] [Batch 346/637] [D loss: 0.163251] [G loss: 0.578389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/200] [Batch 347/637] [D loss: 0.159282] [G loss: 0.499189]\n",
      "[Epoch 35/200] [Batch 348/637] [D loss: 0.149898] [G loss: 0.488387]\n",
      "[Epoch 35/200] [Batch 349/637] [D loss: 0.152487] [G loss: 0.514247]\n",
      "[Epoch 35/200] [Batch 350/637] [D loss: 0.186765] [G loss: 0.474798]\n",
      "[Epoch 35/200] [Batch 351/637] [D loss: 0.184365] [G loss: 0.468955]\n",
      "[Epoch 35/200] [Batch 352/637] [D loss: 0.167101] [G loss: 0.481496]\n",
      "[Epoch 35/200] [Batch 353/637] [D loss: 0.186758] [G loss: 0.594428]\n",
      "[Epoch 35/200] [Batch 354/637] [D loss: 0.184421] [G loss: 0.492998]\n",
      "[Epoch 35/200] [Batch 355/637] [D loss: 0.211646] [G loss: 0.490947]\n",
      "[Epoch 35/200] [Batch 356/637] [D loss: 0.167486] [G loss: 0.492303]\n",
      "[Epoch 35/200] [Batch 357/637] [D loss: 0.182119] [G loss: 0.449077]\n",
      "[Epoch 35/200] [Batch 358/637] [D loss: 0.161894] [G loss: 0.545069]\n",
      "[Epoch 35/200] [Batch 359/637] [D loss: 0.192438] [G loss: 0.460822]\n",
      "[Epoch 35/200] [Batch 360/637] [D loss: 0.173602] [G loss: 0.454724]\n",
      "[Epoch 35/200] [Batch 361/637] [D loss: 0.176226] [G loss: 0.516116]\n",
      "[Epoch 35/200] [Batch 362/637] [D loss: 0.159680] [G loss: 0.451620]\n",
      "[Epoch 35/200] [Batch 363/637] [D loss: 0.168364] [G loss: 0.517415]\n",
      "[Epoch 35/200] [Batch 364/637] [D loss: 0.160363] [G loss: 0.483360]\n",
      "[Epoch 35/200] [Batch 365/637] [D loss: 0.172985] [G loss: 0.508594]\n",
      "[Epoch 35/200] [Batch 366/637] [D loss: 0.161327] [G loss: 0.556568]\n",
      "[Epoch 35/200] [Batch 367/637] [D loss: 0.170297] [G loss: 0.471084]\n",
      "[Epoch 35/200] [Batch 368/637] [D loss: 0.153598] [G loss: 0.532182]\n",
      "[Epoch 35/200] [Batch 369/637] [D loss: 0.165630] [G loss: 0.436828]\n",
      "[Epoch 35/200] [Batch 370/637] [D loss: 0.181144] [G loss: 0.484138]\n",
      "[Epoch 35/200] [Batch 371/637] [D loss: 0.150368] [G loss: 0.533090]\n",
      "[Epoch 35/200] [Batch 372/637] [D loss: 0.178311] [G loss: 0.479244]\n",
      "[Epoch 35/200] [Batch 373/637] [D loss: 0.175497] [G loss: 0.485141]\n",
      "[Epoch 35/200] [Batch 374/637] [D loss: 0.199499] [G loss: 0.451967]\n",
      "[Epoch 35/200] [Batch 375/637] [D loss: 0.176128] [G loss: 0.480358]\n",
      "[Epoch 35/200] [Batch 376/637] [D loss: 0.179047] [G loss: 0.503922]\n",
      "[Epoch 35/200] [Batch 377/637] [D loss: 0.161475] [G loss: 0.537841]\n",
      "[Epoch 35/200] [Batch 378/637] [D loss: 0.176257] [G loss: 0.466691]\n",
      "[Epoch 35/200] [Batch 379/637] [D loss: 0.195754] [G loss: 0.446429]\n",
      "[Epoch 35/200] [Batch 380/637] [D loss: 0.219137] [G loss: 0.410799]\n",
      "[Epoch 35/200] [Batch 381/637] [D loss: 0.178968] [G loss: 0.553252]\n",
      "[Epoch 35/200] [Batch 382/637] [D loss: 0.192469] [G loss: 0.467011]\n",
      "[Epoch 35/200] [Batch 383/637] [D loss: 0.179063] [G loss: 0.456859]\n",
      "[Epoch 35/200] [Batch 384/637] [D loss: 0.160971] [G loss: 0.489458]\n",
      "[Epoch 35/200] [Batch 385/637] [D loss: 0.172623] [G loss: 0.435172]\n",
      "[Epoch 35/200] [Batch 386/637] [D loss: 0.171835] [G loss: 0.479331]\n",
      "[Epoch 35/200] [Batch 387/637] [D loss: 0.186177] [G loss: 0.452385]\n",
      "[Epoch 35/200] [Batch 388/637] [D loss: 0.163801] [G loss: 0.518031]\n",
      "[Epoch 35/200] [Batch 389/637] [D loss: 0.184762] [G loss: 0.466905]\n",
      "[Epoch 35/200] [Batch 390/637] [D loss: 0.167819] [G loss: 0.456336]\n",
      "[Epoch 35/200] [Batch 391/637] [D loss: 0.160269] [G loss: 0.535270]\n",
      "[Epoch 35/200] [Batch 392/637] [D loss: 0.168830] [G loss: 0.472774]\n",
      "[Epoch 35/200] [Batch 393/637] [D loss: 0.170572] [G loss: 0.487045]\n",
      "[Epoch 35/200] [Batch 394/637] [D loss: 0.168225] [G loss: 0.521872]\n",
      "[Epoch 35/200] [Batch 395/637] [D loss: 0.151680] [G loss: 0.620759]\n",
      "[Epoch 35/200] [Batch 396/637] [D loss: 0.169985] [G loss: 0.519796]\n",
      "[Epoch 35/200] [Batch 397/637] [D loss: 0.187980] [G loss: 0.441414]\n",
      "[Epoch 35/200] [Batch 398/637] [D loss: 0.166256] [G loss: 0.434910]\n",
      "[Epoch 35/200] [Batch 399/637] [D loss: 0.167410] [G loss: 0.566467]\n",
      "[Epoch 35/200] [Batch 400/637] [D loss: 0.174784] [G loss: 0.504441]\n",
      "[Epoch 35/200] [Batch 401/637] [D loss: 0.171825] [G loss: 0.494082]\n",
      "[Epoch 35/200] [Batch 402/637] [D loss: 0.180344] [G loss: 0.461293]\n",
      "[Epoch 35/200] [Batch 403/637] [D loss: 0.173766] [G loss: 0.444717]\n",
      "[Epoch 35/200] [Batch 404/637] [D loss: 0.188332] [G loss: 0.401293]\n",
      "[Epoch 35/200] [Batch 405/637] [D loss: 0.163679] [G loss: 0.450940]\n",
      "[Epoch 35/200] [Batch 406/637] [D loss: 0.147542] [G loss: 0.460057]\n",
      "[Epoch 35/200] [Batch 407/637] [D loss: 0.178909] [G loss: 0.452482]\n",
      "[Epoch 35/200] [Batch 408/637] [D loss: 0.203554] [G loss: 0.489326]\n",
      "[Epoch 35/200] [Batch 409/637] [D loss: 0.192295] [G loss: 0.406560]\n",
      "[Epoch 35/200] [Batch 410/637] [D loss: 0.176036] [G loss: 0.447151]\n",
      "[Epoch 35/200] [Batch 411/637] [D loss: 0.180902] [G loss: 0.475926]\n",
      "[Epoch 35/200] [Batch 412/637] [D loss: 0.169560] [G loss: 0.459246]\n",
      "[Epoch 35/200] [Batch 413/637] [D loss: 0.154098] [G loss: 0.517967]\n",
      "[Epoch 35/200] [Batch 414/637] [D loss: 0.186266] [G loss: 0.459847]\n",
      "[Epoch 35/200] [Batch 415/637] [D loss: 0.154452] [G loss: 0.497960]\n",
      "[Epoch 35/200] [Batch 416/637] [D loss: 0.163875] [G loss: 0.469789]\n",
      "[Epoch 35/200] [Batch 417/637] [D loss: 0.169457] [G loss: 0.535900]\n",
      "[Epoch 35/200] [Batch 418/637] [D loss: 0.167556] [G loss: 0.443609]\n",
      "[Epoch 35/200] [Batch 419/637] [D loss: 0.165845] [G loss: 0.472515]\n",
      "[Epoch 35/200] [Batch 420/637] [D loss: 0.182608] [G loss: 0.437594]\n",
      "[Epoch 35/200] [Batch 421/637] [D loss: 0.154070] [G loss: 0.519818]\n",
      "[Epoch 35/200] [Batch 422/637] [D loss: 0.165755] [G loss: 0.497511]\n",
      "[Epoch 35/200] [Batch 423/637] [D loss: 0.168885] [G loss: 0.499364]\n",
      "[Epoch 35/200] [Batch 424/637] [D loss: 0.203257] [G loss: 0.417631]\n",
      "[Epoch 35/200] [Batch 425/637] [D loss: 0.188800] [G loss: 0.430441]\n",
      "[Epoch 35/200] [Batch 426/637] [D loss: 0.175568] [G loss: 0.446362]\n",
      "[Epoch 35/200] [Batch 427/637] [D loss: 0.167693] [G loss: 0.495483]\n",
      "[Epoch 35/200] [Batch 428/637] [D loss: 0.184269] [G loss: 0.413686]\n",
      "[Epoch 35/200] [Batch 429/637] [D loss: 0.163551] [G loss: 0.551775]\n",
      "[Epoch 35/200] [Batch 430/637] [D loss: 0.166020] [G loss: 0.498360]\n",
      "[Epoch 35/200] [Batch 431/637] [D loss: 0.166156] [G loss: 0.415225]\n",
      "[Epoch 35/200] [Batch 432/637] [D loss: 0.188118] [G loss: 0.405562]\n",
      "[Epoch 35/200] [Batch 433/637] [D loss: 0.192708] [G loss: 0.482590]\n",
      "[Epoch 35/200] [Batch 434/637] [D loss: 0.186608] [G loss: 0.535214]\n",
      "[Epoch 35/200] [Batch 435/637] [D loss: 0.172618] [G loss: 0.471340]\n",
      "[Epoch 35/200] [Batch 436/637] [D loss: 0.168125] [G loss: 0.449955]\n",
      "[Epoch 35/200] [Batch 437/637] [D loss: 0.183550] [G loss: 0.438127]\n",
      "[Epoch 35/200] [Batch 438/637] [D loss: 0.175075] [G loss: 0.475021]\n",
      "[Epoch 35/200] [Batch 439/637] [D loss: 0.170190] [G loss: 0.538793]\n",
      "[Epoch 35/200] [Batch 440/637] [D loss: 0.154031] [G loss: 0.504595]\n",
      "[Epoch 35/200] [Batch 441/637] [D loss: 0.167455] [G loss: 0.541053]\n",
      "[Epoch 35/200] [Batch 442/637] [D loss: 0.179091] [G loss: 0.481256]\n",
      "[Epoch 35/200] [Batch 443/637] [D loss: 0.176732] [G loss: 0.429755]\n",
      "[Epoch 35/200] [Batch 444/637] [D loss: 0.181088] [G loss: 0.449857]\n",
      "[Epoch 35/200] [Batch 445/637] [D loss: 0.197585] [G loss: 0.490343]\n",
      "[Epoch 35/200] [Batch 446/637] [D loss: 0.157340] [G loss: 0.551151]\n",
      "[Epoch 35/200] [Batch 447/637] [D loss: 0.157682] [G loss: 0.526885]\n",
      "[Epoch 35/200] [Batch 448/637] [D loss: 0.174560] [G loss: 0.517376]\n",
      "[Epoch 35/200] [Batch 449/637] [D loss: 0.164677] [G loss: 0.483694]\n",
      "[Epoch 35/200] [Batch 450/637] [D loss: 0.181706] [G loss: 0.452187]\n",
      "[Epoch 35/200] [Batch 451/637] [D loss: 0.182860] [G loss: 0.431518]\n",
      "[Epoch 35/200] [Batch 452/637] [D loss: 0.197731] [G loss: 0.526978]\n",
      "[Epoch 35/200] [Batch 453/637] [D loss: 0.167222] [G loss: 0.526947]\n",
      "[Epoch 35/200] [Batch 454/637] [D loss: 0.182165] [G loss: 0.477007]\n",
      "[Epoch 35/200] [Batch 455/637] [D loss: 0.162343] [G loss: 0.514313]\n",
      "[Epoch 35/200] [Batch 456/637] [D loss: 0.137418] [G loss: 0.502393]\n",
      "[Epoch 35/200] [Batch 457/637] [D loss: 0.198526] [G loss: 0.460990]\n",
      "[Epoch 35/200] [Batch 458/637] [D loss: 0.174512] [G loss: 0.426594]\n",
      "[Epoch 35/200] [Batch 459/637] [D loss: 0.172570] [G loss: 0.546468]\n",
      "[Epoch 35/200] [Batch 460/637] [D loss: 0.170683] [G loss: 0.557420]\n",
      "[Epoch 35/200] [Batch 461/637] [D loss: 0.164248] [G loss: 0.499536]\n",
      "[Epoch 35/200] [Batch 462/637] [D loss: 0.168727] [G loss: 0.472836]\n",
      "[Epoch 35/200] [Batch 463/637] [D loss: 0.161861] [G loss: 0.556498]\n",
      "[Epoch 35/200] [Batch 464/637] [D loss: 0.167018] [G loss: 0.542500]\n",
      "[Epoch 35/200] [Batch 465/637] [D loss: 0.204469] [G loss: 0.426378]\n",
      "[Epoch 35/200] [Batch 466/637] [D loss: 0.164735] [G loss: 0.496261]\n",
      "[Epoch 35/200] [Batch 467/637] [D loss: 0.180825] [G loss: 0.505250]\n",
      "[Epoch 35/200] [Batch 468/637] [D loss: 0.174596] [G loss: 0.496891]\n",
      "[Epoch 35/200] [Batch 469/637] [D loss: 0.158378] [G loss: 0.561594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/200] [Batch 470/637] [D loss: 0.158836] [G loss: 0.492452]\n",
      "[Epoch 35/200] [Batch 471/637] [D loss: 0.163084] [G loss: 0.415090]\n",
      "[Epoch 35/200] [Batch 472/637] [D loss: 0.142255] [G loss: 0.469248]\n",
      "[Epoch 35/200] [Batch 473/637] [D loss: 0.162325] [G loss: 0.473886]\n",
      "[Epoch 35/200] [Batch 474/637] [D loss: 0.167929] [G loss: 0.545017]\n",
      "[Epoch 35/200] [Batch 475/637] [D loss: 0.154056] [G loss: 0.606759]\n",
      "[Epoch 35/200] [Batch 476/637] [D loss: 0.175875] [G loss: 0.464556]\n",
      "[Epoch 35/200] [Batch 477/637] [D loss: 0.171763] [G loss: 0.537236]\n",
      "[Epoch 35/200] [Batch 478/637] [D loss: 0.189258] [G loss: 0.458621]\n",
      "[Epoch 35/200] [Batch 479/637] [D loss: 0.175816] [G loss: 0.412203]\n",
      "[Epoch 35/200] [Batch 480/637] [D loss: 0.166617] [G loss: 0.457009]\n",
      "[Epoch 35/200] [Batch 481/637] [D loss: 0.185568] [G loss: 0.425488]\n",
      "[Epoch 35/200] [Batch 482/637] [D loss: 0.180697] [G loss: 0.496188]\n",
      "[Epoch 35/200] [Batch 483/637] [D loss: 0.158861] [G loss: 0.517162]\n",
      "[Epoch 35/200] [Batch 484/637] [D loss: 0.170156] [G loss: 0.509694]\n",
      "[Epoch 35/200] [Batch 485/637] [D loss: 0.166717] [G loss: 0.481224]\n",
      "[Epoch 35/200] [Batch 486/637] [D loss: 0.194390] [G loss: 0.457855]\n",
      "[Epoch 35/200] [Batch 487/637] [D loss: 0.170516] [G loss: 0.480328]\n",
      "[Epoch 35/200] [Batch 488/637] [D loss: 0.173318] [G loss: 0.479211]\n",
      "[Epoch 35/200] [Batch 489/637] [D loss: 0.159464] [G loss: 0.521861]\n",
      "[Epoch 35/200] [Batch 490/637] [D loss: 0.164568] [G loss: 0.533093]\n",
      "[Epoch 35/200] [Batch 491/637] [D loss: 0.149050] [G loss: 0.505229]\n",
      "[Epoch 35/200] [Batch 492/637] [D loss: 0.199099] [G loss: 0.476617]\n",
      "[Epoch 35/200] [Batch 493/637] [D loss: 0.184416] [G loss: 0.467419]\n",
      "[Epoch 35/200] [Batch 494/637] [D loss: 0.152959] [G loss: 0.511176]\n",
      "[Epoch 35/200] [Batch 495/637] [D loss: 0.144722] [G loss: 0.539203]\n",
      "[Epoch 35/200] [Batch 496/637] [D loss: 0.150590] [G loss: 0.498650]\n",
      "[Epoch 35/200] [Batch 497/637] [D loss: 0.196991] [G loss: 0.433315]\n",
      "[Epoch 35/200] [Batch 498/637] [D loss: 0.162902] [G loss: 0.549198]\n",
      "[Epoch 35/200] [Batch 499/637] [D loss: 0.152875] [G loss: 0.531114]\n",
      "[Epoch 35/200] [Batch 500/637] [D loss: 0.181090] [G loss: 0.420383]\n",
      "[Epoch 35/200] [Batch 501/637] [D loss: 0.184811] [G loss: 0.413289]\n",
      "[Epoch 35/200] [Batch 502/637] [D loss: 0.181731] [G loss: 0.455773]\n",
      "[Epoch 35/200] [Batch 503/637] [D loss: 0.186448] [G loss: 0.466868]\n",
      "[Epoch 35/200] [Batch 504/637] [D loss: 0.177461] [G loss: 0.470726]\n",
      "[Epoch 35/200] [Batch 505/637] [D loss: 0.151760] [G loss: 0.502719]\n",
      "[Epoch 35/200] [Batch 506/637] [D loss: 0.170877] [G loss: 0.547344]\n",
      "[Epoch 35/200] [Batch 507/637] [D loss: 0.156770] [G loss: 0.565863]\n",
      "[Epoch 35/200] [Batch 508/637] [D loss: 0.170542] [G loss: 0.469181]\n",
      "[Epoch 35/200] [Batch 509/637] [D loss: 0.192924] [G loss: 0.431844]\n",
      "[Epoch 35/200] [Batch 510/637] [D loss: 0.164438] [G loss: 0.537679]\n",
      "[Epoch 35/200] [Batch 511/637] [D loss: 0.187382] [G loss: 0.496917]\n",
      "[Epoch 35/200] [Batch 512/637] [D loss: 0.192629] [G loss: 0.428593]\n",
      "[Epoch 35/200] [Batch 513/637] [D loss: 0.161647] [G loss: 0.467800]\n",
      "[Epoch 35/200] [Batch 514/637] [D loss: 0.187845] [G loss: 0.447330]\n",
      "[Epoch 35/200] [Batch 515/637] [D loss: 0.175400] [G loss: 0.464729]\n",
      "[Epoch 35/200] [Batch 516/637] [D loss: 0.185257] [G loss: 0.472671]\n",
      "[Epoch 35/200] [Batch 517/637] [D loss: 0.186311] [G loss: 0.445790]\n",
      "[Epoch 35/200] [Batch 518/637] [D loss: 0.168468] [G loss: 0.504679]\n",
      "[Epoch 35/200] [Batch 519/637] [D loss: 0.150556] [G loss: 0.486063]\n",
      "[Epoch 35/200] [Batch 520/637] [D loss: 0.147017] [G loss: 0.522407]\n",
      "[Epoch 35/200] [Batch 521/637] [D loss: 0.155934] [G loss: 0.505360]\n",
      "[Epoch 35/200] [Batch 522/637] [D loss: 0.175740] [G loss: 0.476736]\n",
      "[Epoch 35/200] [Batch 523/637] [D loss: 0.160744] [G loss: 0.480594]\n",
      "[Epoch 35/200] [Batch 524/637] [D loss: 0.165803] [G loss: 0.535379]\n",
      "[Epoch 35/200] [Batch 525/637] [D loss: 0.133664] [G loss: 0.551513]\n",
      "[Epoch 35/200] [Batch 526/637] [D loss: 0.148030] [G loss: 0.586607]\n",
      "[Epoch 35/200] [Batch 527/637] [D loss: 0.146921] [G loss: 0.544766]\n",
      "[Epoch 35/200] [Batch 528/637] [D loss: 0.200982] [G loss: 0.421471]\n",
      "[Epoch 35/200] [Batch 529/637] [D loss: 0.167841] [G loss: 0.532925]\n",
      "[Epoch 35/200] [Batch 530/637] [D loss: 0.199482] [G loss: 0.541169]\n",
      "[Epoch 35/200] [Batch 531/637] [D loss: 0.179879] [G loss: 0.511475]\n",
      "[Epoch 35/200] [Batch 532/637] [D loss: 0.186749] [G loss: 0.437634]\n",
      "[Epoch 35/200] [Batch 533/637] [D loss: 0.183152] [G loss: 0.460806]\n",
      "[Epoch 35/200] [Batch 534/637] [D loss: 0.153287] [G loss: 0.497486]\n",
      "[Epoch 35/200] [Batch 535/637] [D loss: 0.201159] [G loss: 0.496101]\n",
      "[Epoch 35/200] [Batch 536/637] [D loss: 0.173133] [G loss: 0.548352]\n",
      "[Epoch 35/200] [Batch 537/637] [D loss: 0.170583] [G loss: 0.502167]\n",
      "[Epoch 35/200] [Batch 538/637] [D loss: 0.169100] [G loss: 0.481455]\n",
      "[Epoch 35/200] [Batch 539/637] [D loss: 0.178133] [G loss: 0.493568]\n",
      "[Epoch 35/200] [Batch 540/637] [D loss: 0.207732] [G loss: 0.436137]\n",
      "[Epoch 35/200] [Batch 541/637] [D loss: 0.163540] [G loss: 0.578752]\n",
      "[Epoch 35/200] [Batch 542/637] [D loss: 0.176832] [G loss: 0.554748]\n",
      "[Epoch 35/200] [Batch 543/637] [D loss: 0.153687] [G loss: 0.527806]\n",
      "[Epoch 35/200] [Batch 544/637] [D loss: 0.197866] [G loss: 0.476215]\n",
      "[Epoch 35/200] [Batch 545/637] [D loss: 0.153702] [G loss: 0.500067]\n",
      "[Epoch 35/200] [Batch 546/637] [D loss: 0.163008] [G loss: 0.526507]\n",
      "[Epoch 35/200] [Batch 547/637] [D loss: 0.174238] [G loss: 0.496743]\n",
      "[Epoch 35/200] [Batch 548/637] [D loss: 0.176847] [G loss: 0.469582]\n",
      "[Epoch 35/200] [Batch 549/637] [D loss: 0.155485] [G loss: 0.461566]\n",
      "[Epoch 35/200] [Batch 550/637] [D loss: 0.163268] [G loss: 0.443135]\n",
      "[Epoch 35/200] [Batch 551/637] [D loss: 0.147777] [G loss: 0.507160]\n",
      "[Epoch 35/200] [Batch 552/637] [D loss: 0.167597] [G loss: 0.493818]\n",
      "[Epoch 35/200] [Batch 553/637] [D loss: 0.150296] [G loss: 0.495629]\n",
      "[Epoch 35/200] [Batch 554/637] [D loss: 0.153414] [G loss: 0.467232]\n",
      "[Epoch 35/200] [Batch 555/637] [D loss: 0.179139] [G loss: 0.488802]\n",
      "[Epoch 35/200] [Batch 556/637] [D loss: 0.202030] [G loss: 0.469942]\n",
      "[Epoch 35/200] [Batch 557/637] [D loss: 0.196182] [G loss: 0.551661]\n",
      "[Epoch 35/200] [Batch 558/637] [D loss: 0.170880] [G loss: 0.510416]\n",
      "[Epoch 35/200] [Batch 559/637] [D loss: 0.171614] [G loss: 0.450983]\n",
      "[Epoch 35/200] [Batch 560/637] [D loss: 0.191171] [G loss: 0.505471]\n",
      "[Epoch 35/200] [Batch 561/637] [D loss: 0.164351] [G loss: 0.480573]\n",
      "[Epoch 35/200] [Batch 562/637] [D loss: 0.176526] [G loss: 0.426810]\n",
      "[Epoch 35/200] [Batch 563/637] [D loss: 0.182803] [G loss: 0.426190]\n",
      "[Epoch 35/200] [Batch 564/637] [D loss: 0.193913] [G loss: 0.438727]\n",
      "[Epoch 35/200] [Batch 565/637] [D loss: 0.174286] [G loss: 0.472757]\n",
      "[Epoch 35/200] [Batch 566/637] [D loss: 0.151444] [G loss: 0.551843]\n",
      "[Epoch 35/200] [Batch 567/637] [D loss: 0.176421] [G loss: 0.543763]\n",
      "[Epoch 35/200] [Batch 568/637] [D loss: 0.169243] [G loss: 0.472161]\n",
      "[Epoch 35/200] [Batch 569/637] [D loss: 0.178695] [G loss: 0.520851]\n",
      "[Epoch 35/200] [Batch 570/637] [D loss: 0.168832] [G loss: 0.456174]\n",
      "[Epoch 35/200] [Batch 571/637] [D loss: 0.161031] [G loss: 0.515680]\n",
      "[Epoch 35/200] [Batch 572/637] [D loss: 0.181598] [G loss: 0.480465]\n",
      "[Epoch 35/200] [Batch 573/637] [D loss: 0.198843] [G loss: 0.531910]\n",
      "[Epoch 35/200] [Batch 574/637] [D loss: 0.170418] [G loss: 0.435779]\n",
      "[Epoch 35/200] [Batch 575/637] [D loss: 0.160276] [G loss: 0.477431]\n",
      "[Epoch 35/200] [Batch 576/637] [D loss: 0.183943] [G loss: 0.415924]\n",
      "[Epoch 35/200] [Batch 577/637] [D loss: 0.175369] [G loss: 0.442243]\n",
      "[Epoch 35/200] [Batch 578/637] [D loss: 0.149667] [G loss: 0.507199]\n",
      "[Epoch 35/200] [Batch 579/637] [D loss: 0.208584] [G loss: 0.350005]\n",
      "[Epoch 35/200] [Batch 580/637] [D loss: 0.193162] [G loss: 0.430593]\n",
      "[Epoch 35/200] [Batch 581/637] [D loss: 0.199394] [G loss: 0.545834]\n",
      "[Epoch 35/200] [Batch 582/637] [D loss: 0.187612] [G loss: 0.569276]\n",
      "[Epoch 35/200] [Batch 583/637] [D loss: 0.165825] [G loss: 0.459007]\n",
      "[Epoch 35/200] [Batch 584/637] [D loss: 0.173105] [G loss: 0.451779]\n",
      "[Epoch 35/200] [Batch 585/637] [D loss: 0.187562] [G loss: 0.485579]\n",
      "[Epoch 35/200] [Batch 586/637] [D loss: 0.193183] [G loss: 0.493999]\n",
      "[Epoch 35/200] [Batch 587/637] [D loss: 0.189638] [G loss: 0.456431]\n",
      "[Epoch 35/200] [Batch 588/637] [D loss: 0.170426] [G loss: 0.462344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/200] [Batch 589/637] [D loss: 0.191654] [G loss: 0.483207]\n",
      "[Epoch 35/200] [Batch 590/637] [D loss: 0.163566] [G loss: 0.554006]\n",
      "[Epoch 35/200] [Batch 591/637] [D loss: 0.154360] [G loss: 0.548396]\n",
      "[Epoch 35/200] [Batch 592/637] [D loss: 0.191327] [G loss: 0.436777]\n",
      "[Epoch 35/200] [Batch 593/637] [D loss: 0.183874] [G loss: 0.438883]\n",
      "[Epoch 35/200] [Batch 594/637] [D loss: 0.165767] [G loss: 0.505040]\n",
      "[Epoch 35/200] [Batch 595/637] [D loss: 0.194516] [G loss: 0.539421]\n",
      "[Epoch 35/200] [Batch 596/637] [D loss: 0.172055] [G loss: 0.483595]\n",
      "[Epoch 35/200] [Batch 597/637] [D loss: 0.170552] [G loss: 0.445305]\n",
      "[Epoch 35/200] [Batch 598/637] [D loss: 0.172793] [G loss: 0.465154]\n",
      "[Epoch 35/200] [Batch 599/637] [D loss: 0.187081] [G loss: 0.461574]\n",
      "[Epoch 35/200] [Batch 600/637] [D loss: 0.173493] [G loss: 0.494242]\n",
      "[Epoch 35/200] [Batch 601/637] [D loss: 0.202780] [G loss: 0.506839]\n",
      "[Epoch 35/200] [Batch 602/637] [D loss: 0.177809] [G loss: 0.493166]\n",
      "[Epoch 35/200] [Batch 603/637] [D loss: 0.166707] [G loss: 0.488307]\n",
      "[Epoch 35/200] [Batch 604/637] [D loss: 0.150802] [G loss: 0.487595]\n",
      "[Epoch 35/200] [Batch 605/637] [D loss: 0.153586] [G loss: 0.502811]\n",
      "[Epoch 35/200] [Batch 606/637] [D loss: 0.170369] [G loss: 0.486436]\n",
      "[Epoch 35/200] [Batch 607/637] [D loss: 0.169457] [G loss: 0.555655]\n",
      "[Epoch 35/200] [Batch 608/637] [D loss: 0.160830] [G loss: 0.513202]\n",
      "[Epoch 35/200] [Batch 609/637] [D loss: 0.175820] [G loss: 0.481540]\n",
      "[Epoch 35/200] [Batch 610/637] [D loss: 0.180582] [G loss: 0.461952]\n",
      "[Epoch 35/200] [Batch 611/637] [D loss: 0.161975] [G loss: 0.476165]\n",
      "[Epoch 35/200] [Batch 612/637] [D loss: 0.175075] [G loss: 0.545759]\n",
      "[Epoch 35/200] [Batch 613/637] [D loss: 0.148635] [G loss: 0.472261]\n",
      "[Epoch 35/200] [Batch 614/637] [D loss: 0.232789] [G loss: 0.427094]\n",
      "[Epoch 35/200] [Batch 615/637] [D loss: 0.204772] [G loss: 0.509762]\n",
      "[Epoch 35/200] [Batch 616/637] [D loss: 0.188327] [G loss: 0.518119]\n",
      "[Epoch 35/200] [Batch 617/637] [D loss: 0.184445] [G loss: 0.480111]\n",
      "[Epoch 35/200] [Batch 618/637] [D loss: 0.188514] [G loss: 0.441758]\n",
      "[Epoch 35/200] [Batch 619/637] [D loss: 0.170737] [G loss: 0.476269]\n",
      "[Epoch 35/200] [Batch 620/637] [D loss: 0.181196] [G loss: 0.410247]\n",
      "[Epoch 35/200] [Batch 621/637] [D loss: 0.164765] [G loss: 0.475096]\n",
      "[Epoch 35/200] [Batch 622/637] [D loss: 0.174305] [G loss: 0.453418]\n",
      "[Epoch 35/200] [Batch 623/637] [D loss: 0.143442] [G loss: 0.536154]\n",
      "[Epoch 35/200] [Batch 624/637] [D loss: 0.156921] [G loss: 0.524647]\n",
      "[Epoch 35/200] [Batch 625/637] [D loss: 0.156476] [G loss: 0.464919]\n",
      "[Epoch 35/200] [Batch 626/637] [D loss: 0.192698] [G loss: 0.423694]\n",
      "[Epoch 35/200] [Batch 627/637] [D loss: 0.150949] [G loss: 0.512083]\n",
      "[Epoch 35/200] [Batch 628/637] [D loss: 0.170346] [G loss: 0.425231]\n",
      "[Epoch 35/200] [Batch 629/637] [D loss: 0.200227] [G loss: 0.476459]\n",
      "[Epoch 35/200] [Batch 630/637] [D loss: 0.191648] [G loss: 0.547594]\n",
      "[Epoch 35/200] [Batch 631/637] [D loss: 0.168915] [G loss: 0.533871]\n",
      "[Epoch 35/200] [Batch 632/637] [D loss: 0.164787] [G loss: 0.475361]\n",
      "[Epoch 35/200] [Batch 633/637] [D loss: 0.184494] [G loss: 0.449432]\n",
      "[Epoch 35/200] [Batch 634/637] [D loss: 0.187757] [G loss: 0.421168]\n",
      "[Epoch 35/200] [Batch 635/637] [D loss: 0.189186] [G loss: 0.448537]\n",
      "[Epoch 35/200] [Batch 636/637] [D loss: 0.168992] [G loss: 0.560919]\n",
      "[Epoch 36/200] [Batch 0/637] [D loss: 0.178079] [G loss: 0.522573]\n",
      "[Epoch 36/200] [Batch 1/637] [D loss: 0.167629] [G loss: 0.501181]\n",
      "[Epoch 36/200] [Batch 2/637] [D loss: 0.168156] [G loss: 0.473784]\n",
      "[Epoch 36/200] [Batch 3/637] [D loss: 0.147489] [G loss: 0.562151]\n",
      "[Epoch 36/200] [Batch 4/637] [D loss: 0.179056] [G loss: 0.479646]\n",
      "[Epoch 36/200] [Batch 5/637] [D loss: 0.161958] [G loss: 0.547403]\n",
      "[Epoch 36/200] [Batch 6/637] [D loss: 0.174364] [G loss: 0.534743]\n",
      "[Epoch 36/200] [Batch 7/637] [D loss: 0.167469] [G loss: 0.477548]\n",
      "[Epoch 36/200] [Batch 8/637] [D loss: 0.208337] [G loss: 0.426979]\n",
      "[Epoch 36/200] [Batch 9/637] [D loss: 0.168211] [G loss: 0.498578]\n",
      "[Epoch 36/200] [Batch 10/637] [D loss: 0.184925] [G loss: 0.515312]\n",
      "[Epoch 36/200] [Batch 11/637] [D loss: 0.179403] [G loss: 0.454516]\n",
      "[Epoch 36/200] [Batch 12/637] [D loss: 0.163999] [G loss: 0.484702]\n",
      "[Epoch 36/200] [Batch 13/637] [D loss: 0.168361] [G loss: 0.452693]\n",
      "[Epoch 36/200] [Batch 14/637] [D loss: 0.153243] [G loss: 0.525225]\n",
      "[Epoch 36/200] [Batch 15/637] [D loss: 0.199090] [G loss: 0.432245]\n",
      "[Epoch 36/200] [Batch 16/637] [D loss: 0.190811] [G loss: 0.588644]\n",
      "[Epoch 36/200] [Batch 17/637] [D loss: 0.172124] [G loss: 0.554507]\n",
      "[Epoch 36/200] [Batch 18/637] [D loss: 0.149803] [G loss: 0.501463]\n",
      "[Epoch 36/200] [Batch 19/637] [D loss: 0.146701] [G loss: 0.501366]\n",
      "[Epoch 36/200] [Batch 20/637] [D loss: 0.159185] [G loss: 0.473623]\n",
      "[Epoch 36/200] [Batch 21/637] [D loss: 0.165726] [G loss: 0.470125]\n",
      "[Epoch 36/200] [Batch 22/637] [D loss: 0.185798] [G loss: 0.404624]\n",
      "[Epoch 36/200] [Batch 23/637] [D loss: 0.156931] [G loss: 0.548107]\n",
      "[Epoch 36/200] [Batch 24/637] [D loss: 0.169296] [G loss: 0.556530]\n",
      "[Epoch 36/200] [Batch 25/637] [D loss: 0.138314] [G loss: 0.541244]\n",
      "[Epoch 36/200] [Batch 26/637] [D loss: 0.162111] [G loss: 0.478000]\n",
      "[Epoch 36/200] [Batch 27/637] [D loss: 0.162191] [G loss: 0.506226]\n",
      "[Epoch 36/200] [Batch 28/637] [D loss: 0.163712] [G loss: 0.505335]\n",
      "[Epoch 36/200] [Batch 29/637] [D loss: 0.171870] [G loss: 0.558534]\n",
      "[Epoch 36/200] [Batch 30/637] [D loss: 0.178171] [G loss: 0.443710]\n",
      "[Epoch 36/200] [Batch 31/637] [D loss: 0.187672] [G loss: 0.453696]\n",
      "[Epoch 36/200] [Batch 32/637] [D loss: 0.170156] [G loss: 0.618689]\n",
      "[Epoch 36/200] [Batch 33/637] [D loss: 0.188601] [G loss: 0.538577]\n",
      "[Epoch 36/200] [Batch 34/637] [D loss: 0.159204] [G loss: 0.506839]\n",
      "[Epoch 36/200] [Batch 35/637] [D loss: 0.161069] [G loss: 0.488863]\n",
      "[Epoch 36/200] [Batch 36/637] [D loss: 0.159433] [G loss: 0.550663]\n",
      "[Epoch 36/200] [Batch 37/637] [D loss: 0.171263] [G loss: 0.528398]\n",
      "[Epoch 36/200] [Batch 38/637] [D loss: 0.178482] [G loss: 0.476934]\n",
      "[Epoch 36/200] [Batch 39/637] [D loss: 0.197207] [G loss: 0.409820]\n",
      "[Epoch 36/200] [Batch 40/637] [D loss: 0.180546] [G loss: 0.525756]\n",
      "[Epoch 36/200] [Batch 41/637] [D loss: 0.171414] [G loss: 0.464467]\n",
      "[Epoch 36/200] [Batch 42/637] [D loss: 0.178121] [G loss: 0.469063]\n",
      "[Epoch 36/200] [Batch 43/637] [D loss: 0.176449] [G loss: 0.448869]\n",
      "[Epoch 36/200] [Batch 44/637] [D loss: 0.189117] [G loss: 0.521913]\n",
      "[Epoch 36/200] [Batch 45/637] [D loss: 0.185942] [G loss: 0.454542]\n",
      "[Epoch 36/200] [Batch 46/637] [D loss: 0.200139] [G loss: 0.501665]\n",
      "[Epoch 36/200] [Batch 47/637] [D loss: 0.166163] [G loss: 0.498345]\n",
      "[Epoch 36/200] [Batch 48/637] [D loss: 0.168182] [G loss: 0.437942]\n",
      "[Epoch 36/200] [Batch 49/637] [D loss: 0.195703] [G loss: 0.430107]\n",
      "[Epoch 36/200] [Batch 50/637] [D loss: 0.163224] [G loss: 0.508490]\n",
      "[Epoch 36/200] [Batch 51/637] [D loss: 0.184788] [G loss: 0.443244]\n",
      "[Epoch 36/200] [Batch 52/637] [D loss: 0.159719] [G loss: 0.456289]\n",
      "[Epoch 36/200] [Batch 53/637] [D loss: 0.163932] [G loss: 0.498667]\n",
      "[Epoch 36/200] [Batch 54/637] [D loss: 0.184349] [G loss: 0.483293]\n",
      "[Epoch 36/200] [Batch 55/637] [D loss: 0.178331] [G loss: 0.508383]\n",
      "[Epoch 36/200] [Batch 56/637] [D loss: 0.189447] [G loss: 0.458272]\n",
      "[Epoch 36/200] [Batch 57/637] [D loss: 0.155669] [G loss: 0.496690]\n",
      "[Epoch 36/200] [Batch 58/637] [D loss: 0.170665] [G loss: 0.498111]\n",
      "[Epoch 36/200] [Batch 59/637] [D loss: 0.152528] [G loss: 0.554388]\n",
      "[Epoch 36/200] [Batch 60/637] [D loss: 0.143602] [G loss: 0.542419]\n",
      "[Epoch 36/200] [Batch 61/637] [D loss: 0.169732] [G loss: 0.582867]\n",
      "[Epoch 36/200] [Batch 62/637] [D loss: 0.171371] [G loss: 0.561662]\n",
      "[Epoch 36/200] [Batch 63/637] [D loss: 0.167841] [G loss: 0.513275]\n",
      "[Epoch 36/200] [Batch 64/637] [D loss: 0.154217] [G loss: 0.534039]\n",
      "[Epoch 36/200] [Batch 65/637] [D loss: 0.167419] [G loss: 0.451456]\n",
      "[Epoch 36/200] [Batch 66/637] [D loss: 0.207020] [G loss: 0.448487]\n",
      "[Epoch 36/200] [Batch 67/637] [D loss: 0.164934] [G loss: 0.500554]\n",
      "[Epoch 36/200] [Batch 68/637] [D loss: 0.170096] [G loss: 0.466369]\n",
      "[Epoch 36/200] [Batch 69/637] [D loss: 0.172065] [G loss: 0.485501]\n",
      "[Epoch 36/200] [Batch 70/637] [D loss: 0.162232] [G loss: 0.520156]\n",
      "[Epoch 36/200] [Batch 71/637] [D loss: 0.153755] [G loss: 0.494019]\n",
      "[Epoch 36/200] [Batch 72/637] [D loss: 0.170929] [G loss: 0.451276]\n",
      "[Epoch 36/200] [Batch 73/637] [D loss: 0.191601] [G loss: 0.430275]\n",
      "[Epoch 36/200] [Batch 74/637] [D loss: 0.164757] [G loss: 0.512697]\n",
      "[Epoch 36/200] [Batch 75/637] [D loss: 0.203122] [G loss: 0.422186]\n",
      "[Epoch 36/200] [Batch 76/637] [D loss: 0.150835] [G loss: 0.469872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/200] [Batch 77/637] [D loss: 0.178856] [G loss: 0.420062]\n",
      "[Epoch 36/200] [Batch 78/637] [D loss: 0.175391] [G loss: 0.524996]\n",
      "[Epoch 36/200] [Batch 79/637] [D loss: 0.172517] [G loss: 0.539709]\n",
      "[Epoch 36/200] [Batch 80/637] [D loss: 0.178371] [G loss: 0.537169]\n",
      "[Epoch 36/200] [Batch 81/637] [D loss: 0.189225] [G loss: 0.436060]\n",
      "[Epoch 36/200] [Batch 82/637] [D loss: 0.217923] [G loss: 0.483479]\n",
      "[Epoch 36/200] [Batch 83/637] [D loss: 0.195632] [G loss: 0.560986]\n",
      "[Epoch 36/200] [Batch 84/637] [D loss: 0.160887] [G loss: 0.538100]\n",
      "[Epoch 36/200] [Batch 85/637] [D loss: 0.163580] [G loss: 0.550354]\n",
      "[Epoch 36/200] [Batch 86/637] [D loss: 0.178443] [G loss: 0.454471]\n",
      "[Epoch 36/200] [Batch 87/637] [D loss: 0.176734] [G loss: 0.421615]\n",
      "[Epoch 36/200] [Batch 88/637] [D loss: 0.148182] [G loss: 0.553494]\n",
      "[Epoch 36/200] [Batch 89/637] [D loss: 0.167691] [G loss: 0.538923]\n",
      "[Epoch 36/200] [Batch 90/637] [D loss: 0.171009] [G loss: 0.496861]\n",
      "[Epoch 36/200] [Batch 91/637] [D loss: 0.161357] [G loss: 0.553113]\n",
      "[Epoch 36/200] [Batch 92/637] [D loss: 0.180351] [G loss: 0.496345]\n",
      "[Epoch 36/200] [Batch 93/637] [D loss: 0.168541] [G loss: 0.529648]\n",
      "[Epoch 36/200] [Batch 94/637] [D loss: 0.166248] [G loss: 0.502441]\n",
      "[Epoch 36/200] [Batch 95/637] [D loss: 0.180677] [G loss: 0.477138]\n",
      "[Epoch 36/200] [Batch 96/637] [D loss: 0.162519] [G loss: 0.507881]\n",
      "[Epoch 36/200] [Batch 97/637] [D loss: 0.216754] [G loss: 0.389932]\n",
      "[Epoch 36/200] [Batch 98/637] [D loss: 0.166739] [G loss: 0.543781]\n",
      "[Epoch 36/200] [Batch 99/637] [D loss: 0.149463] [G loss: 0.547678]\n",
      "[Epoch 36/200] [Batch 100/637] [D loss: 0.156105] [G loss: 0.504295]\n",
      "[Epoch 36/200] [Batch 101/637] [D loss: 0.158429] [G loss: 0.601981]\n",
      "[Epoch 36/200] [Batch 102/637] [D loss: 0.181678] [G loss: 0.496968]\n",
      "[Epoch 36/200] [Batch 103/637] [D loss: 0.160337] [G loss: 0.505573]\n",
      "[Epoch 36/200] [Batch 104/637] [D loss: 0.162990] [G loss: 0.471616]\n",
      "[Epoch 36/200] [Batch 105/637] [D loss: 0.177383] [G loss: 0.434788]\n",
      "[Epoch 36/200] [Batch 106/637] [D loss: 0.196197] [G loss: 0.463829]\n",
      "[Epoch 36/200] [Batch 107/637] [D loss: 0.181193] [G loss: 0.600081]\n",
      "[Epoch 36/200] [Batch 108/637] [D loss: 0.188452] [G loss: 0.474381]\n",
      "[Epoch 36/200] [Batch 109/637] [D loss: 0.181428] [G loss: 0.443102]\n",
      "[Epoch 36/200] [Batch 110/637] [D loss: 0.162891] [G loss: 0.509117]\n",
      "[Epoch 36/200] [Batch 111/637] [D loss: 0.194835] [G loss: 0.434688]\n",
      "[Epoch 36/200] [Batch 112/637] [D loss: 0.169675] [G loss: 0.498438]\n",
      "[Epoch 36/200] [Batch 113/637] [D loss: 0.161695] [G loss: 0.523916]\n",
      "[Epoch 36/200] [Batch 114/637] [D loss: 0.176494] [G loss: 0.524460]\n",
      "[Epoch 36/200] [Batch 115/637] [D loss: 0.171830] [G loss: 0.546889]\n",
      "[Epoch 36/200] [Batch 116/637] [D loss: 0.182279] [G loss: 0.556596]\n",
      "[Epoch 36/200] [Batch 117/637] [D loss: 0.143661] [G loss: 0.518971]\n",
      "[Epoch 36/200] [Batch 118/637] [D loss: 0.183667] [G loss: 0.443737]\n",
      "[Epoch 36/200] [Batch 119/637] [D loss: 0.144344] [G loss: 0.458808]\n",
      "[Epoch 36/200] [Batch 120/637] [D loss: 0.153057] [G loss: 0.547336]\n",
      "[Epoch 36/200] [Batch 121/637] [D loss: 0.181137] [G loss: 0.554547]\n",
      "[Epoch 36/200] [Batch 122/637] [D loss: 0.176592] [G loss: 0.581451]\n",
      "[Epoch 36/200] [Batch 123/637] [D loss: 0.179193] [G loss: 0.484033]\n",
      "[Epoch 36/200] [Batch 124/637] [D loss: 0.164911] [G loss: 0.524358]\n",
      "[Epoch 36/200] [Batch 125/637] [D loss: 0.137157] [G loss: 0.551997]\n",
      "[Epoch 36/200] [Batch 126/637] [D loss: 0.189131] [G loss: 0.439102]\n",
      "[Epoch 36/200] [Batch 127/637] [D loss: 0.187111] [G loss: 0.476771]\n",
      "[Epoch 36/200] [Batch 128/637] [D loss: 0.187541] [G loss: 0.479905]\n",
      "[Epoch 36/200] [Batch 129/637] [D loss: 0.189813] [G loss: 0.509988]\n",
      "[Epoch 36/200] [Batch 130/637] [D loss: 0.173904] [G loss: 0.448678]\n",
      "[Epoch 36/200] [Batch 131/637] [D loss: 0.186613] [G loss: 0.462342]\n",
      "[Epoch 36/200] [Batch 132/637] [D loss: 0.169415] [G loss: 0.446739]\n",
      "[Epoch 36/200] [Batch 133/637] [D loss: 0.188884] [G loss: 0.439755]\n",
      "[Epoch 36/200] [Batch 134/637] [D loss: 0.155489] [G loss: 0.502580]\n",
      "[Epoch 36/200] [Batch 135/637] [D loss: 0.141484] [G loss: 0.523024]\n",
      "[Epoch 36/200] [Batch 136/637] [D loss: 0.180139] [G loss: 0.427813]\n",
      "[Epoch 36/200] [Batch 137/637] [D loss: 0.174922] [G loss: 0.465144]\n",
      "[Epoch 36/200] [Batch 138/637] [D loss: 0.170138] [G loss: 0.497111]\n",
      "[Epoch 36/200] [Batch 139/637] [D loss: 0.163969] [G loss: 0.469782]\n",
      "[Epoch 36/200] [Batch 140/637] [D loss: 0.169530] [G loss: 0.589875]\n",
      "[Epoch 36/200] [Batch 141/637] [D loss: 0.203111] [G loss: 0.455824]\n",
      "[Epoch 36/200] [Batch 142/637] [D loss: 0.192181] [G loss: 0.395190]\n",
      "[Epoch 36/200] [Batch 143/637] [D loss: 0.181921] [G loss: 0.473969]\n",
      "[Epoch 36/200] [Batch 144/637] [D loss: 0.166990] [G loss: 0.490411]\n",
      "[Epoch 36/200] [Batch 145/637] [D loss: 0.174910] [G loss: 0.474548]\n",
      "[Epoch 36/200] [Batch 146/637] [D loss: 0.187231] [G loss: 0.485770]\n",
      "[Epoch 36/200] [Batch 147/637] [D loss: 0.188383] [G loss: 0.492496]\n",
      "[Epoch 36/200] [Batch 148/637] [D loss: 0.164330] [G loss: 0.462162]\n",
      "[Epoch 36/200] [Batch 149/637] [D loss: 0.230958] [G loss: 0.425640]\n",
      "[Epoch 36/200] [Batch 150/637] [D loss: 0.211510] [G loss: 0.481651]\n",
      "[Epoch 36/200] [Batch 151/637] [D loss: 0.177167] [G loss: 0.530918]\n",
      "[Epoch 36/200] [Batch 152/637] [D loss: 0.213040] [G loss: 0.394043]\n",
      "[Epoch 36/200] [Batch 153/637] [D loss: 0.157685] [G loss: 0.506201]\n",
      "[Epoch 36/200] [Batch 154/637] [D loss: 0.176034] [G loss: 0.522825]\n",
      "[Epoch 36/200] [Batch 155/637] [D loss: 0.181889] [G loss: 0.503001]\n",
      "[Epoch 36/200] [Batch 156/637] [D loss: 0.186694] [G loss: 0.503868]\n",
      "[Epoch 36/200] [Batch 157/637] [D loss: 0.200464] [G loss: 0.449776]\n",
      "[Epoch 36/200] [Batch 158/637] [D loss: 0.175371] [G loss: 0.488852]\n",
      "[Epoch 36/200] [Batch 159/637] [D loss: 0.178518] [G loss: 0.510150]\n",
      "[Epoch 36/200] [Batch 160/637] [D loss: 0.164150] [G loss: 0.475062]\n",
      "[Epoch 36/200] [Batch 161/637] [D loss: 0.188730] [G loss: 0.497546]\n",
      "[Epoch 36/200] [Batch 162/637] [D loss: 0.203544] [G loss: 0.533042]\n",
      "[Epoch 36/200] [Batch 163/637] [D loss: 0.201578] [G loss: 0.497287]\n",
      "[Epoch 36/200] [Batch 164/637] [D loss: 0.174017] [G loss: 0.467985]\n",
      "[Epoch 36/200] [Batch 165/637] [D loss: 0.194920] [G loss: 0.390282]\n",
      "[Epoch 36/200] [Batch 166/637] [D loss: 0.172914] [G loss: 0.417374]\n",
      "[Epoch 36/200] [Batch 167/637] [D loss: 0.163824] [G loss: 0.427468]\n",
      "[Epoch 36/200] [Batch 168/637] [D loss: 0.158053] [G loss: 0.504410]\n",
      "[Epoch 36/200] [Batch 169/637] [D loss: 0.184041] [G loss: 0.438645]\n",
      "[Epoch 36/200] [Batch 170/637] [D loss: 0.163547] [G loss: 0.513480]\n",
      "[Epoch 36/200] [Batch 171/637] [D loss: 0.171051] [G loss: 0.471693]\n",
      "[Epoch 36/200] [Batch 172/637] [D loss: 0.175453] [G loss: 0.451864]\n",
      "[Epoch 36/200] [Batch 173/637] [D loss: 0.178394] [G loss: 0.485283]\n",
      "[Epoch 36/200] [Batch 174/637] [D loss: 0.197931] [G loss: 0.497374]\n",
      "[Epoch 36/200] [Batch 175/637] [D loss: 0.152654] [G loss: 0.503497]\n",
      "[Epoch 36/200] [Batch 176/637] [D loss: 0.157597] [G loss: 0.438676]\n",
      "[Epoch 36/200] [Batch 177/637] [D loss: 0.191499] [G loss: 0.426272]\n",
      "[Epoch 36/200] [Batch 178/637] [D loss: 0.185494] [G loss: 0.459271]\n",
      "[Epoch 36/200] [Batch 179/637] [D loss: 0.174683] [G loss: 0.527135]\n",
      "[Epoch 36/200] [Batch 180/637] [D loss: 0.153911] [G loss: 0.463937]\n",
      "[Epoch 36/200] [Batch 181/637] [D loss: 0.166209] [G loss: 0.424983]\n",
      "[Epoch 36/200] [Batch 182/637] [D loss: 0.168392] [G loss: 0.509927]\n",
      "[Epoch 36/200] [Batch 183/637] [D loss: 0.164500] [G loss: 0.440351]\n",
      "[Epoch 36/200] [Batch 184/637] [D loss: 0.170854] [G loss: 0.523323]\n",
      "[Epoch 36/200] [Batch 185/637] [D loss: 0.174039] [G loss: 0.457176]\n",
      "[Epoch 36/200] [Batch 186/637] [D loss: 0.152061] [G loss: 0.519713]\n",
      "[Epoch 36/200] [Batch 187/637] [D loss: 0.163333] [G loss: 0.497385]\n",
      "[Epoch 36/200] [Batch 188/637] [D loss: 0.185527] [G loss: 0.402389]\n",
      "[Epoch 36/200] [Batch 189/637] [D loss: 0.168425] [G loss: 0.514590]\n",
      "[Epoch 36/200] [Batch 190/637] [D loss: 0.168838] [G loss: 0.530259]\n",
      "[Epoch 36/200] [Batch 191/637] [D loss: 0.157852] [G loss: 0.457717]\n",
      "[Epoch 36/200] [Batch 192/637] [D loss: 0.168223] [G loss: 0.478565]\n",
      "[Epoch 36/200] [Batch 193/637] [D loss: 0.187682] [G loss: 0.456296]\n",
      "[Epoch 36/200] [Batch 194/637] [D loss: 0.160485] [G loss: 0.476081]\n",
      "[Epoch 36/200] [Batch 195/637] [D loss: 0.172348] [G loss: 0.450838]\n",
      "[Epoch 36/200] [Batch 196/637] [D loss: 0.154001] [G loss: 0.514168]\n",
      "[Epoch 36/200] [Batch 197/637] [D loss: 0.196189] [G loss: 0.466836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/200] [Batch 198/637] [D loss: 0.169407] [G loss: 0.489653]\n",
      "[Epoch 36/200] [Batch 199/637] [D loss: 0.151394] [G loss: 0.579249]\n",
      "[Epoch 36/200] [Batch 200/637] [D loss: 0.176996] [G loss: 0.501627]\n",
      "[Epoch 36/200] [Batch 201/637] [D loss: 0.187202] [G loss: 0.472807]\n",
      "[Epoch 36/200] [Batch 202/637] [D loss: 0.167578] [G loss: 0.472040]\n",
      "[Epoch 36/200] [Batch 203/637] [D loss: 0.165541] [G loss: 0.500047]\n",
      "[Epoch 36/200] [Batch 204/637] [D loss: 0.163989] [G loss: 0.532566]\n",
      "[Epoch 36/200] [Batch 205/637] [D loss: 0.161274] [G loss: 0.531783]\n",
      "[Epoch 36/200] [Batch 206/637] [D loss: 0.158786] [G loss: 0.586815]\n",
      "[Epoch 36/200] [Batch 207/637] [D loss: 0.195531] [G loss: 0.454712]\n",
      "[Epoch 36/200] [Batch 208/637] [D loss: 0.173650] [G loss: 0.573692]\n",
      "[Epoch 36/200] [Batch 209/637] [D loss: 0.169168] [G loss: 0.560992]\n",
      "[Epoch 36/200] [Batch 210/637] [D loss: 0.169141] [G loss: 0.542482]\n",
      "[Epoch 36/200] [Batch 211/637] [D loss: 0.166364] [G loss: 0.495001]\n",
      "[Epoch 36/200] [Batch 212/637] [D loss: 0.149104] [G loss: 0.502025]\n",
      "[Epoch 36/200] [Batch 213/637] [D loss: 0.186532] [G loss: 0.460684]\n",
      "[Epoch 36/200] [Batch 214/637] [D loss: 0.165099] [G loss: 0.503815]\n",
      "[Epoch 36/200] [Batch 215/637] [D loss: 0.194140] [G loss: 0.404982]\n",
      "[Epoch 36/200] [Batch 216/637] [D loss: 0.172835] [G loss: 0.512371]\n",
      "[Epoch 36/200] [Batch 217/637] [D loss: 0.172293] [G loss: 0.440114]\n",
      "[Epoch 36/200] [Batch 218/637] [D loss: 0.189355] [G loss: 0.457745]\n",
      "[Epoch 36/200] [Batch 219/637] [D loss: 0.157956] [G loss: 0.483442]\n",
      "[Epoch 36/200] [Batch 220/637] [D loss: 0.170275] [G loss: 0.422522]\n",
      "[Epoch 36/200] [Batch 221/637] [D loss: 0.179226] [G loss: 0.488382]\n",
      "[Epoch 36/200] [Batch 222/637] [D loss: 0.154166] [G loss: 0.553852]\n",
      "[Epoch 36/200] [Batch 223/637] [D loss: 0.166640] [G loss: 0.531485]\n",
      "[Epoch 36/200] [Batch 224/637] [D loss: 0.171554] [G loss: 0.475221]\n",
      "[Epoch 36/200] [Batch 225/637] [D loss: 0.164153] [G loss: 0.527618]\n",
      "[Epoch 36/200] [Batch 226/637] [D loss: 0.165432] [G loss: 0.447951]\n",
      "[Epoch 36/200] [Batch 227/637] [D loss: 0.200667] [G loss: 0.467575]\n",
      "[Epoch 36/200] [Batch 228/637] [D loss: 0.169150] [G loss: 0.532494]\n",
      "[Epoch 36/200] [Batch 229/637] [D loss: 0.179883] [G loss: 0.556911]\n",
      "[Epoch 36/200] [Batch 230/637] [D loss: 0.180773] [G loss: 0.484626]\n",
      "[Epoch 36/200] [Batch 231/637] [D loss: 0.177314] [G loss: 0.445389]\n",
      "[Epoch 36/200] [Batch 232/637] [D loss: 0.168867] [G loss: 0.475389]\n",
      "[Epoch 36/200] [Batch 233/637] [D loss: 0.191058] [G loss: 0.506977]\n",
      "[Epoch 36/200] [Batch 234/637] [D loss: 0.169421] [G loss: 0.481713]\n",
      "[Epoch 36/200] [Batch 235/637] [D loss: 0.166494] [G loss: 0.474152]\n",
      "[Epoch 36/200] [Batch 236/637] [D loss: 0.182340] [G loss: 0.485787]\n",
      "[Epoch 36/200] [Batch 237/637] [D loss: 0.156747] [G loss: 0.443954]\n",
      "[Epoch 36/200] [Batch 238/637] [D loss: 0.208354] [G loss: 0.450048]\n",
      "[Epoch 36/200] [Batch 239/637] [D loss: 0.158651] [G loss: 0.503896]\n",
      "[Epoch 36/200] [Batch 240/637] [D loss: 0.174444] [G loss: 0.509726]\n",
      "[Epoch 36/200] [Batch 241/637] [D loss: 0.183690] [G loss: 0.478062]\n",
      "[Epoch 36/200] [Batch 242/637] [D loss: 0.155477] [G loss: 0.433781]\n",
      "[Epoch 36/200] [Batch 243/637] [D loss: 0.169226] [G loss: 0.428545]\n",
      "[Epoch 36/200] [Batch 244/637] [D loss: 0.176032] [G loss: 0.453726]\n",
      "[Epoch 36/200] [Batch 245/637] [D loss: 0.172384] [G loss: 0.576431]\n",
      "[Epoch 36/200] [Batch 246/637] [D loss: 0.189767] [G loss: 0.439935]\n",
      "[Epoch 36/200] [Batch 247/637] [D loss: 0.192956] [G loss: 0.462772]\n",
      "[Epoch 36/200] [Batch 248/637] [D loss: 0.182492] [G loss: 0.449369]\n",
      "[Epoch 36/200] [Batch 249/637] [D loss: 0.173565] [G loss: 0.519279]\n",
      "[Epoch 36/200] [Batch 250/637] [D loss: 0.181870] [G loss: 0.472140]\n",
      "[Epoch 36/200] [Batch 251/637] [D loss: 0.169735] [G loss: 0.494247]\n",
      "[Epoch 36/200] [Batch 252/637] [D loss: 0.178092] [G loss: 0.469558]\n",
      "[Epoch 36/200] [Batch 253/637] [D loss: 0.204249] [G loss: 0.423868]\n",
      "[Epoch 36/200] [Batch 254/637] [D loss: 0.194328] [G loss: 0.527500]\n",
      "[Epoch 36/200] [Batch 255/637] [D loss: 0.193407] [G loss: 0.534546]\n",
      "[Epoch 36/200] [Batch 256/637] [D loss: 0.169937] [G loss: 0.451389]\n",
      "[Epoch 36/200] [Batch 257/637] [D loss: 0.173195] [G loss: 0.466363]\n",
      "[Epoch 36/200] [Batch 258/637] [D loss: 0.164968] [G loss: 0.504960]\n",
      "[Epoch 36/200] [Batch 259/637] [D loss: 0.166288] [G loss: 0.483440]\n",
      "[Epoch 36/200] [Batch 260/637] [D loss: 0.149243] [G loss: 0.489307]\n",
      "[Epoch 36/200] [Batch 261/637] [D loss: 0.191621] [G loss: 0.445115]\n",
      "[Epoch 36/200] [Batch 262/637] [D loss: 0.180740] [G loss: 0.497837]\n",
      "[Epoch 36/200] [Batch 263/637] [D loss: 0.165724] [G loss: 0.522720]\n",
      "[Epoch 36/200] [Batch 264/637] [D loss: 0.151217] [G loss: 0.581333]\n",
      "[Epoch 36/200] [Batch 265/637] [D loss: 0.192524] [G loss: 0.479939]\n",
      "[Epoch 36/200] [Batch 266/637] [D loss: 0.187426] [G loss: 0.470928]\n",
      "[Epoch 36/200] [Batch 267/637] [D loss: 0.167382] [G loss: 0.504238]\n",
      "[Epoch 36/200] [Batch 268/637] [D loss: 0.182254] [G loss: 0.439162]\n",
      "[Epoch 36/200] [Batch 269/637] [D loss: 0.170715] [G loss: 0.448176]\n",
      "[Epoch 36/200] [Batch 270/637] [D loss: 0.166279] [G loss: 0.508069]\n",
      "[Epoch 36/200] [Batch 271/637] [D loss: 0.164624] [G loss: 0.440660]\n",
      "[Epoch 36/200] [Batch 272/637] [D loss: 0.194416] [G loss: 0.419812]\n",
      "[Epoch 36/200] [Batch 273/637] [D loss: 0.168380] [G loss: 0.543884]\n",
      "[Epoch 36/200] [Batch 274/637] [D loss: 0.157947] [G loss: 0.510833]\n",
      "[Epoch 36/200] [Batch 275/637] [D loss: 0.179752] [G loss: 0.538574]\n",
      "[Epoch 36/200] [Batch 276/637] [D loss: 0.194434] [G loss: 0.492945]\n",
      "[Epoch 36/200] [Batch 277/637] [D loss: 0.178561] [G loss: 0.465569]\n",
      "[Epoch 36/200] [Batch 278/637] [D loss: 0.164994] [G loss: 0.521541]\n",
      "[Epoch 36/200] [Batch 279/637] [D loss: 0.166571] [G loss: 0.476640]\n",
      "[Epoch 36/200] [Batch 280/637] [D loss: 0.141151] [G loss: 0.510967]\n",
      "[Epoch 36/200] [Batch 281/637] [D loss: 0.159024] [G loss: 0.499931]\n",
      "[Epoch 36/200] [Batch 282/637] [D loss: 0.164597] [G loss: 0.468351]\n",
      "[Epoch 36/200] [Batch 283/637] [D loss: 0.135513] [G loss: 0.533027]\n",
      "[Epoch 36/200] [Batch 284/637] [D loss: 0.177456] [G loss: 0.491836]\n",
      "[Epoch 36/200] [Batch 285/637] [D loss: 0.154992] [G loss: 0.527926]\n",
      "[Epoch 36/200] [Batch 286/637] [D loss: 0.139095] [G loss: 0.535593]\n",
      "[Epoch 36/200] [Batch 287/637] [D loss: 0.167181] [G loss: 0.457170]\n",
      "[Epoch 36/200] [Batch 288/637] [D loss: 0.185422] [G loss: 0.511178]\n",
      "[Epoch 36/200] [Batch 289/637] [D loss: 0.172770] [G loss: 0.543660]\n",
      "[Epoch 36/200] [Batch 290/637] [D loss: 0.168335] [G loss: 0.578901]\n",
      "[Epoch 36/200] [Batch 291/637] [D loss: 0.168084] [G loss: 0.511650]\n",
      "[Epoch 36/200] [Batch 292/637] [D loss: 0.189460] [G loss: 0.406374]\n",
      "[Epoch 36/200] [Batch 293/637] [D loss: 0.171235] [G loss: 0.435430]\n",
      "[Epoch 36/200] [Batch 294/637] [D loss: 0.186823] [G loss: 0.480429]\n",
      "[Epoch 36/200] [Batch 295/637] [D loss: 0.169163] [G loss: 0.493125]\n",
      "[Epoch 36/200] [Batch 296/637] [D loss: 0.193685] [G loss: 0.427996]\n",
      "[Epoch 36/200] [Batch 297/637] [D loss: 0.169427] [G loss: 0.487017]\n",
      "[Epoch 36/200] [Batch 298/637] [D loss: 0.168176] [G loss: 0.518003]\n",
      "[Epoch 36/200] [Batch 299/637] [D loss: 0.185886] [G loss: 0.491981]\n",
      "[Epoch 36/200] [Batch 300/637] [D loss: 0.225743] [G loss: 0.436973]\n",
      "[Epoch 36/200] [Batch 301/637] [D loss: 0.154449] [G loss: 0.546471]\n",
      "[Epoch 36/200] [Batch 302/637] [D loss: 0.160695] [G loss: 0.457126]\n",
      "[Epoch 36/200] [Batch 303/637] [D loss: 0.177466] [G loss: 0.478457]\n",
      "[Epoch 36/200] [Batch 304/637] [D loss: 0.162787] [G loss: 0.481958]\n",
      "[Epoch 36/200] [Batch 305/637] [D loss: 0.155747] [G loss: 0.484924]\n",
      "[Epoch 36/200] [Batch 306/637] [D loss: 0.192356] [G loss: 0.450258]\n",
      "[Epoch 36/200] [Batch 307/637] [D loss: 0.178213] [G loss: 0.563153]\n",
      "[Epoch 36/200] [Batch 308/637] [D loss: 0.171559] [G loss: 0.488577]\n",
      "[Epoch 36/200] [Batch 309/637] [D loss: 0.171559] [G loss: 0.453940]\n",
      "[Epoch 36/200] [Batch 310/637] [D loss: 0.163284] [G loss: 0.500963]\n",
      "[Epoch 36/200] [Batch 311/637] [D loss: 0.197214] [G loss: 0.400649]\n",
      "[Epoch 36/200] [Batch 312/637] [D loss: 0.157589] [G loss: 0.514681]\n",
      "[Epoch 36/200] [Batch 313/637] [D loss: 0.162431] [G loss: 0.519438]\n",
      "[Epoch 36/200] [Batch 314/637] [D loss: 0.156569] [G loss: 0.443753]\n",
      "[Epoch 36/200] [Batch 315/637] [D loss: 0.158057] [G loss: 0.467609]\n",
      "[Epoch 36/200] [Batch 316/637] [D loss: 0.159948] [G loss: 0.561160]\n",
      "[Epoch 36/200] [Batch 317/637] [D loss: 0.155658] [G loss: 0.521639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/200] [Batch 318/637] [D loss: 0.157214] [G loss: 0.576611]\n",
      "[Epoch 36/200] [Batch 319/637] [D loss: 0.180051] [G loss: 0.495823]\n",
      "[Epoch 36/200] [Batch 320/637] [D loss: 0.142689] [G loss: 0.517036]\n",
      "[Epoch 36/200] [Batch 321/637] [D loss: 0.176550] [G loss: 0.505812]\n",
      "[Epoch 36/200] [Batch 322/637] [D loss: 0.177594] [G loss: 0.522109]\n",
      "[Epoch 36/200] [Batch 323/637] [D loss: 0.167570] [G loss: 0.469403]\n",
      "[Epoch 36/200] [Batch 324/637] [D loss: 0.160941] [G loss: 0.456000]\n",
      "[Epoch 36/200] [Batch 325/637] [D loss: 0.154865] [G loss: 0.540231]\n",
      "[Epoch 36/200] [Batch 326/637] [D loss: 0.200956] [G loss: 0.435755]\n",
      "[Epoch 36/200] [Batch 327/637] [D loss: 0.147839] [G loss: 0.512774]\n",
      "[Epoch 36/200] [Batch 328/637] [D loss: 0.174720] [G loss: 0.531911]\n",
      "[Epoch 36/200] [Batch 329/637] [D loss: 0.191707] [G loss: 0.474274]\n",
      "[Epoch 36/200] [Batch 330/637] [D loss: 0.163439] [G loss: 0.490762]\n",
      "[Epoch 36/200] [Batch 331/637] [D loss: 0.146045] [G loss: 0.581622]\n",
      "[Epoch 36/200] [Batch 332/637] [D loss: 0.156110] [G loss: 0.572265]\n",
      "[Epoch 36/200] [Batch 333/637] [D loss: 0.154137] [G loss: 0.549497]\n",
      "[Epoch 36/200] [Batch 334/637] [D loss: 0.139613] [G loss: 0.591604]\n",
      "[Epoch 36/200] [Batch 335/637] [D loss: 0.178944] [G loss: 0.463690]\n",
      "[Epoch 36/200] [Batch 336/637] [D loss: 0.181267] [G loss: 0.445023]\n",
      "[Epoch 36/200] [Batch 337/637] [D loss: 0.173655] [G loss: 0.475133]\n",
      "[Epoch 36/200] [Batch 338/637] [D loss: 0.152401] [G loss: 0.528603]\n",
      "[Epoch 36/200] [Batch 339/637] [D loss: 0.159288] [G loss: 0.489843]\n",
      "[Epoch 36/200] [Batch 340/637] [D loss: 0.159294] [G loss: 0.494647]\n",
      "[Epoch 36/200] [Batch 341/637] [D loss: 0.144084] [G loss: 0.543964]\n",
      "[Epoch 36/200] [Batch 342/637] [D loss: 0.140839] [G loss: 0.568200]\n",
      "[Epoch 36/200] [Batch 343/637] [D loss: 0.181284] [G loss: 0.547289]\n",
      "[Epoch 36/200] [Batch 344/637] [D loss: 0.167497] [G loss: 0.487855]\n",
      "[Epoch 36/200] [Batch 345/637] [D loss: 0.190462] [G loss: 0.539649]\n",
      "[Epoch 36/200] [Batch 346/637] [D loss: 0.183215] [G loss: 0.558500]\n",
      "[Epoch 36/200] [Batch 347/637] [D loss: 0.188855] [G loss: 0.424899]\n",
      "[Epoch 36/200] [Batch 348/637] [D loss: 0.173192] [G loss: 0.470938]\n",
      "[Epoch 36/200] [Batch 349/637] [D loss: 0.158644] [G loss: 0.528491]\n",
      "[Epoch 36/200] [Batch 350/637] [D loss: 0.171016] [G loss: 0.520595]\n",
      "[Epoch 36/200] [Batch 351/637] [D loss: 0.160581] [G loss: 0.481676]\n",
      "[Epoch 36/200] [Batch 352/637] [D loss: 0.165270] [G loss: 0.476670]\n",
      "[Epoch 36/200] [Batch 353/637] [D loss: 0.196711] [G loss: 0.452295]\n",
      "[Epoch 36/200] [Batch 354/637] [D loss: 0.152020] [G loss: 0.573192]\n",
      "[Epoch 36/200] [Batch 355/637] [D loss: 0.163679] [G loss: 0.623815]\n",
      "[Epoch 36/200] [Batch 356/637] [D loss: 0.156101] [G loss: 0.456391]\n",
      "[Epoch 36/200] [Batch 357/637] [D loss: 0.200512] [G loss: 0.474528]\n",
      "[Epoch 36/200] [Batch 358/637] [D loss: 0.159664] [G loss: 0.597685]\n",
      "[Epoch 36/200] [Batch 359/637] [D loss: 0.160129] [G loss: 0.615494]\n",
      "[Epoch 36/200] [Batch 360/637] [D loss: 0.168355] [G loss: 0.529562]\n",
      "[Epoch 36/200] [Batch 361/637] [D loss: 0.175522] [G loss: 0.494077]\n",
      "[Epoch 36/200] [Batch 362/637] [D loss: 0.166549] [G loss: 0.492154]\n",
      "[Epoch 36/200] [Batch 363/637] [D loss: 0.153291] [G loss: 0.498188]\n",
      "[Epoch 36/200] [Batch 364/637] [D loss: 0.164637] [G loss: 0.479138]\n",
      "[Epoch 36/200] [Batch 365/637] [D loss: 0.178992] [G loss: 0.531188]\n",
      "[Epoch 36/200] [Batch 366/637] [D loss: 0.175537] [G loss: 0.414253]\n",
      "[Epoch 36/200] [Batch 367/637] [D loss: 0.193157] [G loss: 0.414034]\n",
      "[Epoch 36/200] [Batch 368/637] [D loss: 0.175948] [G loss: 0.547544]\n",
      "[Epoch 36/200] [Batch 369/637] [D loss: 0.166947] [G loss: 0.549942]\n",
      "[Epoch 36/200] [Batch 370/637] [D loss: 0.192073] [G loss: 0.454705]\n",
      "[Epoch 36/200] [Batch 371/637] [D loss: 0.158070] [G loss: 0.514551]\n",
      "[Epoch 36/200] [Batch 372/637] [D loss: 0.143585] [G loss: 0.561136]\n",
      "[Epoch 36/200] [Batch 373/637] [D loss: 0.160246] [G loss: 0.474590]\n",
      "[Epoch 36/200] [Batch 374/637] [D loss: 0.179360] [G loss: 0.424180]\n",
      "[Epoch 36/200] [Batch 375/637] [D loss: 0.161291] [G loss: 0.445815]\n",
      "[Epoch 36/200] [Batch 376/637] [D loss: 0.154589] [G loss: 0.553897]\n",
      "[Epoch 36/200] [Batch 377/637] [D loss: 0.165739] [G loss: 0.543175]\n",
      "[Epoch 36/200] [Batch 378/637] [D loss: 0.149450] [G loss: 0.518077]\n",
      "[Epoch 36/200] [Batch 379/637] [D loss: 0.179584] [G loss: 0.490656]\n",
      "[Epoch 36/200] [Batch 380/637] [D loss: 0.168467] [G loss: 0.483369]\n",
      "[Epoch 36/200] [Batch 381/637] [D loss: 0.183516] [G loss: 0.596148]\n",
      "[Epoch 36/200] [Batch 382/637] [D loss: 0.176424] [G loss: 0.590338]\n",
      "[Epoch 36/200] [Batch 383/637] [D loss: 0.180851] [G loss: 0.434480]\n",
      "[Epoch 36/200] [Batch 384/637] [D loss: 0.152475] [G loss: 0.445758]\n",
      "[Epoch 36/200] [Batch 385/637] [D loss: 0.165737] [G loss: 0.538690]\n",
      "[Epoch 36/200] [Batch 386/637] [D loss: 0.190722] [G loss: 0.545500]\n",
      "[Epoch 36/200] [Batch 387/637] [D loss: 0.160228] [G loss: 0.551154]\n",
      "[Epoch 36/200] [Batch 388/637] [D loss: 0.168506] [G loss: 0.557198]\n",
      "[Epoch 36/200] [Batch 389/637] [D loss: 0.180208] [G loss: 0.499865]\n",
      "[Epoch 36/200] [Batch 390/637] [D loss: 0.167142] [G loss: 0.494923]\n",
      "[Epoch 36/200] [Batch 391/637] [D loss: 0.174727] [G loss: 0.440504]\n",
      "[Epoch 36/200] [Batch 392/637] [D loss: 0.191197] [G loss: 0.426232]\n",
      "[Epoch 36/200] [Batch 393/637] [D loss: 0.161625] [G loss: 0.535087]\n",
      "[Epoch 36/200] [Batch 394/637] [D loss: 0.166825] [G loss: 0.498164]\n",
      "[Epoch 36/200] [Batch 395/637] [D loss: 0.169150] [G loss: 0.502997]\n",
      "[Epoch 36/200] [Batch 396/637] [D loss: 0.184370] [G loss: 0.459010]\n",
      "[Epoch 36/200] [Batch 397/637] [D loss: 0.181073] [G loss: 0.479090]\n",
      "[Epoch 36/200] [Batch 398/637] [D loss: 0.152402] [G loss: 0.541282]\n",
      "[Epoch 36/200] [Batch 399/637] [D loss: 0.202320] [G loss: 0.460440]\n",
      "[Epoch 36/200] [Batch 400/637] [D loss: 0.171509] [G loss: 0.562439]\n",
      "[Epoch 36/200] [Batch 401/637] [D loss: 0.188385] [G loss: 0.524484]\n",
      "[Epoch 36/200] [Batch 402/637] [D loss: 0.169840] [G loss: 0.481359]\n",
      "[Epoch 36/200] [Batch 403/637] [D loss: 0.181789] [G loss: 0.469870]\n",
      "[Epoch 36/200] [Batch 404/637] [D loss: 0.180506] [G loss: 0.461276]\n",
      "[Epoch 36/200] [Batch 405/637] [D loss: 0.162265] [G loss: 0.476579]\n",
      "[Epoch 36/200] [Batch 406/637] [D loss: 0.169314] [G loss: 0.475223]\n",
      "[Epoch 36/200] [Batch 407/637] [D loss: 0.164578] [G loss: 0.528524]\n",
      "[Epoch 36/200] [Batch 408/637] [D loss: 0.172325] [G loss: 0.480202]\n",
      "[Epoch 36/200] [Batch 409/637] [D loss: 0.176537] [G loss: 0.476400]\n",
      "[Epoch 36/200] [Batch 410/637] [D loss: 0.162281] [G loss: 0.436388]\n",
      "[Epoch 36/200] [Batch 411/637] [D loss: 0.157234] [G loss: 0.513203]\n",
      "[Epoch 36/200] [Batch 412/637] [D loss: 0.163469] [G loss: 0.546703]\n",
      "[Epoch 36/200] [Batch 413/637] [D loss: 0.155903] [G loss: 0.520276]\n",
      "[Epoch 36/200] [Batch 414/637] [D loss: 0.157813] [G loss: 0.527567]\n",
      "[Epoch 36/200] [Batch 415/637] [D loss: 0.164136] [G loss: 0.454521]\n",
      "[Epoch 36/200] [Batch 416/637] [D loss: 0.163463] [G loss: 0.522086]\n",
      "[Epoch 36/200] [Batch 417/637] [D loss: 0.170277] [G loss: 0.515216]\n",
      "[Epoch 36/200] [Batch 418/637] [D loss: 0.139435] [G loss: 0.515239]\n",
      "[Epoch 36/200] [Batch 419/637] [D loss: 0.158122] [G loss: 0.454151]\n",
      "[Epoch 36/200] [Batch 420/637] [D loss: 0.156327] [G loss: 0.496784]\n",
      "[Epoch 36/200] [Batch 421/637] [D loss: 0.163484] [G loss: 0.471652]\n",
      "[Epoch 36/200] [Batch 422/637] [D loss: 0.152172] [G loss: 0.534113]\n",
      "[Epoch 36/200] [Batch 423/637] [D loss: 0.176125] [G loss: 0.488700]\n",
      "[Epoch 36/200] [Batch 424/637] [D loss: 0.198611] [G loss: 0.439733]\n",
      "[Epoch 36/200] [Batch 425/637] [D loss: 0.167892] [G loss: 0.513384]\n",
      "[Epoch 36/200] [Batch 426/637] [D loss: 0.151897] [G loss: 0.548057]\n",
      "[Epoch 36/200] [Batch 427/637] [D loss: 0.171968] [G loss: 0.512897]\n",
      "[Epoch 36/200] [Batch 428/637] [D loss: 0.169016] [G loss: 0.450765]\n",
      "[Epoch 36/200] [Batch 429/637] [D loss: 0.171895] [G loss: 0.428499]\n",
      "[Epoch 36/200] [Batch 430/637] [D loss: 0.188214] [G loss: 0.446893]\n",
      "[Epoch 36/200] [Batch 431/637] [D loss: 0.165591] [G loss: 0.489774]\n",
      "[Epoch 36/200] [Batch 432/637] [D loss: 0.148289] [G loss: 0.536267]\n",
      "[Epoch 36/200] [Batch 433/637] [D loss: 0.170271] [G loss: 0.499627]\n",
      "[Epoch 36/200] [Batch 434/637] [D loss: 0.167546] [G loss: 0.515811]\n",
      "[Epoch 36/200] [Batch 435/637] [D loss: 0.159038] [G loss: 0.494913]\n",
      "[Epoch 36/200] [Batch 436/637] [D loss: 0.169238] [G loss: 0.529593]\n",
      "[Epoch 36/200] [Batch 437/637] [D loss: 0.188258] [G loss: 0.419238]\n",
      "[Epoch 36/200] [Batch 438/637] [D loss: 0.136257] [G loss: 0.546117]\n",
      "[Epoch 36/200] [Batch 439/637] [D loss: 0.170450] [G loss: 0.470234]\n",
      "[Epoch 36/200] [Batch 440/637] [D loss: 0.167739] [G loss: 0.424900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/200] [Batch 441/637] [D loss: 0.159914] [G loss: 0.479418]\n",
      "[Epoch 36/200] [Batch 442/637] [D loss: 0.182586] [G loss: 0.442516]\n",
      "[Epoch 36/200] [Batch 443/637] [D loss: 0.175497] [G loss: 0.487387]\n",
      "[Epoch 36/200] [Batch 444/637] [D loss: 0.158186] [G loss: 0.523776]\n",
      "[Epoch 36/200] [Batch 445/637] [D loss: 0.191479] [G loss: 0.438864]\n",
      "[Epoch 36/200] [Batch 446/637] [D loss: 0.169555] [G loss: 0.471392]\n",
      "[Epoch 36/200] [Batch 447/637] [D loss: 0.158171] [G loss: 0.492770]\n",
      "[Epoch 36/200] [Batch 448/637] [D loss: 0.193960] [G loss: 0.431031]\n",
      "[Epoch 36/200] [Batch 449/637] [D loss: 0.162876] [G loss: 0.462948]\n",
      "[Epoch 36/200] [Batch 450/637] [D loss: 0.182669] [G loss: 0.445790]\n",
      "[Epoch 36/200] [Batch 451/637] [D loss: 0.176231] [G loss: 0.554872]\n",
      "[Epoch 36/200] [Batch 452/637] [D loss: 0.173057] [G loss: 0.491332]\n",
      "[Epoch 36/200] [Batch 453/637] [D loss: 0.172506] [G loss: 0.423187]\n",
      "[Epoch 36/200] [Batch 454/637] [D loss: 0.165169] [G loss: 0.500734]\n",
      "[Epoch 36/200] [Batch 455/637] [D loss: 0.163317] [G loss: 0.519416]\n",
      "[Epoch 36/200] [Batch 456/637] [D loss: 0.176453] [G loss: 0.485769]\n",
      "[Epoch 36/200] [Batch 457/637] [D loss: 0.184935] [G loss: 0.469182]\n",
      "[Epoch 36/200] [Batch 458/637] [D loss: 0.187039] [G loss: 0.447907]\n",
      "[Epoch 36/200] [Batch 459/637] [D loss: 0.171963] [G loss: 0.464892]\n",
      "[Epoch 36/200] [Batch 460/637] [D loss: 0.158628] [G loss: 0.490048]\n",
      "[Epoch 36/200] [Batch 461/637] [D loss: 0.190973] [G loss: 0.450739]\n",
      "[Epoch 36/200] [Batch 462/637] [D loss: 0.188764] [G loss: 0.465448]\n",
      "[Epoch 36/200] [Batch 463/637] [D loss: 0.150329] [G loss: 0.540233]\n",
      "[Epoch 36/200] [Batch 464/637] [D loss: 0.154980] [G loss: 0.531387]\n",
      "[Epoch 36/200] [Batch 465/637] [D loss: 0.165497] [G loss: 0.452720]\n",
      "[Epoch 36/200] [Batch 466/637] [D loss: 0.183571] [G loss: 0.449425]\n",
      "[Epoch 36/200] [Batch 467/637] [D loss: 0.171489] [G loss: 0.460262]\n",
      "[Epoch 36/200] [Batch 468/637] [D loss: 0.175124] [G loss: 0.495087]\n",
      "[Epoch 36/200] [Batch 469/637] [D loss: 0.163358] [G loss: 0.524656]\n",
      "[Epoch 36/200] [Batch 470/637] [D loss: 0.172020] [G loss: 0.592947]\n",
      "[Epoch 36/200] [Batch 471/637] [D loss: 0.138972] [G loss: 0.600977]\n",
      "[Epoch 36/200] [Batch 472/637] [D loss: 0.133118] [G loss: 0.552219]\n",
      "[Epoch 36/200] [Batch 473/637] [D loss: 0.186910] [G loss: 0.509642]\n",
      "[Epoch 36/200] [Batch 474/637] [D loss: 0.192949] [G loss: 0.487417]\n",
      "[Epoch 36/200] [Batch 475/637] [D loss: 0.172569] [G loss: 0.550514]\n",
      "[Epoch 36/200] [Batch 476/637] [D loss: 0.169110] [G loss: 0.462919]\n",
      "[Epoch 36/200] [Batch 477/637] [D loss: 0.179479] [G loss: 0.506927]\n",
      "[Epoch 36/200] [Batch 478/637] [D loss: 0.169451] [G loss: 0.534003]\n",
      "[Epoch 36/200] [Batch 479/637] [D loss: 0.158371] [G loss: 0.505593]\n",
      "[Epoch 36/200] [Batch 480/637] [D loss: 0.175708] [G loss: 0.469698]\n",
      "[Epoch 36/200] [Batch 481/637] [D loss: 0.183867] [G loss: 0.470347]\n",
      "[Epoch 36/200] [Batch 482/637] [D loss: 0.157093] [G loss: 0.522921]\n",
      "[Epoch 36/200] [Batch 483/637] [D loss: 0.173646] [G loss: 0.535614]\n",
      "[Epoch 36/200] [Batch 484/637] [D loss: 0.169110] [G loss: 0.471281]\n",
      "[Epoch 36/200] [Batch 485/637] [D loss: 0.169289] [G loss: 0.495098]\n",
      "[Epoch 36/200] [Batch 486/637] [D loss: 0.155853] [G loss: 0.548027]\n",
      "[Epoch 36/200] [Batch 487/637] [D loss: 0.181794] [G loss: 0.490841]\n",
      "[Epoch 36/200] [Batch 488/637] [D loss: 0.175315] [G loss: 0.455603]\n",
      "[Epoch 36/200] [Batch 489/637] [D loss: 0.177570] [G loss: 0.483457]\n",
      "[Epoch 36/200] [Batch 490/637] [D loss: 0.178559] [G loss: 0.515078]\n",
      "[Epoch 36/200] [Batch 491/637] [D loss: 0.159157] [G loss: 0.549544]\n",
      "[Epoch 36/200] [Batch 492/637] [D loss: 0.151853] [G loss: 0.542447]\n",
      "[Epoch 36/200] [Batch 493/637] [D loss: 0.157502] [G loss: 0.445926]\n",
      "[Epoch 36/200] [Batch 494/637] [D loss: 0.154578] [G loss: 0.527059]\n",
      "[Epoch 36/200] [Batch 495/637] [D loss: 0.177960] [G loss: 0.508653]\n",
      "[Epoch 36/200] [Batch 496/637] [D loss: 0.185793] [G loss: 0.448585]\n",
      "[Epoch 36/200] [Batch 497/637] [D loss: 0.147224] [G loss: 0.518817]\n",
      "[Epoch 36/200] [Batch 498/637] [D loss: 0.164461] [G loss: 0.605759]\n",
      "[Epoch 36/200] [Batch 499/637] [D loss: 0.160194] [G loss: 0.518369]\n",
      "[Epoch 36/200] [Batch 500/637] [D loss: 0.156673] [G loss: 0.533549]\n",
      "[Epoch 36/200] [Batch 501/637] [D loss: 0.162849] [G loss: 0.548204]\n",
      "[Epoch 36/200] [Batch 502/637] [D loss: 0.182135] [G loss: 0.626461]\n",
      "[Epoch 36/200] [Batch 503/637] [D loss: 0.166439] [G loss: 0.572737]\n",
      "[Epoch 36/200] [Batch 504/637] [D loss: 0.180282] [G loss: 0.454442]\n",
      "[Epoch 36/200] [Batch 505/637] [D loss: 0.171838] [G loss: 0.453783]\n",
      "[Epoch 36/200] [Batch 506/637] [D loss: 0.158015] [G loss: 0.504406]\n",
      "[Epoch 36/200] [Batch 507/637] [D loss: 0.164599] [G loss: 0.505366]\n",
      "[Epoch 36/200] [Batch 508/637] [D loss: 0.170224] [G loss: 0.549145]\n",
      "[Epoch 36/200] [Batch 509/637] [D loss: 0.173441] [G loss: 0.488035]\n",
      "[Epoch 36/200] [Batch 510/637] [D loss: 0.168735] [G loss: 0.516236]\n",
      "[Epoch 36/200] [Batch 511/637] [D loss: 0.168623] [G loss: 0.480407]\n",
      "[Epoch 36/200] [Batch 512/637] [D loss: 0.143964] [G loss: 0.543114]\n",
      "[Epoch 36/200] [Batch 513/637] [D loss: 0.161350] [G loss: 0.465003]\n",
      "[Epoch 36/200] [Batch 514/637] [D loss: 0.161444] [G loss: 0.535156]\n",
      "[Epoch 36/200] [Batch 515/637] [D loss: 0.156200] [G loss: 0.574197]\n",
      "[Epoch 36/200] [Batch 516/637] [D loss: 0.181067] [G loss: 0.448625]\n",
      "[Epoch 36/200] [Batch 517/637] [D loss: 0.165742] [G loss: 0.510136]\n",
      "[Epoch 36/200] [Batch 518/637] [D loss: 0.167412] [G loss: 0.454046]\n",
      "[Epoch 36/200] [Batch 519/637] [D loss: 0.170946] [G loss: 0.445521]\n",
      "[Epoch 36/200] [Batch 520/637] [D loss: 0.174489] [G loss: 0.428611]\n",
      "[Epoch 36/200] [Batch 521/637] [D loss: 0.158242] [G loss: 0.533118]\n",
      "[Epoch 36/200] [Batch 522/637] [D loss: 0.192792] [G loss: 0.494549]\n",
      "[Epoch 36/200] [Batch 523/637] [D loss: 0.175557] [G loss: 0.487433]\n",
      "[Epoch 36/200] [Batch 524/637] [D loss: 0.172105] [G loss: 0.448458]\n",
      "[Epoch 36/200] [Batch 525/637] [D loss: 0.175367] [G loss: 0.533453]\n",
      "[Epoch 36/200] [Batch 526/637] [D loss: 0.154451] [G loss: 0.491159]\n",
      "[Epoch 36/200] [Batch 527/637] [D loss: 0.188397] [G loss: 0.446483]\n",
      "[Epoch 36/200] [Batch 528/637] [D loss: 0.177005] [G loss: 0.507245]\n",
      "[Epoch 36/200] [Batch 529/637] [D loss: 0.143693] [G loss: 0.655252]\n",
      "[Epoch 36/200] [Batch 530/637] [D loss: 0.180647] [G loss: 0.491978]\n",
      "[Epoch 36/200] [Batch 531/637] [D loss: 0.177136] [G loss: 0.468593]\n",
      "[Epoch 36/200] [Batch 532/637] [D loss: 0.135555] [G loss: 0.551512]\n",
      "[Epoch 36/200] [Batch 533/637] [D loss: 0.164638] [G loss: 0.493552]\n",
      "[Epoch 36/200] [Batch 534/637] [D loss: 0.169430] [G loss: 0.479437]\n",
      "[Epoch 36/200] [Batch 535/637] [D loss: 0.171038] [G loss: 0.503279]\n",
      "[Epoch 36/200] [Batch 536/637] [D loss: 0.152202] [G loss: 0.523622]\n",
      "[Epoch 36/200] [Batch 537/637] [D loss: 0.150938] [G loss: 0.570931]\n",
      "[Epoch 36/200] [Batch 538/637] [D loss: 0.174331] [G loss: 0.522146]\n",
      "[Epoch 36/200] [Batch 539/637] [D loss: 0.169047] [G loss: 0.747082]\n",
      "[Epoch 36/200] [Batch 540/637] [D loss: 0.207726] [G loss: 0.531903]\n",
      "[Epoch 36/200] [Batch 541/637] [D loss: 0.146138] [G loss: 0.475125]\n",
      "[Epoch 36/200] [Batch 542/637] [D loss: 0.169379] [G loss: 0.369624]\n",
      "[Epoch 36/200] [Batch 543/637] [D loss: 0.161266] [G loss: 0.484796]\n",
      "[Epoch 36/200] [Batch 544/637] [D loss: 0.168258] [G loss: 0.472045]\n",
      "[Epoch 36/200] [Batch 545/637] [D loss: 0.147239] [G loss: 0.522009]\n",
      "[Epoch 36/200] [Batch 546/637] [D loss: 0.159132] [G loss: 0.471298]\n",
      "[Epoch 36/200] [Batch 547/637] [D loss: 0.150883] [G loss: 0.576129]\n",
      "[Epoch 36/200] [Batch 548/637] [D loss: 0.150479] [G loss: 0.547156]\n",
      "[Epoch 36/200] [Batch 549/637] [D loss: 0.175825] [G loss: 0.428838]\n",
      "[Epoch 36/200] [Batch 550/637] [D loss: 0.181945] [G loss: 0.463270]\n",
      "[Epoch 36/200] [Batch 551/637] [D loss: 0.181138] [G loss: 0.455902]\n",
      "[Epoch 36/200] [Batch 552/637] [D loss: 0.182225] [G loss: 0.467494]\n",
      "[Epoch 36/200] [Batch 553/637] [D loss: 0.184547] [G loss: 0.540179]\n",
      "[Epoch 36/200] [Batch 554/637] [D loss: 0.180382] [G loss: 0.427533]\n",
      "[Epoch 36/200] [Batch 555/637] [D loss: 0.182255] [G loss: 0.460209]\n",
      "[Epoch 36/200] [Batch 556/637] [D loss: 0.171428] [G loss: 0.472828]\n",
      "[Epoch 36/200] [Batch 557/637] [D loss: 0.181408] [G loss: 0.511670]\n",
      "[Epoch 36/200] [Batch 558/637] [D loss: 0.164166] [G loss: 0.527511]\n",
      "[Epoch 36/200] [Batch 559/637] [D loss: 0.175070] [G loss: 0.480714]\n",
      "[Epoch 36/200] [Batch 560/637] [D loss: 0.162186] [G loss: 0.482854]\n",
      "[Epoch 36/200] [Batch 561/637] [D loss: 0.166053] [G loss: 0.555399]\n",
      "[Epoch 36/200] [Batch 562/637] [D loss: 0.147819] [G loss: 0.570254]\n",
      "[Epoch 36/200] [Batch 563/637] [D loss: 0.177340] [G loss: 0.395141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/200] [Batch 564/637] [D loss: 0.195894] [G loss: 0.389575]\n",
      "[Epoch 36/200] [Batch 565/637] [D loss: 0.161916] [G loss: 0.408403]\n",
      "[Epoch 36/200] [Batch 566/637] [D loss: 0.170556] [G loss: 0.483009]\n",
      "[Epoch 36/200] [Batch 567/637] [D loss: 0.166889] [G loss: 0.501863]\n",
      "[Epoch 36/200] [Batch 568/637] [D loss: 0.162449] [G loss: 0.537414]\n",
      "[Epoch 36/200] [Batch 569/637] [D loss: 0.189780] [G loss: 0.420454]\n",
      "[Epoch 36/200] [Batch 570/637] [D loss: 0.164940] [G loss: 0.465983]\n",
      "[Epoch 36/200] [Batch 571/637] [D loss: 0.168324] [G loss: 0.477720]\n",
      "[Epoch 36/200] [Batch 572/637] [D loss: 0.208316] [G loss: 0.448613]\n",
      "[Epoch 36/200] [Batch 573/637] [D loss: 0.166389] [G loss: 0.494775]\n",
      "[Epoch 36/200] [Batch 574/637] [D loss: 0.179637] [G loss: 0.512369]\n",
      "[Epoch 36/200] [Batch 575/637] [D loss: 0.189460] [G loss: 0.442908]\n",
      "[Epoch 36/200] [Batch 576/637] [D loss: 0.161743] [G loss: 0.510388]\n",
      "[Epoch 36/200] [Batch 577/637] [D loss: 0.160423] [G loss: 0.515296]\n",
      "[Epoch 36/200] [Batch 578/637] [D loss: 0.167548] [G loss: 0.497903]\n",
      "[Epoch 36/200] [Batch 579/637] [D loss: 0.159100] [G loss: 0.500891]\n",
      "[Epoch 36/200] [Batch 580/637] [D loss: 0.184478] [G loss: 0.475739]\n",
      "[Epoch 36/200] [Batch 581/637] [D loss: 0.174150] [G loss: 0.529469]\n",
      "[Epoch 36/200] [Batch 582/637] [D loss: 0.154148] [G loss: 0.526300]\n",
      "[Epoch 36/200] [Batch 583/637] [D loss: 0.164090] [G loss: 0.526153]\n",
      "[Epoch 36/200] [Batch 584/637] [D loss: 0.174273] [G loss: 0.450680]\n",
      "[Epoch 36/200] [Batch 585/637] [D loss: 0.167304] [G loss: 0.488915]\n",
      "[Epoch 36/200] [Batch 586/637] [D loss: 0.183434] [G loss: 0.487310]\n",
      "[Epoch 36/200] [Batch 587/637] [D loss: 0.221425] [G loss: 0.558112]\n",
      "[Epoch 36/200] [Batch 588/637] [D loss: 0.164950] [G loss: 0.559569]\n",
      "[Epoch 36/200] [Batch 589/637] [D loss: 0.195329] [G loss: 0.440649]\n",
      "[Epoch 36/200] [Batch 590/637] [D loss: 0.166982] [G loss: 0.465888]\n",
      "[Epoch 36/200] [Batch 591/637] [D loss: 0.184130] [G loss: 0.451012]\n",
      "[Epoch 36/200] [Batch 592/637] [D loss: 0.162918] [G loss: 0.476718]\n",
      "[Epoch 36/200] [Batch 593/637] [D loss: 0.179935] [G loss: 0.486086]\n",
      "[Epoch 36/200] [Batch 594/637] [D loss: 0.192537] [G loss: 0.461376]\n",
      "[Epoch 36/200] [Batch 595/637] [D loss: 0.186854] [G loss: 0.464109]\n",
      "[Epoch 36/200] [Batch 596/637] [D loss: 0.166855] [G loss: 0.499171]\n",
      "[Epoch 36/200] [Batch 597/637] [D loss: 0.188560] [G loss: 0.483037]\n",
      "[Epoch 36/200] [Batch 598/637] [D loss: 0.170841] [G loss: 0.480963]\n",
      "[Epoch 36/200] [Batch 599/637] [D loss: 0.177796] [G loss: 0.450719]\n",
      "[Epoch 36/200] [Batch 600/637] [D loss: 0.165896] [G loss: 0.475254]\n",
      "[Epoch 36/200] [Batch 601/637] [D loss: 0.150546] [G loss: 0.616139]\n",
      "[Epoch 36/200] [Batch 602/637] [D loss: 0.167980] [G loss: 0.572444]\n",
      "[Epoch 36/200] [Batch 603/637] [D loss: 0.160347] [G loss: 0.481896]\n",
      "[Epoch 36/200] [Batch 604/637] [D loss: 0.181289] [G loss: 0.449923]\n",
      "[Epoch 36/200] [Batch 605/637] [D loss: 0.158695] [G loss: 0.558867]\n",
      "[Epoch 36/200] [Batch 606/637] [D loss: 0.171497] [G loss: 0.482242]\n",
      "[Epoch 36/200] [Batch 607/637] [D loss: 0.174258] [G loss: 0.559080]\n",
      "[Epoch 36/200] [Batch 608/637] [D loss: 0.153350] [G loss: 0.504811]\n",
      "[Epoch 36/200] [Batch 609/637] [D loss: 0.158170] [G loss: 0.482675]\n",
      "[Epoch 36/200] [Batch 610/637] [D loss: 0.147980] [G loss: 0.522780]\n",
      "[Epoch 36/200] [Batch 611/637] [D loss: 0.155741] [G loss: 0.549578]\n",
      "[Epoch 36/200] [Batch 612/637] [D loss: 0.174086] [G loss: 0.532640]\n",
      "[Epoch 36/200] [Batch 613/637] [D loss: 0.171213] [G loss: 0.452899]\n",
      "[Epoch 36/200] [Batch 614/637] [D loss: 0.162390] [G loss: 0.525243]\n",
      "[Epoch 36/200] [Batch 615/637] [D loss: 0.171488] [G loss: 0.480491]\n",
      "[Epoch 36/200] [Batch 616/637] [D loss: 0.175243] [G loss: 0.499224]\n",
      "[Epoch 36/200] [Batch 617/637] [D loss: 0.186144] [G loss: 0.503492]\n",
      "[Epoch 36/200] [Batch 618/637] [D loss: 0.171804] [G loss: 0.579340]\n",
      "[Epoch 36/200] [Batch 619/637] [D loss: 0.142372] [G loss: 0.548442]\n",
      "[Epoch 36/200] [Batch 620/637] [D loss: 0.179588] [G loss: 0.529942]\n",
      "[Epoch 36/200] [Batch 621/637] [D loss: 0.199631] [G loss: 0.421065]\n",
      "[Epoch 36/200] [Batch 622/637] [D loss: 0.179920] [G loss: 0.542126]\n",
      "[Epoch 36/200] [Batch 623/637] [D loss: 0.177899] [G loss: 0.514230]\n",
      "[Epoch 36/200] [Batch 624/637] [D loss: 0.157194] [G loss: 0.476073]\n",
      "[Epoch 36/200] [Batch 625/637] [D loss: 0.162447] [G loss: 0.473278]\n",
      "[Epoch 36/200] [Batch 626/637] [D loss: 0.167247] [G loss: 0.537239]\n",
      "[Epoch 36/200] [Batch 627/637] [D loss: 0.167534] [G loss: 0.515357]\n",
      "[Epoch 36/200] [Batch 628/637] [D loss: 0.178664] [G loss: 0.482069]\n",
      "[Epoch 36/200] [Batch 629/637] [D loss: 0.166826] [G loss: 0.497531]\n",
      "[Epoch 36/200] [Batch 630/637] [D loss: 0.148332] [G loss: 0.521776]\n",
      "[Epoch 36/200] [Batch 631/637] [D loss: 0.188276] [G loss: 0.566715]\n",
      "[Epoch 36/200] [Batch 632/637] [D loss: 0.184761] [G loss: 0.497519]\n",
      "[Epoch 36/200] [Batch 633/637] [D loss: 0.172308] [G loss: 0.463054]\n",
      "[Epoch 36/200] [Batch 634/637] [D loss: 0.163753] [G loss: 0.456352]\n",
      "[Epoch 36/200] [Batch 635/637] [D loss: 0.155456] [G loss: 0.468852]\n",
      "[Epoch 36/200] [Batch 636/637] [D loss: 0.193180] [G loss: 0.509863]\n",
      "[Epoch 37/200] [Batch 0/637] [D loss: 0.163456] [G loss: 0.447072]\n",
      "[Epoch 37/200] [Batch 1/637] [D loss: 0.190396] [G loss: 0.384187]\n",
      "[Epoch 37/200] [Batch 2/637] [D loss: 0.170626] [G loss: 0.526340]\n",
      "[Epoch 37/200] [Batch 3/637] [D loss: 0.153768] [G loss: 0.483604]\n",
      "[Epoch 37/200] [Batch 4/637] [D loss: 0.184636] [G loss: 0.534515]\n",
      "[Epoch 37/200] [Batch 5/637] [D loss: 0.176961] [G loss: 0.454526]\n",
      "[Epoch 37/200] [Batch 6/637] [D loss: 0.160586] [G loss: 0.453415]\n",
      "[Epoch 37/200] [Batch 7/637] [D loss: 0.160308] [G loss: 0.457542]\n",
      "[Epoch 37/200] [Batch 8/637] [D loss: 0.155420] [G loss: 0.490415]\n",
      "[Epoch 37/200] [Batch 9/637] [D loss: 0.177837] [G loss: 0.433407]\n",
      "[Epoch 37/200] [Batch 10/637] [D loss: 0.162394] [G loss: 0.525518]\n",
      "[Epoch 37/200] [Batch 11/637] [D loss: 0.167140] [G loss: 0.535103]\n",
      "[Epoch 37/200] [Batch 12/637] [D loss: 0.156879] [G loss: 0.550844]\n",
      "[Epoch 37/200] [Batch 13/637] [D loss: 0.174965] [G loss: 0.447737]\n",
      "[Epoch 37/200] [Batch 14/637] [D loss: 0.178790] [G loss: 0.486791]\n",
      "[Epoch 37/200] [Batch 15/637] [D loss: 0.185807] [G loss: 0.425880]\n",
      "[Epoch 37/200] [Batch 16/637] [D loss: 0.189878] [G loss: 0.449173]\n",
      "[Epoch 37/200] [Batch 17/637] [D loss: 0.177433] [G loss: 0.504247]\n",
      "[Epoch 37/200] [Batch 18/637] [D loss: 0.201659] [G loss: 0.512535]\n",
      "[Epoch 37/200] [Batch 19/637] [D loss: 0.143812] [G loss: 0.557394]\n",
      "[Epoch 37/200] [Batch 20/637] [D loss: 0.192558] [G loss: 0.453046]\n",
      "[Epoch 37/200] [Batch 21/637] [D loss: 0.168084] [G loss: 0.516778]\n",
      "[Epoch 37/200] [Batch 22/637] [D loss: 0.186968] [G loss: 0.550023]\n",
      "[Epoch 37/200] [Batch 23/637] [D loss: 0.150440] [G loss: 0.539067]\n",
      "[Epoch 37/200] [Batch 24/637] [D loss: 0.161165] [G loss: 0.510129]\n",
      "[Epoch 37/200] [Batch 25/637] [D loss: 0.169116] [G loss: 0.528311]\n",
      "[Epoch 37/200] [Batch 26/637] [D loss: 0.147082] [G loss: 0.528588]\n",
      "[Epoch 37/200] [Batch 27/637] [D loss: 0.171959] [G loss: 0.460048]\n",
      "[Epoch 37/200] [Batch 28/637] [D loss: 0.177073] [G loss: 0.457465]\n",
      "[Epoch 37/200] [Batch 29/637] [D loss: 0.181824] [G loss: 0.492280]\n",
      "[Epoch 37/200] [Batch 30/637] [D loss: 0.166724] [G loss: 0.523734]\n",
      "[Epoch 37/200] [Batch 31/637] [D loss: 0.151611] [G loss: 0.566840]\n",
      "[Epoch 37/200] [Batch 32/637] [D loss: 0.182922] [G loss: 0.458117]\n",
      "[Epoch 37/200] [Batch 33/637] [D loss: 0.157121] [G loss: 0.509043]\n",
      "[Epoch 37/200] [Batch 34/637] [D loss: 0.158250] [G loss: 0.520906]\n",
      "[Epoch 37/200] [Batch 35/637] [D loss: 0.175039] [G loss: 0.477928]\n",
      "[Epoch 37/200] [Batch 36/637] [D loss: 0.160283] [G loss: 0.522074]\n",
      "[Epoch 37/200] [Batch 37/637] [D loss: 0.181839] [G loss: 0.504571]\n",
      "[Epoch 37/200] [Batch 38/637] [D loss: 0.176743] [G loss: 0.550327]\n",
      "[Epoch 37/200] [Batch 39/637] [D loss: 0.140725] [G loss: 0.522263]\n",
      "[Epoch 37/200] [Batch 40/637] [D loss: 0.176469] [G loss: 0.460785]\n",
      "[Epoch 37/200] [Batch 41/637] [D loss: 0.167139] [G loss: 0.482723]\n",
      "[Epoch 37/200] [Batch 42/637] [D loss: 0.169968] [G loss: 0.471717]\n",
      "[Epoch 37/200] [Batch 43/637] [D loss: 0.169127] [G loss: 0.500436]\n",
      "[Epoch 37/200] [Batch 44/637] [D loss: 0.178140] [G loss: 0.541364]\n",
      "[Epoch 37/200] [Batch 45/637] [D loss: 0.165631] [G loss: 0.541925]\n",
      "[Epoch 37/200] [Batch 46/637] [D loss: 0.159828] [G loss: 0.514349]\n",
      "[Epoch 37/200] [Batch 47/637] [D loss: 0.165004] [G loss: 0.475217]\n",
      "[Epoch 37/200] [Batch 48/637] [D loss: 0.168452] [G loss: 0.500318]\n",
      "[Epoch 37/200] [Batch 49/637] [D loss: 0.152858] [G loss: 0.552911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/200] [Batch 50/637] [D loss: 0.169990] [G loss: 0.485204]\n",
      "[Epoch 37/200] [Batch 51/637] [D loss: 0.185511] [G loss: 0.436966]\n",
      "[Epoch 37/200] [Batch 52/637] [D loss: 0.184563] [G loss: 0.474773]\n",
      "[Epoch 37/200] [Batch 53/637] [D loss: 0.152883] [G loss: 0.585567]\n",
      "[Epoch 37/200] [Batch 54/637] [D loss: 0.144518] [G loss: 0.527056]\n",
      "[Epoch 37/200] [Batch 55/637] [D loss: 0.182801] [G loss: 0.489862]\n",
      "[Epoch 37/200] [Batch 56/637] [D loss: 0.150437] [G loss: 0.559158]\n",
      "[Epoch 37/200] [Batch 57/637] [D loss: 0.165024] [G loss: 0.469883]\n",
      "[Epoch 37/200] [Batch 58/637] [D loss: 0.159749] [G loss: 0.568798]\n",
      "[Epoch 37/200] [Batch 59/637] [D loss: 0.167899] [G loss: 0.532163]\n",
      "[Epoch 37/200] [Batch 60/637] [D loss: 0.173718] [G loss: 0.509715]\n",
      "[Epoch 37/200] [Batch 61/637] [D loss: 0.170812] [G loss: 0.479196]\n",
      "[Epoch 37/200] [Batch 62/637] [D loss: 0.158301] [G loss: 0.487387]\n",
      "[Epoch 37/200] [Batch 63/637] [D loss: 0.161232] [G loss: 0.449878]\n",
      "[Epoch 37/200] [Batch 64/637] [D loss: 0.178632] [G loss: 0.526082]\n",
      "[Epoch 37/200] [Batch 65/637] [D loss: 0.149198] [G loss: 0.523018]\n",
      "[Epoch 37/200] [Batch 66/637] [D loss: 0.173828] [G loss: 0.525581]\n",
      "[Epoch 37/200] [Batch 67/637] [D loss: 0.206306] [G loss: 0.468652]\n",
      "[Epoch 37/200] [Batch 68/637] [D loss: 0.179914] [G loss: 0.536363]\n",
      "[Epoch 37/200] [Batch 69/637] [D loss: 0.181523] [G loss: 0.476263]\n",
      "[Epoch 37/200] [Batch 70/637] [D loss: 0.146979] [G loss: 0.514520]\n",
      "[Epoch 37/200] [Batch 71/637] [D loss: 0.158455] [G loss: 0.499143]\n",
      "[Epoch 37/200] [Batch 72/637] [D loss: 0.157082] [G loss: 0.525677]\n",
      "[Epoch 37/200] [Batch 73/637] [D loss: 0.156666] [G loss: 0.511135]\n",
      "[Epoch 37/200] [Batch 74/637] [D loss: 0.174493] [G loss: 0.513331]\n",
      "[Epoch 37/200] [Batch 75/637] [D loss: 0.169240] [G loss: 0.620739]\n",
      "[Epoch 37/200] [Batch 76/637] [D loss: 0.163303] [G loss: 0.487866]\n",
      "[Epoch 37/200] [Batch 77/637] [D loss: 0.168329] [G loss: 0.494930]\n",
      "[Epoch 37/200] [Batch 78/637] [D loss: 0.191295] [G loss: 0.447535]\n",
      "[Epoch 37/200] [Batch 79/637] [D loss: 0.182669] [G loss: 0.549041]\n",
      "[Epoch 37/200] [Batch 80/637] [D loss: 0.162126] [G loss: 0.571543]\n",
      "[Epoch 37/200] [Batch 81/637] [D loss: 0.161395] [G loss: 0.484377]\n",
      "[Epoch 37/200] [Batch 82/637] [D loss: 0.179582] [G loss: 0.442267]\n",
      "[Epoch 37/200] [Batch 83/637] [D loss: 0.159255] [G loss: 0.526336]\n",
      "[Epoch 37/200] [Batch 84/637] [D loss: 0.183930] [G loss: 0.489131]\n",
      "[Epoch 37/200] [Batch 85/637] [D loss: 0.154004] [G loss: 0.527234]\n",
      "[Epoch 37/200] [Batch 86/637] [D loss: 0.185781] [G loss: 0.456911]\n",
      "[Epoch 37/200] [Batch 87/637] [D loss: 0.145987] [G loss: 0.486985]\n",
      "[Epoch 37/200] [Batch 88/637] [D loss: 0.159073] [G loss: 0.526582]\n",
      "[Epoch 37/200] [Batch 89/637] [D loss: 0.149852] [G loss: 0.567946]\n",
      "[Epoch 37/200] [Batch 90/637] [D loss: 0.172077] [G loss: 0.502623]\n",
      "[Epoch 37/200] [Batch 91/637] [D loss: 0.161079] [G loss: 0.524571]\n",
      "[Epoch 37/200] [Batch 92/637] [D loss: 0.158030] [G loss: 0.521573]\n",
      "[Epoch 37/200] [Batch 93/637] [D loss: 0.165904] [G loss: 0.427931]\n",
      "[Epoch 37/200] [Batch 94/637] [D loss: 0.156174] [G loss: 0.497546]\n",
      "[Epoch 37/200] [Batch 95/637] [D loss: 0.160978] [G loss: 0.495104]\n",
      "[Epoch 37/200] [Batch 96/637] [D loss: 0.159109] [G loss: 0.566906]\n",
      "[Epoch 37/200] [Batch 97/637] [D loss: 0.154472] [G loss: 0.541412]\n",
      "[Epoch 37/200] [Batch 98/637] [D loss: 0.165831] [G loss: 0.497692]\n",
      "[Epoch 37/200] [Batch 99/637] [D loss: 0.147824] [G loss: 0.487716]\n",
      "[Epoch 37/200] [Batch 100/637] [D loss: 0.168088] [G loss: 0.474164]\n",
      "[Epoch 37/200] [Batch 101/637] [D loss: 0.144723] [G loss: 0.534040]\n",
      "[Epoch 37/200] [Batch 102/637] [D loss: 0.171769] [G loss: 0.455471]\n",
      "[Epoch 37/200] [Batch 103/637] [D loss: 0.158450] [G loss: 0.454555]\n",
      "[Epoch 37/200] [Batch 104/637] [D loss: 0.191296] [G loss: 0.530760]\n",
      "[Epoch 37/200] [Batch 105/637] [D loss: 0.149883] [G loss: 0.503199]\n",
      "[Epoch 37/200] [Batch 106/637] [D loss: 0.155166] [G loss: 0.478558]\n",
      "[Epoch 37/200] [Batch 107/637] [D loss: 0.161419] [G loss: 0.515140]\n",
      "[Epoch 37/200] [Batch 108/637] [D loss: 0.164935] [G loss: 0.515022]\n",
      "[Epoch 37/200] [Batch 109/637] [D loss: 0.187549] [G loss: 0.461500]\n",
      "[Epoch 37/200] [Batch 110/637] [D loss: 0.161338] [G loss: 0.442205]\n",
      "[Epoch 37/200] [Batch 111/637] [D loss: 0.161677] [G loss: 0.424200]\n",
      "[Epoch 37/200] [Batch 112/637] [D loss: 0.173370] [G loss: 0.483046]\n",
      "[Epoch 37/200] [Batch 113/637] [D loss: 0.195309] [G loss: 0.475195]\n",
      "[Epoch 37/200] [Batch 114/637] [D loss: 0.156423] [G loss: 0.482952]\n",
      "[Epoch 37/200] [Batch 115/637] [D loss: 0.182568] [G loss: 0.461213]\n",
      "[Epoch 37/200] [Batch 116/637] [D loss: 0.185735] [G loss: 0.426207]\n",
      "[Epoch 37/200] [Batch 117/637] [D loss: 0.173380] [G loss: 0.498188]\n",
      "[Epoch 37/200] [Batch 118/637] [D loss: 0.157769] [G loss: 0.503088]\n",
      "[Epoch 37/200] [Batch 119/637] [D loss: 0.177866] [G loss: 0.520905]\n",
      "[Epoch 37/200] [Batch 120/637] [D loss: 0.173257] [G loss: 0.510659]\n",
      "[Epoch 37/200] [Batch 121/637] [D loss: 0.174322] [G loss: 0.543789]\n",
      "[Epoch 37/200] [Batch 122/637] [D loss: 0.155376] [G loss: 0.499930]\n",
      "[Epoch 37/200] [Batch 123/637] [D loss: 0.156736] [G loss: 0.446395]\n",
      "[Epoch 37/200] [Batch 124/637] [D loss: 0.158937] [G loss: 0.496839]\n",
      "[Epoch 37/200] [Batch 125/637] [D loss: 0.163237] [G loss: 0.468943]\n",
      "[Epoch 37/200] [Batch 126/637] [D loss: 0.155959] [G loss: 0.461967]\n",
      "[Epoch 37/200] [Batch 127/637] [D loss: 0.164433] [G loss: 0.447327]\n",
      "[Epoch 37/200] [Batch 128/637] [D loss: 0.151195] [G loss: 0.503796]\n",
      "[Epoch 37/200] [Batch 129/637] [D loss: 0.154536] [G loss: 0.596135]\n",
      "[Epoch 37/200] [Batch 130/637] [D loss: 0.173949] [G loss: 0.471374]\n",
      "[Epoch 37/200] [Batch 131/637] [D loss: 0.177728] [G loss: 0.435741]\n",
      "[Epoch 37/200] [Batch 132/637] [D loss: 0.196116] [G loss: 0.467521]\n",
      "[Epoch 37/200] [Batch 133/637] [D loss: 0.229818] [G loss: 0.675856]\n",
      "[Epoch 37/200] [Batch 134/637] [D loss: 0.210147] [G loss: 0.519904]\n",
      "[Epoch 37/200] [Batch 135/637] [D loss: 0.174273] [G loss: 0.413529]\n",
      "[Epoch 37/200] [Batch 136/637] [D loss: 0.173682] [G loss: 0.393192]\n",
      "[Epoch 37/200] [Batch 137/637] [D loss: 0.180106] [G loss: 0.452729]\n",
      "[Epoch 37/200] [Batch 138/637] [D loss: 0.167402] [G loss: 0.504422]\n",
      "[Epoch 37/200] [Batch 139/637] [D loss: 0.169303] [G loss: 0.435364]\n",
      "[Epoch 37/200] [Batch 140/637] [D loss: 0.204909] [G loss: 0.472047]\n",
      "[Epoch 37/200] [Batch 141/637] [D loss: 0.163366] [G loss: 0.563470]\n",
      "[Epoch 37/200] [Batch 142/637] [D loss: 0.162930] [G loss: 0.474004]\n",
      "[Epoch 37/200] [Batch 143/637] [D loss: 0.177089] [G loss: 0.448750]\n",
      "[Epoch 37/200] [Batch 144/637] [D loss: 0.150124] [G loss: 0.493396]\n",
      "[Epoch 37/200] [Batch 145/637] [D loss: 0.159489] [G loss: 0.442257]\n",
      "[Epoch 37/200] [Batch 146/637] [D loss: 0.162511] [G loss: 0.467037]\n",
      "[Epoch 37/200] [Batch 147/637] [D loss: 0.167484] [G loss: 0.492945]\n",
      "[Epoch 37/200] [Batch 148/637] [D loss: 0.168547] [G loss: 0.514101]\n",
      "[Epoch 37/200] [Batch 149/637] [D loss: 0.167542] [G loss: 0.485197]\n",
      "[Epoch 37/200] [Batch 150/637] [D loss: 0.202968] [G loss: 0.474111]\n",
      "[Epoch 37/200] [Batch 151/637] [D loss: 0.194776] [G loss: 0.585999]\n",
      "[Epoch 37/200] [Batch 152/637] [D loss: 0.190629] [G loss: 0.570968]\n",
      "[Epoch 37/200] [Batch 153/637] [D loss: 0.163503] [G loss: 0.499753]\n",
      "[Epoch 37/200] [Batch 154/637] [D loss: 0.149614] [G loss: 0.532795]\n",
      "[Epoch 37/200] [Batch 155/637] [D loss: 0.204082] [G loss: 0.393383]\n",
      "[Epoch 37/200] [Batch 156/637] [D loss: 0.192624] [G loss: 0.453143]\n",
      "[Epoch 37/200] [Batch 157/637] [D loss: 0.171776] [G loss: 0.520343]\n",
      "[Epoch 37/200] [Batch 158/637] [D loss: 0.168339] [G loss: 0.496726]\n",
      "[Epoch 37/200] [Batch 159/637] [D loss: 0.164311] [G loss: 0.428337]\n",
      "[Epoch 37/200] [Batch 160/637] [D loss: 0.158737] [G loss: 0.457507]\n",
      "[Epoch 37/200] [Batch 161/637] [D loss: 0.163286] [G loss: 0.512873]\n",
      "[Epoch 37/200] [Batch 162/637] [D loss: 0.152280] [G loss: 0.485467]\n",
      "[Epoch 37/200] [Batch 163/637] [D loss: 0.171753] [G loss: 0.507067]\n",
      "[Epoch 37/200] [Batch 164/637] [D loss: 0.158591] [G loss: 0.511481]\n",
      "[Epoch 37/200] [Batch 165/637] [D loss: 0.130392] [G loss: 0.535808]\n",
      "[Epoch 37/200] [Batch 166/637] [D loss: 0.159837] [G loss: 0.520486]\n",
      "[Epoch 37/200] [Batch 167/637] [D loss: 0.152322] [G loss: 0.485893]\n",
      "[Epoch 37/200] [Batch 168/637] [D loss: 0.156284] [G loss: 0.588916]\n",
      "[Epoch 37/200] [Batch 169/637] [D loss: 0.221495] [G loss: 0.452786]\n",
      "[Epoch 37/200] [Batch 170/637] [D loss: 0.139776] [G loss: 0.552121]\n",
      "[Epoch 37/200] [Batch 171/637] [D loss: 0.204632] [G loss: 0.443640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/200] [Batch 172/637] [D loss: 0.163844] [G loss: 0.539767]\n",
      "[Epoch 37/200] [Batch 173/637] [D loss: 0.175656] [G loss: 0.533282]\n",
      "[Epoch 37/200] [Batch 174/637] [D loss: 0.162600] [G loss: 0.535842]\n",
      "[Epoch 37/200] [Batch 175/637] [D loss: 0.159393] [G loss: 0.502158]\n",
      "[Epoch 37/200] [Batch 176/637] [D loss: 0.143516] [G loss: 0.523948]\n",
      "[Epoch 37/200] [Batch 177/637] [D loss: 0.162311] [G loss: 0.464017]\n",
      "[Epoch 37/200] [Batch 178/637] [D loss: 0.190207] [G loss: 0.525598]\n",
      "[Epoch 37/200] [Batch 179/637] [D loss: 0.155911] [G loss: 0.563239]\n",
      "[Epoch 37/200] [Batch 180/637] [D loss: 0.177195] [G loss: 0.447976]\n",
      "[Epoch 37/200] [Batch 181/637] [D loss: 0.188034] [G loss: 0.452690]\n",
      "[Epoch 37/200] [Batch 182/637] [D loss: 0.182489] [G loss: 0.508872]\n",
      "[Epoch 37/200] [Batch 183/637] [D loss: 0.173212] [G loss: 0.485675]\n",
      "[Epoch 37/200] [Batch 184/637] [D loss: 0.164985] [G loss: 0.485346]\n",
      "[Epoch 37/200] [Batch 185/637] [D loss: 0.157531] [G loss: 0.507827]\n",
      "[Epoch 37/200] [Batch 186/637] [D loss: 0.180182] [G loss: 0.468549]\n",
      "[Epoch 37/200] [Batch 187/637] [D loss: 0.168059] [G loss: 0.459702]\n",
      "[Epoch 37/200] [Batch 188/637] [D loss: 0.168644] [G loss: 0.501515]\n",
      "[Epoch 37/200] [Batch 189/637] [D loss: 0.165792] [G loss: 0.503488]\n",
      "[Epoch 37/200] [Batch 190/637] [D loss: 0.166801] [G loss: 0.525490]\n",
      "[Epoch 37/200] [Batch 191/637] [D loss: 0.181519] [G loss: 0.476196]\n",
      "[Epoch 37/200] [Batch 192/637] [D loss: 0.144609] [G loss: 0.533593]\n",
      "[Epoch 37/200] [Batch 193/637] [D loss: 0.181621] [G loss: 0.553235]\n",
      "[Epoch 37/200] [Batch 194/637] [D loss: 0.153492] [G loss: 0.483372]\n",
      "[Epoch 37/200] [Batch 195/637] [D loss: 0.168690] [G loss: 0.480793]\n",
      "[Epoch 37/200] [Batch 196/637] [D loss: 0.168029] [G loss: 0.428809]\n",
      "[Epoch 37/200] [Batch 197/637] [D loss: 0.190592] [G loss: 0.412619]\n",
      "[Epoch 37/200] [Batch 198/637] [D loss: 0.184047] [G loss: 0.477242]\n",
      "[Epoch 37/200] [Batch 199/637] [D loss: 0.180234] [G loss: 0.508950]\n",
      "[Epoch 37/200] [Batch 200/637] [D loss: 0.172018] [G loss: 0.475704]\n",
      "[Epoch 37/200] [Batch 201/637] [D loss: 0.177950] [G loss: 0.452776]\n",
      "[Epoch 37/200] [Batch 202/637] [D loss: 0.168666] [G loss: 0.505719]\n",
      "[Epoch 37/200] [Batch 203/637] [D loss: 0.176629] [G loss: 0.469275]\n",
      "[Epoch 37/200] [Batch 204/637] [D loss: 0.168735] [G loss: 0.507041]\n",
      "[Epoch 37/200] [Batch 205/637] [D loss: 0.149353] [G loss: 0.532368]\n",
      "[Epoch 37/200] [Batch 206/637] [D loss: 0.151922] [G loss: 0.486539]\n",
      "[Epoch 37/200] [Batch 207/637] [D loss: 0.177484] [G loss: 0.481074]\n",
      "[Epoch 37/200] [Batch 208/637] [D loss: 0.152976] [G loss: 0.483265]\n",
      "[Epoch 37/200] [Batch 209/637] [D loss: 0.171659] [G loss: 0.454841]\n",
      "[Epoch 37/200] [Batch 210/637] [D loss: 0.151361] [G loss: 0.522060]\n",
      "[Epoch 37/200] [Batch 211/637] [D loss: 0.178797] [G loss: 0.595517]\n",
      "[Epoch 37/200] [Batch 212/637] [D loss: 0.177851] [G loss: 0.494436]\n",
      "[Epoch 37/200] [Batch 213/637] [D loss: 0.202986] [G loss: 0.484218]\n",
      "[Epoch 37/200] [Batch 214/637] [D loss: 0.170050] [G loss: 0.566417]\n",
      "[Epoch 37/200] [Batch 215/637] [D loss: 0.183446] [G loss: 0.560617]\n",
      "[Epoch 37/200] [Batch 216/637] [D loss: 0.180743] [G loss: 0.455806]\n",
      "[Epoch 37/200] [Batch 217/637] [D loss: 0.176093] [G loss: 0.466745]\n",
      "[Epoch 37/200] [Batch 218/637] [D loss: 0.166334] [G loss: 0.503461]\n",
      "[Epoch 37/200] [Batch 219/637] [D loss: 0.172522] [G loss: 0.509387]\n",
      "[Epoch 37/200] [Batch 220/637] [D loss: 0.180061] [G loss: 0.441878]\n",
      "[Epoch 37/200] [Batch 221/637] [D loss: 0.147733] [G loss: 0.483035]\n",
      "[Epoch 37/200] [Batch 222/637] [D loss: 0.188129] [G loss: 0.426818]\n",
      "[Epoch 37/200] [Batch 223/637] [D loss: 0.176724] [G loss: 0.519821]\n",
      "[Epoch 37/200] [Batch 224/637] [D loss: 0.194864] [G loss: 0.479824]\n",
      "[Epoch 37/200] [Batch 225/637] [D loss: 0.173660] [G loss: 0.454508]\n",
      "[Epoch 37/200] [Batch 226/637] [D loss: 0.195110] [G loss: 0.398643]\n",
      "[Epoch 37/200] [Batch 227/637] [D loss: 0.181153] [G loss: 0.518455]\n",
      "[Epoch 37/200] [Batch 228/637] [D loss: 0.182043] [G loss: 0.522256]\n",
      "[Epoch 37/200] [Batch 229/637] [D loss: 0.177041] [G loss: 0.463978]\n",
      "[Epoch 37/200] [Batch 230/637] [D loss: 0.175788] [G loss: 0.433352]\n",
      "[Epoch 37/200] [Batch 231/637] [D loss: 0.146702] [G loss: 0.550622]\n",
      "[Epoch 37/200] [Batch 232/637] [D loss: 0.157702] [G loss: 0.540899]\n",
      "[Epoch 37/200] [Batch 233/637] [D loss: 0.157724] [G loss: 0.522690]\n",
      "[Epoch 37/200] [Batch 234/637] [D loss: 0.150728] [G loss: 0.569262]\n",
      "[Epoch 37/200] [Batch 235/637] [D loss: 0.153114] [G loss: 0.519728]\n",
      "[Epoch 37/200] [Batch 236/637] [D loss: 0.184560] [G loss: 0.418551]\n",
      "[Epoch 37/200] [Batch 237/637] [D loss: 0.156757] [G loss: 0.464470]\n",
      "[Epoch 37/200] [Batch 238/637] [D loss: 0.164859] [G loss: 0.508582]\n",
      "[Epoch 37/200] [Batch 239/637] [D loss: 0.161097] [G loss: 0.546969]\n",
      "[Epoch 37/200] [Batch 240/637] [D loss: 0.154049] [G loss: 0.496230]\n",
      "[Epoch 37/200] [Batch 241/637] [D loss: 0.166829] [G loss: 0.525023]\n",
      "[Epoch 37/200] [Batch 242/637] [D loss: 0.168427] [G loss: 0.456047]\n",
      "[Epoch 37/200] [Batch 243/637] [D loss: 0.202497] [G loss: 0.457074]\n",
      "[Epoch 37/200] [Batch 244/637] [D loss: 0.172988] [G loss: 0.563872]\n",
      "[Epoch 37/200] [Batch 245/637] [D loss: 0.173850] [G loss: 0.541448]\n",
      "[Epoch 37/200] [Batch 246/637] [D loss: 0.183115] [G loss: 0.521177]\n",
      "[Epoch 37/200] [Batch 247/637] [D loss: 0.167570] [G loss: 0.487487]\n",
      "[Epoch 37/200] [Batch 248/637] [D loss: 0.183626] [G loss: 0.432975]\n",
      "[Epoch 37/200] [Batch 249/637] [D loss: 0.175082] [G loss: 0.481759]\n",
      "[Epoch 37/200] [Batch 250/637] [D loss: 0.178248] [G loss: 0.544893]\n",
      "[Epoch 37/200] [Batch 251/637] [D loss: 0.194031] [G loss: 0.533692]\n",
      "[Epoch 37/200] [Batch 252/637] [D loss: 0.169791] [G loss: 0.500875]\n",
      "[Epoch 37/200] [Batch 253/637] [D loss: 0.158771] [G loss: 0.453557]\n",
      "[Epoch 37/200] [Batch 254/637] [D loss: 0.174213] [G loss: 0.452505]\n",
      "[Epoch 37/200] [Batch 255/637] [D loss: 0.147779] [G loss: 0.533533]\n",
      "[Epoch 37/200] [Batch 256/637] [D loss: 0.191045] [G loss: 0.504024]\n",
      "[Epoch 37/200] [Batch 257/637] [D loss: 0.168152] [G loss: 0.533479]\n",
      "[Epoch 37/200] [Batch 258/637] [D loss: 0.153913] [G loss: 0.491244]\n",
      "[Epoch 37/200] [Batch 259/637] [D loss: 0.136499] [G loss: 0.546658]\n",
      "[Epoch 37/200] [Batch 260/637] [D loss: 0.181584] [G loss: 0.510822]\n",
      "[Epoch 37/200] [Batch 261/637] [D loss: 0.170624] [G loss: 0.499232]\n",
      "[Epoch 37/200] [Batch 262/637] [D loss: 0.171195] [G loss: 0.509357]\n",
      "[Epoch 37/200] [Batch 263/637] [D loss: 0.160396] [G loss: 0.517184]\n",
      "[Epoch 37/200] [Batch 264/637] [D loss: 0.171652] [G loss: 0.475426]\n",
      "[Epoch 37/200] [Batch 265/637] [D loss: 0.160511] [G loss: 0.454254]\n",
      "[Epoch 37/200] [Batch 266/637] [D loss: 0.184802] [G loss: 0.448047]\n",
      "[Epoch 37/200] [Batch 267/637] [D loss: 0.168540] [G loss: 0.518345]\n",
      "[Epoch 37/200] [Batch 268/637] [D loss: 0.166130] [G loss: 0.533168]\n",
      "[Epoch 37/200] [Batch 269/637] [D loss: 0.189492] [G loss: 0.511466]\n",
      "[Epoch 37/200] [Batch 270/637] [D loss: 0.183531] [G loss: 0.480179]\n",
      "[Epoch 37/200] [Batch 271/637] [D loss: 0.193497] [G loss: 0.468405]\n",
      "[Epoch 37/200] [Batch 272/637] [D loss: 0.157184] [G loss: 0.552284]\n",
      "[Epoch 37/200] [Batch 273/637] [D loss: 0.169997] [G loss: 0.480204]\n",
      "[Epoch 37/200] [Batch 274/637] [D loss: 0.165912] [G loss: 0.496892]\n",
      "[Epoch 37/200] [Batch 275/637] [D loss: 0.158776] [G loss: 0.548597]\n",
      "[Epoch 37/200] [Batch 276/637] [D loss: 0.161836] [G loss: 0.453262]\n",
      "[Epoch 37/200] [Batch 277/637] [D loss: 0.147639] [G loss: 0.515970]\n",
      "[Epoch 37/200] [Batch 278/637] [D loss: 0.163747] [G loss: 0.455035]\n",
      "[Epoch 37/200] [Batch 279/637] [D loss: 0.142093] [G loss: 0.544204]\n",
      "[Epoch 37/200] [Batch 280/637] [D loss: 0.195020] [G loss: 0.461402]\n",
      "[Epoch 37/200] [Batch 281/637] [D loss: 0.174579] [G loss: 0.479271]\n",
      "[Epoch 37/200] [Batch 282/637] [D loss: 0.168889] [G loss: 0.482761]\n",
      "[Epoch 37/200] [Batch 283/637] [D loss: 0.153691] [G loss: 0.530109]\n",
      "[Epoch 37/200] [Batch 284/637] [D loss: 0.156151] [G loss: 0.535305]\n",
      "[Epoch 37/200] [Batch 285/637] [D loss: 0.186463] [G loss: 0.465972]\n",
      "[Epoch 37/200] [Batch 286/637] [D loss: 0.162776] [G loss: 0.528388]\n",
      "[Epoch 37/200] [Batch 287/637] [D loss: 0.169330] [G loss: 0.424731]\n",
      "[Epoch 37/200] [Batch 288/637] [D loss: 0.147576] [G loss: 0.511555]\n",
      "[Epoch 37/200] [Batch 289/637] [D loss: 0.148305] [G loss: 0.546152]\n",
      "[Epoch 37/200] [Batch 290/637] [D loss: 0.150676] [G loss: 0.555184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/200] [Batch 291/637] [D loss: 0.143944] [G loss: 0.516767]\n",
      "[Epoch 37/200] [Batch 292/637] [D loss: 0.181637] [G loss: 0.492209]\n",
      "[Epoch 37/200] [Batch 293/637] [D loss: 0.171486] [G loss: 0.598210]\n",
      "[Epoch 37/200] [Batch 294/637] [D loss: 0.174857] [G loss: 0.553261]\n",
      "[Epoch 37/200] [Batch 295/637] [D loss: 0.162243] [G loss: 0.556459]\n",
      "[Epoch 37/200] [Batch 296/637] [D loss: 0.159224] [G loss: 0.535451]\n",
      "[Epoch 37/200] [Batch 297/637] [D loss: 0.173652] [G loss: 0.407324]\n",
      "[Epoch 37/200] [Batch 298/637] [D loss: 0.160180] [G loss: 0.429540]\n",
      "[Epoch 37/200] [Batch 299/637] [D loss: 0.175083] [G loss: 0.515679]\n",
      "[Epoch 37/200] [Batch 300/637] [D loss: 0.213404] [G loss: 0.566301]\n",
      "[Epoch 37/200] [Batch 301/637] [D loss: 0.162273] [G loss: 0.496128]\n",
      "[Epoch 37/200] [Batch 302/637] [D loss: 0.176562] [G loss: 0.381632]\n",
      "[Epoch 37/200] [Batch 303/637] [D loss: 0.168108] [G loss: 0.480713]\n",
      "[Epoch 37/200] [Batch 304/637] [D loss: 0.169297] [G loss: 0.468330]\n",
      "[Epoch 37/200] [Batch 305/637] [D loss: 0.171892] [G loss: 0.456814]\n",
      "[Epoch 37/200] [Batch 306/637] [D loss: 0.148775] [G loss: 0.491148]\n",
      "[Epoch 37/200] [Batch 307/637] [D loss: 0.196818] [G loss: 0.477396]\n",
      "[Epoch 37/200] [Batch 308/637] [D loss: 0.179103] [G loss: 0.489476]\n",
      "[Epoch 37/200] [Batch 309/637] [D loss: 0.181064] [G loss: 0.550477]\n",
      "[Epoch 37/200] [Batch 310/637] [D loss: 0.169999] [G loss: 0.499049]\n",
      "[Epoch 37/200] [Batch 311/637] [D loss: 0.164811] [G loss: 0.446295]\n",
      "[Epoch 37/200] [Batch 312/637] [D loss: 0.164868] [G loss: 0.430792]\n",
      "[Epoch 37/200] [Batch 313/637] [D loss: 0.170541] [G loss: 0.469023]\n",
      "[Epoch 37/200] [Batch 314/637] [D loss: 0.191412] [G loss: 0.464272]\n",
      "[Epoch 37/200] [Batch 315/637] [D loss: 0.156342] [G loss: 0.501632]\n",
      "[Epoch 37/200] [Batch 316/637] [D loss: 0.168675] [G loss: 0.446329]\n",
      "[Epoch 37/200] [Batch 317/637] [D loss: 0.180793] [G loss: 0.468925]\n",
      "[Epoch 37/200] [Batch 318/637] [D loss: 0.160731] [G loss: 0.513075]\n",
      "[Epoch 37/200] [Batch 319/637] [D loss: 0.150402] [G loss: 0.537694]\n",
      "[Epoch 37/200] [Batch 320/637] [D loss: 0.164125] [G loss: 0.516654]\n",
      "[Epoch 37/200] [Batch 321/637] [D loss: 0.142907] [G loss: 0.539710]\n",
      "[Epoch 37/200] [Batch 322/637] [D loss: 0.158752] [G loss: 0.475798]\n",
      "[Epoch 37/200] [Batch 323/637] [D loss: 0.135518] [G loss: 0.499637]\n",
      "[Epoch 37/200] [Batch 324/637] [D loss: 0.163720] [G loss: 0.427411]\n",
      "[Epoch 37/200] [Batch 325/637] [D loss: 0.159974] [G loss: 0.506577]\n",
      "[Epoch 37/200] [Batch 326/637] [D loss: 0.156460] [G loss: 0.530526]\n",
      "[Epoch 37/200] [Batch 327/637] [D loss: 0.150317] [G loss: 0.594286]\n",
      "[Epoch 37/200] [Batch 328/637] [D loss: 0.168731] [G loss: 0.481528]\n",
      "[Epoch 37/200] [Batch 329/637] [D loss: 0.190817] [G loss: 0.415425]\n",
      "[Epoch 37/200] [Batch 330/637] [D loss: 0.160097] [G loss: 0.538389]\n",
      "[Epoch 37/200] [Batch 331/637] [D loss: 0.153718] [G loss: 0.508721]\n",
      "[Epoch 37/200] [Batch 332/637] [D loss: 0.144513] [G loss: 0.499804]\n",
      "[Epoch 37/200] [Batch 333/637] [D loss: 0.160815] [G loss: 0.457136]\n",
      "[Epoch 37/200] [Batch 334/637] [D loss: 0.153855] [G loss: 0.451664]\n",
      "[Epoch 37/200] [Batch 335/637] [D loss: 0.156169] [G loss: 0.497384]\n",
      "[Epoch 37/200] [Batch 336/637] [D loss: 0.143036] [G loss: 0.558548]\n",
      "[Epoch 37/200] [Batch 337/637] [D loss: 0.152194] [G loss: 0.516264]\n",
      "[Epoch 37/200] [Batch 338/637] [D loss: 0.150858] [G loss: 0.492173]\n",
      "[Epoch 37/200] [Batch 339/637] [D loss: 0.180438] [G loss: 0.442732]\n",
      "[Epoch 37/200] [Batch 340/637] [D loss: 0.144379] [G loss: 0.482900]\n",
      "[Epoch 37/200] [Batch 341/637] [D loss: 0.162516] [G loss: 0.538226]\n",
      "[Epoch 37/200] [Batch 342/637] [D loss: 0.201933] [G loss: 0.464045]\n",
      "[Epoch 37/200] [Batch 343/637] [D loss: 0.168968] [G loss: 0.565659]\n",
      "[Epoch 37/200] [Batch 344/637] [D loss: 0.165863] [G loss: 0.541647]\n",
      "[Epoch 37/200] [Batch 345/637] [D loss: 0.163723] [G loss: 0.593446]\n",
      "[Epoch 37/200] [Batch 346/637] [D loss: 0.145367] [G loss: 0.520869]\n",
      "[Epoch 37/200] [Batch 347/637] [D loss: 0.167242] [G loss: 0.457997]\n",
      "[Epoch 37/200] [Batch 348/637] [D loss: 0.154157] [G loss: 0.572850]\n",
      "[Epoch 37/200] [Batch 349/637] [D loss: 0.157954] [G loss: 0.622685]\n",
      "[Epoch 37/200] [Batch 350/637] [D loss: 0.177299] [G loss: 0.486007]\n",
      "[Epoch 37/200] [Batch 351/637] [D loss: 0.173480] [G loss: 0.511749]\n",
      "[Epoch 37/200] [Batch 352/637] [D loss: 0.157126] [G loss: 0.564590]\n",
      "[Epoch 37/200] [Batch 353/637] [D loss: 0.171330] [G loss: 0.507992]\n",
      "[Epoch 37/200] [Batch 354/637] [D loss: 0.169291] [G loss: 0.504099]\n",
      "[Epoch 37/200] [Batch 355/637] [D loss: 0.182669] [G loss: 0.494870]\n",
      "[Epoch 37/200] [Batch 356/637] [D loss: 0.196349] [G loss: 0.447482]\n",
      "[Epoch 37/200] [Batch 357/637] [D loss: 0.165887] [G loss: 0.470988]\n",
      "[Epoch 37/200] [Batch 358/637] [D loss: 0.171302] [G loss: 0.515404]\n",
      "[Epoch 37/200] [Batch 359/637] [D loss: 0.165183] [G loss: 0.490332]\n",
      "[Epoch 37/200] [Batch 360/637] [D loss: 0.163737] [G loss: 0.523431]\n",
      "[Epoch 37/200] [Batch 361/637] [D loss: 0.158258] [G loss: 0.522898]\n",
      "[Epoch 37/200] [Batch 362/637] [D loss: 0.185090] [G loss: 0.512307]\n",
      "[Epoch 37/200] [Batch 363/637] [D loss: 0.194873] [G loss: 0.566270]\n",
      "[Epoch 37/200] [Batch 364/637] [D loss: 0.162883] [G loss: 0.509107]\n",
      "[Epoch 37/200] [Batch 365/637] [D loss: 0.172201] [G loss: 0.462732]\n",
      "[Epoch 37/200] [Batch 366/637] [D loss: 0.162849] [G loss: 0.474253]\n",
      "[Epoch 37/200] [Batch 367/637] [D loss: 0.153529] [G loss: 0.446316]\n",
      "[Epoch 37/200] [Batch 368/637] [D loss: 0.173896] [G loss: 0.419774]\n",
      "[Epoch 37/200] [Batch 369/637] [D loss: 0.161988] [G loss: 0.531529]\n",
      "[Epoch 37/200] [Batch 370/637] [D loss: 0.156429] [G loss: 0.579909]\n",
      "[Epoch 37/200] [Batch 371/637] [D loss: 0.177378] [G loss: 0.474688]\n",
      "[Epoch 37/200] [Batch 372/637] [D loss: 0.159517] [G loss: 0.477130]\n",
      "[Epoch 37/200] [Batch 373/637] [D loss: 0.175804] [G loss: 0.499481]\n",
      "[Epoch 37/200] [Batch 374/637] [D loss: 0.164767] [G loss: 0.498557]\n",
      "[Epoch 37/200] [Batch 375/637] [D loss: 0.149131] [G loss: 0.522389]\n",
      "[Epoch 37/200] [Batch 376/637] [D loss: 0.162615] [G loss: 0.491652]\n",
      "[Epoch 37/200] [Batch 377/637] [D loss: 0.158718] [G loss: 0.520064]\n",
      "[Epoch 37/200] [Batch 378/637] [D loss: 0.144054] [G loss: 0.472737]\n",
      "[Epoch 37/200] [Batch 379/637] [D loss: 0.150972] [G loss: 0.442445]\n",
      "[Epoch 37/200] [Batch 380/637] [D loss: 0.160677] [G loss: 0.523806]\n",
      "[Epoch 37/200] [Batch 381/637] [D loss: 0.221140] [G loss: 0.473891]\n",
      "[Epoch 37/200] [Batch 382/637] [D loss: 0.177875] [G loss: 0.508921]\n",
      "[Epoch 37/200] [Batch 383/637] [D loss: 0.177759] [G loss: 0.580841]\n",
      "[Epoch 37/200] [Batch 384/637] [D loss: 0.165878] [G loss: 0.545177]\n",
      "[Epoch 37/200] [Batch 385/637] [D loss: 0.179597] [G loss: 0.393873]\n",
      "[Epoch 37/200] [Batch 386/637] [D loss: 0.184500] [G loss: 0.342083]\n",
      "[Epoch 37/200] [Batch 387/637] [D loss: 0.171438] [G loss: 0.451820]\n",
      "[Epoch 37/200] [Batch 388/637] [D loss: 0.151522] [G loss: 0.508382]\n",
      "[Epoch 37/200] [Batch 389/637] [D loss: 0.161628] [G loss: 0.415481]\n",
      "[Epoch 37/200] [Batch 390/637] [D loss: 0.157433] [G loss: 0.517439]\n",
      "[Epoch 37/200] [Batch 391/637] [D loss: 0.178876] [G loss: 0.448871]\n",
      "[Epoch 37/200] [Batch 392/637] [D loss: 0.172848] [G loss: 0.494184]\n",
      "[Epoch 37/200] [Batch 393/637] [D loss: 0.154844] [G loss: 0.453618]\n",
      "[Epoch 37/200] [Batch 394/637] [D loss: 0.176417] [G loss: 0.497645]\n",
      "[Epoch 37/200] [Batch 395/637] [D loss: 0.172831] [G loss: 0.575579]\n",
      "[Epoch 37/200] [Batch 396/637] [D loss: 0.177361] [G loss: 0.480315]\n",
      "[Epoch 37/200] [Batch 397/637] [D loss: 0.180142] [G loss: 0.417163]\n",
      "[Epoch 37/200] [Batch 398/637] [D loss: 0.155812] [G loss: 0.467152]\n",
      "[Epoch 37/200] [Batch 399/637] [D loss: 0.174016] [G loss: 0.433637]\n",
      "[Epoch 37/200] [Batch 400/637] [D loss: 0.165356] [G loss: 0.500381]\n",
      "[Epoch 37/200] [Batch 401/637] [D loss: 0.150580] [G loss: 0.514400]\n",
      "[Epoch 37/200] [Batch 402/637] [D loss: 0.152078] [G loss: 0.538999]\n",
      "[Epoch 37/200] [Batch 403/637] [D loss: 0.168274] [G loss: 0.511814]\n",
      "[Epoch 37/200] [Batch 404/637] [D loss: 0.159746] [G loss: 0.448875]\n",
      "[Epoch 37/200] [Batch 405/637] [D loss: 0.198818] [G loss: 0.469140]\n",
      "[Epoch 37/200] [Batch 406/637] [D loss: 0.153270] [G loss: 0.558479]\n",
      "[Epoch 37/200] [Batch 407/637] [D loss: 0.157151] [G loss: 0.533771]\n",
      "[Epoch 37/200] [Batch 408/637] [D loss: 0.148135] [G loss: 0.509113]\n",
      "[Epoch 37/200] [Batch 409/637] [D loss: 0.149215] [G loss: 0.513380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/200] [Batch 410/637] [D loss: 0.156295] [G loss: 0.507696]\n",
      "[Epoch 37/200] [Batch 411/637] [D loss: 0.154870] [G loss: 0.596072]\n",
      "[Epoch 37/200] [Batch 412/637] [D loss: 0.150396] [G loss: 0.549807]\n",
      "[Epoch 37/200] [Batch 413/637] [D loss: 0.153949] [G loss: 0.550810]\n",
      "[Epoch 37/200] [Batch 414/637] [D loss: 0.197341] [G loss: 0.447959]\n",
      "[Epoch 37/200] [Batch 415/637] [D loss: 0.174675] [G loss: 0.561025]\n",
      "[Epoch 37/200] [Batch 416/637] [D loss: 0.180621] [G loss: 0.544678]\n",
      "[Epoch 37/200] [Batch 417/637] [D loss: 0.173091] [G loss: 0.462487]\n",
      "[Epoch 37/200] [Batch 418/637] [D loss: 0.152050] [G loss: 0.546867]\n",
      "[Epoch 37/200] [Batch 419/637] [D loss: 0.170397] [G loss: 0.435619]\n",
      "[Epoch 37/200] [Batch 420/637] [D loss: 0.155228] [G loss: 0.496077]\n",
      "[Epoch 37/200] [Batch 421/637] [D loss: 0.177952] [G loss: 0.476334]\n",
      "[Epoch 37/200] [Batch 422/637] [D loss: 0.178137] [G loss: 0.502507]\n",
      "[Epoch 37/200] [Batch 423/637] [D loss: 0.178698] [G loss: 0.556262]\n",
      "[Epoch 37/200] [Batch 424/637] [D loss: 0.153014] [G loss: 0.535173]\n",
      "[Epoch 37/200] [Batch 425/637] [D loss: 0.165011] [G loss: 0.563134]\n",
      "[Epoch 37/200] [Batch 426/637] [D loss: 0.149554] [G loss: 0.473875]\n",
      "[Epoch 37/200] [Batch 427/637] [D loss: 0.154510] [G loss: 0.552868]\n",
      "[Epoch 37/200] [Batch 428/637] [D loss: 0.166982] [G loss: 0.548995]\n",
      "[Epoch 37/200] [Batch 429/637] [D loss: 0.169532] [G loss: 0.500046]\n",
      "[Epoch 37/200] [Batch 430/637] [D loss: 0.158267] [G loss: 0.534592]\n",
      "[Epoch 37/200] [Batch 431/637] [D loss: 0.185578] [G loss: 0.488324]\n",
      "[Epoch 37/200] [Batch 432/637] [D loss: 0.154327] [G loss: 0.490051]\n",
      "[Epoch 37/200] [Batch 433/637] [D loss: 0.179417] [G loss: 0.461190]\n",
      "[Epoch 37/200] [Batch 434/637] [D loss: 0.168964] [G loss: 0.540769]\n",
      "[Epoch 37/200] [Batch 435/637] [D loss: 0.168222] [G loss: 0.500406]\n",
      "[Epoch 37/200] [Batch 436/637] [D loss: 0.169001] [G loss: 0.453240]\n",
      "[Epoch 37/200] [Batch 437/637] [D loss: 0.165520] [G loss: 0.418318]\n",
      "[Epoch 37/200] [Batch 438/637] [D loss: 0.158921] [G loss: 0.470931]\n",
      "[Epoch 37/200] [Batch 439/637] [D loss: 0.155354] [G loss: 0.484607]\n",
      "[Epoch 37/200] [Batch 440/637] [D loss: 0.164734] [G loss: 0.482656]\n",
      "[Epoch 37/200] [Batch 441/637] [D loss: 0.149953] [G loss: 0.524595]\n",
      "[Epoch 37/200] [Batch 442/637] [D loss: 0.143479] [G loss: 0.571495]\n",
      "[Epoch 37/200] [Batch 443/637] [D loss: 0.169514] [G loss: 0.564015]\n",
      "[Epoch 37/200] [Batch 444/637] [D loss: 0.178094] [G loss: 0.441897]\n",
      "[Epoch 37/200] [Batch 445/637] [D loss: 0.174539] [G loss: 0.487976]\n",
      "[Epoch 37/200] [Batch 446/637] [D loss: 0.164695] [G loss: 0.538363]\n",
      "[Epoch 37/200] [Batch 447/637] [D loss: 0.167494] [G loss: 0.432584]\n",
      "[Epoch 37/200] [Batch 448/637] [D loss: 0.191656] [G loss: 0.424242]\n",
      "[Epoch 37/200] [Batch 449/637] [D loss: 0.179107] [G loss: 0.453944]\n",
      "[Epoch 37/200] [Batch 450/637] [D loss: 0.168294] [G loss: 0.413822]\n",
      "[Epoch 37/200] [Batch 451/637] [D loss: 0.158704] [G loss: 0.520297]\n",
      "[Epoch 37/200] [Batch 452/637] [D loss: 0.184156] [G loss: 0.496300]\n",
      "[Epoch 37/200] [Batch 453/637] [D loss: 0.163797] [G loss: 0.507273]\n",
      "[Epoch 37/200] [Batch 454/637] [D loss: 0.178369] [G loss: 0.456292]\n",
      "[Epoch 37/200] [Batch 455/637] [D loss: 0.153691] [G loss: 0.521822]\n",
      "[Epoch 37/200] [Batch 456/637] [D loss: 0.150336] [G loss: 0.510560]\n",
      "[Epoch 37/200] [Batch 457/637] [D loss: 0.155999] [G loss: 0.488327]\n",
      "[Epoch 37/200] [Batch 458/637] [D loss: 0.184263] [G loss: 0.495979]\n",
      "[Epoch 37/200] [Batch 459/637] [D loss: 0.167701] [G loss: 0.524297]\n",
      "[Epoch 37/200] [Batch 460/637] [D loss: 0.163853] [G loss: 0.553808]\n",
      "[Epoch 37/200] [Batch 461/637] [D loss: 0.173528] [G loss: 0.508030]\n",
      "[Epoch 37/200] [Batch 462/637] [D loss: 0.171233] [G loss: 0.523617]\n",
      "[Epoch 37/200] [Batch 463/637] [D loss: 0.161991] [G loss: 0.473509]\n",
      "[Epoch 37/200] [Batch 464/637] [D loss: 0.180699] [G loss: 0.510335]\n",
      "[Epoch 37/200] [Batch 465/637] [D loss: 0.150403] [G loss: 0.548269]\n",
      "[Epoch 37/200] [Batch 466/637] [D loss: 0.183509] [G loss: 0.559049]\n",
      "[Epoch 37/200] [Batch 467/637] [D loss: 0.184154] [G loss: 0.489012]\n",
      "[Epoch 37/200] [Batch 468/637] [D loss: 0.149778] [G loss: 0.515703]\n",
      "[Epoch 37/200] [Batch 469/637] [D loss: 0.165654] [G loss: 0.556518]\n",
      "[Epoch 37/200] [Batch 470/637] [D loss: 0.157038] [G loss: 0.505275]\n",
      "[Epoch 37/200] [Batch 471/637] [D loss: 0.148325] [G loss: 0.481984]\n",
      "[Epoch 37/200] [Batch 472/637] [D loss: 0.165234] [G loss: 0.538707]\n",
      "[Epoch 37/200] [Batch 473/637] [D loss: 0.199260] [G loss: 0.449629]\n",
      "[Epoch 37/200] [Batch 474/637] [D loss: 0.203012] [G loss: 0.539247]\n",
      "[Epoch 37/200] [Batch 475/637] [D loss: 0.174650] [G loss: 0.499390]\n",
      "[Epoch 37/200] [Batch 476/637] [D loss: 0.177566] [G loss: 0.472973]\n",
      "[Epoch 37/200] [Batch 477/637] [D loss: 0.181176] [G loss: 0.447164]\n",
      "[Epoch 37/200] [Batch 478/637] [D loss: 0.168170] [G loss: 0.542744]\n",
      "[Epoch 37/200] [Batch 479/637] [D loss: 0.197833] [G loss: 0.529152]\n",
      "[Epoch 37/200] [Batch 480/637] [D loss: 0.178115] [G loss: 0.464287]\n",
      "[Epoch 37/200] [Batch 481/637] [D loss: 0.214500] [G loss: 0.366976]\n",
      "[Epoch 37/200] [Batch 482/637] [D loss: 0.165026] [G loss: 0.577848]\n",
      "[Epoch 37/200] [Batch 483/637] [D loss: 0.169785] [G loss: 0.495544]\n",
      "[Epoch 37/200] [Batch 484/637] [D loss: 0.153057] [G loss: 0.516003]\n",
      "[Epoch 37/200] [Batch 485/637] [D loss: 0.148924] [G loss: 0.472782]\n",
      "[Epoch 37/200] [Batch 486/637] [D loss: 0.149699] [G loss: 0.478989]\n",
      "[Epoch 37/200] [Batch 487/637] [D loss: 0.168259] [G loss: 0.531143]\n",
      "[Epoch 37/200] [Batch 488/637] [D loss: 0.156225] [G loss: 0.539605]\n",
      "[Epoch 37/200] [Batch 489/637] [D loss: 0.176705] [G loss: 0.497519]\n",
      "[Epoch 37/200] [Batch 490/637] [D loss: 0.166153] [G loss: 0.492993]\n",
      "[Epoch 37/200] [Batch 491/637] [D loss: 0.173267] [G loss: 0.518802]\n",
      "[Epoch 37/200] [Batch 492/637] [D loss: 0.174819] [G loss: 0.498649]\n",
      "[Epoch 37/200] [Batch 493/637] [D loss: 0.205672] [G loss: 0.378712]\n",
      "[Epoch 37/200] [Batch 494/637] [D loss: 0.183452] [G loss: 0.459650]\n",
      "[Epoch 37/200] [Batch 495/637] [D loss: 0.172945] [G loss: 0.511437]\n",
      "[Epoch 37/200] [Batch 496/637] [D loss: 0.161728] [G loss: 0.513362]\n",
      "[Epoch 37/200] [Batch 497/637] [D loss: 0.174589] [G loss: 0.458578]\n",
      "[Epoch 37/200] [Batch 498/637] [D loss: 0.187280] [G loss: 0.393834]\n",
      "[Epoch 37/200] [Batch 499/637] [D loss: 0.160901] [G loss: 0.508230]\n",
      "[Epoch 37/200] [Batch 500/637] [D loss: 0.171354] [G loss: 0.534876]\n",
      "[Epoch 37/200] [Batch 501/637] [D loss: 0.168652] [G loss: 0.483827]\n",
      "[Epoch 37/200] [Batch 502/637] [D loss: 0.170733] [G loss: 0.450216]\n",
      "[Epoch 37/200] [Batch 503/637] [D loss: 0.173852] [G loss: 0.500518]\n",
      "[Epoch 37/200] [Batch 504/637] [D loss: 0.144655] [G loss: 0.575621]\n",
      "[Epoch 37/200] [Batch 505/637] [D loss: 0.172191] [G loss: 0.527635]\n",
      "[Epoch 37/200] [Batch 506/637] [D loss: 0.156283] [G loss: 0.581166]\n",
      "[Epoch 37/200] [Batch 507/637] [D loss: 0.166834] [G loss: 0.537695]\n",
      "[Epoch 37/200] [Batch 508/637] [D loss: 0.169587] [G loss: 0.463530]\n",
      "[Epoch 37/200] [Batch 509/637] [D loss: 0.185673] [G loss: 0.432934]\n",
      "[Epoch 37/200] [Batch 510/637] [D loss: 0.171126] [G loss: 0.496471]\n",
      "[Epoch 37/200] [Batch 511/637] [D loss: 0.161382] [G loss: 0.510415]\n",
      "[Epoch 37/200] [Batch 512/637] [D loss: 0.173795] [G loss: 0.459704]\n",
      "[Epoch 37/200] [Batch 513/637] [D loss: 0.171383] [G loss: 0.497787]\n",
      "[Epoch 37/200] [Batch 514/637] [D loss: 0.184791] [G loss: 0.435670]\n",
      "[Epoch 37/200] [Batch 515/637] [D loss: 0.159952] [G loss: 0.497650]\n",
      "[Epoch 37/200] [Batch 516/637] [D loss: 0.159261] [G loss: 0.489369]\n",
      "[Epoch 37/200] [Batch 517/637] [D loss: 0.171663] [G loss: 0.454938]\n",
      "[Epoch 37/200] [Batch 518/637] [D loss: 0.188470] [G loss: 0.530939]\n",
      "[Epoch 37/200] [Batch 519/637] [D loss: 0.218139] [G loss: 0.427067]\n",
      "[Epoch 37/200] [Batch 520/637] [D loss: 0.171025] [G loss: 0.547840]\n",
      "[Epoch 37/200] [Batch 521/637] [D loss: 0.184935] [G loss: 0.523946]\n",
      "[Epoch 37/200] [Batch 522/637] [D loss: 0.161909] [G loss: 0.503769]\n",
      "[Epoch 37/200] [Batch 523/637] [D loss: 0.175785] [G loss: 0.421471]\n",
      "[Epoch 37/200] [Batch 524/637] [D loss: 0.181367] [G loss: 0.507487]\n",
      "[Epoch 37/200] [Batch 525/637] [D loss: 0.162067] [G loss: 0.567760]\n",
      "[Epoch 37/200] [Batch 526/637] [D loss: 0.178729] [G loss: 0.503114]\n",
      "[Epoch 37/200] [Batch 527/637] [D loss: 0.173726] [G loss: 0.494688]\n",
      "[Epoch 37/200] [Batch 528/637] [D loss: 0.166514] [G loss: 0.483454]\n",
      "[Epoch 37/200] [Batch 529/637] [D loss: 0.179970] [G loss: 0.462926]\n",
      "[Epoch 37/200] [Batch 530/637] [D loss: 0.153649] [G loss: 0.547060]\n",
      "[Epoch 37/200] [Batch 531/637] [D loss: 0.158179] [G loss: 0.528532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/200] [Batch 532/637] [D loss: 0.154654] [G loss: 0.527048]\n",
      "[Epoch 37/200] [Batch 533/637] [D loss: 0.148156] [G loss: 0.530478]\n",
      "[Epoch 37/200] [Batch 534/637] [D loss: 0.171044] [G loss: 0.501905]\n",
      "[Epoch 37/200] [Batch 535/637] [D loss: 0.163356] [G loss: 0.523417]\n",
      "[Epoch 37/200] [Batch 536/637] [D loss: 0.168094] [G loss: 0.498426]\n",
      "[Epoch 37/200] [Batch 537/637] [D loss: 0.154760] [G loss: 0.543223]\n",
      "[Epoch 37/200] [Batch 538/637] [D loss: 0.183486] [G loss: 0.440071]\n",
      "[Epoch 37/200] [Batch 539/637] [D loss: 0.177061] [G loss: 0.616127]\n",
      "[Epoch 37/200] [Batch 540/637] [D loss: 0.144817] [G loss: 0.616843]\n",
      "[Epoch 37/200] [Batch 541/637] [D loss: 0.169920] [G loss: 0.464242]\n",
      "[Epoch 37/200] [Batch 542/637] [D loss: 0.165022] [G loss: 0.456003]\n",
      "[Epoch 37/200] [Batch 543/637] [D loss: 0.174809] [G loss: 0.514785]\n",
      "[Epoch 37/200] [Batch 544/637] [D loss: 0.157697] [G loss: 0.561164]\n",
      "[Epoch 37/200] [Batch 545/637] [D loss: 0.180483] [G loss: 0.509772]\n",
      "[Epoch 37/200] [Batch 546/637] [D loss: 0.165367] [G loss: 0.517799]\n",
      "[Epoch 37/200] [Batch 547/637] [D loss: 0.165972] [G loss: 0.497040]\n",
      "[Epoch 37/200] [Batch 548/637] [D loss: 0.159590] [G loss: 0.505027]\n",
      "[Epoch 37/200] [Batch 549/637] [D loss: 0.168341] [G loss: 0.430361]\n",
      "[Epoch 37/200] [Batch 550/637] [D loss: 0.150877] [G loss: 0.491345]\n",
      "[Epoch 37/200] [Batch 551/637] [D loss: 0.158002] [G loss: 0.485606]\n",
      "[Epoch 37/200] [Batch 552/637] [D loss: 0.171964] [G loss: 0.455110]\n",
      "[Epoch 37/200] [Batch 553/637] [D loss: 0.188942] [G loss: 0.471690]\n",
      "[Epoch 37/200] [Batch 554/637] [D loss: 0.166417] [G loss: 0.522795]\n",
      "[Epoch 37/200] [Batch 555/637] [D loss: 0.181692] [G loss: 0.467861]\n",
      "[Epoch 37/200] [Batch 556/637] [D loss: 0.181232] [G loss: 0.473373]\n",
      "[Epoch 37/200] [Batch 557/637] [D loss: 0.170244] [G loss: 0.495454]\n",
      "[Epoch 37/200] [Batch 558/637] [D loss: 0.169627] [G loss: 0.487235]\n",
      "[Epoch 37/200] [Batch 559/637] [D loss: 0.167282] [G loss: 0.502488]\n",
      "[Epoch 37/200] [Batch 560/637] [D loss: 0.183750] [G loss: 0.425169]\n",
      "[Epoch 37/200] [Batch 561/637] [D loss: 0.154265] [G loss: 0.463466]\n",
      "[Epoch 37/200] [Batch 562/637] [D loss: 0.158938] [G loss: 0.439830]\n",
      "[Epoch 37/200] [Batch 563/637] [D loss: 0.180213] [G loss: 0.469303]\n",
      "[Epoch 37/200] [Batch 564/637] [D loss: 0.184268] [G loss: 0.517809]\n",
      "[Epoch 37/200] [Batch 565/637] [D loss: 0.164644] [G loss: 0.566701]\n",
      "[Epoch 37/200] [Batch 566/637] [D loss: 0.191945] [G loss: 0.435601]\n",
      "[Epoch 37/200] [Batch 567/637] [D loss: 0.187190] [G loss: 0.386279]\n",
      "[Epoch 37/200] [Batch 568/637] [D loss: 0.168435] [G loss: 0.482839]\n",
      "[Epoch 37/200] [Batch 569/637] [D loss: 0.186312] [G loss: 0.426497]\n",
      "[Epoch 37/200] [Batch 570/637] [D loss: 0.165554] [G loss: 0.514533]\n",
      "[Epoch 37/200] [Batch 571/637] [D loss: 0.190631] [G loss: 0.502006]\n",
      "[Epoch 37/200] [Batch 572/637] [D loss: 0.173354] [G loss: 0.479556]\n",
      "[Epoch 37/200] [Batch 573/637] [D loss: 0.184534] [G loss: 0.488695]\n",
      "[Epoch 37/200] [Batch 574/637] [D loss: 0.157440] [G loss: 0.549022]\n",
      "[Epoch 37/200] [Batch 575/637] [D loss: 0.162870] [G loss: 0.439922]\n",
      "[Epoch 37/200] [Batch 576/637] [D loss: 0.160663] [G loss: 0.487947]\n",
      "[Epoch 37/200] [Batch 577/637] [D loss: 0.167962] [G loss: 0.464711]\n",
      "[Epoch 37/200] [Batch 578/637] [D loss: 0.173607] [G loss: 0.529472]\n",
      "[Epoch 37/200] [Batch 579/637] [D loss: 0.186530] [G loss: 0.536090]\n",
      "[Epoch 37/200] [Batch 580/637] [D loss: 0.167582] [G loss: 0.454863]\n",
      "[Epoch 37/200] [Batch 581/637] [D loss: 0.159204] [G loss: 0.465213]\n",
      "[Epoch 37/200] [Batch 582/637] [D loss: 0.136962] [G loss: 0.470781]\n",
      "[Epoch 37/200] [Batch 583/637] [D loss: 0.160647] [G loss: 0.460888]\n",
      "[Epoch 37/200] [Batch 584/637] [D loss: 0.154443] [G loss: 0.564658]\n",
      "[Epoch 37/200] [Batch 585/637] [D loss: 0.152066] [G loss: 0.478156]\n",
      "[Epoch 37/200] [Batch 586/637] [D loss: 0.156700] [G loss: 0.542700]\n",
      "[Epoch 37/200] [Batch 587/637] [D loss: 0.158890] [G loss: 0.468055]\n",
      "[Epoch 37/200] [Batch 588/637] [D loss: 0.158103] [G loss: 0.520314]\n",
      "[Epoch 37/200] [Batch 589/637] [D loss: 0.179195] [G loss: 0.475381]\n",
      "[Epoch 37/200] [Batch 590/637] [D loss: 0.157411] [G loss: 0.477071]\n",
      "[Epoch 37/200] [Batch 591/637] [D loss: 0.161073] [G loss: 0.514555]\n",
      "[Epoch 37/200] [Batch 592/637] [D loss: 0.159120] [G loss: 0.548500]\n",
      "[Epoch 37/200] [Batch 593/637] [D loss: 0.162963] [G loss: 0.505683]\n",
      "[Epoch 37/200] [Batch 594/637] [D loss: 0.190948] [G loss: 0.416305]\n",
      "[Epoch 37/200] [Batch 595/637] [D loss: 0.148961] [G loss: 0.497912]\n",
      "[Epoch 37/200] [Batch 596/637] [D loss: 0.161817] [G loss: 0.496417]\n",
      "[Epoch 37/200] [Batch 597/637] [D loss: 0.156393] [G loss: 0.529132]\n",
      "[Epoch 37/200] [Batch 598/637] [D loss: 0.164870] [G loss: 0.506695]\n",
      "[Epoch 37/200] [Batch 599/637] [D loss: 0.190526] [G loss: 0.425836]\n",
      "[Epoch 37/200] [Batch 600/637] [D loss: 0.178993] [G loss: 0.500208]\n",
      "[Epoch 37/200] [Batch 601/637] [D loss: 0.156065] [G loss: 0.481607]\n",
      "[Epoch 37/200] [Batch 602/637] [D loss: 0.168887] [G loss: 0.448796]\n",
      "[Epoch 37/200] [Batch 603/637] [D loss: 0.174970] [G loss: 0.489452]\n",
      "[Epoch 37/200] [Batch 604/637] [D loss: 0.159101] [G loss: 0.552023]\n",
      "[Epoch 37/200] [Batch 605/637] [D loss: 0.163709] [G loss: 0.454719]\n",
      "[Epoch 37/200] [Batch 606/637] [D loss: 0.174688] [G loss: 0.484773]\n",
      "[Epoch 37/200] [Batch 607/637] [D loss: 0.147557] [G loss: 0.477489]\n",
      "[Epoch 37/200] [Batch 608/637] [D loss: 0.170880] [G loss: 0.475801]\n",
      "[Epoch 37/200] [Batch 609/637] [D loss: 0.166262] [G loss: 0.536745]\n",
      "[Epoch 37/200] [Batch 610/637] [D loss: 0.157974] [G loss: 0.511272]\n",
      "[Epoch 37/200] [Batch 611/637] [D loss: 0.222438] [G loss: 0.545241]\n",
      "[Epoch 37/200] [Batch 612/637] [D loss: 0.177363] [G loss: 0.560824]\n",
      "[Epoch 37/200] [Batch 613/637] [D loss: 0.197928] [G loss: 0.512135]\n",
      "[Epoch 37/200] [Batch 614/637] [D loss: 0.172923] [G loss: 0.489006]\n",
      "[Epoch 37/200] [Batch 615/637] [D loss: 0.171568] [G loss: 0.492795]\n",
      "[Epoch 37/200] [Batch 616/637] [D loss: 0.163415] [G loss: 0.483332]\n",
      "[Epoch 37/200] [Batch 617/637] [D loss: 0.174060] [G loss: 0.468568]\n",
      "[Epoch 37/200] [Batch 618/637] [D loss: 0.173820] [G loss: 0.481267]\n",
      "[Epoch 37/200] [Batch 619/637] [D loss: 0.176694] [G loss: 0.512293]\n",
      "[Epoch 37/200] [Batch 620/637] [D loss: 0.152705] [G loss: 0.518167]\n",
      "[Epoch 37/200] [Batch 621/637] [D loss: 0.174334] [G loss: 0.559727]\n",
      "[Epoch 37/200] [Batch 622/637] [D loss: 0.161674] [G loss: 0.497623]\n",
      "[Epoch 37/200] [Batch 623/637] [D loss: 0.152948] [G loss: 0.463191]\n",
      "[Epoch 37/200] [Batch 624/637] [D loss: 0.158099] [G loss: 0.496496]\n",
      "[Epoch 37/200] [Batch 625/637] [D loss: 0.165142] [G loss: 0.500930]\n",
      "[Epoch 37/200] [Batch 626/637] [D loss: 0.165075] [G loss: 0.570170]\n",
      "[Epoch 37/200] [Batch 627/637] [D loss: 0.161329] [G loss: 0.498588]\n",
      "[Epoch 37/200] [Batch 628/637] [D loss: 0.151386] [G loss: 0.503531]\n",
      "[Epoch 37/200] [Batch 629/637] [D loss: 0.147130] [G loss: 0.504658]\n",
      "[Epoch 37/200] [Batch 630/637] [D loss: 0.156210] [G loss: 0.488832]\n",
      "[Epoch 37/200] [Batch 631/637] [D loss: 0.178610] [G loss: 0.468212]\n",
      "[Epoch 37/200] [Batch 632/637] [D loss: 0.158461] [G loss: 0.544098]\n",
      "[Epoch 37/200] [Batch 633/637] [D loss: 0.191882] [G loss: 0.442538]\n",
      "[Epoch 37/200] [Batch 634/637] [D loss: 0.215019] [G loss: 0.515352]\n",
      "[Epoch 37/200] [Batch 635/637] [D loss: 0.167241] [G loss: 0.566962]\n",
      "[Epoch 37/200] [Batch 636/637] [D loss: 0.170752] [G loss: 0.552144]\n",
      "[Epoch 38/200] [Batch 0/637] [D loss: 0.189081] [G loss: 0.479286]\n",
      "[Epoch 38/200] [Batch 1/637] [D loss: 0.151322] [G loss: 0.562323]\n",
      "[Epoch 38/200] [Batch 2/637] [D loss: 0.176804] [G loss: 0.536887]\n",
      "[Epoch 38/200] [Batch 3/637] [D loss: 0.178010] [G loss: 0.487262]\n",
      "[Epoch 38/200] [Batch 4/637] [D loss: 0.166219] [G loss: 0.481225]\n",
      "[Epoch 38/200] [Batch 5/637] [D loss: 0.160880] [G loss: 0.510253]\n",
      "[Epoch 38/200] [Batch 6/637] [D loss: 0.178221] [G loss: 0.450418]\n",
      "[Epoch 38/200] [Batch 7/637] [D loss: 0.145970] [G loss: 0.531155]\n",
      "[Epoch 38/200] [Batch 8/637] [D loss: 0.136124] [G loss: 0.539660]\n",
      "[Epoch 38/200] [Batch 9/637] [D loss: 0.148274] [G loss: 0.513536]\n",
      "[Epoch 38/200] [Batch 10/637] [D loss: 0.199010] [G loss: 0.468009]\n",
      "[Epoch 38/200] [Batch 11/637] [D loss: 0.148059] [G loss: 0.586178]\n",
      "[Epoch 38/200] [Batch 12/637] [D loss: 0.184426] [G loss: 0.561205]\n",
      "[Epoch 38/200] [Batch 13/637] [D loss: 0.173886] [G loss: 0.600174]\n",
      "[Epoch 38/200] [Batch 14/637] [D loss: 0.149092] [G loss: 0.536452]\n",
      "[Epoch 38/200] [Batch 15/637] [D loss: 0.186187] [G loss: 0.446463]\n",
      "[Epoch 38/200] [Batch 16/637] [D loss: 0.210312] [G loss: 0.415716]\n",
      "[Epoch 38/200] [Batch 17/637] [D loss: 0.154123] [G loss: 0.536885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/200] [Batch 18/637] [D loss: 0.206384] [G loss: 0.454522]\n",
      "[Epoch 38/200] [Batch 19/637] [D loss: 0.178165] [G loss: 0.464747]\n",
      "[Epoch 38/200] [Batch 20/637] [D loss: 0.155387] [G loss: 0.544323]\n",
      "[Epoch 38/200] [Batch 21/637] [D loss: 0.174186] [G loss: 0.453023]\n",
      "[Epoch 38/200] [Batch 22/637] [D loss: 0.169695] [G loss: 0.490321]\n",
      "[Epoch 38/200] [Batch 23/637] [D loss: 0.162435] [G loss: 0.493961]\n",
      "[Epoch 38/200] [Batch 24/637] [D loss: 0.151482] [G loss: 0.479163]\n",
      "[Epoch 38/200] [Batch 25/637] [D loss: 0.167664] [G loss: 0.412863]\n",
      "[Epoch 38/200] [Batch 26/637] [D loss: 0.182345] [G loss: 0.462439]\n",
      "[Epoch 38/200] [Batch 27/637] [D loss: 0.176413] [G loss: 0.494503]\n",
      "[Epoch 38/200] [Batch 28/637] [D loss: 0.159322] [G loss: 0.472888]\n",
      "[Epoch 38/200] [Batch 29/637] [D loss: 0.163530] [G loss: 0.499643]\n",
      "[Epoch 38/200] [Batch 30/637] [D loss: 0.156331] [G loss: 0.509915]\n",
      "[Epoch 38/200] [Batch 31/637] [D loss: 0.166820] [G loss: 0.469987]\n",
      "[Epoch 38/200] [Batch 32/637] [D loss: 0.153873] [G loss: 0.455263]\n",
      "[Epoch 38/200] [Batch 33/637] [D loss: 0.189290] [G loss: 0.390194]\n",
      "[Epoch 38/200] [Batch 34/637] [D loss: 0.187985] [G loss: 0.486760]\n",
      "[Epoch 38/200] [Batch 35/637] [D loss: 0.152858] [G loss: 0.548009]\n",
      "[Epoch 38/200] [Batch 36/637] [D loss: 0.160471] [G loss: 0.513541]\n",
      "[Epoch 38/200] [Batch 37/637] [D loss: 0.155620] [G loss: 0.448218]\n",
      "[Epoch 38/200] [Batch 38/637] [D loss: 0.185212] [G loss: 0.449894]\n",
      "[Epoch 38/200] [Batch 39/637] [D loss: 0.171818] [G loss: 0.468129]\n",
      "[Epoch 38/200] [Batch 40/637] [D loss: 0.155468] [G loss: 0.514294]\n",
      "[Epoch 38/200] [Batch 41/637] [D loss: 0.157646] [G loss: 0.528621]\n",
      "[Epoch 38/200] [Batch 42/637] [D loss: 0.159095] [G loss: 0.473635]\n",
      "[Epoch 38/200] [Batch 43/637] [D loss: 0.172766] [G loss: 0.473908]\n",
      "[Epoch 38/200] [Batch 44/637] [D loss: 0.157422] [G loss: 0.564807]\n",
      "[Epoch 38/200] [Batch 45/637] [D loss: 0.193156] [G loss: 0.445328]\n",
      "[Epoch 38/200] [Batch 46/637] [D loss: 0.173740] [G loss: 0.471422]\n",
      "[Epoch 38/200] [Batch 47/637] [D loss: 0.175445] [G loss: 0.472823]\n",
      "[Epoch 38/200] [Batch 48/637] [D loss: 0.174680] [G loss: 0.510503]\n",
      "[Epoch 38/200] [Batch 49/637] [D loss: 0.150567] [G loss: 0.484574]\n",
      "[Epoch 38/200] [Batch 50/637] [D loss: 0.151919] [G loss: 0.514538]\n",
      "[Epoch 38/200] [Batch 51/637] [D loss: 0.157944] [G loss: 0.447966]\n",
      "[Epoch 38/200] [Batch 52/637] [D loss: 0.152926] [G loss: 0.477050]\n",
      "[Epoch 38/200] [Batch 53/637] [D loss: 0.149817] [G loss: 0.503997]\n",
      "[Epoch 38/200] [Batch 54/637] [D loss: 0.214957] [G loss: 0.447184]\n",
      "[Epoch 38/200] [Batch 55/637] [D loss: 0.170511] [G loss: 0.557993]\n",
      "[Epoch 38/200] [Batch 56/637] [D loss: 0.186674] [G loss: 0.535110]\n",
      "[Epoch 38/200] [Batch 57/637] [D loss: 0.169953] [G loss: 0.509804]\n",
      "[Epoch 38/200] [Batch 58/637] [D loss: 0.156422] [G loss: 0.529887]\n",
      "[Epoch 38/200] [Batch 59/637] [D loss: 0.176072] [G loss: 0.512834]\n",
      "[Epoch 38/200] [Batch 60/637] [D loss: 0.169515] [G loss: 0.546374]\n",
      "[Epoch 38/200] [Batch 61/637] [D loss: 0.182773] [G loss: 0.439254]\n",
      "[Epoch 38/200] [Batch 62/637] [D loss: 0.182873] [G loss: 0.565130]\n",
      "[Epoch 38/200] [Batch 63/637] [D loss: 0.151729] [G loss: 0.612751]\n",
      "[Epoch 38/200] [Batch 64/637] [D loss: 0.167584] [G loss: 0.474866]\n",
      "[Epoch 38/200] [Batch 65/637] [D loss: 0.166439] [G loss: 0.446176]\n",
      "[Epoch 38/200] [Batch 66/637] [D loss: 0.170913] [G loss: 0.474908]\n",
      "[Epoch 38/200] [Batch 67/637] [D loss: 0.155409] [G loss: 0.506017]\n",
      "[Epoch 38/200] [Batch 68/637] [D loss: 0.165797] [G loss: 0.543297]\n",
      "[Epoch 38/200] [Batch 69/637] [D loss: 0.166070] [G loss: 0.456585]\n",
      "[Epoch 38/200] [Batch 70/637] [D loss: 0.190309] [G loss: 0.452397]\n",
      "[Epoch 38/200] [Batch 71/637] [D loss: 0.167962] [G loss: 0.550251]\n",
      "[Epoch 38/200] [Batch 72/637] [D loss: 0.168061] [G loss: 0.512703]\n",
      "[Epoch 38/200] [Batch 73/637] [D loss: 0.153850] [G loss: 0.519043]\n",
      "[Epoch 38/200] [Batch 74/637] [D loss: 0.192689] [G loss: 0.427878]\n",
      "[Epoch 38/200] [Batch 75/637] [D loss: 0.145959] [G loss: 0.505704]\n",
      "[Epoch 38/200] [Batch 76/637] [D loss: 0.146128] [G loss: 0.525210]\n",
      "[Epoch 38/200] [Batch 77/637] [D loss: 0.174819] [G loss: 0.473460]\n",
      "[Epoch 38/200] [Batch 78/637] [D loss: 0.163266] [G loss: 0.480408]\n",
      "[Epoch 38/200] [Batch 79/637] [D loss: 0.167550] [G loss: 0.482094]\n",
      "[Epoch 38/200] [Batch 80/637] [D loss: 0.160997] [G loss: 0.549227]\n",
      "[Epoch 38/200] [Batch 81/637] [D loss: 0.200280] [G loss: 0.452780]\n",
      "[Epoch 38/200] [Batch 82/637] [D loss: 0.163203] [G loss: 0.571060]\n",
      "[Epoch 38/200] [Batch 83/637] [D loss: 0.228364] [G loss: 0.407591]\n",
      "[Epoch 38/200] [Batch 84/637] [D loss: 0.189337] [G loss: 0.508145]\n",
      "[Epoch 38/200] [Batch 85/637] [D loss: 0.170892] [G loss: 0.487219]\n",
      "[Epoch 38/200] [Batch 86/637] [D loss: 0.161888] [G loss: 0.433048]\n",
      "[Epoch 38/200] [Batch 87/637] [D loss: 0.171937] [G loss: 0.421132]\n",
      "[Epoch 38/200] [Batch 88/637] [D loss: 0.150420] [G loss: 0.535816]\n",
      "[Epoch 38/200] [Batch 89/637] [D loss: 0.156253] [G loss: 0.552088]\n",
      "[Epoch 38/200] [Batch 90/637] [D loss: 0.157244] [G loss: 0.504317]\n",
      "[Epoch 38/200] [Batch 91/637] [D loss: 0.173178] [G loss: 0.500880]\n",
      "[Epoch 38/200] [Batch 92/637] [D loss: 0.171486] [G loss: 0.410400]\n",
      "[Epoch 38/200] [Batch 93/637] [D loss: 0.139187] [G loss: 0.555972]\n",
      "[Epoch 38/200] [Batch 94/637] [D loss: 0.158354] [G loss: 0.601504]\n",
      "[Epoch 38/200] [Batch 95/637] [D loss: 0.158878] [G loss: 0.579303]\n",
      "[Epoch 38/200] [Batch 96/637] [D loss: 0.190565] [G loss: 0.507795]\n",
      "[Epoch 38/200] [Batch 97/637] [D loss: 0.168263] [G loss: 0.494045]\n",
      "[Epoch 38/200] [Batch 98/637] [D loss: 0.155893] [G loss: 0.521347]\n",
      "[Epoch 38/200] [Batch 99/637] [D loss: 0.165400] [G loss: 0.523320]\n",
      "[Epoch 38/200] [Batch 100/637] [D loss: 0.199606] [G loss: 0.449889]\n",
      "[Epoch 38/200] [Batch 101/637] [D loss: 0.159476] [G loss: 0.528357]\n",
      "[Epoch 38/200] [Batch 102/637] [D loss: 0.197722] [G loss: 0.492166]\n",
      "[Epoch 38/200] [Batch 103/637] [D loss: 0.168581] [G loss: 0.583878]\n",
      "[Epoch 38/200] [Batch 104/637] [D loss: 0.158768] [G loss: 0.533127]\n",
      "[Epoch 38/200] [Batch 105/637] [D loss: 0.165990] [G loss: 0.509404]\n",
      "[Epoch 38/200] [Batch 106/637] [D loss: 0.168951] [G loss: 0.452450]\n",
      "[Epoch 38/200] [Batch 107/637] [D loss: 0.160489] [G loss: 0.462184]\n",
      "[Epoch 38/200] [Batch 108/637] [D loss: 0.165109] [G loss: 0.412430]\n",
      "[Epoch 38/200] [Batch 109/637] [D loss: 0.160932] [G loss: 0.498304]\n",
      "[Epoch 38/200] [Batch 110/637] [D loss: 0.167835] [G loss: 0.532723]\n",
      "[Epoch 38/200] [Batch 111/637] [D loss: 0.172934] [G loss: 0.470048]\n",
      "[Epoch 38/200] [Batch 112/637] [D loss: 0.165738] [G loss: 0.468581]\n",
      "[Epoch 38/200] [Batch 113/637] [D loss: 0.167741] [G loss: 0.501926]\n",
      "[Epoch 38/200] [Batch 114/637] [D loss: 0.145010] [G loss: 0.531909]\n",
      "[Epoch 38/200] [Batch 115/637] [D loss: 0.168150] [G loss: 0.446613]\n",
      "[Epoch 38/200] [Batch 116/637] [D loss: 0.138960] [G loss: 0.541767]\n",
      "[Epoch 38/200] [Batch 117/637] [D loss: 0.155088] [G loss: 0.550085]\n",
      "[Epoch 38/200] [Batch 118/637] [D loss: 0.166083] [G loss: 0.525814]\n",
      "[Epoch 38/200] [Batch 119/637] [D loss: 0.157560] [G loss: 0.520564]\n",
      "[Epoch 38/200] [Batch 120/637] [D loss: 0.155764] [G loss: 0.553084]\n",
      "[Epoch 38/200] [Batch 121/637] [D loss: 0.155478] [G loss: 0.516012]\n",
      "[Epoch 38/200] [Batch 122/637] [D loss: 0.202725] [G loss: 0.506163]\n",
      "[Epoch 38/200] [Batch 123/637] [D loss: 0.166088] [G loss: 0.515147]\n",
      "[Epoch 38/200] [Batch 124/637] [D loss: 0.183656] [G loss: 0.479118]\n",
      "[Epoch 38/200] [Batch 125/637] [D loss: 0.166516] [G loss: 0.509602]\n",
      "[Epoch 38/200] [Batch 126/637] [D loss: 0.171637] [G loss: 0.454978]\n",
      "[Epoch 38/200] [Batch 127/637] [D loss: 0.157546] [G loss: 0.511088]\n",
      "[Epoch 38/200] [Batch 128/637] [D loss: 0.157602] [G loss: 0.501042]\n",
      "[Epoch 38/200] [Batch 129/637] [D loss: 0.167775] [G loss: 0.499173]\n",
      "[Epoch 38/200] [Batch 130/637] [D loss: 0.172356] [G loss: 0.515260]\n",
      "[Epoch 38/200] [Batch 131/637] [D loss: 0.148115] [G loss: 0.473349]\n",
      "[Epoch 38/200] [Batch 132/637] [D loss: 0.153104] [G loss: 0.556108]\n",
      "[Epoch 38/200] [Batch 133/637] [D loss: 0.183236] [G loss: 0.536072]\n",
      "[Epoch 38/200] [Batch 134/637] [D loss: 0.158666] [G loss: 0.551504]\n",
      "[Epoch 38/200] [Batch 135/637] [D loss: 0.177132] [G loss: 0.527877]\n",
      "[Epoch 38/200] [Batch 136/637] [D loss: 0.149683] [G loss: 0.537224]\n",
      "[Epoch 38/200] [Batch 137/637] [D loss: 0.165125] [G loss: 0.502569]\n",
      "[Epoch 38/200] [Batch 138/637] [D loss: 0.167431] [G loss: 0.485759]\n",
      "[Epoch 38/200] [Batch 139/637] [D loss: 0.184028] [G loss: 0.579507]\n",
      "[Epoch 38/200] [Batch 140/637] [D loss: 0.198473] [G loss: 0.489998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/200] [Batch 141/637] [D loss: 0.156213] [G loss: 0.638673]\n",
      "[Epoch 38/200] [Batch 142/637] [D loss: 0.203316] [G loss: 0.498210]\n",
      "[Epoch 38/200] [Batch 143/637] [D loss: 0.170523] [G loss: 0.463264]\n",
      "[Epoch 38/200] [Batch 144/637] [D loss: 0.178548] [G loss: 0.405310]\n",
      "[Epoch 38/200] [Batch 145/637] [D loss: 0.170344] [G loss: 0.459976]\n",
      "[Epoch 38/200] [Batch 146/637] [D loss: 0.170122] [G loss: 0.487972]\n",
      "[Epoch 38/200] [Batch 147/637] [D loss: 0.190881] [G loss: 0.504462]\n",
      "[Epoch 38/200] [Batch 148/637] [D loss: 0.170806] [G loss: 0.488571]\n",
      "[Epoch 38/200] [Batch 149/637] [D loss: 0.187558] [G loss: 0.430944]\n",
      "[Epoch 38/200] [Batch 150/637] [D loss: 0.177650] [G loss: 0.422922]\n",
      "[Epoch 38/200] [Batch 151/637] [D loss: 0.165701] [G loss: 0.469309]\n",
      "[Epoch 38/200] [Batch 152/637] [D loss: 0.170842] [G loss: 0.518084]\n",
      "[Epoch 38/200] [Batch 153/637] [D loss: 0.149979] [G loss: 0.577524]\n",
      "[Epoch 38/200] [Batch 154/637] [D loss: 0.175381] [G loss: 0.485213]\n",
      "[Epoch 38/200] [Batch 155/637] [D loss: 0.152514] [G loss: 0.509224]\n",
      "[Epoch 38/200] [Batch 156/637] [D loss: 0.185597] [G loss: 0.451909]\n",
      "[Epoch 38/200] [Batch 157/637] [D loss: 0.222020] [G loss: 0.414399]\n",
      "[Epoch 38/200] [Batch 158/637] [D loss: 0.194363] [G loss: 0.444178]\n",
      "[Epoch 38/200] [Batch 159/637] [D loss: 0.172317] [G loss: 0.467716]\n",
      "[Epoch 38/200] [Batch 160/637] [D loss: 0.173939] [G loss: 0.436767]\n",
      "[Epoch 38/200] [Batch 161/637] [D loss: 0.169112] [G loss: 0.536372]\n",
      "[Epoch 38/200] [Batch 162/637] [D loss: 0.150367] [G loss: 0.500869]\n",
      "[Epoch 38/200] [Batch 163/637] [D loss: 0.155801] [G loss: 0.517252]\n",
      "[Epoch 38/200] [Batch 164/637] [D loss: 0.147118] [G loss: 0.552310]\n",
      "[Epoch 38/200] [Batch 165/637] [D loss: 0.165987] [G loss: 0.522600]\n",
      "[Epoch 38/200] [Batch 166/637] [D loss: 0.202506] [G loss: 0.469255]\n",
      "[Epoch 38/200] [Batch 167/637] [D loss: 0.171456] [G loss: 0.560141]\n",
      "[Epoch 38/200] [Batch 168/637] [D loss: 0.179150] [G loss: 0.480292]\n",
      "[Epoch 38/200] [Batch 169/637] [D loss: 0.145078] [G loss: 0.532538]\n",
      "[Epoch 38/200] [Batch 170/637] [D loss: 0.192595] [G loss: 0.478009]\n",
      "[Epoch 38/200] [Batch 171/637] [D loss: 0.160595] [G loss: 0.540126]\n",
      "[Epoch 38/200] [Batch 172/637] [D loss: 0.192007] [G loss: 0.435685]\n",
      "[Epoch 38/200] [Batch 173/637] [D loss: 0.143743] [G loss: 0.569440]\n",
      "[Epoch 38/200] [Batch 174/637] [D loss: 0.167641] [G loss: 0.477598]\n",
      "[Epoch 38/200] [Batch 175/637] [D loss: 0.167268] [G loss: 0.558980]\n",
      "[Epoch 38/200] [Batch 176/637] [D loss: 0.175100] [G loss: 0.501787]\n",
      "[Epoch 38/200] [Batch 177/637] [D loss: 0.173588] [G loss: 0.536770]\n",
      "[Epoch 38/200] [Batch 178/637] [D loss: 0.156132] [G loss: 0.556200]\n",
      "[Epoch 38/200] [Batch 179/637] [D loss: 0.173470] [G loss: 0.524406]\n",
      "[Epoch 38/200] [Batch 180/637] [D loss: 0.198673] [G loss: 0.543898]\n",
      "[Epoch 38/200] [Batch 181/637] [D loss: 0.169226] [G loss: 0.477191]\n",
      "[Epoch 38/200] [Batch 182/637] [D loss: 0.182566] [G loss: 0.521347]\n",
      "[Epoch 38/200] [Batch 183/637] [D loss: 0.172360] [G loss: 0.503795]\n",
      "[Epoch 38/200] [Batch 184/637] [D loss: 0.170782] [G loss: 0.575224]\n",
      "[Epoch 38/200] [Batch 185/637] [D loss: 0.152529] [G loss: 0.520094]\n",
      "[Epoch 38/200] [Batch 186/637] [D loss: 0.154865] [G loss: 0.475313]\n",
      "[Epoch 38/200] [Batch 187/637] [D loss: 0.175717] [G loss: 0.509197]\n",
      "[Epoch 38/200] [Batch 188/637] [D loss: 0.165751] [G loss: 0.495878]\n",
      "[Epoch 38/200] [Batch 189/637] [D loss: 0.177203] [G loss: 0.513551]\n",
      "[Epoch 38/200] [Batch 190/637] [D loss: 0.157272] [G loss: 0.492235]\n",
      "[Epoch 38/200] [Batch 191/637] [D loss: 0.193315] [G loss: 0.481319]\n",
      "[Epoch 38/200] [Batch 192/637] [D loss: 0.166817] [G loss: 0.580595]\n",
      "[Epoch 38/200] [Batch 193/637] [D loss: 0.165456] [G loss: 0.551018]\n",
      "[Epoch 38/200] [Batch 194/637] [D loss: 0.204970] [G loss: 0.460129]\n",
      "[Epoch 38/200] [Batch 195/637] [D loss: 0.197137] [G loss: 0.481257]\n",
      "[Epoch 38/200] [Batch 196/637] [D loss: 0.188184] [G loss: 0.463832]\n",
      "[Epoch 38/200] [Batch 197/637] [D loss: 0.178312] [G loss: 0.472044]\n",
      "[Epoch 38/200] [Batch 198/637] [D loss: 0.181168] [G loss: 0.439991]\n",
      "[Epoch 38/200] [Batch 199/637] [D loss: 0.163103] [G loss: 0.552432]\n",
      "[Epoch 38/200] [Batch 200/637] [D loss: 0.177131] [G loss: 0.476917]\n",
      "[Epoch 38/200] [Batch 201/637] [D loss: 0.154747] [G loss: 0.485490]\n",
      "[Epoch 38/200] [Batch 202/637] [D loss: 0.168206] [G loss: 0.538923]\n",
      "[Epoch 38/200] [Batch 203/637] [D loss: 0.134428] [G loss: 0.610223]\n",
      "[Epoch 38/200] [Batch 204/637] [D loss: 0.145249] [G loss: 0.521913]\n",
      "[Epoch 38/200] [Batch 205/637] [D loss: 0.135042] [G loss: 0.568860]\n",
      "[Epoch 38/200] [Batch 206/637] [D loss: 0.165328] [G loss: 0.450146]\n",
      "[Epoch 38/200] [Batch 207/637] [D loss: 0.165175] [G loss: 0.472729]\n",
      "[Epoch 38/200] [Batch 208/637] [D loss: 0.160294] [G loss: 0.469325]\n",
      "[Epoch 38/200] [Batch 209/637] [D loss: 0.161194] [G loss: 0.470830]\n",
      "[Epoch 38/200] [Batch 210/637] [D loss: 0.171432] [G loss: 0.478419]\n",
      "[Epoch 38/200] [Batch 211/637] [D loss: 0.191552] [G loss: 0.412104]\n",
      "[Epoch 38/200] [Batch 212/637] [D loss: 0.160009] [G loss: 0.448450]\n",
      "[Epoch 38/200] [Batch 213/637] [D loss: 0.165164] [G loss: 0.529230]\n",
      "[Epoch 38/200] [Batch 214/637] [D loss: 0.179883] [G loss: 0.474089]\n",
      "[Epoch 38/200] [Batch 215/637] [D loss: 0.152032] [G loss: 0.536680]\n",
      "[Epoch 38/200] [Batch 216/637] [D loss: 0.185447] [G loss: 0.419220]\n",
      "[Epoch 38/200] [Batch 217/637] [D loss: 0.149484] [G loss: 0.606693]\n",
      "[Epoch 38/200] [Batch 218/637] [D loss: 0.156309] [G loss: 0.528874]\n",
      "[Epoch 38/200] [Batch 219/637] [D loss: 0.196178] [G loss: 0.452355]\n",
      "[Epoch 38/200] [Batch 220/637] [D loss: 0.171414] [G loss: 0.476255]\n",
      "[Epoch 38/200] [Batch 221/637] [D loss: 0.162240] [G loss: 0.537221]\n",
      "[Epoch 38/200] [Batch 222/637] [D loss: 0.193662] [G loss: 0.455895]\n",
      "[Epoch 38/200] [Batch 223/637] [D loss: 0.164686] [G loss: 0.480661]\n",
      "[Epoch 38/200] [Batch 224/637] [D loss: 0.185473] [G loss: 0.473077]\n",
      "[Epoch 38/200] [Batch 225/637] [D loss: 0.183683] [G loss: 0.444277]\n",
      "[Epoch 38/200] [Batch 226/637] [D loss: 0.183060] [G loss: 0.442944]\n",
      "[Epoch 38/200] [Batch 227/637] [D loss: 0.160129] [G loss: 0.514457]\n",
      "[Epoch 38/200] [Batch 228/637] [D loss: 0.166982] [G loss: 0.472603]\n",
      "[Epoch 38/200] [Batch 229/637] [D loss: 0.156773] [G loss: 0.496207]\n",
      "[Epoch 38/200] [Batch 230/637] [D loss: 0.181158] [G loss: 0.460795]\n",
      "[Epoch 38/200] [Batch 231/637] [D loss: 0.167450] [G loss: 0.528731]\n",
      "[Epoch 38/200] [Batch 232/637] [D loss: 0.193784] [G loss: 0.454472]\n",
      "[Epoch 38/200] [Batch 233/637] [D loss: 0.167122] [G loss: 0.510103]\n",
      "[Epoch 38/200] [Batch 234/637] [D loss: 0.151401] [G loss: 0.574043]\n",
      "[Epoch 38/200] [Batch 235/637] [D loss: 0.161256] [G loss: 0.506074]\n",
      "[Epoch 38/200] [Batch 236/637] [D loss: 0.144111] [G loss: 0.524301]\n",
      "[Epoch 38/200] [Batch 237/637] [D loss: 0.195997] [G loss: 0.403219]\n",
      "[Epoch 38/200] [Batch 238/637] [D loss: 0.193066] [G loss: 0.554204]\n",
      "[Epoch 38/200] [Batch 239/637] [D loss: 0.174414] [G loss: 0.524953]\n",
      "[Epoch 38/200] [Batch 240/637] [D loss: 0.167552] [G loss: 0.527259]\n",
      "[Epoch 38/200] [Batch 241/637] [D loss: 0.179252] [G loss: 0.531311]\n",
      "[Epoch 38/200] [Batch 242/637] [D loss: 0.155350] [G loss: 0.511053]\n",
      "[Epoch 38/200] [Batch 243/637] [D loss: 0.166616] [G loss: 0.482951]\n",
      "[Epoch 38/200] [Batch 244/637] [D loss: 0.183836] [G loss: 0.494096]\n",
      "[Epoch 38/200] [Batch 245/637] [D loss: 0.180776] [G loss: 0.571960]\n",
      "[Epoch 38/200] [Batch 246/637] [D loss: 0.181276] [G loss: 0.579930]\n",
      "[Epoch 38/200] [Batch 247/637] [D loss: 0.170708] [G loss: 0.517607]\n",
      "[Epoch 38/200] [Batch 248/637] [D loss: 0.160832] [G loss: 0.540227]\n",
      "[Epoch 38/200] [Batch 249/637] [D loss: 0.207311] [G loss: 0.430006]\n",
      "[Epoch 38/200] [Batch 250/637] [D loss: 0.189994] [G loss: 0.511065]\n",
      "[Epoch 38/200] [Batch 251/637] [D loss: 0.164087] [G loss: 0.549401]\n",
      "[Epoch 38/200] [Batch 252/637] [D loss: 0.168943] [G loss: 0.470207]\n",
      "[Epoch 38/200] [Batch 253/637] [D loss: 0.170997] [G loss: 0.483654]\n",
      "[Epoch 38/200] [Batch 254/637] [D loss: 0.173154] [G loss: 0.540360]\n",
      "[Epoch 38/200] [Batch 255/637] [D loss: 0.147045] [G loss: 0.577850]\n",
      "[Epoch 38/200] [Batch 256/637] [D loss: 0.175509] [G loss: 0.480187]\n",
      "[Epoch 38/200] [Batch 257/637] [D loss: 0.180580] [G loss: 0.426363]\n",
      "[Epoch 38/200] [Batch 258/637] [D loss: 0.170120] [G loss: 0.474772]\n",
      "[Epoch 38/200] [Batch 259/637] [D loss: 0.193264] [G loss: 0.527553]\n",
      "[Epoch 38/200] [Batch 260/637] [D loss: 0.164784] [G loss: 0.559287]\n",
      "[Epoch 38/200] [Batch 261/637] [D loss: 0.161872] [G loss: 0.531991]\n",
      "[Epoch 38/200] [Batch 262/637] [D loss: 0.174436] [G loss: 0.420487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/200] [Batch 263/637] [D loss: 0.166634] [G loss: 0.536368]\n",
      "[Epoch 38/200] [Batch 264/637] [D loss: 0.163884] [G loss: 0.573562]\n",
      "[Epoch 38/200] [Batch 265/637] [D loss: 0.184905] [G loss: 0.435896]\n",
      "[Epoch 38/200] [Batch 266/637] [D loss: 0.201173] [G loss: 0.436715]\n",
      "[Epoch 38/200] [Batch 267/637] [D loss: 0.154444] [G loss: 0.556216]\n",
      "[Epoch 38/200] [Batch 268/637] [D loss: 0.172244] [G loss: 0.539559]\n",
      "[Epoch 38/200] [Batch 269/637] [D loss: 0.158639] [G loss: 0.459007]\n",
      "[Epoch 38/200] [Batch 270/637] [D loss: 0.163313] [G loss: 0.464349]\n",
      "[Epoch 38/200] [Batch 271/637] [D loss: 0.166875] [G loss: 0.508336]\n",
      "[Epoch 38/200] [Batch 272/637] [D loss: 0.145947] [G loss: 0.507177]\n",
      "[Epoch 38/200] [Batch 273/637] [D loss: 0.172164] [G loss: 0.487366]\n",
      "[Epoch 38/200] [Batch 274/637] [D loss: 0.167451] [G loss: 0.476288]\n",
      "[Epoch 38/200] [Batch 275/637] [D loss: 0.147943] [G loss: 0.513386]\n",
      "[Epoch 38/200] [Batch 276/637] [D loss: 0.141645] [G loss: 0.505708]\n",
      "[Epoch 38/200] [Batch 277/637] [D loss: 0.162338] [G loss: 0.521874]\n",
      "[Epoch 38/200] [Batch 278/637] [D loss: 0.190188] [G loss: 0.436284]\n",
      "[Epoch 38/200] [Batch 279/637] [D loss: 0.160596] [G loss: 0.532742]\n",
      "[Epoch 38/200] [Batch 280/637] [D loss: 0.140030] [G loss: 0.521777]\n",
      "[Epoch 38/200] [Batch 281/637] [D loss: 0.175324] [G loss: 0.511313]\n",
      "[Epoch 38/200] [Batch 282/637] [D loss: 0.175757] [G loss: 0.543239]\n",
      "[Epoch 38/200] [Batch 283/637] [D loss: 0.199491] [G loss: 0.522669]\n",
      "[Epoch 38/200] [Batch 284/637] [D loss: 0.172914] [G loss: 0.489607]\n",
      "[Epoch 38/200] [Batch 285/637] [D loss: 0.153636] [G loss: 0.514326]\n",
      "[Epoch 38/200] [Batch 286/637] [D loss: 0.151483] [G loss: 0.476968]\n",
      "[Epoch 38/200] [Batch 287/637] [D loss: 0.167175] [G loss: 0.515926]\n",
      "[Epoch 38/200] [Batch 288/637] [D loss: 0.187514] [G loss: 0.556306]\n",
      "[Epoch 38/200] [Batch 289/637] [D loss: 0.171239] [G loss: 0.529165]\n",
      "[Epoch 38/200] [Batch 290/637] [D loss: 0.160789] [G loss: 0.445535]\n",
      "[Epoch 38/200] [Batch 291/637] [D loss: 0.164675] [G loss: 0.454948]\n",
      "[Epoch 38/200] [Batch 292/637] [D loss: 0.160553] [G loss: 0.520682]\n",
      "[Epoch 38/200] [Batch 293/637] [D loss: 0.176377] [G loss: 0.500004]\n",
      "[Epoch 38/200] [Batch 294/637] [D loss: 0.167428] [G loss: 0.539366]\n",
      "[Epoch 38/200] [Batch 295/637] [D loss: 0.197155] [G loss: 0.538618]\n",
      "[Epoch 38/200] [Batch 296/637] [D loss: 0.177263] [G loss: 0.484999]\n",
      "[Epoch 38/200] [Batch 297/637] [D loss: 0.173212] [G loss: 0.433998]\n",
      "[Epoch 38/200] [Batch 298/637] [D loss: 0.186012] [G loss: 0.484197]\n",
      "[Epoch 38/200] [Batch 299/637] [D loss: 0.189865] [G loss: 0.495317]\n",
      "[Epoch 38/200] [Batch 300/637] [D loss: 0.193720] [G loss: 0.487637]\n",
      "[Epoch 38/200] [Batch 301/637] [D loss: 0.176458] [G loss: 0.510309]\n",
      "[Epoch 38/200] [Batch 302/637] [D loss: 0.165936] [G loss: 0.495660]\n",
      "[Epoch 38/200] [Batch 303/637] [D loss: 0.168906] [G loss: 0.506196]\n",
      "[Epoch 38/200] [Batch 304/637] [D loss: 0.175769] [G loss: 0.553161]\n",
      "[Epoch 38/200] [Batch 305/637] [D loss: 0.171976] [G loss: 0.553576]\n",
      "[Epoch 38/200] [Batch 306/637] [D loss: 0.178674] [G loss: 0.500080]\n",
      "[Epoch 38/200] [Batch 307/637] [D loss: 0.161669] [G loss: 0.559438]\n",
      "[Epoch 38/200] [Batch 308/637] [D loss: 0.167108] [G loss: 0.513948]\n",
      "[Epoch 38/200] [Batch 309/637] [D loss: 0.173301] [G loss: 0.482020]\n",
      "[Epoch 38/200] [Batch 310/637] [D loss: 0.160873] [G loss: 0.528807]\n",
      "[Epoch 38/200] [Batch 311/637] [D loss: 0.160163] [G loss: 0.564626]\n",
      "[Epoch 38/200] [Batch 312/637] [D loss: 0.164107] [G loss: 0.530512]\n",
      "[Epoch 38/200] [Batch 313/637] [D loss: 0.153057] [G loss: 0.558684]\n",
      "[Epoch 38/200] [Batch 314/637] [D loss: 0.175988] [G loss: 0.540800]\n",
      "[Epoch 38/200] [Batch 315/637] [D loss: 0.155315] [G loss: 0.544400]\n",
      "[Epoch 38/200] [Batch 316/637] [D loss: 0.169930] [G loss: 0.480178]\n",
      "[Epoch 38/200] [Batch 317/637] [D loss: 0.199891] [G loss: 0.442160]\n",
      "[Epoch 38/200] [Batch 318/637] [D loss: 0.183955] [G loss: 0.581877]\n",
      "[Epoch 38/200] [Batch 319/637] [D loss: 0.227897] [G loss: 0.469670]\n",
      "[Epoch 38/200] [Batch 320/637] [D loss: 0.198806] [G loss: 0.459046]\n",
      "[Epoch 38/200] [Batch 321/637] [D loss: 0.178781] [G loss: 0.435873]\n",
      "[Epoch 38/200] [Batch 322/637] [D loss: 0.179897] [G loss: 0.445782]\n",
      "[Epoch 38/200] [Batch 323/637] [D loss: 0.179762] [G loss: 0.468557]\n",
      "[Epoch 38/200] [Batch 324/637] [D loss: 0.165362] [G loss: 0.489056]\n",
      "[Epoch 38/200] [Batch 325/637] [D loss: 0.185888] [G loss: 0.470973]\n",
      "[Epoch 38/200] [Batch 326/637] [D loss: 0.154580] [G loss: 0.520432]\n",
      "[Epoch 38/200] [Batch 327/637] [D loss: 0.162119] [G loss: 0.425428]\n",
      "[Epoch 38/200] [Batch 328/637] [D loss: 0.151021] [G loss: 0.500867]\n",
      "[Epoch 38/200] [Batch 329/637] [D loss: 0.155371] [G loss: 0.535312]\n",
      "[Epoch 38/200] [Batch 330/637] [D loss: 0.154690] [G loss: 0.541709]\n",
      "[Epoch 38/200] [Batch 331/637] [D loss: 0.154856] [G loss: 0.512925]\n",
      "[Epoch 38/200] [Batch 332/637] [D loss: 0.178325] [G loss: 0.471338]\n",
      "[Epoch 38/200] [Batch 333/637] [D loss: 0.142570] [G loss: 0.553691]\n",
      "[Epoch 38/200] [Batch 334/637] [D loss: 0.185898] [G loss: 0.498372]\n",
      "[Epoch 38/200] [Batch 335/637] [D loss: 0.157647] [G loss: 0.582693]\n",
      "[Epoch 38/200] [Batch 336/637] [D loss: 0.160795] [G loss: 0.477644]\n",
      "[Epoch 38/200] [Batch 337/637] [D loss: 0.166290] [G loss: 0.478144]\n",
      "[Epoch 38/200] [Batch 338/637] [D loss: 0.163213] [G loss: 0.508496]\n",
      "[Epoch 38/200] [Batch 339/637] [D loss: 0.147038] [G loss: 0.517711]\n",
      "[Epoch 38/200] [Batch 340/637] [D loss: 0.165611] [G loss: 0.480062]\n",
      "[Epoch 38/200] [Batch 341/637] [D loss: 0.161444] [G loss: 0.545459]\n",
      "[Epoch 38/200] [Batch 342/637] [D loss: 0.176135] [G loss: 0.459590]\n",
      "[Epoch 38/200] [Batch 343/637] [D loss: 0.168160] [G loss: 0.587144]\n",
      "[Epoch 38/200] [Batch 344/637] [D loss: 0.152714] [G loss: 0.595096]\n",
      "[Epoch 38/200] [Batch 345/637] [D loss: 0.170693] [G loss: 0.537139]\n",
      "[Epoch 38/200] [Batch 346/637] [D loss: 0.176004] [G loss: 0.467231]\n",
      "[Epoch 38/200] [Batch 347/637] [D loss: 0.181335] [G loss: 0.471736]\n",
      "[Epoch 38/200] [Batch 348/637] [D loss: 0.172459] [G loss: 0.440368]\n",
      "[Epoch 38/200] [Batch 349/637] [D loss: 0.176575] [G loss: 0.440143]\n",
      "[Epoch 38/200] [Batch 350/637] [D loss: 0.167305] [G loss: 0.460849]\n",
      "[Epoch 38/200] [Batch 351/637] [D loss: 0.179898] [G loss: 0.477771]\n",
      "[Epoch 38/200] [Batch 352/637] [D loss: 0.184753] [G loss: 0.520483]\n",
      "[Epoch 38/200] [Batch 353/637] [D loss: 0.211962] [G loss: 0.453562]\n",
      "[Epoch 38/200] [Batch 354/637] [D loss: 0.165032] [G loss: 0.477403]\n",
      "[Epoch 38/200] [Batch 355/637] [D loss: 0.168786] [G loss: 0.455333]\n",
      "[Epoch 38/200] [Batch 356/637] [D loss: 0.157856] [G loss: 0.463820]\n",
      "[Epoch 38/200] [Batch 357/637] [D loss: 0.149144] [G loss: 0.475565]\n",
      "[Epoch 38/200] [Batch 358/637] [D loss: 0.181943] [G loss: 0.474305]\n",
      "[Epoch 38/200] [Batch 359/637] [D loss: 0.180070] [G loss: 0.438924]\n",
      "[Epoch 38/200] [Batch 360/637] [D loss: 0.186333] [G loss: 0.444131]\n",
      "[Epoch 38/200] [Batch 361/637] [D loss: 0.153861] [G loss: 0.533957]\n",
      "[Epoch 38/200] [Batch 362/637] [D loss: 0.178565] [G loss: 0.434739]\n",
      "[Epoch 38/200] [Batch 363/637] [D loss: 0.178039] [G loss: 0.473764]\n",
      "[Epoch 38/200] [Batch 364/637] [D loss: 0.204811] [G loss: 0.485105]\n",
      "[Epoch 38/200] [Batch 365/637] [D loss: 0.174573] [G loss: 0.520792]\n",
      "[Epoch 38/200] [Batch 366/637] [D loss: 0.178092] [G loss: 0.557042]\n",
      "[Epoch 38/200] [Batch 367/637] [D loss: 0.140167] [G loss: 0.551325]\n",
      "[Epoch 38/200] [Batch 368/637] [D loss: 0.183516] [G loss: 0.428542]\n",
      "[Epoch 38/200] [Batch 369/637] [D loss: 0.189711] [G loss: 0.381991]\n",
      "[Epoch 38/200] [Batch 370/637] [D loss: 0.165628] [G loss: 0.443082]\n",
      "[Epoch 38/200] [Batch 371/637] [D loss: 0.168484] [G loss: 0.497934]\n",
      "[Epoch 38/200] [Batch 372/637] [D loss: 0.182963] [G loss: 0.475746]\n",
      "[Epoch 38/200] [Batch 373/637] [D loss: 0.167776] [G loss: 0.475675]\n",
      "[Epoch 38/200] [Batch 374/637] [D loss: 0.164335] [G loss: 0.474621]\n",
      "[Epoch 38/200] [Batch 375/637] [D loss: 0.151229] [G loss: 0.602261]\n",
      "[Epoch 38/200] [Batch 376/637] [D loss: 0.190763] [G loss: 0.523248]\n",
      "[Epoch 38/200] [Batch 377/637] [D loss: 0.169584] [G loss: 0.493896]\n",
      "[Epoch 38/200] [Batch 378/637] [D loss: 0.162141] [G loss: 0.491466]\n",
      "[Epoch 38/200] [Batch 379/637] [D loss: 0.160325] [G loss: 0.510866]\n",
      "[Epoch 38/200] [Batch 380/637] [D loss: 0.172984] [G loss: 0.606886]\n",
      "[Epoch 38/200] [Batch 381/637] [D loss: 0.172621] [G loss: 0.493001]\n",
      "[Epoch 38/200] [Batch 382/637] [D loss: 0.192826] [G loss: 0.474209]\n",
      "[Epoch 38/200] [Batch 383/637] [D loss: 0.174251] [G loss: 0.457883]\n",
      "[Epoch 38/200] [Batch 384/637] [D loss: 0.166941] [G loss: 0.481554]\n",
      "[Epoch 38/200] [Batch 385/637] [D loss: 0.166605] [G loss: 0.491866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/200] [Batch 386/637] [D loss: 0.159937] [G loss: 0.554147]\n",
      "[Epoch 38/200] [Batch 387/637] [D loss: 0.177398] [G loss: 0.503180]\n",
      "[Epoch 38/200] [Batch 388/637] [D loss: 0.171705] [G loss: 0.444803]\n",
      "[Epoch 38/200] [Batch 389/637] [D loss: 0.183060] [G loss: 0.442477]\n",
      "[Epoch 38/200] [Batch 390/637] [D loss: 0.142986] [G loss: 0.563343]\n",
      "[Epoch 38/200] [Batch 391/637] [D loss: 0.170991] [G loss: 0.487500]\n",
      "[Epoch 38/200] [Batch 392/637] [D loss: 0.180493] [G loss: 0.503073]\n",
      "[Epoch 38/200] [Batch 393/637] [D loss: 0.184303] [G loss: 0.506110]\n",
      "[Epoch 38/200] [Batch 394/637] [D loss: 0.169551] [G loss: 0.464101]\n",
      "[Epoch 38/200] [Batch 395/637] [D loss: 0.155413] [G loss: 0.518763]\n",
      "[Epoch 38/200] [Batch 396/637] [D loss: 0.164056] [G loss: 0.410009]\n",
      "[Epoch 38/200] [Batch 397/637] [D loss: 0.180405] [G loss: 0.475049]\n",
      "[Epoch 38/200] [Batch 398/637] [D loss: 0.140079] [G loss: 0.567452]\n",
      "[Epoch 38/200] [Batch 399/637] [D loss: 0.158938] [G loss: 0.492899]\n",
      "[Epoch 38/200] [Batch 400/637] [D loss: 0.169806] [G loss: 0.497331]\n",
      "[Epoch 38/200] [Batch 401/637] [D loss: 0.161582] [G loss: 0.562765]\n",
      "[Epoch 38/200] [Batch 402/637] [D loss: 0.153769] [G loss: 0.562762]\n",
      "[Epoch 38/200] [Batch 403/637] [D loss: 0.168773] [G loss: 0.576216]\n",
      "[Epoch 38/200] [Batch 404/637] [D loss: 0.168984] [G loss: 0.500376]\n",
      "[Epoch 38/200] [Batch 405/637] [D loss: 0.165667] [G loss: 0.520002]\n",
      "[Epoch 38/200] [Batch 406/637] [D loss: 0.180292] [G loss: 0.466527]\n",
      "[Epoch 38/200] [Batch 407/637] [D loss: 0.155189] [G loss: 0.438733]\n",
      "[Epoch 38/200] [Batch 408/637] [D loss: 0.225205] [G loss: 0.386852]\n",
      "[Epoch 38/200] [Batch 409/637] [D loss: 0.174446] [G loss: 0.575182]\n",
      "[Epoch 38/200] [Batch 410/637] [D loss: 0.193096] [G loss: 0.571256]\n",
      "[Epoch 38/200] [Batch 411/637] [D loss: 0.172323] [G loss: 0.471679]\n",
      "[Epoch 38/200] [Batch 412/637] [D loss: 0.175133] [G loss: 0.464440]\n",
      "[Epoch 38/200] [Batch 413/637] [D loss: 0.176664] [G loss: 0.485291]\n",
      "[Epoch 38/200] [Batch 414/637] [D loss: 0.190152] [G loss: 0.415656]\n",
      "[Epoch 38/200] [Batch 415/637] [D loss: 0.185405] [G loss: 0.512317]\n",
      "[Epoch 38/200] [Batch 416/637] [D loss: 0.180487] [G loss: 0.466498]\n",
      "[Epoch 38/200] [Batch 417/637] [D loss: 0.177557] [G loss: 0.475357]\n",
      "[Epoch 38/200] [Batch 418/637] [D loss: 0.181574] [G loss: 0.450934]\n",
      "[Epoch 38/200] [Batch 419/637] [D loss: 0.166709] [G loss: 0.488548]\n",
      "[Epoch 38/200] [Batch 420/637] [D loss: 0.184208] [G loss: 0.490597]\n",
      "[Epoch 38/200] [Batch 421/637] [D loss: 0.191161] [G loss: 0.431143]\n",
      "[Epoch 38/200] [Batch 422/637] [D loss: 0.171658] [G loss: 0.444427]\n",
      "[Epoch 38/200] [Batch 423/637] [D loss: 0.174771] [G loss: 0.500414]\n",
      "[Epoch 38/200] [Batch 424/637] [D loss: 0.169031] [G loss: 0.484961]\n",
      "[Epoch 38/200] [Batch 425/637] [D loss: 0.182348] [G loss: 0.512839]\n",
      "[Epoch 38/200] [Batch 426/637] [D loss: 0.173360] [G loss: 0.599465]\n",
      "[Epoch 38/200] [Batch 427/637] [D loss: 0.170860] [G loss: 0.429990]\n",
      "[Epoch 38/200] [Batch 428/637] [D loss: 0.184614] [G loss: 0.447185]\n",
      "[Epoch 38/200] [Batch 429/637] [D loss: 0.159725] [G loss: 0.572245]\n",
      "[Epoch 38/200] [Batch 430/637] [D loss: 0.175176] [G loss: 0.522514]\n",
      "[Epoch 38/200] [Batch 431/637] [D loss: 0.181749] [G loss: 0.470777]\n",
      "[Epoch 38/200] [Batch 432/637] [D loss: 0.175340] [G loss: 0.433954]\n",
      "[Epoch 38/200] [Batch 433/637] [D loss: 0.160022] [G loss: 0.464336]\n",
      "[Epoch 38/200] [Batch 434/637] [D loss: 0.177302] [G loss: 0.476099]\n",
      "[Epoch 38/200] [Batch 435/637] [D loss: 0.164403] [G loss: 0.474818]\n",
      "[Epoch 38/200] [Batch 436/637] [D loss: 0.184569] [G loss: 0.461639]\n",
      "[Epoch 38/200] [Batch 437/637] [D loss: 0.173263] [G loss: 0.501754]\n",
      "[Epoch 38/200] [Batch 438/637] [D loss: 0.165390] [G loss: 0.557994]\n",
      "[Epoch 38/200] [Batch 439/637] [D loss: 0.165259] [G loss: 0.501945]\n",
      "[Epoch 38/200] [Batch 440/637] [D loss: 0.203944] [G loss: 0.394157]\n",
      "[Epoch 38/200] [Batch 441/637] [D loss: 0.165537] [G loss: 0.505780]\n",
      "[Epoch 38/200] [Batch 442/637] [D loss: 0.161812] [G loss: 0.544630]\n",
      "[Epoch 38/200] [Batch 443/637] [D loss: 0.160911] [G loss: 0.482006]\n",
      "[Epoch 38/200] [Batch 444/637] [D loss: 0.166805] [G loss: 0.515544]\n",
      "[Epoch 38/200] [Batch 445/637] [D loss: 0.194159] [G loss: 0.426484]\n",
      "[Epoch 38/200] [Batch 446/637] [D loss: 0.166518] [G loss: 0.490750]\n",
      "[Epoch 38/200] [Batch 447/637] [D loss: 0.146227] [G loss: 0.546326]\n",
      "[Epoch 38/200] [Batch 448/637] [D loss: 0.180674] [G loss: 0.527957]\n",
      "[Epoch 38/200] [Batch 449/637] [D loss: 0.168773] [G loss: 0.531577]\n",
      "[Epoch 38/200] [Batch 450/637] [D loss: 0.177790] [G loss: 0.456457]\n",
      "[Epoch 38/200] [Batch 451/637] [D loss: 0.158803] [G loss: 0.442731]\n",
      "[Epoch 38/200] [Batch 452/637] [D loss: 0.170867] [G loss: 0.527628]\n",
      "[Epoch 38/200] [Batch 453/637] [D loss: 0.177519] [G loss: 0.548232]\n",
      "[Epoch 38/200] [Batch 454/637] [D loss: 0.171243] [G loss: 0.549172]\n",
      "[Epoch 38/200] [Batch 455/637] [D loss: 0.184923] [G loss: 0.470197]\n",
      "[Epoch 38/200] [Batch 456/637] [D loss: 0.188714] [G loss: 0.414347]\n",
      "[Epoch 38/200] [Batch 457/637] [D loss: 0.170192] [G loss: 0.479793]\n",
      "[Epoch 38/200] [Batch 458/637] [D loss: 0.179804] [G loss: 0.438589]\n",
      "[Epoch 38/200] [Batch 459/637] [D loss: 0.194076] [G loss: 0.378538]\n",
      "[Epoch 38/200] [Batch 460/637] [D loss: 0.169208] [G loss: 0.497451]\n",
      "[Epoch 38/200] [Batch 461/637] [D loss: 0.200821] [G loss: 0.514480]\n",
      "[Epoch 38/200] [Batch 462/637] [D loss: 0.179857] [G loss: 0.496955]\n",
      "[Epoch 38/200] [Batch 463/637] [D loss: 0.160734] [G loss: 0.477298]\n",
      "[Epoch 38/200] [Batch 464/637] [D loss: 0.183458] [G loss: 0.537565]\n",
      "[Epoch 38/200] [Batch 465/637] [D loss: 0.184217] [G loss: 0.481976]\n",
      "[Epoch 38/200] [Batch 466/637] [D loss: 0.161118] [G loss: 0.500431]\n",
      "[Epoch 38/200] [Batch 467/637] [D loss: 0.175530] [G loss: 0.435518]\n",
      "[Epoch 38/200] [Batch 468/637] [D loss: 0.159267] [G loss: 0.451957]\n",
      "[Epoch 38/200] [Batch 469/637] [D loss: 0.175271] [G loss: 0.444189]\n",
      "[Epoch 38/200] [Batch 470/637] [D loss: 0.163129] [G loss: 0.481556]\n",
      "[Epoch 38/200] [Batch 471/637] [D loss: 0.179726] [G loss: 0.488706]\n",
      "[Epoch 38/200] [Batch 472/637] [D loss: 0.185203] [G loss: 0.403682]\n",
      "[Epoch 38/200] [Batch 473/637] [D loss: 0.165817] [G loss: 0.647449]\n",
      "[Epoch 38/200] [Batch 474/637] [D loss: 0.174972] [G loss: 0.485009]\n",
      "[Epoch 38/200] [Batch 475/637] [D loss: 0.168798] [G loss: 0.431608]\n",
      "[Epoch 38/200] [Batch 476/637] [D loss: 0.164551] [G loss: 0.436909]\n",
      "[Epoch 38/200] [Batch 477/637] [D loss: 0.180291] [G loss: 0.497705]\n",
      "[Epoch 38/200] [Batch 478/637] [D loss: 0.154524] [G loss: 0.493900]\n",
      "[Epoch 38/200] [Batch 479/637] [D loss: 0.171331] [G loss: 0.484738]\n",
      "[Epoch 38/200] [Batch 480/637] [D loss: 0.157691] [G loss: 0.529957]\n",
      "[Epoch 38/200] [Batch 481/637] [D loss: 0.157301] [G loss: 0.488799]\n",
      "[Epoch 38/200] [Batch 482/637] [D loss: 0.160282] [G loss: 0.465283]\n",
      "[Epoch 38/200] [Batch 483/637] [D loss: 0.158448] [G loss: 0.446811]\n",
      "[Epoch 38/200] [Batch 484/637] [D loss: 0.177153] [G loss: 0.483415]\n",
      "[Epoch 38/200] [Batch 485/637] [D loss: 0.163554] [G loss: 0.499643]\n",
      "[Epoch 38/200] [Batch 486/637] [D loss: 0.173491] [G loss: 0.569055]\n",
      "[Epoch 38/200] [Batch 487/637] [D loss: 0.144993] [G loss: 0.618665]\n",
      "[Epoch 38/200] [Batch 488/637] [D loss: 0.182446] [G loss: 0.495694]\n",
      "[Epoch 38/200] [Batch 489/637] [D loss: 0.168433] [G loss: 0.508187]\n",
      "[Epoch 38/200] [Batch 490/637] [D loss: 0.189992] [G loss: 0.479559]\n",
      "[Epoch 38/200] [Batch 491/637] [D loss: 0.181425] [G loss: 0.537159]\n",
      "[Epoch 38/200] [Batch 492/637] [D loss: 0.202446] [G loss: 0.524064]\n",
      "[Epoch 38/200] [Batch 493/637] [D loss: 0.167167] [G loss: 0.542366]\n",
      "[Epoch 38/200] [Batch 494/637] [D loss: 0.184953] [G loss: 0.518829]\n",
      "[Epoch 38/200] [Batch 495/637] [D loss: 0.190392] [G loss: 0.502217]\n",
      "[Epoch 38/200] [Batch 496/637] [D loss: 0.163450] [G loss: 0.489128]\n",
      "[Epoch 38/200] [Batch 497/637] [D loss: 0.171767] [G loss: 0.597077]\n",
      "[Epoch 38/200] [Batch 498/637] [D loss: 0.145438] [G loss: 0.515322]\n",
      "[Epoch 38/200] [Batch 499/637] [D loss: 0.175845] [G loss: 0.519837]\n",
      "[Epoch 38/200] [Batch 500/637] [D loss: 0.176120] [G loss: 0.546505]\n",
      "[Epoch 38/200] [Batch 501/637] [D loss: 0.159444] [G loss: 0.426860]\n",
      "[Epoch 38/200] [Batch 502/637] [D loss: 0.187052] [G loss: 0.423013]\n",
      "[Epoch 38/200] [Batch 503/637] [D loss: 0.181325] [G loss: 0.401626]\n",
      "[Epoch 38/200] [Batch 504/637] [D loss: 0.162481] [G loss: 0.482558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/200] [Batch 505/637] [D loss: 0.189202] [G loss: 0.502162]\n",
      "[Epoch 38/200] [Batch 506/637] [D loss: 0.175646] [G loss: 0.480518]\n",
      "[Epoch 38/200] [Batch 507/637] [D loss: 0.175751] [G loss: 0.490176]\n",
      "[Epoch 38/200] [Batch 508/637] [D loss: 0.174744] [G loss: 0.471182]\n",
      "[Epoch 38/200] [Batch 509/637] [D loss: 0.168828] [G loss: 0.468050]\n",
      "[Epoch 38/200] [Batch 510/637] [D loss: 0.166212] [G loss: 0.480945]\n",
      "[Epoch 38/200] [Batch 511/637] [D loss: 0.163602] [G loss: 0.452721]\n",
      "[Epoch 38/200] [Batch 512/637] [D loss: 0.188595] [G loss: 0.436392]\n",
      "[Epoch 38/200] [Batch 513/637] [D loss: 0.170915] [G loss: 0.525766]\n",
      "[Epoch 38/200] [Batch 514/637] [D loss: 0.162994] [G loss: 0.507374]\n",
      "[Epoch 38/200] [Batch 515/637] [D loss: 0.178565] [G loss: 0.405464]\n",
      "[Epoch 38/200] [Batch 516/637] [D loss: 0.165098] [G loss: 0.496770]\n",
      "[Epoch 38/200] [Batch 517/637] [D loss: 0.166576] [G loss: 0.434444]\n",
      "[Epoch 38/200] [Batch 518/637] [D loss: 0.177594] [G loss: 0.473108]\n",
      "[Epoch 38/200] [Batch 519/637] [D loss: 0.170046] [G loss: 0.564183]\n",
      "[Epoch 38/200] [Batch 520/637] [D loss: 0.186407] [G loss: 0.516258]\n",
      "[Epoch 38/200] [Batch 521/637] [D loss: 0.153022] [G loss: 0.491720]\n",
      "[Epoch 38/200] [Batch 522/637] [D loss: 0.176396] [G loss: 0.448192]\n",
      "[Epoch 38/200] [Batch 523/637] [D loss: 0.159529] [G loss: 0.503123]\n",
      "[Epoch 38/200] [Batch 524/637] [D loss: 0.176599] [G loss: 0.493785]\n",
      "[Epoch 38/200] [Batch 525/637] [D loss: 0.193999] [G loss: 0.482382]\n",
      "[Epoch 38/200] [Batch 526/637] [D loss: 0.172199] [G loss: 0.506232]\n",
      "[Epoch 38/200] [Batch 527/637] [D loss: 0.158399] [G loss: 0.490739]\n",
      "[Epoch 38/200] [Batch 528/637] [D loss: 0.172623] [G loss: 0.519046]\n",
      "[Epoch 38/200] [Batch 529/637] [D loss: 0.170679] [G loss: 0.506280]\n",
      "[Epoch 38/200] [Batch 530/637] [D loss: 0.165683] [G loss: 0.481212]\n",
      "[Epoch 38/200] [Batch 531/637] [D loss: 0.170930] [G loss: 0.466986]\n",
      "[Epoch 38/200] [Batch 532/637] [D loss: 0.173000] [G loss: 0.576315]\n",
      "[Epoch 38/200] [Batch 533/637] [D loss: 0.172660] [G loss: 0.541342]\n",
      "[Epoch 38/200] [Batch 534/637] [D loss: 0.174487] [G loss: 0.493163]\n",
      "[Epoch 38/200] [Batch 535/637] [D loss: 0.204638] [G loss: 0.453452]\n",
      "[Epoch 38/200] [Batch 536/637] [D loss: 0.143401] [G loss: 0.551817]\n",
      "[Epoch 38/200] [Batch 537/637] [D loss: 0.159296] [G loss: 0.529252]\n",
      "[Epoch 38/200] [Batch 538/637] [D loss: 0.165808] [G loss: 0.577708]\n",
      "[Epoch 38/200] [Batch 539/637] [D loss: 0.186413] [G loss: 0.513951]\n",
      "[Epoch 38/200] [Batch 540/637] [D loss: 0.165999] [G loss: 0.526516]\n",
      "[Epoch 38/200] [Batch 541/637] [D loss: 0.147113] [G loss: 0.557237]\n",
      "[Epoch 38/200] [Batch 542/637] [D loss: 0.174399] [G loss: 0.500837]\n",
      "[Epoch 38/200] [Batch 543/637] [D loss: 0.160386] [G loss: 0.447767]\n",
      "[Epoch 38/200] [Batch 544/637] [D loss: 0.188143] [G loss: 0.537224]\n",
      "[Epoch 38/200] [Batch 545/637] [D loss: 0.166291] [G loss: 0.538482]\n",
      "[Epoch 38/200] [Batch 546/637] [D loss: 0.179697] [G loss: 0.489192]\n",
      "[Epoch 38/200] [Batch 547/637] [D loss: 0.191596] [G loss: 0.459300]\n",
      "[Epoch 38/200] [Batch 548/637] [D loss: 0.177470] [G loss: 0.413393]\n",
      "[Epoch 38/200] [Batch 549/637] [D loss: 0.176707] [G loss: 0.495309]\n",
      "[Epoch 38/200] [Batch 550/637] [D loss: 0.155186] [G loss: 0.578953]\n",
      "[Epoch 38/200] [Batch 551/637] [D loss: 0.183632] [G loss: 0.554717]\n",
      "[Epoch 38/200] [Batch 552/637] [D loss: 0.166740] [G loss: 0.473648]\n",
      "[Epoch 38/200] [Batch 553/637] [D loss: 0.176825] [G loss: 0.417735]\n",
      "[Epoch 38/200] [Batch 554/637] [D loss: 0.159325] [G loss: 0.488090]\n",
      "[Epoch 38/200] [Batch 555/637] [D loss: 0.195480] [G loss: 0.387239]\n",
      "[Epoch 38/200] [Batch 556/637] [D loss: 0.149559] [G loss: 0.534969]\n",
      "[Epoch 38/200] [Batch 557/637] [D loss: 0.165616] [G loss: 0.503896]\n",
      "[Epoch 38/200] [Batch 558/637] [D loss: 0.186481] [G loss: 0.522698]\n",
      "[Epoch 38/200] [Batch 559/637] [D loss: 0.168371] [G loss: 0.543020]\n",
      "[Epoch 38/200] [Batch 560/637] [D loss: 0.170908] [G loss: 0.501839]\n",
      "[Epoch 38/200] [Batch 561/637] [D loss: 0.176127] [G loss: 0.440966]\n",
      "[Epoch 38/200] [Batch 562/637] [D loss: 0.153510] [G loss: 0.469496]\n",
      "[Epoch 38/200] [Batch 563/637] [D loss: 0.155399] [G loss: 0.531390]\n",
      "[Epoch 38/200] [Batch 564/637] [D loss: 0.168057] [G loss: 0.466894]\n",
      "[Epoch 38/200] [Batch 565/637] [D loss: 0.152473] [G loss: 0.585039]\n",
      "[Epoch 38/200] [Batch 566/637] [D loss: 0.162565] [G loss: 0.575095]\n",
      "[Epoch 38/200] [Batch 567/637] [D loss: 0.176960] [G loss: 0.443929]\n",
      "[Epoch 38/200] [Batch 568/637] [D loss: 0.201721] [G loss: 0.519535]\n",
      "[Epoch 38/200] [Batch 569/637] [D loss: 0.154573] [G loss: 0.538121]\n",
      "[Epoch 38/200] [Batch 570/637] [D loss: 0.178925] [G loss: 0.464040]\n",
      "[Epoch 38/200] [Batch 571/637] [D loss: 0.172980] [G loss: 0.512666]\n",
      "[Epoch 38/200] [Batch 572/637] [D loss: 0.179273] [G loss: 0.518241]\n",
      "[Epoch 38/200] [Batch 573/637] [D loss: 0.181778] [G loss: 0.471721]\n",
      "[Epoch 38/200] [Batch 574/637] [D loss: 0.158095] [G loss: 0.542593]\n",
      "[Epoch 38/200] [Batch 575/637] [D loss: 0.162621] [G loss: 0.478644]\n",
      "[Epoch 38/200] [Batch 576/637] [D loss: 0.170196] [G loss: 0.474482]\n",
      "[Epoch 38/200] [Batch 577/637] [D loss: 0.175780] [G loss: 0.513086]\n",
      "[Epoch 38/200] [Batch 578/637] [D loss: 0.190991] [G loss: 0.476520]\n",
      "[Epoch 38/200] [Batch 579/637] [D loss: 0.174689] [G loss: 0.568705]\n",
      "[Epoch 38/200] [Batch 580/637] [D loss: 0.170541] [G loss: 0.514150]\n",
      "[Epoch 38/200] [Batch 581/637] [D loss: 0.142285] [G loss: 0.474000]\n",
      "[Epoch 38/200] [Batch 582/637] [D loss: 0.165446] [G loss: 0.430617]\n",
      "[Epoch 38/200] [Batch 583/637] [D loss: 0.153941] [G loss: 0.537039]\n",
      "[Epoch 38/200] [Batch 584/637] [D loss: 0.161568] [G loss: 0.471700]\n",
      "[Epoch 38/200] [Batch 585/637] [D loss: 0.162349] [G loss: 0.493598]\n",
      "[Epoch 38/200] [Batch 586/637] [D loss: 0.146888] [G loss: 0.579215]\n",
      "[Epoch 38/200] [Batch 587/637] [D loss: 0.181061] [G loss: 0.488824]\n",
      "[Epoch 38/200] [Batch 588/637] [D loss: 0.172271] [G loss: 0.472369]\n",
      "[Epoch 38/200] [Batch 589/637] [D loss: 0.166178] [G loss: 0.476743]\n",
      "[Epoch 38/200] [Batch 590/637] [D loss: 0.176711] [G loss: 0.487758]\n",
      "[Epoch 38/200] [Batch 591/637] [D loss: 0.173929] [G loss: 0.510590]\n",
      "[Epoch 38/200] [Batch 592/637] [D loss: 0.152480] [G loss: 0.480693]\n",
      "[Epoch 38/200] [Batch 593/637] [D loss: 0.164802] [G loss: 0.484583]\n",
      "[Epoch 38/200] [Batch 594/637] [D loss: 0.181334] [G loss: 0.489331]\n",
      "[Epoch 38/200] [Batch 595/637] [D loss: 0.179428] [G loss: 0.541051]\n",
      "[Epoch 38/200] [Batch 596/637] [D loss: 0.164511] [G loss: 0.473205]\n",
      "[Epoch 38/200] [Batch 597/637] [D loss: 0.177726] [G loss: 0.505602]\n",
      "[Epoch 38/200] [Batch 598/637] [D loss: 0.157332] [G loss: 0.525580]\n",
      "[Epoch 38/200] [Batch 599/637] [D loss: 0.180835] [G loss: 0.464032]\n",
      "[Epoch 38/200] [Batch 600/637] [D loss: 0.167148] [G loss: 0.483197]\n",
      "[Epoch 38/200] [Batch 601/637] [D loss: 0.163962] [G loss: 0.550390]\n",
      "[Epoch 38/200] [Batch 602/637] [D loss: 0.190937] [G loss: 0.503820]\n",
      "[Epoch 38/200] [Batch 603/637] [D loss: 0.167068] [G loss: 0.507736]\n",
      "[Epoch 38/200] [Batch 604/637] [D loss: 0.158069] [G loss: 0.530400]\n",
      "[Epoch 38/200] [Batch 605/637] [D loss: 0.179472] [G loss: 0.478027]\n",
      "[Epoch 38/200] [Batch 606/637] [D loss: 0.157106] [G loss: 0.490253]\n",
      "[Epoch 38/200] [Batch 607/637] [D loss: 0.172205] [G loss: 0.499170]\n",
      "[Epoch 38/200] [Batch 608/637] [D loss: 0.159448] [G loss: 0.620977]\n",
      "[Epoch 38/200] [Batch 609/637] [D loss: 0.143243] [G loss: 0.487328]\n",
      "[Epoch 38/200] [Batch 610/637] [D loss: 0.192992] [G loss: 0.391588]\n",
      "[Epoch 38/200] [Batch 611/637] [D loss: 0.172411] [G loss: 0.510969]\n",
      "[Epoch 38/200] [Batch 612/637] [D loss: 0.184829] [G loss: 0.558878]\n",
      "[Epoch 38/200] [Batch 613/637] [D loss: 0.168001] [G loss: 0.511594]\n",
      "[Epoch 38/200] [Batch 614/637] [D loss: 0.183965] [G loss: 0.542455]\n",
      "[Epoch 38/200] [Batch 615/637] [D loss: 0.162670] [G loss: 0.484322]\n",
      "[Epoch 38/200] [Batch 616/637] [D loss: 0.176264] [G loss: 0.472729]\n",
      "[Epoch 38/200] [Batch 617/637] [D loss: 0.142934] [G loss: 0.512307]\n",
      "[Epoch 38/200] [Batch 618/637] [D loss: 0.159399] [G loss: 0.480888]\n",
      "[Epoch 38/200] [Batch 619/637] [D loss: 0.178564] [G loss: 0.473788]\n",
      "[Epoch 38/200] [Batch 620/637] [D loss: 0.180002] [G loss: 0.472141]\n",
      "[Epoch 38/200] [Batch 621/637] [D loss: 0.137858] [G loss: 0.528259]\n",
      "[Epoch 38/200] [Batch 622/637] [D loss: 0.183834] [G loss: 0.524626]\n",
      "[Epoch 38/200] [Batch 623/637] [D loss: 0.160955] [G loss: 0.471974]\n",
      "[Epoch 38/200] [Batch 624/637] [D loss: 0.185720] [G loss: 0.389441]\n",
      "[Epoch 38/200] [Batch 625/637] [D loss: 0.171916] [G loss: 0.525158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/200] [Batch 626/637] [D loss: 0.174110] [G loss: 0.529548]\n",
      "[Epoch 38/200] [Batch 627/637] [D loss: 0.153898] [G loss: 0.520967]\n",
      "[Epoch 38/200] [Batch 628/637] [D loss: 0.176699] [G loss: 0.412501]\n",
      "[Epoch 38/200] [Batch 629/637] [D loss: 0.195092] [G loss: 0.437847]\n",
      "[Epoch 38/200] [Batch 630/637] [D loss: 0.182352] [G loss: 0.479198]\n",
      "[Epoch 38/200] [Batch 631/637] [D loss: 0.155827] [G loss: 0.467367]\n",
      "[Epoch 38/200] [Batch 632/637] [D loss: 0.153569] [G loss: 0.519504]\n",
      "[Epoch 38/200] [Batch 633/637] [D loss: 0.169416] [G loss: 0.470497]\n",
      "[Epoch 38/200] [Batch 634/637] [D loss: 0.148474] [G loss: 0.512958]\n",
      "[Epoch 38/200] [Batch 635/637] [D loss: 0.187153] [G loss: 0.448550]\n",
      "[Epoch 38/200] [Batch 636/637] [D loss: 0.174832] [G loss: 0.531015]\n",
      "[Epoch 39/200] [Batch 0/637] [D loss: 0.189323] [G loss: 0.446535]\n",
      "[Epoch 39/200] [Batch 1/637] [D loss: 0.191383] [G loss: 0.491386]\n",
      "[Epoch 39/200] [Batch 2/637] [D loss: 0.178780] [G loss: 0.521757]\n",
      "[Epoch 39/200] [Batch 3/637] [D loss: 0.185804] [G loss: 0.522941]\n",
      "[Epoch 39/200] [Batch 4/637] [D loss: 0.178307] [G loss: 0.501668]\n",
      "[Epoch 39/200] [Batch 5/637] [D loss: 0.180680] [G loss: 0.470252]\n",
      "[Epoch 39/200] [Batch 6/637] [D loss: 0.172017] [G loss: 0.416146]\n",
      "[Epoch 39/200] [Batch 7/637] [D loss: 0.162372] [G loss: 0.448572]\n",
      "[Epoch 39/200] [Batch 8/637] [D loss: 0.177863] [G loss: 0.523686]\n",
      "[Epoch 39/200] [Batch 9/637] [D loss: 0.158350] [G loss: 0.506007]\n",
      "[Epoch 39/200] [Batch 10/637] [D loss: 0.168631] [G loss: 0.485222]\n",
      "[Epoch 39/200] [Batch 11/637] [D loss: 0.194827] [G loss: 0.497675]\n",
      "[Epoch 39/200] [Batch 12/637] [D loss: 0.188380] [G loss: 0.453197]\n",
      "[Epoch 39/200] [Batch 13/637] [D loss: 0.183419] [G loss: 0.520039]\n",
      "[Epoch 39/200] [Batch 14/637] [D loss: 0.180124] [G loss: 0.475993]\n",
      "[Epoch 39/200] [Batch 15/637] [D loss: 0.174411] [G loss: 0.446247]\n",
      "[Epoch 39/200] [Batch 16/637] [D loss: 0.190073] [G loss: 0.401463]\n",
      "[Epoch 39/200] [Batch 17/637] [D loss: 0.163256] [G loss: 0.483546]\n",
      "[Epoch 39/200] [Batch 18/637] [D loss: 0.173132] [G loss: 0.483509]\n",
      "[Epoch 39/200] [Batch 19/637] [D loss: 0.157505] [G loss: 0.656176]\n",
      "[Epoch 39/200] [Batch 20/637] [D loss: 0.179589] [G loss: 0.527543]\n",
      "[Epoch 39/200] [Batch 21/637] [D loss: 0.183434] [G loss: 0.459768]\n",
      "[Epoch 39/200] [Batch 22/637] [D loss: 0.169359] [G loss: 0.430536]\n",
      "[Epoch 39/200] [Batch 23/637] [D loss: 0.170710] [G loss: 0.492644]\n",
      "[Epoch 39/200] [Batch 24/637] [D loss: 0.188612] [G loss: 0.460934]\n",
      "[Epoch 39/200] [Batch 25/637] [D loss: 0.187126] [G loss: 0.446172]\n",
      "[Epoch 39/200] [Batch 26/637] [D loss: 0.200458] [G loss: 0.449100]\n",
      "[Epoch 39/200] [Batch 27/637] [D loss: 0.175099] [G loss: 0.527281]\n",
      "[Epoch 39/200] [Batch 28/637] [D loss: 0.161423] [G loss: 0.511825]\n",
      "[Epoch 39/200] [Batch 29/637] [D loss: 0.182314] [G loss: 0.465661]\n",
      "[Epoch 39/200] [Batch 30/637] [D loss: 0.164190] [G loss: 0.482448]\n",
      "[Epoch 39/200] [Batch 31/637] [D loss: 0.172863] [G loss: 0.487276]\n",
      "[Epoch 39/200] [Batch 32/637] [D loss: 0.171488] [G loss: 0.505925]\n",
      "[Epoch 39/200] [Batch 33/637] [D loss: 0.139733] [G loss: 0.514077]\n",
      "[Epoch 39/200] [Batch 34/637] [D loss: 0.130159] [G loss: 0.560039]\n",
      "[Epoch 39/200] [Batch 35/637] [D loss: 0.196204] [G loss: 0.450168]\n",
      "[Epoch 39/200] [Batch 36/637] [D loss: 0.196506] [G loss: 0.521175]\n",
      "[Epoch 39/200] [Batch 37/637] [D loss: 0.188739] [G loss: 0.561351]\n",
      "[Epoch 39/200] [Batch 38/637] [D loss: 0.186387] [G loss: 0.469107]\n",
      "[Epoch 39/200] [Batch 39/637] [D loss: 0.178652] [G loss: 0.451850]\n",
      "[Epoch 39/200] [Batch 40/637] [D loss: 0.187192] [G loss: 0.431015]\n",
      "[Epoch 39/200] [Batch 41/637] [D loss: 0.157465] [G loss: 0.504721]\n",
      "[Epoch 39/200] [Batch 42/637] [D loss: 0.183465] [G loss: 0.511014]\n",
      "[Epoch 39/200] [Batch 43/637] [D loss: 0.167748] [G loss: 0.518997]\n",
      "[Epoch 39/200] [Batch 44/637] [D loss: 0.177160] [G loss: 0.447923]\n",
      "[Epoch 39/200] [Batch 45/637] [D loss: 0.140464] [G loss: 0.516634]\n",
      "[Epoch 39/200] [Batch 46/637] [D loss: 0.183536] [G loss: 0.491100]\n",
      "[Epoch 39/200] [Batch 47/637] [D loss: 0.167553] [G loss: 0.461415]\n",
      "[Epoch 39/200] [Batch 48/637] [D loss: 0.157940] [G loss: 0.455809]\n",
      "[Epoch 39/200] [Batch 49/637] [D loss: 0.161260] [G loss: 0.517839]\n",
      "[Epoch 39/200] [Batch 50/637] [D loss: 0.150894] [G loss: 0.544211]\n",
      "[Epoch 39/200] [Batch 51/637] [D loss: 0.150343] [G loss: 0.472073]\n",
      "[Epoch 39/200] [Batch 52/637] [D loss: 0.173883] [G loss: 0.564260]\n",
      "[Epoch 39/200] [Batch 53/637] [D loss: 0.157183] [G loss: 0.541214]\n",
      "[Epoch 39/200] [Batch 54/637] [D loss: 0.230833] [G loss: 0.481193]\n",
      "[Epoch 39/200] [Batch 55/637] [D loss: 0.210196] [G loss: 0.563166]\n",
      "[Epoch 39/200] [Batch 56/637] [D loss: 0.209780] [G loss: 0.431555]\n",
      "[Epoch 39/200] [Batch 57/637] [D loss: 0.174871] [G loss: 0.427422]\n",
      "[Epoch 39/200] [Batch 58/637] [D loss: 0.211497] [G loss: 0.443307]\n",
      "[Epoch 39/200] [Batch 59/637] [D loss: 0.175112] [G loss: 0.582766]\n",
      "[Epoch 39/200] [Batch 60/637] [D loss: 0.174499] [G loss: 0.591169]\n",
      "[Epoch 39/200] [Batch 61/637] [D loss: 0.167581] [G loss: 0.496386]\n",
      "[Epoch 39/200] [Batch 62/637] [D loss: 0.170547] [G loss: 0.480261]\n",
      "[Epoch 39/200] [Batch 63/637] [D loss: 0.182738] [G loss: 0.457947]\n",
      "[Epoch 39/200] [Batch 64/637] [D loss: 0.143383] [G loss: 0.532321]\n",
      "[Epoch 39/200] [Batch 65/637] [D loss: 0.142890] [G loss: 0.502966]\n",
      "[Epoch 39/200] [Batch 66/637] [D loss: 0.178457] [G loss: 0.529433]\n",
      "[Epoch 39/200] [Batch 67/637] [D loss: 0.151344] [G loss: 0.481097]\n",
      "[Epoch 39/200] [Batch 68/637] [D loss: 0.212450] [G loss: 0.380139]\n",
      "[Epoch 39/200] [Batch 69/637] [D loss: 0.178065] [G loss: 0.566589]\n",
      "[Epoch 39/200] [Batch 70/637] [D loss: 0.159652] [G loss: 0.579475]\n",
      "[Epoch 39/200] [Batch 71/637] [D loss: 0.153360] [G loss: 0.508755]\n",
      "[Epoch 39/200] [Batch 72/637] [D loss: 0.210917] [G loss: 0.369069]\n",
      "[Epoch 39/200] [Batch 73/637] [D loss: 0.208057] [G loss: 0.456062]\n",
      "[Epoch 39/200] [Batch 74/637] [D loss: 0.184697] [G loss: 0.463390]\n",
      "[Epoch 39/200] [Batch 75/637] [D loss: 0.169708] [G loss: 0.538287]\n",
      "[Epoch 39/200] [Batch 76/637] [D loss: 0.148261] [G loss: 0.537525]\n",
      "[Epoch 39/200] [Batch 77/637] [D loss: 0.201209] [G loss: 0.396145]\n",
      "[Epoch 39/200] [Batch 78/637] [D loss: 0.153805] [G loss: 0.430752]\n",
      "[Epoch 39/200] [Batch 79/637] [D loss: 0.142102] [G loss: 0.491899]\n",
      "[Epoch 39/200] [Batch 80/637] [D loss: 0.175530] [G loss: 0.474058]\n",
      "[Epoch 39/200] [Batch 81/637] [D loss: 0.163490] [G loss: 0.511583]\n",
      "[Epoch 39/200] [Batch 82/637] [D loss: 0.159271] [G loss: 0.508396]\n",
      "[Epoch 39/200] [Batch 83/637] [D loss: 0.150869] [G loss: 0.544138]\n",
      "[Epoch 39/200] [Batch 84/637] [D loss: 0.159004] [G loss: 0.488162]\n",
      "[Epoch 39/200] [Batch 85/637] [D loss: 0.162317] [G loss: 0.569850]\n",
      "[Epoch 39/200] [Batch 86/637] [D loss: 0.162987] [G loss: 0.596603]\n",
      "[Epoch 39/200] [Batch 87/637] [D loss: 0.180343] [G loss: 0.569108]\n",
      "[Epoch 39/200] [Batch 88/637] [D loss: 0.161226] [G loss: 0.559113]\n",
      "[Epoch 39/200] [Batch 89/637] [D loss: 0.206079] [G loss: 0.460077]\n",
      "[Epoch 39/200] [Batch 90/637] [D loss: 0.171853] [G loss: 0.534702]\n",
      "[Epoch 39/200] [Batch 91/637] [D loss: 0.149106] [G loss: 0.553936]\n",
      "[Epoch 39/200] [Batch 92/637] [D loss: 0.173376] [G loss: 0.516894]\n",
      "[Epoch 39/200] [Batch 93/637] [D loss: 0.156188] [G loss: 0.488838]\n",
      "[Epoch 39/200] [Batch 94/637] [D loss: 0.161035] [G loss: 0.436374]\n",
      "[Epoch 39/200] [Batch 95/637] [D loss: 0.152490] [G loss: 0.488712]\n",
      "[Epoch 39/200] [Batch 96/637] [D loss: 0.162314] [G loss: 0.486621]\n",
      "[Epoch 39/200] [Batch 97/637] [D loss: 0.185036] [G loss: 0.554902]\n",
      "[Epoch 39/200] [Batch 98/637] [D loss: 0.180526] [G loss: 0.497760]\n",
      "[Epoch 39/200] [Batch 99/637] [D loss: 0.180073] [G loss: 0.498229]\n",
      "[Epoch 39/200] [Batch 100/637] [D loss: 0.179566] [G loss: 0.478732]\n",
      "[Epoch 39/200] [Batch 101/637] [D loss: 0.171677] [G loss: 0.442463]\n",
      "[Epoch 39/200] [Batch 102/637] [D loss: 0.179337] [G loss: 0.475339]\n",
      "[Epoch 39/200] [Batch 103/637] [D loss: 0.175815] [G loss: 0.449980]\n",
      "[Epoch 39/200] [Batch 104/637] [D loss: 0.177705] [G loss: 0.408252]\n",
      "[Epoch 39/200] [Batch 105/637] [D loss: 0.179429] [G loss: 0.431616]\n",
      "[Epoch 39/200] [Batch 106/637] [D loss: 0.168321] [G loss: 0.467662]\n",
      "[Epoch 39/200] [Batch 107/637] [D loss: 0.167179] [G loss: 0.450157]\n",
      "[Epoch 39/200] [Batch 108/637] [D loss: 0.166851] [G loss: 0.469473]\n",
      "[Epoch 39/200] [Batch 109/637] [D loss: 0.192777] [G loss: 0.480262]\n",
      "[Epoch 39/200] [Batch 110/637] [D loss: 0.181292] [G loss: 0.571451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/200] [Batch 111/637] [D loss: 0.181916] [G loss: 0.458181]\n",
      "[Epoch 39/200] [Batch 112/637] [D loss: 0.178842] [G loss: 0.433928]\n",
      "[Epoch 39/200] [Batch 113/637] [D loss: 0.161950] [G loss: 0.407659]\n",
      "[Epoch 39/200] [Batch 114/637] [D loss: 0.169859] [G loss: 0.403972]\n",
      "[Epoch 39/200] [Batch 115/637] [D loss: 0.171089] [G loss: 0.456418]\n",
      "[Epoch 39/200] [Batch 116/637] [D loss: 0.173504] [G loss: 0.476843]\n",
      "[Epoch 39/200] [Batch 117/637] [D loss: 0.165310] [G loss: 0.530225]\n",
      "[Epoch 39/200] [Batch 118/637] [D loss: 0.180860] [G loss: 0.521271]\n",
      "[Epoch 39/200] [Batch 119/637] [D loss: 0.183654] [G loss: 0.492329]\n",
      "[Epoch 39/200] [Batch 120/637] [D loss: 0.188648] [G loss: 0.452135]\n",
      "[Epoch 39/200] [Batch 121/637] [D loss: 0.154357] [G loss: 0.523521]\n",
      "[Epoch 39/200] [Batch 122/637] [D loss: 0.153131] [G loss: 0.517702]\n",
      "[Epoch 39/200] [Batch 123/637] [D loss: 0.164678] [G loss: 0.465918]\n",
      "[Epoch 39/200] [Batch 124/637] [D loss: 0.155365] [G loss: 0.518385]\n",
      "[Epoch 39/200] [Batch 125/637] [D loss: 0.148119] [G loss: 0.500561]\n",
      "[Epoch 39/200] [Batch 126/637] [D loss: 0.165646] [G loss: 0.448482]\n",
      "[Epoch 39/200] [Batch 127/637] [D loss: 0.166515] [G loss: 0.504653]\n",
      "[Epoch 39/200] [Batch 128/637] [D loss: 0.171542] [G loss: 0.568156]\n",
      "[Epoch 39/200] [Batch 129/637] [D loss: 0.168423] [G loss: 0.502995]\n",
      "[Epoch 39/200] [Batch 130/637] [D loss: 0.153340] [G loss: 0.519347]\n",
      "[Epoch 39/200] [Batch 131/637] [D loss: 0.156354] [G loss: 0.483467]\n",
      "[Epoch 39/200] [Batch 132/637] [D loss: 0.182594] [G loss: 0.486849]\n",
      "[Epoch 39/200] [Batch 133/637] [D loss: 0.153047] [G loss: 0.512069]\n",
      "[Epoch 39/200] [Batch 134/637] [D loss: 0.180177] [G loss: 0.492352]\n",
      "[Epoch 39/200] [Batch 135/637] [D loss: 0.155764] [G loss: 0.509289]\n",
      "[Epoch 39/200] [Batch 136/637] [D loss: 0.161119] [G loss: 0.578220]\n",
      "[Epoch 39/200] [Batch 137/637] [D loss: 0.183646] [G loss: 0.457880]\n",
      "[Epoch 39/200] [Batch 138/637] [D loss: 0.192098] [G loss: 0.409259]\n",
      "[Epoch 39/200] [Batch 139/637] [D loss: 0.162219] [G loss: 0.519646]\n",
      "[Epoch 39/200] [Batch 140/637] [D loss: 0.190608] [G loss: 0.545867]\n",
      "[Epoch 39/200] [Batch 141/637] [D loss: 0.184763] [G loss: 0.505196]\n",
      "[Epoch 39/200] [Batch 142/637] [D loss: 0.180083] [G loss: 0.574335]\n",
      "[Epoch 39/200] [Batch 143/637] [D loss: 0.166837] [G loss: 0.499149]\n",
      "[Epoch 39/200] [Batch 144/637] [D loss: 0.176012] [G loss: 0.449576]\n",
      "[Epoch 39/200] [Batch 145/637] [D loss: 0.220190] [G loss: 0.380839]\n",
      "[Epoch 39/200] [Batch 146/637] [D loss: 0.211815] [G loss: 0.494895]\n",
      "[Epoch 39/200] [Batch 147/637] [D loss: 0.167058] [G loss: 0.536259]\n",
      "[Epoch 39/200] [Batch 148/637] [D loss: 0.170080] [G loss: 0.514006]\n",
      "[Epoch 39/200] [Batch 149/637] [D loss: 0.152186] [G loss: 0.516321]\n",
      "[Epoch 39/200] [Batch 150/637] [D loss: 0.166805] [G loss: 0.477282]\n",
      "[Epoch 39/200] [Batch 151/637] [D loss: 0.168560] [G loss: 0.535618]\n",
      "[Epoch 39/200] [Batch 152/637] [D loss: 0.163251] [G loss: 0.515268]\n",
      "[Epoch 39/200] [Batch 153/637] [D loss: 0.182044] [G loss: 0.423833]\n",
      "[Epoch 39/200] [Batch 154/637] [D loss: 0.173245] [G loss: 0.499985]\n",
      "[Epoch 39/200] [Batch 155/637] [D loss: 0.183950] [G loss: 0.480806]\n",
      "[Epoch 39/200] [Batch 156/637] [D loss: 0.151389] [G loss: 0.508617]\n",
      "[Epoch 39/200] [Batch 157/637] [D loss: 0.151371] [G loss: 0.537476]\n",
      "[Epoch 39/200] [Batch 158/637] [D loss: 0.161514] [G loss: 0.468439]\n",
      "[Epoch 39/200] [Batch 159/637] [D loss: 0.164652] [G loss: 0.458759]\n",
      "[Epoch 39/200] [Batch 160/637] [D loss: 0.163409] [G loss: 0.471797]\n",
      "[Epoch 39/200] [Batch 161/637] [D loss: 0.175808] [G loss: 0.460336]\n",
      "[Epoch 39/200] [Batch 162/637] [D loss: 0.154063] [G loss: 0.503075]\n",
      "[Epoch 39/200] [Batch 163/637] [D loss: 0.186600] [G loss: 0.450752]\n",
      "[Epoch 39/200] [Batch 164/637] [D loss: 0.181232] [G loss: 0.445176]\n",
      "[Epoch 39/200] [Batch 165/637] [D loss: 0.178615] [G loss: 0.493427]\n",
      "[Epoch 39/200] [Batch 166/637] [D loss: 0.177081] [G loss: 0.410325]\n",
      "[Epoch 39/200] [Batch 167/637] [D loss: 0.208695] [G loss: 0.397105]\n",
      "[Epoch 39/200] [Batch 168/637] [D loss: 0.182705] [G loss: 0.427316]\n",
      "[Epoch 39/200] [Batch 169/637] [D loss: 0.194903] [G loss: 0.415175]\n",
      "[Epoch 39/200] [Batch 170/637] [D loss: 0.200874] [G loss: 0.417976]\n",
      "[Epoch 39/200] [Batch 171/637] [D loss: 0.189782] [G loss: 0.438504]\n",
      "[Epoch 39/200] [Batch 172/637] [D loss: 0.160235] [G loss: 0.467765]\n",
      "[Epoch 39/200] [Batch 173/637] [D loss: 0.157039] [G loss: 0.491777]\n",
      "[Epoch 39/200] [Batch 174/637] [D loss: 0.173903] [G loss: 0.439068]\n",
      "[Epoch 39/200] [Batch 175/637] [D loss: 0.164442] [G loss: 0.420123]\n",
      "[Epoch 39/200] [Batch 176/637] [D loss: 0.176468] [G loss: 0.445334]\n",
      "[Epoch 39/200] [Batch 177/637] [D loss: 0.147384] [G loss: 0.527070]\n",
      "[Epoch 39/200] [Batch 178/637] [D loss: 0.236467] [G loss: 0.439512]\n",
      "[Epoch 39/200] [Batch 179/637] [D loss: 0.180409] [G loss: 0.531005]\n",
      "[Epoch 39/200] [Batch 180/637] [D loss: 0.196946] [G loss: 0.453314]\n",
      "[Epoch 39/200] [Batch 181/637] [D loss: 0.157799] [G loss: 0.507234]\n",
      "[Epoch 39/200] [Batch 182/637] [D loss: 0.170108] [G loss: 0.440586]\n",
      "[Epoch 39/200] [Batch 183/637] [D loss: 0.166973] [G loss: 0.452483]\n",
      "[Epoch 39/200] [Batch 184/637] [D loss: 0.184779] [G loss: 0.465978]\n",
      "[Epoch 39/200] [Batch 185/637] [D loss: 0.168065] [G loss: 0.500076]\n",
      "[Epoch 39/200] [Batch 186/637] [D loss: 0.153789] [G loss: 0.536424]\n",
      "[Epoch 39/200] [Batch 187/637] [D loss: 0.175850] [G loss: 0.437967]\n",
      "[Epoch 39/200] [Batch 188/637] [D loss: 0.144550] [G loss: 0.523423]\n",
      "[Epoch 39/200] [Batch 189/637] [D loss: 0.167117] [G loss: 0.455809]\n",
      "[Epoch 39/200] [Batch 190/637] [D loss: 0.168738] [G loss: 0.509156]\n",
      "[Epoch 39/200] [Batch 191/637] [D loss: 0.150538] [G loss: 0.604171]\n",
      "[Epoch 39/200] [Batch 192/637] [D loss: 0.151819] [G loss: 0.523056]\n",
      "[Epoch 39/200] [Batch 193/637] [D loss: 0.159672] [G loss: 0.496132]\n",
      "[Epoch 39/200] [Batch 194/637] [D loss: 0.170123] [G loss: 0.466215]\n",
      "[Epoch 39/200] [Batch 195/637] [D loss: 0.171014] [G loss: 0.566087]\n",
      "[Epoch 39/200] [Batch 196/637] [D loss: 0.156965] [G loss: 0.530676]\n",
      "[Epoch 39/200] [Batch 197/637] [D loss: 0.165863] [G loss: 0.488340]\n",
      "[Epoch 39/200] [Batch 198/637] [D loss: 0.179244] [G loss: 0.411472]\n",
      "[Epoch 39/200] [Batch 199/637] [D loss: 0.156622] [G loss: 0.492860]\n",
      "[Epoch 39/200] [Batch 200/637] [D loss: 0.158828] [G loss: 0.520986]\n",
      "[Epoch 39/200] [Batch 201/637] [D loss: 0.174697] [G loss: 0.595355]\n",
      "[Epoch 39/200] [Batch 202/637] [D loss: 0.182545] [G loss: 0.504081]\n",
      "[Epoch 39/200] [Batch 203/637] [D loss: 0.164627] [G loss: 0.557481]\n",
      "[Epoch 39/200] [Batch 204/637] [D loss: 0.163375] [G loss: 0.533899]\n",
      "[Epoch 39/200] [Batch 205/637] [D loss: 0.164008] [G loss: 0.480008]\n",
      "[Epoch 39/200] [Batch 206/637] [D loss: 0.150254] [G loss: 0.448172]\n",
      "[Epoch 39/200] [Batch 207/637] [D loss: 0.135774] [G loss: 0.562460]\n",
      "[Epoch 39/200] [Batch 208/637] [D loss: 0.155939] [G loss: 0.518697]\n",
      "[Epoch 39/200] [Batch 209/637] [D loss: 0.154222] [G loss: 0.501909]\n",
      "[Epoch 39/200] [Batch 210/637] [D loss: 0.174021] [G loss: 0.477346]\n",
      "[Epoch 39/200] [Batch 211/637] [D loss: 0.164668] [G loss: 0.496371]\n",
      "[Epoch 39/200] [Batch 212/637] [D loss: 0.163737] [G loss: 0.507096]\n",
      "[Epoch 39/200] [Batch 213/637] [D loss: 0.176978] [G loss: 0.528810]\n",
      "[Epoch 39/200] [Batch 214/637] [D loss: 0.173247] [G loss: 0.513240]\n",
      "[Epoch 39/200] [Batch 215/637] [D loss: 0.186668] [G loss: 0.544016]\n",
      "[Epoch 39/200] [Batch 216/637] [D loss: 0.158172] [G loss: 0.430779]\n",
      "[Epoch 39/200] [Batch 217/637] [D loss: 0.149416] [G loss: 0.508919]\n",
      "[Epoch 39/200] [Batch 218/637] [D loss: 0.187434] [G loss: 0.469542]\n",
      "[Epoch 39/200] [Batch 219/637] [D loss: 0.181978] [G loss: 0.478693]\n",
      "[Epoch 39/200] [Batch 220/637] [D loss: 0.208678] [G loss: 0.466196]\n",
      "[Epoch 39/200] [Batch 221/637] [D loss: 0.150718] [G loss: 0.613820]\n",
      "[Epoch 39/200] [Batch 222/637] [D loss: 0.168735] [G loss: 0.534024]\n",
      "[Epoch 39/200] [Batch 223/637] [D loss: 0.182369] [G loss: 0.465372]\n",
      "[Epoch 39/200] [Batch 224/637] [D loss: 0.179721] [G loss: 0.377072]\n",
      "[Epoch 39/200] [Batch 225/637] [D loss: 0.175901] [G loss: 0.413590]\n",
      "[Epoch 39/200] [Batch 226/637] [D loss: 0.144529] [G loss: 0.549900]\n",
      "[Epoch 39/200] [Batch 227/637] [D loss: 0.148953] [G loss: 0.482591]\n",
      "[Epoch 39/200] [Batch 228/637] [D loss: 0.150541] [G loss: 0.526320]\n",
      "[Epoch 39/200] [Batch 229/637] [D loss: 0.169340] [G loss: 0.512049]\n",
      "[Epoch 39/200] [Batch 230/637] [D loss: 0.213958] [G loss: 0.497095]\n",
      "[Epoch 39/200] [Batch 231/637] [D loss: 0.169577] [G loss: 0.585930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/200] [Batch 232/637] [D loss: 0.191987] [G loss: 0.524302]\n",
      "[Epoch 39/200] [Batch 233/637] [D loss: 0.182658] [G loss: 0.569461]\n",
      "[Epoch 39/200] [Batch 234/637] [D loss: 0.199030] [G loss: 0.394155]\n",
      "[Epoch 39/200] [Batch 235/637] [D loss: 0.225506] [G loss: 0.477409]\n",
      "[Epoch 39/200] [Batch 236/637] [D loss: 0.168542] [G loss: 0.631182]\n",
      "[Epoch 39/200] [Batch 237/637] [D loss: 0.183966] [G loss: 0.501686]\n",
      "[Epoch 39/200] [Batch 238/637] [D loss: 0.199112] [G loss: 0.424046]\n",
      "[Epoch 39/200] [Batch 239/637] [D loss: 0.178761] [G loss: 0.465217]\n",
      "[Epoch 39/200] [Batch 240/637] [D loss: 0.184344] [G loss: 0.426468]\n",
      "[Epoch 39/200] [Batch 241/637] [D loss: 0.173911] [G loss: 0.416951]\n",
      "[Epoch 39/200] [Batch 242/637] [D loss: 0.205638] [G loss: 0.446412]\n",
      "[Epoch 39/200] [Batch 243/637] [D loss: 0.172968] [G loss: 0.473427]\n",
      "[Epoch 39/200] [Batch 244/637] [D loss: 0.147901] [G loss: 0.465861]\n",
      "[Epoch 39/200] [Batch 245/637] [D loss: 0.164596] [G loss: 0.452711]\n",
      "[Epoch 39/200] [Batch 246/637] [D loss: 0.156241] [G loss: 0.474456]\n",
      "[Epoch 39/200] [Batch 247/637] [D loss: 0.197537] [G loss: 0.440735]\n",
      "[Epoch 39/200] [Batch 248/637] [D loss: 0.185660] [G loss: 0.498092]\n",
      "[Epoch 39/200] [Batch 249/637] [D loss: 0.170536] [G loss: 0.501886]\n",
      "[Epoch 39/200] [Batch 250/637] [D loss: 0.207678] [G loss: 0.420186]\n",
      "[Epoch 39/200] [Batch 251/637] [D loss: 0.181409] [G loss: 0.502085]\n",
      "[Epoch 39/200] [Batch 252/637] [D loss: 0.177351] [G loss: 0.456096]\n",
      "[Epoch 39/200] [Batch 253/637] [D loss: 0.183243] [G loss: 0.436099]\n",
      "[Epoch 39/200] [Batch 254/637] [D loss: 0.168150] [G loss: 0.468718]\n",
      "[Epoch 39/200] [Batch 255/637] [D loss: 0.176440] [G loss: 0.456457]\n",
      "[Epoch 39/200] [Batch 256/637] [D loss: 0.170784] [G loss: 0.554525]\n",
      "[Epoch 39/200] [Batch 257/637] [D loss: 0.180236] [G loss: 0.548671]\n",
      "[Epoch 39/200] [Batch 258/637] [D loss: 0.146985] [G loss: 0.494478]\n",
      "[Epoch 39/200] [Batch 259/637] [D loss: 0.152792] [G loss: 0.501197]\n",
      "[Epoch 39/200] [Batch 260/637] [D loss: 0.140698] [G loss: 0.510311]\n",
      "[Epoch 39/200] [Batch 261/637] [D loss: 0.176460] [G loss: 0.487643]\n",
      "[Epoch 39/200] [Batch 262/637] [D loss: 0.166823] [G loss: 0.515265]\n",
      "[Epoch 39/200] [Batch 263/637] [D loss: 0.204107] [G loss: 0.488324]\n",
      "[Epoch 39/200] [Batch 264/637] [D loss: 0.180673] [G loss: 0.503344]\n",
      "[Epoch 39/200] [Batch 265/637] [D loss: 0.150159] [G loss: 0.517480]\n",
      "[Epoch 39/200] [Batch 266/637] [D loss: 0.155432] [G loss: 0.481078]\n",
      "[Epoch 39/200] [Batch 267/637] [D loss: 0.190915] [G loss: 0.434851]\n",
      "[Epoch 39/200] [Batch 268/637] [D loss: 0.160939] [G loss: 0.492361]\n",
      "[Epoch 39/200] [Batch 269/637] [D loss: 0.145869] [G loss: 0.549709]\n",
      "[Epoch 39/200] [Batch 270/637] [D loss: 0.153830] [G loss: 0.542909]\n",
      "[Epoch 39/200] [Batch 271/637] [D loss: 0.206715] [G loss: 0.541447]\n",
      "[Epoch 39/200] [Batch 272/637] [D loss: 0.162784] [G loss: 0.490875]\n",
      "[Epoch 39/200] [Batch 273/637] [D loss: 0.166263] [G loss: 0.498382]\n",
      "[Epoch 39/200] [Batch 274/637] [D loss: 0.185630] [G loss: 0.503212]\n",
      "[Epoch 39/200] [Batch 275/637] [D loss: 0.179061] [G loss: 0.459210]\n",
      "[Epoch 39/200] [Batch 276/637] [D loss: 0.183867] [G loss: 0.477997]\n",
      "[Epoch 39/200] [Batch 277/637] [D loss: 0.149898] [G loss: 0.510670]\n",
      "[Epoch 39/200] [Batch 278/637] [D loss: 0.177244] [G loss: 0.498627]\n",
      "[Epoch 39/200] [Batch 279/637] [D loss: 0.169651] [G loss: 0.506593]\n",
      "[Epoch 39/200] [Batch 280/637] [D loss: 0.160146] [G loss: 0.496894]\n",
      "[Epoch 39/200] [Batch 281/637] [D loss: 0.160519] [G loss: 0.476101]\n",
      "[Epoch 39/200] [Batch 282/637] [D loss: 0.159225] [G loss: 0.469170]\n",
      "[Epoch 39/200] [Batch 283/637] [D loss: 0.173735] [G loss: 0.516639]\n",
      "[Epoch 39/200] [Batch 284/637] [D loss: 0.186266] [G loss: 0.515765]\n",
      "[Epoch 39/200] [Batch 285/637] [D loss: 0.147673] [G loss: 0.584486]\n",
      "[Epoch 39/200] [Batch 286/637] [D loss: 0.152543] [G loss: 0.536640]\n",
      "[Epoch 39/200] [Batch 287/637] [D loss: 0.157023] [G loss: 0.475245]\n",
      "[Epoch 39/200] [Batch 288/637] [D loss: 0.162519] [G loss: 0.480271]\n",
      "[Epoch 39/200] [Batch 289/637] [D loss: 0.166895] [G loss: 0.489782]\n",
      "[Epoch 39/200] [Batch 290/637] [D loss: 0.172490] [G loss: 0.509263]\n",
      "[Epoch 39/200] [Batch 291/637] [D loss: 0.168288] [G loss: 0.500879]\n",
      "[Epoch 39/200] [Batch 292/637] [D loss: 0.210524] [G loss: 0.545932]\n",
      "[Epoch 39/200] [Batch 293/637] [D loss: 0.167176] [G loss: 0.542616]\n",
      "[Epoch 39/200] [Batch 294/637] [D loss: 0.151268] [G loss: 0.550572]\n",
      "[Epoch 39/200] [Batch 295/637] [D loss: 0.246705] [G loss: 0.412357]\n",
      "[Epoch 39/200] [Batch 296/637] [D loss: 0.231357] [G loss: 0.498958]\n",
      "[Epoch 39/200] [Batch 297/637] [D loss: 0.224694] [G loss: 0.371650]\n",
      "[Epoch 39/200] [Batch 298/637] [D loss: 0.210887] [G loss: 0.518976]\n",
      "[Epoch 39/200] [Batch 299/637] [D loss: 0.178190] [G loss: 0.499837]\n",
      "[Epoch 39/200] [Batch 300/637] [D loss: 0.164412] [G loss: 0.542174]\n",
      "[Epoch 39/200] [Batch 301/637] [D loss: 0.190947] [G loss: 0.431129]\n",
      "[Epoch 39/200] [Batch 302/637] [D loss: 0.181762] [G loss: 0.433482]\n",
      "[Epoch 39/200] [Batch 303/637] [D loss: 0.186443] [G loss: 0.455019]\n",
      "[Epoch 39/200] [Batch 304/637] [D loss: 0.165338] [G loss: 0.453775]\n",
      "[Epoch 39/200] [Batch 305/637] [D loss: 0.181510] [G loss: 0.420862]\n",
      "[Epoch 39/200] [Batch 306/637] [D loss: 0.156125] [G loss: 0.516650]\n",
      "[Epoch 39/200] [Batch 307/637] [D loss: 0.177652] [G loss: 0.485313]\n",
      "[Epoch 39/200] [Batch 308/637] [D loss: 0.195477] [G loss: 0.451826]\n",
      "[Epoch 39/200] [Batch 309/637] [D loss: 0.183513] [G loss: 0.527103]\n",
      "[Epoch 39/200] [Batch 310/637] [D loss: 0.162571] [G loss: 0.514293]\n",
      "[Epoch 39/200] [Batch 311/637] [D loss: 0.201280] [G loss: 0.426938]\n",
      "[Epoch 39/200] [Batch 312/637] [D loss: 0.166832] [G loss: 0.448448]\n",
      "[Epoch 39/200] [Batch 313/637] [D loss: 0.169858] [G loss: 0.488921]\n",
      "[Epoch 39/200] [Batch 314/637] [D loss: 0.164427] [G loss: 0.494762]\n",
      "[Epoch 39/200] [Batch 315/637] [D loss: 0.171206] [G loss: 0.455263]\n",
      "[Epoch 39/200] [Batch 316/637] [D loss: 0.188050] [G loss: 0.504660]\n",
      "[Epoch 39/200] [Batch 317/637] [D loss: 0.175764] [G loss: 0.518376]\n",
      "[Epoch 39/200] [Batch 318/637] [D loss: 0.188910] [G loss: 0.473279]\n",
      "[Epoch 39/200] [Batch 319/637] [D loss: 0.156404] [G loss: 0.561094]\n",
      "[Epoch 39/200] [Batch 320/637] [D loss: 0.189316] [G loss: 0.501349]\n",
      "[Epoch 39/200] [Batch 321/637] [D loss: 0.184650] [G loss: 0.508461]\n",
      "[Epoch 39/200] [Batch 322/637] [D loss: 0.181114] [G loss: 0.483562]\n",
      "[Epoch 39/200] [Batch 323/637] [D loss: 0.178330] [G loss: 0.427827]\n",
      "[Epoch 39/200] [Batch 324/637] [D loss: 0.179963] [G loss: 0.451701]\n",
      "[Epoch 39/200] [Batch 325/637] [D loss: 0.159192] [G loss: 0.496322]\n",
      "[Epoch 39/200] [Batch 326/637] [D loss: 0.162706] [G loss: 0.439797]\n",
      "[Epoch 39/200] [Batch 327/637] [D loss: 0.142469] [G loss: 0.527177]\n",
      "[Epoch 39/200] [Batch 328/637] [D loss: 0.160525] [G loss: 0.590860]\n",
      "[Epoch 39/200] [Batch 329/637] [D loss: 0.150627] [G loss: 0.435980]\n",
      "[Epoch 39/200] [Batch 330/637] [D loss: 0.156306] [G loss: 0.512817]\n",
      "[Epoch 39/200] [Batch 331/637] [D loss: 0.141944] [G loss: 0.493160]\n",
      "[Epoch 39/200] [Batch 332/637] [D loss: 0.204326] [G loss: 0.422252]\n",
      "[Epoch 39/200] [Batch 333/637] [D loss: 0.154700] [G loss: 0.610108]\n",
      "[Epoch 39/200] [Batch 334/637] [D loss: 0.155468] [G loss: 0.575289]\n",
      "[Epoch 39/200] [Batch 335/637] [D loss: 0.206319] [G loss: 0.470568]\n",
      "[Epoch 39/200] [Batch 336/637] [D loss: 0.199160] [G loss: 0.488583]\n",
      "[Epoch 39/200] [Batch 337/637] [D loss: 0.181270] [G loss: 0.518216]\n",
      "[Epoch 39/200] [Batch 338/637] [D loss: 0.164078] [G loss: 0.541801]\n",
      "[Epoch 39/200] [Batch 339/637] [D loss: 0.176417] [G loss: 0.438204]\n",
      "[Epoch 39/200] [Batch 340/637] [D loss: 0.166490] [G loss: 0.490615]\n",
      "[Epoch 39/200] [Batch 341/637] [D loss: 0.151685] [G loss: 0.516146]\n",
      "[Epoch 39/200] [Batch 342/637] [D loss: 0.162287] [G loss: 0.473548]\n",
      "[Epoch 39/200] [Batch 343/637] [D loss: 0.177905] [G loss: 0.455530]\n",
      "[Epoch 39/200] [Batch 344/637] [D loss: 0.204542] [G loss: 0.475021]\n",
      "[Epoch 39/200] [Batch 345/637] [D loss: 0.153321] [G loss: 0.559311]\n",
      "[Epoch 39/200] [Batch 346/637] [D loss: 0.189882] [G loss: 0.456306]\n",
      "[Epoch 39/200] [Batch 347/637] [D loss: 0.189352] [G loss: 0.547231]\n",
      "[Epoch 39/200] [Batch 348/637] [D loss: 0.173295] [G loss: 0.485498]\n",
      "[Epoch 39/200] [Batch 349/637] [D loss: 0.216569] [G loss: 0.397546]\n",
      "[Epoch 39/200] [Batch 350/637] [D loss: 0.174313] [G loss: 0.523310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/200] [Batch 351/637] [D loss: 0.199761] [G loss: 0.515153]\n",
      "[Epoch 39/200] [Batch 352/637] [D loss: 0.186193] [G loss: 0.464508]\n",
      "[Epoch 39/200] [Batch 353/637] [D loss: 0.184176] [G loss: 0.491367]\n",
      "[Epoch 39/200] [Batch 354/637] [D loss: 0.160249] [G loss: 0.538582]\n",
      "[Epoch 39/200] [Batch 355/637] [D loss: 0.184088] [G loss: 0.538700]\n",
      "[Epoch 39/200] [Batch 356/637] [D loss: 0.179908] [G loss: 0.493868]\n",
      "[Epoch 39/200] [Batch 357/637] [D loss: 0.158390] [G loss: 0.486082]\n",
      "[Epoch 39/200] [Batch 358/637] [D loss: 0.166232] [G loss: 0.519596]\n",
      "[Epoch 39/200] [Batch 359/637] [D loss: 0.151391] [G loss: 0.505881]\n",
      "[Epoch 39/200] [Batch 360/637] [D loss: 0.163806] [G loss: 0.504567]\n",
      "[Epoch 39/200] [Batch 361/637] [D loss: 0.157105] [G loss: 0.462723]\n",
      "[Epoch 39/200] [Batch 362/637] [D loss: 0.176100] [G loss: 0.446368]\n",
      "[Epoch 39/200] [Batch 363/637] [D loss: 0.180108] [G loss: 0.479851]\n",
      "[Epoch 39/200] [Batch 364/637] [D loss: 0.185797] [G loss: 0.506608]\n",
      "[Epoch 39/200] [Batch 365/637] [D loss: 0.163892] [G loss: 0.511552]\n",
      "[Epoch 39/200] [Batch 366/637] [D loss: 0.157772] [G loss: 0.507871]\n",
      "[Epoch 39/200] [Batch 367/637] [D loss: 0.177480] [G loss: 0.506769]\n",
      "[Epoch 39/200] [Batch 368/637] [D loss: 0.151803] [G loss: 0.549489]\n",
      "[Epoch 39/200] [Batch 369/637] [D loss: 0.151501] [G loss: 0.532810]\n",
      "[Epoch 39/200] [Batch 370/637] [D loss: 0.177852] [G loss: 0.475434]\n",
      "[Epoch 39/200] [Batch 371/637] [D loss: 0.173118] [G loss: 0.447741]\n",
      "[Epoch 39/200] [Batch 372/637] [D loss: 0.166474] [G loss: 0.480324]\n",
      "[Epoch 39/200] [Batch 373/637] [D loss: 0.183156] [G loss: 0.472137]\n",
      "[Epoch 39/200] [Batch 374/637] [D loss: 0.165635] [G loss: 0.471642]\n",
      "[Epoch 39/200] [Batch 375/637] [D loss: 0.178673] [G loss: 0.466863]\n",
      "[Epoch 39/200] [Batch 376/637] [D loss: 0.180527] [G loss: 0.431424]\n",
      "[Epoch 39/200] [Batch 377/637] [D loss: 0.168798] [G loss: 0.474011]\n",
      "[Epoch 39/200] [Batch 378/637] [D loss: 0.155038] [G loss: 0.492264]\n",
      "[Epoch 39/200] [Batch 379/637] [D loss: 0.167429] [G loss: 0.495815]\n",
      "[Epoch 39/200] [Batch 380/637] [D loss: 0.163794] [G loss: 0.438227]\n",
      "[Epoch 39/200] [Batch 381/637] [D loss: 0.195623] [G loss: 0.478003]\n",
      "[Epoch 39/200] [Batch 382/637] [D loss: 0.147201] [G loss: 0.544427]\n",
      "[Epoch 39/200] [Batch 383/637] [D loss: 0.181583] [G loss: 0.528808]\n",
      "[Epoch 39/200] [Batch 384/637] [D loss: 0.176812] [G loss: 0.499857]\n",
      "[Epoch 39/200] [Batch 385/637] [D loss: 0.186741] [G loss: 0.424404]\n",
      "[Epoch 39/200] [Batch 386/637] [D loss: 0.165157] [G loss: 0.472493]\n",
      "[Epoch 39/200] [Batch 387/637] [D loss: 0.170343] [G loss: 0.438491]\n",
      "[Epoch 39/200] [Batch 388/637] [D loss: 0.178053] [G loss: 0.493570]\n",
      "[Epoch 39/200] [Batch 389/637] [D loss: 0.162674] [G loss: 0.493208]\n",
      "[Epoch 39/200] [Batch 390/637] [D loss: 0.171319] [G loss: 0.428048]\n",
      "[Epoch 39/200] [Batch 391/637] [D loss: 0.174253] [G loss: 0.459059]\n",
      "[Epoch 39/200] [Batch 392/637] [D loss: 0.178808] [G loss: 0.532435]\n",
      "[Epoch 39/200] [Batch 393/637] [D loss: 0.151193] [G loss: 0.526924]\n",
      "[Epoch 39/200] [Batch 394/637] [D loss: 0.191518] [G loss: 0.450175]\n",
      "[Epoch 39/200] [Batch 395/637] [D loss: 0.185984] [G loss: 0.429321]\n",
      "[Epoch 39/200] [Batch 396/637] [D loss: 0.193484] [G loss: 0.468033]\n",
      "[Epoch 39/200] [Batch 397/637] [D loss: 0.171925] [G loss: 0.490062]\n",
      "[Epoch 39/200] [Batch 398/637] [D loss: 0.184076] [G loss: 0.477634]\n",
      "[Epoch 39/200] [Batch 399/637] [D loss: 0.168263] [G loss: 0.457578]\n",
      "[Epoch 39/200] [Batch 400/637] [D loss: 0.174285] [G loss: 0.423540]\n",
      "[Epoch 39/200] [Batch 401/637] [D loss: 0.194886] [G loss: 0.440756]\n",
      "[Epoch 39/200] [Batch 402/637] [D loss: 0.174168] [G loss: 0.469269]\n",
      "[Epoch 39/200] [Batch 403/637] [D loss: 0.190252] [G loss: 0.454140]\n",
      "[Epoch 39/200] [Batch 404/637] [D loss: 0.152374] [G loss: 0.507646]\n",
      "[Epoch 39/200] [Batch 405/637] [D loss: 0.170662] [G loss: 0.417744]\n",
      "[Epoch 39/200] [Batch 406/637] [D loss: 0.165092] [G loss: 0.497095]\n",
      "[Epoch 39/200] [Batch 407/637] [D loss: 0.186468] [G loss: 0.465648]\n",
      "[Epoch 39/200] [Batch 408/637] [D loss: 0.190765] [G loss: 0.508090]\n",
      "[Epoch 39/200] [Batch 409/637] [D loss: 0.177213] [G loss: 0.528266]\n",
      "[Epoch 39/200] [Batch 410/637] [D loss: 0.209520] [G loss: 0.486574]\n",
      "[Epoch 39/200] [Batch 411/637] [D loss: 0.217620] [G loss: 0.397023]\n",
      "[Epoch 39/200] [Batch 412/637] [D loss: 0.193503] [G loss: 0.547031]\n",
      "[Epoch 39/200] [Batch 413/637] [D loss: 0.178165] [G loss: 0.605992]\n",
      "[Epoch 39/200] [Batch 414/637] [D loss: 0.140547] [G loss: 0.593250]\n",
      "[Epoch 39/200] [Batch 415/637] [D loss: 0.161043] [G loss: 0.502332]\n",
      "[Epoch 39/200] [Batch 416/637] [D loss: 0.165727] [G loss: 0.465034]\n",
      "[Epoch 39/200] [Batch 417/637] [D loss: 0.175800] [G loss: 0.538014]\n",
      "[Epoch 39/200] [Batch 418/637] [D loss: 0.180279] [G loss: 0.500995]\n",
      "[Epoch 39/200] [Batch 419/637] [D loss: 0.177374] [G loss: 0.525465]\n",
      "[Epoch 39/200] [Batch 420/637] [D loss: 0.170663] [G loss: 0.479600]\n",
      "[Epoch 39/200] [Batch 421/637] [D loss: 0.170433] [G loss: 0.474682]\n",
      "[Epoch 39/200] [Batch 422/637] [D loss: 0.170280] [G loss: 0.475181]\n",
      "[Epoch 39/200] [Batch 423/637] [D loss: 0.174798] [G loss: 0.459237]\n",
      "[Epoch 39/200] [Batch 424/637] [D loss: 0.159042] [G loss: 0.492504]\n",
      "[Epoch 39/200] [Batch 425/637] [D loss: 0.179499] [G loss: 0.470079]\n",
      "[Epoch 39/200] [Batch 426/637] [D loss: 0.166078] [G loss: 0.516087]\n",
      "[Epoch 39/200] [Batch 427/637] [D loss: 0.176312] [G loss: 0.433580]\n",
      "[Epoch 39/200] [Batch 428/637] [D loss: 0.194414] [G loss: 0.511886]\n",
      "[Epoch 39/200] [Batch 429/637] [D loss: 0.154409] [G loss: 0.569406]\n",
      "[Epoch 39/200] [Batch 430/637] [D loss: 0.180029] [G loss: 0.568968]\n",
      "[Epoch 39/200] [Batch 431/637] [D loss: 0.173774] [G loss: 0.481297]\n",
      "[Epoch 39/200] [Batch 432/637] [D loss: 0.173850] [G loss: 0.447866]\n",
      "[Epoch 39/200] [Batch 433/637] [D loss: 0.196573] [G loss: 0.441767]\n",
      "[Epoch 39/200] [Batch 434/637] [D loss: 0.166079] [G loss: 0.473193]\n",
      "[Epoch 39/200] [Batch 435/637] [D loss: 0.174580] [G loss: 0.500437]\n",
      "[Epoch 39/200] [Batch 436/637] [D loss: 0.160502] [G loss: 0.476226]\n",
      "[Epoch 39/200] [Batch 437/637] [D loss: 0.178071] [G loss: 0.523433]\n",
      "[Epoch 39/200] [Batch 438/637] [D loss: 0.170966] [G loss: 0.485408]\n",
      "[Epoch 39/200] [Batch 439/637] [D loss: 0.155687] [G loss: 0.533990]\n",
      "[Epoch 39/200] [Batch 440/637] [D loss: 0.159189] [G loss: 0.468558]\n",
      "[Epoch 39/200] [Batch 441/637] [D loss: 0.179003] [G loss: 0.497157]\n",
      "[Epoch 39/200] [Batch 442/637] [D loss: 0.171267] [G loss: 0.493819]\n",
      "[Epoch 39/200] [Batch 443/637] [D loss: 0.164151] [G loss: 0.489832]\n",
      "[Epoch 39/200] [Batch 444/637] [D loss: 0.132944] [G loss: 0.495625]\n",
      "[Epoch 39/200] [Batch 445/637] [D loss: 0.161998] [G loss: 0.421740]\n",
      "[Epoch 39/200] [Batch 446/637] [D loss: 0.156002] [G loss: 0.465753]\n",
      "[Epoch 39/200] [Batch 447/637] [D loss: 0.165031] [G loss: 0.530840]\n",
      "[Epoch 39/200] [Batch 448/637] [D loss: 0.183323] [G loss: 0.507671]\n",
      "[Epoch 39/200] [Batch 449/637] [D loss: 0.159300] [G loss: 0.443825]\n",
      "[Epoch 39/200] [Batch 450/637] [D loss: 0.163834] [G loss: 0.489683]\n",
      "[Epoch 39/200] [Batch 451/637] [D loss: 0.192308] [G loss: 0.446778]\n",
      "[Epoch 39/200] [Batch 452/637] [D loss: 0.165195] [G loss: 0.523147]\n",
      "[Epoch 39/200] [Batch 453/637] [D loss: 0.155256] [G loss: 0.616977]\n",
      "[Epoch 39/200] [Batch 454/637] [D loss: 0.181013] [G loss: 0.516073]\n",
      "[Epoch 39/200] [Batch 455/637] [D loss: 0.166455] [G loss: 0.506845]\n",
      "[Epoch 39/200] [Batch 456/637] [D loss: 0.174365] [G loss: 0.437223]\n",
      "[Epoch 39/200] [Batch 457/637] [D loss: 0.193812] [G loss: 0.471892]\n",
      "[Epoch 39/200] [Batch 458/637] [D loss: 0.172867] [G loss: 0.471454]\n",
      "[Epoch 39/200] [Batch 459/637] [D loss: 0.183258] [G loss: 0.477455]\n",
      "[Epoch 39/200] [Batch 460/637] [D loss: 0.171723] [G loss: 0.475327]\n",
      "[Epoch 39/200] [Batch 461/637] [D loss: 0.161276] [G loss: 0.471456]\n",
      "[Epoch 39/200] [Batch 462/637] [D loss: 0.157412] [G loss: 0.466817]\n",
      "[Epoch 39/200] [Batch 463/637] [D loss: 0.161342] [G loss: 0.522977]\n",
      "[Epoch 39/200] [Batch 464/637] [D loss: 0.181691] [G loss: 0.435311]\n",
      "[Epoch 39/200] [Batch 465/637] [D loss: 0.169743] [G loss: 0.527032]\n",
      "[Epoch 39/200] [Batch 466/637] [D loss: 0.175416] [G loss: 0.506823]\n",
      "[Epoch 39/200] [Batch 467/637] [D loss: 0.157429] [G loss: 0.520654]\n",
      "[Epoch 39/200] [Batch 468/637] [D loss: 0.168377] [G loss: 0.480935]\n",
      "[Epoch 39/200] [Batch 469/637] [D loss: 0.170956] [G loss: 0.529368]\n",
      "[Epoch 39/200] [Batch 470/637] [D loss: 0.160592] [G loss: 0.498511]\n",
      "[Epoch 39/200] [Batch 471/637] [D loss: 0.195868] [G loss: 0.444634]\n",
      "[Epoch 39/200] [Batch 472/637] [D loss: 0.169020] [G loss: 0.534408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/200] [Batch 473/637] [D loss: 0.184750] [G loss: 0.427894]\n",
      "[Epoch 39/200] [Batch 474/637] [D loss: 0.188069] [G loss: 0.481805]\n",
      "[Epoch 39/200] [Batch 475/637] [D loss: 0.177837] [G loss: 0.435854]\n",
      "[Epoch 39/200] [Batch 476/637] [D loss: 0.162237] [G loss: 0.518682]\n",
      "[Epoch 39/200] [Batch 477/637] [D loss: 0.175507] [G loss: 0.496612]\n",
      "[Epoch 39/200] [Batch 478/637] [D loss: 0.190122] [G loss: 0.515196]\n",
      "[Epoch 39/200] [Batch 479/637] [D loss: 0.173373] [G loss: 0.540022]\n",
      "[Epoch 39/200] [Batch 480/637] [D loss: 0.169951] [G loss: 0.480106]\n",
      "[Epoch 39/200] [Batch 481/637] [D loss: 0.165629] [G loss: 0.429982]\n",
      "[Epoch 39/200] [Batch 482/637] [D loss: 0.165847] [G loss: 0.503532]\n",
      "[Epoch 39/200] [Batch 483/637] [D loss: 0.161187] [G loss: 0.473175]\n",
      "[Epoch 39/200] [Batch 484/637] [D loss: 0.186827] [G loss: 0.464688]\n",
      "[Epoch 39/200] [Batch 485/637] [D loss: 0.161798] [G loss: 0.532520]\n",
      "[Epoch 39/200] [Batch 486/637] [D loss: 0.173865] [G loss: 0.513709]\n",
      "[Epoch 39/200] [Batch 487/637] [D loss: 0.182758] [G loss: 0.506685]\n",
      "[Epoch 39/200] [Batch 488/637] [D loss: 0.174655] [G loss: 0.446095]\n",
      "[Epoch 39/200] [Batch 489/637] [D loss: 0.205660] [G loss: 0.418653]\n",
      "[Epoch 39/200] [Batch 490/637] [D loss: 0.185240] [G loss: 0.457729]\n",
      "[Epoch 39/200] [Batch 491/637] [D loss: 0.181751] [G loss: 0.492330]\n",
      "[Epoch 39/200] [Batch 492/637] [D loss: 0.171536] [G loss: 0.513154]\n",
      "[Epoch 39/200] [Batch 493/637] [D loss: 0.186814] [G loss: 0.436654]\n",
      "[Epoch 39/200] [Batch 494/637] [D loss: 0.172351] [G loss: 0.420365]\n",
      "[Epoch 39/200] [Batch 495/637] [D loss: 0.172724] [G loss: 0.454571]\n",
      "[Epoch 39/200] [Batch 496/637] [D loss: 0.186950] [G loss: 0.422655]\n",
      "[Epoch 39/200] [Batch 497/637] [D loss: 0.168877] [G loss: 0.439556]\n",
      "[Epoch 39/200] [Batch 498/637] [D loss: 0.182351] [G loss: 0.435358]\n",
      "[Epoch 39/200] [Batch 499/637] [D loss: 0.158884] [G loss: 0.506329]\n",
      "[Epoch 39/200] [Batch 500/637] [D loss: 0.168054] [G loss: 0.455587]\n",
      "[Epoch 39/200] [Batch 501/637] [D loss: 0.189314] [G loss: 0.466784]\n",
      "[Epoch 39/200] [Batch 502/637] [D loss: 0.162027] [G loss: 0.487205]\n",
      "[Epoch 39/200] [Batch 503/637] [D loss: 0.175828] [G loss: 0.454571]\n",
      "[Epoch 39/200] [Batch 504/637] [D loss: 0.170172] [G loss: 0.454575]\n",
      "[Epoch 39/200] [Batch 505/637] [D loss: 0.181971] [G loss: 0.441901]\n",
      "[Epoch 39/200] [Batch 506/637] [D loss: 0.159936] [G loss: 0.460307]\n",
      "[Epoch 39/200] [Batch 507/637] [D loss: 0.170409] [G loss: 0.521152]\n",
      "[Epoch 39/200] [Batch 508/637] [D loss: 0.193455] [G loss: 0.464135]\n",
      "[Epoch 39/200] [Batch 509/637] [D loss: 0.180509] [G loss: 0.470634]\n",
      "[Epoch 39/200] [Batch 510/637] [D loss: 0.163338] [G loss: 0.529912]\n",
      "[Epoch 39/200] [Batch 511/637] [D loss: 0.178911] [G loss: 0.451557]\n",
      "[Epoch 39/200] [Batch 512/637] [D loss: 0.167622] [G loss: 0.454571]\n",
      "[Epoch 39/200] [Batch 513/637] [D loss: 0.177929] [G loss: 0.508080]\n",
      "[Epoch 39/200] [Batch 514/637] [D loss: 0.170277] [G loss: 0.482644]\n",
      "[Epoch 39/200] [Batch 515/637] [D loss: 0.195108] [G loss: 0.496274]\n",
      "[Epoch 39/200] [Batch 516/637] [D loss: 0.165939] [G loss: 0.523449]\n",
      "[Epoch 39/200] [Batch 517/637] [D loss: 0.177252] [G loss: 0.541476]\n",
      "[Epoch 39/200] [Batch 518/637] [D loss: 0.185927] [G loss: 0.499612]\n",
      "[Epoch 39/200] [Batch 519/637] [D loss: 0.179820] [G loss: 0.447769]\n",
      "[Epoch 39/200] [Batch 520/637] [D loss: 0.169968] [G loss: 0.507713]\n",
      "[Epoch 39/200] [Batch 521/637] [D loss: 0.180629] [G loss: 0.509548]\n",
      "[Epoch 39/200] [Batch 522/637] [D loss: 0.160896] [G loss: 0.590050]\n",
      "[Epoch 39/200] [Batch 523/637] [D loss: 0.175385] [G loss: 0.489250]\n",
      "[Epoch 39/200] [Batch 524/637] [D loss: 0.184228] [G loss: 0.458009]\n",
      "[Epoch 39/200] [Batch 525/637] [D loss: 0.174162] [G loss: 0.506041]\n",
      "[Epoch 39/200] [Batch 526/637] [D loss: 0.187270] [G loss: 0.475797]\n",
      "[Epoch 39/200] [Batch 527/637] [D loss: 0.170917] [G loss: 0.476192]\n",
      "[Epoch 39/200] [Batch 528/637] [D loss: 0.170954] [G loss: 0.460147]\n",
      "[Epoch 39/200] [Batch 529/637] [D loss: 0.164039] [G loss: 0.489071]\n",
      "[Epoch 39/200] [Batch 530/637] [D loss: 0.158923] [G loss: 0.534045]\n",
      "[Epoch 39/200] [Batch 531/637] [D loss: 0.182319] [G loss: 0.467803]\n",
      "[Epoch 39/200] [Batch 532/637] [D loss: 0.166715] [G loss: 0.488012]\n",
      "[Epoch 39/200] [Batch 533/637] [D loss: 0.166044] [G loss: 0.565885]\n",
      "[Epoch 39/200] [Batch 534/637] [D loss: 0.150576] [G loss: 0.494418]\n",
      "[Epoch 39/200] [Batch 535/637] [D loss: 0.154634] [G loss: 0.447779]\n",
      "[Epoch 39/200] [Batch 536/637] [D loss: 0.162572] [G loss: 0.514782]\n",
      "[Epoch 39/200] [Batch 537/637] [D loss: 0.176201] [G loss: 0.467182]\n",
      "[Epoch 39/200] [Batch 538/637] [D loss: 0.184469] [G loss: 0.483249]\n",
      "[Epoch 39/200] [Batch 539/637] [D loss: 0.166564] [G loss: 0.470314]\n",
      "[Epoch 39/200] [Batch 540/637] [D loss: 0.177165] [G loss: 0.532517]\n",
      "[Epoch 39/200] [Batch 541/637] [D loss: 0.149903] [G loss: 0.522690]\n",
      "[Epoch 39/200] [Batch 542/637] [D loss: 0.180042] [G loss: 0.433602]\n",
      "[Epoch 39/200] [Batch 543/637] [D loss: 0.189554] [G loss: 0.413767]\n",
      "[Epoch 39/200] [Batch 544/637] [D loss: 0.181968] [G loss: 0.440982]\n",
      "[Epoch 39/200] [Batch 545/637] [D loss: 0.170082] [G loss: 0.476327]\n",
      "[Epoch 39/200] [Batch 546/637] [D loss: 0.190532] [G loss: 0.492453]\n",
      "[Epoch 39/200] [Batch 547/637] [D loss: 0.161782] [G loss: 0.566447]\n",
      "[Epoch 39/200] [Batch 548/637] [D loss: 0.175367] [G loss: 0.467721]\n",
      "[Epoch 39/200] [Batch 549/637] [D loss: 0.144255] [G loss: 0.584218]\n",
      "[Epoch 39/200] [Batch 550/637] [D loss: 0.175803] [G loss: 0.472851]\n",
      "[Epoch 39/200] [Batch 551/637] [D loss: 0.192027] [G loss: 0.434590]\n",
      "[Epoch 39/200] [Batch 552/637] [D loss: 0.154583] [G loss: 0.514402]\n",
      "[Epoch 39/200] [Batch 553/637] [D loss: 0.216886] [G loss: 0.513003]\n",
      "[Epoch 39/200] [Batch 554/637] [D loss: 0.153794] [G loss: 0.556037]\n",
      "[Epoch 39/200] [Batch 555/637] [D loss: 0.206389] [G loss: 0.493514]\n",
      "[Epoch 39/200] [Batch 556/637] [D loss: 0.147375] [G loss: 0.563374]\n",
      "[Epoch 39/200] [Batch 557/637] [D loss: 0.164186] [G loss: 0.545543]\n",
      "[Epoch 39/200] [Batch 558/637] [D loss: 0.174188] [G loss: 0.477672]\n",
      "[Epoch 39/200] [Batch 559/637] [D loss: 0.155442] [G loss: 0.499257]\n",
      "[Epoch 39/200] [Batch 560/637] [D loss: 0.162628] [G loss: 0.483613]\n",
      "[Epoch 39/200] [Batch 561/637] [D loss: 0.175792] [G loss: 0.551489]\n",
      "[Epoch 39/200] [Batch 562/637] [D loss: 0.174390] [G loss: 0.477021]\n",
      "[Epoch 39/200] [Batch 563/637] [D loss: 0.150546] [G loss: 0.476673]\n",
      "[Epoch 39/200] [Batch 564/637] [D loss: 0.172390] [G loss: 0.464617]\n",
      "[Epoch 39/200] [Batch 565/637] [D loss: 0.156313] [G loss: 0.487080]\n",
      "[Epoch 39/200] [Batch 566/637] [D loss: 0.183068] [G loss: 0.619709]\n",
      "[Epoch 39/200] [Batch 567/637] [D loss: 0.148632] [G loss: 0.521925]\n",
      "[Epoch 39/200] [Batch 568/637] [D loss: 0.157523] [G loss: 0.490723]\n",
      "[Epoch 39/200] [Batch 569/637] [D loss: 0.158213] [G loss: 0.486997]\n",
      "[Epoch 39/200] [Batch 570/637] [D loss: 0.156533] [G loss: 0.545584]\n",
      "[Epoch 39/200] [Batch 571/637] [D loss: 0.155925] [G loss: 0.502373]\n",
      "[Epoch 39/200] [Batch 572/637] [D loss: 0.183146] [G loss: 0.494112]\n",
      "[Epoch 39/200] [Batch 573/637] [D loss: 0.184728] [G loss: 0.597976]\n",
      "[Epoch 39/200] [Batch 574/637] [D loss: 0.172173] [G loss: 0.503705]\n",
      "[Epoch 39/200] [Batch 575/637] [D loss: 0.172056] [G loss: 0.421482]\n",
      "[Epoch 39/200] [Batch 576/637] [D loss: 0.173649] [G loss: 0.529193]\n",
      "[Epoch 39/200] [Batch 577/637] [D loss: 0.180343] [G loss: 0.472412]\n",
      "[Epoch 39/200] [Batch 578/637] [D loss: 0.157990] [G loss: 0.550383]\n",
      "[Epoch 39/200] [Batch 579/637] [D loss: 0.150216] [G loss: 0.557656]\n",
      "[Epoch 39/200] [Batch 580/637] [D loss: 0.196064] [G loss: 0.454563]\n",
      "[Epoch 39/200] [Batch 581/637] [D loss: 0.184612] [G loss: 0.428464]\n",
      "[Epoch 39/200] [Batch 582/637] [D loss: 0.148679] [G loss: 0.538254]\n",
      "[Epoch 39/200] [Batch 583/637] [D loss: 0.154334] [G loss: 0.506642]\n",
      "[Epoch 39/200] [Batch 584/637] [D loss: 0.173497] [G loss: 0.454724]\n",
      "[Epoch 39/200] [Batch 585/637] [D loss: 0.161798] [G loss: 0.531693]\n",
      "[Epoch 39/200] [Batch 586/637] [D loss: 0.156193] [G loss: 0.488530]\n",
      "[Epoch 39/200] [Batch 587/637] [D loss: 0.189304] [G loss: 0.468812]\n",
      "[Epoch 39/200] [Batch 588/637] [D loss: 0.155250] [G loss: 0.530087]\n",
      "[Epoch 39/200] [Batch 589/637] [D loss: 0.170306] [G loss: 0.481978]\n",
      "[Epoch 39/200] [Batch 590/637] [D loss: 0.168291] [G loss: 0.409823]\n",
      "[Epoch 39/200] [Batch 591/637] [D loss: 0.175686] [G loss: 0.382746]\n",
      "[Epoch 39/200] [Batch 592/637] [D loss: 0.187324] [G loss: 0.429133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/200] [Batch 593/637] [D loss: 0.167522] [G loss: 0.449905]\n",
      "[Epoch 39/200] [Batch 594/637] [D loss: 0.161334] [G loss: 0.545985]\n",
      "[Epoch 39/200] [Batch 595/637] [D loss: 0.192713] [G loss: 0.519082]\n",
      "[Epoch 39/200] [Batch 596/637] [D loss: 0.162292] [G loss: 0.507181]\n",
      "[Epoch 39/200] [Batch 597/637] [D loss: 0.141213] [G loss: 0.572558]\n",
      "[Epoch 39/200] [Batch 598/637] [D loss: 0.174359] [G loss: 0.507398]\n",
      "[Epoch 39/200] [Batch 599/637] [D loss: 0.177604] [G loss: 0.430871]\n",
      "[Epoch 39/200] [Batch 600/637] [D loss: 0.162995] [G loss: 0.532753]\n",
      "[Epoch 39/200] [Batch 601/637] [D loss: 0.150589] [G loss: 0.510280]\n",
      "[Epoch 39/200] [Batch 602/637] [D loss: 0.141885] [G loss: 0.508863]\n",
      "[Epoch 39/200] [Batch 603/637] [D loss: 0.158101] [G loss: 0.444323]\n",
      "[Epoch 39/200] [Batch 604/637] [D loss: 0.179956] [G loss: 0.448132]\n",
      "[Epoch 39/200] [Batch 605/637] [D loss: 0.171676] [G loss: 0.522690]\n",
      "[Epoch 39/200] [Batch 606/637] [D loss: 0.154738] [G loss: 0.481404]\n",
      "[Epoch 39/200] [Batch 607/637] [D loss: 0.163983] [G loss: 0.557874]\n",
      "[Epoch 39/200] [Batch 608/637] [D loss: 0.162967] [G loss: 0.549586]\n",
      "[Epoch 39/200] [Batch 609/637] [D loss: 0.164520] [G loss: 0.499850]\n",
      "[Epoch 39/200] [Batch 610/637] [D loss: 0.174352] [G loss: 0.431712]\n",
      "[Epoch 39/200] [Batch 611/637] [D loss: 0.173038] [G loss: 0.466227]\n",
      "[Epoch 39/200] [Batch 612/637] [D loss: 0.160105] [G loss: 0.504916]\n",
      "[Epoch 39/200] [Batch 613/637] [D loss: 0.171615] [G loss: 0.537074]\n",
      "[Epoch 39/200] [Batch 614/637] [D loss: 0.168683] [G loss: 0.466333]\n",
      "[Epoch 39/200] [Batch 615/637] [D loss: 0.171216] [G loss: 0.468368]\n",
      "[Epoch 39/200] [Batch 616/637] [D loss: 0.178336] [G loss: 0.526426]\n",
      "[Epoch 39/200] [Batch 617/637] [D loss: 0.148831] [G loss: 0.514197]\n",
      "[Epoch 39/200] [Batch 618/637] [D loss: 0.243691] [G loss: 0.553668]\n",
      "[Epoch 39/200] [Batch 619/637] [D loss: 0.199883] [G loss: 0.568307]\n",
      "[Epoch 39/200] [Batch 620/637] [D loss: 0.170826] [G loss: 0.573386]\n",
      "[Epoch 39/200] [Batch 621/637] [D loss: 0.174845] [G loss: 0.489673]\n",
      "[Epoch 39/200] [Batch 622/637] [D loss: 0.157030] [G loss: 0.443477]\n",
      "[Epoch 39/200] [Batch 623/637] [D loss: 0.154450] [G loss: 0.504760]\n",
      "[Epoch 39/200] [Batch 624/637] [D loss: 0.148064] [G loss: 0.559685]\n",
      "[Epoch 39/200] [Batch 625/637] [D loss: 0.149285] [G loss: 0.486892]\n",
      "[Epoch 39/200] [Batch 626/637] [D loss: 0.153279] [G loss: 0.522192]\n",
      "[Epoch 39/200] [Batch 627/637] [D loss: 0.198749] [G loss: 0.396244]\n",
      "[Epoch 39/200] [Batch 628/637] [D loss: 0.165030] [G loss: 0.484205]\n",
      "[Epoch 39/200] [Batch 629/637] [D loss: 0.180390] [G loss: 0.463165]\n",
      "[Epoch 39/200] [Batch 630/637] [D loss: 0.161657] [G loss: 0.530747]\n",
      "[Epoch 39/200] [Batch 631/637] [D loss: 0.168448] [G loss: 0.503509]\n",
      "[Epoch 39/200] [Batch 632/637] [D loss: 0.174413] [G loss: 0.537746]\n",
      "[Epoch 39/200] [Batch 633/637] [D loss: 0.178488] [G loss: 0.486128]\n",
      "[Epoch 39/200] [Batch 634/637] [D loss: 0.189929] [G loss: 0.439439]\n",
      "[Epoch 39/200] [Batch 635/637] [D loss: 0.151129] [G loss: 0.505033]\n",
      "[Epoch 39/200] [Batch 636/637] [D loss: 0.209201] [G loss: 0.583990]\n",
      "[Epoch 40/200] [Batch 0/637] [D loss: 0.166455] [G loss: 0.510192]\n",
      "[Epoch 40/200] [Batch 1/637] [D loss: 0.201544] [G loss: 0.442052]\n",
      "[Epoch 40/200] [Batch 2/637] [D loss: 0.171371] [G loss: 0.453308]\n",
      "[Epoch 40/200] [Batch 3/637] [D loss: 0.166199] [G loss: 0.526168]\n",
      "[Epoch 40/200] [Batch 4/637] [D loss: 0.192177] [G loss: 0.495532]\n",
      "[Epoch 40/200] [Batch 5/637] [D loss: 0.154507] [G loss: 0.505195]\n",
      "[Epoch 40/200] [Batch 6/637] [D loss: 0.173694] [G loss: 0.484628]\n",
      "[Epoch 40/200] [Batch 7/637] [D loss: 0.167631] [G loss: 0.544149]\n",
      "[Epoch 40/200] [Batch 8/637] [D loss: 0.167743] [G loss: 0.517410]\n",
      "[Epoch 40/200] [Batch 9/637] [D loss: 0.179744] [G loss: 0.520163]\n",
      "[Epoch 40/200] [Batch 10/637] [D loss: 0.161848] [G loss: 0.512944]\n",
      "[Epoch 40/200] [Batch 11/637] [D loss: 0.176958] [G loss: 0.531095]\n",
      "[Epoch 40/200] [Batch 12/637] [D loss: 0.179487] [G loss: 0.560687]\n",
      "[Epoch 40/200] [Batch 13/637] [D loss: 0.179653] [G loss: 0.471640]\n",
      "[Epoch 40/200] [Batch 14/637] [D loss: 0.165649] [G loss: 0.406898]\n",
      "[Epoch 40/200] [Batch 15/637] [D loss: 0.189433] [G loss: 0.456417]\n",
      "[Epoch 40/200] [Batch 16/637] [D loss: 0.161637] [G loss: 0.568929]\n",
      "[Epoch 40/200] [Batch 17/637] [D loss: 0.164642] [G loss: 0.561782]\n",
      "[Epoch 40/200] [Batch 18/637] [D loss: 0.178257] [G loss: 0.491789]\n",
      "[Epoch 40/200] [Batch 19/637] [D loss: 0.170968] [G loss: 0.527498]\n",
      "[Epoch 40/200] [Batch 20/637] [D loss: 0.182554] [G loss: 0.431909]\n",
      "[Epoch 40/200] [Batch 21/637] [D loss: 0.176251] [G loss: 0.488675]\n",
      "[Epoch 40/200] [Batch 22/637] [D loss: 0.193245] [G loss: 0.480235]\n",
      "[Epoch 40/200] [Batch 23/637] [D loss: 0.169263] [G loss: 0.514826]\n",
      "[Epoch 40/200] [Batch 24/637] [D loss: 0.172087] [G loss: 0.454613]\n",
      "[Epoch 40/200] [Batch 25/637] [D loss: 0.162816] [G loss: 0.451352]\n",
      "[Epoch 40/200] [Batch 26/637] [D loss: 0.175688] [G loss: 0.443774]\n",
      "[Epoch 40/200] [Batch 27/637] [D loss: 0.187329] [G loss: 0.464573]\n",
      "[Epoch 40/200] [Batch 28/637] [D loss: 0.202737] [G loss: 0.512568]\n",
      "[Epoch 40/200] [Batch 29/637] [D loss: 0.180673] [G loss: 0.487258]\n",
      "[Epoch 40/200] [Batch 30/637] [D loss: 0.188065] [G loss: 0.432898]\n",
      "[Epoch 40/200] [Batch 31/637] [D loss: 0.180401] [G loss: 0.407796]\n",
      "[Epoch 40/200] [Batch 32/637] [D loss: 0.154493] [G loss: 0.456693]\n",
      "[Epoch 40/200] [Batch 33/637] [D loss: 0.180831] [G loss: 0.440313]\n",
      "[Epoch 40/200] [Batch 34/637] [D loss: 0.165117] [G loss: 0.448075]\n",
      "[Epoch 40/200] [Batch 35/637] [D loss: 0.171028] [G loss: 0.465833]\n",
      "[Epoch 40/200] [Batch 36/637] [D loss: 0.175986] [G loss: 0.391820]\n",
      "[Epoch 40/200] [Batch 37/637] [D loss: 0.162332] [G loss: 0.433327]\n",
      "[Epoch 40/200] [Batch 38/637] [D loss: 0.151253] [G loss: 0.448582]\n",
      "[Epoch 40/200] [Batch 39/637] [D loss: 0.146945] [G loss: 0.508903]\n",
      "[Epoch 40/200] [Batch 40/637] [D loss: 0.163858] [G loss: 0.525852]\n",
      "[Epoch 40/200] [Batch 41/637] [D loss: 0.157913] [G loss: 0.549309]\n",
      "[Epoch 40/200] [Batch 42/637] [D loss: 0.158439] [G loss: 0.537686]\n",
      "[Epoch 40/200] [Batch 43/637] [D loss: 0.153770] [G loss: 0.473522]\n",
      "[Epoch 40/200] [Batch 44/637] [D loss: 0.176647] [G loss: 0.448076]\n",
      "[Epoch 40/200] [Batch 45/637] [D loss: 0.177936] [G loss: 0.469674]\n",
      "[Epoch 40/200] [Batch 46/637] [D loss: 0.175038] [G loss: 0.555120]\n",
      "[Epoch 40/200] [Batch 47/637] [D loss: 0.148946] [G loss: 0.521300]\n",
      "[Epoch 40/200] [Batch 48/637] [D loss: 0.166997] [G loss: 0.500266]\n",
      "[Epoch 40/200] [Batch 49/637] [D loss: 0.151644] [G loss: 0.490987]\n",
      "[Epoch 40/200] [Batch 50/637] [D loss: 0.181664] [G loss: 0.495574]\n",
      "[Epoch 40/200] [Batch 51/637] [D loss: 0.162759] [G loss: 0.594911]\n",
      "[Epoch 40/200] [Batch 52/637] [D loss: 0.151687] [G loss: 0.534882]\n",
      "[Epoch 40/200] [Batch 53/637] [D loss: 0.169484] [G loss: 0.516550]\n",
      "[Epoch 40/200] [Batch 54/637] [D loss: 0.181119] [G loss: 0.465605]\n",
      "[Epoch 40/200] [Batch 55/637] [D loss: 0.163686] [G loss: 0.546770]\n",
      "[Epoch 40/200] [Batch 56/637] [D loss: 0.161172] [G loss: 0.534587]\n",
      "[Epoch 40/200] [Batch 57/637] [D loss: 0.185955] [G loss: 0.479587]\n",
      "[Epoch 40/200] [Batch 58/637] [D loss: 0.161990] [G loss: 0.522297]\n",
      "[Epoch 40/200] [Batch 59/637] [D loss: 0.171688] [G loss: 0.395264]\n",
      "[Epoch 40/200] [Batch 60/637] [D loss: 0.169243] [G loss: 0.532909]\n",
      "[Epoch 40/200] [Batch 61/637] [D loss: 0.192813] [G loss: 0.445637]\n",
      "[Epoch 40/200] [Batch 62/637] [D loss: 0.164102] [G loss: 0.489456]\n",
      "[Epoch 40/200] [Batch 63/637] [D loss: 0.154006] [G loss: 0.500630]\n",
      "[Epoch 40/200] [Batch 64/637] [D loss: 0.167512] [G loss: 0.453042]\n",
      "[Epoch 40/200] [Batch 65/637] [D loss: 0.144223] [G loss: 0.524476]\n",
      "[Epoch 40/200] [Batch 66/637] [D loss: 0.174773] [G loss: 0.488637]\n",
      "[Epoch 40/200] [Batch 67/637] [D loss: 0.191032] [G loss: 0.494721]\n",
      "[Epoch 40/200] [Batch 68/637] [D loss: 0.174582] [G loss: 0.505517]\n",
      "[Epoch 40/200] [Batch 69/637] [D loss: 0.166410] [G loss: 0.456128]\n",
      "[Epoch 40/200] [Batch 70/637] [D loss: 0.161201] [G loss: 0.458693]\n",
      "[Epoch 40/200] [Batch 71/637] [D loss: 0.177518] [G loss: 0.366950]\n",
      "[Epoch 40/200] [Batch 72/637] [D loss: 0.180579] [G loss: 0.489991]\n",
      "[Epoch 40/200] [Batch 73/637] [D loss: 0.175513] [G loss: 0.472992]\n",
      "[Epoch 40/200] [Batch 74/637] [D loss: 0.158993] [G loss: 0.528824]\n",
      "[Epoch 40/200] [Batch 75/637] [D loss: 0.174069] [G loss: 0.520015]\n",
      "[Epoch 40/200] [Batch 76/637] [D loss: 0.170628] [G loss: 0.452349]\n",
      "[Epoch 40/200] [Batch 77/637] [D loss: 0.197295] [G loss: 0.427286]\n",
      "[Epoch 40/200] [Batch 78/637] [D loss: 0.213546] [G loss: 0.513304]\n",
      "[Epoch 40/200] [Batch 79/637] [D loss: 0.185009] [G loss: 0.527399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/200] [Batch 80/637] [D loss: 0.177233] [G loss: 0.450062]\n",
      "[Epoch 40/200] [Batch 81/637] [D loss: 0.206497] [G loss: 0.361835]\n",
      "[Epoch 40/200] [Batch 82/637] [D loss: 0.199578] [G loss: 0.483956]\n",
      "[Epoch 40/200] [Batch 83/637] [D loss: 0.170342] [G loss: 0.531022]\n",
      "[Epoch 40/200] [Batch 84/637] [D loss: 0.166191] [G loss: 0.443254]\n",
      "[Epoch 40/200] [Batch 85/637] [D loss: 0.156102] [G loss: 0.458850]\n",
      "[Epoch 40/200] [Batch 86/637] [D loss: 0.176904] [G loss: 0.417700]\n",
      "[Epoch 40/200] [Batch 87/637] [D loss: 0.170663] [G loss: 0.435749]\n",
      "[Epoch 40/200] [Batch 88/637] [D loss: 0.184512] [G loss: 0.491928]\n",
      "[Epoch 40/200] [Batch 89/637] [D loss: 0.154581] [G loss: 0.591581]\n",
      "[Epoch 40/200] [Batch 90/637] [D loss: 0.173055] [G loss: 0.434023]\n",
      "[Epoch 40/200] [Batch 91/637] [D loss: 0.155661] [G loss: 0.448088]\n",
      "[Epoch 40/200] [Batch 92/637] [D loss: 0.170757] [G loss: 0.507280]\n",
      "[Epoch 40/200] [Batch 93/637] [D loss: 0.149051] [G loss: 0.495056]\n",
      "[Epoch 40/200] [Batch 94/637] [D loss: 0.176592] [G loss: 0.505258]\n",
      "[Epoch 40/200] [Batch 95/637] [D loss: 0.148188] [G loss: 0.534410]\n",
      "[Epoch 40/200] [Batch 96/637] [D loss: 0.188324] [G loss: 0.458676]\n",
      "[Epoch 40/200] [Batch 97/637] [D loss: 0.166177] [G loss: 0.452162]\n",
      "[Epoch 40/200] [Batch 98/637] [D loss: 0.179636] [G loss: 0.445545]\n",
      "[Epoch 40/200] [Batch 99/637] [D loss: 0.190078] [G loss: 0.485930]\n",
      "[Epoch 40/200] [Batch 100/637] [D loss: 0.175591] [G loss: 0.497331]\n",
      "[Epoch 40/200] [Batch 101/637] [D loss: 0.160782] [G loss: 0.553490]\n",
      "[Epoch 40/200] [Batch 102/637] [D loss: 0.163420] [G loss: 0.484299]\n",
      "[Epoch 40/200] [Batch 103/637] [D loss: 0.167901] [G loss: 0.482214]\n",
      "[Epoch 40/200] [Batch 104/637] [D loss: 0.155693] [G loss: 0.497789]\n",
      "[Epoch 40/200] [Batch 105/637] [D loss: 0.172923] [G loss: 0.514473]\n",
      "[Epoch 40/200] [Batch 106/637] [D loss: 0.181015] [G loss: 0.584866]\n",
      "[Epoch 40/200] [Batch 107/637] [D loss: 0.208540] [G loss: 0.520219]\n",
      "[Epoch 40/200] [Batch 108/637] [D loss: 0.129072] [G loss: 0.616068]\n",
      "[Epoch 40/200] [Batch 109/637] [D loss: 0.177739] [G loss: 0.523006]\n",
      "[Epoch 40/200] [Batch 110/637] [D loss: 0.179255] [G loss: 0.498315]\n",
      "[Epoch 40/200] [Batch 111/637] [D loss: 0.182151] [G loss: 0.440797]\n",
      "[Epoch 40/200] [Batch 112/637] [D loss: 0.128648] [G loss: 0.528741]\n",
      "[Epoch 40/200] [Batch 113/637] [D loss: 0.195153] [G loss: 0.404843]\n",
      "[Epoch 40/200] [Batch 114/637] [D loss: 0.176809] [G loss: 0.496027]\n",
      "[Epoch 40/200] [Batch 115/637] [D loss: 0.155248] [G loss: 0.602729]\n",
      "[Epoch 40/200] [Batch 116/637] [D loss: 0.190671] [G loss: 0.505432]\n",
      "[Epoch 40/200] [Batch 117/637] [D loss: 0.168323] [G loss: 0.458550]\n",
      "[Epoch 40/200] [Batch 118/637] [D loss: 0.148720] [G loss: 0.467243]\n",
      "[Epoch 40/200] [Batch 119/637] [D loss: 0.156207] [G loss: 0.505695]\n",
      "[Epoch 40/200] [Batch 120/637] [D loss: 0.153989] [G loss: 0.509667]\n",
      "[Epoch 40/200] [Batch 121/637] [D loss: 0.181620] [G loss: 0.454603]\n",
      "[Epoch 40/200] [Batch 122/637] [D loss: 0.150465] [G loss: 0.527372]\n",
      "[Epoch 40/200] [Batch 123/637] [D loss: 0.151522] [G loss: 0.513872]\n",
      "[Epoch 40/200] [Batch 124/637] [D loss: 0.164956] [G loss: 0.469997]\n",
      "[Epoch 40/200] [Batch 125/637] [D loss: 0.170470] [G loss: 0.479572]\n",
      "[Epoch 40/200] [Batch 126/637] [D loss: 0.159947] [G loss: 0.566501]\n",
      "[Epoch 40/200] [Batch 127/637] [D loss: 0.155891] [G loss: 0.550381]\n",
      "[Epoch 40/200] [Batch 128/637] [D loss: 0.181183] [G loss: 0.581548]\n",
      "[Epoch 40/200] [Batch 129/637] [D loss: 0.160868] [G loss: 0.522558]\n",
      "[Epoch 40/200] [Batch 130/637] [D loss: 0.140473] [G loss: 0.539918]\n",
      "[Epoch 40/200] [Batch 131/637] [D loss: 0.169810] [G loss: 0.509107]\n",
      "[Epoch 40/200] [Batch 132/637] [D loss: 0.157618] [G loss: 0.506862]\n",
      "[Epoch 40/200] [Batch 133/637] [D loss: 0.165117] [G loss: 0.507449]\n",
      "[Epoch 40/200] [Batch 134/637] [D loss: 0.175777] [G loss: 0.527899]\n",
      "[Epoch 40/200] [Batch 135/637] [D loss: 0.181708] [G loss: 0.542205]\n",
      "[Epoch 40/200] [Batch 136/637] [D loss: 0.162965] [G loss: 0.514759]\n",
      "[Epoch 40/200] [Batch 137/637] [D loss: 0.199958] [G loss: 0.418282]\n",
      "[Epoch 40/200] [Batch 138/637] [D loss: 0.180018] [G loss: 0.636177]\n",
      "[Epoch 40/200] [Batch 139/637] [D loss: 0.199640] [G loss: 0.569365]\n",
      "[Epoch 40/200] [Batch 140/637] [D loss: 0.187514] [G loss: 0.428393]\n",
      "[Epoch 40/200] [Batch 141/637] [D loss: 0.173545] [G loss: 0.452805]\n",
      "[Epoch 40/200] [Batch 142/637] [D loss: 0.177054] [G loss: 0.555274]\n",
      "[Epoch 40/200] [Batch 143/637] [D loss: 0.167318] [G loss: 0.481810]\n",
      "[Epoch 40/200] [Batch 144/637] [D loss: 0.152424] [G loss: 0.532817]\n",
      "[Epoch 40/200] [Batch 145/637] [D loss: 0.153097] [G loss: 0.528701]\n",
      "[Epoch 40/200] [Batch 146/637] [D loss: 0.179417] [G loss: 0.473013]\n",
      "[Epoch 40/200] [Batch 147/637] [D loss: 0.172668] [G loss: 0.571311]\n",
      "[Epoch 40/200] [Batch 148/637] [D loss: 0.154020] [G loss: 0.505139]\n",
      "[Epoch 40/200] [Batch 149/637] [D loss: 0.155052] [G loss: 0.540113]\n",
      "[Epoch 40/200] [Batch 150/637] [D loss: 0.164794] [G loss: 0.425554]\n",
      "[Epoch 40/200] [Batch 151/637] [D loss: 0.154974] [G loss: 0.500070]\n",
      "[Epoch 40/200] [Batch 152/637] [D loss: 0.137583] [G loss: 0.537260]\n",
      "[Epoch 40/200] [Batch 153/637] [D loss: 0.143720] [G loss: 0.559819]\n",
      "[Epoch 40/200] [Batch 154/637] [D loss: 0.188367] [G loss: 0.489752]\n",
      "[Epoch 40/200] [Batch 155/637] [D loss: 0.182847] [G loss: 0.512293]\n",
      "[Epoch 40/200] [Batch 156/637] [D loss: 0.155674] [G loss: 0.503020]\n",
      "[Epoch 40/200] [Batch 157/637] [D loss: 0.120263] [G loss: 0.601489]\n",
      "[Epoch 40/200] [Batch 158/637] [D loss: 0.141943] [G loss: 0.507436]\n",
      "[Epoch 40/200] [Batch 159/637] [D loss: 0.177537] [G loss: 0.462344]\n",
      "[Epoch 40/200] [Batch 160/637] [D loss: 0.172050] [G loss: 0.438749]\n",
      "[Epoch 40/200] [Batch 161/637] [D loss: 0.166723] [G loss: 0.506284]\n",
      "[Epoch 40/200] [Batch 162/637] [D loss: 0.154398] [G loss: 0.451298]\n",
      "[Epoch 40/200] [Batch 163/637] [D loss: 0.174235] [G loss: 0.411354]\n",
      "[Epoch 40/200] [Batch 164/637] [D loss: 0.175929] [G loss: 0.559470]\n",
      "[Epoch 40/200] [Batch 165/637] [D loss: 0.168496] [G loss: 0.492615]\n",
      "[Epoch 40/200] [Batch 166/637] [D loss: 0.186435] [G loss: 0.465122]\n",
      "[Epoch 40/200] [Batch 167/637] [D loss: 0.162023] [G loss: 0.539354]\n",
      "[Epoch 40/200] [Batch 168/637] [D loss: 0.170117] [G loss: 0.430321]\n",
      "[Epoch 40/200] [Batch 169/637] [D loss: 0.169952] [G loss: 0.558492]\n",
      "[Epoch 40/200] [Batch 170/637] [D loss: 0.169444] [G loss: 0.495507]\n",
      "[Epoch 40/200] [Batch 171/637] [D loss: 0.169077] [G loss: 0.448212]\n",
      "[Epoch 40/200] [Batch 172/637] [D loss: 0.194253] [G loss: 0.392872]\n",
      "[Epoch 40/200] [Batch 173/637] [D loss: 0.166670] [G loss: 0.496154]\n",
      "[Epoch 40/200] [Batch 174/637] [D loss: 0.165858] [G loss: 0.505690]\n",
      "[Epoch 40/200] [Batch 175/637] [D loss: 0.197107] [G loss: 0.424561]\n",
      "[Epoch 40/200] [Batch 176/637] [D loss: 0.169726] [G loss: 0.510226]\n",
      "[Epoch 40/200] [Batch 177/637] [D loss: 0.171852] [G loss: 0.483837]\n",
      "[Epoch 40/200] [Batch 178/637] [D loss: 0.175010] [G loss: 0.456517]\n",
      "[Epoch 40/200] [Batch 179/637] [D loss: 0.176430] [G loss: 0.442573]\n",
      "[Epoch 40/200] [Batch 180/637] [D loss: 0.172026] [G loss: 0.474086]\n",
      "[Epoch 40/200] [Batch 181/637] [D loss: 0.147153] [G loss: 0.533240]\n",
      "[Epoch 40/200] [Batch 182/637] [D loss: 0.160328] [G loss: 0.451493]\n",
      "[Epoch 40/200] [Batch 183/637] [D loss: 0.153606] [G loss: 0.547852]\n",
      "[Epoch 40/200] [Batch 184/637] [D loss: 0.186496] [G loss: 0.505955]\n",
      "[Epoch 40/200] [Batch 185/637] [D loss: 0.196506] [G loss: 0.480440]\n",
      "[Epoch 40/200] [Batch 186/637] [D loss: 0.155646] [G loss: 0.496788]\n",
      "[Epoch 40/200] [Batch 187/637] [D loss: 0.185029] [G loss: 0.423059]\n",
      "[Epoch 40/200] [Batch 188/637] [D loss: 0.176569] [G loss: 0.558251]\n",
      "[Epoch 40/200] [Batch 189/637] [D loss: 0.144806] [G loss: 0.569670]\n",
      "[Epoch 40/200] [Batch 190/637] [D loss: 0.169957] [G loss: 0.553342]\n",
      "[Epoch 40/200] [Batch 191/637] [D loss: 0.174969] [G loss: 0.449294]\n",
      "[Epoch 40/200] [Batch 192/637] [D loss: 0.164067] [G loss: 0.473800]\n",
      "[Epoch 40/200] [Batch 193/637] [D loss: 0.162559] [G loss: 0.481022]\n",
      "[Epoch 40/200] [Batch 194/637] [D loss: 0.165009] [G loss: 0.450713]\n",
      "[Epoch 40/200] [Batch 195/637] [D loss: 0.142864] [G loss: 0.560226]\n",
      "[Epoch 40/200] [Batch 196/637] [D loss: 0.173639] [G loss: 0.498936]\n",
      "[Epoch 40/200] [Batch 197/637] [D loss: 0.182687] [G loss: 0.552228]\n",
      "[Epoch 40/200] [Batch 198/637] [D loss: 0.165795] [G loss: 0.434487]\n",
      "[Epoch 40/200] [Batch 199/637] [D loss: 0.187903] [G loss: 0.419500]\n",
      "[Epoch 40/200] [Batch 200/637] [D loss: 0.160655] [G loss: 0.483568]\n",
      "[Epoch 40/200] [Batch 201/637] [D loss: 0.168111] [G loss: 0.522069]\n",
      "[Epoch 40/200] [Batch 202/637] [D loss: 0.152007] [G loss: 0.550712]\n",
      "[Epoch 40/200] [Batch 203/637] [D loss: 0.180123] [G loss: 0.465036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/200] [Batch 204/637] [D loss: 0.207952] [G loss: 0.522939]\n",
      "[Epoch 40/200] [Batch 205/637] [D loss: 0.180938] [G loss: 0.491975]\n",
      "[Epoch 40/200] [Batch 206/637] [D loss: 0.177723] [G loss: 0.511774]\n",
      "[Epoch 40/200] [Batch 207/637] [D loss: 0.160579] [G loss: 0.535876]\n",
      "[Epoch 40/200] [Batch 208/637] [D loss: 0.169130] [G loss: 0.573168]\n",
      "[Epoch 40/200] [Batch 209/637] [D loss: 0.192768] [G loss: 0.494720]\n",
      "[Epoch 40/200] [Batch 210/637] [D loss: 0.185406] [G loss: 0.393977]\n",
      "[Epoch 40/200] [Batch 211/637] [D loss: 0.173052] [G loss: 0.500707]\n",
      "[Epoch 40/200] [Batch 212/637] [D loss: 0.190091] [G loss: 0.483935]\n",
      "[Epoch 40/200] [Batch 213/637] [D loss: 0.171209] [G loss: 0.552603]\n",
      "[Epoch 40/200] [Batch 214/637] [D loss: 0.176034] [G loss: 0.472847]\n",
      "[Epoch 40/200] [Batch 215/637] [D loss: 0.151256] [G loss: 0.494901]\n",
      "[Epoch 40/200] [Batch 216/637] [D loss: 0.193339] [G loss: 0.404918]\n",
      "[Epoch 40/200] [Batch 217/637] [D loss: 0.246694] [G loss: 0.427328]\n",
      "[Epoch 40/200] [Batch 218/637] [D loss: 0.218463] [G loss: 0.537318]\n",
      "[Epoch 40/200] [Batch 219/637] [D loss: 0.210682] [G loss: 0.478591]\n",
      "[Epoch 40/200] [Batch 220/637] [D loss: 0.179553] [G loss: 0.444321]\n",
      "[Epoch 40/200] [Batch 221/637] [D loss: 0.171766] [G loss: 0.432710]\n",
      "[Epoch 40/200] [Batch 222/637] [D loss: 0.195932] [G loss: 0.432081]\n",
      "[Epoch 40/200] [Batch 223/637] [D loss: 0.184733] [G loss: 0.396984]\n",
      "[Epoch 40/200] [Batch 224/637] [D loss: 0.190724] [G loss: 0.458237]\n",
      "[Epoch 40/200] [Batch 225/637] [D loss: 0.144481] [G loss: 0.579814]\n",
      "[Epoch 40/200] [Batch 226/637] [D loss: 0.176667] [G loss: 0.530111]\n",
      "[Epoch 40/200] [Batch 227/637] [D loss: 0.208246] [G loss: 0.429925]\n",
      "[Epoch 40/200] [Batch 228/637] [D loss: 0.167318] [G loss: 0.505196]\n",
      "[Epoch 40/200] [Batch 229/637] [D loss: 0.162876] [G loss: 0.426427]\n",
      "[Epoch 40/200] [Batch 230/637] [D loss: 0.188590] [G loss: 0.410442]\n",
      "[Epoch 40/200] [Batch 231/637] [D loss: 0.171329] [G loss: 0.497705]\n",
      "[Epoch 40/200] [Batch 232/637] [D loss: 0.189086] [G loss: 0.440983]\n",
      "[Epoch 40/200] [Batch 233/637] [D loss: 0.153633] [G loss: 0.490059]\n",
      "[Epoch 40/200] [Batch 234/637] [D loss: 0.170392] [G loss: 0.498701]\n",
      "[Epoch 40/200] [Batch 235/637] [D loss: 0.191507] [G loss: 0.487435]\n",
      "[Epoch 40/200] [Batch 236/637] [D loss: 0.176419] [G loss: 0.455066]\n",
      "[Epoch 40/200] [Batch 237/637] [D loss: 0.172089] [G loss: 0.519626]\n",
      "[Epoch 40/200] [Batch 238/637] [D loss: 0.163883] [G loss: 0.459977]\n",
      "[Epoch 40/200] [Batch 239/637] [D loss: 0.153225] [G loss: 0.462565]\n",
      "[Epoch 40/200] [Batch 240/637] [D loss: 0.172962] [G loss: 0.483427]\n",
      "[Epoch 40/200] [Batch 241/637] [D loss: 0.169523] [G loss: 0.573334]\n",
      "[Epoch 40/200] [Batch 242/637] [D loss: 0.187543] [G loss: 0.460624]\n",
      "[Epoch 40/200] [Batch 243/637] [D loss: 0.181805] [G loss: 0.469881]\n",
      "[Epoch 40/200] [Batch 244/637] [D loss: 0.170412] [G loss: 0.498689]\n",
      "[Epoch 40/200] [Batch 245/637] [D loss: 0.161589] [G loss: 0.505303]\n",
      "[Epoch 40/200] [Batch 246/637] [D loss: 0.195544] [G loss: 0.487126]\n",
      "[Epoch 40/200] [Batch 247/637] [D loss: 0.181633] [G loss: 0.539285]\n",
      "[Epoch 40/200] [Batch 248/637] [D loss: 0.162297] [G loss: 0.545474]\n",
      "[Epoch 40/200] [Batch 249/637] [D loss: 0.194422] [G loss: 0.410522]\n",
      "[Epoch 40/200] [Batch 250/637] [D loss: 0.192853] [G loss: 0.409925]\n",
      "[Epoch 40/200] [Batch 251/637] [D loss: 0.178296] [G loss: 0.474258]\n",
      "[Epoch 40/200] [Batch 252/637] [D loss: 0.188009] [G loss: 0.573775]\n",
      "[Epoch 40/200] [Batch 253/637] [D loss: 0.163785] [G loss: 0.475584]\n",
      "[Epoch 40/200] [Batch 254/637] [D loss: 0.175703] [G loss: 0.416328]\n",
      "[Epoch 40/200] [Batch 255/637] [D loss: 0.188732] [G loss: 0.417515]\n",
      "[Epoch 40/200] [Batch 256/637] [D loss: 0.175819] [G loss: 0.501022]\n",
      "[Epoch 40/200] [Batch 257/637] [D loss: 0.176442] [G loss: 0.452722]\n",
      "[Epoch 40/200] [Batch 258/637] [D loss: 0.169319] [G loss: 0.470849]\n",
      "[Epoch 40/200] [Batch 259/637] [D loss: 0.217002] [G loss: 0.406789]\n",
      "[Epoch 40/200] [Batch 260/637] [D loss: 0.163803] [G loss: 0.541822]\n",
      "[Epoch 40/200] [Batch 261/637] [D loss: 0.181186] [G loss: 0.553870]\n",
      "[Epoch 40/200] [Batch 262/637] [D loss: 0.170246] [G loss: 0.624516]\n",
      "[Epoch 40/200] [Batch 263/637] [D loss: 0.191239] [G loss: 0.481581]\n",
      "[Epoch 40/200] [Batch 264/637] [D loss: 0.204798] [G loss: 0.498707]\n",
      "[Epoch 40/200] [Batch 265/637] [D loss: 0.194366] [G loss: 0.386214]\n",
      "[Epoch 40/200] [Batch 266/637] [D loss: 0.172252] [G loss: 0.445194]\n",
      "[Epoch 40/200] [Batch 267/637] [D loss: 0.162260] [G loss: 0.524698]\n",
      "[Epoch 40/200] [Batch 268/637] [D loss: 0.155508] [G loss: 0.518081]\n",
      "[Epoch 40/200] [Batch 269/637] [D loss: 0.193739] [G loss: 0.460080]\n",
      "[Epoch 40/200] [Batch 270/637] [D loss: 0.175095] [G loss: 0.471662]\n",
      "[Epoch 40/200] [Batch 271/637] [D loss: 0.155954] [G loss: 0.449959]\n",
      "[Epoch 40/200] [Batch 272/637] [D loss: 0.226237] [G loss: 0.399224]\n",
      "[Epoch 40/200] [Batch 273/637] [D loss: 0.182817] [G loss: 0.484301]\n",
      "[Epoch 40/200] [Batch 274/637] [D loss: 0.206836] [G loss: 0.494183]\n",
      "[Epoch 40/200] [Batch 275/637] [D loss: 0.175277] [G loss: 0.526058]\n",
      "[Epoch 40/200] [Batch 276/637] [D loss: 0.164312] [G loss: 0.498355]\n",
      "[Epoch 40/200] [Batch 277/637] [D loss: 0.188678] [G loss: 0.419373]\n",
      "[Epoch 40/200] [Batch 278/637] [D loss: 0.155243] [G loss: 0.477661]\n",
      "[Epoch 40/200] [Batch 279/637] [D loss: 0.158025] [G loss: 0.534810]\n",
      "[Epoch 40/200] [Batch 280/637] [D loss: 0.149776] [G loss: 0.492089]\n",
      "[Epoch 40/200] [Batch 281/637] [D loss: 0.152550] [G loss: 0.529247]\n",
      "[Epoch 40/200] [Batch 282/637] [D loss: 0.165099] [G loss: 0.493757]\n",
      "[Epoch 40/200] [Batch 283/637] [D loss: 0.165447] [G loss: 0.532374]\n",
      "[Epoch 40/200] [Batch 284/637] [D loss: 0.180156] [G loss: 0.448182]\n",
      "[Epoch 40/200] [Batch 285/637] [D loss: 0.193594] [G loss: 0.478848]\n",
      "[Epoch 40/200] [Batch 286/637] [D loss: 0.167619] [G loss: 0.497174]\n",
      "[Epoch 40/200] [Batch 287/637] [D loss: 0.167908] [G loss: 0.518003]\n",
      "[Epoch 40/200] [Batch 288/637] [D loss: 0.169693] [G loss: 0.444998]\n",
      "[Epoch 40/200] [Batch 289/637] [D loss: 0.151481] [G loss: 0.538676]\n",
      "[Epoch 40/200] [Batch 290/637] [D loss: 0.174566] [G loss: 0.496518]\n",
      "[Epoch 40/200] [Batch 291/637] [D loss: 0.173508] [G loss: 0.442259]\n",
      "[Epoch 40/200] [Batch 292/637] [D loss: 0.155417] [G loss: 0.516250]\n",
      "[Epoch 40/200] [Batch 293/637] [D loss: 0.155628] [G loss: 0.447829]\n",
      "[Epoch 40/200] [Batch 294/637] [D loss: 0.177655] [G loss: 0.548648]\n",
      "[Epoch 40/200] [Batch 295/637] [D loss: 0.176549] [G loss: 0.505913]\n",
      "[Epoch 40/200] [Batch 296/637] [D loss: 0.162728] [G loss: 0.497602]\n",
      "[Epoch 40/200] [Batch 297/637] [D loss: 0.176658] [G loss: 0.453962]\n",
      "[Epoch 40/200] [Batch 298/637] [D loss: 0.162480] [G loss: 0.575916]\n",
      "[Epoch 40/200] [Batch 299/637] [D loss: 0.176657] [G loss: 0.581849]\n",
      "[Epoch 40/200] [Batch 300/637] [D loss: 0.185878] [G loss: 0.472561]\n",
      "[Epoch 40/200] [Batch 301/637] [D loss: 0.151568] [G loss: 0.469050]\n",
      "[Epoch 40/200] [Batch 302/637] [D loss: 0.185223] [G loss: 0.399220]\n",
      "[Epoch 40/200] [Batch 303/637] [D loss: 0.239237] [G loss: 0.491935]\n",
      "[Epoch 40/200] [Batch 304/637] [D loss: 0.181784] [G loss: 0.523301]\n",
      "[Epoch 40/200] [Batch 305/637] [D loss: 0.163524] [G loss: 0.517274]\n",
      "[Epoch 40/200] [Batch 306/637] [D loss: 0.183796] [G loss: 0.481963]\n",
      "[Epoch 40/200] [Batch 307/637] [D loss: 0.185639] [G loss: 0.499397]\n",
      "[Epoch 40/200] [Batch 308/637] [D loss: 0.159106] [G loss: 0.443958]\n",
      "[Epoch 40/200] [Batch 309/637] [D loss: 0.196506] [G loss: 0.450953]\n",
      "[Epoch 40/200] [Batch 310/637] [D loss: 0.166600] [G loss: 0.459474]\n",
      "[Epoch 40/200] [Batch 311/637] [D loss: 0.182937] [G loss: 0.414792]\n",
      "[Epoch 40/200] [Batch 312/637] [D loss: 0.172027] [G loss: 0.570089]\n",
      "[Epoch 40/200] [Batch 313/637] [D loss: 0.179894] [G loss: 0.574981]\n",
      "[Epoch 40/200] [Batch 314/637] [D loss: 0.176170] [G loss: 0.453843]\n",
      "[Epoch 40/200] [Batch 315/637] [D loss: 0.197891] [G loss: 0.403869]\n",
      "[Epoch 40/200] [Batch 316/637] [D loss: 0.192627] [G loss: 0.514509]\n",
      "[Epoch 40/200] [Batch 317/637] [D loss: 0.165896] [G loss: 0.573037]\n",
      "[Epoch 40/200] [Batch 318/637] [D loss: 0.164513] [G loss: 0.430661]\n",
      "[Epoch 40/200] [Batch 319/637] [D loss: 0.188308] [G loss: 0.390084]\n",
      "[Epoch 40/200] [Batch 320/637] [D loss: 0.180708] [G loss: 0.400956]\n",
      "[Epoch 40/200] [Batch 321/637] [D loss: 0.182029] [G loss: 0.469731]\n",
      "[Epoch 40/200] [Batch 322/637] [D loss: 0.199057] [G loss: 0.515144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/200] [Batch 323/637] [D loss: 0.183690] [G loss: 0.457347]\n",
      "[Epoch 40/200] [Batch 324/637] [D loss: 0.168076] [G loss: 0.459681]\n",
      "[Epoch 40/200] [Batch 325/637] [D loss: 0.170533] [G loss: 0.497176]\n",
      "[Epoch 40/200] [Batch 326/637] [D loss: 0.167686] [G loss: 0.444629]\n",
      "[Epoch 40/200] [Batch 327/637] [D loss: 0.139417] [G loss: 0.496638]\n",
      "[Epoch 40/200] [Batch 328/637] [D loss: 0.176340] [G loss: 0.469212]\n",
      "[Epoch 40/200] [Batch 329/637] [D loss: 0.178008] [G loss: 0.510289]\n",
      "[Epoch 40/200] [Batch 330/637] [D loss: 0.155131] [G loss: 0.554910]\n",
      "[Epoch 40/200] [Batch 331/637] [D loss: 0.179226] [G loss: 0.488614]\n",
      "[Epoch 40/200] [Batch 332/637] [D loss: 0.168292] [G loss: 0.528175]\n",
      "[Epoch 40/200] [Batch 333/637] [D loss: 0.168309] [G loss: 0.478059]\n",
      "[Epoch 40/200] [Batch 334/637] [D loss: 0.181132] [G loss: 0.464788]\n",
      "[Epoch 40/200] [Batch 335/637] [D loss: 0.169768] [G loss: 0.472084]\n",
      "[Epoch 40/200] [Batch 336/637] [D loss: 0.179482] [G loss: 0.478656]\n",
      "[Epoch 40/200] [Batch 337/637] [D loss: 0.191167] [G loss: 0.458818]\n",
      "[Epoch 40/200] [Batch 338/637] [D loss: 0.181413] [G loss: 0.483771]\n",
      "[Epoch 40/200] [Batch 339/637] [D loss: 0.177855] [G loss: 0.471925]\n",
      "[Epoch 40/200] [Batch 340/637] [D loss: 0.182881] [G loss: 0.491399]\n",
      "[Epoch 40/200] [Batch 341/637] [D loss: 0.184287] [G loss: 0.443347]\n",
      "[Epoch 40/200] [Batch 342/637] [D loss: 0.170003] [G loss: 0.466394]\n",
      "[Epoch 40/200] [Batch 343/637] [D loss: 0.166350] [G loss: 0.482478]\n",
      "[Epoch 40/200] [Batch 344/637] [D loss: 0.154590] [G loss: 0.522623]\n",
      "[Epoch 40/200] [Batch 345/637] [D loss: 0.150996] [G loss: 0.563251]\n",
      "[Epoch 40/200] [Batch 346/637] [D loss: 0.174102] [G loss: 0.469541]\n",
      "[Epoch 40/200] [Batch 347/637] [D loss: 0.142134] [G loss: 0.510674]\n",
      "[Epoch 40/200] [Batch 348/637] [D loss: 0.180145] [G loss: 0.434029]\n",
      "[Epoch 40/200] [Batch 349/637] [D loss: 0.164416] [G loss: 0.477082]\n",
      "[Epoch 40/200] [Batch 350/637] [D loss: 0.177401] [G loss: 0.494264]\n",
      "[Epoch 40/200] [Batch 351/637] [D loss: 0.144720] [G loss: 0.526153]\n",
      "[Epoch 40/200] [Batch 352/637] [D loss: 0.171800] [G loss: 0.446371]\n",
      "[Epoch 40/200] [Batch 353/637] [D loss: 0.172287] [G loss: 0.517496]\n",
      "[Epoch 40/200] [Batch 354/637] [D loss: 0.168630] [G loss: 0.500016]\n",
      "[Epoch 40/200] [Batch 355/637] [D loss: 0.211558] [G loss: 0.474990]\n",
      "[Epoch 40/200] [Batch 356/637] [D loss: 0.191122] [G loss: 0.527679]\n",
      "[Epoch 40/200] [Batch 357/637] [D loss: 0.175303] [G loss: 0.525045]\n",
      "[Epoch 40/200] [Batch 358/637] [D loss: 0.175971] [G loss: 0.487947]\n",
      "[Epoch 40/200] [Batch 359/637] [D loss: 0.185933] [G loss: 0.455528]\n",
      "[Epoch 40/200] [Batch 360/637] [D loss: 0.157962] [G loss: 0.465686]\n",
      "[Epoch 40/200] [Batch 361/637] [D loss: 0.140847] [G loss: 0.566552]\n",
      "[Epoch 40/200] [Batch 362/637] [D loss: 0.172557] [G loss: 0.475323]\n",
      "[Epoch 40/200] [Batch 363/637] [D loss: 0.181324] [G loss: 0.599140]\n",
      "[Epoch 40/200] [Batch 364/637] [D loss: 0.160285] [G loss: 0.539712]\n",
      "[Epoch 40/200] [Batch 365/637] [D loss: 0.172521] [G loss: 0.516505]\n",
      "[Epoch 40/200] [Batch 366/637] [D loss: 0.162587] [G loss: 0.495549]\n",
      "[Epoch 40/200] [Batch 367/637] [D loss: 0.159415] [G loss: 0.465364]\n",
      "[Epoch 40/200] [Batch 368/637] [D loss: 0.197778] [G loss: 0.443219]\n",
      "[Epoch 40/200] [Batch 369/637] [D loss: 0.185657] [G loss: 0.530112]\n",
      "[Epoch 40/200] [Batch 370/637] [D loss: 0.173153] [G loss: 0.500727]\n",
      "[Epoch 40/200] [Batch 371/637] [D loss: 0.202107] [G loss: 0.461682]\n",
      "[Epoch 40/200] [Batch 372/637] [D loss: 0.197290] [G loss: 0.562562]\n",
      "[Epoch 40/200] [Batch 373/637] [D loss: 0.243708] [G loss: 0.440049]\n",
      "[Epoch 40/200] [Batch 374/637] [D loss: 0.178255] [G loss: 0.441920]\n",
      "[Epoch 40/200] [Batch 375/637] [D loss: 0.157984] [G loss: 0.495998]\n",
      "[Epoch 40/200] [Batch 376/637] [D loss: 0.161582] [G loss: 0.535415]\n",
      "[Epoch 40/200] [Batch 377/637] [D loss: 0.202385] [G loss: 0.379603]\n",
      "[Epoch 40/200] [Batch 378/637] [D loss: 0.176504] [G loss: 0.562730]\n",
      "[Epoch 40/200] [Batch 379/637] [D loss: 0.199652] [G loss: 0.586275]\n",
      "[Epoch 40/200] [Batch 380/637] [D loss: 0.158354] [G loss: 0.489392]\n",
      "[Epoch 40/200] [Batch 381/637] [D loss: 0.187684] [G loss: 0.388917]\n",
      "[Epoch 40/200] [Batch 382/637] [D loss: 0.170297] [G loss: 0.469922]\n",
      "[Epoch 40/200] [Batch 383/637] [D loss: 0.152782] [G loss: 0.518494]\n",
      "[Epoch 40/200] [Batch 384/637] [D loss: 0.179750] [G loss: 0.456085]\n",
      "[Epoch 40/200] [Batch 385/637] [D loss: 0.142952] [G loss: 0.534703]\n",
      "[Epoch 40/200] [Batch 386/637] [D loss: 0.166199] [G loss: 0.502097]\n",
      "[Epoch 40/200] [Batch 387/637] [D loss: 0.149293] [G loss: 0.585448]\n",
      "[Epoch 40/200] [Batch 388/637] [D loss: 0.165121] [G loss: 0.625917]\n",
      "[Epoch 40/200] [Batch 389/637] [D loss: 0.172984] [G loss: 0.422718]\n",
      "[Epoch 40/200] [Batch 390/637] [D loss: 0.159976] [G loss: 0.442504]\n",
      "[Epoch 40/200] [Batch 391/637] [D loss: 0.165827] [G loss: 0.474708]\n",
      "[Epoch 40/200] [Batch 392/637] [D loss: 0.173530] [G loss: 0.509014]\n",
      "[Epoch 40/200] [Batch 393/637] [D loss: 0.172600] [G loss: 0.535380]\n",
      "[Epoch 40/200] [Batch 394/637] [D loss: 0.169441] [G loss: 0.571630]\n",
      "[Epoch 40/200] [Batch 395/637] [D loss: 0.193671] [G loss: 0.443749]\n",
      "[Epoch 40/200] [Batch 396/637] [D loss: 0.191216] [G loss: 0.462452]\n",
      "[Epoch 40/200] [Batch 397/637] [D loss: 0.185252] [G loss: 0.537916]\n",
      "[Epoch 40/200] [Batch 398/637] [D loss: 0.173062] [G loss: 0.508446]\n",
      "[Epoch 40/200] [Batch 399/637] [D loss: 0.192853] [G loss: 0.443237]\n",
      "[Epoch 40/200] [Batch 400/637] [D loss: 0.183838] [G loss: 0.435356]\n",
      "[Epoch 40/200] [Batch 401/637] [D loss: 0.157724] [G loss: 0.467350]\n",
      "[Epoch 40/200] [Batch 402/637] [D loss: 0.177538] [G loss: 0.458416]\n",
      "[Epoch 40/200] [Batch 403/637] [D loss: 0.161842] [G loss: 0.447317]\n",
      "[Epoch 40/200] [Batch 404/637] [D loss: 0.202169] [G loss: 0.385600]\n",
      "[Epoch 40/200] [Batch 405/637] [D loss: 0.182918] [G loss: 0.506037]\n",
      "[Epoch 40/200] [Batch 406/637] [D loss: 0.178377] [G loss: 0.648681]\n",
      "[Epoch 40/200] [Batch 407/637] [D loss: 0.165304] [G loss: 0.500609]\n",
      "[Epoch 40/200] [Batch 408/637] [D loss: 0.154160] [G loss: 0.469924]\n",
      "[Epoch 40/200] [Batch 409/637] [D loss: 0.146797] [G loss: 0.499005]\n",
      "[Epoch 40/200] [Batch 410/637] [D loss: 0.176637] [G loss: 0.467768]\n",
      "[Epoch 40/200] [Batch 411/637] [D loss: 0.169477] [G loss: 0.435533]\n",
      "[Epoch 40/200] [Batch 412/637] [D loss: 0.156915] [G loss: 0.453594]\n",
      "[Epoch 40/200] [Batch 413/637] [D loss: 0.173751] [G loss: 0.459353]\n",
      "[Epoch 40/200] [Batch 414/637] [D loss: 0.183018] [G loss: 0.502254]\n",
      "[Epoch 40/200] [Batch 415/637] [D loss: 0.155836] [G loss: 0.532187]\n",
      "[Epoch 40/200] [Batch 416/637] [D loss: 0.164815] [G loss: 0.444492]\n",
      "[Epoch 40/200] [Batch 417/637] [D loss: 0.170561] [G loss: 0.419755]\n",
      "[Epoch 40/200] [Batch 418/637] [D loss: 0.155295] [G loss: 0.489655]\n",
      "[Epoch 40/200] [Batch 419/637] [D loss: 0.171858] [G loss: 0.485886]\n",
      "[Epoch 40/200] [Batch 420/637] [D loss: 0.198611] [G loss: 0.471048]\n",
      "[Epoch 40/200] [Batch 421/637] [D loss: 0.170754] [G loss: 0.528651]\n",
      "[Epoch 40/200] [Batch 422/637] [D loss: 0.177890] [G loss: 0.482777]\n",
      "[Epoch 40/200] [Batch 423/637] [D loss: 0.171065] [G loss: 0.495903]\n",
      "[Epoch 40/200] [Batch 424/637] [D loss: 0.161529] [G loss: 0.497069]\n",
      "[Epoch 40/200] [Batch 425/637] [D loss: 0.178594] [G loss: 0.409286]\n",
      "[Epoch 40/200] [Batch 426/637] [D loss: 0.152525] [G loss: 0.522553]\n",
      "[Epoch 40/200] [Batch 427/637] [D loss: 0.177498] [G loss: 0.500843]\n",
      "[Epoch 40/200] [Batch 428/637] [D loss: 0.165342] [G loss: 0.472044]\n",
      "[Epoch 40/200] [Batch 429/637] [D loss: 0.164255] [G loss: 0.454273]\n",
      "[Epoch 40/200] [Batch 430/637] [D loss: 0.159143] [G loss: 0.460488]\n",
      "[Epoch 40/200] [Batch 431/637] [D loss: 0.159450] [G loss: 0.474556]\n",
      "[Epoch 40/200] [Batch 432/637] [D loss: 0.173885] [G loss: 0.458915]\n",
      "[Epoch 40/200] [Batch 433/637] [D loss: 0.203146] [G loss: 0.427349]\n",
      "[Epoch 40/200] [Batch 434/637] [D loss: 0.182758] [G loss: 0.509943]\n",
      "[Epoch 40/200] [Batch 435/637] [D loss: 0.161868] [G loss: 0.547595]\n",
      "[Epoch 40/200] [Batch 436/637] [D loss: 0.174326] [G loss: 0.489890]\n",
      "[Epoch 40/200] [Batch 437/637] [D loss: 0.159126] [G loss: 0.538275]\n",
      "[Epoch 40/200] [Batch 438/637] [D loss: 0.179205] [G loss: 0.460933]\n",
      "[Epoch 40/200] [Batch 439/637] [D loss: 0.175211] [G loss: 0.506514]\n",
      "[Epoch 40/200] [Batch 440/637] [D loss: 0.180720] [G loss: 0.499281]\n",
      "[Epoch 40/200] [Batch 441/637] [D loss: 0.154492] [G loss: 0.517314]\n",
      "[Epoch 40/200] [Batch 442/637] [D loss: 0.171803] [G loss: 0.443614]\n",
      "[Epoch 40/200] [Batch 443/637] [D loss: 0.193596] [G loss: 0.447175]\n",
      "[Epoch 40/200] [Batch 444/637] [D loss: 0.147947] [G loss: 0.508982]\n",
      "[Epoch 40/200] [Batch 445/637] [D loss: 0.165671] [G loss: 0.533518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/200] [Batch 446/637] [D loss: 0.171141] [G loss: 0.517763]\n",
      "[Epoch 40/200] [Batch 447/637] [D loss: 0.158732] [G loss: 0.464960]\n",
      "[Epoch 40/200] [Batch 448/637] [D loss: 0.188001] [G loss: 0.451393]\n",
      "[Epoch 40/200] [Batch 449/637] [D loss: 0.180430] [G loss: 0.517541]\n",
      "[Epoch 40/200] [Batch 450/637] [D loss: 0.194232] [G loss: 0.533674]\n",
      "[Epoch 40/200] [Batch 451/637] [D loss: 0.184415] [G loss: 0.500861]\n",
      "[Epoch 40/200] [Batch 452/637] [D loss: 0.179399] [G loss: 0.558689]\n",
      "[Epoch 40/200] [Batch 453/637] [D loss: 0.154850] [G loss: 0.493435]\n",
      "[Epoch 40/200] [Batch 454/637] [D loss: 0.248840] [G loss: 0.443366]\n",
      "[Epoch 40/200] [Batch 455/637] [D loss: 0.229458] [G loss: 0.468346]\n",
      "[Epoch 40/200] [Batch 456/637] [D loss: 0.183156] [G loss: 0.504267]\n",
      "[Epoch 40/200] [Batch 457/637] [D loss: 0.173127] [G loss: 0.518702]\n",
      "[Epoch 40/200] [Batch 458/637] [D loss: 0.184914] [G loss: 0.474440]\n",
      "[Epoch 40/200] [Batch 459/637] [D loss: 0.197874] [G loss: 0.509167]\n",
      "[Epoch 40/200] [Batch 460/637] [D loss: 0.167447] [G loss: 0.551720]\n",
      "[Epoch 40/200] [Batch 461/637] [D loss: 0.169380] [G loss: 0.441848]\n",
      "[Epoch 40/200] [Batch 462/637] [D loss: 0.148444] [G loss: 0.507972]\n",
      "[Epoch 40/200] [Batch 463/637] [D loss: 0.182419] [G loss: 0.461150]\n",
      "[Epoch 40/200] [Batch 464/637] [D loss: 0.147680] [G loss: 0.556307]\n",
      "[Epoch 40/200] [Batch 465/637] [D loss: 0.213238] [G loss: 0.467454]\n",
      "[Epoch 40/200] [Batch 466/637] [D loss: 0.170923] [G loss: 0.519686]\n",
      "[Epoch 40/200] [Batch 467/637] [D loss: 0.206382] [G loss: 0.480091]\n",
      "[Epoch 40/200] [Batch 468/637] [D loss: 0.170297] [G loss: 0.514895]\n",
      "[Epoch 40/200] [Batch 469/637] [D loss: 0.162460] [G loss: 0.620084]\n",
      "[Epoch 40/200] [Batch 470/637] [D loss: 0.176355] [G loss: 0.483647]\n",
      "[Epoch 40/200] [Batch 471/637] [D loss: 0.161251] [G loss: 0.466856]\n",
      "[Epoch 40/200] [Batch 472/637] [D loss: 0.179502] [G loss: 0.474685]\n",
      "[Epoch 40/200] [Batch 473/637] [D loss: 0.169179] [G loss: 0.448518]\n",
      "[Epoch 40/200] [Batch 474/637] [D loss: 0.166210] [G loss: 0.471765]\n",
      "[Epoch 40/200] [Batch 475/637] [D loss: 0.167037] [G loss: 0.562489]\n",
      "[Epoch 40/200] [Batch 476/637] [D loss: 0.165213] [G loss: 0.532813]\n",
      "[Epoch 40/200] [Batch 477/637] [D loss: 0.163236] [G loss: 0.479293]\n",
      "[Epoch 40/200] [Batch 478/637] [D loss: 0.155322] [G loss: 0.489476]\n",
      "[Epoch 40/200] [Batch 479/637] [D loss: 0.169232] [G loss: 0.403299]\n",
      "[Epoch 40/200] [Batch 480/637] [D loss: 0.180927] [G loss: 0.461241]\n",
      "[Epoch 40/200] [Batch 481/637] [D loss: 0.170997] [G loss: 0.536176]\n",
      "[Epoch 40/200] [Batch 482/637] [D loss: 0.159931] [G loss: 0.545484]\n",
      "[Epoch 40/200] [Batch 483/637] [D loss: 0.182295] [G loss: 0.466042]\n",
      "[Epoch 40/200] [Batch 484/637] [D loss: 0.195271] [G loss: 0.422453]\n",
      "[Epoch 40/200] [Batch 485/637] [D loss: 0.181402] [G loss: 0.478445]\n",
      "[Epoch 40/200] [Batch 486/637] [D loss: 0.175544] [G loss: 0.440481]\n",
      "[Epoch 40/200] [Batch 487/637] [D loss: 0.195742] [G loss: 0.532304]\n",
      "[Epoch 40/200] [Batch 488/637] [D loss: 0.161337] [G loss: 0.549118]\n",
      "[Epoch 40/200] [Batch 489/637] [D loss: 0.151590] [G loss: 0.510310]\n",
      "[Epoch 40/200] [Batch 490/637] [D loss: 0.174999] [G loss: 0.469410]\n",
      "[Epoch 40/200] [Batch 491/637] [D loss: 0.159538] [G loss: 0.508703]\n",
      "[Epoch 40/200] [Batch 492/637] [D loss: 0.153835] [G loss: 0.488248]\n",
      "[Epoch 40/200] [Batch 493/637] [D loss: 0.195466] [G loss: 0.408684]\n",
      "[Epoch 40/200] [Batch 494/637] [D loss: 0.170048] [G loss: 0.455381]\n",
      "[Epoch 40/200] [Batch 495/637] [D loss: 0.195977] [G loss: 0.484750]\n",
      "[Epoch 40/200] [Batch 496/637] [D loss: 0.159039] [G loss: 0.546572]\n",
      "[Epoch 40/200] [Batch 497/637] [D loss: 0.151288] [G loss: 0.546948]\n",
      "[Epoch 40/200] [Batch 498/637] [D loss: 0.147512] [G loss: 0.514910]\n",
      "[Epoch 40/200] [Batch 499/637] [D loss: 0.162876] [G loss: 0.483602]\n",
      "[Epoch 40/200] [Batch 500/637] [D loss: 0.163576] [G loss: 0.435154]\n",
      "[Epoch 40/200] [Batch 501/637] [D loss: 0.154408] [G loss: 0.505335]\n",
      "[Epoch 40/200] [Batch 502/637] [D loss: 0.204666] [G loss: 0.472078]\n",
      "[Epoch 40/200] [Batch 503/637] [D loss: 0.179441] [G loss: 0.527173]\n",
      "[Epoch 40/200] [Batch 504/637] [D loss: 0.158303] [G loss: 0.493889]\n",
      "[Epoch 40/200] [Batch 505/637] [D loss: 0.182631] [G loss: 0.511079]\n",
      "[Epoch 40/200] [Batch 506/637] [D loss: 0.179047] [G loss: 0.463439]\n",
      "[Epoch 40/200] [Batch 507/637] [D loss: 0.172573] [G loss: 0.444279]\n",
      "[Epoch 40/200] [Batch 508/637] [D loss: 0.214565] [G loss: 0.446763]\n",
      "[Epoch 40/200] [Batch 509/637] [D loss: 0.171993] [G loss: 0.510322]\n",
      "[Epoch 40/200] [Batch 510/637] [D loss: 0.169113] [G loss: 0.498110]\n",
      "[Epoch 40/200] [Batch 511/637] [D loss: 0.167809] [G loss: 0.478797]\n",
      "[Epoch 40/200] [Batch 512/637] [D loss: 0.154369] [G loss: 0.481616]\n",
      "[Epoch 40/200] [Batch 513/637] [D loss: 0.166541] [G loss: 0.479046]\n",
      "[Epoch 40/200] [Batch 514/637] [D loss: 0.151655] [G loss: 0.498095]\n",
      "[Epoch 40/200] [Batch 515/637] [D loss: 0.177365] [G loss: 0.542490]\n",
      "[Epoch 40/200] [Batch 516/637] [D loss: 0.153358] [G loss: 0.554625]\n",
      "[Epoch 40/200] [Batch 517/637] [D loss: 0.158527] [G loss: 0.537490]\n",
      "[Epoch 40/200] [Batch 518/637] [D loss: 0.204903] [G loss: 0.395465]\n",
      "[Epoch 40/200] [Batch 519/637] [D loss: 0.168658] [G loss: 0.526601]\n",
      "[Epoch 40/200] [Batch 520/637] [D loss: 0.243841] [G loss: 0.485128]\n",
      "[Epoch 40/200] [Batch 521/637] [D loss: 0.167336] [G loss: 0.488557]\n",
      "[Epoch 40/200] [Batch 522/637] [D loss: 0.180645] [G loss: 0.494318]\n",
      "[Epoch 40/200] [Batch 523/637] [D loss: 0.186889] [G loss: 0.496034]\n",
      "[Epoch 40/200] [Batch 524/637] [D loss: 0.164462] [G loss: 0.572478]\n",
      "[Epoch 40/200] [Batch 525/637] [D loss: 0.168925] [G loss: 0.435865]\n",
      "[Epoch 40/200] [Batch 526/637] [D loss: 0.182847] [G loss: 0.476727]\n",
      "[Epoch 40/200] [Batch 527/637] [D loss: 0.181855] [G loss: 0.514890]\n",
      "[Epoch 40/200] [Batch 528/637] [D loss: 0.183234] [G loss: 0.522689]\n",
      "[Epoch 40/200] [Batch 529/637] [D loss: 0.187442] [G loss: 0.494308]\n",
      "[Epoch 40/200] [Batch 530/637] [D loss: 0.164785] [G loss: 0.430288]\n",
      "[Epoch 40/200] [Batch 531/637] [D loss: 0.173110] [G loss: 0.468085]\n",
      "[Epoch 40/200] [Batch 532/637] [D loss: 0.174068] [G loss: 0.403725]\n",
      "[Epoch 40/200] [Batch 533/637] [D loss: 0.153800] [G loss: 0.470185]\n",
      "[Epoch 40/200] [Batch 534/637] [D loss: 0.183468] [G loss: 0.457801]\n",
      "[Epoch 40/200] [Batch 535/637] [D loss: 0.178928] [G loss: 0.543088]\n",
      "[Epoch 40/200] [Batch 536/637] [D loss: 0.214655] [G loss: 0.459139]\n",
      "[Epoch 40/200] [Batch 537/637] [D loss: 0.171527] [G loss: 0.462530]\n",
      "[Epoch 40/200] [Batch 538/637] [D loss: 0.172450] [G loss: 0.462719]\n",
      "[Epoch 40/200] [Batch 539/637] [D loss: 0.173888] [G loss: 0.422652]\n",
      "[Epoch 40/200] [Batch 540/637] [D loss: 0.166767] [G loss: 0.446409]\n",
      "[Epoch 40/200] [Batch 541/637] [D loss: 0.182304] [G loss: 0.458163]\n",
      "[Epoch 40/200] [Batch 542/637] [D loss: 0.174266] [G loss: 0.490177]\n",
      "[Epoch 40/200] [Batch 543/637] [D loss: 0.179307] [G loss: 0.507717]\n",
      "[Epoch 40/200] [Batch 544/637] [D loss: 0.160791] [G loss: 0.426420]\n",
      "[Epoch 40/200] [Batch 545/637] [D loss: 0.187060] [G loss: 0.505372]\n",
      "[Epoch 40/200] [Batch 546/637] [D loss: 0.154342] [G loss: 0.560520]\n",
      "[Epoch 40/200] [Batch 547/637] [D loss: 0.197548] [G loss: 0.413384]\n",
      "[Epoch 40/200] [Batch 548/637] [D loss: 0.178219] [G loss: 0.463458]\n",
      "[Epoch 40/200] [Batch 549/637] [D loss: 0.157778] [G loss: 0.468448]\n",
      "[Epoch 40/200] [Batch 550/637] [D loss: 0.150137] [G loss: 0.517102]\n",
      "[Epoch 40/200] [Batch 551/637] [D loss: 0.179993] [G loss: 0.446302]\n",
      "[Epoch 40/200] [Batch 552/637] [D loss: 0.182058] [G loss: 0.484124]\n",
      "[Epoch 40/200] [Batch 553/637] [D loss: 0.173178] [G loss: 0.481007]\n",
      "[Epoch 40/200] [Batch 554/637] [D loss: 0.178886] [G loss: 0.489396]\n",
      "[Epoch 40/200] [Batch 555/637] [D loss: 0.163626] [G loss: 0.489536]\n",
      "[Epoch 40/200] [Batch 556/637] [D loss: 0.189956] [G loss: 0.498177]\n",
      "[Epoch 40/200] [Batch 557/637] [D loss: 0.155903] [G loss: 0.528571]\n",
      "[Epoch 40/200] [Batch 558/637] [D loss: 0.155484] [G loss: 0.480507]\n",
      "[Epoch 40/200] [Batch 559/637] [D loss: 0.157191] [G loss: 0.477940]\n",
      "[Epoch 40/200] [Batch 560/637] [D loss: 0.182391] [G loss: 0.494235]\n",
      "[Epoch 40/200] [Batch 561/637] [D loss: 0.177511] [G loss: 0.581028]\n",
      "[Epoch 40/200] [Batch 562/637] [D loss: 0.156593] [G loss: 0.602897]\n",
      "[Epoch 40/200] [Batch 563/637] [D loss: 0.166364] [G loss: 0.517536]\n",
      "[Epoch 40/200] [Batch 564/637] [D loss: 0.179872] [G loss: 0.448276]\n",
      "[Epoch 40/200] [Batch 565/637] [D loss: 0.171877] [G loss: 0.478763]\n",
      "[Epoch 40/200] [Batch 566/637] [D loss: 0.179358] [G loss: 0.484945]\n",
      "[Epoch 40/200] [Batch 567/637] [D loss: 0.193974] [G loss: 0.423825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/200] [Batch 568/637] [D loss: 0.167763] [G loss: 0.579704]\n",
      "[Epoch 40/200] [Batch 569/637] [D loss: 0.158912] [G loss: 0.505235]\n",
      "[Epoch 40/200] [Batch 570/637] [D loss: 0.177461] [G loss: 0.472040]\n",
      "[Epoch 40/200] [Batch 571/637] [D loss: 0.154736] [G loss: 0.461459]\n",
      "[Epoch 40/200] [Batch 572/637] [D loss: 0.160235] [G loss: 0.500482]\n",
      "[Epoch 40/200] [Batch 573/637] [D loss: 0.154937] [G loss: 0.509374]\n",
      "[Epoch 40/200] [Batch 574/637] [D loss: 0.171194] [G loss: 0.531589]\n",
      "[Epoch 40/200] [Batch 575/637] [D loss: 0.164750] [G loss: 0.465169]\n",
      "[Epoch 40/200] [Batch 576/637] [D loss: 0.159256] [G loss: 0.520136]\n",
      "[Epoch 40/200] [Batch 577/637] [D loss: 0.145753] [G loss: 0.496787]\n",
      "[Epoch 40/200] [Batch 578/637] [D loss: 0.157721] [G loss: 0.451806]\n",
      "[Epoch 40/200] [Batch 579/637] [D loss: 0.185270] [G loss: 0.471883]\n",
      "[Epoch 40/200] [Batch 580/637] [D loss: 0.158312] [G loss: 0.656079]\n",
      "[Epoch 40/200] [Batch 581/637] [D loss: 0.167928] [G loss: 0.588449]\n",
      "[Epoch 40/200] [Batch 582/637] [D loss: 0.175303] [G loss: 0.499678]\n",
      "[Epoch 40/200] [Batch 583/637] [D loss: 0.180986] [G loss: 0.461480]\n",
      "[Epoch 40/200] [Batch 584/637] [D loss: 0.163184] [G loss: 0.498981]\n",
      "[Epoch 40/200] [Batch 585/637] [D loss: 0.151902] [G loss: 0.524650]\n",
      "[Epoch 40/200] [Batch 586/637] [D loss: 0.160863] [G loss: 0.527473]\n",
      "[Epoch 40/200] [Batch 587/637] [D loss: 0.176351] [G loss: 0.492384]\n",
      "[Epoch 40/200] [Batch 588/637] [D loss: 0.175616] [G loss: 0.472728]\n",
      "[Epoch 40/200] [Batch 589/637] [D loss: 0.166659] [G loss: 0.467979]\n",
      "[Epoch 40/200] [Batch 590/637] [D loss: 0.157984] [G loss: 0.465491]\n",
      "[Epoch 40/200] [Batch 591/637] [D loss: 0.153953] [G loss: 0.456920]\n",
      "[Epoch 40/200] [Batch 592/637] [D loss: 0.155130] [G loss: 0.495848]\n",
      "[Epoch 40/200] [Batch 593/637] [D loss: 0.159674] [G loss: 0.580077]\n",
      "[Epoch 40/200] [Batch 594/637] [D loss: 0.185415] [G loss: 0.475511]\n",
      "[Epoch 40/200] [Batch 595/637] [D loss: 0.166393] [G loss: 0.506652]\n",
      "[Epoch 40/200] [Batch 596/637] [D loss: 0.168399] [G loss: 0.446139]\n",
      "[Epoch 40/200] [Batch 597/637] [D loss: 0.145787] [G loss: 0.469569]\n",
      "[Epoch 40/200] [Batch 598/637] [D loss: 0.175614] [G loss: 0.436446]\n",
      "[Epoch 40/200] [Batch 599/637] [D loss: 0.145019] [G loss: 0.557661]\n",
      "[Epoch 40/200] [Batch 600/637] [D loss: 0.178333] [G loss: 0.516834]\n",
      "[Epoch 40/200] [Batch 601/637] [D loss: 0.155747] [G loss: 0.516323]\n",
      "[Epoch 40/200] [Batch 602/637] [D loss: 0.156286] [G loss: 0.555884]\n",
      "[Epoch 40/200] [Batch 603/637] [D loss: 0.154710] [G loss: 0.507394]\n",
      "[Epoch 40/200] [Batch 604/637] [D loss: 0.181899] [G loss: 0.498640]\n",
      "[Epoch 40/200] [Batch 605/637] [D loss: 0.153862] [G loss: 0.556781]\n",
      "[Epoch 40/200] [Batch 606/637] [D loss: 0.148590] [G loss: 0.534069]\n",
      "[Epoch 40/200] [Batch 607/637] [D loss: 0.143030] [G loss: 0.578457]\n",
      "[Epoch 40/200] [Batch 608/637] [D loss: 0.163088] [G loss: 0.559651]\n",
      "[Epoch 40/200] [Batch 609/637] [D loss: 0.193118] [G loss: 0.626072]\n",
      "[Epoch 40/200] [Batch 610/637] [D loss: 0.156827] [G loss: 0.537996]\n",
      "[Epoch 40/200] [Batch 611/637] [D loss: 0.202243] [G loss: 0.404542]\n",
      "[Epoch 40/200] [Batch 612/637] [D loss: 0.191650] [G loss: 0.475829]\n",
      "[Epoch 40/200] [Batch 613/637] [D loss: 0.164906] [G loss: 0.500498]\n",
      "[Epoch 40/200] [Batch 614/637] [D loss: 0.159253] [G loss: 0.518900]\n",
      "[Epoch 40/200] [Batch 615/637] [D loss: 0.143511] [G loss: 0.538937]\n",
      "[Epoch 40/200] [Batch 616/637] [D loss: 0.177140] [G loss: 0.475439]\n",
      "[Epoch 40/200] [Batch 617/637] [D loss: 0.166457] [G loss: 0.477658]\n",
      "[Epoch 40/200] [Batch 618/637] [D loss: 0.168436] [G loss: 0.472233]\n",
      "[Epoch 40/200] [Batch 619/637] [D loss: 0.171988] [G loss: 0.511540]\n",
      "[Epoch 40/200] [Batch 620/637] [D loss: 0.182803] [G loss: 0.515468]\n",
      "[Epoch 40/200] [Batch 621/637] [D loss: 0.174351] [G loss: 0.516459]\n",
      "[Epoch 40/200] [Batch 622/637] [D loss: 0.164484] [G loss: 0.543222]\n",
      "[Epoch 40/200] [Batch 623/637] [D loss: 0.139747] [G loss: 0.589311]\n",
      "[Epoch 40/200] [Batch 624/637] [D loss: 0.199045] [G loss: 0.460792]\n",
      "[Epoch 40/200] [Batch 625/637] [D loss: 0.175951] [G loss: 0.503557]\n",
      "[Epoch 40/200] [Batch 626/637] [D loss: 0.152362] [G loss: 0.464968]\n",
      "[Epoch 40/200] [Batch 627/637] [D loss: 0.158627] [G loss: 0.517162]\n",
      "[Epoch 40/200] [Batch 628/637] [D loss: 0.145698] [G loss: 0.592595]\n",
      "[Epoch 40/200] [Batch 629/637] [D loss: 0.153408] [G loss: 0.509654]\n",
      "[Epoch 40/200] [Batch 630/637] [D loss: 0.209803] [G loss: 0.400591]\n",
      "[Epoch 40/200] [Batch 631/637] [D loss: 0.191592] [G loss: 0.469128]\n",
      "[Epoch 40/200] [Batch 632/637] [D loss: 0.185290] [G loss: 0.607250]\n",
      "[Epoch 40/200] [Batch 633/637] [D loss: 0.177616] [G loss: 0.630307]\n",
      "[Epoch 40/200] [Batch 634/637] [D loss: 0.161532] [G loss: 0.501046]\n",
      "[Epoch 40/200] [Batch 635/637] [D loss: 0.182195] [G loss: 0.437869]\n",
      "[Epoch 40/200] [Batch 636/637] [D loss: 0.173372] [G loss: 0.435705]\n",
      "[Epoch 41/200] [Batch 0/637] [D loss: 0.185212] [G loss: 0.516378]\n",
      "[Epoch 41/200] [Batch 1/637] [D loss: 0.161155] [G loss: 0.572242]\n",
      "[Epoch 41/200] [Batch 2/637] [D loss: 0.146914] [G loss: 0.503916]\n",
      "[Epoch 41/200] [Batch 3/637] [D loss: 0.147596] [G loss: 0.524418]\n",
      "[Epoch 41/200] [Batch 4/637] [D loss: 0.174619] [G loss: 0.451584]\n",
      "[Epoch 41/200] [Batch 5/637] [D loss: 0.152998] [G loss: 0.493080]\n",
      "[Epoch 41/200] [Batch 6/637] [D loss: 0.175322] [G loss: 0.450648]\n",
      "[Epoch 41/200] [Batch 7/637] [D loss: 0.161419] [G loss: 0.484116]\n",
      "[Epoch 41/200] [Batch 8/637] [D loss: 0.157849] [G loss: 0.504552]\n",
      "[Epoch 41/200] [Batch 9/637] [D loss: 0.185579] [G loss: 0.440491]\n",
      "[Epoch 41/200] [Batch 10/637] [D loss: 0.140284] [G loss: 0.591158]\n",
      "[Epoch 41/200] [Batch 11/637] [D loss: 0.145463] [G loss: 0.583093]\n",
      "[Epoch 41/200] [Batch 12/637] [D loss: 0.161252] [G loss: 0.509630]\n",
      "[Epoch 41/200] [Batch 13/637] [D loss: 0.199006] [G loss: 0.427376]\n",
      "[Epoch 41/200] [Batch 14/637] [D loss: 0.189069] [G loss: 0.483286]\n",
      "[Epoch 41/200] [Batch 15/637] [D loss: 0.192843] [G loss: 0.546651]\n",
      "[Epoch 41/200] [Batch 16/637] [D loss: 0.178554] [G loss: 0.503321]\n",
      "[Epoch 41/200] [Batch 17/637] [D loss: 0.162077] [G loss: 0.484501]\n",
      "[Epoch 41/200] [Batch 18/637] [D loss: 0.175426] [G loss: 0.513290]\n",
      "[Epoch 41/200] [Batch 19/637] [D loss: 0.155805] [G loss: 0.453794]\n",
      "[Epoch 41/200] [Batch 20/637] [D loss: 0.150279] [G loss: 0.532972]\n",
      "[Epoch 41/200] [Batch 21/637] [D loss: 0.178251] [G loss: 0.529739]\n",
      "[Epoch 41/200] [Batch 22/637] [D loss: 0.179951] [G loss: 0.509105]\n",
      "[Epoch 41/200] [Batch 23/637] [D loss: 0.161627] [G loss: 0.570675]\n",
      "[Epoch 41/200] [Batch 24/637] [D loss: 0.151787] [G loss: 0.595307]\n",
      "[Epoch 41/200] [Batch 25/637] [D loss: 0.177351] [G loss: 0.469943]\n",
      "[Epoch 41/200] [Batch 26/637] [D loss: 0.148024] [G loss: 0.560779]\n",
      "[Epoch 41/200] [Batch 27/637] [D loss: 0.168980] [G loss: 0.512447]\n",
      "[Epoch 41/200] [Batch 28/637] [D loss: 0.156994] [G loss: 0.534786]\n",
      "[Epoch 41/200] [Batch 29/637] [D loss: 0.157598] [G loss: 0.493599]\n",
      "[Epoch 41/200] [Batch 30/637] [D loss: 0.166841] [G loss: 0.517888]\n",
      "[Epoch 41/200] [Batch 31/637] [D loss: 0.158247] [G loss: 0.587074]\n",
      "[Epoch 41/200] [Batch 32/637] [D loss: 0.170391] [G loss: 0.451071]\n",
      "[Epoch 41/200] [Batch 33/637] [D loss: 0.159848] [G loss: 0.479437]\n",
      "[Epoch 41/200] [Batch 34/637] [D loss: 0.174814] [G loss: 0.453094]\n",
      "[Epoch 41/200] [Batch 35/637] [D loss: 0.164759] [G loss: 0.527352]\n",
      "[Epoch 41/200] [Batch 36/637] [D loss: 0.197929] [G loss: 0.480099]\n",
      "[Epoch 41/200] [Batch 37/637] [D loss: 0.166864] [G loss: 0.531524]\n",
      "[Epoch 41/200] [Batch 38/637] [D loss: 0.172110] [G loss: 0.524454]\n",
      "[Epoch 41/200] [Batch 39/637] [D loss: 0.161355] [G loss: 0.514426]\n",
      "[Epoch 41/200] [Batch 40/637] [D loss: 0.144501] [G loss: 0.541693]\n",
      "[Epoch 41/200] [Batch 41/637] [D loss: 0.137933] [G loss: 0.559985]\n",
      "[Epoch 41/200] [Batch 42/637] [D loss: 0.171050] [G loss: 0.458308]\n",
      "[Epoch 41/200] [Batch 43/637] [D loss: 0.154581] [G loss: 0.523221]\n",
      "[Epoch 41/200] [Batch 44/637] [D loss: 0.159097] [G loss: 0.529223]\n",
      "[Epoch 41/200] [Batch 45/637] [D loss: 0.175067] [G loss: 0.540471]\n",
      "[Epoch 41/200] [Batch 46/637] [D loss: 0.193246] [G loss: 0.461447]\n",
      "[Epoch 41/200] [Batch 47/637] [D loss: 0.163597] [G loss: 0.532843]\n",
      "[Epoch 41/200] [Batch 48/637] [D loss: 0.152995] [G loss: 0.547264]\n",
      "[Epoch 41/200] [Batch 49/637] [D loss: 0.149690] [G loss: 0.528232]\n",
      "[Epoch 41/200] [Batch 50/637] [D loss: 0.170234] [G loss: 0.476077]\n",
      "[Epoch 41/200] [Batch 51/637] [D loss: 0.152610] [G loss: 0.558201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/200] [Batch 52/637] [D loss: 0.191071] [G loss: 0.454035]\n",
      "[Epoch 41/200] [Batch 53/637] [D loss: 0.169831] [G loss: 0.481258]\n",
      "[Epoch 41/200] [Batch 54/637] [D loss: 0.144514] [G loss: 0.566942]\n",
      "[Epoch 41/200] [Batch 55/637] [D loss: 0.206304] [G loss: 0.466552]\n",
      "[Epoch 41/200] [Batch 56/637] [D loss: 0.174671] [G loss: 0.517235]\n",
      "[Epoch 41/200] [Batch 57/637] [D loss: 0.192324] [G loss: 0.505577]\n",
      "[Epoch 41/200] [Batch 58/637] [D loss: 0.184580] [G loss: 0.525287]\n",
      "[Epoch 41/200] [Batch 59/637] [D loss: 0.164460] [G loss: 0.543626]\n",
      "[Epoch 41/200] [Batch 60/637] [D loss: 0.143943] [G loss: 0.542485]\n",
      "[Epoch 41/200] [Batch 61/637] [D loss: 0.188684] [G loss: 0.444170]\n",
      "[Epoch 41/200] [Batch 62/637] [D loss: 0.175618] [G loss: 0.441741]\n",
      "[Epoch 41/200] [Batch 63/637] [D loss: 0.173592] [G loss: 0.472783]\n",
      "[Epoch 41/200] [Batch 64/637] [D loss: 0.171100] [G loss: 0.556836]\n",
      "[Epoch 41/200] [Batch 65/637] [D loss: 0.158602] [G loss: 0.580452]\n",
      "[Epoch 41/200] [Batch 66/637] [D loss: 0.167989] [G loss: 0.514628]\n",
      "[Epoch 41/200] [Batch 67/637] [D loss: 0.202218] [G loss: 0.373394]\n",
      "[Epoch 41/200] [Batch 68/637] [D loss: 0.170575] [G loss: 0.528182]\n",
      "[Epoch 41/200] [Batch 69/637] [D loss: 0.174425] [G loss: 0.485464]\n",
      "[Epoch 41/200] [Batch 70/637] [D loss: 0.209663] [G loss: 0.441231]\n",
      "[Epoch 41/200] [Batch 71/637] [D loss: 0.189481] [G loss: 0.499908]\n",
      "[Epoch 41/200] [Batch 72/637] [D loss: 0.192063] [G loss: 0.535380]\n",
      "[Epoch 41/200] [Batch 73/637] [D loss: 0.186137] [G loss: 0.464068]\n",
      "[Epoch 41/200] [Batch 74/637] [D loss: 0.181589] [G loss: 0.393936]\n",
      "[Epoch 41/200] [Batch 75/637] [D loss: 0.164516] [G loss: 0.446533]\n",
      "[Epoch 41/200] [Batch 76/637] [D loss: 0.169598] [G loss: 0.466791]\n",
      "[Epoch 41/200] [Batch 77/637] [D loss: 0.142345] [G loss: 0.560611]\n",
      "[Epoch 41/200] [Batch 78/637] [D loss: 0.176243] [G loss: 0.482501]\n",
      "[Epoch 41/200] [Batch 79/637] [D loss: 0.198058] [G loss: 0.425300]\n",
      "[Epoch 41/200] [Batch 80/637] [D loss: 0.217035] [G loss: 0.491485]\n",
      "[Epoch 41/200] [Batch 81/637] [D loss: 0.168124] [G loss: 0.547566]\n",
      "[Epoch 41/200] [Batch 82/637] [D loss: 0.167094] [G loss: 0.478121]\n",
      "[Epoch 41/200] [Batch 83/637] [D loss: 0.168974] [G loss: 0.463764]\n",
      "[Epoch 41/200] [Batch 84/637] [D loss: 0.166564] [G loss: 0.573015]\n",
      "[Epoch 41/200] [Batch 85/637] [D loss: 0.168907] [G loss: 0.544926]\n",
      "[Epoch 41/200] [Batch 86/637] [D loss: 0.171600] [G loss: 0.537075]\n",
      "[Epoch 41/200] [Batch 87/637] [D loss: 0.175638] [G loss: 0.526594]\n",
      "[Epoch 41/200] [Batch 88/637] [D loss: 0.175436] [G loss: 0.465132]\n",
      "[Epoch 41/200] [Batch 89/637] [D loss: 0.159794] [G loss: 0.541836]\n",
      "[Epoch 41/200] [Batch 90/637] [D loss: 0.168589] [G loss: 0.541822]\n",
      "[Epoch 41/200] [Batch 91/637] [D loss: 0.156186] [G loss: 0.511862]\n",
      "[Epoch 41/200] [Batch 92/637] [D loss: 0.164415] [G loss: 0.527720]\n",
      "[Epoch 41/200] [Batch 93/637] [D loss: 0.187350] [G loss: 0.487079]\n",
      "[Epoch 41/200] [Batch 94/637] [D loss: 0.171127] [G loss: 0.496339]\n",
      "[Epoch 41/200] [Batch 95/637] [D loss: 0.191847] [G loss: 0.472395]\n",
      "[Epoch 41/200] [Batch 96/637] [D loss: 0.149825] [G loss: 0.495902]\n",
      "[Epoch 41/200] [Batch 97/637] [D loss: 0.253570] [G loss: 0.429568]\n",
      "[Epoch 41/200] [Batch 98/637] [D loss: 0.192929] [G loss: 0.563287]\n",
      "[Epoch 41/200] [Batch 99/637] [D loss: 0.161906] [G loss: 0.554953]\n",
      "[Epoch 41/200] [Batch 100/637] [D loss: 0.181582] [G loss: 0.509058]\n",
      "[Epoch 41/200] [Batch 101/637] [D loss: 0.165946] [G loss: 0.427162]\n",
      "[Epoch 41/200] [Batch 102/637] [D loss: 0.159033] [G loss: 0.481584]\n",
      "[Epoch 41/200] [Batch 103/637] [D loss: 0.167024] [G loss: 0.500878]\n",
      "[Epoch 41/200] [Batch 104/637] [D loss: 0.164716] [G loss: 0.472169]\n",
      "[Epoch 41/200] [Batch 105/637] [D loss: 0.150964] [G loss: 0.535761]\n",
      "[Epoch 41/200] [Batch 106/637] [D loss: 0.157409] [G loss: 0.442522]\n",
      "[Epoch 41/200] [Batch 107/637] [D loss: 0.166600] [G loss: 0.543730]\n",
      "[Epoch 41/200] [Batch 108/637] [D loss: 0.137395] [G loss: 0.569619]\n",
      "[Epoch 41/200] [Batch 109/637] [D loss: 0.161828] [G loss: 0.557264]\n",
      "[Epoch 41/200] [Batch 110/637] [D loss: 0.137457] [G loss: 0.522845]\n",
      "[Epoch 41/200] [Batch 111/637] [D loss: 0.133664] [G loss: 0.546087]\n",
      "[Epoch 41/200] [Batch 112/637] [D loss: 0.183174] [G loss: 0.380700]\n",
      "[Epoch 41/200] [Batch 113/637] [D loss: 0.158873] [G loss: 0.531549]\n",
      "[Epoch 41/200] [Batch 114/637] [D loss: 0.190405] [G loss: 0.507478]\n",
      "[Epoch 41/200] [Batch 115/637] [D loss: 0.158073] [G loss: 0.565727]\n",
      "[Epoch 41/200] [Batch 116/637] [D loss: 0.154806] [G loss: 0.512770]\n",
      "[Epoch 41/200] [Batch 117/637] [D loss: 0.142521] [G loss: 0.536894]\n",
      "[Epoch 41/200] [Batch 118/637] [D loss: 0.143597] [G loss: 0.557386]\n",
      "[Epoch 41/200] [Batch 119/637] [D loss: 0.174829] [G loss: 0.447424]\n",
      "[Epoch 41/200] [Batch 120/637] [D loss: 0.162767] [G loss: 0.494744]\n",
      "[Epoch 41/200] [Batch 121/637] [D loss: 0.185605] [G loss: 0.440790]\n",
      "[Epoch 41/200] [Batch 122/637] [D loss: 0.158198] [G loss: 0.512728]\n",
      "[Epoch 41/200] [Batch 123/637] [D loss: 0.146735] [G loss: 0.576635]\n",
      "[Epoch 41/200] [Batch 124/637] [D loss: 0.167257] [G loss: 0.533847]\n",
      "[Epoch 41/200] [Batch 125/637] [D loss: 0.166431] [G loss: 0.478840]\n",
      "[Epoch 41/200] [Batch 126/637] [D loss: 0.165187] [G loss: 0.479028]\n",
      "[Epoch 41/200] [Batch 127/637] [D loss: 0.154373] [G loss: 0.495294]\n",
      "[Epoch 41/200] [Batch 128/637] [D loss: 0.147786] [G loss: 0.568676]\n",
      "[Epoch 41/200] [Batch 129/637] [D loss: 0.259759] [G loss: 0.511636]\n",
      "[Epoch 41/200] [Batch 130/637] [D loss: 0.218825] [G loss: 0.529006]\n",
      "[Epoch 41/200] [Batch 131/637] [D loss: 0.206434] [G loss: 0.442993]\n",
      "[Epoch 41/200] [Batch 132/637] [D loss: 0.167345] [G loss: 0.572401]\n",
      "[Epoch 41/200] [Batch 133/637] [D loss: 0.199345] [G loss: 0.516359]\n",
      "[Epoch 41/200] [Batch 134/637] [D loss: 0.169087] [G loss: 0.517960]\n",
      "[Epoch 41/200] [Batch 135/637] [D loss: 0.162655] [G loss: 0.516145]\n",
      "[Epoch 41/200] [Batch 136/637] [D loss: 0.166076] [G loss: 0.486633]\n",
      "[Epoch 41/200] [Batch 137/637] [D loss: 0.169930] [G loss: 0.482785]\n",
      "[Epoch 41/200] [Batch 138/637] [D loss: 0.160165] [G loss: 0.555950]\n",
      "[Epoch 41/200] [Batch 139/637] [D loss: 0.153813] [G loss: 0.475563]\n",
      "[Epoch 41/200] [Batch 140/637] [D loss: 0.167768] [G loss: 0.492856]\n",
      "[Epoch 41/200] [Batch 141/637] [D loss: 0.183975] [G loss: 0.481355]\n",
      "[Epoch 41/200] [Batch 142/637] [D loss: 0.180244] [G loss: 0.448632]\n",
      "[Epoch 41/200] [Batch 143/637] [D loss: 0.168756] [G loss: 0.522736]\n",
      "[Epoch 41/200] [Batch 144/637] [D loss: 0.152812] [G loss: 0.530219]\n",
      "[Epoch 41/200] [Batch 145/637] [D loss: 0.206583] [G loss: 0.499288]\n",
      "[Epoch 41/200] [Batch 146/637] [D loss: 0.166466] [G loss: 0.445045]\n",
      "[Epoch 41/200] [Batch 147/637] [D loss: 0.194784] [G loss: 0.438282]\n",
      "[Epoch 41/200] [Batch 148/637] [D loss: 0.167395] [G loss: 0.508545]\n",
      "[Epoch 41/200] [Batch 149/637] [D loss: 0.182057] [G loss: 0.505242]\n",
      "[Epoch 41/200] [Batch 150/637] [D loss: 0.159441] [G loss: 0.489410]\n",
      "[Epoch 41/200] [Batch 151/637] [D loss: 0.166377] [G loss: 0.502759]\n",
      "[Epoch 41/200] [Batch 152/637] [D loss: 0.200030] [G loss: 0.397458]\n",
      "[Epoch 41/200] [Batch 153/637] [D loss: 0.166351] [G loss: 0.478846]\n",
      "[Epoch 41/200] [Batch 154/637] [D loss: 0.156913] [G loss: 0.470404]\n",
      "[Epoch 41/200] [Batch 155/637] [D loss: 0.176087] [G loss: 0.449519]\n",
      "[Epoch 41/200] [Batch 156/637] [D loss: 0.147606] [G loss: 0.510505]\n",
      "[Epoch 41/200] [Batch 157/637] [D loss: 0.154288] [G loss: 0.505715]\n",
      "[Epoch 41/200] [Batch 158/637] [D loss: 0.173835] [G loss: 0.435761]\n",
      "[Epoch 41/200] [Batch 159/637] [D loss: 0.170568] [G loss: 0.451343]\n",
      "[Epoch 41/200] [Batch 160/637] [D loss: 0.154439] [G loss: 0.490986]\n",
      "[Epoch 41/200] [Batch 161/637] [D loss: 0.152213] [G loss: 0.467116]\n",
      "[Epoch 41/200] [Batch 162/637] [D loss: 0.165069] [G loss: 0.516001]\n",
      "[Epoch 41/200] [Batch 163/637] [D loss: 0.207015] [G loss: 0.445444]\n",
      "[Epoch 41/200] [Batch 164/637] [D loss: 0.190610] [G loss: 0.488553]\n",
      "[Epoch 41/200] [Batch 165/637] [D loss: 0.185148] [G loss: 0.463776]\n",
      "[Epoch 41/200] [Batch 166/637] [D loss: 0.174803] [G loss: 0.414372]\n",
      "[Epoch 41/200] [Batch 167/637] [D loss: 0.170723] [G loss: 0.402220]\n",
      "[Epoch 41/200] [Batch 168/637] [D loss: 0.161619] [G loss: 0.467450]\n",
      "[Epoch 41/200] [Batch 169/637] [D loss: 0.148570] [G loss: 0.478145]\n",
      "[Epoch 41/200] [Batch 170/637] [D loss: 0.187722] [G loss: 0.400094]\n",
      "[Epoch 41/200] [Batch 171/637] [D loss: 0.182716] [G loss: 0.428504]\n",
      "[Epoch 41/200] [Batch 172/637] [D loss: 0.170268] [G loss: 0.526572]\n",
      "[Epoch 41/200] [Batch 173/637] [D loss: 0.178575] [G loss: 0.462716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/200] [Batch 174/637] [D loss: 0.192424] [G loss: 0.440703]\n",
      "[Epoch 41/200] [Batch 175/637] [D loss: 0.180650] [G loss: 0.472097]\n",
      "[Epoch 41/200] [Batch 176/637] [D loss: 0.162927] [G loss: 0.485806]\n",
      "[Epoch 41/200] [Batch 177/637] [D loss: 0.183710] [G loss: 0.477843]\n",
      "[Epoch 41/200] [Batch 178/637] [D loss: 0.137920] [G loss: 0.531495]\n",
      "[Epoch 41/200] [Batch 179/637] [D loss: 0.158388] [G loss: 0.478777]\n",
      "[Epoch 41/200] [Batch 180/637] [D loss: 0.189042] [G loss: 0.392244]\n",
      "[Epoch 41/200] [Batch 181/637] [D loss: 0.185875] [G loss: 0.573704]\n",
      "[Epoch 41/200] [Batch 182/637] [D loss: 0.177112] [G loss: 0.476159]\n",
      "[Epoch 41/200] [Batch 183/637] [D loss: 0.162826] [G loss: 0.507306]\n",
      "[Epoch 41/200] [Batch 184/637] [D loss: 0.164372] [G loss: 0.428629]\n",
      "[Epoch 41/200] [Batch 185/637] [D loss: 0.168135] [G loss: 0.476932]\n",
      "[Epoch 41/200] [Batch 186/637] [D loss: 0.194730] [G loss: 0.455864]\n",
      "[Epoch 41/200] [Batch 187/637] [D loss: 0.168991] [G loss: 0.466313]\n",
      "[Epoch 41/200] [Batch 188/637] [D loss: 0.153932] [G loss: 0.481308]\n",
      "[Epoch 41/200] [Batch 189/637] [D loss: 0.158718] [G loss: 0.433727]\n",
      "[Epoch 41/200] [Batch 190/637] [D loss: 0.187712] [G loss: 0.466061]\n",
      "[Epoch 41/200] [Batch 191/637] [D loss: 0.168583] [G loss: 0.497211]\n",
      "[Epoch 41/200] [Batch 192/637] [D loss: 0.188974] [G loss: 0.437313]\n",
      "[Epoch 41/200] [Batch 193/637] [D loss: 0.174102] [G loss: 0.590974]\n",
      "[Epoch 41/200] [Batch 194/637] [D loss: 0.173585] [G loss: 0.553776]\n",
      "[Epoch 41/200] [Batch 195/637] [D loss: 0.158175] [G loss: 0.469565]\n",
      "[Epoch 41/200] [Batch 196/637] [D loss: 0.145486] [G loss: 0.491805]\n",
      "[Epoch 41/200] [Batch 197/637] [D loss: 0.155304] [G loss: 0.468291]\n",
      "[Epoch 41/200] [Batch 198/637] [D loss: 0.160319] [G loss: 0.458431]\n",
      "[Epoch 41/200] [Batch 199/637] [D loss: 0.182187] [G loss: 0.488395]\n",
      "[Epoch 41/200] [Batch 200/637] [D loss: 0.165544] [G loss: 0.588493]\n",
      "[Epoch 41/200] [Batch 201/637] [D loss: 0.161912] [G loss: 0.478785]\n",
      "[Epoch 41/200] [Batch 202/637] [D loss: 0.185504] [G loss: 0.410205]\n",
      "[Epoch 41/200] [Batch 203/637] [D loss: 0.164469] [G loss: 0.483586]\n",
      "[Epoch 41/200] [Batch 204/637] [D loss: 0.161482] [G loss: 0.623916]\n",
      "[Epoch 41/200] [Batch 205/637] [D loss: 0.167798] [G loss: 0.517528]\n",
      "[Epoch 41/200] [Batch 206/637] [D loss: 0.175252] [G loss: 0.481350]\n",
      "[Epoch 41/200] [Batch 207/637] [D loss: 0.175559] [G loss: 0.429546]\n",
      "[Epoch 41/200] [Batch 208/637] [D loss: 0.178880] [G loss: 0.522363]\n",
      "[Epoch 41/200] [Batch 209/637] [D loss: 0.161259] [G loss: 0.441232]\n",
      "[Epoch 41/200] [Batch 210/637] [D loss: 0.185492] [G loss: 0.543111]\n",
      "[Epoch 41/200] [Batch 211/637] [D loss: 0.182262] [G loss: 0.500076]\n",
      "[Epoch 41/200] [Batch 212/637] [D loss: 0.156277] [G loss: 0.457715]\n",
      "[Epoch 41/200] [Batch 213/637] [D loss: 0.173907] [G loss: 0.423959]\n",
      "[Epoch 41/200] [Batch 214/637] [D loss: 0.145942] [G loss: 0.507136]\n",
      "[Epoch 41/200] [Batch 215/637] [D loss: 0.161084] [G loss: 0.496327]\n",
      "[Epoch 41/200] [Batch 216/637] [D loss: 0.177112] [G loss: 0.508049]\n",
      "[Epoch 41/200] [Batch 217/637] [D loss: 0.194030] [G loss: 0.444568]\n",
      "[Epoch 41/200] [Batch 218/637] [D loss: 0.187863] [G loss: 0.434520]\n",
      "[Epoch 41/200] [Batch 219/637] [D loss: 0.176740] [G loss: 0.483752]\n",
      "[Epoch 41/200] [Batch 220/637] [D loss: 0.174698] [G loss: 0.515773]\n",
      "[Epoch 41/200] [Batch 221/637] [D loss: 0.175910] [G loss: 0.500446]\n",
      "[Epoch 41/200] [Batch 222/637] [D loss: 0.179102] [G loss: 0.473719]\n",
      "[Epoch 41/200] [Batch 223/637] [D loss: 0.165027] [G loss: 0.435956]\n",
      "[Epoch 41/200] [Batch 224/637] [D loss: 0.164923] [G loss: 0.471232]\n",
      "[Epoch 41/200] [Batch 225/637] [D loss: 0.164474] [G loss: 0.556967]\n",
      "[Epoch 41/200] [Batch 226/637] [D loss: 0.175152] [G loss: 0.558546]\n",
      "[Epoch 41/200] [Batch 227/637] [D loss: 0.171323] [G loss: 0.514044]\n",
      "[Epoch 41/200] [Batch 228/637] [D loss: 0.155142] [G loss: 0.470910]\n",
      "[Epoch 41/200] [Batch 229/637] [D loss: 0.176201] [G loss: 0.480941]\n",
      "[Epoch 41/200] [Batch 230/637] [D loss: 0.172102] [G loss: 0.662536]\n",
      "[Epoch 41/200] [Batch 231/637] [D loss: 0.186939] [G loss: 0.530659]\n",
      "[Epoch 41/200] [Batch 232/637] [D loss: 0.200997] [G loss: 0.408872]\n",
      "[Epoch 41/200] [Batch 233/637] [D loss: 0.163125] [G loss: 0.524992]\n",
      "[Epoch 41/200] [Batch 234/637] [D loss: 0.176897] [G loss: 0.492516]\n",
      "[Epoch 41/200] [Batch 235/637] [D loss: 0.172253] [G loss: 0.510287]\n",
      "[Epoch 41/200] [Batch 236/637] [D loss: 0.189052] [G loss: 0.465644]\n",
      "[Epoch 41/200] [Batch 237/637] [D loss: 0.161690] [G loss: 0.538955]\n",
      "[Epoch 41/200] [Batch 238/637] [D loss: 0.155176] [G loss: 0.510645]\n",
      "[Epoch 41/200] [Batch 239/637] [D loss: 0.178039] [G loss: 0.510903]\n",
      "[Epoch 41/200] [Batch 240/637] [D loss: 0.184660] [G loss: 0.473990]\n",
      "[Epoch 41/200] [Batch 241/637] [D loss: 0.148191] [G loss: 0.545635]\n",
      "[Epoch 41/200] [Batch 242/637] [D loss: 0.183619] [G loss: 0.458081]\n",
      "[Epoch 41/200] [Batch 243/637] [D loss: 0.192650] [G loss: 0.492839]\n",
      "[Epoch 41/200] [Batch 244/637] [D loss: 0.164079] [G loss: 0.529841]\n",
      "[Epoch 41/200] [Batch 245/637] [D loss: 0.192158] [G loss: 0.542208]\n",
      "[Epoch 41/200] [Batch 246/637] [D loss: 0.182405] [G loss: 0.439586]\n",
      "[Epoch 41/200] [Batch 247/637] [D loss: 0.179217] [G loss: 0.492122]\n",
      "[Epoch 41/200] [Batch 248/637] [D loss: 0.185381] [G loss: 0.431705]\n",
      "[Epoch 41/200] [Batch 249/637] [D loss: 0.195037] [G loss: 0.491946]\n",
      "[Epoch 41/200] [Batch 250/637] [D loss: 0.158439] [G loss: 0.526564]\n",
      "[Epoch 41/200] [Batch 251/637] [D loss: 0.188261] [G loss: 0.504414]\n",
      "[Epoch 41/200] [Batch 252/637] [D loss: 0.168032] [G loss: 0.487988]\n",
      "[Epoch 41/200] [Batch 253/637] [D loss: 0.172790] [G loss: 0.510417]\n",
      "[Epoch 41/200] [Batch 254/637] [D loss: 0.170851] [G loss: 0.468689]\n",
      "[Epoch 41/200] [Batch 255/637] [D loss: 0.158873] [G loss: 0.506522]\n",
      "[Epoch 41/200] [Batch 256/637] [D loss: 0.175882] [G loss: 0.503850]\n",
      "[Epoch 41/200] [Batch 257/637] [D loss: 0.164928] [G loss: 0.507142]\n",
      "[Epoch 41/200] [Batch 258/637] [D loss: 0.173122] [G loss: 0.457020]\n",
      "[Epoch 41/200] [Batch 259/637] [D loss: 0.152678] [G loss: 0.519421]\n",
      "[Epoch 41/200] [Batch 260/637] [D loss: 0.149544] [G loss: 0.536042]\n",
      "[Epoch 41/200] [Batch 261/637] [D loss: 0.176566] [G loss: 0.461288]\n",
      "[Epoch 41/200] [Batch 262/637] [D loss: 0.163415] [G loss: 0.483505]\n",
      "[Epoch 41/200] [Batch 263/637] [D loss: 0.179771] [G loss: 0.455855]\n",
      "[Epoch 41/200] [Batch 264/637] [D loss: 0.153336] [G loss: 0.543701]\n",
      "[Epoch 41/200] [Batch 265/637] [D loss: 0.170814] [G loss: 0.456935]\n",
      "[Epoch 41/200] [Batch 266/637] [D loss: 0.165747] [G loss: 0.544959]\n",
      "[Epoch 41/200] [Batch 267/637] [D loss: 0.191581] [G loss: 0.480116]\n",
      "[Epoch 41/200] [Batch 268/637] [D loss: 0.178030] [G loss: 0.471261]\n",
      "[Epoch 41/200] [Batch 269/637] [D loss: 0.170147] [G loss: 0.487018]\n",
      "[Epoch 41/200] [Batch 270/637] [D loss: 0.157775] [G loss: 0.497515]\n",
      "[Epoch 41/200] [Batch 271/637] [D loss: 0.177460] [G loss: 0.499426]\n",
      "[Epoch 41/200] [Batch 272/637] [D loss: 0.164358] [G loss: 0.553671]\n",
      "[Epoch 41/200] [Batch 273/637] [D loss: 0.161799] [G loss: 0.519303]\n",
      "[Epoch 41/200] [Batch 274/637] [D loss: 0.167817] [G loss: 0.459716]\n",
      "[Epoch 41/200] [Batch 275/637] [D loss: 0.168666] [G loss: 0.469257]\n",
      "[Epoch 41/200] [Batch 276/637] [D loss: 0.170352] [G loss: 0.493588]\n",
      "[Epoch 41/200] [Batch 277/637] [D loss: 0.179792] [G loss: 0.464618]\n",
      "[Epoch 41/200] [Batch 278/637] [D loss: 0.179249] [G loss: 0.516879]\n",
      "[Epoch 41/200] [Batch 279/637] [D loss: 0.165907] [G loss: 0.520868]\n",
      "[Epoch 41/200] [Batch 280/637] [D loss: 0.160951] [G loss: 0.512352]\n",
      "[Epoch 41/200] [Batch 281/637] [D loss: 0.179814] [G loss: 0.513058]\n",
      "[Epoch 41/200] [Batch 282/637] [D loss: 0.151795] [G loss: 0.536007]\n",
      "[Epoch 41/200] [Batch 283/637] [D loss: 0.178952] [G loss: 0.456849]\n",
      "[Epoch 41/200] [Batch 284/637] [D loss: 0.172243] [G loss: 0.424549]\n",
      "[Epoch 41/200] [Batch 285/637] [D loss: 0.159334] [G loss: 0.542570]\n",
      "[Epoch 41/200] [Batch 286/637] [D loss: 0.164025] [G loss: 0.504563]\n",
      "[Epoch 41/200] [Batch 287/637] [D loss: 0.196384] [G loss: 0.484299]\n",
      "[Epoch 41/200] [Batch 288/637] [D loss: 0.169722] [G loss: 0.549941]\n",
      "[Epoch 41/200] [Batch 289/637] [D loss: 0.206473] [G loss: 0.404636]\n",
      "[Epoch 41/200] [Batch 290/637] [D loss: 0.186626] [G loss: 0.472334]\n",
      "[Epoch 41/200] [Batch 291/637] [D loss: 0.185508] [G loss: 0.499128]\n",
      "[Epoch 41/200] [Batch 292/637] [D loss: 0.160019] [G loss: 0.494410]\n",
      "[Epoch 41/200] [Batch 293/637] [D loss: 0.182142] [G loss: 0.433215]\n",
      "[Epoch 41/200] [Batch 294/637] [D loss: 0.174942] [G loss: 0.480229]\n",
      "[Epoch 41/200] [Batch 295/637] [D loss: 0.164580] [G loss: 0.449033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/200] [Batch 296/637] [D loss: 0.160529] [G loss: 0.520929]\n",
      "[Epoch 41/200] [Batch 297/637] [D loss: 0.144045] [G loss: 0.523251]\n",
      "[Epoch 41/200] [Batch 298/637] [D loss: 0.181778] [G loss: 0.416709]\n",
      "[Epoch 41/200] [Batch 299/637] [D loss: 0.161659] [G loss: 0.498945]\n",
      "[Epoch 41/200] [Batch 300/637] [D loss: 0.159924] [G loss: 0.506299]\n",
      "[Epoch 41/200] [Batch 301/637] [D loss: 0.152343] [G loss: 0.520332]\n",
      "[Epoch 41/200] [Batch 302/637] [D loss: 0.170218] [G loss: 0.414384]\n",
      "[Epoch 41/200] [Batch 303/637] [D loss: 0.175920] [G loss: 0.476105]\n",
      "[Epoch 41/200] [Batch 304/637] [D loss: 0.158303] [G loss: 0.559588]\n",
      "[Epoch 41/200] [Batch 305/637] [D loss: 0.170884] [G loss: 0.592745]\n",
      "[Epoch 41/200] [Batch 306/637] [D loss: 0.205260] [G loss: 0.435703]\n",
      "[Epoch 41/200] [Batch 307/637] [D loss: 0.153016] [G loss: 0.508001]\n",
      "[Epoch 41/200] [Batch 308/637] [D loss: 0.216444] [G loss: 0.534388]\n",
      "[Epoch 41/200] [Batch 309/637] [D loss: 0.158865] [G loss: 0.494768]\n",
      "[Epoch 41/200] [Batch 310/637] [D loss: 0.196964] [G loss: 0.469547]\n",
      "[Epoch 41/200] [Batch 311/637] [D loss: 0.172573] [G loss: 0.524189]\n",
      "[Epoch 41/200] [Batch 312/637] [D loss: 0.191376] [G loss: 0.500651]\n",
      "[Epoch 41/200] [Batch 313/637] [D loss: 0.182829] [G loss: 0.465410]\n",
      "[Epoch 41/200] [Batch 314/637] [D loss: 0.188513] [G loss: 0.484706]\n",
      "[Epoch 41/200] [Batch 315/637] [D loss: 0.181963] [G loss: 0.411414]\n",
      "[Epoch 41/200] [Batch 316/637] [D loss: 0.214567] [G loss: 0.446631]\n",
      "[Epoch 41/200] [Batch 317/637] [D loss: 0.186212] [G loss: 0.516308]\n",
      "[Epoch 41/200] [Batch 318/637] [D loss: 0.190399] [G loss: 0.495768]\n",
      "[Epoch 41/200] [Batch 319/637] [D loss: 0.187173] [G loss: 0.477135]\n",
      "[Epoch 41/200] [Batch 320/637] [D loss: 0.167209] [G loss: 0.499540]\n",
      "[Epoch 41/200] [Batch 321/637] [D loss: 0.184115] [G loss: 0.425444]\n",
      "[Epoch 41/200] [Batch 322/637] [D loss: 0.172936] [G loss: 0.474670]\n",
      "[Epoch 41/200] [Batch 323/637] [D loss: 0.180440] [G loss: 0.445820]\n",
      "[Epoch 41/200] [Batch 324/637] [D loss: 0.144639] [G loss: 0.547232]\n",
      "[Epoch 41/200] [Batch 325/637] [D loss: 0.179897] [G loss: 0.537996]\n",
      "[Epoch 41/200] [Batch 326/637] [D loss: 0.169230] [G loss: 0.484279]\n",
      "[Epoch 41/200] [Batch 327/637] [D loss: 0.172764] [G loss: 0.469694]\n",
      "[Epoch 41/200] [Batch 328/637] [D loss: 0.151921] [G loss: 0.550099]\n",
      "[Epoch 41/200] [Batch 329/637] [D loss: 0.159750] [G loss: 0.535927]\n",
      "[Epoch 41/200] [Batch 330/637] [D loss: 0.163306] [G loss: 0.518442]\n",
      "[Epoch 41/200] [Batch 331/637] [D loss: 0.154296] [G loss: 0.495588]\n",
      "[Epoch 41/200] [Batch 332/637] [D loss: 0.185707] [G loss: 0.461004]\n",
      "[Epoch 41/200] [Batch 333/637] [D loss: 0.173407] [G loss: 0.530287]\n",
      "[Epoch 41/200] [Batch 334/637] [D loss: 0.163352] [G loss: 0.581727]\n",
      "[Epoch 41/200] [Batch 335/637] [D loss: 0.149136] [G loss: 0.517854]\n",
      "[Epoch 41/200] [Batch 336/637] [D loss: 0.186789] [G loss: 0.453265]\n",
      "[Epoch 41/200] [Batch 337/637] [D loss: 0.147350] [G loss: 0.519397]\n",
      "[Epoch 41/200] [Batch 338/637] [D loss: 0.148669] [G loss: 0.509953]\n",
      "[Epoch 41/200] [Batch 339/637] [D loss: 0.139302] [G loss: 0.515149]\n",
      "[Epoch 41/200] [Batch 340/637] [D loss: 0.168471] [G loss: 0.515837]\n",
      "[Epoch 41/200] [Batch 341/637] [D loss: 0.145963] [G loss: 0.726482]\n",
      "[Epoch 41/200] [Batch 342/637] [D loss: 0.166534] [G loss: 0.551551]\n",
      "[Epoch 41/200] [Batch 343/637] [D loss: 0.170271] [G loss: 0.514832]\n",
      "[Epoch 41/200] [Batch 344/637] [D loss: 0.195065] [G loss: 0.406283]\n",
      "[Epoch 41/200] [Batch 345/637] [D loss: 0.222242] [G loss: 0.427847]\n",
      "[Epoch 41/200] [Batch 346/637] [D loss: 0.194508] [G loss: 0.563550]\n",
      "[Epoch 41/200] [Batch 347/637] [D loss: 0.171139] [G loss: 0.480989]\n",
      "[Epoch 41/200] [Batch 348/637] [D loss: 0.176419] [G loss: 0.448199]\n",
      "[Epoch 41/200] [Batch 349/637] [D loss: 0.163244] [G loss: 0.478350]\n",
      "[Epoch 41/200] [Batch 350/637] [D loss: 0.201012] [G loss: 0.500431]\n",
      "[Epoch 41/200] [Batch 351/637] [D loss: 0.203508] [G loss: 0.626080]\n",
      "[Epoch 41/200] [Batch 352/637] [D loss: 0.169293] [G loss: 0.508857]\n",
      "[Epoch 41/200] [Batch 353/637] [D loss: 0.163018] [G loss: 0.570282]\n",
      "[Epoch 41/200] [Batch 354/637] [D loss: 0.188941] [G loss: 0.437836]\n",
      "[Epoch 41/200] [Batch 355/637] [D loss: 0.151251] [G loss: 0.488423]\n",
      "[Epoch 41/200] [Batch 356/637] [D loss: 0.153207] [G loss: 0.467557]\n",
      "[Epoch 41/200] [Batch 357/637] [D loss: 0.161266] [G loss: 0.552597]\n",
      "[Epoch 41/200] [Batch 358/637] [D loss: 0.166988] [G loss: 0.503098]\n",
      "[Epoch 41/200] [Batch 359/637] [D loss: 0.153410] [G loss: 0.532088]\n",
      "[Epoch 41/200] [Batch 360/637] [D loss: 0.159749] [G loss: 0.459891]\n",
      "[Epoch 41/200] [Batch 361/637] [D loss: 0.170347] [G loss: 0.447100]\n",
      "[Epoch 41/200] [Batch 362/637] [D loss: 0.184832] [G loss: 0.555953]\n",
      "[Epoch 41/200] [Batch 363/637] [D loss: 0.192518] [G loss: 0.470264]\n",
      "[Epoch 41/200] [Batch 364/637] [D loss: 0.169826] [G loss: 0.464301]\n",
      "[Epoch 41/200] [Batch 365/637] [D loss: 0.170691] [G loss: 0.465160]\n",
      "[Epoch 41/200] [Batch 366/637] [D loss: 0.146995] [G loss: 0.577924]\n",
      "[Epoch 41/200] [Batch 367/637] [D loss: 0.164623] [G loss: 0.516898]\n",
      "[Epoch 41/200] [Batch 368/637] [D loss: 0.175110] [G loss: 0.507509]\n",
      "[Epoch 41/200] [Batch 369/637] [D loss: 0.186804] [G loss: 0.463400]\n",
      "[Epoch 41/200] [Batch 370/637] [D loss: 0.193880] [G loss: 0.467695]\n",
      "[Epoch 41/200] [Batch 371/637] [D loss: 0.160472] [G loss: 0.517470]\n",
      "[Epoch 41/200] [Batch 372/637] [D loss: 0.187308] [G loss: 0.492404]\n",
      "[Epoch 41/200] [Batch 373/637] [D loss: 0.156285] [G loss: 0.538725]\n",
      "[Epoch 41/200] [Batch 374/637] [D loss: 0.192890] [G loss: 0.434077]\n",
      "[Epoch 41/200] [Batch 375/637] [D loss: 0.177823] [G loss: 0.424685]\n",
      "[Epoch 41/200] [Batch 376/637] [D loss: 0.187491] [G loss: 0.436579]\n",
      "[Epoch 41/200] [Batch 377/637] [D loss: 0.185994] [G loss: 0.468223]\n",
      "[Epoch 41/200] [Batch 378/637] [D loss: 0.179961] [G loss: 0.506821]\n",
      "[Epoch 41/200] [Batch 379/637] [D loss: 0.178617] [G loss: 0.486712]\n",
      "[Epoch 41/200] [Batch 380/637] [D loss: 0.174755] [G loss: 0.473357]\n",
      "[Epoch 41/200] [Batch 381/637] [D loss: 0.172714] [G loss: 0.462049]\n",
      "[Epoch 41/200] [Batch 382/637] [D loss: 0.182596] [G loss: 0.390971]\n",
      "[Epoch 41/200] [Batch 383/637] [D loss: 0.202712] [G loss: 0.461561]\n",
      "[Epoch 41/200] [Batch 384/637] [D loss: 0.156649] [G loss: 0.534269]\n",
      "[Epoch 41/200] [Batch 385/637] [D loss: 0.163776] [G loss: 0.497586]\n",
      "[Epoch 41/200] [Batch 386/637] [D loss: 0.170078] [G loss: 0.440768]\n",
      "[Epoch 41/200] [Batch 387/637] [D loss: 0.145820] [G loss: 0.539858]\n",
      "[Epoch 41/200] [Batch 388/637] [D loss: 0.159765] [G loss: 0.556646]\n",
      "[Epoch 41/200] [Batch 389/637] [D loss: 0.170385] [G loss: 0.505448]\n",
      "[Epoch 41/200] [Batch 390/637] [D loss: 0.144252] [G loss: 0.511539]\n",
      "[Epoch 41/200] [Batch 391/637] [D loss: 0.206458] [G loss: 0.504072]\n",
      "[Epoch 41/200] [Batch 392/637] [D loss: 0.171340] [G loss: 0.571118]\n",
      "[Epoch 41/200] [Batch 393/637] [D loss: 0.179527] [G loss: 0.579300]\n",
      "[Epoch 41/200] [Batch 394/637] [D loss: 0.159893] [G loss: 0.451339]\n",
      "[Epoch 41/200] [Batch 395/637] [D loss: 0.180596] [G loss: 0.434466]\n",
      "[Epoch 41/200] [Batch 396/637] [D loss: 0.156253] [G loss: 0.508184]\n",
      "[Epoch 41/200] [Batch 397/637] [D loss: 0.170667] [G loss: 0.475406]\n",
      "[Epoch 41/200] [Batch 398/637] [D loss: 0.186140] [G loss: 0.478705]\n",
      "[Epoch 41/200] [Batch 399/637] [D loss: 0.171917] [G loss: 0.555721]\n",
      "[Epoch 41/200] [Batch 400/637] [D loss: 0.158913] [G loss: 0.538132]\n",
      "[Epoch 41/200] [Batch 401/637] [D loss: 0.179484] [G loss: 0.650363]\n",
      "[Epoch 41/200] [Batch 402/637] [D loss: 0.175551] [G loss: 0.479051]\n",
      "[Epoch 41/200] [Batch 403/637] [D loss: 0.207341] [G loss: 0.448552]\n",
      "[Epoch 41/200] [Batch 404/637] [D loss: 0.151531] [G loss: 0.515814]\n",
      "[Epoch 41/200] [Batch 405/637] [D loss: 0.168817] [G loss: 0.492924]\n",
      "[Epoch 41/200] [Batch 406/637] [D loss: 0.170391] [G loss: 0.490632]\n",
      "[Epoch 41/200] [Batch 407/637] [D loss: 0.194154] [G loss: 0.479166]\n",
      "[Epoch 41/200] [Batch 408/637] [D loss: 0.182794] [G loss: 0.506429]\n",
      "[Epoch 41/200] [Batch 409/637] [D loss: 0.157667] [G loss: 0.491795]\n",
      "[Epoch 41/200] [Batch 410/637] [D loss: 0.170916] [G loss: 0.503717]\n",
      "[Epoch 41/200] [Batch 411/637] [D loss: 0.150302] [G loss: 0.534194]\n",
      "[Epoch 41/200] [Batch 412/637] [D loss: 0.195181] [G loss: 0.471016]\n",
      "[Epoch 41/200] [Batch 413/637] [D loss: 0.170494] [G loss: 0.449706]\n",
      "[Epoch 41/200] [Batch 414/637] [D loss: 0.180241] [G loss: 0.448506]\n",
      "[Epoch 41/200] [Batch 415/637] [D loss: 0.174058] [G loss: 0.501676]\n",
      "[Epoch 41/200] [Batch 416/637] [D loss: 0.169510] [G loss: 0.461382]\n",
      "[Epoch 41/200] [Batch 417/637] [D loss: 0.167600] [G loss: 0.502471]\n",
      "[Epoch 41/200] [Batch 418/637] [D loss: 0.159116] [G loss: 0.506081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/200] [Batch 419/637] [D loss: 0.163844] [G loss: 0.526830]\n",
      "[Epoch 41/200] [Batch 420/637] [D loss: 0.163072] [G loss: 0.485746]\n",
      "[Epoch 41/200] [Batch 421/637] [D loss: 0.145312] [G loss: 0.513071]\n",
      "[Epoch 41/200] [Batch 422/637] [D loss: 0.175948] [G loss: 0.469882]\n",
      "[Epoch 41/200] [Batch 423/637] [D loss: 0.185899] [G loss: 0.457050]\n",
      "[Epoch 41/200] [Batch 424/637] [D loss: 0.166521] [G loss: 0.501869]\n",
      "[Epoch 41/200] [Batch 425/637] [D loss: 0.176381] [G loss: 0.478212]\n",
      "[Epoch 41/200] [Batch 426/637] [D loss: 0.160279] [G loss: 0.455341]\n",
      "[Epoch 41/200] [Batch 427/637] [D loss: 0.176656] [G loss: 0.473777]\n",
      "[Epoch 41/200] [Batch 428/637] [D loss: 0.185091] [G loss: 0.468460]\n",
      "[Epoch 41/200] [Batch 429/637] [D loss: 0.155847] [G loss: 0.536849]\n",
      "[Epoch 41/200] [Batch 430/637] [D loss: 0.174961] [G loss: 0.499823]\n",
      "[Epoch 41/200] [Batch 431/637] [D loss: 0.180614] [G loss: 0.519032]\n",
      "[Epoch 41/200] [Batch 432/637] [D loss: 0.167250] [G loss: 0.470687]\n",
      "[Epoch 41/200] [Batch 433/637] [D loss: 0.179819] [G loss: 0.427426]\n",
      "[Epoch 41/200] [Batch 434/637] [D loss: 0.164016] [G loss: 0.451791]\n",
      "[Epoch 41/200] [Batch 435/637] [D loss: 0.177852] [G loss: 0.447283]\n",
      "[Epoch 41/200] [Batch 436/637] [D loss: 0.174362] [G loss: 0.502766]\n",
      "[Epoch 41/200] [Batch 437/637] [D loss: 0.180718] [G loss: 0.444875]\n",
      "[Epoch 41/200] [Batch 438/637] [D loss: 0.173286] [G loss: 0.438846]\n",
      "[Epoch 41/200] [Batch 439/637] [D loss: 0.172895] [G loss: 0.475952]\n",
      "[Epoch 41/200] [Batch 440/637] [D loss: 0.165173] [G loss: 0.507617]\n",
      "[Epoch 41/200] [Batch 441/637] [D loss: 0.162975] [G loss: 0.505008]\n",
      "[Epoch 41/200] [Batch 442/637] [D loss: 0.171026] [G loss: 0.568766]\n",
      "[Epoch 41/200] [Batch 443/637] [D loss: 0.178975] [G loss: 0.496524]\n",
      "[Epoch 41/200] [Batch 444/637] [D loss: 0.211039] [G loss: 0.418136]\n",
      "[Epoch 41/200] [Batch 445/637] [D loss: 0.198826] [G loss: 0.368101]\n",
      "[Epoch 41/200] [Batch 446/637] [D loss: 0.197674] [G loss: 0.443492]\n",
      "[Epoch 41/200] [Batch 447/637] [D loss: 0.187459] [G loss: 0.454057]\n",
      "[Epoch 41/200] [Batch 448/637] [D loss: 0.181991] [G loss: 0.460792]\n",
      "[Epoch 41/200] [Batch 449/637] [D loss: 0.149242] [G loss: 0.462840]\n",
      "[Epoch 41/200] [Batch 450/637] [D loss: 0.164419] [G loss: 0.421433]\n",
      "[Epoch 41/200] [Batch 451/637] [D loss: 0.164858] [G loss: 0.425479]\n",
      "[Epoch 41/200] [Batch 452/637] [D loss: 0.170893] [G loss: 0.482203]\n",
      "[Epoch 41/200] [Batch 453/637] [D loss: 0.165719] [G loss: 0.548688]\n",
      "[Epoch 41/200] [Batch 454/637] [D loss: 0.171871] [G loss: 0.506747]\n",
      "[Epoch 41/200] [Batch 455/637] [D loss: 0.193171] [G loss: 0.426337]\n",
      "[Epoch 41/200] [Batch 456/637] [D loss: 0.159541] [G loss: 0.531980]\n",
      "[Epoch 41/200] [Batch 457/637] [D loss: 0.223754] [G loss: 0.489601]\n",
      "[Epoch 41/200] [Batch 458/637] [D loss: 0.218640] [G loss: 0.487385]\n",
      "[Epoch 41/200] [Batch 459/637] [D loss: 0.184831] [G loss: 0.490452]\n",
      "[Epoch 41/200] [Batch 460/637] [D loss: 0.197479] [G loss: 0.454689]\n",
      "[Epoch 41/200] [Batch 461/637] [D loss: 0.180762] [G loss: 0.389972]\n",
      "[Epoch 41/200] [Batch 462/637] [D loss: 0.172379] [G loss: 0.490493]\n",
      "[Epoch 41/200] [Batch 463/637] [D loss: 0.213587] [G loss: 0.394062]\n",
      "[Epoch 41/200] [Batch 464/637] [D loss: 0.173830] [G loss: 0.556551]\n",
      "[Epoch 41/200] [Batch 465/637] [D loss: 0.176027] [G loss: 0.531167]\n",
      "[Epoch 41/200] [Batch 466/637] [D loss: 0.170961] [G loss: 0.443206]\n",
      "[Epoch 41/200] [Batch 467/637] [D loss: 0.201474] [G loss: 0.402433]\n",
      "[Epoch 41/200] [Batch 468/637] [D loss: 0.187168] [G loss: 0.433345]\n",
      "[Epoch 41/200] [Batch 469/637] [D loss: 0.155987] [G loss: 0.546052]\n",
      "[Epoch 41/200] [Batch 470/637] [D loss: 0.161563] [G loss: 0.483021]\n",
      "[Epoch 41/200] [Batch 471/637] [D loss: 0.168357] [G loss: 0.541103]\n",
      "[Epoch 41/200] [Batch 472/637] [D loss: 0.158901] [G loss: 0.517864]\n",
      "[Epoch 41/200] [Batch 473/637] [D loss: 0.186298] [G loss: 0.477023]\n",
      "[Epoch 41/200] [Batch 474/637] [D loss: 0.160798] [G loss: 0.502579]\n",
      "[Epoch 41/200] [Batch 475/637] [D loss: 0.186267] [G loss: 0.476146]\n",
      "[Epoch 41/200] [Batch 476/637] [D loss: 0.161517] [G loss: 0.528980]\n",
      "[Epoch 41/200] [Batch 477/637] [D loss: 0.151582] [G loss: 0.533841]\n",
      "[Epoch 41/200] [Batch 478/637] [D loss: 0.183219] [G loss: 0.514326]\n",
      "[Epoch 41/200] [Batch 479/637] [D loss: 0.159096] [G loss: 0.465275]\n",
      "[Epoch 41/200] [Batch 480/637] [D loss: 0.179294] [G loss: 0.502246]\n",
      "[Epoch 41/200] [Batch 481/637] [D loss: 0.166978] [G loss: 0.549600]\n",
      "[Epoch 41/200] [Batch 482/637] [D loss: 0.164211] [G loss: 0.567573]\n",
      "[Epoch 41/200] [Batch 483/637] [D loss: 0.178347] [G loss: 0.508590]\n",
      "[Epoch 41/200] [Batch 484/637] [D loss: 0.181637] [G loss: 0.464232]\n",
      "[Epoch 41/200] [Batch 485/637] [D loss: 0.169200] [G loss: 0.458472]\n",
      "[Epoch 41/200] [Batch 486/637] [D loss: 0.159423] [G loss: 0.505237]\n",
      "[Epoch 41/200] [Batch 487/637] [D loss: 0.166799] [G loss: 0.520788]\n",
      "[Epoch 41/200] [Batch 488/637] [D loss: 0.172457] [G loss: 0.447381]\n",
      "[Epoch 41/200] [Batch 489/637] [D loss: 0.167117] [G loss: 0.513720]\n",
      "[Epoch 41/200] [Batch 490/637] [D loss: 0.176255] [G loss: 0.528154]\n",
      "[Epoch 41/200] [Batch 491/637] [D loss: 0.181913] [G loss: 0.513538]\n",
      "[Epoch 41/200] [Batch 492/637] [D loss: 0.190459] [G loss: 0.461627]\n",
      "[Epoch 41/200] [Batch 493/637] [D loss: 0.164897] [G loss: 0.506849]\n",
      "[Epoch 41/200] [Batch 494/637] [D loss: 0.155053] [G loss: 0.503377]\n",
      "[Epoch 41/200] [Batch 495/637] [D loss: 0.166224] [G loss: 0.503290]\n",
      "[Epoch 41/200] [Batch 496/637] [D loss: 0.155334] [G loss: 0.572287]\n",
      "[Epoch 41/200] [Batch 497/637] [D loss: 0.168196] [G loss: 0.536906]\n",
      "[Epoch 41/200] [Batch 498/637] [D loss: 0.185048] [G loss: 0.459283]\n",
      "[Epoch 41/200] [Batch 499/637] [D loss: 0.147257] [G loss: 0.448529]\n",
      "[Epoch 41/200] [Batch 500/637] [D loss: 0.172779] [G loss: 0.429331]\n",
      "[Epoch 41/200] [Batch 501/637] [D loss: 0.182210] [G loss: 0.505450]\n",
      "[Epoch 41/200] [Batch 502/637] [D loss: 0.166245] [G loss: 0.520832]\n",
      "[Epoch 41/200] [Batch 503/637] [D loss: 0.163510] [G loss: 0.517198]\n",
      "[Epoch 41/200] [Batch 504/637] [D loss: 0.202697] [G loss: 0.384578]\n",
      "[Epoch 41/200] [Batch 505/637] [D loss: 0.180942] [G loss: 0.453619]\n",
      "[Epoch 41/200] [Batch 506/637] [D loss: 0.176637] [G loss: 0.478994]\n",
      "[Epoch 41/200] [Batch 507/637] [D loss: 0.161849] [G loss: 0.500217]\n",
      "[Epoch 41/200] [Batch 508/637] [D loss: 0.160710] [G loss: 0.502662]\n",
      "[Epoch 41/200] [Batch 509/637] [D loss: 0.158848] [G loss: 0.525279]\n",
      "[Epoch 41/200] [Batch 510/637] [D loss: 0.168433] [G loss: 0.485035]\n",
      "[Epoch 41/200] [Batch 511/637] [D loss: 0.184601] [G loss: 0.555867]\n",
      "[Epoch 41/200] [Batch 512/637] [D loss: 0.180663] [G loss: 0.510956]\n",
      "[Epoch 41/200] [Batch 513/637] [D loss: 0.179414] [G loss: 0.408155]\n",
      "[Epoch 41/200] [Batch 514/637] [D loss: 0.174724] [G loss: 0.411814]\n",
      "[Epoch 41/200] [Batch 515/637] [D loss: 0.178909] [G loss: 0.471354]\n",
      "[Epoch 41/200] [Batch 516/637] [D loss: 0.178254] [G loss: 0.472078]\n",
      "[Epoch 41/200] [Batch 517/637] [D loss: 0.170206] [G loss: 0.484526]\n",
      "[Epoch 41/200] [Batch 518/637] [D loss: 0.189435] [G loss: 0.470737]\n",
      "[Epoch 41/200] [Batch 519/637] [D loss: 0.164015] [G loss: 0.449610]\n",
      "[Epoch 41/200] [Batch 520/637] [D loss: 0.166700] [G loss: 0.478190]\n",
      "[Epoch 41/200] [Batch 521/637] [D loss: 0.164002] [G loss: 0.516107]\n",
      "[Epoch 41/200] [Batch 522/637] [D loss: 0.175887] [G loss: 0.468464]\n",
      "[Epoch 41/200] [Batch 523/637] [D loss: 0.174838] [G loss: 0.449263]\n",
      "[Epoch 41/200] [Batch 524/637] [D loss: 0.178676] [G loss: 0.477700]\n",
      "[Epoch 41/200] [Batch 525/637] [D loss: 0.161133] [G loss: 0.467594]\n",
      "[Epoch 41/200] [Batch 526/637] [D loss: 0.176000] [G loss: 0.460317]\n",
      "[Epoch 41/200] [Batch 527/637] [D loss: 0.152864] [G loss: 0.641790]\n",
      "[Epoch 41/200] [Batch 528/637] [D loss: 0.189981] [G loss: 0.393332]\n",
      "[Epoch 41/200] [Batch 529/637] [D loss: 0.167774] [G loss: 0.519054]\n",
      "[Epoch 41/200] [Batch 530/637] [D loss: 0.179566] [G loss: 0.478209]\n",
      "[Epoch 41/200] [Batch 531/637] [D loss: 0.189187] [G loss: 0.582717]\n",
      "[Epoch 41/200] [Batch 532/637] [D loss: 0.164325] [G loss: 0.536836]\n",
      "[Epoch 41/200] [Batch 533/637] [D loss: 0.179725] [G loss: 0.438349]\n",
      "[Epoch 41/200] [Batch 534/637] [D loss: 0.160830] [G loss: 0.466555]\n",
      "[Epoch 41/200] [Batch 535/637] [D loss: 0.215204] [G loss: 0.383477]\n",
      "[Epoch 41/200] [Batch 536/637] [D loss: 0.174349] [G loss: 0.504079]\n",
      "[Epoch 41/200] [Batch 537/637] [D loss: 0.143775] [G loss: 0.527433]\n",
      "[Epoch 41/200] [Batch 538/637] [D loss: 0.156822] [G loss: 0.528844]\n",
      "[Epoch 41/200] [Batch 539/637] [D loss: 0.157336] [G loss: 0.449332]\n",
      "[Epoch 41/200] [Batch 540/637] [D loss: 0.173879] [G loss: 0.395126]\n",
      "[Epoch 41/200] [Batch 541/637] [D loss: 0.176277] [G loss: 0.502842]\n",
      "[Epoch 41/200] [Batch 542/637] [D loss: 0.166752] [G loss: 0.528247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/200] [Batch 543/637] [D loss: 0.178203] [G loss: 0.496087]\n",
      "[Epoch 41/200] [Batch 544/637] [D loss: 0.180539] [G loss: 0.426056]\n",
      "[Epoch 41/200] [Batch 545/637] [D loss: 0.174443] [G loss: 0.451392]\n",
      "[Epoch 41/200] [Batch 546/637] [D loss: 0.166799] [G loss: 0.420978]\n",
      "[Epoch 41/200] [Batch 547/637] [D loss: 0.154365] [G loss: 0.551559]\n",
      "[Epoch 41/200] [Batch 548/637] [D loss: 0.175363] [G loss: 0.504886]\n",
      "[Epoch 41/200] [Batch 549/637] [D loss: 0.174525] [G loss: 0.456021]\n",
      "[Epoch 41/200] [Batch 550/637] [D loss: 0.169611] [G loss: 0.480322]\n",
      "[Epoch 41/200] [Batch 551/637] [D loss: 0.183139] [G loss: 0.479395]\n",
      "[Epoch 41/200] [Batch 552/637] [D loss: 0.201000] [G loss: 0.393952]\n",
      "[Epoch 41/200] [Batch 553/637] [D loss: 0.227720] [G loss: 0.445748]\n",
      "[Epoch 41/200] [Batch 554/637] [D loss: 0.196055] [G loss: 0.537017]\n",
      "[Epoch 41/200] [Batch 555/637] [D loss: 0.193088] [G loss: 0.508595]\n",
      "[Epoch 41/200] [Batch 556/637] [D loss: 0.168507] [G loss: 0.449597]\n",
      "[Epoch 41/200] [Batch 557/637] [D loss: 0.171539] [G loss: 0.400742]\n",
      "[Epoch 41/200] [Batch 558/637] [D loss: 0.175557] [G loss: 0.466550]\n",
      "[Epoch 41/200] [Batch 559/637] [D loss: 0.172382] [G loss: 0.491716]\n",
      "[Epoch 41/200] [Batch 560/637] [D loss: 0.152442] [G loss: 0.505564]\n",
      "[Epoch 41/200] [Batch 561/637] [D loss: 0.154444] [G loss: 0.537631]\n",
      "[Epoch 41/200] [Batch 562/637] [D loss: 0.171428] [G loss: 0.479645]\n",
      "[Epoch 41/200] [Batch 563/637] [D loss: 0.147721] [G loss: 0.497511]\n",
      "[Epoch 41/200] [Batch 564/637] [D loss: 0.139738] [G loss: 0.592203]\n",
      "[Epoch 41/200] [Batch 565/637] [D loss: 0.170586] [G loss: 0.488195]\n",
      "[Epoch 41/200] [Batch 566/637] [D loss: 0.174986] [G loss: 0.472513]\n",
      "[Epoch 41/200] [Batch 567/637] [D loss: 0.179973] [G loss: 0.528060]\n",
      "[Epoch 41/200] [Batch 568/637] [D loss: 0.173378] [G loss: 0.539986]\n",
      "[Epoch 41/200] [Batch 569/637] [D loss: 0.192586] [G loss: 0.451189]\n",
      "[Epoch 41/200] [Batch 570/637] [D loss: 0.205074] [G loss: 0.445148]\n",
      "[Epoch 41/200] [Batch 571/637] [D loss: 0.153542] [G loss: 0.535538]\n",
      "[Epoch 41/200] [Batch 572/637] [D loss: 0.156089] [G loss: 0.454685]\n",
      "[Epoch 41/200] [Batch 573/637] [D loss: 0.171136] [G loss: 0.490449]\n",
      "[Epoch 41/200] [Batch 574/637] [D loss: 0.182890] [G loss: 0.437131]\n",
      "[Epoch 41/200] [Batch 575/637] [D loss: 0.179761] [G loss: 0.456756]\n",
      "[Epoch 41/200] [Batch 576/637] [D loss: 0.185753] [G loss: 0.445236]\n",
      "[Epoch 41/200] [Batch 577/637] [D loss: 0.145351] [G loss: 0.499572]\n",
      "[Epoch 41/200] [Batch 578/637] [D loss: 0.137919] [G loss: 0.488716]\n",
      "[Epoch 41/200] [Batch 579/637] [D loss: 0.161606] [G loss: 0.446367]\n",
      "[Epoch 41/200] [Batch 580/637] [D loss: 0.177264] [G loss: 0.534848]\n",
      "[Epoch 41/200] [Batch 581/637] [D loss: 0.174241] [G loss: 0.518180]\n",
      "[Epoch 41/200] [Batch 582/637] [D loss: 0.161534] [G loss: 0.552547]\n",
      "[Epoch 41/200] [Batch 583/637] [D loss: 0.172028] [G loss: 0.497996]\n",
      "[Epoch 41/200] [Batch 584/637] [D loss: 0.208224] [G loss: 0.523631]\n",
      "[Epoch 41/200] [Batch 585/637] [D loss: 0.149714] [G loss: 0.541516]\n",
      "[Epoch 41/200] [Batch 586/637] [D loss: 0.174858] [G loss: 0.496734]\n",
      "[Epoch 41/200] [Batch 587/637] [D loss: 0.174967] [G loss: 0.500235]\n",
      "[Epoch 41/200] [Batch 588/637] [D loss: 0.161392] [G loss: 0.526903]\n",
      "[Epoch 41/200] [Batch 589/637] [D loss: 0.186161] [G loss: 0.536890]\n",
      "[Epoch 41/200] [Batch 590/637] [D loss: 0.170008] [G loss: 0.490806]\n",
      "[Epoch 41/200] [Batch 591/637] [D loss: 0.154337] [G loss: 0.489675]\n",
      "[Epoch 41/200] [Batch 592/637] [D loss: 0.192343] [G loss: 0.422404]\n",
      "[Epoch 41/200] [Batch 593/637] [D loss: 0.168896] [G loss: 0.449375]\n",
      "[Epoch 41/200] [Batch 594/637] [D loss: 0.181190] [G loss: 0.469988]\n",
      "[Epoch 41/200] [Batch 595/637] [D loss: 0.169480] [G loss: 0.525773]\n",
      "[Epoch 41/200] [Batch 596/637] [D loss: 0.158559] [G loss: 0.474171]\n",
      "[Epoch 41/200] [Batch 597/637] [D loss: 0.168195] [G loss: 0.487316]\n",
      "[Epoch 41/200] [Batch 598/637] [D loss: 0.171513] [G loss: 0.447885]\n",
      "[Epoch 41/200] [Batch 599/637] [D loss: 0.153147] [G loss: 0.472775]\n",
      "[Epoch 41/200] [Batch 600/637] [D loss: 0.148065] [G loss: 0.499814]\n",
      "[Epoch 41/200] [Batch 601/637] [D loss: 0.163307] [G loss: 0.461524]\n",
      "[Epoch 41/200] [Batch 602/637] [D loss: 0.159798] [G loss: 0.482666]\n",
      "[Epoch 41/200] [Batch 603/637] [D loss: 0.162846] [G loss: 0.525037]\n",
      "[Epoch 41/200] [Batch 604/637] [D loss: 0.177982] [G loss: 0.497598]\n",
      "[Epoch 41/200] [Batch 605/637] [D loss: 0.190804] [G loss: 0.445021]\n",
      "[Epoch 41/200] [Batch 606/637] [D loss: 0.169117] [G loss: 0.463045]\n",
      "[Epoch 41/200] [Batch 607/637] [D loss: 0.178332] [G loss: 0.521964]\n",
      "[Epoch 41/200] [Batch 608/637] [D loss: 0.186278] [G loss: 0.509897]\n",
      "[Epoch 41/200] [Batch 609/637] [D loss: 0.157740] [G loss: 0.459653]\n",
      "[Epoch 41/200] [Batch 610/637] [D loss: 0.159908] [G loss: 0.452011]\n",
      "[Epoch 41/200] [Batch 611/637] [D loss: 0.191854] [G loss: 0.436686]\n",
      "[Epoch 41/200] [Batch 612/637] [D loss: 0.179517] [G loss: 0.481831]\n",
      "[Epoch 41/200] [Batch 613/637] [D loss: 0.168668] [G loss: 0.550232]\n",
      "[Epoch 41/200] [Batch 614/637] [D loss: 0.152038] [G loss: 0.451093]\n",
      "[Epoch 41/200] [Batch 615/637] [D loss: 0.181700] [G loss: 0.521378]\n",
      "[Epoch 41/200] [Batch 616/637] [D loss: 0.186457] [G loss: 0.489511]\n",
      "[Epoch 41/200] [Batch 617/637] [D loss: 0.187930] [G loss: 0.492279]\n",
      "[Epoch 41/200] [Batch 618/637] [D loss: 0.160077] [G loss: 0.483159]\n",
      "[Epoch 41/200] [Batch 619/637] [D loss: 0.189920] [G loss: 0.405675]\n",
      "[Epoch 41/200] [Batch 620/637] [D loss: 0.192578] [G loss: 0.463654]\n",
      "[Epoch 41/200] [Batch 621/637] [D loss: 0.174994] [G loss: 0.510730]\n",
      "[Epoch 41/200] [Batch 622/637] [D loss: 0.162117] [G loss: 0.506998]\n",
      "[Epoch 41/200] [Batch 623/637] [D loss: 0.178888] [G loss: 0.490568]\n",
      "[Epoch 41/200] [Batch 624/637] [D loss: 0.193139] [G loss: 0.412182]\n",
      "[Epoch 41/200] [Batch 625/637] [D loss: 0.157049] [G loss: 0.489343]\n",
      "[Epoch 41/200] [Batch 626/637] [D loss: 0.149518] [G loss: 0.529451]\n",
      "[Epoch 41/200] [Batch 627/637] [D loss: 0.180066] [G loss: 0.535676]\n",
      "[Epoch 41/200] [Batch 628/637] [D loss: 0.186507] [G loss: 0.492725]\n",
      "[Epoch 41/200] [Batch 629/637] [D loss: 0.162965] [G loss: 0.562573]\n",
      "[Epoch 41/200] [Batch 630/637] [D loss: 0.169355] [G loss: 0.513933]\n",
      "[Epoch 41/200] [Batch 631/637] [D loss: 0.185830] [G loss: 0.454118]\n",
      "[Epoch 41/200] [Batch 632/637] [D loss: 0.155416] [G loss: 0.511402]\n",
      "[Epoch 41/200] [Batch 633/637] [D loss: 0.160605] [G loss: 0.501788]\n",
      "[Epoch 41/200] [Batch 634/637] [D loss: 0.192894] [G loss: 0.477577]\n",
      "[Epoch 41/200] [Batch 635/637] [D loss: 0.165672] [G loss: 0.517261]\n",
      "[Epoch 41/200] [Batch 636/637] [D loss: 0.159904] [G loss: 0.518445]\n",
      "[Epoch 42/200] [Batch 0/637] [D loss: 0.198054] [G loss: 0.546692]\n",
      "[Epoch 42/200] [Batch 1/637] [D loss: 0.182903] [G loss: 0.495622]\n",
      "[Epoch 42/200] [Batch 2/637] [D loss: 0.215557] [G loss: 0.669636]\n",
      "[Epoch 42/200] [Batch 3/637] [D loss: 0.195292] [G loss: 0.440015]\n",
      "[Epoch 42/200] [Batch 4/637] [D loss: 0.147346] [G loss: 0.475569]\n",
      "[Epoch 42/200] [Batch 5/637] [D loss: 0.158934] [G loss: 0.489496]\n",
      "[Epoch 42/200] [Batch 6/637] [D loss: 0.174026] [G loss: 0.491972]\n",
      "[Epoch 42/200] [Batch 7/637] [D loss: 0.154335] [G loss: 0.488974]\n",
      "[Epoch 42/200] [Batch 8/637] [D loss: 0.154925] [G loss: 0.540198]\n",
      "[Epoch 42/200] [Batch 9/637] [D loss: 0.161891] [G loss: 0.468125]\n",
      "[Epoch 42/200] [Batch 10/637] [D loss: 0.164497] [G loss: 0.506614]\n",
      "[Epoch 42/200] [Batch 11/637] [D loss: 0.152176] [G loss: 0.546674]\n",
      "[Epoch 42/200] [Batch 12/637] [D loss: 0.194732] [G loss: 0.440366]\n",
      "[Epoch 42/200] [Batch 13/637] [D loss: 0.168246] [G loss: 0.522023]\n",
      "[Epoch 42/200] [Batch 14/637] [D loss: 0.177784] [G loss: 0.502624]\n",
      "[Epoch 42/200] [Batch 15/637] [D loss: 0.176001] [G loss: 0.451923]\n",
      "[Epoch 42/200] [Batch 16/637] [D loss: 0.166637] [G loss: 0.494046]\n",
      "[Epoch 42/200] [Batch 17/637] [D loss: 0.167907] [G loss: 0.490615]\n",
      "[Epoch 42/200] [Batch 18/637] [D loss: 0.218855] [G loss: 0.407620]\n",
      "[Epoch 42/200] [Batch 19/637] [D loss: 0.195109] [G loss: 0.385926]\n",
      "[Epoch 42/200] [Batch 20/637] [D loss: 0.160800] [G loss: 0.468138]\n",
      "[Epoch 42/200] [Batch 21/637] [D loss: 0.174398] [G loss: 0.499457]\n",
      "[Epoch 42/200] [Batch 22/637] [D loss: 0.172865] [G loss: 0.509001]\n",
      "[Epoch 42/200] [Batch 23/637] [D loss: 0.174804] [G loss: 0.527867]\n",
      "[Epoch 42/200] [Batch 24/637] [D loss: 0.174768] [G loss: 0.479073]\n",
      "[Epoch 42/200] [Batch 25/637] [D loss: 0.175975] [G loss: 0.429934]\n",
      "[Epoch 42/200] [Batch 26/637] [D loss: 0.177782] [G loss: 0.409278]\n",
      "[Epoch 42/200] [Batch 27/637] [D loss: 0.169112] [G loss: 0.451446]\n",
      "[Epoch 42/200] [Batch 28/637] [D loss: 0.174932] [G loss: 0.548616]\n",
      "[Epoch 42/200] [Batch 29/637] [D loss: 0.168838] [G loss: 0.490097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/200] [Batch 30/637] [D loss: 0.148974] [G loss: 0.516594]\n",
      "[Epoch 42/200] [Batch 31/637] [D loss: 0.227345] [G loss: 0.426439]\n",
      "[Epoch 42/200] [Batch 32/637] [D loss: 0.137631] [G loss: 0.565338]\n",
      "[Epoch 42/200] [Batch 33/637] [D loss: 0.153383] [G loss: 0.492081]\n",
      "[Epoch 42/200] [Batch 34/637] [D loss: 0.183906] [G loss: 0.442764]\n",
      "[Epoch 42/200] [Batch 35/637] [D loss: 0.176712] [G loss: 0.380399]\n",
      "[Epoch 42/200] [Batch 36/637] [D loss: 0.177891] [G loss: 0.435824]\n",
      "[Epoch 42/200] [Batch 37/637] [D loss: 0.161873] [G loss: 0.542532]\n",
      "[Epoch 42/200] [Batch 38/637] [D loss: 0.179604] [G loss: 0.531318]\n",
      "[Epoch 42/200] [Batch 39/637] [D loss: 0.176699] [G loss: 0.539052]\n",
      "[Epoch 42/200] [Batch 40/637] [D loss: 0.162689] [G loss: 0.554690]\n",
      "[Epoch 42/200] [Batch 41/637] [D loss: 0.175512] [G loss: 0.513360]\n",
      "[Epoch 42/200] [Batch 42/637] [D loss: 0.172211] [G loss: 0.469674]\n",
      "[Epoch 42/200] [Batch 43/637] [D loss: 0.174678] [G loss: 0.505338]\n",
      "[Epoch 42/200] [Batch 44/637] [D loss: 0.164981] [G loss: 0.469649]\n",
      "[Epoch 42/200] [Batch 45/637] [D loss: 0.188012] [G loss: 0.441273]\n",
      "[Epoch 42/200] [Batch 46/637] [D loss: 0.160074] [G loss: 0.537564]\n",
      "[Epoch 42/200] [Batch 47/637] [D loss: 0.176778] [G loss: 0.424856]\n",
      "[Epoch 42/200] [Batch 48/637] [D loss: 0.153252] [G loss: 0.558479]\n",
      "[Epoch 42/200] [Batch 49/637] [D loss: 0.150080] [G loss: 0.530119]\n",
      "[Epoch 42/200] [Batch 50/637] [D loss: 0.178649] [G loss: 0.429204]\n",
      "[Epoch 42/200] [Batch 51/637] [D loss: 0.185303] [G loss: 0.489250]\n",
      "[Epoch 42/200] [Batch 52/637] [D loss: 0.168745] [G loss: 0.586108]\n",
      "[Epoch 42/200] [Batch 53/637] [D loss: 0.152216] [G loss: 0.545958]\n",
      "[Epoch 42/200] [Batch 54/637] [D loss: 0.161671] [G loss: 0.455571]\n",
      "[Epoch 42/200] [Batch 55/637] [D loss: 0.172026] [G loss: 0.444446]\n",
      "[Epoch 42/200] [Batch 56/637] [D loss: 0.160730] [G loss: 0.475170]\n",
      "[Epoch 42/200] [Batch 57/637] [D loss: 0.181836] [G loss: 0.468342]\n",
      "[Epoch 42/200] [Batch 58/637] [D loss: 0.165404] [G loss: 0.495032]\n",
      "[Epoch 42/200] [Batch 59/637] [D loss: 0.158119] [G loss: 0.596434]\n",
      "[Epoch 42/200] [Batch 60/637] [D loss: 0.179740] [G loss: 0.514354]\n",
      "[Epoch 42/200] [Batch 61/637] [D loss: 0.161638] [G loss: 0.520462]\n",
      "[Epoch 42/200] [Batch 62/637] [D loss: 0.173126] [G loss: 0.492922]\n",
      "[Epoch 42/200] [Batch 63/637] [D loss: 0.160842] [G loss: 0.492570]\n",
      "[Epoch 42/200] [Batch 64/637] [D loss: 0.165307] [G loss: 0.526395]\n",
      "[Epoch 42/200] [Batch 65/637] [D loss: 0.177428] [G loss: 0.517193]\n",
      "[Epoch 42/200] [Batch 66/637] [D loss: 0.174762] [G loss: 0.443181]\n",
      "[Epoch 42/200] [Batch 67/637] [D loss: 0.161095] [G loss: 0.499692]\n",
      "[Epoch 42/200] [Batch 68/637] [D loss: 0.145080] [G loss: 0.570309]\n",
      "[Epoch 42/200] [Batch 69/637] [D loss: 0.176933] [G loss: 0.544668]\n",
      "[Epoch 42/200] [Batch 70/637] [D loss: 0.168734] [G loss: 0.544303]\n",
      "[Epoch 42/200] [Batch 71/637] [D loss: 0.167158] [G loss: 0.478457]\n",
      "[Epoch 42/200] [Batch 72/637] [D loss: 0.164767] [G loss: 0.477317]\n",
      "[Epoch 42/200] [Batch 73/637] [D loss: 0.159797] [G loss: 0.509810]\n",
      "[Epoch 42/200] [Batch 74/637] [D loss: 0.179790] [G loss: 0.534665]\n",
      "[Epoch 42/200] [Batch 75/637] [D loss: 0.157116] [G loss: 0.545362]\n",
      "[Epoch 42/200] [Batch 76/637] [D loss: 0.162854] [G loss: 0.535590]\n",
      "[Epoch 42/200] [Batch 77/637] [D loss: 0.181660] [G loss: 0.475472]\n",
      "[Epoch 42/200] [Batch 78/637] [D loss: 0.150963] [G loss: 0.474891]\n",
      "[Epoch 42/200] [Batch 79/637] [D loss: 0.184216] [G loss: 0.483914]\n",
      "[Epoch 42/200] [Batch 80/637] [D loss: 0.196965] [G loss: 0.504722]\n",
      "[Epoch 42/200] [Batch 81/637] [D loss: 0.185201] [G loss: 0.512008]\n",
      "[Epoch 42/200] [Batch 82/637] [D loss: 0.170359] [G loss: 0.479781]\n",
      "[Epoch 42/200] [Batch 83/637] [D loss: 0.175220] [G loss: 0.459668]\n",
      "[Epoch 42/200] [Batch 84/637] [D loss: 0.169478] [G loss: 0.475813]\n",
      "[Epoch 42/200] [Batch 85/637] [D loss: 0.168319] [G loss: 0.536077]\n",
      "[Epoch 42/200] [Batch 86/637] [D loss: 0.160323] [G loss: 0.535966]\n",
      "[Epoch 42/200] [Batch 87/637] [D loss: 0.155446] [G loss: 0.501072]\n",
      "[Epoch 42/200] [Batch 88/637] [D loss: 0.160476] [G loss: 0.489298]\n",
      "[Epoch 42/200] [Batch 89/637] [D loss: 0.164056] [G loss: 0.498209]\n",
      "[Epoch 42/200] [Batch 90/637] [D loss: 0.179277] [G loss: 0.471558]\n",
      "[Epoch 42/200] [Batch 91/637] [D loss: 0.139555] [G loss: 0.549302]\n",
      "[Epoch 42/200] [Batch 92/637] [D loss: 0.189965] [G loss: 0.542296]\n",
      "[Epoch 42/200] [Batch 93/637] [D loss: 0.184049] [G loss: 0.513697]\n",
      "[Epoch 42/200] [Batch 94/637] [D loss: 0.154443] [G loss: 0.526245]\n",
      "[Epoch 42/200] [Batch 95/637] [D loss: 0.163303] [G loss: 0.463551]\n",
      "[Epoch 42/200] [Batch 96/637] [D loss: 0.150396] [G loss: 0.461606]\n",
      "[Epoch 42/200] [Batch 97/637] [D loss: 0.166303] [G loss: 0.510715]\n",
      "[Epoch 42/200] [Batch 98/637] [D loss: 0.158643] [G loss: 0.464707]\n",
      "[Epoch 42/200] [Batch 99/637] [D loss: 0.159600] [G loss: 0.474882]\n",
      "[Epoch 42/200] [Batch 100/637] [D loss: 0.152768] [G loss: 0.546396]\n",
      "[Epoch 42/200] [Batch 101/637] [D loss: 0.183999] [G loss: 0.447383]\n",
      "[Epoch 42/200] [Batch 102/637] [D loss: 0.175425] [G loss: 0.489814]\n",
      "[Epoch 42/200] [Batch 103/637] [D loss: 0.164027] [G loss: 0.522376]\n",
      "[Epoch 42/200] [Batch 104/637] [D loss: 0.174654] [G loss: 0.447602]\n",
      "[Epoch 42/200] [Batch 105/637] [D loss: 0.158755] [G loss: 0.509510]\n",
      "[Epoch 42/200] [Batch 106/637] [D loss: 0.168380] [G loss: 0.540651]\n",
      "[Epoch 42/200] [Batch 107/637] [D loss: 0.173670] [G loss: 0.487816]\n",
      "[Epoch 42/200] [Batch 108/637] [D loss: 0.165448] [G loss: 0.455647]\n",
      "[Epoch 42/200] [Batch 109/637] [D loss: 0.194436] [G loss: 0.417649]\n",
      "[Epoch 42/200] [Batch 110/637] [D loss: 0.170611] [G loss: 0.484343]\n",
      "[Epoch 42/200] [Batch 111/637] [D loss: 0.167514] [G loss: 0.475736]\n",
      "[Epoch 42/200] [Batch 112/637] [D loss: 0.165300] [G loss: 0.506541]\n",
      "[Epoch 42/200] [Batch 113/637] [D loss: 0.150762] [G loss: 0.515094]\n",
      "[Epoch 42/200] [Batch 114/637] [D loss: 0.154033] [G loss: 0.488382]\n",
      "[Epoch 42/200] [Batch 115/637] [D loss: 0.154180] [G loss: 0.581973]\n",
      "[Epoch 42/200] [Batch 116/637] [D loss: 0.157776] [G loss: 0.530502]\n",
      "[Epoch 42/200] [Batch 117/637] [D loss: 0.156991] [G loss: 0.520513]\n",
      "[Epoch 42/200] [Batch 118/637] [D loss: 0.190200] [G loss: 0.458131]\n",
      "[Epoch 42/200] [Batch 119/637] [D loss: 0.166408] [G loss: 0.532165]\n",
      "[Epoch 42/200] [Batch 120/637] [D loss: 0.178404] [G loss: 0.502149]\n",
      "[Epoch 42/200] [Batch 121/637] [D loss: 0.149847] [G loss: 0.526171]\n",
      "[Epoch 42/200] [Batch 122/637] [D loss: 0.148352] [G loss: 0.455903]\n",
      "[Epoch 42/200] [Batch 123/637] [D loss: 0.177594] [G loss: 0.489689]\n",
      "[Epoch 42/200] [Batch 124/637] [D loss: 0.149905] [G loss: 0.512484]\n",
      "[Epoch 42/200] [Batch 125/637] [D loss: 0.143406] [G loss: 0.523561]\n",
      "[Epoch 42/200] [Batch 126/637] [D loss: 0.175589] [G loss: 0.469625]\n",
      "[Epoch 42/200] [Batch 127/637] [D loss: 0.171232] [G loss: 0.514116]\n",
      "[Epoch 42/200] [Batch 128/637] [D loss: 0.214009] [G loss: 0.459076]\n",
      "[Epoch 42/200] [Batch 129/637] [D loss: 0.160142] [G loss: 0.610306]\n",
      "[Epoch 42/200] [Batch 130/637] [D loss: 0.153690] [G loss: 0.528377]\n",
      "[Epoch 42/200] [Batch 131/637] [D loss: 0.165444] [G loss: 0.488102]\n",
      "[Epoch 42/200] [Batch 132/637] [D loss: 0.176833] [G loss: 0.466238]\n",
      "[Epoch 42/200] [Batch 133/637] [D loss: 0.196144] [G loss: 0.532393]\n",
      "[Epoch 42/200] [Batch 134/637] [D loss: 0.181913] [G loss: 0.529414]\n",
      "[Epoch 42/200] [Batch 135/637] [D loss: 0.173065] [G loss: 0.503980]\n",
      "[Epoch 42/200] [Batch 136/637] [D loss: 0.159097] [G loss: 0.503041]\n",
      "[Epoch 42/200] [Batch 137/637] [D loss: 0.151474] [G loss: 0.514016]\n",
      "[Epoch 42/200] [Batch 138/637] [D loss: 0.181687] [G loss: 0.408986]\n",
      "[Epoch 42/200] [Batch 139/637] [D loss: 0.169954] [G loss: 0.501689]\n",
      "[Epoch 42/200] [Batch 140/637] [D loss: 0.160199] [G loss: 0.533385]\n",
      "[Epoch 42/200] [Batch 141/637] [D loss: 0.178750] [G loss: 0.537322]\n",
      "[Epoch 42/200] [Batch 142/637] [D loss: 0.152933] [G loss: 0.571345]\n",
      "[Epoch 42/200] [Batch 143/637] [D loss: 0.152238] [G loss: 0.502143]\n",
      "[Epoch 42/200] [Batch 144/637] [D loss: 0.155669] [G loss: 0.524597]\n",
      "[Epoch 42/200] [Batch 145/637] [D loss: 0.159449] [G loss: 0.509338]\n",
      "[Epoch 42/200] [Batch 146/637] [D loss: 0.145433] [G loss: 0.549940]\n",
      "[Epoch 42/200] [Batch 147/637] [D loss: 0.171089] [G loss: 0.520190]\n",
      "[Epoch 42/200] [Batch 148/637] [D loss: 0.189921] [G loss: 0.493309]\n",
      "[Epoch 42/200] [Batch 149/637] [D loss: 0.188197] [G loss: 0.514030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/200] [Batch 150/637] [D loss: 0.175143] [G loss: 0.507991]\n",
      "[Epoch 42/200] [Batch 151/637] [D loss: 0.168566] [G loss: 0.438054]\n",
      "[Epoch 42/200] [Batch 152/637] [D loss: 0.155337] [G loss: 0.437431]\n",
      "[Epoch 42/200] [Batch 153/637] [D loss: 0.185168] [G loss: 0.523393]\n",
      "[Epoch 42/200] [Batch 154/637] [D loss: 0.176035] [G loss: 0.571604]\n",
      "[Epoch 42/200] [Batch 155/637] [D loss: 0.166641] [G loss: 0.537902]\n",
      "[Epoch 42/200] [Batch 156/637] [D loss: 0.161787] [G loss: 0.464136]\n",
      "[Epoch 42/200] [Batch 157/637] [D loss: 0.147010] [G loss: 0.492665]\n",
      "[Epoch 42/200] [Batch 158/637] [D loss: 0.176458] [G loss: 0.469015]\n",
      "[Epoch 42/200] [Batch 159/637] [D loss: 0.175618] [G loss: 0.518656]\n",
      "[Epoch 42/200] [Batch 160/637] [D loss: 0.163795] [G loss: 0.536944]\n",
      "[Epoch 42/200] [Batch 161/637] [D loss: 0.161549] [G loss: 0.491222]\n",
      "[Epoch 42/200] [Batch 162/637] [D loss: 0.143883] [G loss: 0.584876]\n",
      "[Epoch 42/200] [Batch 163/637] [D loss: 0.179287] [G loss: 0.450584]\n",
      "[Epoch 42/200] [Batch 164/637] [D loss: 0.163411] [G loss: 0.511043]\n",
      "[Epoch 42/200] [Batch 165/637] [D loss: 0.160393] [G loss: 0.505612]\n",
      "[Epoch 42/200] [Batch 166/637] [D loss: 0.171449] [G loss: 0.516213]\n",
      "[Epoch 42/200] [Batch 167/637] [D loss: 0.162992] [G loss: 0.554208]\n",
      "[Epoch 42/200] [Batch 168/637] [D loss: 0.178811] [G loss: 0.478194]\n",
      "[Epoch 42/200] [Batch 169/637] [D loss: 0.193232] [G loss: 0.489058]\n",
      "[Epoch 42/200] [Batch 170/637] [D loss: 0.161886] [G loss: 0.497494]\n",
      "[Epoch 42/200] [Batch 171/637] [D loss: 0.159778] [G loss: 0.529120]\n",
      "[Epoch 42/200] [Batch 172/637] [D loss: 0.175088] [G loss: 0.407919]\n",
      "[Epoch 42/200] [Batch 173/637] [D loss: 0.179627] [G loss: 0.497748]\n",
      "[Epoch 42/200] [Batch 174/637] [D loss: 0.158916] [G loss: 0.522002]\n",
      "[Epoch 42/200] [Batch 175/637] [D loss: 0.163271] [G loss: 0.555160]\n",
      "[Epoch 42/200] [Batch 176/637] [D loss: 0.167362] [G loss: 0.490281]\n",
      "[Epoch 42/200] [Batch 177/637] [D loss: 0.158399] [G loss: 0.463690]\n",
      "[Epoch 42/200] [Batch 178/637] [D loss: 0.150767] [G loss: 0.469366]\n",
      "[Epoch 42/200] [Batch 179/637] [D loss: 0.165410] [G loss: 0.554375]\n",
      "[Epoch 42/200] [Batch 180/637] [D loss: 0.152342] [G loss: 0.532001]\n",
      "[Epoch 42/200] [Batch 181/637] [D loss: 0.190395] [G loss: 0.418081]\n",
      "[Epoch 42/200] [Batch 182/637] [D loss: 0.174843] [G loss: 0.506067]\n",
      "[Epoch 42/200] [Batch 183/637] [D loss: 0.166649] [G loss: 0.505470]\n",
      "[Epoch 42/200] [Batch 184/637] [D loss: 0.164253] [G loss: 0.487742]\n",
      "[Epoch 42/200] [Batch 185/637] [D loss: 0.171972] [G loss: 0.504815]\n",
      "[Epoch 42/200] [Batch 186/637] [D loss: 0.184439] [G loss: 0.500384]\n",
      "[Epoch 42/200] [Batch 187/637] [D loss: 0.176149] [G loss: 0.477710]\n",
      "[Epoch 42/200] [Batch 188/637] [D loss: 0.154762] [G loss: 0.551071]\n",
      "[Epoch 42/200] [Batch 189/637] [D loss: 0.153255] [G loss: 0.531817]\n",
      "[Epoch 42/200] [Batch 190/637] [D loss: 0.163367] [G loss: 0.534965]\n",
      "[Epoch 42/200] [Batch 191/637] [D loss: 0.183306] [G loss: 0.450038]\n",
      "[Epoch 42/200] [Batch 192/637] [D loss: 0.173388] [G loss: 0.488747]\n",
      "[Epoch 42/200] [Batch 193/637] [D loss: 0.164638] [G loss: 0.558768]\n",
      "[Epoch 42/200] [Batch 194/637] [D loss: 0.154421] [G loss: 0.527134]\n",
      "[Epoch 42/200] [Batch 195/637] [D loss: 0.178320] [G loss: 0.457399]\n",
      "[Epoch 42/200] [Batch 196/637] [D loss: 0.172147] [G loss: 0.521790]\n",
      "[Epoch 42/200] [Batch 197/637] [D loss: 0.168598] [G loss: 0.552389]\n",
      "[Epoch 42/200] [Batch 198/637] [D loss: 0.178725] [G loss: 0.529625]\n",
      "[Epoch 42/200] [Batch 199/637] [D loss: 0.179154] [G loss: 0.470285]\n",
      "[Epoch 42/200] [Batch 200/637] [D loss: 0.194155] [G loss: 0.481892]\n",
      "[Epoch 42/200] [Batch 201/637] [D loss: 0.200911] [G loss: 0.463921]\n",
      "[Epoch 42/200] [Batch 202/637] [D loss: 0.177313] [G loss: 0.547292]\n",
      "[Epoch 42/200] [Batch 203/637] [D loss: 0.178480] [G loss: 0.467914]\n",
      "[Epoch 42/200] [Batch 204/637] [D loss: 0.158673] [G loss: 0.529276]\n",
      "[Epoch 42/200] [Batch 205/637] [D loss: 0.166494] [G loss: 0.497128]\n",
      "[Epoch 42/200] [Batch 206/637] [D loss: 0.151901] [G loss: 0.518280]\n",
      "[Epoch 42/200] [Batch 207/637] [D loss: 0.183064] [G loss: 0.552911]\n",
      "[Epoch 42/200] [Batch 208/637] [D loss: 0.174208] [G loss: 0.540645]\n",
      "[Epoch 42/200] [Batch 209/637] [D loss: 0.241757] [G loss: 0.465383]\n",
      "[Epoch 42/200] [Batch 210/637] [D loss: 0.211429] [G loss: 0.607189]\n",
      "[Epoch 42/200] [Batch 211/637] [D loss: 0.200886] [G loss: 0.534402]\n",
      "[Epoch 42/200] [Batch 212/637] [D loss: 0.168361] [G loss: 0.498638]\n",
      "[Epoch 42/200] [Batch 213/637] [D loss: 0.190981] [G loss: 0.403835]\n",
      "[Epoch 42/200] [Batch 214/637] [D loss: 0.189265] [G loss: 0.436159]\n",
      "[Epoch 42/200] [Batch 215/637] [D loss: 0.186742] [G loss: 0.487026]\n",
      "[Epoch 42/200] [Batch 216/637] [D loss: 0.172818] [G loss: 0.522724]\n",
      "[Epoch 42/200] [Batch 217/637] [D loss: 0.175761] [G loss: 0.535530]\n",
      "[Epoch 42/200] [Batch 218/637] [D loss: 0.164731] [G loss: 0.469347]\n",
      "[Epoch 42/200] [Batch 219/637] [D loss: 0.164029] [G loss: 0.468679]\n",
      "[Epoch 42/200] [Batch 220/637] [D loss: 0.163641] [G loss: 0.502269]\n",
      "[Epoch 42/200] [Batch 221/637] [D loss: 0.158733] [G loss: 0.508926]\n",
      "[Epoch 42/200] [Batch 222/637] [D loss: 0.194578] [G loss: 0.447914]\n",
      "[Epoch 42/200] [Batch 223/637] [D loss: 0.160223] [G loss: 0.523261]\n",
      "[Epoch 42/200] [Batch 224/637] [D loss: 0.147444] [G loss: 0.540208]\n",
      "[Epoch 42/200] [Batch 225/637] [D loss: 0.158528] [G loss: 0.561304]\n",
      "[Epoch 42/200] [Batch 226/637] [D loss: 0.156216] [G loss: 0.485404]\n",
      "[Epoch 42/200] [Batch 227/637] [D loss: 0.181227] [G loss: 0.532870]\n",
      "[Epoch 42/200] [Batch 228/637] [D loss: 0.180726] [G loss: 0.522091]\n",
      "[Epoch 42/200] [Batch 229/637] [D loss: 0.173937] [G loss: 0.502836]\n",
      "[Epoch 42/200] [Batch 230/637] [D loss: 0.175194] [G loss: 0.462759]\n",
      "[Epoch 42/200] [Batch 231/637] [D loss: 0.157106] [G loss: 0.448448]\n",
      "[Epoch 42/200] [Batch 232/637] [D loss: 0.166789] [G loss: 0.487194]\n",
      "[Epoch 42/200] [Batch 233/637] [D loss: 0.164944] [G loss: 0.552136]\n",
      "[Epoch 42/200] [Batch 234/637] [D loss: 0.157673] [G loss: 0.519225]\n",
      "[Epoch 42/200] [Batch 235/637] [D loss: 0.152588] [G loss: 0.499165]\n",
      "[Epoch 42/200] [Batch 236/637] [D loss: 0.182926] [G loss: 0.452300]\n",
      "[Epoch 42/200] [Batch 237/637] [D loss: 0.173811] [G loss: 0.475092]\n",
      "[Epoch 42/200] [Batch 238/637] [D loss: 0.174637] [G loss: 0.512044]\n",
      "[Epoch 42/200] [Batch 239/637] [D loss: 0.174262] [G loss: 0.551836]\n",
      "[Epoch 42/200] [Batch 240/637] [D loss: 0.151819] [G loss: 0.552106]\n",
      "[Epoch 42/200] [Batch 241/637] [D loss: 0.167215] [G loss: 0.467253]\n",
      "[Epoch 42/200] [Batch 242/637] [D loss: 0.198492] [G loss: 0.471424]\n",
      "[Epoch 42/200] [Batch 243/637] [D loss: 0.167839] [G loss: 0.475293]\n",
      "[Epoch 42/200] [Batch 244/637] [D loss: 0.152648] [G loss: 0.532421]\n",
      "[Epoch 42/200] [Batch 245/637] [D loss: 0.169578] [G loss: 0.496408]\n",
      "[Epoch 42/200] [Batch 246/637] [D loss: 0.192051] [G loss: 0.476642]\n",
      "[Epoch 42/200] [Batch 247/637] [D loss: 0.176716] [G loss: 0.516009]\n",
      "[Epoch 42/200] [Batch 248/637] [D loss: 0.140248] [G loss: 0.543176]\n",
      "[Epoch 42/200] [Batch 249/637] [D loss: 0.168937] [G loss: 0.527205]\n",
      "[Epoch 42/200] [Batch 250/637] [D loss: 0.178236] [G loss: 0.597714]\n",
      "[Epoch 42/200] [Batch 251/637] [D loss: 0.163635] [G loss: 0.475486]\n",
      "[Epoch 42/200] [Batch 252/637] [D loss: 0.161980] [G loss: 0.542474]\n",
      "[Epoch 42/200] [Batch 253/637] [D loss: 0.169539] [G loss: 0.487056]\n",
      "[Epoch 42/200] [Batch 254/637] [D loss: 0.150568] [G loss: 0.523751]\n",
      "[Epoch 42/200] [Batch 255/637] [D loss: 0.150614] [G loss: 0.528124]\n",
      "[Epoch 42/200] [Batch 256/637] [D loss: 0.178638] [G loss: 0.429778]\n",
      "[Epoch 42/200] [Batch 257/637] [D loss: 0.182735] [G loss: 0.532402]\n",
      "[Epoch 42/200] [Batch 258/637] [D loss: 0.163311] [G loss: 0.554205]\n",
      "[Epoch 42/200] [Batch 259/637] [D loss: 0.163997] [G loss: 0.513313]\n",
      "[Epoch 42/200] [Batch 260/637] [D loss: 0.176191] [G loss: 0.488715]\n",
      "[Epoch 42/200] [Batch 261/637] [D loss: 0.178490] [G loss: 0.464082]\n",
      "[Epoch 42/200] [Batch 262/637] [D loss: 0.174106] [G loss: 0.519192]\n",
      "[Epoch 42/200] [Batch 263/637] [D loss: 0.180044] [G loss: 0.507896]\n",
      "[Epoch 42/200] [Batch 264/637] [D loss: 0.168991] [G loss: 0.447529]\n",
      "[Epoch 42/200] [Batch 265/637] [D loss: 0.167726] [G loss: 0.525971]\n",
      "[Epoch 42/200] [Batch 266/637] [D loss: 0.177936] [G loss: 0.562670]\n",
      "[Epoch 42/200] [Batch 267/637] [D loss: 0.183925] [G loss: 0.497251]\n",
      "[Epoch 42/200] [Batch 268/637] [D loss: 0.165793] [G loss: 0.463404]\n",
      "[Epoch 42/200] [Batch 269/637] [D loss: 0.169486] [G loss: 0.487015]\n",
      "[Epoch 42/200] [Batch 270/637] [D loss: 0.175384] [G loss: 0.473149]\n",
      "[Epoch 42/200] [Batch 271/637] [D loss: 0.170849] [G loss: 0.557989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/200] [Batch 272/637] [D loss: 0.158357] [G loss: 0.544997]\n",
      "[Epoch 42/200] [Batch 273/637] [D loss: 0.169438] [G loss: 0.496715]\n",
      "[Epoch 42/200] [Batch 274/637] [D loss: 0.180536] [G loss: 0.492458]\n",
      "[Epoch 42/200] [Batch 275/637] [D loss: 0.166456] [G loss: 0.491141]\n",
      "[Epoch 42/200] [Batch 276/637] [D loss: 0.184225] [G loss: 0.504686]\n",
      "[Epoch 42/200] [Batch 277/637] [D loss: 0.159119] [G loss: 0.588918]\n",
      "[Epoch 42/200] [Batch 278/637] [D loss: 0.220655] [G loss: 0.468976]\n",
      "[Epoch 42/200] [Batch 279/637] [D loss: 0.173603] [G loss: 0.490208]\n",
      "[Epoch 42/200] [Batch 280/637] [D loss: 0.178172] [G loss: 0.552614]\n",
      "[Epoch 42/200] [Batch 281/637] [D loss: 0.167262] [G loss: 0.443303]\n",
      "[Epoch 42/200] [Batch 282/637] [D loss: 0.173830] [G loss: 0.406614]\n",
      "[Epoch 42/200] [Batch 283/637] [D loss: 0.188684] [G loss: 0.419181]\n",
      "[Epoch 42/200] [Batch 284/637] [D loss: 0.174651] [G loss: 0.452721]\n",
      "[Epoch 42/200] [Batch 285/637] [D loss: 0.163882] [G loss: 0.479688]\n",
      "[Epoch 42/200] [Batch 286/637] [D loss: 0.204195] [G loss: 0.493538]\n",
      "[Epoch 42/200] [Batch 287/637] [D loss: 0.183702] [G loss: 0.402907]\n",
      "[Epoch 42/200] [Batch 288/637] [D loss: 0.185617] [G loss: 0.439863]\n",
      "[Epoch 42/200] [Batch 289/637] [D loss: 0.173260] [G loss: 0.465810]\n",
      "[Epoch 42/200] [Batch 290/637] [D loss: 0.184651] [G loss: 0.415675]\n",
      "[Epoch 42/200] [Batch 291/637] [D loss: 0.175972] [G loss: 0.386749]\n",
      "[Epoch 42/200] [Batch 292/637] [D loss: 0.186355] [G loss: 0.469908]\n",
      "[Epoch 42/200] [Batch 293/637] [D loss: 0.165693] [G loss: 0.493851]\n",
      "[Epoch 42/200] [Batch 294/637] [D loss: 0.184424] [G loss: 0.486362]\n",
      "[Epoch 42/200] [Batch 295/637] [D loss: 0.155233] [G loss: 0.436244]\n",
      "[Epoch 42/200] [Batch 296/637] [D loss: 0.171772] [G loss: 0.448619]\n",
      "[Epoch 42/200] [Batch 297/637] [D loss: 0.189051] [G loss: 0.422989]\n",
      "[Epoch 42/200] [Batch 298/637] [D loss: 0.142106] [G loss: 0.639250]\n",
      "[Epoch 42/200] [Batch 299/637] [D loss: 0.170945] [G loss: 0.514175]\n",
      "[Epoch 42/200] [Batch 300/637] [D loss: 0.175389] [G loss: 0.404287]\n",
      "[Epoch 42/200] [Batch 301/637] [D loss: 0.142744] [G loss: 0.513872]\n",
      "[Epoch 42/200] [Batch 302/637] [D loss: 0.181054] [G loss: 0.456241]\n",
      "[Epoch 42/200] [Batch 303/637] [D loss: 0.165676] [G loss: 0.452336]\n",
      "[Epoch 42/200] [Batch 304/637] [D loss: 0.157282] [G loss: 0.581646]\n",
      "[Epoch 42/200] [Batch 305/637] [D loss: 0.163095] [G loss: 0.530588]\n",
      "[Epoch 42/200] [Batch 306/637] [D loss: 0.144278] [G loss: 0.465898]\n",
      "[Epoch 42/200] [Batch 307/637] [D loss: 0.155328] [G loss: 0.473107]\n",
      "[Epoch 42/200] [Batch 308/637] [D loss: 0.162423] [G loss: 0.450580]\n",
      "[Epoch 42/200] [Batch 309/637] [D loss: 0.196773] [G loss: 0.394958]\n",
      "[Epoch 42/200] [Batch 310/637] [D loss: 0.207427] [G loss: 0.535098]\n",
      "[Epoch 42/200] [Batch 311/637] [D loss: 0.163336] [G loss: 0.640262]\n",
      "[Epoch 42/200] [Batch 312/637] [D loss: 0.205568] [G loss: 0.544181]\n",
      "[Epoch 42/200] [Batch 313/637] [D loss: 0.154089] [G loss: 0.491232]\n",
      "[Epoch 42/200] [Batch 314/637] [D loss: 0.181683] [G loss: 0.477229]\n",
      "[Epoch 42/200] [Batch 315/637] [D loss: 0.151960] [G loss: 0.478239]\n",
      "[Epoch 42/200] [Batch 316/637] [D loss: 0.160899] [G loss: 0.529401]\n",
      "[Epoch 42/200] [Batch 317/637] [D loss: 0.161892] [G loss: 0.492573]\n",
      "[Epoch 42/200] [Batch 318/637] [D loss: 0.179612] [G loss: 0.549975]\n",
      "[Epoch 42/200] [Batch 319/637] [D loss: 0.201997] [G loss: 0.417547]\n",
      "[Epoch 42/200] [Batch 320/637] [D loss: 0.156736] [G loss: 0.583796]\n",
      "[Epoch 42/200] [Batch 321/637] [D loss: 0.152931] [G loss: 0.516479]\n",
      "[Epoch 42/200] [Batch 322/637] [D loss: 0.194260] [G loss: 0.462124]\n",
      "[Epoch 42/200] [Batch 323/637] [D loss: 0.160664] [G loss: 0.531767]\n",
      "[Epoch 42/200] [Batch 324/637] [D loss: 0.172063] [G loss: 0.488609]\n",
      "[Epoch 42/200] [Batch 325/637] [D loss: 0.140195] [G loss: 0.540639]\n",
      "[Epoch 42/200] [Batch 326/637] [D loss: 0.150600] [G loss: 0.520703]\n",
      "[Epoch 42/200] [Batch 327/637] [D loss: 0.143463] [G loss: 0.553580]\n",
      "[Epoch 42/200] [Batch 328/637] [D loss: 0.167670] [G loss: 0.471790]\n",
      "[Epoch 42/200] [Batch 329/637] [D loss: 0.144263] [G loss: 0.527503]\n",
      "[Epoch 42/200] [Batch 330/637] [D loss: 0.172905] [G loss: 0.489961]\n",
      "[Epoch 42/200] [Batch 331/637] [D loss: 0.169863] [G loss: 0.506247]\n",
      "[Epoch 42/200] [Batch 332/637] [D loss: 0.172088] [G loss: 0.504232]\n",
      "[Epoch 42/200] [Batch 333/637] [D loss: 0.171141] [G loss: 0.527055]\n",
      "[Epoch 42/200] [Batch 334/637] [D loss: 0.184438] [G loss: 0.431402]\n",
      "[Epoch 42/200] [Batch 335/637] [D loss: 0.161583] [G loss: 0.475241]\n",
      "[Epoch 42/200] [Batch 336/637] [D loss: 0.169176] [G loss: 0.405700]\n",
      "[Epoch 42/200] [Batch 337/637] [D loss: 0.174524] [G loss: 0.533100]\n",
      "[Epoch 42/200] [Batch 338/637] [D loss: 0.185838] [G loss: 0.499163]\n",
      "[Epoch 42/200] [Batch 339/637] [D loss: 0.181317] [G loss: 0.486357]\n",
      "[Epoch 42/200] [Batch 340/637] [D loss: 0.188636] [G loss: 0.469202]\n",
      "[Epoch 42/200] [Batch 341/637] [D loss: 0.175616] [G loss: 0.504593]\n",
      "[Epoch 42/200] [Batch 342/637] [D loss: 0.159393] [G loss: 0.515303]\n",
      "[Epoch 42/200] [Batch 343/637] [D loss: 0.200512] [G loss: 0.424657]\n",
      "[Epoch 42/200] [Batch 344/637] [D loss: 0.174815] [G loss: 0.522581]\n",
      "[Epoch 42/200] [Batch 345/637] [D loss: 0.169393] [G loss: 0.527445]\n",
      "[Epoch 42/200] [Batch 346/637] [D loss: 0.155013] [G loss: 0.441492]\n",
      "[Epoch 42/200] [Batch 347/637] [D loss: 0.165256] [G loss: 0.447030]\n",
      "[Epoch 42/200] [Batch 348/637] [D loss: 0.164081] [G loss: 0.464917]\n",
      "[Epoch 42/200] [Batch 349/637] [D loss: 0.182549] [G loss: 0.487163]\n",
      "[Epoch 42/200] [Batch 350/637] [D loss: 0.165053] [G loss: 0.527013]\n",
      "[Epoch 42/200] [Batch 351/637] [D loss: 0.170121] [G loss: 0.469241]\n",
      "[Epoch 42/200] [Batch 352/637] [D loss: 0.177275] [G loss: 0.434353]\n",
      "[Epoch 42/200] [Batch 353/637] [D loss: 0.147056] [G loss: 0.538073]\n",
      "[Epoch 42/200] [Batch 354/637] [D loss: 0.179830] [G loss: 0.451366]\n",
      "[Epoch 42/200] [Batch 355/637] [D loss: 0.185355] [G loss: 0.527417]\n",
      "[Epoch 42/200] [Batch 356/637] [D loss: 0.171154] [G loss: 0.521858]\n",
      "[Epoch 42/200] [Batch 357/637] [D loss: 0.148634] [G loss: 0.510269]\n",
      "[Epoch 42/200] [Batch 358/637] [D loss: 0.154042] [G loss: 0.487394]\n",
      "[Epoch 42/200] [Batch 359/637] [D loss: 0.179526] [G loss: 0.410268]\n",
      "[Epoch 42/200] [Batch 360/637] [D loss: 0.155796] [G loss: 0.540297]\n",
      "[Epoch 42/200] [Batch 361/637] [D loss: 0.186071] [G loss: 0.450925]\n",
      "[Epoch 42/200] [Batch 362/637] [D loss: 0.155977] [G loss: 0.505115]\n",
      "[Epoch 42/200] [Batch 363/637] [D loss: 0.168830] [G loss: 0.499747]\n",
      "[Epoch 42/200] [Batch 364/637] [D loss: 0.179431] [G loss: 0.642229]\n",
      "[Epoch 42/200] [Batch 365/637] [D loss: 0.139356] [G loss: 0.527406]\n",
      "[Epoch 42/200] [Batch 366/637] [D loss: 0.163308] [G loss: 0.460495]\n",
      "[Epoch 42/200] [Batch 367/637] [D loss: 0.177354] [G loss: 0.400735]\n",
      "[Epoch 42/200] [Batch 368/637] [D loss: 0.147998] [G loss: 0.511576]\n",
      "[Epoch 42/200] [Batch 369/637] [D loss: 0.167057] [G loss: 0.489523]\n",
      "[Epoch 42/200] [Batch 370/637] [D loss: 0.141638] [G loss: 0.542635]\n",
      "[Epoch 42/200] [Batch 371/637] [D loss: 0.168839] [G loss: 0.556663]\n",
      "[Epoch 42/200] [Batch 372/637] [D loss: 0.165533] [G loss: 0.477007]\n",
      "[Epoch 42/200] [Batch 373/637] [D loss: 0.168373] [G loss: 0.492466]\n",
      "[Epoch 42/200] [Batch 374/637] [D loss: 0.193344] [G loss: 0.396941]\n",
      "[Epoch 42/200] [Batch 375/637] [D loss: 0.162098] [G loss: 0.585680]\n",
      "[Epoch 42/200] [Batch 376/637] [D loss: 0.160173] [G loss: 0.545497]\n",
      "[Epoch 42/200] [Batch 377/637] [D loss: 0.163067] [G loss: 0.559178]\n",
      "[Epoch 42/200] [Batch 378/637] [D loss: 0.151111] [G loss: 0.541107]\n",
      "[Epoch 42/200] [Batch 379/637] [D loss: 0.222536] [G loss: 0.389926]\n",
      "[Epoch 42/200] [Batch 380/637] [D loss: 0.194555] [G loss: 0.465306]\n",
      "[Epoch 42/200] [Batch 381/637] [D loss: 0.175670] [G loss: 0.537311]\n",
      "[Epoch 42/200] [Batch 382/637] [D loss: 0.148312] [G loss: 0.559183]\n",
      "[Epoch 42/200] [Batch 383/637] [D loss: 0.173554] [G loss: 0.507454]\n",
      "[Epoch 42/200] [Batch 384/637] [D loss: 0.176797] [G loss: 0.435820]\n",
      "[Epoch 42/200] [Batch 385/637] [D loss: 0.162686] [G loss: 0.497334]\n",
      "[Epoch 42/200] [Batch 386/637] [D loss: 0.168299] [G loss: 0.473101]\n",
      "[Epoch 42/200] [Batch 387/637] [D loss: 0.181751] [G loss: 0.569018]\n",
      "[Epoch 42/200] [Batch 388/637] [D loss: 0.171951] [G loss: 0.450033]\n",
      "[Epoch 42/200] [Batch 389/637] [D loss: 0.146518] [G loss: 0.528701]\n",
      "[Epoch 42/200] [Batch 390/637] [D loss: 0.152815] [G loss: 0.475691]\n",
      "[Epoch 42/200] [Batch 391/637] [D loss: 0.142586] [G loss: 0.527650]\n",
      "[Epoch 42/200] [Batch 392/637] [D loss: 0.158651] [G loss: 0.506542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/200] [Batch 393/637] [D loss: 0.180189] [G loss: 0.536050]\n",
      "[Epoch 42/200] [Batch 394/637] [D loss: 0.157114] [G loss: 0.499301]\n",
      "[Epoch 42/200] [Batch 395/637] [D loss: 0.159481] [G loss: 0.465374]\n",
      "[Epoch 42/200] [Batch 396/637] [D loss: 0.168630] [G loss: 0.474764]\n",
      "[Epoch 42/200] [Batch 397/637] [D loss: 0.173469] [G loss: 0.490189]\n",
      "[Epoch 42/200] [Batch 398/637] [D loss: 0.174715] [G loss: 0.469718]\n",
      "[Epoch 42/200] [Batch 399/637] [D loss: 0.197524] [G loss: 0.451285]\n",
      "[Epoch 42/200] [Batch 400/637] [D loss: 0.171409] [G loss: 0.529297]\n",
      "[Epoch 42/200] [Batch 401/637] [D loss: 0.178671] [G loss: 0.542495]\n",
      "[Epoch 42/200] [Batch 402/637] [D loss: 0.176914] [G loss: 0.474458]\n",
      "[Epoch 42/200] [Batch 403/637] [D loss: 0.166372] [G loss: 0.456055]\n",
      "[Epoch 42/200] [Batch 404/637] [D loss: 0.194618] [G loss: 0.462537]\n",
      "[Epoch 42/200] [Batch 405/637] [D loss: 0.170044] [G loss: 0.451734]\n",
      "[Epoch 42/200] [Batch 406/637] [D loss: 0.148791] [G loss: 0.519484]\n",
      "[Epoch 42/200] [Batch 407/637] [D loss: 0.193497] [G loss: 0.502903]\n",
      "[Epoch 42/200] [Batch 408/637] [D loss: 0.152530] [G loss: 0.604410]\n",
      "[Epoch 42/200] [Batch 409/637] [D loss: 0.182146] [G loss: 0.513565]\n",
      "[Epoch 42/200] [Batch 410/637] [D loss: 0.182993] [G loss: 0.485045]\n",
      "[Epoch 42/200] [Batch 411/637] [D loss: 0.148686] [G loss: 0.495735]\n",
      "[Epoch 42/200] [Batch 412/637] [D loss: 0.144248] [G loss: 0.501438]\n",
      "[Epoch 42/200] [Batch 413/637] [D loss: 0.182741] [G loss: 0.457552]\n",
      "[Epoch 42/200] [Batch 414/637] [D loss: 0.166954] [G loss: 0.542304]\n",
      "[Epoch 42/200] [Batch 415/637] [D loss: 0.179588] [G loss: 0.522753]\n",
      "[Epoch 42/200] [Batch 416/637] [D loss: 0.158331] [G loss: 0.493551]\n",
      "[Epoch 42/200] [Batch 417/637] [D loss: 0.158450] [G loss: 0.532615]\n",
      "[Epoch 42/200] [Batch 418/637] [D loss: 0.209335] [G loss: 0.545655]\n",
      "[Epoch 42/200] [Batch 419/637] [D loss: 0.169926] [G loss: 0.480803]\n",
      "[Epoch 42/200] [Batch 420/637] [D loss: 0.190738] [G loss: 0.437791]\n",
      "[Epoch 42/200] [Batch 421/637] [D loss: 0.152330] [G loss: 0.531993]\n",
      "[Epoch 42/200] [Batch 422/637] [D loss: 0.188316] [G loss: 0.503182]\n",
      "[Epoch 42/200] [Batch 423/637] [D loss: 0.161333] [G loss: 0.513606]\n",
      "[Epoch 42/200] [Batch 424/637] [D loss: 0.167211] [G loss: 0.432496]\n",
      "[Epoch 42/200] [Batch 425/637] [D loss: 0.170704] [G loss: 0.444526]\n",
      "[Epoch 42/200] [Batch 426/637] [D loss: 0.155761] [G loss: 0.483330]\n",
      "[Epoch 42/200] [Batch 427/637] [D loss: 0.157817] [G loss: 0.482368]\n",
      "[Epoch 42/200] [Batch 428/637] [D loss: 0.146724] [G loss: 0.513160]\n",
      "[Epoch 42/200] [Batch 429/637] [D loss: 0.169810] [G loss: 0.534283]\n",
      "[Epoch 42/200] [Batch 430/637] [D loss: 0.150300] [G loss: 0.528701]\n",
      "[Epoch 42/200] [Batch 431/637] [D loss: 0.159381] [G loss: 0.444186]\n",
      "[Epoch 42/200] [Batch 432/637] [D loss: 0.164295] [G loss: 0.476789]\n",
      "[Epoch 42/200] [Batch 433/637] [D loss: 0.170052] [G loss: 0.509304]\n",
      "[Epoch 42/200] [Batch 434/637] [D loss: 0.247793] [G loss: 0.380416]\n",
      "[Epoch 42/200] [Batch 435/637] [D loss: 0.214744] [G loss: 0.509371]\n",
      "[Epoch 42/200] [Batch 436/637] [D loss: 0.168918] [G loss: 0.501856]\n",
      "[Epoch 42/200] [Batch 437/637] [D loss: 0.166873] [G loss: 0.523206]\n",
      "[Epoch 42/200] [Batch 438/637] [D loss: 0.183214] [G loss: 0.501299]\n",
      "[Epoch 42/200] [Batch 439/637] [D loss: 0.193286] [G loss: 0.501332]\n",
      "[Epoch 42/200] [Batch 440/637] [D loss: 0.166479] [G loss: 0.562225]\n",
      "[Epoch 42/200] [Batch 441/637] [D loss: 0.172513] [G loss: 0.478645]\n",
      "[Epoch 42/200] [Batch 442/637] [D loss: 0.173818] [G loss: 0.523049]\n",
      "[Epoch 42/200] [Batch 443/637] [D loss: 0.146385] [G loss: 0.501859]\n",
      "[Epoch 42/200] [Batch 444/637] [D loss: 0.149741] [G loss: 0.614678]\n",
      "[Epoch 42/200] [Batch 445/637] [D loss: 0.149724] [G loss: 0.551835]\n",
      "[Epoch 42/200] [Batch 446/637] [D loss: 0.144799] [G loss: 0.434869]\n",
      "[Epoch 42/200] [Batch 447/637] [D loss: 0.155176] [G loss: 0.484771]\n",
      "[Epoch 42/200] [Batch 448/637] [D loss: 0.200151] [G loss: 0.440155]\n",
      "[Epoch 42/200] [Batch 449/637] [D loss: 0.206043] [G loss: 0.488661]\n",
      "[Epoch 42/200] [Batch 450/637] [D loss: 0.169237] [G loss: 0.451258]\n",
      "[Epoch 42/200] [Batch 451/637] [D loss: 0.163379] [G loss: 0.530488]\n",
      "[Epoch 42/200] [Batch 452/637] [D loss: 0.165138] [G loss: 0.520645]\n",
      "[Epoch 42/200] [Batch 453/637] [D loss: 0.166569] [G loss: 0.470863]\n",
      "[Epoch 42/200] [Batch 454/637] [D loss: 0.162649] [G loss: 0.449176]\n",
      "[Epoch 42/200] [Batch 455/637] [D loss: 0.159276] [G loss: 0.430761]\n",
      "[Epoch 42/200] [Batch 456/637] [D loss: 0.190360] [G loss: 0.423861]\n",
      "[Epoch 42/200] [Batch 457/637] [D loss: 0.165631] [G loss: 0.529573]\n",
      "[Epoch 42/200] [Batch 458/637] [D loss: 0.169262] [G loss: 0.524883]\n",
      "[Epoch 42/200] [Batch 459/637] [D loss: 0.161831] [G loss: 0.427414]\n",
      "[Epoch 42/200] [Batch 460/637] [D loss: 0.181752] [G loss: 0.410281]\n",
      "[Epoch 42/200] [Batch 461/637] [D loss: 0.157866] [G loss: 0.477443]\n",
      "[Epoch 42/200] [Batch 462/637] [D loss: 0.200326] [G loss: 0.449031]\n",
      "[Epoch 42/200] [Batch 463/637] [D loss: 0.177741] [G loss: 0.549779]\n",
      "[Epoch 42/200] [Batch 464/637] [D loss: 0.183312] [G loss: 0.395820]\n",
      "[Epoch 42/200] [Batch 465/637] [D loss: 0.142510] [G loss: 0.501166]\n",
      "[Epoch 42/200] [Batch 466/637] [D loss: 0.176165] [G loss: 0.427311]\n",
      "[Epoch 42/200] [Batch 467/637] [D loss: 0.175256] [G loss: 0.492829]\n",
      "[Epoch 42/200] [Batch 468/637] [D loss: 0.165821] [G loss: 0.624991]\n",
      "[Epoch 42/200] [Batch 469/637] [D loss: 0.176761] [G loss: 0.518309]\n",
      "[Epoch 42/200] [Batch 470/637] [D loss: 0.185585] [G loss: 0.473076]\n",
      "[Epoch 42/200] [Batch 471/637] [D loss: 0.162800] [G loss: 0.529137]\n",
      "[Epoch 42/200] [Batch 472/637] [D loss: 0.161868] [G loss: 0.475095]\n",
      "[Epoch 42/200] [Batch 473/637] [D loss: 0.158777] [G loss: 0.444679]\n",
      "[Epoch 42/200] [Batch 474/637] [D loss: 0.147175] [G loss: 0.505288]\n",
      "[Epoch 42/200] [Batch 475/637] [D loss: 0.149409] [G loss: 0.577197]\n",
      "[Epoch 42/200] [Batch 476/637] [D loss: 0.158159] [G loss: 0.534239]\n",
      "[Epoch 42/200] [Batch 477/637] [D loss: 0.156508] [G loss: 0.543077]\n",
      "[Epoch 42/200] [Batch 478/637] [D loss: 0.165395] [G loss: 0.517012]\n",
      "[Epoch 42/200] [Batch 479/637] [D loss: 0.132113] [G loss: 0.511287]\n",
      "[Epoch 42/200] [Batch 480/637] [D loss: 0.163573] [G loss: 0.518865]\n",
      "[Epoch 42/200] [Batch 481/637] [D loss: 0.155292] [G loss: 0.491636]\n",
      "[Epoch 42/200] [Batch 482/637] [D loss: 0.154711] [G loss: 0.493408]\n",
      "[Epoch 42/200] [Batch 483/637] [D loss: 0.151089] [G loss: 0.447986]\n",
      "[Epoch 42/200] [Batch 484/637] [D loss: 0.172120] [G loss: 0.535068]\n",
      "[Epoch 42/200] [Batch 485/637] [D loss: 0.178485] [G loss: 0.447970]\n",
      "[Epoch 42/200] [Batch 486/637] [D loss: 0.174143] [G loss: 0.460008]\n",
      "[Epoch 42/200] [Batch 487/637] [D loss: 0.204874] [G loss: 0.558066]\n",
      "[Epoch 42/200] [Batch 488/637] [D loss: 0.184445] [G loss: 0.445916]\n",
      "[Epoch 42/200] [Batch 489/637] [D loss: 0.165181] [G loss: 0.451197]\n",
      "[Epoch 42/200] [Batch 490/637] [D loss: 0.174442] [G loss: 0.481423]\n",
      "[Epoch 42/200] [Batch 491/637] [D loss: 0.180506] [G loss: 0.475510]\n",
      "[Epoch 42/200] [Batch 492/637] [D loss: 0.178838] [G loss: 0.503060]\n",
      "[Epoch 42/200] [Batch 493/637] [D loss: 0.185646] [G loss: 0.459288]\n",
      "[Epoch 42/200] [Batch 494/637] [D loss: 0.172321] [G loss: 0.460658]\n",
      "[Epoch 42/200] [Batch 495/637] [D loss: 0.161480] [G loss: 0.505141]\n",
      "[Epoch 42/200] [Batch 496/637] [D loss: 0.159930] [G loss: 0.438975]\n",
      "[Epoch 42/200] [Batch 497/637] [D loss: 0.153618] [G loss: 0.501731]\n",
      "[Epoch 42/200] [Batch 498/637] [D loss: 0.166260] [G loss: 0.467708]\n",
      "[Epoch 42/200] [Batch 499/637] [D loss: 0.164074] [G loss: 0.582321]\n",
      "[Epoch 42/200] [Batch 500/637] [D loss: 0.180962] [G loss: 0.526606]\n",
      "[Epoch 42/200] [Batch 501/637] [D loss: 0.156405] [G loss: 0.497272]\n",
      "[Epoch 42/200] [Batch 502/637] [D loss: 0.204063] [G loss: 0.467126]\n",
      "[Epoch 42/200] [Batch 503/637] [D loss: 0.192402] [G loss: 0.554062]\n",
      "[Epoch 42/200] [Batch 504/637] [D loss: 0.159636] [G loss: 0.642150]\n",
      "[Epoch 42/200] [Batch 505/637] [D loss: 0.179639] [G loss: 0.478828]\n",
      "[Epoch 42/200] [Batch 506/637] [D loss: 0.169344] [G loss: 0.487857]\n",
      "[Epoch 42/200] [Batch 507/637] [D loss: 0.178163] [G loss: 0.488962]\n",
      "[Epoch 42/200] [Batch 508/637] [D loss: 0.170531] [G loss: 0.489591]\n",
      "[Epoch 42/200] [Batch 509/637] [D loss: 0.189129] [G loss: 0.482436]\n",
      "[Epoch 42/200] [Batch 510/637] [D loss: 0.151312] [G loss: 0.505067]\n",
      "[Epoch 42/200] [Batch 511/637] [D loss: 0.164385] [G loss: 0.507391]\n",
      "[Epoch 42/200] [Batch 512/637] [D loss: 0.148726] [G loss: 0.501048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/200] [Batch 513/637] [D loss: 0.156571] [G loss: 0.464763]\n",
      "[Epoch 42/200] [Batch 514/637] [D loss: 0.172976] [G loss: 0.484065]\n",
      "[Epoch 42/200] [Batch 515/637] [D loss: 0.145748] [G loss: 0.610766]\n",
      "[Epoch 42/200] [Batch 516/637] [D loss: 0.173103] [G loss: 0.534891]\n",
      "[Epoch 42/200] [Batch 517/637] [D loss: 0.162629] [G loss: 0.510304]\n",
      "[Epoch 42/200] [Batch 518/637] [D loss: 0.156038] [G loss: 0.436249]\n",
      "[Epoch 42/200] [Batch 519/637] [D loss: 0.163178] [G loss: 0.447093]\n",
      "[Epoch 42/200] [Batch 520/637] [D loss: 0.194896] [G loss: 0.429082]\n",
      "[Epoch 42/200] [Batch 521/637] [D loss: 0.163312] [G loss: 0.489562]\n",
      "[Epoch 42/200] [Batch 522/637] [D loss: 0.169292] [G loss: 0.512823]\n",
      "[Epoch 42/200] [Batch 523/637] [D loss: 0.164701] [G loss: 0.481425]\n",
      "[Epoch 42/200] [Batch 524/637] [D loss: 0.148754] [G loss: 0.501875]\n",
      "[Epoch 42/200] [Batch 525/637] [D loss: 0.179264] [G loss: 0.466906]\n",
      "[Epoch 42/200] [Batch 526/637] [D loss: 0.159050] [G loss: 0.562989]\n",
      "[Epoch 42/200] [Batch 527/637] [D loss: 0.165503] [G loss: 0.462960]\n",
      "[Epoch 42/200] [Batch 528/637] [D loss: 0.180851] [G loss: 0.431485]\n",
      "[Epoch 42/200] [Batch 529/637] [D loss: 0.178347] [G loss: 0.551014]\n",
      "[Epoch 42/200] [Batch 530/637] [D loss: 0.190175] [G loss: 0.534309]\n",
      "[Epoch 42/200] [Batch 531/637] [D loss: 0.182096] [G loss: 0.467591]\n",
      "[Epoch 42/200] [Batch 532/637] [D loss: 0.185719] [G loss: 0.419469]\n",
      "[Epoch 42/200] [Batch 533/637] [D loss: 0.178952] [G loss: 0.427972]\n",
      "[Epoch 42/200] [Batch 534/637] [D loss: 0.177859] [G loss: 0.514547]\n",
      "[Epoch 42/200] [Batch 535/637] [D loss: 0.147174] [G loss: 0.544834]\n",
      "[Epoch 42/200] [Batch 536/637] [D loss: 0.164755] [G loss: 0.465889]\n",
      "[Epoch 42/200] [Batch 537/637] [D loss: 0.171908] [G loss: 0.446139]\n",
      "[Epoch 42/200] [Batch 538/637] [D loss: 0.167883] [G loss: 0.478310]\n",
      "[Epoch 42/200] [Batch 539/637] [D loss: 0.170681] [G loss: 0.492260]\n",
      "[Epoch 42/200] [Batch 540/637] [D loss: 0.180220] [G loss: 0.462818]\n",
      "[Epoch 42/200] [Batch 541/637] [D loss: 0.178896] [G loss: 0.467748]\n",
      "[Epoch 42/200] [Batch 542/637] [D loss: 0.168650] [G loss: 0.504908]\n",
      "[Epoch 42/200] [Batch 543/637] [D loss: 0.183487] [G loss: 0.454031]\n",
      "[Epoch 42/200] [Batch 544/637] [D loss: 0.158528] [G loss: 0.530113]\n",
      "[Epoch 42/200] [Batch 545/637] [D loss: 0.176385] [G loss: 0.495231]\n",
      "[Epoch 42/200] [Batch 546/637] [D loss: 0.169563] [G loss: 0.421224]\n",
      "[Epoch 42/200] [Batch 547/637] [D loss: 0.176592] [G loss: 0.444396]\n",
      "[Epoch 42/200] [Batch 548/637] [D loss: 0.148082] [G loss: 0.554243]\n",
      "[Epoch 42/200] [Batch 549/637] [D loss: 0.191811] [G loss: 0.462741]\n",
      "[Epoch 42/200] [Batch 550/637] [D loss: 0.179321] [G loss: 0.540199]\n",
      "[Epoch 42/200] [Batch 551/637] [D loss: 0.177812] [G loss: 0.516641]\n",
      "[Epoch 42/200] [Batch 552/637] [D loss: 0.206488] [G loss: 0.396296]\n",
      "[Epoch 42/200] [Batch 553/637] [D loss: 0.169076] [G loss: 0.420878]\n",
      "[Epoch 42/200] [Batch 554/637] [D loss: 0.177834] [G loss: 0.418943]\n",
      "[Epoch 42/200] [Batch 555/637] [D loss: 0.156383] [G loss: 0.467694]\n",
      "[Epoch 42/200] [Batch 556/637] [D loss: 0.162993] [G loss: 0.442406]\n",
      "[Epoch 42/200] [Batch 557/637] [D loss: 0.164533] [G loss: 0.548077]\n",
      "[Epoch 42/200] [Batch 558/637] [D loss: 0.155087] [G loss: 0.483344]\n",
      "[Epoch 42/200] [Batch 559/637] [D loss: 0.188056] [G loss: 0.400168]\n",
      "[Epoch 42/200] [Batch 560/637] [D loss: 0.162440] [G loss: 0.516958]\n",
      "[Epoch 42/200] [Batch 561/637] [D loss: 0.180670] [G loss: 0.526453]\n",
      "[Epoch 42/200] [Batch 562/637] [D loss: 0.155678] [G loss: 0.503023]\n",
      "[Epoch 42/200] [Batch 563/637] [D loss: 0.143002] [G loss: 0.590890]\n",
      "[Epoch 42/200] [Batch 564/637] [D loss: 0.147466] [G loss: 0.504086]\n",
      "[Epoch 42/200] [Batch 565/637] [D loss: 0.171551] [G loss: 0.450673]\n",
      "[Epoch 42/200] [Batch 566/637] [D loss: 0.163089] [G loss: 0.469060]\n",
      "[Epoch 42/200] [Batch 567/637] [D loss: 0.146277] [G loss: 0.495481]\n",
      "[Epoch 42/200] [Batch 568/637] [D loss: 0.152575] [G loss: 0.498875]\n",
      "[Epoch 42/200] [Batch 569/637] [D loss: 0.189562] [G loss: 0.570129]\n",
      "[Epoch 42/200] [Batch 570/637] [D loss: 0.163872] [G loss: 0.538155]\n",
      "[Epoch 42/200] [Batch 571/637] [D loss: 0.162655] [G loss: 0.449296]\n",
      "[Epoch 42/200] [Batch 572/637] [D loss: 0.151893] [G loss: 0.528040]\n",
      "[Epoch 42/200] [Batch 573/637] [D loss: 0.269765] [G loss: 0.371188]\n",
      "[Epoch 42/200] [Batch 574/637] [D loss: 0.301852] [G loss: 0.858152]\n",
      "[Epoch 42/200] [Batch 575/637] [D loss: 0.189183] [G loss: 0.539811]\n",
      "[Epoch 42/200] [Batch 576/637] [D loss: 0.219295] [G loss: 0.397534]\n",
      "[Epoch 42/200] [Batch 577/637] [D loss: 0.212953] [G loss: 0.387136]\n",
      "[Epoch 42/200] [Batch 578/637] [D loss: 0.183267] [G loss: 0.494562]\n",
      "[Epoch 42/200] [Batch 579/637] [D loss: 0.178142] [G loss: 0.504821]\n",
      "[Epoch 42/200] [Batch 580/637] [D loss: 0.187714] [G loss: 0.455260]\n",
      "[Epoch 42/200] [Batch 581/637] [D loss: 0.185679] [G loss: 0.471734]\n",
      "[Epoch 42/200] [Batch 582/637] [D loss: 0.171620] [G loss: 0.534788]\n",
      "[Epoch 42/200] [Batch 583/637] [D loss: 0.188937] [G loss: 0.486360]\n",
      "[Epoch 42/200] [Batch 584/637] [D loss: 0.189521] [G loss: 0.412149]\n",
      "[Epoch 42/200] [Batch 585/637] [D loss: 0.164062] [G loss: 0.456653]\n",
      "[Epoch 42/200] [Batch 586/637] [D loss: 0.190797] [G loss: 0.431202]\n",
      "[Epoch 42/200] [Batch 587/637] [D loss: 0.165721] [G loss: 0.450176]\n",
      "[Epoch 42/200] [Batch 588/637] [D loss: 0.169633] [G loss: 0.461664]\n",
      "[Epoch 42/200] [Batch 589/637] [D loss: 0.152766] [G loss: 0.520263]\n",
      "[Epoch 42/200] [Batch 590/637] [D loss: 0.173010] [G loss: 0.510336]\n",
      "[Epoch 42/200] [Batch 591/637] [D loss: 0.167516] [G loss: 0.433534]\n",
      "[Epoch 42/200] [Batch 592/637] [D loss: 0.194989] [G loss: 0.489464]\n",
      "[Epoch 42/200] [Batch 593/637] [D loss: 0.176789] [G loss: 0.681746]\n",
      "[Epoch 42/200] [Batch 594/637] [D loss: 0.165644] [G loss: 0.560156]\n",
      "[Epoch 42/200] [Batch 595/637] [D loss: 0.175198] [G loss: 0.468743]\n",
      "[Epoch 42/200] [Batch 596/637] [D loss: 0.169314] [G loss: 0.516263]\n",
      "[Epoch 42/200] [Batch 597/637] [D loss: 0.184820] [G loss: 0.449264]\n",
      "[Epoch 42/200] [Batch 598/637] [D loss: 0.188604] [G loss: 0.447465]\n",
      "[Epoch 42/200] [Batch 599/637] [D loss: 0.161026] [G loss: 0.458830]\n",
      "[Epoch 42/200] [Batch 600/637] [D loss: 0.151978] [G loss: 0.493879]\n",
      "[Epoch 42/200] [Batch 601/637] [D loss: 0.159575] [G loss: 0.449081]\n",
      "[Epoch 42/200] [Batch 602/637] [D loss: 0.160107] [G loss: 0.477428]\n",
      "[Epoch 42/200] [Batch 603/637] [D loss: 0.159592] [G loss: 0.595177]\n",
      "[Epoch 42/200] [Batch 604/637] [D loss: 0.200124] [G loss: 0.459355]\n",
      "[Epoch 42/200] [Batch 605/637] [D loss: 0.176723] [G loss: 0.437185]\n",
      "[Epoch 42/200] [Batch 606/637] [D loss: 0.193300] [G loss: 0.443958]\n",
      "[Epoch 42/200] [Batch 607/637] [D loss: 0.178367] [G loss: 0.490090]\n",
      "[Epoch 42/200] [Batch 608/637] [D loss: 0.180682] [G loss: 0.445443]\n",
      "[Epoch 42/200] [Batch 609/637] [D loss: 0.173304] [G loss: 0.364627]\n",
      "[Epoch 42/200] [Batch 610/637] [D loss: 0.189596] [G loss: 0.413973]\n",
      "[Epoch 42/200] [Batch 611/637] [D loss: 0.157106] [G loss: 0.532641]\n",
      "[Epoch 42/200] [Batch 612/637] [D loss: 0.184581] [G loss: 0.451994]\n",
      "[Epoch 42/200] [Batch 613/637] [D loss: 0.151454] [G loss: 0.535627]\n",
      "[Epoch 42/200] [Batch 614/637] [D loss: 0.146151] [G loss: 0.545914]\n",
      "[Epoch 42/200] [Batch 615/637] [D loss: 0.186415] [G loss: 0.507191]\n",
      "[Epoch 42/200] [Batch 616/637] [D loss: 0.176991] [G loss: 0.438637]\n",
      "[Epoch 42/200] [Batch 617/637] [D loss: 0.166603] [G loss: 0.464236]\n",
      "[Epoch 42/200] [Batch 618/637] [D loss: 0.172359] [G loss: 0.521576]\n",
      "[Epoch 42/200] [Batch 619/637] [D loss: 0.187503] [G loss: 0.477866]\n",
      "[Epoch 42/200] [Batch 620/637] [D loss: 0.167780] [G loss: 0.480765]\n",
      "[Epoch 42/200] [Batch 621/637] [D loss: 0.162510] [G loss: 0.487448]\n",
      "[Epoch 42/200] [Batch 622/637] [D loss: 0.172095] [G loss: 0.468633]\n",
      "[Epoch 42/200] [Batch 623/637] [D loss: 0.181926] [G loss: 0.489633]\n",
      "[Epoch 42/200] [Batch 624/637] [D loss: 0.182001] [G loss: 0.456201]\n",
      "[Epoch 42/200] [Batch 625/637] [D loss: 0.166048] [G loss: 0.492418]\n",
      "[Epoch 42/200] [Batch 626/637] [D loss: 0.190356] [G loss: 0.456952]\n",
      "[Epoch 42/200] [Batch 627/637] [D loss: 0.167351] [G loss: 0.587265]\n",
      "[Epoch 42/200] [Batch 628/637] [D loss: 0.178277] [G loss: 0.483714]\n",
      "[Epoch 42/200] [Batch 629/637] [D loss: 0.169606] [G loss: 0.448556]\n",
      "[Epoch 42/200] [Batch 630/637] [D loss: 0.169705] [G loss: 0.392768]\n",
      "[Epoch 42/200] [Batch 631/637] [D loss: 0.176781] [G loss: 0.412812]\n",
      "[Epoch 42/200] [Batch 632/637] [D loss: 0.187252] [G loss: 0.415257]\n",
      "[Epoch 42/200] [Batch 633/637] [D loss: 0.165426] [G loss: 0.565202]\n",
      "[Epoch 42/200] [Batch 634/637] [D loss: 0.175285] [G loss: 0.520727]\n",
      "[Epoch 42/200] [Batch 635/637] [D loss: 0.188318] [G loss: 0.498352]\n",
      "[Epoch 42/200] [Batch 636/637] [D loss: 0.241825] [G loss: 0.270715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/200] [Batch 0/637] [D loss: 0.178926] [G loss: 0.625124]\n",
      "[Epoch 43/200] [Batch 1/637] [D loss: 0.183392] [G loss: 0.602013]\n",
      "[Epoch 43/200] [Batch 2/637] [D loss: 0.179217] [G loss: 0.482867]\n",
      "[Epoch 43/200] [Batch 3/637] [D loss: 0.164636] [G loss: 0.387470]\n",
      "[Epoch 43/200] [Batch 4/637] [D loss: 0.176551] [G loss: 0.364022]\n",
      "[Epoch 43/200] [Batch 5/637] [D loss: 0.165372] [G loss: 0.433122]\n",
      "[Epoch 43/200] [Batch 6/637] [D loss: 0.164475] [G loss: 0.535023]\n",
      "[Epoch 43/200] [Batch 7/637] [D loss: 0.163265] [G loss: 0.515831]\n",
      "[Epoch 43/200] [Batch 8/637] [D loss: 0.150096] [G loss: 0.460005]\n",
      "[Epoch 43/200] [Batch 9/637] [D loss: 0.157087] [G loss: 0.457168]\n",
      "[Epoch 43/200] [Batch 10/637] [D loss: 0.175581] [G loss: 0.485240]\n",
      "[Epoch 43/200] [Batch 11/637] [D loss: 0.148280] [G loss: 0.542155]\n",
      "[Epoch 43/200] [Batch 12/637] [D loss: 0.162834] [G loss: 0.563329]\n",
      "[Epoch 43/200] [Batch 13/637] [D loss: 0.171320] [G loss: 0.491260]\n",
      "[Epoch 43/200] [Batch 14/637] [D loss: 0.197641] [G loss: 0.534377]\n",
      "[Epoch 43/200] [Batch 15/637] [D loss: 0.143480] [G loss: 0.553059]\n",
      "[Epoch 43/200] [Batch 16/637] [D loss: 0.201563] [G loss: 0.400428]\n",
      "[Epoch 43/200] [Batch 17/637] [D loss: 0.177528] [G loss: 0.394366]\n",
      "[Epoch 43/200] [Batch 18/637] [D loss: 0.176681] [G loss: 0.452453]\n",
      "[Epoch 43/200] [Batch 19/637] [D loss: 0.189011] [G loss: 0.475362]\n",
      "[Epoch 43/200] [Batch 20/637] [D loss: 0.196283] [G loss: 0.426797]\n",
      "[Epoch 43/200] [Batch 21/637] [D loss: 0.197448] [G loss: 0.531294]\n",
      "[Epoch 43/200] [Batch 22/637] [D loss: 0.166500] [G loss: 0.505020]\n",
      "[Epoch 43/200] [Batch 23/637] [D loss: 0.177712] [G loss: 0.521761]\n",
      "[Epoch 43/200] [Batch 24/637] [D loss: 0.183958] [G loss: 0.503807]\n",
      "[Epoch 43/200] [Batch 25/637] [D loss: 0.162669] [G loss: 0.461892]\n",
      "[Epoch 43/200] [Batch 26/637] [D loss: 0.168658] [G loss: 0.439841]\n",
      "[Epoch 43/200] [Batch 27/637] [D loss: 0.161103] [G loss: 0.467501]\n",
      "[Epoch 43/200] [Batch 28/637] [D loss: 0.162457] [G loss: 0.535799]\n",
      "[Epoch 43/200] [Batch 29/637] [D loss: 0.169578] [G loss: 0.541750]\n",
      "[Epoch 43/200] [Batch 30/637] [D loss: 0.166758] [G loss: 0.497733]\n",
      "[Epoch 43/200] [Batch 31/637] [D loss: 0.169730] [G loss: 0.487374]\n",
      "[Epoch 43/200] [Batch 32/637] [D loss: 0.162184] [G loss: 0.476853]\n",
      "[Epoch 43/200] [Batch 33/637] [D loss: 0.164433] [G loss: 0.482763]\n",
      "[Epoch 43/200] [Batch 34/637] [D loss: 0.170288] [G loss: 0.553544]\n",
      "[Epoch 43/200] [Batch 35/637] [D loss: 0.172368] [G loss: 0.470131]\n",
      "[Epoch 43/200] [Batch 36/637] [D loss: 0.191326] [G loss: 0.472650]\n",
      "[Epoch 43/200] [Batch 37/637] [D loss: 0.170634] [G loss: 0.498070]\n",
      "[Epoch 43/200] [Batch 38/637] [D loss: 0.170893] [G loss: 0.541820]\n",
      "[Epoch 43/200] [Batch 39/637] [D loss: 0.170564] [G loss: 0.518559]\n",
      "[Epoch 43/200] [Batch 40/637] [D loss: 0.166549] [G loss: 0.497774]\n",
      "[Epoch 43/200] [Batch 41/637] [D loss: 0.157405] [G loss: 0.531421]\n",
      "[Epoch 43/200] [Batch 42/637] [D loss: 0.210111] [G loss: 0.455632]\n",
      "[Epoch 43/200] [Batch 43/637] [D loss: 0.176983] [G loss: 0.539544]\n",
      "[Epoch 43/200] [Batch 44/637] [D loss: 0.164168] [G loss: 0.517663]\n",
      "[Epoch 43/200] [Batch 45/637] [D loss: 0.169520] [G loss: 0.526624]\n",
      "[Epoch 43/200] [Batch 46/637] [D loss: 0.160576] [G loss: 0.518462]\n",
      "[Epoch 43/200] [Batch 47/637] [D loss: 0.148568] [G loss: 0.507287]\n",
      "[Epoch 43/200] [Batch 48/637] [D loss: 0.155083] [G loss: 0.544315]\n",
      "[Epoch 43/200] [Batch 49/637] [D loss: 0.149615] [G loss: 0.574029]\n",
      "[Epoch 43/200] [Batch 50/637] [D loss: 0.144883] [G loss: 0.570389]\n",
      "[Epoch 43/200] [Batch 51/637] [D loss: 0.148051] [G loss: 0.494164]\n",
      "[Epoch 43/200] [Batch 52/637] [D loss: 0.181212] [G loss: 0.486667]\n",
      "[Epoch 43/200] [Batch 53/637] [D loss: 0.155984] [G loss: 0.515689]\n",
      "[Epoch 43/200] [Batch 54/637] [D loss: 0.182900] [G loss: 0.521811]\n",
      "[Epoch 43/200] [Batch 55/637] [D loss: 0.162779] [G loss: 0.543011]\n",
      "[Epoch 43/200] [Batch 56/637] [D loss: 0.163903] [G loss: 0.569924]\n",
      "[Epoch 43/200] [Batch 57/637] [D loss: 0.158585] [G loss: 0.489785]\n",
      "[Epoch 43/200] [Batch 58/637] [D loss: 0.196684] [G loss: 0.501747]\n",
      "[Epoch 43/200] [Batch 59/637] [D loss: 0.153197] [G loss: 0.461228]\n",
      "[Epoch 43/200] [Batch 60/637] [D loss: 0.170617] [G loss: 0.511673]\n",
      "[Epoch 43/200] [Batch 61/637] [D loss: 0.151619] [G loss: 0.492976]\n",
      "[Epoch 43/200] [Batch 62/637] [D loss: 0.165911] [G loss: 0.575701]\n",
      "[Epoch 43/200] [Batch 63/637] [D loss: 0.177202] [G loss: 0.491133]\n",
      "[Epoch 43/200] [Batch 64/637] [D loss: 0.169214] [G loss: 0.552144]\n",
      "[Epoch 43/200] [Batch 65/637] [D loss: 0.165655] [G loss: 0.508134]\n",
      "[Epoch 43/200] [Batch 66/637] [D loss: 0.164457] [G loss: 0.411301]\n",
      "[Epoch 43/200] [Batch 67/637] [D loss: 0.168024] [G loss: 0.477636]\n",
      "[Epoch 43/200] [Batch 68/637] [D loss: 0.169939] [G loss: 0.528609]\n",
      "[Epoch 43/200] [Batch 69/637] [D loss: 0.149297] [G loss: 0.516979]\n",
      "[Epoch 43/200] [Batch 70/637] [D loss: 0.171797] [G loss: 0.459549]\n",
      "[Epoch 43/200] [Batch 71/637] [D loss: 0.214890] [G loss: 0.454344]\n",
      "[Epoch 43/200] [Batch 72/637] [D loss: 0.148352] [G loss: 0.641649]\n",
      "[Epoch 43/200] [Batch 73/637] [D loss: 0.183407] [G loss: 0.578953]\n",
      "[Epoch 43/200] [Batch 74/637] [D loss: 0.154600] [G loss: 0.604670]\n",
      "[Epoch 43/200] [Batch 75/637] [D loss: 0.172110] [G loss: 0.528750]\n",
      "[Epoch 43/200] [Batch 76/637] [D loss: 0.185794] [G loss: 0.464148]\n",
      "[Epoch 43/200] [Batch 77/637] [D loss: 0.139578] [G loss: 0.487987]\n",
      "[Epoch 43/200] [Batch 78/637] [D loss: 0.176959] [G loss: 0.475890]\n",
      "[Epoch 43/200] [Batch 79/637] [D loss: 0.177419] [G loss: 0.464182]\n",
      "[Epoch 43/200] [Batch 80/637] [D loss: 0.166954] [G loss: 0.579876]\n",
      "[Epoch 43/200] [Batch 81/637] [D loss: 0.189604] [G loss: 0.538078]\n",
      "[Epoch 43/200] [Batch 82/637] [D loss: 0.166116] [G loss: 0.527331]\n",
      "[Epoch 43/200] [Batch 83/637] [D loss: 0.174929] [G loss: 0.457045]\n",
      "[Epoch 43/200] [Batch 84/637] [D loss: 0.163742] [G loss: 0.440861]\n",
      "[Epoch 43/200] [Batch 85/637] [D loss: 0.171669] [G loss: 0.432173]\n",
      "[Epoch 43/200] [Batch 86/637] [D loss: 0.188158] [G loss: 0.532750]\n",
      "[Epoch 43/200] [Batch 87/637] [D loss: 0.161553] [G loss: 0.500006]\n",
      "[Epoch 43/200] [Batch 88/637] [D loss: 0.148698] [G loss: 0.535669]\n",
      "[Epoch 43/200] [Batch 89/637] [D loss: 0.168797] [G loss: 0.463761]\n",
      "[Epoch 43/200] [Batch 90/637] [D loss: 0.152228] [G loss: 0.536316]\n",
      "[Epoch 43/200] [Batch 91/637] [D loss: 0.168491] [G loss: 0.388154]\n",
      "[Epoch 43/200] [Batch 92/637] [D loss: 0.167647] [G loss: 0.454538]\n",
      "[Epoch 43/200] [Batch 93/637] [D loss: 0.176170] [G loss: 0.517564]\n",
      "[Epoch 43/200] [Batch 94/637] [D loss: 0.157524] [G loss: 0.570076]\n",
      "[Epoch 43/200] [Batch 95/637] [D loss: 0.161994] [G loss: 0.491594]\n",
      "[Epoch 43/200] [Batch 96/637] [D loss: 0.149131] [G loss: 0.484732]\n",
      "[Epoch 43/200] [Batch 97/637] [D loss: 0.175505] [G loss: 0.488097]\n",
      "[Epoch 43/200] [Batch 98/637] [D loss: 0.178228] [G loss: 0.482742]\n",
      "[Epoch 43/200] [Batch 99/637] [D loss: 0.156164] [G loss: 0.524388]\n",
      "[Epoch 43/200] [Batch 100/637] [D loss: 0.168438] [G loss: 0.443226]\n",
      "[Epoch 43/200] [Batch 101/637] [D loss: 0.188145] [G loss: 0.563851]\n",
      "[Epoch 43/200] [Batch 102/637] [D loss: 0.171233] [G loss: 0.518199]\n",
      "[Epoch 43/200] [Batch 103/637] [D loss: 0.166547] [G loss: 0.440482]\n",
      "[Epoch 43/200] [Batch 104/637] [D loss: 0.175377] [G loss: 0.490546]\n",
      "[Epoch 43/200] [Batch 105/637] [D loss: 0.175562] [G loss: 0.509462]\n",
      "[Epoch 43/200] [Batch 106/637] [D loss: 0.146866] [G loss: 0.532743]\n",
      "[Epoch 43/200] [Batch 107/637] [D loss: 0.183459] [G loss: 0.490644]\n",
      "[Epoch 43/200] [Batch 108/637] [D loss: 0.175446] [G loss: 0.513024]\n",
      "[Epoch 43/200] [Batch 109/637] [D loss: 0.176431] [G loss: 0.592948]\n",
      "[Epoch 43/200] [Batch 110/637] [D loss: 0.167302] [G loss: 0.558249]\n",
      "[Epoch 43/200] [Batch 111/637] [D loss: 0.187026] [G loss: 0.505445]\n",
      "[Epoch 43/200] [Batch 112/637] [D loss: 0.171306] [G loss: 0.469494]\n",
      "[Epoch 43/200] [Batch 113/637] [D loss: 0.168598] [G loss: 0.516719]\n",
      "[Epoch 43/200] [Batch 114/637] [D loss: 0.165965] [G loss: 0.544143]\n",
      "[Epoch 43/200] [Batch 115/637] [D loss: 0.164488] [G loss: 0.496199]\n",
      "[Epoch 43/200] [Batch 116/637] [D loss: 0.181869] [G loss: 0.455212]\n",
      "[Epoch 43/200] [Batch 117/637] [D loss: 0.161793] [G loss: 0.496348]\n",
      "[Epoch 43/200] [Batch 118/637] [D loss: 0.152619] [G loss: 0.465709]\n",
      "[Epoch 43/200] [Batch 119/637] [D loss: 0.168459] [G loss: 0.525324]\n",
      "[Epoch 43/200] [Batch 120/637] [D loss: 0.157568] [G loss: 0.533686]\n",
      "[Epoch 43/200] [Batch 121/637] [D loss: 0.139859] [G loss: 0.516927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/200] [Batch 122/637] [D loss: 0.159344] [G loss: 0.509450]\n",
      "[Epoch 43/200] [Batch 123/637] [D loss: 0.201197] [G loss: 0.605222]\n",
      "[Epoch 43/200] [Batch 124/637] [D loss: 0.186707] [G loss: 0.475809]\n",
      "[Epoch 43/200] [Batch 125/637] [D loss: 0.166570] [G loss: 0.444350]\n",
      "[Epoch 43/200] [Batch 126/637] [D loss: 0.187846] [G loss: 0.454621]\n",
      "[Epoch 43/200] [Batch 127/637] [D loss: 0.153816] [G loss: 0.526900]\n",
      "[Epoch 43/200] [Batch 128/637] [D loss: 0.187047] [G loss: 0.463793]\n",
      "[Epoch 43/200] [Batch 129/637] [D loss: 0.164974] [G loss: 0.476959]\n",
      "[Epoch 43/200] [Batch 130/637] [D loss: 0.166902] [G loss: 0.469175]\n",
      "[Epoch 43/200] [Batch 131/637] [D loss: 0.199198] [G loss: 0.445110]\n",
      "[Epoch 43/200] [Batch 132/637] [D loss: 0.154347] [G loss: 0.527542]\n",
      "[Epoch 43/200] [Batch 133/637] [D loss: 0.154523] [G loss: 0.519808]\n",
      "[Epoch 43/200] [Batch 134/637] [D loss: 0.156970] [G loss: 0.495528]\n",
      "[Epoch 43/200] [Batch 135/637] [D loss: 0.174653] [G loss: 0.441690]\n",
      "[Epoch 43/200] [Batch 136/637] [D loss: 0.176235] [G loss: 0.453529]\n",
      "[Epoch 43/200] [Batch 137/637] [D loss: 0.177411] [G loss: 0.507559]\n",
      "[Epoch 43/200] [Batch 138/637] [D loss: 0.176267] [G loss: 0.532044]\n",
      "[Epoch 43/200] [Batch 139/637] [D loss: 0.164110] [G loss: 0.543964]\n",
      "[Epoch 43/200] [Batch 140/637] [D loss: 0.156195] [G loss: 0.517671]\n",
      "[Epoch 43/200] [Batch 141/637] [D loss: 0.162449] [G loss: 0.466313]\n",
      "[Epoch 43/200] [Batch 142/637] [D loss: 0.162943] [G loss: 0.488071]\n",
      "[Epoch 43/200] [Batch 143/637] [D loss: 0.169053] [G loss: 0.499454]\n",
      "[Epoch 43/200] [Batch 144/637] [D loss: 0.159207] [G loss: 0.541952]\n",
      "[Epoch 43/200] [Batch 145/637] [D loss: 0.171068] [G loss: 0.444963]\n",
      "[Epoch 43/200] [Batch 146/637] [D loss: 0.148580] [G loss: 0.520453]\n",
      "[Epoch 43/200] [Batch 147/637] [D loss: 0.181047] [G loss: 0.458380]\n",
      "[Epoch 43/200] [Batch 148/637] [D loss: 0.156388] [G loss: 0.514882]\n",
      "[Epoch 43/200] [Batch 149/637] [D loss: 0.183050] [G loss: 0.476648]\n",
      "[Epoch 43/200] [Batch 150/637] [D loss: 0.170817] [G loss: 0.506322]\n",
      "[Epoch 43/200] [Batch 151/637] [D loss: 0.157773] [G loss: 0.502619]\n",
      "[Epoch 43/200] [Batch 152/637] [D loss: 0.149880] [G loss: 0.503602]\n",
      "[Epoch 43/200] [Batch 153/637] [D loss: 0.161958] [G loss: 0.462261]\n",
      "[Epoch 43/200] [Batch 154/637] [D loss: 0.167724] [G loss: 0.481985]\n",
      "[Epoch 43/200] [Batch 155/637] [D loss: 0.176490] [G loss: 0.537317]\n",
      "[Epoch 43/200] [Batch 156/637] [D loss: 0.159549] [G loss: 0.620236]\n",
      "[Epoch 43/200] [Batch 157/637] [D loss: 0.195226] [G loss: 0.416102]\n",
      "[Epoch 43/200] [Batch 158/637] [D loss: 0.164245] [G loss: 0.551678]\n",
      "[Epoch 43/200] [Batch 159/637] [D loss: 0.161144] [G loss: 0.533483]\n",
      "[Epoch 43/200] [Batch 160/637] [D loss: 0.191909] [G loss: 0.442215]\n",
      "[Epoch 43/200] [Batch 161/637] [D loss: 0.184848] [G loss: 0.466216]\n",
      "[Epoch 43/200] [Batch 162/637] [D loss: 0.176461] [G loss: 0.576512]\n",
      "[Epoch 43/200] [Batch 163/637] [D loss: 0.162766] [G loss: 0.513666]\n",
      "[Epoch 43/200] [Batch 164/637] [D loss: 0.161102] [G loss: 0.505528]\n",
      "[Epoch 43/200] [Batch 165/637] [D loss: 0.153035] [G loss: 0.489534]\n",
      "[Epoch 43/200] [Batch 166/637] [D loss: 0.152967] [G loss: 0.437421]\n",
      "[Epoch 43/200] [Batch 167/637] [D loss: 0.131570] [G loss: 0.521482]\n",
      "[Epoch 43/200] [Batch 168/637] [D loss: 0.188479] [G loss: 0.482593]\n",
      "[Epoch 43/200] [Batch 169/637] [D loss: 0.168099] [G loss: 0.524149]\n",
      "[Epoch 43/200] [Batch 170/637] [D loss: 0.143957] [G loss: 0.594397]\n",
      "[Epoch 43/200] [Batch 171/637] [D loss: 0.173126] [G loss: 0.602739]\n",
      "[Epoch 43/200] [Batch 172/637] [D loss: 0.170618] [G loss: 0.500487]\n",
      "[Epoch 43/200] [Batch 173/637] [D loss: 0.150426] [G loss: 0.497795]\n",
      "[Epoch 43/200] [Batch 174/637] [D loss: 0.184398] [G loss: 0.421350]\n",
      "[Epoch 43/200] [Batch 175/637] [D loss: 0.149824] [G loss: 0.597089]\n",
      "[Epoch 43/200] [Batch 176/637] [D loss: 0.204458] [G loss: 0.530352]\n",
      "[Epoch 43/200] [Batch 177/637] [D loss: 0.219671] [G loss: 0.414086]\n",
      "[Epoch 43/200] [Batch 178/637] [D loss: 0.170966] [G loss: 0.510993]\n",
      "[Epoch 43/200] [Batch 179/637] [D loss: 0.139292] [G loss: 0.536886]\n",
      "[Epoch 43/200] [Batch 180/637] [D loss: 0.153810] [G loss: 0.536268]\n",
      "[Epoch 43/200] [Batch 181/637] [D loss: 0.151591] [G loss: 0.527396]\n",
      "[Epoch 43/200] [Batch 182/637] [D loss: 0.147428] [G loss: 0.549006]\n",
      "[Epoch 43/200] [Batch 183/637] [D loss: 0.178508] [G loss: 0.436711]\n",
      "[Epoch 43/200] [Batch 184/637] [D loss: 0.156078] [G loss: 0.543215]\n",
      "[Epoch 43/200] [Batch 185/637] [D loss: 0.187302] [G loss: 0.634346]\n",
      "[Epoch 43/200] [Batch 186/637] [D loss: 0.155835] [G loss: 0.588361]\n",
      "[Epoch 43/200] [Batch 187/637] [D loss: 0.162126] [G loss: 0.472466]\n",
      "[Epoch 43/200] [Batch 188/637] [D loss: 0.155391] [G loss: 0.441130]\n",
      "[Epoch 43/200] [Batch 189/637] [D loss: 0.170669] [G loss: 0.500024]\n",
      "[Epoch 43/200] [Batch 190/637] [D loss: 0.167078] [G loss: 0.515392]\n",
      "[Epoch 43/200] [Batch 191/637] [D loss: 0.170984] [G loss: 0.479334]\n",
      "[Epoch 43/200] [Batch 192/637] [D loss: 0.154280] [G loss: 0.511728]\n",
      "[Epoch 43/200] [Batch 193/637] [D loss: 0.166571] [G loss: 0.449601]\n",
      "[Epoch 43/200] [Batch 194/637] [D loss: 0.161526] [G loss: 0.511970]\n",
      "[Epoch 43/200] [Batch 195/637] [D loss: 0.157164] [G loss: 0.501548]\n",
      "[Epoch 43/200] [Batch 196/637] [D loss: 0.175526] [G loss: 0.431929]\n",
      "[Epoch 43/200] [Batch 197/637] [D loss: 0.169832] [G loss: 0.483842]\n",
      "[Epoch 43/200] [Batch 198/637] [D loss: 0.247665] [G loss: 0.426316]\n",
      "[Epoch 43/200] [Batch 199/637] [D loss: 0.242737] [G loss: 0.678896]\n",
      "[Epoch 43/200] [Batch 200/637] [D loss: 0.180516] [G loss: 0.517165]\n",
      "[Epoch 43/200] [Batch 201/637] [D loss: 0.170315] [G loss: 0.411502]\n",
      "[Epoch 43/200] [Batch 202/637] [D loss: 0.195539] [G loss: 0.381146]\n",
      "[Epoch 43/200] [Batch 203/637] [D loss: 0.172562] [G loss: 0.493980]\n",
      "[Epoch 43/200] [Batch 204/637] [D loss: 0.157069] [G loss: 0.563300]\n",
      "[Epoch 43/200] [Batch 205/637] [D loss: 0.166829] [G loss: 0.527777]\n",
      "[Epoch 43/200] [Batch 206/637] [D loss: 0.165088] [G loss: 0.483400]\n",
      "[Epoch 43/200] [Batch 207/637] [D loss: 0.176677] [G loss: 0.476393]\n",
      "[Epoch 43/200] [Batch 208/637] [D loss: 0.152116] [G loss: 0.545669]\n",
      "[Epoch 43/200] [Batch 209/637] [D loss: 0.149240] [G loss: 0.468215]\n",
      "[Epoch 43/200] [Batch 210/637] [D loss: 0.170068] [G loss: 0.537419]\n",
      "[Epoch 43/200] [Batch 211/637] [D loss: 0.154520] [G loss: 0.527979]\n",
      "[Epoch 43/200] [Batch 212/637] [D loss: 0.146647] [G loss: 0.499681]\n",
      "[Epoch 43/200] [Batch 213/637] [D loss: 0.160145] [G loss: 0.497535]\n",
      "[Epoch 43/200] [Batch 214/637] [D loss: 0.169197] [G loss: 0.524419]\n",
      "[Epoch 43/200] [Batch 215/637] [D loss: 0.151854] [G loss: 0.518914]\n",
      "[Epoch 43/200] [Batch 216/637] [D loss: 0.148270] [G loss: 0.523213]\n",
      "[Epoch 43/200] [Batch 217/637] [D loss: 0.180672] [G loss: 0.474641]\n",
      "[Epoch 43/200] [Batch 218/637] [D loss: 0.178186] [G loss: 0.492598]\n",
      "[Epoch 43/200] [Batch 219/637] [D loss: 0.146422] [G loss: 0.508070]\n",
      "[Epoch 43/200] [Batch 220/637] [D loss: 0.155586] [G loss: 0.472133]\n",
      "[Epoch 43/200] [Batch 221/637] [D loss: 0.172030] [G loss: 0.462218]\n",
      "[Epoch 43/200] [Batch 222/637] [D loss: 0.165452] [G loss: 0.484574]\n",
      "[Epoch 43/200] [Batch 223/637] [D loss: 0.166198] [G loss: 0.540686]\n",
      "[Epoch 43/200] [Batch 224/637] [D loss: 0.150859] [G loss: 0.513938]\n",
      "[Epoch 43/200] [Batch 225/637] [D loss: 0.165893] [G loss: 0.487696]\n",
      "[Epoch 43/200] [Batch 226/637] [D loss: 0.185440] [G loss: 0.560330]\n",
      "[Epoch 43/200] [Batch 227/637] [D loss: 0.171407] [G loss: 0.490950]\n",
      "[Epoch 43/200] [Batch 228/637] [D loss: 0.167285] [G loss: 0.422611]\n",
      "[Epoch 43/200] [Batch 229/637] [D loss: 0.168947] [G loss: 0.458231]\n",
      "[Epoch 43/200] [Batch 230/637] [D loss: 0.180142] [G loss: 0.517666]\n",
      "[Epoch 43/200] [Batch 231/637] [D loss: 0.165765] [G loss: 0.528120]\n",
      "[Epoch 43/200] [Batch 232/637] [D loss: 0.155968] [G loss: 0.530743]\n",
      "[Epoch 43/200] [Batch 233/637] [D loss: 0.140118] [G loss: 0.484656]\n",
      "[Epoch 43/200] [Batch 234/637] [D loss: 0.166638] [G loss: 0.423922]\n",
      "[Epoch 43/200] [Batch 235/637] [D loss: 0.143972] [G loss: 0.561604]\n",
      "[Epoch 43/200] [Batch 236/637] [D loss: 0.151238] [G loss: 0.569515]\n",
      "[Epoch 43/200] [Batch 237/637] [D loss: 0.158556] [G loss: 0.538480]\n",
      "[Epoch 43/200] [Batch 238/637] [D loss: 0.151682] [G loss: 0.541882]\n",
      "[Epoch 43/200] [Batch 239/637] [D loss: 0.157477] [G loss: 0.535238]\n",
      "[Epoch 43/200] [Batch 240/637] [D loss: 0.185397] [G loss: 0.488378]\n",
      "[Epoch 43/200] [Batch 241/637] [D loss: 0.208373] [G loss: 0.445296]\n",
      "[Epoch 43/200] [Batch 242/637] [D loss: 0.173546] [G loss: 0.592745]\n",
      "[Epoch 43/200] [Batch 243/637] [D loss: 0.178600] [G loss: 0.510135]\n",
      "[Epoch 43/200] [Batch 244/637] [D loss: 0.161705] [G loss: 0.489319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/200] [Batch 245/637] [D loss: 0.162648] [G loss: 0.489191]\n",
      "[Epoch 43/200] [Batch 246/637] [D loss: 0.194251] [G loss: 0.459137]\n",
      "[Epoch 43/200] [Batch 247/637] [D loss: 0.169609] [G loss: 0.539270]\n",
      "[Epoch 43/200] [Batch 248/637] [D loss: 0.181551] [G loss: 0.541851]\n",
      "[Epoch 43/200] [Batch 249/637] [D loss: 0.154302] [G loss: 0.523263]\n",
      "[Epoch 43/200] [Batch 250/637] [D loss: 0.156147] [G loss: 0.542626]\n",
      "[Epoch 43/200] [Batch 251/637] [D loss: 0.175779] [G loss: 0.526540]\n",
      "[Epoch 43/200] [Batch 252/637] [D loss: 0.142635] [G loss: 0.596028]\n",
      "[Epoch 43/200] [Batch 253/637] [D loss: 0.169933] [G loss: 0.468689]\n",
      "[Epoch 43/200] [Batch 254/637] [D loss: 0.141376] [G loss: 0.529483]\n",
      "[Epoch 43/200] [Batch 255/637] [D loss: 0.146341] [G loss: 0.532543]\n",
      "[Epoch 43/200] [Batch 256/637] [D loss: 0.149429] [G loss: 0.572037]\n",
      "[Epoch 43/200] [Batch 257/637] [D loss: 0.176827] [G loss: 0.477878]\n",
      "[Epoch 43/200] [Batch 258/637] [D loss: 0.173488] [G loss: 0.514347]\n",
      "[Epoch 43/200] [Batch 259/637] [D loss: 0.153930] [G loss: 0.558801]\n",
      "[Epoch 43/200] [Batch 260/637] [D loss: 0.141962] [G loss: 0.495796]\n",
      "[Epoch 43/200] [Batch 261/637] [D loss: 0.174289] [G loss: 0.462267]\n",
      "[Epoch 43/200] [Batch 262/637] [D loss: 0.159855] [G loss: 0.436375]\n",
      "[Epoch 43/200] [Batch 263/637] [D loss: 0.169118] [G loss: 0.470544]\n",
      "[Epoch 43/200] [Batch 264/637] [D loss: 0.177609] [G loss: 0.488128]\n",
      "[Epoch 43/200] [Batch 265/637] [D loss: 0.170994] [G loss: 0.495845]\n",
      "[Epoch 43/200] [Batch 266/637] [D loss: 0.169918] [G loss: 0.482578]\n",
      "[Epoch 43/200] [Batch 267/637] [D loss: 0.165993] [G loss: 0.489686]\n",
      "[Epoch 43/200] [Batch 268/637] [D loss: 0.173894] [G loss: 0.449054]\n",
      "[Epoch 43/200] [Batch 269/637] [D loss: 0.160877] [G loss: 0.442003]\n",
      "[Epoch 43/200] [Batch 270/637] [D loss: 0.177490] [G loss: 0.516250]\n",
      "[Epoch 43/200] [Batch 271/637] [D loss: 0.190475] [G loss: 0.438323]\n",
      "[Epoch 43/200] [Batch 272/637] [D loss: 0.169415] [G loss: 0.462780]\n",
      "[Epoch 43/200] [Batch 273/637] [D loss: 0.183545] [G loss: 0.518269]\n",
      "[Epoch 43/200] [Batch 274/637] [D loss: 0.166531] [G loss: 0.477987]\n",
      "[Epoch 43/200] [Batch 275/637] [D loss: 0.189296] [G loss: 0.449379]\n",
      "[Epoch 43/200] [Batch 276/637] [D loss: 0.170738] [G loss: 0.422511]\n",
      "[Epoch 43/200] [Batch 277/637] [D loss: 0.170695] [G loss: 0.459237]\n",
      "[Epoch 43/200] [Batch 278/637] [D loss: 0.184141] [G loss: 0.412029]\n",
      "[Epoch 43/200] [Batch 279/637] [D loss: 0.142354] [G loss: 0.511590]\n",
      "[Epoch 43/200] [Batch 280/637] [D loss: 0.143724] [G loss: 0.527276]\n",
      "[Epoch 43/200] [Batch 281/637] [D loss: 0.134629] [G loss: 0.531712]\n",
      "[Epoch 43/200] [Batch 282/637] [D loss: 0.146436] [G loss: 0.497654]\n",
      "[Epoch 43/200] [Batch 283/637] [D loss: 0.166801] [G loss: 0.572757]\n",
      "[Epoch 43/200] [Batch 284/637] [D loss: 0.191308] [G loss: 0.510728]\n",
      "[Epoch 43/200] [Batch 285/637] [D loss: 0.166429] [G loss: 0.506918]\n",
      "[Epoch 43/200] [Batch 286/637] [D loss: 0.154938] [G loss: 0.486127]\n",
      "[Epoch 43/200] [Batch 287/637] [D loss: 0.177427] [G loss: 0.569525]\n",
      "[Epoch 43/200] [Batch 288/637] [D loss: 0.185388] [G loss: 0.449701]\n",
      "[Epoch 43/200] [Batch 289/637] [D loss: 0.143742] [G loss: 0.566586]\n",
      "[Epoch 43/200] [Batch 290/637] [D loss: 0.139703] [G loss: 0.525192]\n",
      "[Epoch 43/200] [Batch 291/637] [D loss: 0.171777] [G loss: 0.494919]\n",
      "[Epoch 43/200] [Batch 292/637] [D loss: 0.172512] [G loss: 0.547194]\n",
      "[Epoch 43/200] [Batch 293/637] [D loss: 0.177106] [G loss: 0.586362]\n",
      "[Epoch 43/200] [Batch 294/637] [D loss: 0.178093] [G loss: 0.493424]\n",
      "[Epoch 43/200] [Batch 295/637] [D loss: 0.183935] [G loss: 0.502969]\n",
      "[Epoch 43/200] [Batch 296/637] [D loss: 0.149288] [G loss: 0.542203]\n",
      "[Epoch 43/200] [Batch 297/637] [D loss: 0.164415] [G loss: 0.479127]\n",
      "[Epoch 43/200] [Batch 298/637] [D loss: 0.173824] [G loss: 0.453923]\n",
      "[Epoch 43/200] [Batch 299/637] [D loss: 0.171535] [G loss: 0.581836]\n",
      "[Epoch 43/200] [Batch 300/637] [D loss: 0.164293] [G loss: 0.600986]\n",
      "[Epoch 43/200] [Batch 301/637] [D loss: 0.166735] [G loss: 0.543722]\n",
      "[Epoch 43/200] [Batch 302/637] [D loss: 0.173419] [G loss: 0.480062]\n",
      "[Epoch 43/200] [Batch 303/637] [D loss: 0.159047] [G loss: 0.500294]\n",
      "[Epoch 43/200] [Batch 304/637] [D loss: 0.143941] [G loss: 0.589585]\n",
      "[Epoch 43/200] [Batch 305/637] [D loss: 0.160457] [G loss: 0.516994]\n",
      "[Epoch 43/200] [Batch 306/637] [D loss: 0.137580] [G loss: 0.554587]\n",
      "[Epoch 43/200] [Batch 307/637] [D loss: 0.175468] [G loss: 0.537355]\n",
      "[Epoch 43/200] [Batch 308/637] [D loss: 0.168678] [G loss: 0.559544]\n",
      "[Epoch 43/200] [Batch 309/637] [D loss: 0.161559] [G loss: 0.504856]\n",
      "[Epoch 43/200] [Batch 310/637] [D loss: 0.155507] [G loss: 0.510337]\n",
      "[Epoch 43/200] [Batch 311/637] [D loss: 0.147620] [G loss: 0.517800]\n",
      "[Epoch 43/200] [Batch 312/637] [D loss: 0.138787] [G loss: 0.594033]\n",
      "[Epoch 43/200] [Batch 313/637] [D loss: 0.159451] [G loss: 0.477491]\n",
      "[Epoch 43/200] [Batch 314/637] [D loss: 0.169133] [G loss: 0.503649]\n",
      "[Epoch 43/200] [Batch 315/637] [D loss: 0.191230] [G loss: 0.579632]\n",
      "[Epoch 43/200] [Batch 316/637] [D loss: 0.176072] [G loss: 0.569534]\n",
      "[Epoch 43/200] [Batch 317/637] [D loss: 0.184490] [G loss: 0.509173]\n",
      "[Epoch 43/200] [Batch 318/637] [D loss: 0.153030] [G loss: 0.474075]\n",
      "[Epoch 43/200] [Batch 319/637] [D loss: 0.158992] [G loss: 0.420899]\n",
      "[Epoch 43/200] [Batch 320/637] [D loss: 0.174615] [G loss: 0.493776]\n",
      "[Epoch 43/200] [Batch 321/637] [D loss: 0.177137] [G loss: 0.487082]\n",
      "[Epoch 43/200] [Batch 322/637] [D loss: 0.169383] [G loss: 0.534870]\n",
      "[Epoch 43/200] [Batch 323/637] [D loss: 0.154666] [G loss: 0.565272]\n",
      "[Epoch 43/200] [Batch 324/637] [D loss: 0.151371] [G loss: 0.478772]\n",
      "[Epoch 43/200] [Batch 325/637] [D loss: 0.176533] [G loss: 0.488101]\n",
      "[Epoch 43/200] [Batch 326/637] [D loss: 0.157254] [G loss: 0.440653]\n",
      "[Epoch 43/200] [Batch 327/637] [D loss: 0.176873] [G loss: 0.440554]\n",
      "[Epoch 43/200] [Batch 328/637] [D loss: 0.165279] [G loss: 0.510292]\n",
      "[Epoch 43/200] [Batch 329/637] [D loss: 0.185290] [G loss: 0.543062]\n",
      "[Epoch 43/200] [Batch 330/637] [D loss: 0.170399] [G loss: 0.469826]\n",
      "[Epoch 43/200] [Batch 331/637] [D loss: 0.158330] [G loss: 0.440725]\n",
      "[Epoch 43/200] [Batch 332/637] [D loss: 0.167636] [G loss: 0.447810]\n",
      "[Epoch 43/200] [Batch 333/637] [D loss: 0.189086] [G loss: 0.395900]\n",
      "[Epoch 43/200] [Batch 334/637] [D loss: 0.175202] [G loss: 0.527048]\n",
      "[Epoch 43/200] [Batch 335/637] [D loss: 0.209559] [G loss: 0.441061]\n",
      "[Epoch 43/200] [Batch 336/637] [D loss: 0.157313] [G loss: 0.528196]\n",
      "[Epoch 43/200] [Batch 337/637] [D loss: 0.180632] [G loss: 0.449372]\n",
      "[Epoch 43/200] [Batch 338/637] [D loss: 0.179143] [G loss: 0.420460]\n",
      "[Epoch 43/200] [Batch 339/637] [D loss: 0.172153] [G loss: 0.490592]\n",
      "[Epoch 43/200] [Batch 340/637] [D loss: 0.170985] [G loss: 0.505579]\n",
      "[Epoch 43/200] [Batch 341/637] [D loss: 0.174198] [G loss: 0.416749]\n",
      "[Epoch 43/200] [Batch 342/637] [D loss: 0.182961] [G loss: 0.420913]\n",
      "[Epoch 43/200] [Batch 343/637] [D loss: 0.174221] [G loss: 0.577529]\n",
      "[Epoch 43/200] [Batch 344/637] [D loss: 0.176377] [G loss: 0.482107]\n",
      "[Epoch 43/200] [Batch 345/637] [D loss: 0.167657] [G loss: 0.463270]\n",
      "[Epoch 43/200] [Batch 346/637] [D loss: 0.165901] [G loss: 0.556656]\n",
      "[Epoch 43/200] [Batch 347/637] [D loss: 0.167664] [G loss: 0.542935]\n",
      "[Epoch 43/200] [Batch 348/637] [D loss: 0.187555] [G loss: 0.513900]\n",
      "[Epoch 43/200] [Batch 349/637] [D loss: 0.189663] [G loss: 0.495467]\n",
      "[Epoch 43/200] [Batch 350/637] [D loss: 0.168956] [G loss: 0.496083]\n",
      "[Epoch 43/200] [Batch 351/637] [D loss: 0.167128] [G loss: 0.442256]\n",
      "[Epoch 43/200] [Batch 352/637] [D loss: 0.173362] [G loss: 0.464281]\n",
      "[Epoch 43/200] [Batch 353/637] [D loss: 0.164212] [G loss: 0.494845]\n",
      "[Epoch 43/200] [Batch 354/637] [D loss: 0.159702] [G loss: 0.487539]\n",
      "[Epoch 43/200] [Batch 355/637] [D loss: 0.173326] [G loss: 0.430997]\n",
      "[Epoch 43/200] [Batch 356/637] [D loss: 0.185331] [G loss: 0.475217]\n",
      "[Epoch 43/200] [Batch 357/637] [D loss: 0.148234] [G loss: 0.473804]\n",
      "[Epoch 43/200] [Batch 358/637] [D loss: 0.162385] [G loss: 0.509252]\n",
      "[Epoch 43/200] [Batch 359/637] [D loss: 0.173431] [G loss: 0.472005]\n",
      "[Epoch 43/200] [Batch 360/637] [D loss: 0.163300] [G loss: 0.555707]\n",
      "[Epoch 43/200] [Batch 361/637] [D loss: 0.174557] [G loss: 0.478842]\n",
      "[Epoch 43/200] [Batch 362/637] [D loss: 0.178762] [G loss: 0.457804]\n",
      "[Epoch 43/200] [Batch 363/637] [D loss: 0.162958] [G loss: 0.459756]\n",
      "[Epoch 43/200] [Batch 364/637] [D loss: 0.149971] [G loss: 0.502801]\n",
      "[Epoch 43/200] [Batch 365/637] [D loss: 0.143119] [G loss: 0.543570]\n",
      "[Epoch 43/200] [Batch 366/637] [D loss: 0.153760] [G loss: 0.527448]\n",
      "[Epoch 43/200] [Batch 367/637] [D loss: 0.178791] [G loss: 0.461500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/200] [Batch 368/637] [D loss: 0.152850] [G loss: 0.536557]\n",
      "[Epoch 43/200] [Batch 369/637] [D loss: 0.165643] [G loss: 0.531303]\n",
      "[Epoch 43/200] [Batch 370/637] [D loss: 0.168486] [G loss: 0.565436]\n",
      "[Epoch 43/200] [Batch 371/637] [D loss: 0.167432] [G loss: 0.509333]\n",
      "[Epoch 43/200] [Batch 372/637] [D loss: 0.178241] [G loss: 0.456151]\n",
      "[Epoch 43/200] [Batch 373/637] [D loss: 0.165725] [G loss: 0.585499]\n",
      "[Epoch 43/200] [Batch 374/637] [D loss: 0.182539] [G loss: 0.478564]\n",
      "[Epoch 43/200] [Batch 375/637] [D loss: 0.165439] [G loss: 0.503097]\n",
      "[Epoch 43/200] [Batch 376/637] [D loss: 0.209385] [G loss: 0.405572]\n",
      "[Epoch 43/200] [Batch 377/637] [D loss: 0.171014] [G loss: 0.583499]\n",
      "[Epoch 43/200] [Batch 378/637] [D loss: 0.179379] [G loss: 0.546989]\n",
      "[Epoch 43/200] [Batch 379/637] [D loss: 0.168781] [G loss: 0.539475]\n",
      "[Epoch 43/200] [Batch 380/637] [D loss: 0.157238] [G loss: 0.476909]\n",
      "[Epoch 43/200] [Batch 381/637] [D loss: 0.206594] [G loss: 0.540477]\n",
      "[Epoch 43/200] [Batch 382/637] [D loss: 0.163345] [G loss: 0.581625]\n",
      "[Epoch 43/200] [Batch 383/637] [D loss: 0.169840] [G loss: 0.563332]\n",
      "[Epoch 43/200] [Batch 384/637] [D loss: 0.195563] [G loss: 0.488771]\n",
      "[Epoch 43/200] [Batch 385/637] [D loss: 0.163918] [G loss: 0.516208]\n",
      "[Epoch 43/200] [Batch 386/637] [D loss: 0.167868] [G loss: 0.478879]\n",
      "[Epoch 43/200] [Batch 387/637] [D loss: 0.158797] [G loss: 0.463770]\n",
      "[Epoch 43/200] [Batch 388/637] [D loss: 0.170459] [G loss: 0.397884]\n",
      "[Epoch 43/200] [Batch 389/637] [D loss: 0.174274] [G loss: 0.488748]\n",
      "[Epoch 43/200] [Batch 390/637] [D loss: 0.175037] [G loss: 0.500836]\n",
      "[Epoch 43/200] [Batch 391/637] [D loss: 0.165333] [G loss: 0.541374]\n",
      "[Epoch 43/200] [Batch 392/637] [D loss: 0.160080] [G loss: 0.450510]\n",
      "[Epoch 43/200] [Batch 393/637] [D loss: 0.161664] [G loss: 0.460767]\n",
      "[Epoch 43/200] [Batch 394/637] [D loss: 0.183822] [G loss: 0.550037]\n",
      "[Epoch 43/200] [Batch 395/637] [D loss: 0.158264] [G loss: 0.568684]\n",
      "[Epoch 43/200] [Batch 396/637] [D loss: 0.156761] [G loss: 0.508129]\n",
      "[Epoch 43/200] [Batch 397/637] [D loss: 0.160539] [G loss: 0.541392]\n",
      "[Epoch 43/200] [Batch 398/637] [D loss: 0.151111] [G loss: 0.506463]\n",
      "[Epoch 43/200] [Batch 399/637] [D loss: 0.157856] [G loss: 0.473188]\n",
      "[Epoch 43/200] [Batch 400/637] [D loss: 0.218091] [G loss: 0.416835]\n",
      "[Epoch 43/200] [Batch 401/637] [D loss: 0.185142] [G loss: 0.585637]\n",
      "[Epoch 43/200] [Batch 402/637] [D loss: 0.169832] [G loss: 0.550926]\n",
      "[Epoch 43/200] [Batch 403/637] [D loss: 0.171200] [G loss: 0.520385]\n",
      "[Epoch 43/200] [Batch 404/637] [D loss: 0.181836] [G loss: 0.484090]\n",
      "[Epoch 43/200] [Batch 405/637] [D loss: 0.164534] [G loss: 0.407016]\n",
      "[Epoch 43/200] [Batch 406/637] [D loss: 0.168797] [G loss: 0.465773]\n",
      "[Epoch 43/200] [Batch 407/637] [D loss: 0.182303] [G loss: 0.490292]\n",
      "[Epoch 43/200] [Batch 408/637] [D loss: 0.173673] [G loss: 0.480947]\n",
      "[Epoch 43/200] [Batch 409/637] [D loss: 0.185758] [G loss: 0.473526]\n",
      "[Epoch 43/200] [Batch 410/637] [D loss: 0.198859] [G loss: 0.483864]\n",
      "[Epoch 43/200] [Batch 411/637] [D loss: 0.177304] [G loss: 0.472379]\n",
      "[Epoch 43/200] [Batch 412/637] [D loss: 0.164070] [G loss: 0.482266]\n",
      "[Epoch 43/200] [Batch 413/637] [D loss: 0.183540] [G loss: 0.452529]\n",
      "[Epoch 43/200] [Batch 414/637] [D loss: 0.170349] [G loss: 0.504736]\n",
      "[Epoch 43/200] [Batch 415/637] [D loss: 0.162213] [G loss: 0.575408]\n",
      "[Epoch 43/200] [Batch 416/637] [D loss: 0.187364] [G loss: 0.494304]\n",
      "[Epoch 43/200] [Batch 417/637] [D loss: 0.181708] [G loss: 0.509227]\n",
      "[Epoch 43/200] [Batch 418/637] [D loss: 0.162973] [G loss: 0.496504]\n",
      "[Epoch 43/200] [Batch 419/637] [D loss: 0.190303] [G loss: 0.451679]\n",
      "[Epoch 43/200] [Batch 420/637] [D loss: 0.151388] [G loss: 0.460569]\n",
      "[Epoch 43/200] [Batch 421/637] [D loss: 0.150408] [G loss: 0.446209]\n",
      "[Epoch 43/200] [Batch 422/637] [D loss: 0.193434] [G loss: 0.516437]\n",
      "[Epoch 43/200] [Batch 423/637] [D loss: 0.160237] [G loss: 0.516249]\n",
      "[Epoch 43/200] [Batch 424/637] [D loss: 0.180782] [G loss: 0.469050]\n",
      "[Epoch 43/200] [Batch 425/637] [D loss: 0.177565] [G loss: 0.509126]\n",
      "[Epoch 43/200] [Batch 426/637] [D loss: 0.172624] [G loss: 0.435885]\n",
      "[Epoch 43/200] [Batch 427/637] [D loss: 0.145281] [G loss: 0.507028]\n",
      "[Epoch 43/200] [Batch 428/637] [D loss: 0.172647] [G loss: 0.508341]\n",
      "[Epoch 43/200] [Batch 429/637] [D loss: 0.179250] [G loss: 0.545393]\n",
      "[Epoch 43/200] [Batch 430/637] [D loss: 0.162393] [G loss: 0.522994]\n",
      "[Epoch 43/200] [Batch 431/637] [D loss: 0.181646] [G loss: 0.462784]\n",
      "[Epoch 43/200] [Batch 432/637] [D loss: 0.173497] [G loss: 0.415680]\n",
      "[Epoch 43/200] [Batch 433/637] [D loss: 0.161771] [G loss: 0.457248]\n",
      "[Epoch 43/200] [Batch 434/637] [D loss: 0.162879] [G loss: 0.513607]\n",
      "[Epoch 43/200] [Batch 435/637] [D loss: 0.160012] [G loss: 0.526028]\n",
      "[Epoch 43/200] [Batch 436/637] [D loss: 0.183077] [G loss: 0.525007]\n",
      "[Epoch 43/200] [Batch 437/637] [D loss: 0.159982] [G loss: 0.492494]\n",
      "[Epoch 43/200] [Batch 438/637] [D loss: 0.156816] [G loss: 0.463449]\n",
      "[Epoch 43/200] [Batch 439/637] [D loss: 0.160591] [G loss: 0.518742]\n",
      "[Epoch 43/200] [Batch 440/637] [D loss: 0.161029] [G loss: 0.482946]\n",
      "[Epoch 43/200] [Batch 441/637] [D loss: 0.177139] [G loss: 0.453880]\n",
      "[Epoch 43/200] [Batch 442/637] [D loss: 0.180055] [G loss: 0.511286]\n",
      "[Epoch 43/200] [Batch 443/637] [D loss: 0.164082] [G loss: 0.530517]\n",
      "[Epoch 43/200] [Batch 444/637] [D loss: 0.161284] [G loss: 0.486894]\n",
      "[Epoch 43/200] [Batch 445/637] [D loss: 0.204874] [G loss: 0.439114]\n",
      "[Epoch 43/200] [Batch 446/637] [D loss: 0.150806] [G loss: 0.543322]\n",
      "[Epoch 43/200] [Batch 447/637] [D loss: 0.183733] [G loss: 0.500211]\n",
      "[Epoch 43/200] [Batch 448/637] [D loss: 0.172213] [G loss: 0.463806]\n",
      "[Epoch 43/200] [Batch 449/637] [D loss: 0.218782] [G loss: 0.505437]\n",
      "[Epoch 43/200] [Batch 450/637] [D loss: 0.160936] [G loss: 0.443294]\n",
      "[Epoch 43/200] [Batch 451/637] [D loss: 0.173444] [G loss: 0.482994]\n",
      "[Epoch 43/200] [Batch 452/637] [D loss: 0.161905] [G loss: 0.510489]\n",
      "[Epoch 43/200] [Batch 453/637] [D loss: 0.198695] [G loss: 0.546504]\n",
      "[Epoch 43/200] [Batch 454/637] [D loss: 0.190983] [G loss: 0.512883]\n",
      "[Epoch 43/200] [Batch 455/637] [D loss: 0.190515] [G loss: 0.458038]\n",
      "[Epoch 43/200] [Batch 456/637] [D loss: 0.161043] [G loss: 0.557438]\n",
      "[Epoch 43/200] [Batch 457/637] [D loss: 0.169692] [G loss: 0.450581]\n",
      "[Epoch 43/200] [Batch 458/637] [D loss: 0.163196] [G loss: 0.403707]\n",
      "[Epoch 43/200] [Batch 459/637] [D loss: 0.152945] [G loss: 0.504535]\n",
      "[Epoch 43/200] [Batch 460/637] [D loss: 0.166059] [G loss: 0.529500]\n",
      "[Epoch 43/200] [Batch 461/637] [D loss: 0.160723] [G loss: 0.466181]\n",
      "[Epoch 43/200] [Batch 462/637] [D loss: 0.174936] [G loss: 0.479307]\n",
      "[Epoch 43/200] [Batch 463/637] [D loss: 0.157874] [G loss: 0.543079]\n",
      "[Epoch 43/200] [Batch 464/637] [D loss: 0.157397] [G loss: 0.523349]\n",
      "[Epoch 43/200] [Batch 465/637] [D loss: 0.172973] [G loss: 0.561152]\n",
      "[Epoch 43/200] [Batch 466/637] [D loss: 0.161433] [G loss: 0.499347]\n",
      "[Epoch 43/200] [Batch 467/637] [D loss: 0.182538] [G loss: 0.414757]\n",
      "[Epoch 43/200] [Batch 468/637] [D loss: 0.182179] [G loss: 0.446915]\n",
      "[Epoch 43/200] [Batch 469/637] [D loss: 0.165540] [G loss: 0.483456]\n",
      "[Epoch 43/200] [Batch 470/637] [D loss: 0.183164] [G loss: 0.456661]\n",
      "[Epoch 43/200] [Batch 471/637] [D loss: 0.162409] [G loss: 0.510309]\n",
      "[Epoch 43/200] [Batch 472/637] [D loss: 0.156431] [G loss: 0.488551]\n",
      "[Epoch 43/200] [Batch 473/637] [D loss: 0.159543] [G loss: 0.458092]\n",
      "[Epoch 43/200] [Batch 474/637] [D loss: 0.162221] [G loss: 0.476212]\n",
      "[Epoch 43/200] [Batch 475/637] [D loss: 0.147930] [G loss: 0.590594]\n",
      "[Epoch 43/200] [Batch 476/637] [D loss: 0.149118] [G loss: 0.494206]\n",
      "[Epoch 43/200] [Batch 477/637] [D loss: 0.157132] [G loss: 0.434587]\n",
      "[Epoch 43/200] [Batch 478/637] [D loss: 0.162830] [G loss: 0.519998]\n",
      "[Epoch 43/200] [Batch 479/637] [D loss: 0.153512] [G loss: 0.598366]\n",
      "[Epoch 43/200] [Batch 480/637] [D loss: 0.192937] [G loss: 0.464750]\n",
      "[Epoch 43/200] [Batch 481/637] [D loss: 0.163662] [G loss: 0.489295]\n",
      "[Epoch 43/200] [Batch 482/637] [D loss: 0.184781] [G loss: 0.468465]\n",
      "[Epoch 43/200] [Batch 483/637] [D loss: 0.161071] [G loss: 0.451367]\n",
      "[Epoch 43/200] [Batch 484/637] [D loss: 0.170379] [G loss: 0.477050]\n",
      "[Epoch 43/200] [Batch 485/637] [D loss: 0.167609] [G loss: 0.537385]\n",
      "[Epoch 43/200] [Batch 486/637] [D loss: 0.149559] [G loss: 0.570336]\n",
      "[Epoch 43/200] [Batch 487/637] [D loss: 0.196947] [G loss: 0.462779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/200] [Batch 488/637] [D loss: 0.181702] [G loss: 0.484738]\n",
      "[Epoch 43/200] [Batch 489/637] [D loss: 0.156298] [G loss: 0.495140]\n",
      "[Epoch 43/200] [Batch 490/637] [D loss: 0.167757] [G loss: 0.511922]\n",
      "[Epoch 43/200] [Batch 491/637] [D loss: 0.158569] [G loss: 0.499866]\n",
      "[Epoch 43/200] [Batch 492/637] [D loss: 0.157719] [G loss: 0.466621]\n",
      "[Epoch 43/200] [Batch 493/637] [D loss: 0.171866] [G loss: 0.473041]\n",
      "[Epoch 43/200] [Batch 494/637] [D loss: 0.170012] [G loss: 0.504388]\n",
      "[Epoch 43/200] [Batch 495/637] [D loss: 0.153413] [G loss: 0.496195]\n",
      "[Epoch 43/200] [Batch 496/637] [D loss: 0.157181] [G loss: 0.556064]\n",
      "[Epoch 43/200] [Batch 497/637] [D loss: 0.161343] [G loss: 0.475256]\n",
      "[Epoch 43/200] [Batch 498/637] [D loss: 0.165531] [G loss: 0.543736]\n",
      "[Epoch 43/200] [Batch 499/637] [D loss: 0.175010] [G loss: 0.512224]\n",
      "[Epoch 43/200] [Batch 500/637] [D loss: 0.185493] [G loss: 0.450991]\n",
      "[Epoch 43/200] [Batch 501/637] [D loss: 0.163259] [G loss: 0.556870]\n",
      "[Epoch 43/200] [Batch 502/637] [D loss: 0.166423] [G loss: 0.503868]\n",
      "[Epoch 43/200] [Batch 503/637] [D loss: 0.158781] [G loss: 0.522524]\n",
      "[Epoch 43/200] [Batch 504/637] [D loss: 0.160381] [G loss: 0.575314]\n",
      "[Epoch 43/200] [Batch 505/637] [D loss: 0.183112] [G loss: 0.493769]\n",
      "[Epoch 43/200] [Batch 506/637] [D loss: 0.170406] [G loss: 0.450615]\n",
      "[Epoch 43/200] [Batch 507/637] [D loss: 0.161804] [G loss: 0.516685]\n",
      "[Epoch 43/200] [Batch 508/637] [D loss: 0.175518] [G loss: 0.566877]\n",
      "[Epoch 43/200] [Batch 509/637] [D loss: 0.166170] [G loss: 0.547320]\n",
      "[Epoch 43/200] [Batch 510/637] [D loss: 0.179326] [G loss: 0.504494]\n",
      "[Epoch 43/200] [Batch 511/637] [D loss: 0.154992] [G loss: 0.493666]\n",
      "[Epoch 43/200] [Batch 512/637] [D loss: 0.149475] [G loss: 0.453837]\n",
      "[Epoch 43/200] [Batch 513/637] [D loss: 0.177605] [G loss: 0.495757]\n",
      "[Epoch 43/200] [Batch 514/637] [D loss: 0.159099] [G loss: 0.606112]\n",
      "[Epoch 43/200] [Batch 515/637] [D loss: 0.163158] [G loss: 0.508807]\n",
      "[Epoch 43/200] [Batch 516/637] [D loss: 0.164122] [G loss: 0.461129]\n",
      "[Epoch 43/200] [Batch 517/637] [D loss: 0.200756] [G loss: 0.585250]\n",
      "[Epoch 43/200] [Batch 518/637] [D loss: 0.189399] [G loss: 0.468638]\n",
      "[Epoch 43/200] [Batch 519/637] [D loss: 0.160797] [G loss: 0.450751]\n",
      "[Epoch 43/200] [Batch 520/637] [D loss: 0.177579] [G loss: 0.405930]\n",
      "[Epoch 43/200] [Batch 521/637] [D loss: 0.179402] [G loss: 0.552948]\n",
      "[Epoch 43/200] [Batch 522/637] [D loss: 0.181113] [G loss: 0.562579]\n",
      "[Epoch 43/200] [Batch 523/637] [D loss: 0.175904] [G loss: 0.477795]\n",
      "[Epoch 43/200] [Batch 524/637] [D loss: 0.162117] [G loss: 0.539975]\n",
      "[Epoch 43/200] [Batch 525/637] [D loss: 0.154279] [G loss: 0.523279]\n",
      "[Epoch 43/200] [Batch 526/637] [D loss: 0.184606] [G loss: 0.479823]\n",
      "[Epoch 43/200] [Batch 527/637] [D loss: 0.156816] [G loss: 0.497617]\n",
      "[Epoch 43/200] [Batch 528/637] [D loss: 0.161148] [G loss: 0.585462]\n",
      "[Epoch 43/200] [Batch 529/637] [D loss: 0.192619] [G loss: 0.514546]\n",
      "[Epoch 43/200] [Batch 530/637] [D loss: 0.164385] [G loss: 0.501892]\n",
      "[Epoch 43/200] [Batch 531/637] [D loss: 0.162717] [G loss: 0.463324]\n",
      "[Epoch 43/200] [Batch 532/637] [D loss: 0.159805] [G loss: 0.505052]\n",
      "[Epoch 43/200] [Batch 533/637] [D loss: 0.145237] [G loss: 0.468956]\n",
      "[Epoch 43/200] [Batch 534/637] [D loss: 0.149220] [G loss: 0.535244]\n",
      "[Epoch 43/200] [Batch 535/637] [D loss: 0.145198] [G loss: 0.572603]\n",
      "[Epoch 43/200] [Batch 536/637] [D loss: 0.172985] [G loss: 0.560229]\n",
      "[Epoch 43/200] [Batch 537/637] [D loss: 0.174460] [G loss: 0.524266]\n",
      "[Epoch 43/200] [Batch 538/637] [D loss: 0.172665] [G loss: 0.508071]\n",
      "[Epoch 43/200] [Batch 539/637] [D loss: 0.159070] [G loss: 0.551164]\n",
      "[Epoch 43/200] [Batch 540/637] [D loss: 0.168513] [G loss: 0.505845]\n",
      "[Epoch 43/200] [Batch 541/637] [D loss: 0.164542] [G loss: 0.466702]\n",
      "[Epoch 43/200] [Batch 542/637] [D loss: 0.167080] [G loss: 0.574634]\n",
      "[Epoch 43/200] [Batch 543/637] [D loss: 0.173726] [G loss: 0.486768]\n",
      "[Epoch 43/200] [Batch 544/637] [D loss: 0.171096] [G loss: 0.531511]\n",
      "[Epoch 43/200] [Batch 545/637] [D loss: 0.169525] [G loss: 0.568277]\n",
      "[Epoch 43/200] [Batch 546/637] [D loss: 0.185368] [G loss: 0.460531]\n",
      "[Epoch 43/200] [Batch 547/637] [D loss: 0.164338] [G loss: 0.545986]\n",
      "[Epoch 43/200] [Batch 548/637] [D loss: 0.177508] [G loss: 0.477961]\n",
      "[Epoch 43/200] [Batch 549/637] [D loss: 0.177931] [G loss: 0.453401]\n",
      "[Epoch 43/200] [Batch 550/637] [D loss: 0.173776] [G loss: 0.444437]\n",
      "[Epoch 43/200] [Batch 551/637] [D loss: 0.196953] [G loss: 0.494248]\n",
      "[Epoch 43/200] [Batch 552/637] [D loss: 0.173979] [G loss: 0.625371]\n",
      "[Epoch 43/200] [Batch 553/637] [D loss: 0.179928] [G loss: 0.603221]\n",
      "[Epoch 43/200] [Batch 554/637] [D loss: 0.171548] [G loss: 0.532296]\n",
      "[Epoch 43/200] [Batch 555/637] [D loss: 0.162820] [G loss: 0.455980]\n",
      "[Epoch 43/200] [Batch 556/637] [D loss: 0.175139] [G loss: 0.483070]\n",
      "[Epoch 43/200] [Batch 557/637] [D loss: 0.175114] [G loss: 0.493056]\n",
      "[Epoch 43/200] [Batch 558/637] [D loss: 0.162332] [G loss: 0.506682]\n",
      "[Epoch 43/200] [Batch 559/637] [D loss: 0.187406] [G loss: 0.453448]\n",
      "[Epoch 43/200] [Batch 560/637] [D loss: 0.171052] [G loss: 0.505328]\n",
      "[Epoch 43/200] [Batch 561/637] [D loss: 0.170420] [G loss: 0.456867]\n",
      "[Epoch 43/200] [Batch 562/637] [D loss: 0.150421] [G loss: 0.497429]\n",
      "[Epoch 43/200] [Batch 563/637] [D loss: 0.136392] [G loss: 0.530489]\n",
      "[Epoch 43/200] [Batch 564/637] [D loss: 0.159759] [G loss: 0.582839]\n",
      "[Epoch 43/200] [Batch 565/637] [D loss: 0.148510] [G loss: 0.539697]\n",
      "[Epoch 43/200] [Batch 566/637] [D loss: 0.145801] [G loss: 0.448427]\n",
      "[Epoch 43/200] [Batch 567/637] [D loss: 0.165932] [G loss: 0.468665]\n",
      "[Epoch 43/200] [Batch 568/637] [D loss: 0.157204] [G loss: 0.555464]\n",
      "[Epoch 43/200] [Batch 569/637] [D loss: 0.177848] [G loss: 0.538871]\n",
      "[Epoch 43/200] [Batch 570/637] [D loss: 0.196915] [G loss: 0.548471]\n",
      "[Epoch 43/200] [Batch 571/637] [D loss: 0.176640] [G loss: 0.497230]\n",
      "[Epoch 43/200] [Batch 572/637] [D loss: 0.189547] [G loss: 0.421024]\n",
      "[Epoch 43/200] [Batch 573/637] [D loss: 0.152542] [G loss: 0.497263]\n",
      "[Epoch 43/200] [Batch 574/637] [D loss: 0.170255] [G loss: 0.507374]\n",
      "[Epoch 43/200] [Batch 575/637] [D loss: 0.144706] [G loss: 0.500569]\n",
      "[Epoch 43/200] [Batch 576/637] [D loss: 0.171852] [G loss: 0.471009]\n",
      "[Epoch 43/200] [Batch 577/637] [D loss: 0.164093] [G loss: 0.534827]\n",
      "[Epoch 43/200] [Batch 578/637] [D loss: 0.164902] [G loss: 0.576964]\n",
      "[Epoch 43/200] [Batch 579/637] [D loss: 0.188111] [G loss: 0.484986]\n",
      "[Epoch 43/200] [Batch 580/637] [D loss: 0.186656] [G loss: 0.518746]\n",
      "[Epoch 43/200] [Batch 581/637] [D loss: 0.198232] [G loss: 0.607548]\n",
      "[Epoch 43/200] [Batch 582/637] [D loss: 0.158248] [G loss: 0.508820]\n",
      "[Epoch 43/200] [Batch 583/637] [D loss: 0.198665] [G loss: 0.451764]\n",
      "[Epoch 43/200] [Batch 584/637] [D loss: 0.161871] [G loss: 0.608830]\n",
      "[Epoch 43/200] [Batch 585/637] [D loss: 0.195738] [G loss: 0.558224]\n",
      "[Epoch 43/200] [Batch 586/637] [D loss: 0.170131] [G loss: 0.483727]\n",
      "[Epoch 43/200] [Batch 587/637] [D loss: 0.182509] [G loss: 0.422522]\n",
      "[Epoch 43/200] [Batch 588/637] [D loss: 0.153124] [G loss: 0.481943]\n",
      "[Epoch 43/200] [Batch 589/637] [D loss: 0.176840] [G loss: 0.477745]\n",
      "[Epoch 43/200] [Batch 590/637] [D loss: 0.161828] [G loss: 0.522485]\n",
      "[Epoch 43/200] [Batch 591/637] [D loss: 0.152241] [G loss: 0.541292]\n",
      "[Epoch 43/200] [Batch 592/637] [D loss: 0.143082] [G loss: 0.475175]\n",
      "[Epoch 43/200] [Batch 593/637] [D loss: 0.153868] [G loss: 0.530442]\n",
      "[Epoch 43/200] [Batch 594/637] [D loss: 0.134509] [G loss: 0.544208]\n",
      "[Epoch 43/200] [Batch 595/637] [D loss: 0.153087] [G loss: 0.503197]\n",
      "[Epoch 43/200] [Batch 596/637] [D loss: 0.152757] [G loss: 0.484363]\n",
      "[Epoch 43/200] [Batch 597/637] [D loss: 0.142813] [G loss: 0.511145]\n",
      "[Epoch 43/200] [Batch 598/637] [D loss: 0.177496] [G loss: 0.507145]\n",
      "[Epoch 43/200] [Batch 599/637] [D loss: 0.144301] [G loss: 0.510696]\n",
      "[Epoch 43/200] [Batch 600/637] [D loss: 0.185338] [G loss: 0.417636]\n",
      "[Epoch 43/200] [Batch 601/637] [D loss: 0.155718] [G loss: 0.528894]\n",
      "[Epoch 43/200] [Batch 602/637] [D loss: 0.168856] [G loss: 0.454528]\n",
      "[Epoch 43/200] [Batch 603/637] [D loss: 0.181097] [G loss: 0.440274]\n",
      "[Epoch 43/200] [Batch 604/637] [D loss: 0.184270] [G loss: 0.423990]\n",
      "[Epoch 43/200] [Batch 605/637] [D loss: 0.149289] [G loss: 0.550582]\n",
      "[Epoch 43/200] [Batch 606/637] [D loss: 0.144173] [G loss: 0.561358]\n",
      "[Epoch 43/200] [Batch 607/637] [D loss: 0.152484] [G loss: 0.481584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/200] [Batch 608/637] [D loss: 0.157867] [G loss: 0.400566]\n",
      "[Epoch 43/200] [Batch 609/637] [D loss: 0.142836] [G loss: 0.496048]\n",
      "[Epoch 43/200] [Batch 610/637] [D loss: 0.174252] [G loss: 0.426867]\n",
      "[Epoch 43/200] [Batch 611/637] [D loss: 0.164550] [G loss: 0.598954]\n",
      "[Epoch 43/200] [Batch 612/637] [D loss: 0.174742] [G loss: 0.583692]\n",
      "[Epoch 43/200] [Batch 613/637] [D loss: 0.183490] [G loss: 0.428218]\n",
      "[Epoch 43/200] [Batch 614/637] [D loss: 0.174122] [G loss: 0.491440]\n",
      "[Epoch 43/200] [Batch 615/637] [D loss: 0.139000] [G loss: 0.502816]\n",
      "[Epoch 43/200] [Batch 616/637] [D loss: 0.151133] [G loss: 0.602516]\n",
      "[Epoch 43/200] [Batch 617/637] [D loss: 0.158388] [G loss: 0.502839]\n",
      "[Epoch 43/200] [Batch 618/637] [D loss: 0.149467] [G loss: 0.516670]\n",
      "[Epoch 43/200] [Batch 619/637] [D loss: 0.180268] [G loss: 0.448519]\n",
      "[Epoch 43/200] [Batch 620/637] [D loss: 0.170924] [G loss: 0.446463]\n",
      "[Epoch 43/200] [Batch 621/637] [D loss: 0.161242] [G loss: 0.525704]\n",
      "[Epoch 43/200] [Batch 622/637] [D loss: 0.155690] [G loss: 0.518558]\n",
      "[Epoch 43/200] [Batch 623/637] [D loss: 0.152443] [G loss: 0.576263]\n",
      "[Epoch 43/200] [Batch 624/637] [D loss: 0.166465] [G loss: 0.534534]\n",
      "[Epoch 43/200] [Batch 625/637] [D loss: 0.156845] [G loss: 0.475272]\n",
      "[Epoch 43/200] [Batch 626/637] [D loss: 0.206304] [G loss: 0.504689]\n",
      "[Epoch 43/200] [Batch 627/637] [D loss: 0.163693] [G loss: 0.521003]\n",
      "[Epoch 43/200] [Batch 628/637] [D loss: 0.172848] [G loss: 0.529074]\n",
      "[Epoch 43/200] [Batch 629/637] [D loss: 0.176081] [G loss: 0.481516]\n",
      "[Epoch 43/200] [Batch 630/637] [D loss: 0.175425] [G loss: 0.492920]\n",
      "[Epoch 43/200] [Batch 631/637] [D loss: 0.157902] [G loss: 0.524190]\n",
      "[Epoch 43/200] [Batch 632/637] [D loss: 0.174639] [G loss: 0.421565]\n",
      "[Epoch 43/200] [Batch 633/637] [D loss: 0.145824] [G loss: 0.531152]\n",
      "[Epoch 43/200] [Batch 634/637] [D loss: 0.176990] [G loss: 0.514933]\n",
      "[Epoch 43/200] [Batch 635/637] [D loss: 0.162629] [G loss: 0.524018]\n",
      "[Epoch 43/200] [Batch 636/637] [D loss: 0.151013] [G loss: 0.510999]\n",
      "[Epoch 44/200] [Batch 0/637] [D loss: 0.180223] [G loss: 0.495228]\n",
      "[Epoch 44/200] [Batch 1/637] [D loss: 0.178902] [G loss: 0.457302]\n",
      "[Epoch 44/200] [Batch 2/637] [D loss: 0.169124] [G loss: 0.492940]\n",
      "[Epoch 44/200] [Batch 3/637] [D loss: 0.177681] [G loss: 0.516795]\n",
      "[Epoch 44/200] [Batch 4/637] [D loss: 0.162785] [G loss: 0.476102]\n",
      "[Epoch 44/200] [Batch 5/637] [D loss: 0.164051] [G loss: 0.536698]\n",
      "[Epoch 44/200] [Batch 6/637] [D loss: 0.160078] [G loss: 0.544919]\n",
      "[Epoch 44/200] [Batch 7/637] [D loss: 0.158589] [G loss: 0.484821]\n",
      "[Epoch 44/200] [Batch 8/637] [D loss: 0.165394] [G loss: 0.463410]\n",
      "[Epoch 44/200] [Batch 9/637] [D loss: 0.176968] [G loss: 0.520092]\n",
      "[Epoch 44/200] [Batch 10/637] [D loss: 0.169151] [G loss: 0.478508]\n",
      "[Epoch 44/200] [Batch 11/637] [D loss: 0.174715] [G loss: 0.449398]\n",
      "[Epoch 44/200] [Batch 12/637] [D loss: 0.170972] [G loss: 0.480048]\n",
      "[Epoch 44/200] [Batch 13/637] [D loss: 0.160007] [G loss: 0.467650]\n",
      "[Epoch 44/200] [Batch 14/637] [D loss: 0.154760] [G loss: 0.496387]\n",
      "[Epoch 44/200] [Batch 15/637] [D loss: 0.180885] [G loss: 0.456359]\n",
      "[Epoch 44/200] [Batch 16/637] [D loss: 0.152322] [G loss: 0.469421]\n",
      "[Epoch 44/200] [Batch 17/637] [D loss: 0.191333] [G loss: 0.494328]\n",
      "[Epoch 44/200] [Batch 18/637] [D loss: 0.183310] [G loss: 0.556901]\n",
      "[Epoch 44/200] [Batch 19/637] [D loss: 0.173340] [G loss: 0.575403]\n",
      "[Epoch 44/200] [Batch 20/637] [D loss: 0.150069] [G loss: 0.544045]\n",
      "[Epoch 44/200] [Batch 21/637] [D loss: 0.177717] [G loss: 0.463581]\n",
      "[Epoch 44/200] [Batch 22/637] [D loss: 0.152600] [G loss: 0.503202]\n",
      "[Epoch 44/200] [Batch 23/637] [D loss: 0.169556] [G loss: 0.523579]\n",
      "[Epoch 44/200] [Batch 24/637] [D loss: 0.164301] [G loss: 0.473983]\n",
      "[Epoch 44/200] [Batch 25/637] [D loss: 0.147442] [G loss: 0.523607]\n",
      "[Epoch 44/200] [Batch 26/637] [D loss: 0.143843] [G loss: 0.514414]\n",
      "[Epoch 44/200] [Batch 27/637] [D loss: 0.166160] [G loss: 0.569840]\n",
      "[Epoch 44/200] [Batch 28/637] [D loss: 0.164962] [G loss: 0.632440]\n",
      "[Epoch 44/200] [Batch 29/637] [D loss: 0.192687] [G loss: 0.429366]\n",
      "[Epoch 44/200] [Batch 30/637] [D loss: 0.157839] [G loss: 0.509040]\n",
      "[Epoch 44/200] [Batch 31/637] [D loss: 0.180880] [G loss: 0.475424]\n",
      "[Epoch 44/200] [Batch 32/637] [D loss: 0.159599] [G loss: 0.514599]\n",
      "[Epoch 44/200] [Batch 33/637] [D loss: 0.179813] [G loss: 0.472487]\n",
      "[Epoch 44/200] [Batch 34/637] [D loss: 0.168600] [G loss: 0.557074]\n",
      "[Epoch 44/200] [Batch 35/637] [D loss: 0.162139] [G loss: 0.450129]\n",
      "[Epoch 44/200] [Batch 36/637] [D loss: 0.181410] [G loss: 0.481481]\n",
      "[Epoch 44/200] [Batch 37/637] [D loss: 0.164925] [G loss: 0.472035]\n",
      "[Epoch 44/200] [Batch 38/637] [D loss: 0.165816] [G loss: 0.468977]\n",
      "[Epoch 44/200] [Batch 39/637] [D loss: 0.160328] [G loss: 0.483643]\n",
      "[Epoch 44/200] [Batch 40/637] [D loss: 0.166676] [G loss: 0.486897]\n",
      "[Epoch 44/200] [Batch 41/637] [D loss: 0.178988] [G loss: 0.494856]\n",
      "[Epoch 44/200] [Batch 42/637] [D loss: 0.181186] [G loss: 0.510404]\n",
      "[Epoch 44/200] [Batch 43/637] [D loss: 0.176718] [G loss: 0.616325]\n",
      "[Epoch 44/200] [Batch 44/637] [D loss: 0.146560] [G loss: 0.524756]\n",
      "[Epoch 44/200] [Batch 45/637] [D loss: 0.169561] [G loss: 0.432276]\n",
      "[Epoch 44/200] [Batch 46/637] [D loss: 0.157209] [G loss: 0.457953]\n",
      "[Epoch 44/200] [Batch 47/637] [D loss: 0.153707] [G loss: 0.468903]\n",
      "[Epoch 44/200] [Batch 48/637] [D loss: 0.162741] [G loss: 0.562963]\n",
      "[Epoch 44/200] [Batch 49/637] [D loss: 0.159598] [G loss: 0.523446]\n",
      "[Epoch 44/200] [Batch 50/637] [D loss: 0.152128] [G loss: 0.550426]\n",
      "[Epoch 44/200] [Batch 51/637] [D loss: 0.150858] [G loss: 0.582865]\n",
      "[Epoch 44/200] [Batch 52/637] [D loss: 0.180486] [G loss: 0.475345]\n",
      "[Epoch 44/200] [Batch 53/637] [D loss: 0.166021] [G loss: 0.613370]\n",
      "[Epoch 44/200] [Batch 54/637] [D loss: 0.203353] [G loss: 0.463613]\n",
      "[Epoch 44/200] [Batch 55/637] [D loss: 0.145462] [G loss: 0.557859]\n",
      "[Epoch 44/200] [Batch 56/637] [D loss: 0.159587] [G loss: 0.469398]\n",
      "[Epoch 44/200] [Batch 57/637] [D loss: 0.144082] [G loss: 0.493381]\n",
      "[Epoch 44/200] [Batch 58/637] [D loss: 0.182488] [G loss: 0.426157]\n",
      "[Epoch 44/200] [Batch 59/637] [D loss: 0.188730] [G loss: 0.435848]\n",
      "[Epoch 44/200] [Batch 60/637] [D loss: 0.158412] [G loss: 0.609792]\n",
      "[Epoch 44/200] [Batch 61/637] [D loss: 0.171477] [G loss: 0.542510]\n",
      "[Epoch 44/200] [Batch 62/637] [D loss: 0.163043] [G loss: 0.545260]\n",
      "[Epoch 44/200] [Batch 63/637] [D loss: 0.175616] [G loss: 0.468255]\n",
      "[Epoch 44/200] [Batch 64/637] [D loss: 0.174747] [G loss: 0.471180]\n",
      "[Epoch 44/200] [Batch 65/637] [D loss: 0.162100] [G loss: 0.517415]\n",
      "[Epoch 44/200] [Batch 66/637] [D loss: 0.161441] [G loss: 0.602642]\n",
      "[Epoch 44/200] [Batch 67/637] [D loss: 0.193292] [G loss: 0.504968]\n",
      "[Epoch 44/200] [Batch 68/637] [D loss: 0.159020] [G loss: 0.596874]\n",
      "[Epoch 44/200] [Batch 69/637] [D loss: 0.194449] [G loss: 0.509281]\n",
      "[Epoch 44/200] [Batch 70/637] [D loss: 0.172667] [G loss: 0.483125]\n",
      "[Epoch 44/200] [Batch 71/637] [D loss: 0.171659] [G loss: 0.420881]\n",
      "[Epoch 44/200] [Batch 72/637] [D loss: 0.157075] [G loss: 0.492513]\n",
      "[Epoch 44/200] [Batch 73/637] [D loss: 0.158070] [G loss: 0.506526]\n",
      "[Epoch 44/200] [Batch 74/637] [D loss: 0.181865] [G loss: 0.524545]\n",
      "[Epoch 44/200] [Batch 75/637] [D loss: 0.160720] [G loss: 0.512277]\n",
      "[Epoch 44/200] [Batch 76/637] [D loss: 0.174161] [G loss: 0.638109]\n",
      "[Epoch 44/200] [Batch 77/637] [D loss: 0.207988] [G loss: 0.568130]\n",
      "[Epoch 44/200] [Batch 78/637] [D loss: 0.150118] [G loss: 0.483863]\n",
      "[Epoch 44/200] [Batch 79/637] [D loss: 0.165686] [G loss: 0.470414]\n",
      "[Epoch 44/200] [Batch 80/637] [D loss: 0.155361] [G loss: 0.451612]\n",
      "[Epoch 44/200] [Batch 81/637] [D loss: 0.173466] [G loss: 0.517483]\n",
      "[Epoch 44/200] [Batch 82/637] [D loss: 0.165566] [G loss: 0.521346]\n",
      "[Epoch 44/200] [Batch 83/637] [D loss: 0.154619] [G loss: 0.438891]\n",
      "[Epoch 44/200] [Batch 84/637] [D loss: 0.147551] [G loss: 0.496693]\n",
      "[Epoch 44/200] [Batch 85/637] [D loss: 0.174919] [G loss: 0.506863]\n",
      "[Epoch 44/200] [Batch 86/637] [D loss: 0.174345] [G loss: 0.502734]\n",
      "[Epoch 44/200] [Batch 87/637] [D loss: 0.161969] [G loss: 0.471650]\n",
      "[Epoch 44/200] [Batch 88/637] [D loss: 0.146626] [G loss: 0.529132]\n",
      "[Epoch 44/200] [Batch 89/637] [D loss: 0.168675] [G loss: 0.516389]\n",
      "[Epoch 44/200] [Batch 90/637] [D loss: 0.159312] [G loss: 0.510127]\n",
      "[Epoch 44/200] [Batch 91/637] [D loss: 0.151633] [G loss: 0.420265]\n",
      "[Epoch 44/200] [Batch 92/637] [D loss: 0.167078] [G loss: 0.463362]\n",
      "[Epoch 44/200] [Batch 93/637] [D loss: 0.175568] [G loss: 0.591325]\n",
      "[Epoch 44/200] [Batch 94/637] [D loss: 0.183726] [G loss: 0.532507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/200] [Batch 95/637] [D loss: 0.170435] [G loss: 0.452744]\n",
      "[Epoch 44/200] [Batch 96/637] [D loss: 0.153145] [G loss: 0.469938]\n",
      "[Epoch 44/200] [Batch 97/637] [D loss: 0.162318] [G loss: 0.526001]\n",
      "[Epoch 44/200] [Batch 98/637] [D loss: 0.185820] [G loss: 0.495505]\n",
      "[Epoch 44/200] [Batch 99/637] [D loss: 0.153085] [G loss: 0.615410]\n",
      "[Epoch 44/200] [Batch 100/637] [D loss: 0.149497] [G loss: 0.447104]\n",
      "[Epoch 44/200] [Batch 101/637] [D loss: 0.175285] [G loss: 0.474213]\n",
      "[Epoch 44/200] [Batch 102/637] [D loss: 0.162009] [G loss: 0.480930]\n",
      "[Epoch 44/200] [Batch 103/637] [D loss: 0.178530] [G loss: 0.475752]\n",
      "[Epoch 44/200] [Batch 104/637] [D loss: 0.177716] [G loss: 0.457809]\n",
      "[Epoch 44/200] [Batch 105/637] [D loss: 0.197135] [G loss: 0.493903]\n",
      "[Epoch 44/200] [Batch 106/637] [D loss: 0.177333] [G loss: 0.479394]\n",
      "[Epoch 44/200] [Batch 107/637] [D loss: 0.170770] [G loss: 0.485185]\n",
      "[Epoch 44/200] [Batch 108/637] [D loss: 0.197810] [G loss: 0.480346]\n",
      "[Epoch 44/200] [Batch 109/637] [D loss: 0.157611] [G loss: 0.437920]\n",
      "[Epoch 44/200] [Batch 110/637] [D loss: 0.174193] [G loss: 0.478830]\n",
      "[Epoch 44/200] [Batch 111/637] [D loss: 0.147640] [G loss: 0.531216]\n",
      "[Epoch 44/200] [Batch 112/637] [D loss: 0.177438] [G loss: 0.512912]\n",
      "[Epoch 44/200] [Batch 113/637] [D loss: 0.159953] [G loss: 0.491888]\n",
      "[Epoch 44/200] [Batch 114/637] [D loss: 0.162075] [G loss: 0.487011]\n",
      "[Epoch 44/200] [Batch 115/637] [D loss: 0.174156] [G loss: 0.534594]\n",
      "[Epoch 44/200] [Batch 116/637] [D loss: 0.191909] [G loss: 0.503340]\n",
      "[Epoch 44/200] [Batch 117/637] [D loss: 0.184030] [G loss: 0.425910]\n",
      "[Epoch 44/200] [Batch 118/637] [D loss: 0.163397] [G loss: 0.543999]\n",
      "[Epoch 44/200] [Batch 119/637] [D loss: 0.172549] [G loss: 0.490410]\n",
      "[Epoch 44/200] [Batch 120/637] [D loss: 0.162223] [G loss: 0.452549]\n",
      "[Epoch 44/200] [Batch 121/637] [D loss: 0.162119] [G loss: 0.445289]\n",
      "[Epoch 44/200] [Batch 122/637] [D loss: 0.172054] [G loss: 0.490048]\n",
      "[Epoch 44/200] [Batch 123/637] [D loss: 0.178693] [G loss: 0.518371]\n",
      "[Epoch 44/200] [Batch 124/637] [D loss: 0.150869] [G loss: 0.614676]\n",
      "[Epoch 44/200] [Batch 125/637] [D loss: 0.162512] [G loss: 0.513805]\n",
      "[Epoch 44/200] [Batch 126/637] [D loss: 0.171416] [G loss: 0.519600]\n",
      "[Epoch 44/200] [Batch 127/637] [D loss: 0.180751] [G loss: 0.480187]\n",
      "[Epoch 44/200] [Batch 128/637] [D loss: 0.160172] [G loss: 0.540839]\n",
      "[Epoch 44/200] [Batch 129/637] [D loss: 0.181281] [G loss: 0.475970]\n",
      "[Epoch 44/200] [Batch 130/637] [D loss: 0.166346] [G loss: 0.536294]\n",
      "[Epoch 44/200] [Batch 131/637] [D loss: 0.198473] [G loss: 0.442550]\n",
      "[Epoch 44/200] [Batch 132/637] [D loss: 0.161653] [G loss: 0.454634]\n",
      "[Epoch 44/200] [Batch 133/637] [D loss: 0.175830] [G loss: 0.446303]\n",
      "[Epoch 44/200] [Batch 134/637] [D loss: 0.156112] [G loss: 0.501098]\n",
      "[Epoch 44/200] [Batch 135/637] [D loss: 0.186526] [G loss: 0.457757]\n",
      "[Epoch 44/200] [Batch 136/637] [D loss: 0.182994] [G loss: 0.525928]\n",
      "[Epoch 44/200] [Batch 137/637] [D loss: 0.172527] [G loss: 0.463455]\n",
      "[Epoch 44/200] [Batch 138/637] [D loss: 0.166235] [G loss: 0.460986]\n",
      "[Epoch 44/200] [Batch 139/637] [D loss: 0.190090] [G loss: 0.470805]\n",
      "[Epoch 44/200] [Batch 140/637] [D loss: 0.167349] [G loss: 0.486643]\n",
      "[Epoch 44/200] [Batch 141/637] [D loss: 0.160117] [G loss: 0.493561]\n",
      "[Epoch 44/200] [Batch 142/637] [D loss: 0.167577] [G loss: 0.546860]\n",
      "[Epoch 44/200] [Batch 143/637] [D loss: 0.160272] [G loss: 0.493256]\n",
      "[Epoch 44/200] [Batch 144/637] [D loss: 0.176804] [G loss: 0.456136]\n",
      "[Epoch 44/200] [Batch 145/637] [D loss: 0.170350] [G loss: 0.466633]\n",
      "[Epoch 44/200] [Batch 146/637] [D loss: 0.161406] [G loss: 0.537171]\n",
      "[Epoch 44/200] [Batch 147/637] [D loss: 0.173989] [G loss: 0.501567]\n",
      "[Epoch 44/200] [Batch 148/637] [D loss: 0.158023] [G loss: 0.537128]\n",
      "[Epoch 44/200] [Batch 149/637] [D loss: 0.175366] [G loss: 0.516606]\n",
      "[Epoch 44/200] [Batch 150/637] [D loss: 0.193696] [G loss: 0.485653]\n",
      "[Epoch 44/200] [Batch 151/637] [D loss: 0.190576] [G loss: 0.551320]\n",
      "[Epoch 44/200] [Batch 152/637] [D loss: 0.168524] [G loss: 0.556178]\n",
      "[Epoch 44/200] [Batch 153/637] [D loss: 0.144022] [G loss: 0.514858]\n",
      "[Epoch 44/200] [Batch 154/637] [D loss: 0.164106] [G loss: 0.502753]\n",
      "[Epoch 44/200] [Batch 155/637] [D loss: 0.160877] [G loss: 0.494748]\n",
      "[Epoch 44/200] [Batch 156/637] [D loss: 0.186985] [G loss: 0.477432]\n",
      "[Epoch 44/200] [Batch 157/637] [D loss: 0.172433] [G loss: 0.555692]\n",
      "[Epoch 44/200] [Batch 158/637] [D loss: 0.149872] [G loss: 0.496270]\n",
      "[Epoch 44/200] [Batch 159/637] [D loss: 0.190821] [G loss: 0.424361]\n",
      "[Epoch 44/200] [Batch 160/637] [D loss: 0.156286] [G loss: 0.570598]\n",
      "[Epoch 44/200] [Batch 161/637] [D loss: 0.155864] [G loss: 0.515918]\n",
      "[Epoch 44/200] [Batch 162/637] [D loss: 0.163723] [G loss: 0.488302]\n",
      "[Epoch 44/200] [Batch 163/637] [D loss: 0.179268] [G loss: 0.436997]\n",
      "[Epoch 44/200] [Batch 164/637] [D loss: 0.164716] [G loss: 0.547578]\n",
      "[Epoch 44/200] [Batch 165/637] [D loss: 0.175623] [G loss: 0.541003]\n",
      "[Epoch 44/200] [Batch 166/637] [D loss: 0.153908] [G loss: 0.534643]\n",
      "[Epoch 44/200] [Batch 167/637] [D loss: 0.174861] [G loss: 0.482740]\n",
      "[Epoch 44/200] [Batch 168/637] [D loss: 0.157635] [G loss: 0.444735]\n",
      "[Epoch 44/200] [Batch 169/637] [D loss: 0.194078] [G loss: 0.462274]\n",
      "[Epoch 44/200] [Batch 170/637] [D loss: 0.178607] [G loss: 0.557323]\n",
      "[Epoch 44/200] [Batch 171/637] [D loss: 0.155992] [G loss: 0.565472]\n",
      "[Epoch 44/200] [Batch 172/637] [D loss: 0.164321] [G loss: 0.456631]\n",
      "[Epoch 44/200] [Batch 173/637] [D loss: 0.179836] [G loss: 0.461587]\n",
      "[Epoch 44/200] [Batch 174/637] [D loss: 0.173546] [G loss: 0.469641]\n",
      "[Epoch 44/200] [Batch 175/637] [D loss: 0.175275] [G loss: 0.523748]\n",
      "[Epoch 44/200] [Batch 176/637] [D loss: 0.153646] [G loss: 0.514520]\n",
      "[Epoch 44/200] [Batch 177/637] [D loss: 0.173959] [G loss: 0.471097]\n",
      "[Epoch 44/200] [Batch 178/637] [D loss: 0.157532] [G loss: 0.574909]\n",
      "[Epoch 44/200] [Batch 179/637] [D loss: 0.139097] [G loss: 0.533709]\n",
      "[Epoch 44/200] [Batch 180/637] [D loss: 0.166662] [G loss: 0.440458]\n",
      "[Epoch 44/200] [Batch 181/637] [D loss: 0.157984] [G loss: 0.566417]\n",
      "[Epoch 44/200] [Batch 182/637] [D loss: 0.160907] [G loss: 0.641741]\n",
      "[Epoch 44/200] [Batch 183/637] [D loss: 0.213044] [G loss: 0.440224]\n",
      "[Epoch 44/200] [Batch 184/637] [D loss: 0.160212] [G loss: 0.489121]\n",
      "[Epoch 44/200] [Batch 185/637] [D loss: 0.172591] [G loss: 0.495058]\n",
      "[Epoch 44/200] [Batch 186/637] [D loss: 0.156315] [G loss: 0.548819]\n",
      "[Epoch 44/200] [Batch 187/637] [D loss: 0.153311] [G loss: 0.450963]\n",
      "[Epoch 44/200] [Batch 188/637] [D loss: 0.137745] [G loss: 0.534903]\n",
      "[Epoch 44/200] [Batch 189/637] [D loss: 0.159242] [G loss: 0.509361]\n",
      "[Epoch 44/200] [Batch 190/637] [D loss: 0.145734] [G loss: 0.548729]\n",
      "[Epoch 44/200] [Batch 191/637] [D loss: 0.144724] [G loss: 0.485182]\n",
      "[Epoch 44/200] [Batch 192/637] [D loss: 0.149115] [G loss: 0.545526]\n",
      "[Epoch 44/200] [Batch 193/637] [D loss: 0.147202] [G loss: 0.590678]\n",
      "[Epoch 44/200] [Batch 194/637] [D loss: 0.191574] [G loss: 0.448709]\n",
      "[Epoch 44/200] [Batch 195/637] [D loss: 0.155488] [G loss: 0.477570]\n",
      "[Epoch 44/200] [Batch 196/637] [D loss: 0.175583] [G loss: 0.465182]\n",
      "[Epoch 44/200] [Batch 197/637] [D loss: 0.154659] [G loss: 0.528940]\n",
      "[Epoch 44/200] [Batch 198/637] [D loss: 0.189954] [G loss: 0.547439]\n",
      "[Epoch 44/200] [Batch 199/637] [D loss: 0.170644] [G loss: 0.487698]\n",
      "[Epoch 44/200] [Batch 200/637] [D loss: 0.174763] [G loss: 0.457572]\n",
      "[Epoch 44/200] [Batch 201/637] [D loss: 0.176531] [G loss: 0.480218]\n",
      "[Epoch 44/200] [Batch 202/637] [D loss: 0.160763] [G loss: 0.497769]\n",
      "[Epoch 44/200] [Batch 203/637] [D loss: 0.166133] [G loss: 0.460532]\n",
      "[Epoch 44/200] [Batch 204/637] [D loss: 0.213783] [G loss: 0.400302]\n",
      "[Epoch 44/200] [Batch 205/637] [D loss: 0.204030] [G loss: 0.525330]\n",
      "[Epoch 44/200] [Batch 206/637] [D loss: 0.175391] [G loss: 0.515074]\n",
      "[Epoch 44/200] [Batch 207/637] [D loss: 0.155792] [G loss: 0.460491]\n",
      "[Epoch 44/200] [Batch 208/637] [D loss: 0.203001] [G loss: 0.418667]\n",
      "[Epoch 44/200] [Batch 209/637] [D loss: 0.168071] [G loss: 0.457835]\n",
      "[Epoch 44/200] [Batch 210/637] [D loss: 0.188560] [G loss: 0.437242]\n",
      "[Epoch 44/200] [Batch 211/637] [D loss: 0.168663] [G loss: 0.451059]\n",
      "[Epoch 44/200] [Batch 212/637] [D loss: 0.187840] [G loss: 0.455497]\n",
      "[Epoch 44/200] [Batch 213/637] [D loss: 0.171884] [G loss: 0.499725]\n",
      "[Epoch 44/200] [Batch 214/637] [D loss: 0.166828] [G loss: 0.502782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/200] [Batch 215/637] [D loss: 0.156796] [G loss: 0.506416]\n",
      "[Epoch 44/200] [Batch 216/637] [D loss: 0.155428] [G loss: 0.464034]\n",
      "[Epoch 44/200] [Batch 217/637] [D loss: 0.170021] [G loss: 0.473809]\n",
      "[Epoch 44/200] [Batch 218/637] [D loss: 0.161918] [G loss: 0.502596]\n",
      "[Epoch 44/200] [Batch 219/637] [D loss: 0.163804] [G loss: 0.471786]\n",
      "[Epoch 44/200] [Batch 220/637] [D loss: 0.153787] [G loss: 0.511689]\n",
      "[Epoch 44/200] [Batch 221/637] [D loss: 0.159307] [G loss: 0.526312]\n",
      "[Epoch 44/200] [Batch 222/637] [D loss: 0.141328] [G loss: 0.538516]\n",
      "[Epoch 44/200] [Batch 223/637] [D loss: 0.178490] [G loss: 0.516982]\n",
      "[Epoch 44/200] [Batch 224/637] [D loss: 0.150785] [G loss: 0.576859]\n",
      "[Epoch 44/200] [Batch 225/637] [D loss: 0.156556] [G loss: 0.549654]\n",
      "[Epoch 44/200] [Batch 226/637] [D loss: 0.151797] [G loss: 0.479687]\n",
      "[Epoch 44/200] [Batch 227/637] [D loss: 0.158998] [G loss: 0.482835]\n",
      "[Epoch 44/200] [Batch 228/637] [D loss: 0.171759] [G loss: 0.490470]\n",
      "[Epoch 44/200] [Batch 229/637] [D loss: 0.176257] [G loss: 0.466909]\n",
      "[Epoch 44/200] [Batch 230/637] [D loss: 0.157732] [G loss: 0.543835]\n",
      "[Epoch 44/200] [Batch 231/637] [D loss: 0.164131] [G loss: 0.502465]\n",
      "[Epoch 44/200] [Batch 232/637] [D loss: 0.239156] [G loss: 0.441846]\n",
      "[Epoch 44/200] [Batch 233/637] [D loss: 0.197573] [G loss: 0.470397]\n",
      "[Epoch 44/200] [Batch 234/637] [D loss: 0.184262] [G loss: 0.481842]\n",
      "[Epoch 44/200] [Batch 235/637] [D loss: 0.202103] [G loss: 0.468232]\n",
      "[Epoch 44/200] [Batch 236/637] [D loss: 0.176990] [G loss: 0.564131]\n",
      "[Epoch 44/200] [Batch 237/637] [D loss: 0.167909] [G loss: 0.573383]\n",
      "[Epoch 44/200] [Batch 238/637] [D loss: 0.206881] [G loss: 0.477491]\n",
      "[Epoch 44/200] [Batch 239/637] [D loss: 0.177481] [G loss: 0.506746]\n",
      "[Epoch 44/200] [Batch 240/637] [D loss: 0.169732] [G loss: 0.516250]\n",
      "[Epoch 44/200] [Batch 241/637] [D loss: 0.161599] [G loss: 0.520852]\n",
      "[Epoch 44/200] [Batch 242/637] [D loss: 0.153754] [G loss: 0.493363]\n",
      "[Epoch 44/200] [Batch 243/637] [D loss: 0.169748] [G loss: 0.542729]\n",
      "[Epoch 44/200] [Batch 244/637] [D loss: 0.156485] [G loss: 0.485375]\n",
      "[Epoch 44/200] [Batch 245/637] [D loss: 0.177511] [G loss: 0.510018]\n",
      "[Epoch 44/200] [Batch 246/637] [D loss: 0.162579] [G loss: 0.496551]\n",
      "[Epoch 44/200] [Batch 247/637] [D loss: 0.150339] [G loss: 0.474787]\n",
      "[Epoch 44/200] [Batch 248/637] [D loss: 0.174787] [G loss: 0.524689]\n",
      "[Epoch 44/200] [Batch 249/637] [D loss: 0.156323] [G loss: 0.530555]\n",
      "[Epoch 44/200] [Batch 250/637] [D loss: 0.149482] [G loss: 0.482336]\n",
      "[Epoch 44/200] [Batch 251/637] [D loss: 0.182815] [G loss: 0.552631]\n",
      "[Epoch 44/200] [Batch 252/637] [D loss: 0.166564] [G loss: 0.563752]\n",
      "[Epoch 44/200] [Batch 253/637] [D loss: 0.197009] [G loss: 0.454209]\n",
      "[Epoch 44/200] [Batch 254/637] [D loss: 0.189770] [G loss: 0.399004]\n",
      "[Epoch 44/200] [Batch 255/637] [D loss: 0.185886] [G loss: 0.454894]\n",
      "[Epoch 44/200] [Batch 256/637] [D loss: 0.174448] [G loss: 0.505387]\n",
      "[Epoch 44/200] [Batch 257/637] [D loss: 0.183188] [G loss: 0.480823]\n",
      "[Epoch 44/200] [Batch 258/637] [D loss: 0.159661] [G loss: 0.552571]\n",
      "[Epoch 44/200] [Batch 259/637] [D loss: 0.184797] [G loss: 0.463816]\n",
      "[Epoch 44/200] [Batch 260/637] [D loss: 0.145630] [G loss: 0.475716]\n",
      "[Epoch 44/200] [Batch 261/637] [D loss: 0.221486] [G loss: 0.458623]\n",
      "[Epoch 44/200] [Batch 262/637] [D loss: 0.160220] [G loss: 0.526360]\n",
      "[Epoch 44/200] [Batch 263/637] [D loss: 0.151582] [G loss: 0.534700]\n",
      "[Epoch 44/200] [Batch 264/637] [D loss: 0.142871] [G loss: 0.501442]\n",
      "[Epoch 44/200] [Batch 265/637] [D loss: 0.163328] [G loss: 0.508811]\n",
      "[Epoch 44/200] [Batch 266/637] [D loss: 0.194941] [G loss: 0.426283]\n",
      "[Epoch 44/200] [Batch 267/637] [D loss: 0.152296] [G loss: 0.531343]\n",
      "[Epoch 44/200] [Batch 268/637] [D loss: 0.165764] [G loss: 0.500197]\n",
      "[Epoch 44/200] [Batch 269/637] [D loss: 0.137395] [G loss: 0.487587]\n",
      "[Epoch 44/200] [Batch 270/637] [D loss: 0.176444] [G loss: 0.527493]\n",
      "[Epoch 44/200] [Batch 271/637] [D loss: 0.163487] [G loss: 0.476345]\n",
      "[Epoch 44/200] [Batch 272/637] [D loss: 0.183589] [G loss: 0.472457]\n",
      "[Epoch 44/200] [Batch 273/637] [D loss: 0.176239] [G loss: 0.495569]\n",
      "[Epoch 44/200] [Batch 274/637] [D loss: 0.192557] [G loss: 0.391399]\n",
      "[Epoch 44/200] [Batch 275/637] [D loss: 0.150170] [G loss: 0.535308]\n",
      "[Epoch 44/200] [Batch 276/637] [D loss: 0.172783] [G loss: 0.513134]\n",
      "[Epoch 44/200] [Batch 277/637] [D loss: 0.151880] [G loss: 0.540819]\n",
      "[Epoch 44/200] [Batch 278/637] [D loss: 0.146374] [G loss: 0.585904]\n",
      "[Epoch 44/200] [Batch 279/637] [D loss: 0.135974] [G loss: 0.644760]\n",
      "[Epoch 44/200] [Batch 280/637] [D loss: 0.166274] [G loss: 0.540976]\n",
      "[Epoch 44/200] [Batch 281/637] [D loss: 0.169610] [G loss: 0.511675]\n",
      "[Epoch 44/200] [Batch 282/637] [D loss: 0.160160] [G loss: 0.578059]\n",
      "[Epoch 44/200] [Batch 283/637] [D loss: 0.156451] [G loss: 0.570254]\n",
      "[Epoch 44/200] [Batch 284/637] [D loss: 0.169134] [G loss: 0.609074]\n",
      "[Epoch 44/200] [Batch 285/637] [D loss: 0.151902] [G loss: 0.547207]\n",
      "[Epoch 44/200] [Batch 286/637] [D loss: 0.158506] [G loss: 0.503742]\n",
      "[Epoch 44/200] [Batch 287/637] [D loss: 0.179474] [G loss: 0.472919]\n",
      "[Epoch 44/200] [Batch 288/637] [D loss: 0.177067] [G loss: 0.531617]\n",
      "[Epoch 44/200] [Batch 289/637] [D loss: 0.145667] [G loss: 0.571198]\n",
      "[Epoch 44/200] [Batch 290/637] [D loss: 0.161825] [G loss: 0.493110]\n",
      "[Epoch 44/200] [Batch 291/637] [D loss: 0.161991] [G loss: 0.511926]\n",
      "[Epoch 44/200] [Batch 292/637] [D loss: 0.150351] [G loss: 0.565179]\n",
      "[Epoch 44/200] [Batch 293/637] [D loss: 0.153097] [G loss: 0.589198]\n",
      "[Epoch 44/200] [Batch 294/637] [D loss: 0.171727] [G loss: 0.434854]\n",
      "[Epoch 44/200] [Batch 295/637] [D loss: 0.172247] [G loss: 0.443491]\n",
      "[Epoch 44/200] [Batch 296/637] [D loss: 0.173664] [G loss: 0.429181]\n",
      "[Epoch 44/200] [Batch 297/637] [D loss: 0.158010] [G loss: 0.539859]\n",
      "[Epoch 44/200] [Batch 298/637] [D loss: 0.179455] [G loss: 0.532415]\n",
      "[Epoch 44/200] [Batch 299/637] [D loss: 0.169455] [G loss: 0.541998]\n",
      "[Epoch 44/200] [Batch 300/637] [D loss: 0.144881] [G loss: 0.474682]\n",
      "[Epoch 44/200] [Batch 301/637] [D loss: 0.182379] [G loss: 0.460116]\n",
      "[Epoch 44/200] [Batch 302/637] [D loss: 0.143329] [G loss: 0.464313]\n",
      "[Epoch 44/200] [Batch 303/637] [D loss: 0.167945] [G loss: 0.486382]\n",
      "[Epoch 44/200] [Batch 304/637] [D loss: 0.176781] [G loss: 0.443136]\n",
      "[Epoch 44/200] [Batch 305/637] [D loss: 0.148907] [G loss: 0.569914]\n",
      "[Epoch 44/200] [Batch 306/637] [D loss: 0.168698] [G loss: 0.506675]\n",
      "[Epoch 44/200] [Batch 307/637] [D loss: 0.149245] [G loss: 0.485461]\n",
      "[Epoch 44/200] [Batch 308/637] [D loss: 0.144328] [G loss: 0.547870]\n",
      "[Epoch 44/200] [Batch 309/637] [D loss: 0.165575] [G loss: 0.518534]\n",
      "[Epoch 44/200] [Batch 310/637] [D loss: 0.177633] [G loss: 0.495056]\n",
      "[Epoch 44/200] [Batch 311/637] [D loss: 0.170053] [G loss: 0.671396]\n",
      "[Epoch 44/200] [Batch 312/637] [D loss: 0.173648] [G loss: 0.604984]\n",
      "[Epoch 44/200] [Batch 313/637] [D loss: 0.165602] [G loss: 0.519096]\n",
      "[Epoch 44/200] [Batch 314/637] [D loss: 0.181322] [G loss: 0.408327]\n",
      "[Epoch 44/200] [Batch 315/637] [D loss: 0.157451] [G loss: 0.499586]\n",
      "[Epoch 44/200] [Batch 316/637] [D loss: 0.170268] [G loss: 0.549419]\n",
      "[Epoch 44/200] [Batch 317/637] [D loss: 0.147273] [G loss: 0.564114]\n",
      "[Epoch 44/200] [Batch 318/637] [D loss: 0.147970] [G loss: 0.522119]\n",
      "[Epoch 44/200] [Batch 319/637] [D loss: 0.179571] [G loss: 0.443500]\n",
      "[Epoch 44/200] [Batch 320/637] [D loss: 0.139075] [G loss: 0.565413]\n",
      "[Epoch 44/200] [Batch 321/637] [D loss: 0.156257] [G loss: 0.620332]\n",
      "[Epoch 44/200] [Batch 322/637] [D loss: 0.152456] [G loss: 0.561804]\n",
      "[Epoch 44/200] [Batch 323/637] [D loss: 0.178612] [G loss: 0.478763]\n",
      "[Epoch 44/200] [Batch 324/637] [D loss: 0.151105] [G loss: 0.503433]\n",
      "[Epoch 44/200] [Batch 325/637] [D loss: 0.160740] [G loss: 0.510747]\n",
      "[Epoch 44/200] [Batch 326/637] [D loss: 0.152835] [G loss: 0.557482]\n",
      "[Epoch 44/200] [Batch 327/637] [D loss: 0.183665] [G loss: 0.458025]\n",
      "[Epoch 44/200] [Batch 328/637] [D loss: 0.168877] [G loss: 0.559883]\n",
      "[Epoch 44/200] [Batch 329/637] [D loss: 0.159423] [G loss: 0.535107]\n",
      "[Epoch 44/200] [Batch 330/637] [D loss: 0.187270] [G loss: 0.454291]\n",
      "[Epoch 44/200] [Batch 331/637] [D loss: 0.226607] [G loss: 0.456893]\n",
      "[Epoch 44/200] [Batch 332/637] [D loss: 0.211936] [G loss: 0.453308]\n",
      "[Epoch 44/200] [Batch 333/637] [D loss: 0.186131] [G loss: 0.572600]\n",
      "[Epoch 44/200] [Batch 334/637] [D loss: 0.171782] [G loss: 0.540471]\n",
      "[Epoch 44/200] [Batch 335/637] [D loss: 0.182089] [G loss: 0.464339]\n",
      "[Epoch 44/200] [Batch 336/637] [D loss: 0.170416] [G loss: 0.474382]\n",
      "[Epoch 44/200] [Batch 337/637] [D loss: 0.172746] [G loss: 0.435989]\n",
      "[Epoch 44/200] [Batch 338/637] [D loss: 0.182650] [G loss: 0.464443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/200] [Batch 339/637] [D loss: 0.155663] [G loss: 0.628645]\n",
      "[Epoch 44/200] [Batch 340/637] [D loss: 0.179674] [G loss: 0.511452]\n",
      "[Epoch 44/200] [Batch 341/637] [D loss: 0.166419] [G loss: 0.473367]\n",
      "[Epoch 44/200] [Batch 342/637] [D loss: 0.171480] [G loss: 0.533668]\n",
      "[Epoch 44/200] [Batch 343/637] [D loss: 0.157745] [G loss: 0.508130]\n",
      "[Epoch 44/200] [Batch 344/637] [D loss: 0.164378] [G loss: 0.512613]\n",
      "[Epoch 44/200] [Batch 345/637] [D loss: 0.195588] [G loss: 0.481383]\n",
      "[Epoch 44/200] [Batch 346/637] [D loss: 0.166204] [G loss: 0.465844]\n",
      "[Epoch 44/200] [Batch 347/637] [D loss: 0.172807] [G loss: 0.495571]\n",
      "[Epoch 44/200] [Batch 348/637] [D loss: 0.150835] [G loss: 0.512426]\n",
      "[Epoch 44/200] [Batch 349/637] [D loss: 0.162675] [G loss: 0.440577]\n",
      "[Epoch 44/200] [Batch 350/637] [D loss: 0.161398] [G loss: 0.469208]\n",
      "[Epoch 44/200] [Batch 351/637] [D loss: 0.179195] [G loss: 0.457718]\n",
      "[Epoch 44/200] [Batch 352/637] [D loss: 0.167268] [G loss: 0.480073]\n",
      "[Epoch 44/200] [Batch 353/637] [D loss: 0.161988] [G loss: 0.467478]\n",
      "[Epoch 44/200] [Batch 354/637] [D loss: 0.178558] [G loss: 0.480521]\n",
      "[Epoch 44/200] [Batch 355/637] [D loss: 0.146699] [G loss: 0.537153]\n",
      "[Epoch 44/200] [Batch 356/637] [D loss: 0.165810] [G loss: 0.559198]\n",
      "[Epoch 44/200] [Batch 357/637] [D loss: 0.157876] [G loss: 0.538704]\n",
      "[Epoch 44/200] [Batch 358/637] [D loss: 0.175107] [G loss: 0.496696]\n",
      "[Epoch 44/200] [Batch 359/637] [D loss: 0.165546] [G loss: 0.495166]\n",
      "[Epoch 44/200] [Batch 360/637] [D loss: 0.186758] [G loss: 0.436543]\n",
      "[Epoch 44/200] [Batch 361/637] [D loss: 0.167455] [G loss: 0.485874]\n",
      "[Epoch 44/200] [Batch 362/637] [D loss: 0.176729] [G loss: 0.483248]\n",
      "[Epoch 44/200] [Batch 363/637] [D loss: 0.163436] [G loss: 0.541210]\n",
      "[Epoch 44/200] [Batch 364/637] [D loss: 0.163140] [G loss: 0.528634]\n",
      "[Epoch 44/200] [Batch 365/637] [D loss: 0.151761] [G loss: 0.493184]\n",
      "[Epoch 44/200] [Batch 366/637] [D loss: 0.144227] [G loss: 0.460290]\n",
      "[Epoch 44/200] [Batch 367/637] [D loss: 0.171502] [G loss: 0.498193]\n",
      "[Epoch 44/200] [Batch 368/637] [D loss: 0.168648] [G loss: 0.540629]\n",
      "[Epoch 44/200] [Batch 369/637] [D loss: 0.188030] [G loss: 0.506315]\n",
      "[Epoch 44/200] [Batch 370/637] [D loss: 0.169130] [G loss: 0.503123]\n",
      "[Epoch 44/200] [Batch 371/637] [D loss: 0.177072] [G loss: 0.480170]\n",
      "[Epoch 44/200] [Batch 372/637] [D loss: 0.142936] [G loss: 0.519655]\n",
      "[Epoch 44/200] [Batch 373/637] [D loss: 0.162536] [G loss: 0.526184]\n",
      "[Epoch 44/200] [Batch 374/637] [D loss: 0.160016] [G loss: 0.463486]\n",
      "[Epoch 44/200] [Batch 375/637] [D loss: 0.180477] [G loss: 0.470182]\n",
      "[Epoch 44/200] [Batch 376/637] [D loss: 0.155118] [G loss: 0.559156]\n",
      "[Epoch 44/200] [Batch 377/637] [D loss: 0.162827] [G loss: 0.536766]\n",
      "[Epoch 44/200] [Batch 378/637] [D loss: 0.187831] [G loss: 0.570034]\n",
      "[Epoch 44/200] [Batch 379/637] [D loss: 0.175196] [G loss: 0.446918]\n",
      "[Epoch 44/200] [Batch 380/637] [D loss: 0.155696] [G loss: 0.440155]\n",
      "[Epoch 44/200] [Batch 381/637] [D loss: 0.153895] [G loss: 0.499756]\n",
      "[Epoch 44/200] [Batch 382/637] [D loss: 0.161074] [G loss: 0.487480]\n",
      "[Epoch 44/200] [Batch 383/637] [D loss: 0.169120] [G loss: 0.497370]\n",
      "[Epoch 44/200] [Batch 384/637] [D loss: 0.150490] [G loss: 0.564316]\n",
      "[Epoch 44/200] [Batch 385/637] [D loss: 0.208413] [G loss: 0.443902]\n",
      "[Epoch 44/200] [Batch 386/637] [D loss: 0.156431] [G loss: 0.532147]\n",
      "[Epoch 44/200] [Batch 387/637] [D loss: 0.183510] [G loss: 0.530247]\n",
      "[Epoch 44/200] [Batch 388/637] [D loss: 0.176566] [G loss: 0.543485]\n",
      "[Epoch 44/200] [Batch 389/637] [D loss: 0.205179] [G loss: 0.451189]\n",
      "[Epoch 44/200] [Batch 390/637] [D loss: 0.157656] [G loss: 0.516641]\n",
      "[Epoch 44/200] [Batch 391/637] [D loss: 0.165905] [G loss: 0.478451]\n",
      "[Epoch 44/200] [Batch 392/637] [D loss: 0.214076] [G loss: 0.387404]\n",
      "[Epoch 44/200] [Batch 393/637] [D loss: 0.194479] [G loss: 0.518481]\n",
      "[Epoch 44/200] [Batch 394/637] [D loss: 0.170225] [G loss: 0.514919]\n",
      "[Epoch 44/200] [Batch 395/637] [D loss: 0.185414] [G loss: 0.436163]\n",
      "[Epoch 44/200] [Batch 396/637] [D loss: 0.164532] [G loss: 0.526340]\n",
      "[Epoch 44/200] [Batch 397/637] [D loss: 0.174343] [G loss: 0.506468]\n",
      "[Epoch 44/200] [Batch 398/637] [D loss: 0.191474] [G loss: 0.481962]\n",
      "[Epoch 44/200] [Batch 399/637] [D loss: 0.171065] [G loss: 0.454291]\n",
      "[Epoch 44/200] [Batch 400/637] [D loss: 0.163392] [G loss: 0.459745]\n",
      "[Epoch 44/200] [Batch 401/637] [D loss: 0.196050] [G loss: 0.426119]\n",
      "[Epoch 44/200] [Batch 402/637] [D loss: 0.171828] [G loss: 0.573436]\n",
      "[Epoch 44/200] [Batch 403/637] [D loss: 0.179962] [G loss: 0.466597]\n",
      "[Epoch 44/200] [Batch 404/637] [D loss: 0.178595] [G loss: 0.474581]\n",
      "[Epoch 44/200] [Batch 405/637] [D loss: 0.181401] [G loss: 0.456472]\n",
      "[Epoch 44/200] [Batch 406/637] [D loss: 0.177773] [G loss: 0.465143]\n",
      "[Epoch 44/200] [Batch 407/637] [D loss: 0.171013] [G loss: 0.484852]\n",
      "[Epoch 44/200] [Batch 408/637] [D loss: 0.171606] [G loss: 0.496667]\n",
      "[Epoch 44/200] [Batch 409/637] [D loss: 0.155896] [G loss: 0.474349]\n",
      "[Epoch 44/200] [Batch 410/637] [D loss: 0.157393] [G loss: 0.540063]\n",
      "[Epoch 44/200] [Batch 411/637] [D loss: 0.168056] [G loss: 0.530737]\n",
      "[Epoch 44/200] [Batch 412/637] [D loss: 0.146543] [G loss: 0.542385]\n",
      "[Epoch 44/200] [Batch 413/637] [D loss: 0.141989] [G loss: 0.497247]\n",
      "[Epoch 44/200] [Batch 414/637] [D loss: 0.169880] [G loss: 0.455520]\n",
      "[Epoch 44/200] [Batch 415/637] [D loss: 0.178275] [G loss: 0.491738]\n",
      "[Epoch 44/200] [Batch 416/637] [D loss: 0.174292] [G loss: 0.509981]\n",
      "[Epoch 44/200] [Batch 417/637] [D loss: 0.168346] [G loss: 0.454004]\n",
      "[Epoch 44/200] [Batch 418/637] [D loss: 0.168827] [G loss: 0.498743]\n",
      "[Epoch 44/200] [Batch 419/637] [D loss: 0.191122] [G loss: 0.565063]\n",
      "[Epoch 44/200] [Batch 420/637] [D loss: 0.180707] [G loss: 0.549024]\n",
      "[Epoch 44/200] [Batch 421/637] [D loss: 0.196144] [G loss: 0.523890]\n",
      "[Epoch 44/200] [Batch 422/637] [D loss: 0.184377] [G loss: 0.456265]\n",
      "[Epoch 44/200] [Batch 423/637] [D loss: 0.142555] [G loss: 0.463339]\n",
      "[Epoch 44/200] [Batch 424/637] [D loss: 0.162421] [G loss: 0.488649]\n",
      "[Epoch 44/200] [Batch 425/637] [D loss: 0.150961] [G loss: 0.453126]\n",
      "[Epoch 44/200] [Batch 426/637] [D loss: 0.181817] [G loss: 0.532988]\n",
      "[Epoch 44/200] [Batch 427/637] [D loss: 0.153154] [G loss: 0.613802]\n",
      "[Epoch 44/200] [Batch 428/637] [D loss: 0.155333] [G loss: 0.596040]\n",
      "[Epoch 44/200] [Batch 429/637] [D loss: 0.142834] [G loss: 0.574704]\n",
      "[Epoch 44/200] [Batch 430/637] [D loss: 0.162418] [G loss: 0.532034]\n",
      "[Epoch 44/200] [Batch 431/637] [D loss: 0.168375] [G loss: 0.475222]\n",
      "[Epoch 44/200] [Batch 432/637] [D loss: 0.183922] [G loss: 0.509945]\n",
      "[Epoch 44/200] [Batch 433/637] [D loss: 0.161937] [G loss: 0.483355]\n",
      "[Epoch 44/200] [Batch 434/637] [D loss: 0.211194] [G loss: 0.421754]\n",
      "[Epoch 44/200] [Batch 435/637] [D loss: 0.164892] [G loss: 0.476057]\n",
      "[Epoch 44/200] [Batch 436/637] [D loss: 0.198030] [G loss: 0.437443]\n",
      "[Epoch 44/200] [Batch 437/637] [D loss: 0.162231] [G loss: 0.444611]\n",
      "[Epoch 44/200] [Batch 438/637] [D loss: 0.181265] [G loss: 0.482290]\n",
      "[Epoch 44/200] [Batch 439/637] [D loss: 0.202519] [G loss: 0.448619]\n",
      "[Epoch 44/200] [Batch 440/637] [D loss: 0.167119] [G loss: 0.467122]\n",
      "[Epoch 44/200] [Batch 441/637] [D loss: 0.166267] [G loss: 0.471205]\n",
      "[Epoch 44/200] [Batch 442/637] [D loss: 0.180416] [G loss: 0.447985]\n",
      "[Epoch 44/200] [Batch 443/637] [D loss: 0.158828] [G loss: 0.486517]\n",
      "[Epoch 44/200] [Batch 444/637] [D loss: 0.167423] [G loss: 0.509082]\n",
      "[Epoch 44/200] [Batch 445/637] [D loss: 0.150592] [G loss: 0.535471]\n",
      "[Epoch 44/200] [Batch 446/637] [D loss: 0.160116] [G loss: 0.450846]\n",
      "[Epoch 44/200] [Batch 447/637] [D loss: 0.158644] [G loss: 0.487591]\n",
      "[Epoch 44/200] [Batch 448/637] [D loss: 0.152077] [G loss: 0.559442]\n",
      "[Epoch 44/200] [Batch 449/637] [D loss: 0.177360] [G loss: 0.478792]\n",
      "[Epoch 44/200] [Batch 450/637] [D loss: 0.155339] [G loss: 0.445042]\n",
      "[Epoch 44/200] [Batch 451/637] [D loss: 0.169470] [G loss: 0.417053]\n",
      "[Epoch 44/200] [Batch 452/637] [D loss: 0.172146] [G loss: 0.455484]\n",
      "[Epoch 44/200] [Batch 453/637] [D loss: 0.161407] [G loss: 0.544436]\n",
      "[Epoch 44/200] [Batch 454/637] [D loss: 0.167156] [G loss: 0.470917]\n",
      "[Epoch 44/200] [Batch 455/637] [D loss: 0.166843] [G loss: 0.457205]\n",
      "[Epoch 44/200] [Batch 456/637] [D loss: 0.157432] [G loss: 0.533895]\n",
      "[Epoch 44/200] [Batch 457/637] [D loss: 0.173800] [G loss: 0.467869]\n",
      "[Epoch 44/200] [Batch 458/637] [D loss: 0.172871] [G loss: 0.441626]\n",
      "[Epoch 44/200] [Batch 459/637] [D loss: 0.172656] [G loss: 0.495831]\n",
      "[Epoch 44/200] [Batch 460/637] [D loss: 0.167504] [G loss: 0.558915]\n",
      "[Epoch 44/200] [Batch 461/637] [D loss: 0.157155] [G loss: 0.487397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/200] [Batch 462/637] [D loss: 0.198579] [G loss: 0.435625]\n",
      "[Epoch 44/200] [Batch 463/637] [D loss: 0.211995] [G loss: 0.476890]\n",
      "[Epoch 44/200] [Batch 464/637] [D loss: 0.176666] [G loss: 0.594558]\n",
      "[Epoch 44/200] [Batch 465/637] [D loss: 0.171861] [G loss: 0.565309]\n",
      "[Epoch 44/200] [Batch 466/637] [D loss: 0.173898] [G loss: 0.473303]\n",
      "[Epoch 44/200] [Batch 467/637] [D loss: 0.175983] [G loss: 0.448607]\n",
      "[Epoch 44/200] [Batch 468/637] [D loss: 0.188240] [G loss: 0.390882]\n",
      "[Epoch 44/200] [Batch 469/637] [D loss: 0.171524] [G loss: 0.488953]\n",
      "[Epoch 44/200] [Batch 470/637] [D loss: 0.170991] [G loss: 0.533953]\n",
      "[Epoch 44/200] [Batch 471/637] [D loss: 0.145856] [G loss: 0.500913]\n",
      "[Epoch 44/200] [Batch 472/637] [D loss: 0.192194] [G loss: 0.474013]\n",
      "[Epoch 44/200] [Batch 473/637] [D loss: 0.171662] [G loss: 0.548641]\n",
      "[Epoch 44/200] [Batch 474/637] [D loss: 0.159703] [G loss: 0.511668]\n",
      "[Epoch 44/200] [Batch 475/637] [D loss: 0.179495] [G loss: 0.396921]\n",
      "[Epoch 44/200] [Batch 476/637] [D loss: 0.177950] [G loss: 0.453739]\n",
      "[Epoch 44/200] [Batch 477/637] [D loss: 0.150513] [G loss: 0.573027]\n",
      "[Epoch 44/200] [Batch 478/637] [D loss: 0.190116] [G loss: 0.454710]\n",
      "[Epoch 44/200] [Batch 479/637] [D loss: 0.184773] [G loss: 0.500219]\n",
      "[Epoch 44/200] [Batch 480/637] [D loss: 0.166103] [G loss: 0.509711]\n",
      "[Epoch 44/200] [Batch 481/637] [D loss: 0.168772] [G loss: 0.460581]\n",
      "[Epoch 44/200] [Batch 482/637] [D loss: 0.186111] [G loss: 0.457030]\n",
      "[Epoch 44/200] [Batch 483/637] [D loss: 0.176453] [G loss: 0.512671]\n",
      "[Epoch 44/200] [Batch 484/637] [D loss: 0.174313] [G loss: 0.521631]\n",
      "[Epoch 44/200] [Batch 485/637] [D loss: 0.165268] [G loss: 0.533894]\n",
      "[Epoch 44/200] [Batch 486/637] [D loss: 0.175263] [G loss: 0.627270]\n",
      "[Epoch 44/200] [Batch 487/637] [D loss: 0.158358] [G loss: 0.584903]\n",
      "[Epoch 44/200] [Batch 488/637] [D loss: 0.200867] [G loss: 0.451296]\n",
      "[Epoch 44/200] [Batch 489/637] [D loss: 0.180766] [G loss: 0.463662]\n",
      "[Epoch 44/200] [Batch 490/637] [D loss: 0.189597] [G loss: 0.405463]\n",
      "[Epoch 44/200] [Batch 491/637] [D loss: 0.183308] [G loss: 0.479766]\n",
      "[Epoch 44/200] [Batch 492/637] [D loss: 0.164241] [G loss: 0.471454]\n",
      "[Epoch 44/200] [Batch 493/637] [D loss: 0.155355] [G loss: 0.536318]\n",
      "[Epoch 44/200] [Batch 494/637] [D loss: 0.173350] [G loss: 0.437619]\n",
      "[Epoch 44/200] [Batch 495/637] [D loss: 0.154317] [G loss: 0.453898]\n",
      "[Epoch 44/200] [Batch 496/637] [D loss: 0.212542] [G loss: 0.492776]\n",
      "[Epoch 44/200] [Batch 497/637] [D loss: 0.156783] [G loss: 0.591509]\n",
      "[Epoch 44/200] [Batch 498/637] [D loss: 0.171795] [G loss: 0.577643]\n",
      "[Epoch 44/200] [Batch 499/637] [D loss: 0.161212] [G loss: 0.481297]\n",
      "[Epoch 44/200] [Batch 500/637] [D loss: 0.192511] [G loss: 0.345681]\n",
      "[Epoch 44/200] [Batch 501/637] [D loss: 0.173732] [G loss: 0.417173]\n",
      "[Epoch 44/200] [Batch 502/637] [D loss: 0.164252] [G loss: 0.553357]\n",
      "[Epoch 44/200] [Batch 503/637] [D loss: 0.174291] [G loss: 0.500391]\n",
      "[Epoch 44/200] [Batch 504/637] [D loss: 0.151036] [G loss: 0.532396]\n",
      "[Epoch 44/200] [Batch 505/637] [D loss: 0.178663] [G loss: 0.404571]\n",
      "[Epoch 44/200] [Batch 506/637] [D loss: 0.168924] [G loss: 0.430240]\n",
      "[Epoch 44/200] [Batch 507/637] [D loss: 0.174664] [G loss: 0.490471]\n",
      "[Epoch 44/200] [Batch 508/637] [D loss: 0.159496] [G loss: 0.542298]\n",
      "[Epoch 44/200] [Batch 509/637] [D loss: 0.184395] [G loss: 0.476617]\n",
      "[Epoch 44/200] [Batch 510/637] [D loss: 0.192019] [G loss: 0.450636]\n",
      "[Epoch 44/200] [Batch 511/637] [D loss: 0.185058] [G loss: 0.465530]\n",
      "[Epoch 44/200] [Batch 512/637] [D loss: 0.178035] [G loss: 0.514012]\n",
      "[Epoch 44/200] [Batch 513/637] [D loss: 0.172070] [G loss: 0.460829]\n",
      "[Epoch 44/200] [Batch 514/637] [D loss: 0.206380] [G loss: 0.434016]\n",
      "[Epoch 44/200] [Batch 515/637] [D loss: 0.157695] [G loss: 0.522502]\n",
      "[Epoch 44/200] [Batch 516/637] [D loss: 0.157472] [G loss: 0.504784]\n",
      "[Epoch 44/200] [Batch 517/637] [D loss: 0.159852] [G loss: 0.473076]\n",
      "[Epoch 44/200] [Batch 518/637] [D loss: 0.155319] [G loss: 0.511819]\n",
      "[Epoch 44/200] [Batch 519/637] [D loss: 0.155151] [G loss: 0.525208]\n",
      "[Epoch 44/200] [Batch 520/637] [D loss: 0.160723] [G loss: 0.484155]\n",
      "[Epoch 44/200] [Batch 521/637] [D loss: 0.149297] [G loss: 0.509969]\n",
      "[Epoch 44/200] [Batch 522/637] [D loss: 0.148222] [G loss: 0.559224]\n",
      "[Epoch 44/200] [Batch 523/637] [D loss: 0.168282] [G loss: 0.554032]\n",
      "[Epoch 44/200] [Batch 524/637] [D loss: 0.169487] [G loss: 0.500884]\n",
      "[Epoch 44/200] [Batch 525/637] [D loss: 0.193078] [G loss: 0.419212]\n",
      "[Epoch 44/200] [Batch 526/637] [D loss: 0.175757] [G loss: 0.482296]\n",
      "[Epoch 44/200] [Batch 527/637] [D loss: 0.164332] [G loss: 0.540245]\n",
      "[Epoch 44/200] [Batch 528/637] [D loss: 0.177594] [G loss: 0.470553]\n",
      "[Epoch 44/200] [Batch 529/637] [D loss: 0.171828] [G loss: 0.426611]\n",
      "[Epoch 44/200] [Batch 530/637] [D loss: 0.175575] [G loss: 0.500567]\n",
      "[Epoch 44/200] [Batch 531/637] [D loss: 0.169632] [G loss: 0.476809]\n",
      "[Epoch 44/200] [Batch 532/637] [D loss: 0.145063] [G loss: 0.493549]\n",
      "[Epoch 44/200] [Batch 533/637] [D loss: 0.155257] [G loss: 0.537154]\n",
      "[Epoch 44/200] [Batch 534/637] [D loss: 0.144917] [G loss: 0.504696]\n",
      "[Epoch 44/200] [Batch 535/637] [D loss: 0.159850] [G loss: 0.517669]\n",
      "[Epoch 44/200] [Batch 536/637] [D loss: 0.166914] [G loss: 0.532559]\n",
      "[Epoch 44/200] [Batch 537/637] [D loss: 0.168006] [G loss: 0.535468]\n",
      "[Epoch 44/200] [Batch 538/637] [D loss: 0.173214] [G loss: 0.505179]\n",
      "[Epoch 44/200] [Batch 539/637] [D loss: 0.174681] [G loss: 0.465312]\n",
      "[Epoch 44/200] [Batch 540/637] [D loss: 0.180693] [G loss: 0.429702]\n",
      "[Epoch 44/200] [Batch 541/637] [D loss: 0.162957] [G loss: 0.534760]\n",
      "[Epoch 44/200] [Batch 542/637] [D loss: 0.201317] [G loss: 0.509572]\n",
      "[Epoch 44/200] [Batch 543/637] [D loss: 0.168331] [G loss: 0.563350]\n",
      "[Epoch 44/200] [Batch 544/637] [D loss: 0.178071] [G loss: 0.502440]\n",
      "[Epoch 44/200] [Batch 545/637] [D loss: 0.169956] [G loss: 0.503678]\n",
      "[Epoch 44/200] [Batch 546/637] [D loss: 0.163555] [G loss: 0.522312]\n",
      "[Epoch 44/200] [Batch 547/637] [D loss: 0.165842] [G loss: 0.490373]\n",
      "[Epoch 44/200] [Batch 548/637] [D loss: 0.171374] [G loss: 0.400091]\n",
      "[Epoch 44/200] [Batch 549/637] [D loss: 0.179918] [G loss: 0.484784]\n",
      "[Epoch 44/200] [Batch 550/637] [D loss: 0.156077] [G loss: 0.511858]\n",
      "[Epoch 44/200] [Batch 551/637] [D loss: 0.168955] [G loss: 0.559359]\n",
      "[Epoch 44/200] [Batch 552/637] [D loss: 0.173292] [G loss: 0.453788]\n",
      "[Epoch 44/200] [Batch 553/637] [D loss: 0.162464] [G loss: 0.466740]\n",
      "[Epoch 44/200] [Batch 554/637] [D loss: 0.177564] [G loss: 0.463586]\n",
      "[Epoch 44/200] [Batch 555/637] [D loss: 0.141433] [G loss: 0.535064]\n",
      "[Epoch 44/200] [Batch 556/637] [D loss: 0.173524] [G loss: 0.502246]\n",
      "[Epoch 44/200] [Batch 557/637] [D loss: 0.183097] [G loss: 0.479752]\n",
      "[Epoch 44/200] [Batch 558/637] [D loss: 0.185443] [G loss: 0.422783]\n",
      "[Epoch 44/200] [Batch 559/637] [D loss: 0.187197] [G loss: 0.475768]\n",
      "[Epoch 44/200] [Batch 560/637] [D loss: 0.174334] [G loss: 0.520786]\n",
      "[Epoch 44/200] [Batch 561/637] [D loss: 0.168156] [G loss: 0.454945]\n",
      "[Epoch 44/200] [Batch 562/637] [D loss: 0.167454] [G loss: 0.461038]\n",
      "[Epoch 44/200] [Batch 563/637] [D loss: 0.160401] [G loss: 0.511606]\n",
      "[Epoch 44/200] [Batch 564/637] [D loss: 0.167457] [G loss: 0.421047]\n",
      "[Epoch 44/200] [Batch 565/637] [D loss: 0.204376] [G loss: 0.395558]\n",
      "[Epoch 44/200] [Batch 566/637] [D loss: 0.155507] [G loss: 0.526510]\n",
      "[Epoch 44/200] [Batch 567/637] [D loss: 0.163182] [G loss: 0.485217]\n",
      "[Epoch 44/200] [Batch 568/637] [D loss: 0.170615] [G loss: 0.506454]\n",
      "[Epoch 44/200] [Batch 569/637] [D loss: 0.166408] [G loss: 0.512191]\n",
      "[Epoch 44/200] [Batch 570/637] [D loss: 0.175535] [G loss: 0.515460]\n",
      "[Epoch 44/200] [Batch 571/637] [D loss: 0.183709] [G loss: 0.493336]\n",
      "[Epoch 44/200] [Batch 572/637] [D loss: 0.171865] [G loss: 0.484796]\n",
      "[Epoch 44/200] [Batch 573/637] [D loss: 0.196211] [G loss: 0.425018]\n",
      "[Epoch 44/200] [Batch 574/637] [D loss: 0.144509] [G loss: 0.439621]\n",
      "[Epoch 44/200] [Batch 575/637] [D loss: 0.171661] [G loss: 0.444700]\n",
      "[Epoch 44/200] [Batch 576/637] [D loss: 0.154425] [G loss: 0.513274]\n",
      "[Epoch 44/200] [Batch 577/637] [D loss: 0.155767] [G loss: 0.562706]\n",
      "[Epoch 44/200] [Batch 578/637] [D loss: 0.162014] [G loss: 0.531659]\n",
      "[Epoch 44/200] [Batch 579/637] [D loss: 0.166592] [G loss: 0.446477]\n",
      "[Epoch 44/200] [Batch 580/637] [D loss: 0.166108] [G loss: 0.465648]\n",
      "[Epoch 44/200] [Batch 581/637] [D loss: 0.156744] [G loss: 0.517570]\n",
      "[Epoch 44/200] [Batch 582/637] [D loss: 0.176392] [G loss: 0.450176]\n",
      "[Epoch 44/200] [Batch 583/637] [D loss: 0.163396] [G loss: 0.506270]\n",
      "[Epoch 44/200] [Batch 584/637] [D loss: 0.171359] [G loss: 0.507954]\n",
      "[Epoch 44/200] [Batch 585/637] [D loss: 0.193270] [G loss: 0.475381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/200] [Batch 586/637] [D loss: 0.181717] [G loss: 0.408912]\n",
      "[Epoch 44/200] [Batch 587/637] [D loss: 0.160599] [G loss: 0.503081]\n",
      "[Epoch 44/200] [Batch 588/637] [D loss: 0.165102] [G loss: 0.565180]\n",
      "[Epoch 44/200] [Batch 589/637] [D loss: 0.183333] [G loss: 0.468130]\n",
      "[Epoch 44/200] [Batch 590/637] [D loss: 0.145505] [G loss: 0.532032]\n",
      "[Epoch 44/200] [Batch 591/637] [D loss: 0.162756] [G loss: 0.542068]\n",
      "[Epoch 44/200] [Batch 592/637] [D loss: 0.165625] [G loss: 0.512518]\n",
      "[Epoch 44/200] [Batch 593/637] [D loss: 0.159031] [G loss: 0.521477]\n",
      "[Epoch 44/200] [Batch 594/637] [D loss: 0.178229] [G loss: 0.500051]\n",
      "[Epoch 44/200] [Batch 595/637] [D loss: 0.156409] [G loss: 0.436877]\n",
      "[Epoch 44/200] [Batch 596/637] [D loss: 0.180414] [G loss: 0.463848]\n",
      "[Epoch 44/200] [Batch 597/637] [D loss: 0.150654] [G loss: 0.498891]\n",
      "[Epoch 44/200] [Batch 598/637] [D loss: 0.179929] [G loss: 0.487984]\n",
      "[Epoch 44/200] [Batch 599/637] [D loss: 0.179683] [G loss: 0.487475]\n",
      "[Epoch 44/200] [Batch 600/637] [D loss: 0.160150] [G loss: 0.558543]\n",
      "[Epoch 44/200] [Batch 601/637] [D loss: 0.151753] [G loss: 0.494117]\n",
      "[Epoch 44/200] [Batch 602/637] [D loss: 0.149720] [G loss: 0.554079]\n",
      "[Epoch 44/200] [Batch 603/637] [D loss: 0.160379] [G loss: 0.494733]\n",
      "[Epoch 44/200] [Batch 604/637] [D loss: 0.151913] [G loss: 0.510081]\n",
      "[Epoch 44/200] [Batch 605/637] [D loss: 0.147766] [G loss: 0.557710]\n",
      "[Epoch 44/200] [Batch 606/637] [D loss: 0.169664] [G loss: 0.532601]\n",
      "[Epoch 44/200] [Batch 607/637] [D loss: 0.208893] [G loss: 0.511650]\n",
      "[Epoch 44/200] [Batch 608/637] [D loss: 0.165203] [G loss: 0.477620]\n",
      "[Epoch 44/200] [Batch 609/637] [D loss: 0.214350] [G loss: 0.454810]\n",
      "[Epoch 44/200] [Batch 610/637] [D loss: 0.171780] [G loss: 0.517922]\n",
      "[Epoch 44/200] [Batch 611/637] [D loss: 0.171993] [G loss: 0.519137]\n",
      "[Epoch 44/200] [Batch 612/637] [D loss: 0.176487] [G loss: 0.448271]\n",
      "[Epoch 44/200] [Batch 613/637] [D loss: 0.156869] [G loss: 0.509580]\n",
      "[Epoch 44/200] [Batch 614/637] [D loss: 0.152850] [G loss: 0.476249]\n",
      "[Epoch 44/200] [Batch 615/637] [D loss: 0.164998] [G loss: 0.427154]\n",
      "[Epoch 44/200] [Batch 616/637] [D loss: 0.166944] [G loss: 0.487660]\n",
      "[Epoch 44/200] [Batch 617/637] [D loss: 0.174800] [G loss: 0.479493]\n",
      "[Epoch 44/200] [Batch 618/637] [D loss: 0.166117] [G loss: 0.549045]\n",
      "[Epoch 44/200] [Batch 619/637] [D loss: 0.157314] [G loss: 0.473369]\n",
      "[Epoch 44/200] [Batch 620/637] [D loss: 0.148955] [G loss: 0.537290]\n",
      "[Epoch 44/200] [Batch 621/637] [D loss: 0.164143] [G loss: 0.560286]\n",
      "[Epoch 44/200] [Batch 622/637] [D loss: 0.145382] [G loss: 0.509200]\n",
      "[Epoch 44/200] [Batch 623/637] [D loss: 0.167626] [G loss: 0.531183]\n",
      "[Epoch 44/200] [Batch 624/637] [D loss: 0.152244] [G loss: 0.512541]\n",
      "[Epoch 44/200] [Batch 625/637] [D loss: 0.228030] [G loss: 0.520397]\n",
      "[Epoch 44/200] [Batch 626/637] [D loss: 0.184766] [G loss: 0.418893]\n",
      "[Epoch 44/200] [Batch 627/637] [D loss: 0.166415] [G loss: 0.512149]\n",
      "[Epoch 44/200] [Batch 628/637] [D loss: 0.172565] [G loss: 0.460678]\n",
      "[Epoch 44/200] [Batch 629/637] [D loss: 0.151779] [G loss: 0.502805]\n",
      "[Epoch 44/200] [Batch 630/637] [D loss: 0.151511] [G loss: 0.465423]\n",
      "[Epoch 44/200] [Batch 631/637] [D loss: 0.171361] [G loss: 0.460923]\n",
      "[Epoch 44/200] [Batch 632/637] [D loss: 0.152386] [G loss: 0.471142]\n",
      "[Epoch 44/200] [Batch 633/637] [D loss: 0.145870] [G loss: 0.506976]\n",
      "[Epoch 44/200] [Batch 634/637] [D loss: 0.167283] [G loss: 0.459743]\n",
      "[Epoch 44/200] [Batch 635/637] [D loss: 0.184304] [G loss: 0.542428]\n",
      "[Epoch 44/200] [Batch 636/637] [D loss: 0.140981] [G loss: 0.563855]\n",
      "[Epoch 45/200] [Batch 0/637] [D loss: 0.198761] [G loss: 0.507672]\n",
      "[Epoch 45/200] [Batch 1/637] [D loss: 0.183494] [G loss: 0.474054]\n",
      "[Epoch 45/200] [Batch 2/637] [D loss: 0.174955] [G loss: 0.593329]\n",
      "[Epoch 45/200] [Batch 3/637] [D loss: 0.169241] [G loss: 0.533154]\n",
      "[Epoch 45/200] [Batch 4/637] [D loss: 0.165611] [G loss: 0.425963]\n",
      "[Epoch 45/200] [Batch 5/637] [D loss: 0.167851] [G loss: 0.463596]\n",
      "[Epoch 45/200] [Batch 6/637] [D loss: 0.168747] [G loss: 0.487506]\n",
      "[Epoch 45/200] [Batch 7/637] [D loss: 0.151206] [G loss: 0.589700]\n",
      "[Epoch 45/200] [Batch 8/637] [D loss: 0.184334] [G loss: 0.467540]\n",
      "[Epoch 45/200] [Batch 9/637] [D loss: 0.162215] [G loss: 0.473747]\n",
      "[Epoch 45/200] [Batch 10/637] [D loss: 0.171197] [G loss: 0.399320]\n",
      "[Epoch 45/200] [Batch 11/637] [D loss: 0.155329] [G loss: 0.522371]\n",
      "[Epoch 45/200] [Batch 12/637] [D loss: 0.173293] [G loss: 0.484380]\n",
      "[Epoch 45/200] [Batch 13/637] [D loss: 0.159765] [G loss: 0.531982]\n",
      "[Epoch 45/200] [Batch 14/637] [D loss: 0.132131] [G loss: 0.578461]\n",
      "[Epoch 45/200] [Batch 15/637] [D loss: 0.155188] [G loss: 0.458933]\n",
      "[Epoch 45/200] [Batch 16/637] [D loss: 0.191367] [G loss: 0.447096]\n",
      "[Epoch 45/200] [Batch 17/637] [D loss: 0.148627] [G loss: 0.525046]\n",
      "[Epoch 45/200] [Batch 18/637] [D loss: 0.173461] [G loss: 0.531314]\n",
      "[Epoch 45/200] [Batch 19/637] [D loss: 0.159652] [G loss: 0.544584]\n",
      "[Epoch 45/200] [Batch 20/637] [D loss: 0.142885] [G loss: 0.559394]\n",
      "[Epoch 45/200] [Batch 21/637] [D loss: 0.182712] [G loss: 0.471665]\n",
      "[Epoch 45/200] [Batch 22/637] [D loss: 0.177276] [G loss: 0.551946]\n",
      "[Epoch 45/200] [Batch 23/637] [D loss: 0.167614] [G loss: 0.570855]\n",
      "[Epoch 45/200] [Batch 24/637] [D loss: 0.184672] [G loss: 0.434186]\n",
      "[Epoch 45/200] [Batch 25/637] [D loss: 0.186109] [G loss: 0.512911]\n",
      "[Epoch 45/200] [Batch 26/637] [D loss: 0.154762] [G loss: 0.585104]\n",
      "[Epoch 45/200] [Batch 27/637] [D loss: 0.147123] [G loss: 0.544513]\n",
      "[Epoch 45/200] [Batch 28/637] [D loss: 0.156166] [G loss: 0.518824]\n",
      "[Epoch 45/200] [Batch 29/637] [D loss: 0.173285] [G loss: 0.462244]\n",
      "[Epoch 45/200] [Batch 30/637] [D loss: 0.177639] [G loss: 0.492935]\n",
      "[Epoch 45/200] [Batch 31/637] [D loss: 0.144783] [G loss: 0.498031]\n",
      "[Epoch 45/200] [Batch 32/637] [D loss: 0.167711] [G loss: 0.552215]\n",
      "[Epoch 45/200] [Batch 33/637] [D loss: 0.186035] [G loss: 0.543472]\n",
      "[Epoch 45/200] [Batch 34/637] [D loss: 0.161772] [G loss: 0.497785]\n",
      "[Epoch 45/200] [Batch 35/637] [D loss: 0.151180] [G loss: 0.514516]\n",
      "[Epoch 45/200] [Batch 36/637] [D loss: 0.164163] [G loss: 0.454849]\n",
      "[Epoch 45/200] [Batch 37/637] [D loss: 0.160301] [G loss: 0.497933]\n",
      "[Epoch 45/200] [Batch 38/637] [D loss: 0.187661] [G loss: 0.509344]\n",
      "[Epoch 45/200] [Batch 39/637] [D loss: 0.166027] [G loss: 0.501746]\n",
      "[Epoch 45/200] [Batch 40/637] [D loss: 0.182401] [G loss: 0.484384]\n",
      "[Epoch 45/200] [Batch 41/637] [D loss: 0.180336] [G loss: 0.501255]\n",
      "[Epoch 45/200] [Batch 42/637] [D loss: 0.158448] [G loss: 0.534831]\n",
      "[Epoch 45/200] [Batch 43/637] [D loss: 0.166670] [G loss: 0.494611]\n",
      "[Epoch 45/200] [Batch 44/637] [D loss: 0.193768] [G loss: 0.474167]\n",
      "[Epoch 45/200] [Batch 45/637] [D loss: 0.160596] [G loss: 0.525709]\n",
      "[Epoch 45/200] [Batch 46/637] [D loss: 0.161614] [G loss: 0.421867]\n",
      "[Epoch 45/200] [Batch 47/637] [D loss: 0.168717] [G loss: 0.449365]\n",
      "[Epoch 45/200] [Batch 48/637] [D loss: 0.143431] [G loss: 0.540342]\n",
      "[Epoch 45/200] [Batch 49/637] [D loss: 0.206650] [G loss: 0.453172]\n",
      "[Epoch 45/200] [Batch 50/637] [D loss: 0.171940] [G loss: 0.584682]\n",
      "[Epoch 45/200] [Batch 51/637] [D loss: 0.170992] [G loss: 0.532707]\n",
      "[Epoch 45/200] [Batch 52/637] [D loss: 0.154522] [G loss: 0.533405]\n",
      "[Epoch 45/200] [Batch 53/637] [D loss: 0.152855] [G loss: 0.472724]\n",
      "[Epoch 45/200] [Batch 54/637] [D loss: 0.170315] [G loss: 0.412215]\n",
      "[Epoch 45/200] [Batch 55/637] [D loss: 0.157038] [G loss: 0.504156]\n",
      "[Epoch 45/200] [Batch 56/637] [D loss: 0.154259] [G loss: 0.601887]\n",
      "[Epoch 45/200] [Batch 57/637] [D loss: 0.168176] [G loss: 0.546284]\n",
      "[Epoch 45/200] [Batch 58/637] [D loss: 0.141035] [G loss: 0.589945]\n",
      "[Epoch 45/200] [Batch 59/637] [D loss: 0.165373] [G loss: 0.452537]\n",
      "[Epoch 45/200] [Batch 60/637] [D loss: 0.151880] [G loss: 0.531181]\n",
      "[Epoch 45/200] [Batch 61/637] [D loss: 0.139629] [G loss: 0.574174]\n",
      "[Epoch 45/200] [Batch 62/637] [D loss: 0.175576] [G loss: 0.530999]\n",
      "[Epoch 45/200] [Batch 63/637] [D loss: 0.188244] [G loss: 0.454496]\n",
      "[Epoch 45/200] [Batch 64/637] [D loss: 0.170051] [G loss: 0.502707]\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            sample_image(n_row=27, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([729, 3, 64, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_imgs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
